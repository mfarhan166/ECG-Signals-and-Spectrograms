{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "7e88OLey6Bgd"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7e88OLey6Bgd"
      },
      "source": [
        "# **Image Classification with Convolutional Neural Networks (CNNs)**\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsTzc3oi726u"
      },
      "source": [
        "# **Building a Convolutional Neural Network with Keras**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import Libraries**"
      ],
      "metadata": {
        "id": "lT2H7gBmACML"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCglDGFy8AhT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "ebd8e8a1-250e-44d5-bd08-8a165139a39a"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "tf.__version__\n",
        "\n",
        "import psutil\n",
        "import GPUtil\n",
        "\n",
        "import os,sys,humanize,psutil,GPUtil\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import matplotlib.image as mpimg\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "import imageio\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.8.2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Memory Utilization Checkup (Before/After Model Execution)**"
      ],
      "metadata": {
        "id": "OwMflxlbAsfK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#CPU AND GPU LIBRARIES INSTALLATION (if you find error on import of psutil and GPUtil, please refer below)\n",
        "!pip install psutil\n",
        "!pip install GPUtil"
      ],
      "metadata": {
        "id": "Q2bPbY1LEG_0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb5e5f78-f535-4f74-915e-bf25d7e1b7fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting GPUtil\n",
            "  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\n",
            "Building wheels for collected packages: GPUtil\n",
            "  Building wheel for GPUtil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for GPUtil: filename=GPUtil-1.4.0-py3-none-any.whl size=7411 sha256=f41c3354aa64dc7521ad9786ec65f356a8194b9338ce1ecca32f161dcf013c0c\n",
            "  Stored in directory: /root/.cache/pip/wheels/6e/f8/83/534c52482d6da64622ddbf72cd93c35d2ef2881b78fd08ff0c\n",
            "Successfully built GPUtil\n",
            "Installing collected packages: GPUtil\n",
            "Successfully installed GPUtil-1.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CHECKING THE CPU AND GPU MEMORY\n",
        "\n",
        "# Testing the psutil library for both CPU and RAM performance details\n",
        "print(psutil.cpu_percent())\n",
        "print(psutil.sys.ram)\n",
        "print(psutil.virtual_memory().percent)\n",
        "# Testing the GPUtil library for both GPU performance details\n",
        "GPUtil.showUtilization()"
      ],
      "metadata": {
        "id": "rnT_bgIWERmI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#CPU MEMORY UTILIZATION\n",
        "\n",
        "!cat /proc/meminfo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rwrm76EmJ2Fv",
        "outputId": "2c6abe31-7da2-49b3-f888-d0bfc63f886b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MemTotal:       13298572 kB\n",
            "MemFree:         3426352 kB\n",
            "MemAvailable:   10348672 kB\n",
            "Buffers:          130260 kB\n",
            "Cached:          5873676 kB\n",
            "SwapCached:            0 kB\n",
            "Active:          3185400 kB\n",
            "Inactive:        6177368 kB\n",
            "Active(anon):    2329176 kB\n",
            "Inactive(anon):    14792 kB\n",
            "Active(file):     856224 kB\n",
            "Inactive(file):  6162576 kB\n",
            "Unevictable:           0 kB\n",
            "Mlocked:               0 kB\n",
            "SwapTotal:             0 kB\n",
            "SwapFree:              0 kB\n",
            "Dirty:               248 kB\n",
            "Writeback:             0 kB\n",
            "AnonPages:       3358868 kB\n",
            "Mapped:          1712792 kB\n",
            "Shmem:             15548 kB\n",
            "KReclaimable:     229572 kB\n",
            "Slab:             295072 kB\n",
            "SReclaimable:     229572 kB\n",
            "SUnreclaim:        65500 kB\n",
            "KernelStack:        5312 kB\n",
            "PageTables:        24120 kB\n",
            "NFS_Unstable:          0 kB\n",
            "Bounce:                0 kB\n",
            "WritebackTmp:          0 kB\n",
            "CommitLimit:     6649284 kB\n",
            "Committed_AS:    5873988 kB\n",
            "VmallocTotal:   34359738367 kB\n",
            "VmallocUsed:       51372 kB\n",
            "VmallocChunk:          0 kB\n",
            "Percpu:             1504 kB\n",
            "AnonHugePages:     40960 kB\n",
            "ShmemHugePages:        0 kB\n",
            "ShmemPmdMapped:        0 kB\n",
            "FileHugePages:         0 kB\n",
            "FilePmdMapped:         0 kB\n",
            "CmaTotal:              0 kB\n",
            "CmaFree:               0 kB\n",
            "HugePages_Total:       0\n",
            "HugePages_Free:        0\n",
            "HugePages_Rsvd:        0\n",
            "HugePages_Surp:        0\n",
            "Hugepagesize:       2048 kB\n",
            "Hugetlb:               0 kB\n",
            "DirectMap4k:      226112 kB\n",
            "DirectMap2M:     8159232 kB\n",
            "DirectMap1G:     7340032 kB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!grep MemTotal /proc/meminfo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0pgr9seSLdYf",
        "outputId": "098c34a9-beff-4d3a-b2ec-11c412c15673"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MemTotal:       13298572 kB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#GPU MEMORY UTILIZATION \n",
        "!nvidia-smi --query-gpu=memory.total --format=csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLQu663TLjBQ",
        "outputId": "1b2b200d-94fb-4838-f688-96d2f5acc765"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "memory.total [MiB]\n",
            "15109 MiB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function\n",
        "def mem_report():\n",
        "  print(\"CPU RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ))\n",
        "  \n",
        "  GPUs = GPUtil.getGPUs()\n",
        "  for i, gpu in enumerate(GPUs):\n",
        "    print('GPU {:d} ... Mem Free: {:.0f}MB / {:.0f}MB | Utilization {:3.0f}%'.format(i, gpu.memoryFree, gpu.memoryTotal, gpu.memoryUtil*100))\n",
        "\n",
        "mem_report()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fd_O6FIRJGtv",
        "outputId": "8ee3632f-aee1-4634-f181-48bab157cc53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU RAM Free: 10.6 GB\n",
            "GPU 0 ... Mem Free: 10421MB / 15109MB | Utilization  31%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Let's Start with Model Implementation**"
      ],
      "metadata": {
        "id": "LOyPVde22QGD"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qf7eW3HC9XVL"
      },
      "source": [
        "**Data Acquisition and ImageDataGenerator**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0BfyGlJbx0l"
      },
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255) #Normalize the pixel values\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hsimgs7aqt6G"
      },
      "source": [
        "#File path to the folder containin images\n",
        "train_dir = os.path.join('/content/dataset-colab/Train')\n",
        "validation_dir = os.path.join('/content/dataset-colab/Test')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NyvlF41oqxEP",
        "outputId": "4cfabfb0-9a59-492d-9e3e-287714f55f05",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(64,64),\n",
        "    batch_size=256,\n",
        "    shuffle=True,\n",
        "    class_mode='binary')\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    validation_dir,\n",
        "    target_size=(64,64),\n",
        "    batch_size=256,\n",
        "    shuffle=True,\n",
        "    class_mode='binary')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 33128 images belonging to 2 classes.\n",
            "Found 6780 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3yhwpN_-BaS"
      },
      "source": [
        "**Building the Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSzxq4KDtKN6"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "                                    \n",
        "    # First convolution layer \n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(64, 64, 3),use_bias=True),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "\n",
        "    # Second convolution layer \n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu',use_bias=True),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    \n",
        "\n",
        "    # Third convolution layer \n",
        "    tf.keras.layers.Conv2D(256, (3,3), activation='relu',use_bias=True),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "\n",
        "    # Fourth convolution layer  \n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu',use_bias=True),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "\n",
        "    # Flatten the pooled feature maps\n",
        "    tf.keras.layers.Flatten(),\n",
        "\n",
        "    # Fully connected hidden layer\n",
        "    tf.keras.layers.Dense(8, activation='relu',use_bias=True),\n",
        "\n",
        "    # Output layer\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid',activity_regularizer=regularizers.L1(0.001))   \n",
        "\n",
        "])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Printing Model Summary**"
      ],
      "metadata": {
        "id": "QF4_GItOBHKI"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HU0RFGLtNJb",
        "outputId": "08c30a3c-9036-4547-f6ec-6ffdd88b7e8f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 62, 62, 64)        1792      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 31, 31, 64)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 31, 31, 64)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 29, 29, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 14, 14, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 12, 12, 256)       295168    \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 6, 6, 256)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 6, 6, 256)         0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 4, 4, 64)          147520    \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 2, 2, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 2, 2, 64)          0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 8)                 2056      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 520,401\n",
            "Trainable params: 520,401\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Optimizer Implementation and model training/validation**"
      ],
      "metadata": {
        "id": "uVYZ8VwKBQRC"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBN3GBMItPMH"
      },
      "source": [
        "#from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import SensitivityAtSpecificity,SpecificityAtSensitivity,Recall,Precision\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=Adam(learning_rate=0.001),\n",
        "              metrics=['accuracy',SensitivityAtSpecificity(0.5),SpecificityAtSensitivity(0.5),Recall(0.5),Precision(0.5)])  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Q0MPMwh3EgY"
      },
      "source": [
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('val_accuracy')>0.99): \n",
        "      print(\"\\nReached 99% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "callbacks = myCallback()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7f6gDG3dx9sJ",
        "outputId": "a394d933-66c2-4bb8-ab07-4fce74eb1682",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "checkpoint = ModelCheckpoint(\"ECG_Spectrogram_Model.h5\", monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
        "\n",
        "history = model.fit(\n",
        "      train_generator,\n",
        "      steps_per_epoch=10,  \n",
        "      epochs=500,\n",
        "      verbose=1,\n",
        "      validation_data = validation_generator,\n",
        "      validation_steps=5, \n",
        "      callbacks = [callbacks,checkpoint]\n",
        ") "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6997 - accuracy: 0.5004 - sensitivity_at_specificity: 0.4652 - specificity_at_sensitivity: 0.4637 - recall: 0.3439 - precision: 0.5086\n",
            "Epoch 1: val_accuracy improved from -inf to 0.50313, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 18s 237ms/step - loss: 0.6997 - accuracy: 0.5004 - sensitivity_at_specificity: 0.4652 - specificity_at_sensitivity: 0.4637 - recall: 0.3439 - precision: 0.5086 - val_loss: 0.6936 - val_accuracy: 0.5031 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.0000e+00 - val_recall: 1.0000 - val_precision: 0.5031\n",
            "Epoch 2/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6935 - accuracy: 0.5277 - sensitivity_at_specificity: 0.0406 - specificity_at_sensitivity: 0.0772 - recall: 0.9077 - precision: 0.5315\n",
            "Epoch 2: val_accuracy did not improve from 0.50313\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.6935 - accuracy: 0.5277 - sensitivity_at_specificity: 0.0406 - specificity_at_sensitivity: 0.0772 - recall: 0.9077 - precision: 0.5315 - val_loss: 0.6938 - val_accuracy: 0.4898 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.0000e+00 - val_recall: 1.0000 - val_precision: 0.4898\n",
            "Epoch 3/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6947 - accuracy: 0.5063 - sensitivity_at_specificity: 0.3118 - specificity_at_sensitivity: 0.0119 - recall: 0.9862 - precision: 0.5075\n",
            "Epoch 3: val_accuracy improved from 0.50313 to 0.51172, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.6947 - accuracy: 0.5063 - sensitivity_at_specificity: 0.3118 - specificity_at_sensitivity: 0.0119 - recall: 0.9862 - precision: 0.5075 - val_loss: 0.6935 - val_accuracy: 0.5117 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.0000e+00 - val_recall: 1.0000 - val_precision: 0.5117\n",
            "Epoch 4/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6937 - accuracy: 0.4992 - sensitivity_at_specificity: 0.0117 - specificity_at_sensitivity: 0.0070 - recall: 0.9953 - precision: 0.5000\n",
            "Epoch 4: val_accuracy did not improve from 0.51172\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.6937 - accuracy: 0.4992 - sensitivity_at_specificity: 0.0117 - specificity_at_sensitivity: 0.0070 - recall: 0.9953 - precision: 0.5000 - val_loss: 0.6936 - val_accuracy: 0.5023 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.0000e+00 - val_recall: 1.0000 - val_precision: 0.5023\n",
            "Epoch 5/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6936 - accuracy: 0.5035 - sensitivity_at_specificity: 0.0000e+00 - specificity_at_sensitivity: 0.0220 - recall: 0.9899 - precision: 0.5036\n",
            "Epoch 5: val_accuracy did not improve from 0.51172\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.6936 - accuracy: 0.5035 - sensitivity_at_specificity: 0.0000e+00 - specificity_at_sensitivity: 0.0220 - recall: 0.9899 - precision: 0.5036 - val_loss: 0.6936 - val_accuracy: 0.5039 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.0000e+00 - val_recall: 1.0000 - val_precision: 0.5039\n",
            "Epoch 6/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6937 - accuracy: 0.4941 - sensitivity_at_specificity: 0.0000e+00 - specificity_at_sensitivity: 0.0355 - recall: 0.9897 - precision: 0.4937\n",
            "Epoch 6: val_accuracy did not improve from 0.51172\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.6937 - accuracy: 0.4941 - sensitivity_at_specificity: 0.0000e+00 - specificity_at_sensitivity: 0.0355 - recall: 0.9897 - precision: 0.4937 - val_loss: 0.6938 - val_accuracy: 0.4891 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.0000e+00 - val_recall: 1.0000 - val_precision: 0.4891\n",
            "Epoch 7/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6937 - accuracy: 0.5000 - sensitivity_at_specificity: 0.0000e+00 - specificity_at_sensitivity: 0.0381 - recall: 0.9867 - precision: 0.4990\n",
            "Epoch 7: val_accuracy improved from 0.51172 to 0.51797, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.6937 - accuracy: 0.5000 - sensitivity_at_specificity: 0.0000e+00 - specificity_at_sensitivity: 0.0381 - recall: 0.9867 - precision: 0.4990 - val_loss: 0.6935 - val_accuracy: 0.5180 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.0000e+00 - val_recall: 1.0000 - val_precision: 0.5180\n",
            "Epoch 8/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6936 - accuracy: 0.5063 - sensitivity_at_specificity: 0.0000e+00 - specificity_at_sensitivity: 0.0419 - recall: 0.9838 - precision: 0.5062\n",
            "Epoch 8: val_accuracy did not improve from 0.51797\n",
            "10/10 [==============================] - 2s 223ms/step - loss: 0.6936 - accuracy: 0.5063 - sensitivity_at_specificity: 0.0000e+00 - specificity_at_sensitivity: 0.0419 - recall: 0.9838 - precision: 0.5062 - val_loss: 0.6937 - val_accuracy: 0.4953 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.0000e+00 - val_recall: 1.0000 - val_precision: 0.4953\n",
            "Epoch 9/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6938 - accuracy: 0.4891 - sensitivity_at_specificity: 0.0000e+00 - specificity_at_sensitivity: 0.0374 - recall: 0.9880 - precision: 0.4883\n",
            "Epoch 9: val_accuracy did not improve from 0.51797\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.6938 - accuracy: 0.4891 - sensitivity_at_specificity: 0.0000e+00 - specificity_at_sensitivity: 0.0374 - recall: 0.9880 - precision: 0.4883 - val_loss: 0.6937 - val_accuracy: 0.4930 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.0000e+00 - val_recall: 1.0000 - val_precision: 0.4930\n",
            "Epoch 10/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6938 - accuracy: 0.4875 - sensitivity_at_specificity: 0.0833 - specificity_at_sensitivity: 0.0107 - recall: 0.9776 - precision: 0.4872\n",
            "Epoch 10: val_accuracy improved from 0.51797 to 0.51875, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.6938 - accuracy: 0.4875 - sensitivity_at_specificity: 0.0833 - specificity_at_sensitivity: 0.0107 - recall: 0.9776 - precision: 0.4872 - val_loss: 0.6935 - val_accuracy: 0.5188 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.0000e+00 - val_recall: 1.0000 - val_precision: 0.5188\n",
            "Epoch 11/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6936 - accuracy: 0.5004 - sensitivity_at_specificity: 0.0000e+00 - specificity_at_sensitivity: 0.0078 - recall: 0.9859 - precision: 0.4994\n",
            "Epoch 11: val_accuracy did not improve from 0.51875\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.6936 - accuracy: 0.5004 - sensitivity_at_specificity: 0.0000e+00 - specificity_at_sensitivity: 0.0078 - recall: 0.9859 - precision: 0.4994 - val_loss: 0.6936 - val_accuracy: 0.5063 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.0000e+00 - val_recall: 1.0000 - val_precision: 0.5063\n",
            "Epoch 12/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6937 - accuracy: 0.4926 - sensitivity_at_specificity: 0.0000e+00 - specificity_at_sensitivity: 0.0054 - recall: 0.9788 - precision: 0.4950\n",
            "Epoch 12: val_accuracy did not improve from 0.51875\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.6937 - accuracy: 0.4926 - sensitivity_at_specificity: 0.0000e+00 - specificity_at_sensitivity: 0.0054 - recall: 0.9788 - precision: 0.4950 - val_loss: 0.6937 - val_accuracy: 0.4984 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.0000e+00 - val_recall: 1.0000 - val_precision: 0.4984\n",
            "Epoch 13/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6936 - accuracy: 0.5188 - sensitivity_at_specificity: 0.0000e+00 - specificity_at_sensitivity: 0.0041 - recall: 0.9895 - precision: 0.5195\n",
            "Epoch 13: val_accuracy improved from 0.51875 to 0.52266, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.6936 - accuracy: 0.5188 - sensitivity_at_specificity: 0.0000e+00 - specificity_at_sensitivity: 0.0041 - recall: 0.9895 - precision: 0.5195 - val_loss: 0.6936 - val_accuracy: 0.5227 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.0000e+00 - val_recall: 1.0000 - val_precision: 0.5227\n",
            "Epoch 14/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6937 - accuracy: 0.4975 - sensitivity_at_specificity: 0.0000e+00 - specificity_at_sensitivity: 0.0017 - recall: 0.9950 - precision: 0.4973\n",
            "Epoch 14: val_accuracy did not improve from 0.52266\n",
            "10/10 [==============================] - 2s 196ms/step - loss: 0.6937 - accuracy: 0.4975 - sensitivity_at_specificity: 0.0000e+00 - specificity_at_sensitivity: 0.0017 - recall: 0.9950 - precision: 0.4973 - val_loss: 0.6937 - val_accuracy: 0.4922 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.0000e+00 - val_recall: 1.0000 - val_precision: 0.4922\n",
            "Epoch 15/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6937 - accuracy: 0.5004 - sensitivity_at_specificity: 0.0000e+00 - specificity_at_sensitivity: 0.0023 - recall: 0.9930 - precision: 0.5008\n",
            "Epoch 15: val_accuracy did not improve from 0.52266\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.6937 - accuracy: 0.5004 - sensitivity_at_specificity: 0.0000e+00 - specificity_at_sensitivity: 0.0023 - recall: 0.9930 - precision: 0.5008 - val_loss: 0.6937 - val_accuracy: 0.4961 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.0000e+00 - val_recall: 1.0000 - val_precision: 0.4961\n",
            "Epoch 16/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6936 - accuracy: 0.5023 - sensitivity_at_specificity: 0.0000e+00 - specificity_at_sensitivity: 0.0000e+00 - recall: 0.9977 - precision: 0.5022\n",
            "Epoch 16: val_accuracy did not improve from 0.52266\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.6936 - accuracy: 0.5023 - sensitivity_at_specificity: 0.0000e+00 - specificity_at_sensitivity: 0.0000e+00 - recall: 0.9977 - precision: 0.5022 - val_loss: 0.6937 - val_accuracy: 0.4938 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.0000e+00 - val_recall: 1.0000 - val_precision: 0.4938\n",
            "Epoch 17/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6936 - accuracy: 0.5141 - sensitivity_at_specificity: 0.0000e+00 - specificity_at_sensitivity: 0.0032 - recall: 0.9954 - precision: 0.5136\n",
            "Epoch 17: val_accuracy did not improve from 0.52266\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.6936 - accuracy: 0.5141 - sensitivity_at_specificity: 0.0000e+00 - specificity_at_sensitivity: 0.0032 - recall: 0.9954 - precision: 0.5136 - val_loss: 0.6937 - val_accuracy: 0.4922 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.0000e+00 - val_recall: 1.0000 - val_precision: 0.4922\n",
            "Epoch 18/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6936 - accuracy: 0.5000 - sensitivity_at_specificity: 0.0000e+00 - specificity_at_sensitivity: 0.0047 - recall: 0.9891 - precision: 0.5006\n",
            "Epoch 18: val_accuracy did not improve from 0.52266\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.6936 - accuracy: 0.5000 - sensitivity_at_specificity: 0.0000e+00 - specificity_at_sensitivity: 0.0047 - recall: 0.9891 - precision: 0.5006 - val_loss: 0.6937 - val_accuracy: 0.5008 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.0000e+00 - val_recall: 1.0000 - val_precision: 0.5008\n",
            "Epoch 19/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6937 - accuracy: 0.4909 - sensitivity_at_specificity: 0.0000e+00 - specificity_at_sensitivity: 0.0065 - recall: 0.9856 - precision: 0.4912\n",
            "Epoch 19: val_accuracy did not improve from 0.52266\n",
            "10/10 [==============================] - 2s 155ms/step - loss: 0.6937 - accuracy: 0.4909 - sensitivity_at_specificity: 0.0000e+00 - specificity_at_sensitivity: 0.0065 - recall: 0.9856 - precision: 0.4912 - val_loss: 0.6937 - val_accuracy: 0.4938 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.0000e+00 - val_recall: 1.0000 - val_precision: 0.4938\n",
            "Epoch 20/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6935 - accuracy: 0.5090 - sensitivity_at_specificity: 0.0000e+00 - specificity_at_sensitivity: 0.0418 - recall: 0.9551 - precision: 0.5072\n",
            "Epoch 20: val_accuracy did not improve from 0.52266\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.6935 - accuracy: 0.5090 - sensitivity_at_specificity: 0.0000e+00 - specificity_at_sensitivity: 0.0418 - recall: 0.9551 - precision: 0.5072 - val_loss: 0.6936 - val_accuracy: 0.5008 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.0000e+00 - val_recall: 1.0000 - val_precision: 0.5008\n",
            "Epoch 21/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6938 - accuracy: 0.5168 - sensitivity_at_specificity: 0.5160 - specificity_at_sensitivity: 0.5098 - recall: 0.4754 - precision: 0.5196\n",
            "Epoch 21: val_accuracy did not improve from 0.52266\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.6938 - accuracy: 0.5168 - sensitivity_at_specificity: 0.5160 - specificity_at_sensitivity: 0.5098 - recall: 0.4754 - precision: 0.5196 - val_loss: 0.6935 - val_accuracy: 0.4727 - val_sensitivity_at_specificity: 0.5230 - val_specificity_at_sensitivity: 0.5321 - val_recall: 0.1560 - val_precision: 0.4953\n",
            "Epoch 22/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6919 - accuracy: 0.4980 - sensitivity_at_specificity: 0.4521 - specificity_at_sensitivity: 0.4455 - recall: 0.3733 - precision: 0.5047\n",
            "Epoch 22: val_accuracy did not improve from 0.52266\n",
            "10/10 [==============================] - 2s 203ms/step - loss: 0.6919 - accuracy: 0.4980 - sensitivity_at_specificity: 0.4521 - specificity_at_sensitivity: 0.4455 - recall: 0.3733 - precision: 0.5047 - val_loss: 0.6876 - val_accuracy: 0.5000 - val_sensitivity_at_specificity: 0.6221 - val_specificity_at_sensitivity: 0.5667 - val_recall: 0.2348 - val_precision: 0.5050\n",
            "Epoch 23/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6763 - accuracy: 0.5547 - sensitivity_at_specificity: 0.6577 - specificity_at_sensitivity: 0.6424 - recall: 0.3872 - precision: 0.5749\n",
            "Epoch 23: val_accuracy improved from 0.52266 to 0.60781, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 184ms/step - loss: 0.6763 - accuracy: 0.5547 - sensitivity_at_specificity: 0.6577 - specificity_at_sensitivity: 0.6424 - recall: 0.3872 - precision: 0.5749 - val_loss: 0.6649 - val_accuracy: 0.6078 - val_sensitivity_at_specificity: 0.7453 - val_specificity_at_sensitivity: 0.5932 - val_recall: 0.6336 - val_precision: 0.5997\n",
            "Epoch 24/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6503 - accuracy: 0.5984 - sensitivity_at_specificity: 0.7254 - specificity_at_sensitivity: 0.6333 - recall: 0.5931 - precision: 0.6071\n",
            "Epoch 24: val_accuracy did not improve from 0.60781\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.6503 - accuracy: 0.5984 - sensitivity_at_specificity: 0.7254 - specificity_at_sensitivity: 0.6333 - recall: 0.5931 - precision: 0.6071 - val_loss: 0.6780 - val_accuracy: 0.5523 - val_sensitivity_at_specificity: 0.6503 - val_specificity_at_sensitivity: 0.6497 - val_recall: 0.9755 - val_precision: 0.5169\n",
            "Epoch 25/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6071 - accuracy: 0.6438 - sensitivity_at_specificity: 0.7862 - specificity_at_sensitivity: 0.7174 - recall: 0.8068 - precision: 0.6027\n",
            "Epoch 25: val_accuracy improved from 0.60781 to 0.68125, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.6071 - accuracy: 0.6438 - sensitivity_at_specificity: 0.7862 - specificity_at_sensitivity: 0.7174 - recall: 0.8068 - precision: 0.6027 - val_loss: 0.5835 - val_accuracy: 0.6812 - val_sensitivity_at_specificity: 0.8536 - val_specificity_at_sensitivity: 0.9232 - val_recall: 0.6355 - val_precision: 0.7010\n",
            "Epoch 26/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6187 - accuracy: 0.6555 - sensitivity_at_specificity: 0.8062 - specificity_at_sensitivity: 0.7984 - recall: 0.7659 - precision: 0.6301\n",
            "Epoch 26: val_accuracy did not improve from 0.68125\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.6187 - accuracy: 0.6555 - sensitivity_at_specificity: 0.8062 - specificity_at_sensitivity: 0.7984 - recall: 0.7659 - precision: 0.6301 - val_loss: 0.6226 - val_accuracy: 0.6281 - val_sensitivity_at_specificity: 0.7398 - val_specificity_at_sensitivity: 0.8352 - val_recall: 0.7307 - val_precision: 0.6184\n",
            "Epoch 27/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5695 - accuracy: 0.6730 - sensitivity_at_specificity: 0.8388 - specificity_at_sensitivity: 0.8233 - recall: 0.8101 - precision: 0.6289\n",
            "Epoch 27: val_accuracy improved from 0.68125 to 0.76484, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.5695 - accuracy: 0.6730 - sensitivity_at_specificity: 0.8388 - specificity_at_sensitivity: 0.8233 - recall: 0.8101 - precision: 0.6289 - val_loss: 0.5078 - val_accuracy: 0.7648 - val_sensitivity_at_specificity: 0.9271 - val_specificity_at_sensitivity: 0.9228 - val_recall: 0.8313 - val_precision: 0.7422\n",
            "Epoch 28/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4925 - accuracy: 0.7437 - sensitivity_at_specificity: 0.9203 - specificity_at_sensitivity: 0.9143 - recall: 0.7826 - precision: 0.7158\n",
            "Epoch 28: val_accuracy improved from 0.76484 to 0.80469, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.4925 - accuracy: 0.7437 - sensitivity_at_specificity: 0.9203 - specificity_at_sensitivity: 0.9143 - recall: 0.7826 - precision: 0.7158 - val_loss: 0.4571 - val_accuracy: 0.8047 - val_sensitivity_at_specificity: 0.9724 - val_specificity_at_sensitivity: 0.9157 - val_recall: 0.8602 - val_precision: 0.7789\n",
            "Epoch 29/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4429 - accuracy: 0.7895 - sensitivity_at_specificity: 0.9578 - specificity_at_sensitivity: 0.9375 - recall: 0.8055 - precision: 0.7805\n",
            "Epoch 29: val_accuracy improved from 0.80469 to 0.81016, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.4429 - accuracy: 0.7895 - sensitivity_at_specificity: 0.9578 - specificity_at_sensitivity: 0.9375 - recall: 0.8055 - precision: 0.7805 - val_loss: 0.4399 - val_accuracy: 0.8102 - val_sensitivity_at_specificity: 0.9602 - val_specificity_at_sensitivity: 0.9537 - val_recall: 0.8899 - val_precision: 0.7729\n",
            "Epoch 30/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4179 - accuracy: 0.8086 - sensitivity_at_specificity: 0.9589 - specificity_at_sensitivity: 0.9513 - recall: 0.8245 - precision: 0.8009\n",
            "Epoch 30: val_accuracy did not improve from 0.81016\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.4179 - accuracy: 0.8086 - sensitivity_at_specificity: 0.9589 - specificity_at_sensitivity: 0.9513 - recall: 0.8245 - precision: 0.8009 - val_loss: 0.5909 - val_accuracy: 0.6859 - val_sensitivity_at_specificity: 0.9799 - val_specificity_at_sensitivity: 0.9464 - val_recall: 0.9938 - val_precision: 0.6173\n",
            "Epoch 31/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4076 - accuracy: 0.8203 - sensitivity_at_specificity: 0.9721 - specificity_at_sensitivity: 0.9479 - recall: 0.8319 - precision: 0.8074\n",
            "Epoch 31: val_accuracy did not improve from 0.81016\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.4076 - accuracy: 0.8203 - sensitivity_at_specificity: 0.9721 - specificity_at_sensitivity: 0.9479 - recall: 0.8319 - precision: 0.8074 - val_loss: 0.4368 - val_accuracy: 0.8047 - val_sensitivity_at_specificity: 0.9839 - val_specificity_at_sensitivity: 0.9361 - val_recall: 0.8828 - val_precision: 0.7565\n",
            "Epoch 32/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3768 - accuracy: 0.8258 - sensitivity_at_specificity: 0.9793 - specificity_at_sensitivity: 0.9655 - recall: 0.8207 - precision: 0.8233\n",
            "Epoch 32: val_accuracy improved from 0.81016 to 0.85312, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.3768 - accuracy: 0.8258 - sensitivity_at_specificity: 0.9793 - specificity_at_sensitivity: 0.9655 - recall: 0.8207 - precision: 0.8233 - val_loss: 0.3721 - val_accuracy: 0.8531 - val_sensitivity_at_specificity: 0.9785 - val_specificity_at_sensitivity: 0.9650 - val_recall: 0.8848 - val_precision: 0.8360\n",
            "Epoch 33/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3927 - accuracy: 0.8328 - sensitivity_at_specificity: 0.9657 - specificity_at_sensitivity: 0.9564 - recall: 0.8206 - precision: 0.8352\n",
            "Epoch 33: val_accuracy did not improve from 0.85312\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.3927 - accuracy: 0.8328 - sensitivity_at_specificity: 0.9657 - specificity_at_sensitivity: 0.9564 - recall: 0.8206 - precision: 0.8352 - val_loss: 0.4288 - val_accuracy: 0.7977 - val_sensitivity_at_specificity: 0.9874 - val_specificity_at_sensitivity: 0.9643 - val_recall: 0.9591 - val_precision: 0.7233\n",
            "Epoch 34/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3610 - accuracy: 0.8371 - sensitivity_at_specificity: 0.9851 - specificity_at_sensitivity: 0.9697 - recall: 0.8611 - precision: 0.8205\n",
            "Epoch 34: val_accuracy did not improve from 0.85312\n",
            "10/10 [==============================] - 2s 204ms/step - loss: 0.3610 - accuracy: 0.8371 - sensitivity_at_specificity: 0.9851 - specificity_at_sensitivity: 0.9697 - recall: 0.8611 - precision: 0.8205 - val_loss: 0.3573 - val_accuracy: 0.8422 - val_sensitivity_at_specificity: 0.9888 - val_specificity_at_sensitivity: 0.9574 - val_recall: 0.7833 - val_precision: 0.8793\n",
            "Epoch 35/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3631 - accuracy: 0.8461 - sensitivity_at_specificity: 0.9828 - specificity_at_sensitivity: 0.9665 - recall: 0.8480 - precision: 0.8440\n",
            "Epoch 35: val_accuracy improved from 0.85312 to 0.88594, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.3631 - accuracy: 0.8461 - sensitivity_at_specificity: 0.9828 - specificity_at_sensitivity: 0.9665 - recall: 0.8480 - precision: 0.8440 - val_loss: 0.3193 - val_accuracy: 0.8859 - val_sensitivity_at_specificity: 0.9924 - val_specificity_at_sensitivity: 0.9679 - val_recall: 0.8963 - val_precision: 0.8829\n",
            "Epoch 36/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3527 - accuracy: 0.8492 - sensitivity_at_specificity: 0.9829 - specificity_at_sensitivity: 0.9725 - recall: 0.8524 - precision: 0.8484\n",
            "Epoch 36: val_accuracy did not improve from 0.88594\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.3527 - accuracy: 0.8492 - sensitivity_at_specificity: 0.9829 - specificity_at_sensitivity: 0.9725 - recall: 0.8524 - precision: 0.8484 - val_loss: 0.3366 - val_accuracy: 0.8773 - val_sensitivity_at_specificity: 0.9935 - val_specificity_at_sensitivity: 0.9639 - val_recall: 0.9220 - val_precision: 0.8388\n",
            "Epoch 37/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3317 - accuracy: 0.8613 - sensitivity_at_specificity: 0.9924 - specificity_at_sensitivity: 0.9655 - recall: 0.8867 - precision: 0.8499\n",
            "Epoch 37: val_accuracy did not improve from 0.88594\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.3317 - accuracy: 0.8613 - sensitivity_at_specificity: 0.9924 - specificity_at_sensitivity: 0.9655 - recall: 0.8867 - precision: 0.8499 - val_loss: 0.3948 - val_accuracy: 0.8359 - val_sensitivity_at_specificity: 0.9923 - val_specificity_at_sensitivity: 0.9668 - val_recall: 0.9460 - val_precision: 0.7779\n",
            "Epoch 38/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3154 - accuracy: 0.8648 - sensitivity_at_specificity: 0.9937 - specificity_at_sensitivity: 0.9722 - recall: 0.8672 - precision: 0.8604\n",
            "Epoch 38: val_accuracy did not improve from 0.88594\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.3154 - accuracy: 0.8648 - sensitivity_at_specificity: 0.9937 - specificity_at_sensitivity: 0.9722 - recall: 0.8672 - precision: 0.8604 - val_loss: 0.3915 - val_accuracy: 0.8320 - val_sensitivity_at_specificity: 0.9847 - val_specificity_at_sensitivity: 0.9665 - val_recall: 0.9296 - val_precision: 0.7822\n",
            "Epoch 39/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3139 - accuracy: 0.8691 - sensitivity_at_specificity: 0.9921 - specificity_at_sensitivity: 0.9775 - recall: 0.8687 - precision: 0.8680\n",
            "Epoch 39: val_accuracy did not improve from 0.88594\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.3139 - accuracy: 0.8691 - sensitivity_at_specificity: 0.9921 - specificity_at_sensitivity: 0.9775 - recall: 0.8687 - precision: 0.8680 - val_loss: 0.3384 - val_accuracy: 0.8586 - val_sensitivity_at_specificity: 0.9937 - val_specificity_at_sensitivity: 0.9735 - val_recall: 0.9452 - val_precision: 0.8053\n",
            "Epoch 40/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3212 - accuracy: 0.8656 - sensitivity_at_specificity: 0.9915 - specificity_at_sensitivity: 0.9715 - recall: 0.8798 - precision: 0.8586\n",
            "Epoch 40: val_accuracy did not improve from 0.88594\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.3212 - accuracy: 0.8656 - sensitivity_at_specificity: 0.9915 - specificity_at_sensitivity: 0.9715 - recall: 0.8798 - precision: 0.8586 - val_loss: 0.3008 - val_accuracy: 0.8797 - val_sensitivity_at_specificity: 0.9935 - val_specificity_at_sensitivity: 0.9804 - val_recall: 0.9222 - val_precision: 0.8430\n",
            "Epoch 41/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2983 - accuracy: 0.8750 - sensitivity_at_specificity: 0.9930 - specificity_at_sensitivity: 0.9742 - recall: 0.8870 - precision: 0.8667\n",
            "Epoch 41: val_accuracy did not improve from 0.88594\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.2983 - accuracy: 0.8750 - sensitivity_at_specificity: 0.9930 - specificity_at_sensitivity: 0.9742 - recall: 0.8870 - precision: 0.8667 - val_loss: 0.3334 - val_accuracy: 0.8609 - val_sensitivity_at_specificity: 0.9935 - val_specificity_at_sensitivity: 0.9713 - val_recall: 0.9287 - val_precision: 0.8105\n",
            "Epoch 42/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2980 - accuracy: 0.8727 - sensitivity_at_specificity: 0.9930 - specificity_at_sensitivity: 0.9819 - recall: 0.8632 - precision: 0.8810\n",
            "Epoch 42: val_accuracy did not improve from 0.88594\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.2980 - accuracy: 0.8727 - sensitivity_at_specificity: 0.9930 - specificity_at_sensitivity: 0.9819 - recall: 0.8632 - precision: 0.8810 - val_loss: 0.3797 - val_accuracy: 0.8305 - val_sensitivity_at_specificity: 0.9937 - val_specificity_at_sensitivity: 0.9676 - val_recall: 0.9746 - val_precision: 0.7537\n",
            "Epoch 43/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3101 - accuracy: 0.8703 - sensitivity_at_specificity: 0.9921 - specificity_at_sensitivity: 0.9769 - recall: 0.8964 - precision: 0.8493\n",
            "Epoch 43: val_accuracy did not improve from 0.88594\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.3101 - accuracy: 0.8703 - sensitivity_at_specificity: 0.9921 - specificity_at_sensitivity: 0.9769 - recall: 0.8964 - precision: 0.8493 - val_loss: 0.3363 - val_accuracy: 0.8687 - val_sensitivity_at_specificity: 0.9954 - val_specificity_at_sensitivity: 0.9651 - val_recall: 0.9431 - val_precision: 0.8239\n",
            "Epoch 44/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3033 - accuracy: 0.8641 - sensitivity_at_specificity: 0.9962 - specificity_at_sensitivity: 0.9785 - recall: 0.8774 - precision: 0.8590\n",
            "Epoch 44: val_accuracy did not improve from 0.88594\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.3033 - accuracy: 0.8641 - sensitivity_at_specificity: 0.9962 - specificity_at_sensitivity: 0.9785 - recall: 0.8774 - precision: 0.8590 - val_loss: 0.3675 - val_accuracy: 0.8359 - val_sensitivity_at_specificity: 0.9954 - val_specificity_at_sensitivity: 0.9760 - val_recall: 0.9588 - val_precision: 0.7746\n",
            "Epoch 45/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3186 - accuracy: 0.8617 - sensitivity_at_specificity: 0.9936 - specificity_at_sensitivity: 0.9701 - recall: 0.8814 - precision: 0.8438\n",
            "Epoch 45: val_accuracy did not improve from 0.88594\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.3186 - accuracy: 0.8617 - sensitivity_at_specificity: 0.9936 - specificity_at_sensitivity: 0.9701 - recall: 0.8814 - precision: 0.8438 - val_loss: 0.3798 - val_accuracy: 0.8313 - val_sensitivity_at_specificity: 0.9953 - val_specificity_at_sensitivity: 0.9720 - val_recall: 0.9592 - val_precision: 0.7631\n",
            "Epoch 46/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3162 - accuracy: 0.8617 - sensitivity_at_specificity: 0.9915 - specificity_at_sensitivity: 0.9770 - recall: 0.8751 - precision: 0.8553\n",
            "Epoch 46: val_accuracy improved from 0.88594 to 0.88672, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.3162 - accuracy: 0.8617 - sensitivity_at_specificity: 0.9915 - specificity_at_sensitivity: 0.9770 - recall: 0.8751 - precision: 0.8553 - val_loss: 0.3020 - val_accuracy: 0.8867 - val_sensitivity_at_specificity: 0.9921 - val_specificity_at_sensitivity: 0.9846 - val_recall: 0.9351 - val_precision: 0.8504\n",
            "Epoch 47/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2862 - accuracy: 0.8793 - sensitivity_at_specificity: 0.9954 - specificity_at_sensitivity: 0.9770 - recall: 0.8882 - precision: 0.8754\n",
            "Epoch 47: val_accuracy did not improve from 0.88672\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.2862 - accuracy: 0.8793 - sensitivity_at_specificity: 0.9954 - specificity_at_sensitivity: 0.9770 - recall: 0.8882 - precision: 0.8754 - val_loss: 0.3387 - val_accuracy: 0.8617 - val_sensitivity_at_specificity: 0.9922 - val_specificity_at_sensitivity: 0.9748 - val_recall: 0.9658 - val_precision: 0.8005\n",
            "Epoch 48/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2983 - accuracy: 0.8637 - sensitivity_at_specificity: 0.9938 - specificity_at_sensitivity: 0.9851 - recall: 0.8840 - precision: 0.8503\n",
            "Epoch 48: val_accuracy did not improve from 0.88672\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.2983 - accuracy: 0.8637 - sensitivity_at_specificity: 0.9938 - specificity_at_sensitivity: 0.9851 - recall: 0.8840 - precision: 0.8503 - val_loss: 0.3517 - val_accuracy: 0.8523 - val_sensitivity_at_specificity: 0.9968 - val_specificity_at_sensitivity: 0.9818 - val_recall: 0.9629 - val_precision: 0.7824\n",
            "Epoch 49/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2833 - accuracy: 0.8805 - sensitivity_at_specificity: 0.9969 - specificity_at_sensitivity: 0.9784 - recall: 0.8855 - precision: 0.8815\n",
            "Epoch 49: val_accuracy did not improve from 0.88672\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.2833 - accuracy: 0.8805 - sensitivity_at_specificity: 0.9969 - specificity_at_sensitivity: 0.9784 - recall: 0.8855 - precision: 0.8815 - val_loss: 0.3327 - val_accuracy: 0.8594 - val_sensitivity_at_specificity: 0.9923 - val_specificity_at_sensitivity: 0.9746 - val_recall: 0.9570 - val_precision: 0.8039\n",
            "Epoch 50/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2645 - accuracy: 0.8930 - sensitivity_at_specificity: 0.9968 - specificity_at_sensitivity: 0.9823 - recall: 0.9001 - precision: 0.8846\n",
            "Epoch 50: val_accuracy did not improve from 0.88672\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.2645 - accuracy: 0.8930 - sensitivity_at_specificity: 0.9968 - specificity_at_sensitivity: 0.9823 - recall: 0.9001 - precision: 0.8846 - val_loss: 0.3779 - val_accuracy: 0.8438 - val_sensitivity_at_specificity: 0.9936 - val_specificity_at_sensitivity: 0.9740 - val_recall: 0.9601 - val_precision: 0.7745\n",
            "Epoch 51/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2859 - accuracy: 0.8785 - sensitivity_at_specificity: 0.9960 - specificity_at_sensitivity: 0.9757 - recall: 0.8954 - precision: 0.8601\n",
            "Epoch 51: val_accuracy did not improve from 0.88672\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.2859 - accuracy: 0.8785 - sensitivity_at_specificity: 0.9960 - specificity_at_sensitivity: 0.9757 - recall: 0.8954 - precision: 0.8601 - val_loss: 0.2933 - val_accuracy: 0.8680 - val_sensitivity_at_specificity: 0.9954 - val_specificity_at_sensitivity: 0.9825 - val_recall: 0.9401 - val_precision: 0.8248\n",
            "Epoch 52/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2842 - accuracy: 0.8805 - sensitivity_at_specificity: 0.9931 - specificity_at_sensitivity: 0.9881 - recall: 0.8940 - precision: 0.8739\n",
            "Epoch 52: val_accuracy did not improve from 0.88672\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.2842 - accuracy: 0.8805 - sensitivity_at_specificity: 0.9931 - specificity_at_sensitivity: 0.9881 - recall: 0.8940 - precision: 0.8739 - val_loss: 0.2826 - val_accuracy: 0.8836 - val_sensitivity_at_specificity: 0.9921 - val_specificity_at_sensitivity: 0.9860 - val_recall: 0.9104 - val_precision: 0.8629\n",
            "Epoch 53/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2654 - accuracy: 0.8949 - sensitivity_at_specificity: 0.9967 - specificity_at_sensitivity: 0.9850 - recall: 0.9081 - precision: 0.8854\n",
            "Epoch 53: val_accuracy did not improve from 0.88672\n",
            "10/10 [==============================] - 2s 157ms/step - loss: 0.2654 - accuracy: 0.8949 - sensitivity_at_specificity: 0.9967 - specificity_at_sensitivity: 0.9850 - recall: 0.9081 - precision: 0.8854 - val_loss: 0.2825 - val_accuracy: 0.8859 - val_sensitivity_at_specificity: 0.9968 - val_specificity_at_sensitivity: 0.9861 - val_recall: 0.9400 - val_precision: 0.8464\n",
            "Epoch 54/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2697 - accuracy: 0.8844 - sensitivity_at_specificity: 0.9976 - specificity_at_sensitivity: 0.9837 - recall: 0.8947 - precision: 0.8755\n",
            "Epoch 54: val_accuracy did not improve from 0.88672\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.2697 - accuracy: 0.8844 - sensitivity_at_specificity: 0.9976 - specificity_at_sensitivity: 0.9837 - recall: 0.8947 - precision: 0.8755 - val_loss: 0.2903 - val_accuracy: 0.8711 - val_sensitivity_at_specificity: 0.9939 - val_specificity_at_sensitivity: 0.9807 - val_recall: 0.8832 - val_precision: 0.8687\n",
            "Epoch 55/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2922 - accuracy: 0.8781 - sensitivity_at_specificity: 0.9937 - specificity_at_sensitivity: 0.9791 - recall: 0.8910 - precision: 0.8664\n",
            "Epoch 55: val_accuracy improved from 0.88672 to 0.90781, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.2922 - accuracy: 0.8781 - sensitivity_at_specificity: 0.9937 - specificity_at_sensitivity: 0.9791 - recall: 0.8910 - precision: 0.8664 - val_loss: 0.2464 - val_accuracy: 0.9078 - val_sensitivity_at_specificity: 0.9904 - val_specificity_at_sensitivity: 0.9969 - val_recall: 0.9408 - val_precision: 0.8789\n",
            "Epoch 56/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2612 - accuracy: 0.8922 - sensitivity_at_specificity: 0.9961 - specificity_at_sensitivity: 0.9829 - recall: 0.9071 - precision: 0.8794\n",
            "Epoch 56: val_accuracy did not improve from 0.90781\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.2612 - accuracy: 0.8922 - sensitivity_at_specificity: 0.9961 - specificity_at_sensitivity: 0.9829 - recall: 0.9071 - precision: 0.8794 - val_loss: 0.3346 - val_accuracy: 0.8695 - val_sensitivity_at_specificity: 0.9968 - val_specificity_at_sensitivity: 0.9741 - val_recall: 0.9567 - val_precision: 0.8098\n",
            "Epoch 57/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2803 - accuracy: 0.8866 - sensitivity_at_specificity: 0.9933 - specificity_at_sensitivity: 0.9770 - recall: 0.8838 - precision: 0.8861\n",
            "Epoch 57: val_accuracy did not improve from 0.90781\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.2803 - accuracy: 0.8866 - sensitivity_at_specificity: 0.9933 - specificity_at_sensitivity: 0.9770 - recall: 0.8838 - precision: 0.8861 - val_loss: 0.3912 - val_accuracy: 0.8219 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.9860 - val_recall: 0.9686 - val_precision: 0.7476\n",
            "Epoch 58/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2831 - accuracy: 0.8836 - sensitivity_at_specificity: 0.9960 - specificity_at_sensitivity: 0.9830 - recall: 0.9018 - precision: 0.8675\n",
            "Epoch 58: val_accuracy did not improve from 0.90781\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.2831 - accuracy: 0.8836 - sensitivity_at_specificity: 0.9960 - specificity_at_sensitivity: 0.9830 - recall: 0.9018 - precision: 0.8675 - val_loss: 0.2886 - val_accuracy: 0.8813 - val_sensitivity_at_specificity: 0.9953 - val_specificity_at_sensitivity: 0.9907 - val_recall: 0.9715 - val_precision: 0.8209\n",
            "Epoch 59/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2702 - accuracy: 0.8844 - sensitivity_at_specificity: 0.9969 - specificity_at_sensitivity: 0.9801 - recall: 0.9087 - precision: 0.8699\n",
            "Epoch 59: val_accuracy did not improve from 0.90781\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.2702 - accuracy: 0.8844 - sensitivity_at_specificity: 0.9969 - specificity_at_sensitivity: 0.9801 - recall: 0.9087 - precision: 0.8699 - val_loss: 0.2856 - val_accuracy: 0.8711 - val_sensitivity_at_specificity: 0.9968 - val_specificity_at_sensitivity: 0.9908 - val_recall: 0.9236 - val_precision: 0.8321\n",
            "Epoch 60/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2554 - accuracy: 0.8949 - sensitivity_at_specificity: 0.9976 - specificity_at_sensitivity: 0.9840 - recall: 0.9051 - precision: 0.8818\n",
            "Epoch 60: val_accuracy did not improve from 0.90781\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.2554 - accuracy: 0.8949 - sensitivity_at_specificity: 0.9976 - specificity_at_sensitivity: 0.9840 - recall: 0.9051 - precision: 0.8818 - val_loss: 0.2575 - val_accuracy: 0.8938 - val_sensitivity_at_specificity: 0.9968 - val_specificity_at_sensitivity: 0.9877 - val_recall: 0.9684 - val_precision: 0.8407\n",
            "Epoch 61/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2853 - accuracy: 0.8844 - sensitivity_at_specificity: 0.9924 - specificity_at_sensitivity: 0.9839 - recall: 0.8922 - precision: 0.8841\n",
            "Epoch 61: val_accuracy did not improve from 0.90781\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.2853 - accuracy: 0.8844 - sensitivity_at_specificity: 0.9924 - specificity_at_sensitivity: 0.9839 - recall: 0.8922 - precision: 0.8841 - val_loss: 0.4335 - val_accuracy: 0.8031 - val_sensitivity_at_specificity: 0.9939 - val_specificity_at_sensitivity: 0.9807 - val_recall: 0.9863 - val_precision: 0.7273\n",
            "Epoch 62/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2642 - accuracy: 0.8934 - sensitivity_at_specificity: 0.9929 - specificity_at_sensitivity: 0.9899 - recall: 0.9090 - precision: 0.8807\n",
            "Epoch 62: val_accuracy did not improve from 0.90781\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.2642 - accuracy: 0.8934 - sensitivity_at_specificity: 0.9929 - specificity_at_sensitivity: 0.9899 - recall: 0.9090 - precision: 0.8807 - val_loss: 0.3051 - val_accuracy: 0.8656 - val_sensitivity_at_specificity: 0.9970 - val_specificity_at_sensitivity: 0.9838 - val_recall: 0.9668 - val_precision: 0.8101\n",
            "Epoch 63/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2723 - accuracy: 0.8949 - sensitivity_at_specificity: 0.9937 - specificity_at_sensitivity: 0.9808 - recall: 0.9040 - precision: 0.8851\n",
            "Epoch 63: val_accuracy did not improve from 0.90781\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.2723 - accuracy: 0.8949 - sensitivity_at_specificity: 0.9937 - specificity_at_sensitivity: 0.9808 - recall: 0.9040 - precision: 0.8851 - val_loss: 0.2583 - val_accuracy: 0.8953 - val_sensitivity_at_specificity: 0.9969 - val_specificity_at_sensitivity: 0.9859 - val_recall: 0.9203 - val_precision: 0.8765\n",
            "Epoch 64/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2507 - accuracy: 0.8996 - sensitivity_at_specificity: 0.9953 - specificity_at_sensitivity: 0.9906 - recall: 0.9146 - precision: 0.8891\n",
            "Epoch 64: val_accuracy did not improve from 0.90781\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.2507 - accuracy: 0.8996 - sensitivity_at_specificity: 0.9953 - specificity_at_sensitivity: 0.9906 - recall: 0.9146 - precision: 0.8891 - val_loss: 0.3389 - val_accuracy: 0.8523 - val_sensitivity_at_specificity: 0.9968 - val_specificity_at_sensitivity: 0.9830 - val_recall: 0.9699 - val_precision: 0.7829\n",
            "Epoch 65/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2478 - accuracy: 0.8957 - sensitivity_at_specificity: 0.9961 - specificity_at_sensitivity: 0.9874 - recall: 0.8951 - precision: 0.8972\n",
            "Epoch 65: val_accuracy did not improve from 0.90781\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.2478 - accuracy: 0.8957 - sensitivity_at_specificity: 0.9961 - specificity_at_sensitivity: 0.9874 - recall: 0.8951 - precision: 0.8972 - val_loss: 0.4077 - val_accuracy: 0.8188 - val_sensitivity_at_specificity: 0.9831 - val_specificity_at_sensitivity: 0.9857 - val_recall: 0.9601 - val_precision: 0.7524\n",
            "Epoch 66/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2633 - accuracy: 0.8895 - sensitivity_at_specificity: 0.9935 - specificity_at_sensitivity: 0.9842 - recall: 0.8938 - precision: 0.8788\n",
            "Epoch 66: val_accuracy did not improve from 0.90781\n",
            "10/10 [==============================] - 2s 203ms/step - loss: 0.2633 - accuracy: 0.8895 - sensitivity_at_specificity: 0.9935 - specificity_at_sensitivity: 0.9842 - recall: 0.8938 - precision: 0.8788 - val_loss: 0.2667 - val_accuracy: 0.8898 - val_sensitivity_at_specificity: 0.9968 - val_specificity_at_sensitivity: 0.9878 - val_recall: 0.9551 - val_precision: 0.8406\n",
            "Epoch 67/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2629 - accuracy: 0.8934 - sensitivity_at_specificity: 0.9951 - specificity_at_sensitivity: 0.9872 - recall: 0.9123 - precision: 0.8719\n",
            "Epoch 67: val_accuracy did not improve from 0.90781\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.2629 - accuracy: 0.8934 - sensitivity_at_specificity: 0.9951 - specificity_at_sensitivity: 0.9872 - recall: 0.9123 - precision: 0.8719 - val_loss: 0.2580 - val_accuracy: 0.8930 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 0.9902 - val_recall: 0.8979 - val_precision: 0.8966\n",
            "Epoch 68/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2506 - accuracy: 0.8996 - sensitivity_at_specificity: 0.9953 - specificity_at_sensitivity: 0.9861 - recall: 0.9028 - precision: 0.8951\n",
            "Epoch 68: val_accuracy did not improve from 0.90781\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.2506 - accuracy: 0.8996 - sensitivity_at_specificity: 0.9953 - specificity_at_sensitivity: 0.9861 - recall: 0.9028 - precision: 0.8951 - val_loss: 0.3156 - val_accuracy: 0.8672 - val_sensitivity_at_specificity: 0.9967 - val_specificity_at_sensitivity: 0.9822 - val_recall: 0.9521 - val_precision: 0.8036\n",
            "Epoch 69/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2500 - accuracy: 0.8970 - sensitivity_at_specificity: 0.9967 - specificity_at_sensitivity: 0.9917 - recall: 0.9147 - precision: 0.8839\n",
            "Epoch 69: val_accuracy did not improve from 0.90781\n",
            "10/10 [==============================] - 2s 156ms/step - loss: 0.2500 - accuracy: 0.8970 - sensitivity_at_specificity: 0.9967 - specificity_at_sensitivity: 0.9917 - recall: 0.9147 - precision: 0.8839 - val_loss: 0.2866 - val_accuracy: 0.8758 - val_sensitivity_at_specificity: 0.9968 - val_specificity_at_sensitivity: 0.9894 - val_recall: 0.9757 - val_precision: 0.8072\n",
            "Epoch 70/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2437 - accuracy: 0.9000 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 0.9873 - recall: 0.9174 - precision: 0.8886\n",
            "Epoch 70: val_accuracy improved from 0.90781 to 0.91719, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.2437 - accuracy: 0.9000 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 0.9873 - recall: 0.9174 - precision: 0.8886 - val_loss: 0.2228 - val_accuracy: 0.9172 - val_sensitivity_at_specificity: 0.9968 - val_specificity_at_sensitivity: 0.9909 - val_recall: 0.9385 - val_precision: 0.8951\n",
            "Epoch 71/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2465 - accuracy: 0.9016 - sensitivity_at_specificity: 0.9970 - specificity_at_sensitivity: 0.9936 - recall: 0.9202 - precision: 0.8918\n",
            "Epoch 71: val_accuracy did not improve from 0.91719\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.2465 - accuracy: 0.9016 - sensitivity_at_specificity: 0.9970 - specificity_at_sensitivity: 0.9936 - recall: 0.9202 - precision: 0.8918 - val_loss: 0.3299 - val_accuracy: 0.8445 - val_sensitivity_at_specificity: 0.9969 - val_specificity_at_sensitivity: 0.9876 - val_recall: 0.9702 - val_precision: 0.7744\n",
            "Epoch 72/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2282 - accuracy: 0.9125 - sensitivity_at_specificity: 0.9977 - specificity_at_sensitivity: 0.9875 - recall: 0.9264 - precision: 0.9011\n",
            "Epoch 72: val_accuracy did not improve from 0.91719\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.2282 - accuracy: 0.9125 - sensitivity_at_specificity: 0.9977 - specificity_at_sensitivity: 0.9875 - recall: 0.9264 - precision: 0.9011 - val_loss: 0.2828 - val_accuracy: 0.8820 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9844 - val_recall: 0.9640 - val_precision: 0.8280\n",
            "Epoch 73/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2447 - accuracy: 0.9024 - sensitivity_at_specificity: 0.9976 - specificity_at_sensitivity: 0.9862 - recall: 0.9124 - precision: 0.9002\n",
            "Epoch 73: val_accuracy did not improve from 0.91719\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.2447 - accuracy: 0.9024 - sensitivity_at_specificity: 0.9976 - specificity_at_sensitivity: 0.9862 - recall: 0.9124 - precision: 0.9002 - val_loss: 0.5072 - val_accuracy: 0.7742 - val_sensitivity_at_specificity: 0.9939 - val_specificity_at_sensitivity: 0.9838 - val_recall: 0.9939 - val_precision: 0.6975\n",
            "Epoch 74/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2613 - accuracy: 0.8949 - sensitivity_at_specificity: 0.9918 - specificity_at_sensitivity: 0.9873 - recall: 0.9002 - precision: 0.8822\n",
            "Epoch 74: val_accuracy did not improve from 0.91719\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.2613 - accuracy: 0.8949 - sensitivity_at_specificity: 0.9918 - specificity_at_sensitivity: 0.9873 - recall: 0.9002 - precision: 0.8822 - val_loss: 0.3359 - val_accuracy: 0.8523 - val_sensitivity_at_specificity: 0.9969 - val_specificity_at_sensitivity: 0.9905 - val_recall: 0.9861 - val_precision: 0.7797\n",
            "Epoch 75/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2607 - accuracy: 0.8957 - sensitivity_at_specificity: 0.9952 - specificity_at_sensitivity: 0.9831 - recall: 0.9116 - precision: 0.8800\n",
            "Epoch 75: val_accuracy did not improve from 0.91719\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.2607 - accuracy: 0.8957 - sensitivity_at_specificity: 0.9952 - specificity_at_sensitivity: 0.9831 - recall: 0.9116 - precision: 0.8800 - val_loss: 0.2787 - val_accuracy: 0.8758 - val_sensitivity_at_specificity: 0.9938 - val_specificity_at_sensitivity: 0.9875 - val_recall: 0.9766 - val_precision: 0.8130\n",
            "Epoch 76/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2460 - accuracy: 0.8922 - sensitivity_at_specificity: 0.9976 - specificity_at_sensitivity: 0.9860 - recall: 0.9167 - precision: 0.8728\n",
            "Epoch 76: val_accuracy did not improve from 0.91719\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.2460 - accuracy: 0.8922 - sensitivity_at_specificity: 0.9976 - specificity_at_sensitivity: 0.9860 - recall: 0.9167 - precision: 0.8728 - val_loss: 0.3155 - val_accuracy: 0.8703 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.9851 - val_recall: 0.9639 - val_precision: 0.8033\n",
            "Epoch 77/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2280 - accuracy: 0.9098 - sensitivity_at_specificity: 0.9983 - specificity_at_sensitivity: 0.9911 - recall: 0.9065 - precision: 0.9027\n",
            "Epoch 77: val_accuracy did not improve from 0.91719\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.2280 - accuracy: 0.9098 - sensitivity_at_specificity: 0.9983 - specificity_at_sensitivity: 0.9911 - recall: 0.9065 - precision: 0.9027 - val_loss: 0.3819 - val_accuracy: 0.8398 - val_sensitivity_at_specificity: 0.9937 - val_specificity_at_sensitivity: 0.9829 - val_recall: 0.9890 - val_precision: 0.7606\n",
            "Epoch 78/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2493 - accuracy: 0.8953 - sensitivity_at_specificity: 0.9976 - specificity_at_sensitivity: 0.9900 - recall: 0.9100 - precision: 0.8821\n",
            "Epoch 78: val_accuracy did not improve from 0.91719\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.2493 - accuracy: 0.8953 - sensitivity_at_specificity: 0.9976 - specificity_at_sensitivity: 0.9900 - recall: 0.9100 - precision: 0.8821 - val_loss: 0.2992 - val_accuracy: 0.8703 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 0.9905 - val_recall: 0.9721 - val_precision: 0.8093\n",
            "Epoch 79/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2231 - accuracy: 0.9098 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9907 - recall: 0.9308 - precision: 0.8922\n",
            "Epoch 79: val_accuracy did not improve from 0.91719\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.2231 - accuracy: 0.9098 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9907 - recall: 0.9308 - precision: 0.8922 - val_loss: 0.2559 - val_accuracy: 0.8977 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 0.9873 - val_recall: 0.9525 - val_precision: 0.8613\n",
            "Epoch 80/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2539 - accuracy: 0.8906 - sensitivity_at_specificity: 0.9976 - specificity_at_sensitivity: 0.9860 - recall: 0.9075 - precision: 0.8773\n",
            "Epoch 80: val_accuracy did not improve from 0.91719\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.2539 - accuracy: 0.8906 - sensitivity_at_specificity: 0.9976 - specificity_at_sensitivity: 0.9860 - recall: 0.9075 - precision: 0.8773 - val_loss: 0.2537 - val_accuracy: 0.8891 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 0.9935 - val_recall: 0.9563 - val_precision: 0.8487\n",
            "Epoch 81/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2712 - accuracy: 0.8934 - sensitivity_at_specificity: 0.9922 - specificity_at_sensitivity: 0.9844 - recall: 0.9071 - precision: 0.8830\n",
            "Epoch 81: val_accuracy did not improve from 0.91719\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.2712 - accuracy: 0.8934 - sensitivity_at_specificity: 0.9922 - specificity_at_sensitivity: 0.9844 - recall: 0.9071 - precision: 0.8830 - val_loss: 0.3173 - val_accuracy: 0.8656 - val_sensitivity_at_specificity: 0.9940 - val_specificity_at_sensitivity: 0.9836 - val_recall: 0.9523 - val_precision: 0.8203\n",
            "Epoch 82/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2495 - accuracy: 0.8945 - sensitivity_at_specificity: 0.9976 - specificity_at_sensitivity: 0.9902 - recall: 0.8863 - precision: 0.8935\n",
            "Epoch 82: val_accuracy did not improve from 0.91719\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.2495 - accuracy: 0.8945 - sensitivity_at_specificity: 0.9976 - specificity_at_sensitivity: 0.9902 - recall: 0.8863 - precision: 0.8935 - val_loss: 0.2554 - val_accuracy: 0.8969 - val_sensitivity_at_specificity: 0.9967 - val_specificity_at_sensitivity: 0.9955 - val_recall: 0.9739 - val_precision: 0.8375\n",
            "Epoch 83/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2389 - accuracy: 0.9031 - sensitivity_at_specificity: 0.9970 - specificity_at_sensitivity: 0.9911 - recall: 0.9308 - precision: 0.8880\n",
            "Epoch 83: val_accuracy did not improve from 0.91719\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.2389 - accuracy: 0.9031 - sensitivity_at_specificity: 0.9970 - specificity_at_sensitivity: 0.9911 - recall: 0.9308 - precision: 0.8880 - val_loss: 0.2454 - val_accuracy: 0.9000 - val_sensitivity_at_specificity: 0.9968 - val_specificity_at_sensitivity: 0.9938 - val_recall: 0.9606 - val_precision: 0.8553\n",
            "Epoch 84/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2328 - accuracy: 0.9152 - sensitivity_at_specificity: 0.9977 - specificity_at_sensitivity: 0.9855 - recall: 0.9273 - precision: 0.9100\n",
            "Epoch 84: val_accuracy did not improve from 0.91719\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.2328 - accuracy: 0.9152 - sensitivity_at_specificity: 0.9977 - specificity_at_sensitivity: 0.9855 - recall: 0.9273 - precision: 0.9100 - val_loss: 0.2474 - val_accuracy: 0.8938 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9843 - val_recall: 0.9548 - val_precision: 0.8514\n",
            "Epoch 85/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2563 - accuracy: 0.8926 - sensitivity_at_specificity: 0.9961 - specificity_at_sensitivity: 0.9883 - recall: 0.8943 - precision: 0.8908\n",
            "Epoch 85: val_accuracy did not improve from 0.91719\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.2563 - accuracy: 0.8926 - sensitivity_at_specificity: 0.9961 - specificity_at_sensitivity: 0.9883 - recall: 0.8943 - precision: 0.8908 - val_loss: 0.2722 - val_accuracy: 0.8789 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9922 - val_recall: 0.9764 - val_precision: 0.8160\n",
            "Epoch 86/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2436 - accuracy: 0.8949 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9923 - recall: 0.9051 - precision: 0.8848\n",
            "Epoch 86: val_accuracy did not improve from 0.91719\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.2436 - accuracy: 0.8949 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9923 - recall: 0.9051 - precision: 0.8848 - val_loss: 0.2339 - val_accuracy: 0.9086 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.9860 - val_recall: 0.9546 - val_precision: 0.8739\n",
            "Epoch 87/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2521 - accuracy: 0.9035 - sensitivity_at_specificity: 0.9968 - specificity_at_sensitivity: 0.9853 - recall: 0.9209 - precision: 0.8879\n",
            "Epoch 87: val_accuracy did not improve from 0.91719\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.2521 - accuracy: 0.9035 - sensitivity_at_specificity: 0.9968 - specificity_at_sensitivity: 0.9853 - recall: 0.9209 - precision: 0.8879 - val_loss: 0.2225 - val_accuracy: 0.9102 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9925 - val_recall: 0.9540 - val_precision: 0.8698\n",
            "Epoch 88/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2363 - accuracy: 0.9051 - sensitivity_at_specificity: 0.9939 - specificity_at_sensitivity: 0.9904 - recall: 0.9069 - precision: 0.9076\n",
            "Epoch 88: val_accuracy did not improve from 0.91719\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.2363 - accuracy: 0.9051 - sensitivity_at_specificity: 0.9939 - specificity_at_sensitivity: 0.9904 - recall: 0.9069 - precision: 0.9076 - val_loss: 0.4127 - val_accuracy: 0.8250 - val_sensitivity_at_specificity: 0.9954 - val_specificity_at_sensitivity: 0.9856 - val_recall: 0.9741 - val_precision: 0.7553\n",
            "Epoch 89/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2365 - accuracy: 0.9059 - sensitivity_at_specificity: 0.9947 - specificity_at_sensitivity: 0.9952 - recall: 0.9217 - precision: 0.8979\n",
            "Epoch 89: val_accuracy did not improve from 0.91719\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.2365 - accuracy: 0.9059 - sensitivity_at_specificity: 0.9947 - specificity_at_sensitivity: 0.9952 - recall: 0.9217 - precision: 0.8979 - val_loss: 0.2259 - val_accuracy: 0.9117 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 0.9935 - val_recall: 0.9306 - val_precision: 0.9020\n",
            "Epoch 90/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2457 - accuracy: 0.8949 - sensitivity_at_specificity: 0.9969 - specificity_at_sensitivity: 0.9907 - recall: 0.9138 - precision: 0.8800\n",
            "Epoch 90: val_accuracy improved from 0.91719 to 0.93750, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.2457 - accuracy: 0.8949 - sensitivity_at_specificity: 0.9969 - specificity_at_sensitivity: 0.9907 - recall: 0.9138 - precision: 0.8800 - val_loss: 0.1884 - val_accuracy: 0.9375 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 0.9905 - val_recall: 0.9706 - val_precision: 0.9113\n",
            "Epoch 91/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2393 - accuracy: 0.8988 - sensitivity_at_specificity: 0.9968 - specificity_at_sensitivity: 0.9931 - recall: 0.9007 - precision: 0.8943\n",
            "Epoch 91: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.2393 - accuracy: 0.8988 - sensitivity_at_specificity: 0.9968 - specificity_at_sensitivity: 0.9931 - recall: 0.9007 - precision: 0.8943 - val_loss: 0.2475 - val_accuracy: 0.8922 - val_sensitivity_at_specificity: 0.9968 - val_specificity_at_sensitivity: 0.9970 - val_recall: 0.9501 - val_precision: 0.8465\n",
            "Epoch 92/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2093 - accuracy: 0.9156 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9922 - recall: 0.9218 - precision: 0.9104\n",
            "Epoch 92: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.2093 - accuracy: 0.9156 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9922 - recall: 0.9218 - precision: 0.9104 - val_loss: 0.2717 - val_accuracy: 0.8930 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.9849 - val_recall: 0.9740 - val_precision: 0.8322\n",
            "Epoch 93/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2081 - accuracy: 0.9180 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9913 - recall: 0.9336 - precision: 0.9070\n",
            "Epoch 93: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.2081 - accuracy: 0.9180 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9913 - recall: 0.9336 - precision: 0.9070 - val_loss: 0.2584 - val_accuracy: 0.8992 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 0.9873 - val_recall: 0.9691 - val_precision: 0.8521\n",
            "Epoch 94/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2342 - accuracy: 0.9059 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9868 - recall: 0.9276 - precision: 0.8877\n",
            "Epoch 94: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.2342 - accuracy: 0.9059 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9868 - recall: 0.9276 - precision: 0.8877 - val_loss: 0.2265 - val_accuracy: 0.9070 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9893 - val_recall: 0.9618 - val_precision: 0.8641\n",
            "Epoch 95/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2362 - accuracy: 0.9074 - sensitivity_at_specificity: 0.9976 - specificity_at_sensitivity: 0.9899 - recall: 0.9077 - precision: 0.9055\n",
            "Epoch 95: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.2362 - accuracy: 0.9074 - sensitivity_at_specificity: 0.9976 - specificity_at_sensitivity: 0.9899 - recall: 0.9077 - precision: 0.9055 - val_loss: 0.2949 - val_accuracy: 0.8813 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 0.9937 - val_recall: 0.9799 - val_precision: 0.8202\n",
            "Epoch 96/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2147 - accuracy: 0.9105 - sensitivity_at_specificity: 0.9977 - specificity_at_sensitivity: 0.9937 - recall: 0.9182 - precision: 0.9063\n",
            "Epoch 96: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.2147 - accuracy: 0.9105 - sensitivity_at_specificity: 0.9977 - specificity_at_sensitivity: 0.9937 - recall: 0.9182 - precision: 0.9063 - val_loss: 0.2469 - val_accuracy: 0.8992 - val_sensitivity_at_specificity: 0.9952 - val_specificity_at_sensitivity: 0.9908 - val_recall: 0.9635 - val_precision: 0.8515\n",
            "Epoch 97/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1990 - accuracy: 0.9211 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 0.9944 - recall: 0.9310 - precision: 0.9156\n",
            "Epoch 97: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.1990 - accuracy: 0.9211 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 0.9944 - recall: 0.9310 - precision: 0.9156 - val_loss: 0.2389 - val_accuracy: 0.9086 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.9906 - val_recall: 0.9657 - val_precision: 0.8669\n",
            "Epoch 98/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1991 - accuracy: 0.9172 - sensitivity_at_specificity: 0.9976 - specificity_at_sensitivity: 0.9946 - recall: 0.9338 - precision: 0.9008\n",
            "Epoch 98: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.1991 - accuracy: 0.9172 - sensitivity_at_specificity: 0.9976 - specificity_at_sensitivity: 0.9946 - recall: 0.9338 - precision: 0.9008 - val_loss: 0.2574 - val_accuracy: 0.8992 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9905 - val_recall: 0.9737 - val_precision: 0.8491\n",
            "Epoch 99/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2209 - accuracy: 0.9035 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 0.9953 - recall: 0.9112 - precision: 0.8994\n",
            "Epoch 99: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.2209 - accuracy: 0.9035 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 0.9953 - recall: 0.9112 - precision: 0.8994 - val_loss: 0.2185 - val_accuracy: 0.9141 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9922 - val_recall: 0.9780 - val_precision: 0.8665\n",
            "Epoch 100/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2316 - accuracy: 0.9051 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9864 - recall: 0.9226 - precision: 0.8861\n",
            "Epoch 100: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.2316 - accuracy: 0.9051 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9864 - recall: 0.9226 - precision: 0.8861 - val_loss: 0.3019 - val_accuracy: 0.8703 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.9954 - val_recall: 0.9840 - val_precision: 0.7979\n",
            "Epoch 101/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2010 - accuracy: 0.9230 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9907 - recall: 0.9274 - precision: 0.9180\n",
            "Epoch 101: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.2010 - accuracy: 0.9230 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9907 - recall: 0.9274 - precision: 0.9180 - val_loss: 0.2695 - val_accuracy: 0.8852 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.9891 - val_recall: 0.9531 - val_precision: 0.8391\n",
            "Epoch 102/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2293 - accuracy: 0.9098 - sensitivity_at_specificity: 0.9962 - specificity_at_sensitivity: 0.9928 - recall: 0.9235 - precision: 0.9022\n",
            "Epoch 102: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.2293 - accuracy: 0.9098 - sensitivity_at_specificity: 0.9962 - specificity_at_sensitivity: 0.9928 - recall: 0.9235 - precision: 0.9022 - val_loss: 0.2910 - val_accuracy: 0.8797 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9950 - val_recall: 0.9765 - val_precision: 0.8279\n",
            "Epoch 103/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2185 - accuracy: 0.9172 - sensitivity_at_specificity: 0.9969 - specificity_at_sensitivity: 0.9883 - recall: 0.9189 - precision: 0.9161\n",
            "Epoch 103: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.2185 - accuracy: 0.9172 - sensitivity_at_specificity: 0.9969 - specificity_at_sensitivity: 0.9883 - recall: 0.9189 - precision: 0.9161 - val_loss: 0.3183 - val_accuracy: 0.8648 - val_sensitivity_at_specificity: 0.9969 - val_specificity_at_sensitivity: 0.9889 - val_recall: 0.9816 - val_precision: 0.7990\n",
            "Epoch 104/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2284 - accuracy: 0.9121 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9891 - recall: 0.9311 - precision: 0.8967\n",
            "Epoch 104: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.2284 - accuracy: 0.9121 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9891 - recall: 0.9311 - precision: 0.8967 - val_loss: 0.2561 - val_accuracy: 0.9062 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.9863 - val_recall: 0.9584 - val_precision: 0.8644\n",
            "Epoch 105/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2113 - accuracy: 0.9195 - sensitivity_at_specificity: 0.9977 - specificity_at_sensitivity: 0.9897 - recall: 0.9259 - precision: 0.9160\n",
            "Epoch 105: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 2s 182ms/step - loss: 0.2113 - accuracy: 0.9195 - sensitivity_at_specificity: 0.9977 - specificity_at_sensitivity: 0.9897 - recall: 0.9259 - precision: 0.9160 - val_loss: 0.2153 - val_accuracy: 0.9133 - val_sensitivity_at_specificity: 0.9968 - val_specificity_at_sensitivity: 0.9877 - val_recall: 0.9430 - val_precision: 0.8882\n",
            "Epoch 106/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2203 - accuracy: 0.9090 - sensitivity_at_specificity: 0.9968 - specificity_at_sensitivity: 0.9930 - recall: 0.9259 - precision: 0.8942\n",
            "Epoch 106: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.2203 - accuracy: 0.9090 - sensitivity_at_specificity: 0.9968 - specificity_at_sensitivity: 0.9930 - recall: 0.9259 - precision: 0.8942 - val_loss: 0.2021 - val_accuracy: 0.9156 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9926 - val_recall: 0.9372 - val_precision: 0.8901\n",
            "Epoch 107/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2107 - accuracy: 0.9121 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9930 - recall: 0.9171 - precision: 0.9063\n",
            "Epoch 107: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.2107 - accuracy: 0.9121 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9930 - recall: 0.9171 - precision: 0.9063 - val_loss: 0.2697 - val_accuracy: 0.8883 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9953 - val_recall: 0.9829 - val_precision: 0.8277\n",
            "Epoch 108/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2139 - accuracy: 0.9180 - sensitivity_at_specificity: 0.9969 - specificity_at_sensitivity: 0.9944 - recall: 0.9210 - precision: 0.9182\n",
            "Epoch 108: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.2139 - accuracy: 0.9180 - sensitivity_at_specificity: 0.9969 - specificity_at_sensitivity: 0.9944 - recall: 0.9210 - precision: 0.9182 - val_loss: 0.3151 - val_accuracy: 0.8703 - val_sensitivity_at_specificity: 0.9970 - val_specificity_at_sensitivity: 0.9886 - val_recall: 0.9805 - val_precision: 0.8102\n",
            "Epoch 109/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2217 - accuracy: 0.9148 - sensitivity_at_specificity: 0.9953 - specificity_at_sensitivity: 0.9892 - recall: 0.9226 - precision: 0.9068\n",
            "Epoch 109: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.2217 - accuracy: 0.9148 - sensitivity_at_specificity: 0.9953 - specificity_at_sensitivity: 0.9892 - recall: 0.9226 - precision: 0.9068 - val_loss: 0.2114 - val_accuracy: 0.9187 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9954 - val_recall: 0.9775 - val_precision: 0.8712\n",
            "Epoch 110/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2191 - accuracy: 0.9082 - sensitivity_at_specificity: 0.9975 - specificity_at_sensitivity: 0.9934 - recall: 0.9201 - precision: 0.8985\n",
            "Epoch 110: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.2191 - accuracy: 0.9082 - sensitivity_at_specificity: 0.9975 - specificity_at_sensitivity: 0.9934 - recall: 0.9201 - precision: 0.8985 - val_loss: 0.2112 - val_accuracy: 0.9094 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9906 - val_recall: 0.9719 - val_precision: 0.8639\n",
            "Epoch 111/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1934 - accuracy: 0.9270 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9939 - recall: 0.9331 - precision: 0.9192\n",
            "Epoch 111: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.1934 - accuracy: 0.9270 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9939 - recall: 0.9331 - precision: 0.9192 - val_loss: 0.2182 - val_accuracy: 0.9125 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9875 - val_recall: 0.9436 - val_precision: 0.8879\n",
            "Epoch 112/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2156 - accuracy: 0.9168 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 0.9913 - recall: 0.9312 - precision: 0.9067\n",
            "Epoch 112: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.2156 - accuracy: 0.9168 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 0.9913 - recall: 0.9312 - precision: 0.9067 - val_loss: 0.2296 - val_accuracy: 0.9117 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.9906 - val_recall: 0.9829 - val_precision: 0.8612\n",
            "Epoch 113/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1909 - accuracy: 0.9195 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9946 - recall: 0.9199 - precision: 0.9185\n",
            "Epoch 113: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.1909 - accuracy: 0.9195 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9946 - recall: 0.9199 - precision: 0.9185 - val_loss: 0.4138 - val_accuracy: 0.8148 - val_sensitivity_at_specificity: 0.9983 - val_specificity_at_sensitivity: 0.9867 - val_recall: 0.9835 - val_precision: 0.7238\n",
            "Epoch 114/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2019 - accuracy: 0.9199 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9946 - recall: 0.9242 - precision: 0.9148\n",
            "Epoch 114: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.2019 - accuracy: 0.9199 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9946 - recall: 0.9242 - precision: 0.9148 - val_loss: 0.2731 - val_accuracy: 0.8820 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9902 - val_recall: 0.9790 - val_precision: 0.8268\n",
            "Epoch 115/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1912 - accuracy: 0.9246 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9961 - recall: 0.9320 - precision: 0.9183\n",
            "Epoch 115: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.1912 - accuracy: 0.9246 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9961 - recall: 0.9320 - precision: 0.9183 - val_loss: 0.2467 - val_accuracy: 0.8969 - val_sensitivity_at_specificity: 0.9970 - val_specificity_at_sensitivity: 0.9984 - val_recall: 0.9742 - val_precision: 0.8483\n",
            "Epoch 116/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2152 - accuracy: 0.9160 - sensitivity_at_specificity: 0.9976 - specificity_at_sensitivity: 0.9922 - recall: 0.9285 - precision: 0.9050\n",
            "Epoch 116: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.2152 - accuracy: 0.9160 - sensitivity_at_specificity: 0.9976 - specificity_at_sensitivity: 0.9922 - recall: 0.9285 - precision: 0.9050 - val_loss: 0.2245 - val_accuracy: 0.9055 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9939 - val_recall: 0.9693 - val_precision: 0.8547\n",
            "Epoch 117/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1832 - accuracy: 0.9238 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9977 - recall: 0.9274 - precision: 0.9179\n",
            "Epoch 117: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.1832 - accuracy: 0.9238 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9977 - recall: 0.9274 - precision: 0.9179 - val_loss: 0.2047 - val_accuracy: 0.9133 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9985 - val_recall: 0.9696 - val_precision: 0.8682\n",
            "Epoch 118/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1928 - accuracy: 0.9230 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 0.9953 - recall: 0.9336 - precision: 0.9160\n",
            "Epoch 118: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.1928 - accuracy: 0.9230 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 0.9953 - recall: 0.9336 - precision: 0.9160 - val_loss: 0.2450 - val_accuracy: 0.8938 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9953 - val_recall: 0.9811 - val_precision: 0.8342\n",
            "Epoch 119/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2149 - accuracy: 0.9105 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 0.9945 - recall: 0.9167 - precision: 0.9076\n",
            "Epoch 119: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 2s 183ms/step - loss: 0.2149 - accuracy: 0.9105 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 0.9945 - recall: 0.9167 - precision: 0.9076 - val_loss: 0.3701 - val_accuracy: 0.8414 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 0.9823 - val_recall: 0.9924 - val_precision: 0.7676\n",
            "Epoch 120/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2331 - accuracy: 0.9035 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9930 - recall: 0.9131 - precision: 0.8940\n",
            "Epoch 120: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.2331 - accuracy: 0.9035 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9930 - recall: 0.9131 - precision: 0.8940 - val_loss: 0.2201 - val_accuracy: 0.9234 - val_sensitivity_at_specificity: 0.9969 - val_specificity_at_sensitivity: 0.9906 - val_recall: 0.9767 - val_precision: 0.8834\n",
            "Epoch 121/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2234 - accuracy: 0.9082 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9913 - recall: 0.9260 - precision: 0.8963\n",
            "Epoch 121: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.2234 - accuracy: 0.9082 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9913 - recall: 0.9260 - precision: 0.8963 - val_loss: 0.2069 - val_accuracy: 0.9312 - val_sensitivity_at_specificity: 0.9968 - val_specificity_at_sensitivity: 0.9892 - val_recall: 0.9620 - val_precision: 0.9046\n",
            "Epoch 122/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1930 - accuracy: 0.9250 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9920 - recall: 0.9336 - precision: 0.9210\n",
            "Epoch 122: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.1930 - accuracy: 0.9250 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9920 - recall: 0.9336 - precision: 0.9210 - val_loss: 0.2165 - val_accuracy: 0.9039 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9969 - val_recall: 0.9333 - val_precision: 0.8789\n",
            "Epoch 123/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2023 - accuracy: 0.9172 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9961 - recall: 0.9200 - precision: 0.9158\n",
            "Epoch 123: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.2023 - accuracy: 0.9172 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9961 - recall: 0.9200 - precision: 0.9158 - val_loss: 0.2100 - val_accuracy: 0.9203 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9937 - val_recall: 0.9768 - val_precision: 0.8788\n",
            "Epoch 124/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2022 - accuracy: 0.9153 - sensitivity_at_specificity: 0.9983 - specificity_at_sensitivity: 0.9967 - recall: 0.9313 - precision: 0.9011\n",
            "Epoch 124: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.2022 - accuracy: 0.9153 - sensitivity_at_specificity: 0.9983 - specificity_at_sensitivity: 0.9967 - recall: 0.9313 - precision: 0.9011 - val_loss: 0.1934 - val_accuracy: 0.9148 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9953 - val_recall: 0.9638 - val_precision: 0.8768\n",
            "Epoch 125/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1913 - accuracy: 0.9203 - sensitivity_at_specificity: 0.9977 - specificity_at_sensitivity: 0.9938 - recall: 0.9217 - precision: 0.9188\n",
            "Epoch 125: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.1913 - accuracy: 0.9203 - sensitivity_at_specificity: 0.9977 - specificity_at_sensitivity: 0.9938 - recall: 0.9217 - precision: 0.9188 - val_loss: 0.2082 - val_accuracy: 0.9156 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9954 - val_recall: 0.9747 - val_precision: 0.8701\n",
            "Epoch 126/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1967 - accuracy: 0.9234 - sensitivity_at_specificity: 0.9977 - specificity_at_sensitivity: 0.9937 - recall: 0.9274 - precision: 0.9217\n",
            "Epoch 126: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 2s 181ms/step - loss: 0.1967 - accuracy: 0.9234 - sensitivity_at_specificity: 0.9977 - specificity_at_sensitivity: 0.9937 - recall: 0.9274 - precision: 0.9217 - val_loss: 0.3105 - val_accuracy: 0.8672 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9887 - val_recall: 0.9939 - val_precision: 0.7976\n",
            "Epoch 127/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1939 - accuracy: 0.9238 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9946 - recall: 0.9291 - precision: 0.9182\n",
            "Epoch 127: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 2s 180ms/step - loss: 0.1939 - accuracy: 0.9238 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9946 - recall: 0.9291 - precision: 0.9182 - val_loss: 0.2139 - val_accuracy: 0.9180 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9923 - val_recall: 0.9874 - val_precision: 0.8657\n",
            "Epoch 128/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1904 - accuracy: 0.9262 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9940 - recall: 0.9294 - precision: 0.9183\n",
            "Epoch 128: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.1904 - accuracy: 0.9262 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9940 - recall: 0.9294 - precision: 0.9183 - val_loss: 0.1859 - val_accuracy: 0.9273 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9984 - val_recall: 0.9709 - val_precision: 0.8955\n",
            "Epoch 129/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1805 - accuracy: 0.9270 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9962 - recall: 0.9397 - precision: 0.9143\n",
            "Epoch 129: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.1805 - accuracy: 0.9270 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9962 - recall: 0.9397 - precision: 0.9143 - val_loss: 0.1697 - val_accuracy: 0.9367 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9967 - val_recall: 0.9598 - val_precision: 0.9227\n",
            "Epoch 130/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1984 - accuracy: 0.9234 - sensitivity_at_specificity: 0.9977 - specificity_at_sensitivity: 0.9921 - recall: 0.9277 - precision: 0.9206\n",
            "Epoch 130: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.1984 - accuracy: 0.9234 - sensitivity_at_specificity: 0.9977 - specificity_at_sensitivity: 0.9921 - recall: 0.9277 - precision: 0.9206 - val_loss: 0.1722 - val_accuracy: 0.9359 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.9938 - val_recall: 0.9327 - val_precision: 0.9386\n",
            "Epoch 131/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1742 - accuracy: 0.9301 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9954 - recall: 0.9359 - precision: 0.9234\n",
            "Epoch 131: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.1742 - accuracy: 0.9301 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9954 - recall: 0.9359 - precision: 0.9234 - val_loss: 0.2132 - val_accuracy: 0.9047 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9984 - val_recall: 0.9910 - val_precision: 0.8509\n",
            "Epoch 132/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1795 - accuracy: 0.9270 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9953 - recall: 0.9283 - precision: 0.9247\n",
            "Epoch 132: val_accuracy did not improve from 0.93750\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.1795 - accuracy: 0.9270 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9953 - recall: 0.9283 - precision: 0.9247 - val_loss: 0.2209 - val_accuracy: 0.9055 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9970 - val_recall: 0.9821 - val_precision: 0.8459\n",
            "Epoch 133/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1587 - accuracy: 0.9391 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9953 - recall: 0.9475 - precision: 0.9314\n",
            "Epoch 133: val_accuracy improved from 0.93750 to 0.93828, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 174ms/step - loss: 0.1587 - accuracy: 0.9391 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9953 - recall: 0.9475 - precision: 0.9314 - val_loss: 0.1786 - val_accuracy: 0.9383 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.9938 - val_recall: 0.9528 - val_precision: 0.9252\n",
            "Epoch 134/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1936 - accuracy: 0.9211 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9946 - recall: 0.9200 - precision: 0.9200\n",
            "Epoch 134: val_accuracy did not improve from 0.93828\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.1936 - accuracy: 0.9211 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9946 - recall: 0.9200 - precision: 0.9200 - val_loss: 0.3208 - val_accuracy: 0.8453 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9953 - val_recall: 0.9906 - val_precision: 0.7667\n",
            "Epoch 135/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2036 - accuracy: 0.9195 - sensitivity_at_specificity: 0.9977 - specificity_at_sensitivity: 0.9943 - recall: 0.9359 - precision: 0.9112\n",
            "Epoch 135: val_accuracy did not improve from 0.93828\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.2036 - accuracy: 0.9195 - sensitivity_at_specificity: 0.9977 - specificity_at_sensitivity: 0.9943 - recall: 0.9359 - precision: 0.9112 - val_loss: 0.2117 - val_accuracy: 0.9195 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9938 - val_recall: 0.9450 - val_precision: 0.8984\n",
            "Epoch 136/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1914 - accuracy: 0.9258 - sensitivity_at_specificity: 0.9969 - specificity_at_sensitivity: 0.9930 - recall: 0.9330 - precision: 0.9201\n",
            "Epoch 136: val_accuracy improved from 0.93828 to 0.94531, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 176ms/step - loss: 0.1914 - accuracy: 0.9258 - sensitivity_at_specificity: 0.9969 - specificity_at_sensitivity: 0.9930 - recall: 0.9330 - precision: 0.9201 - val_loss: 0.1703 - val_accuracy: 0.9453 - val_sensitivity_at_specificity: 0.9970 - val_specificity_at_sensitivity: 0.9918 - val_recall: 0.9640 - val_precision: 0.9332\n",
            "Epoch 137/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2351 - accuracy: 0.9027 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9946 - recall: 0.9043 - precision: 0.9008\n",
            "Epoch 137: val_accuracy did not improve from 0.94531\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.2351 - accuracy: 0.9027 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9946 - recall: 0.9043 - precision: 0.9008 - val_loss: 0.2025 - val_accuracy: 0.9180 - val_sensitivity_at_specificity: 0.9969 - val_specificity_at_sensitivity: 0.9969 - val_recall: 0.9532 - val_precision: 0.8907\n",
            "Epoch 138/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2234 - accuracy: 0.9090 - sensitivity_at_specificity: 0.9961 - specificity_at_sensitivity: 0.9906 - recall: 0.9165 - precision: 0.9031\n",
            "Epoch 138: val_accuracy did not improve from 0.94531\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.2234 - accuracy: 0.9090 - sensitivity_at_specificity: 0.9961 - specificity_at_sensitivity: 0.9906 - recall: 0.9165 - precision: 0.9031 - val_loss: 0.1767 - val_accuracy: 0.9359 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9967 - val_recall: 0.9419 - val_precision: 0.9363\n",
            "Epoch 139/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1883 - accuracy: 0.9238 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9961 - recall: 0.9299 - precision: 0.9176\n",
            "Epoch 139: val_accuracy did not improve from 0.94531\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.1883 - accuracy: 0.9238 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9961 - recall: 0.9299 - precision: 0.9176 - val_loss: 0.2031 - val_accuracy: 0.9133 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.9969 - val_recall: 0.9389 - val_precision: 0.8927\n",
            "Epoch 140/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2044 - accuracy: 0.9160 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9907 - recall: 0.9147 - precision: 0.9154\n",
            "Epoch 140: val_accuracy did not improve from 0.94531\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.2044 - accuracy: 0.9160 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9907 - recall: 0.9147 - precision: 0.9154 - val_loss: 0.1824 - val_accuracy: 0.9297 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9985 - val_recall: 0.9841 - val_precision: 0.8852\n",
            "Epoch 141/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1887 - accuracy: 0.9262 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9985 - recall: 0.9387 - precision: 0.9114\n",
            "Epoch 141: val_accuracy did not improve from 0.94531\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.1887 - accuracy: 0.9262 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9985 - recall: 0.9387 - precision: 0.9114 - val_loss: 0.2140 - val_accuracy: 0.9148 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.9954 - val_recall: 0.9697 - val_precision: 0.8712\n",
            "Epoch 142/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1799 - accuracy: 0.9262 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9931 - recall: 0.9281 - precision: 0.9230\n",
            "Epoch 142: val_accuracy did not improve from 0.94531\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.1799 - accuracy: 0.9262 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9931 - recall: 0.9281 - precision: 0.9230 - val_loss: 0.1571 - val_accuracy: 0.9414 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9906 - val_recall: 0.9534 - val_precision: 0.9317\n",
            "Epoch 143/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1920 - accuracy: 0.9199 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9977 - recall: 0.9210 - precision: 0.9189\n",
            "Epoch 143: val_accuracy did not improve from 0.94531\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.1920 - accuracy: 0.9199 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9977 - recall: 0.9210 - precision: 0.9189 - val_loss: 0.1961 - val_accuracy: 0.9258 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9880 - val_recall: 0.9574 - val_precision: 0.8945\n",
            "Epoch 144/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1801 - accuracy: 0.9277 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9946 - recall: 0.9301 - precision: 0.9250\n",
            "Epoch 144: val_accuracy did not improve from 0.94531\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.1801 - accuracy: 0.9277 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9946 - recall: 0.9301 - precision: 0.9250 - val_loss: 0.1837 - val_accuracy: 0.9273 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9952 - val_recall: 0.9740 - val_precision: 0.8934\n",
            "Epoch 145/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1808 - accuracy: 0.9328 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9927 - recall: 0.9386 - precision: 0.9316\n",
            "Epoch 145: val_accuracy did not improve from 0.94531\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.1808 - accuracy: 0.9328 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9927 - recall: 0.9386 - precision: 0.9316 - val_loss: 0.1923 - val_accuracy: 0.9250 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9938 - val_recall: 0.9603 - val_precision: 0.8950\n",
            "Epoch 146/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1727 - accuracy: 0.9262 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9954 - recall: 0.9325 - precision: 0.9187\n",
            "Epoch 146: val_accuracy did not improve from 0.94531\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.1727 - accuracy: 0.9262 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9954 - recall: 0.9325 - precision: 0.9187 - val_loss: 0.2347 - val_accuracy: 0.9070 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9939 - val_recall: 0.9952 - val_precision: 0.8437\n",
            "Epoch 147/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1704 - accuracy: 0.9391 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9954 - recall: 0.9431 - precision: 0.9343\n",
            "Epoch 147: val_accuracy did not improve from 0.94531\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.1704 - accuracy: 0.9391 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9954 - recall: 0.9431 - precision: 0.9343 - val_loss: 0.1898 - val_accuracy: 0.9195 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9971 - val_recall: 0.9797 - val_precision: 0.8640\n",
            "Epoch 148/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1851 - accuracy: 0.9219 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9913 - recall: 0.9264 - precision: 0.9192\n",
            "Epoch 148: val_accuracy did not improve from 0.94531\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.1851 - accuracy: 0.9219 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9913 - recall: 0.9264 - precision: 0.9192 - val_loss: 0.1516 - val_accuracy: 0.9430 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9936 - val_recall: 0.9527 - val_precision: 0.9369\n",
            "Epoch 149/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1853 - accuracy: 0.9301 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9937 - recall: 0.9326 - precision: 0.9290\n",
            "Epoch 149: val_accuracy did not improve from 0.94531\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.1853 - accuracy: 0.9301 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9937 - recall: 0.9326 - precision: 0.9290 - val_loss: 0.2388 - val_accuracy: 0.9008 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9968 - val_recall: 0.9799 - val_precision: 0.8478\n",
            "Epoch 150/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1798 - accuracy: 0.9273 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9976 - recall: 0.9295 - precision: 0.9224\n",
            "Epoch 150: val_accuracy did not improve from 0.94531\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.1798 - accuracy: 0.9273 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9976 - recall: 0.9295 - precision: 0.9224 - val_loss: 0.1873 - val_accuracy: 0.9234 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9984 - val_recall: 0.9586 - val_precision: 0.8980\n",
            "Epoch 151/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1731 - accuracy: 0.9266 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9250 - precision: 0.9279\n",
            "Epoch 151: val_accuracy did not improve from 0.94531\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.1731 - accuracy: 0.9266 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9250 - precision: 0.9279 - val_loss: 0.2142 - val_accuracy: 0.9164 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9889 - val_recall: 0.9768 - val_precision: 0.8729\n",
            "Epoch 152/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1888 - accuracy: 0.9203 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9961 - recall: 0.9273 - precision: 0.9129\n",
            "Epoch 152: val_accuracy did not improve from 0.94531\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.1888 - accuracy: 0.9203 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9961 - recall: 0.9273 - precision: 0.9129 - val_loss: 0.1620 - val_accuracy: 0.9438 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9922 - val_recall: 0.9718 - val_precision: 0.9199\n",
            "Epoch 153/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1761 - accuracy: 0.9312 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9928 - recall: 0.9369 - precision: 0.9299\n",
            "Epoch 153: val_accuracy did not improve from 0.94531\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.1761 - accuracy: 0.9312 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9928 - recall: 0.9369 - precision: 0.9299 - val_loss: 0.2340 - val_accuracy: 0.9039 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9937 - val_recall: 0.9892 - val_precision: 0.8468\n",
            "Epoch 154/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2187 - accuracy: 0.9141 - sensitivity_at_specificity: 0.9976 - specificity_at_sensitivity: 0.9962 - recall: 0.9144 - precision: 0.9115\n",
            "Epoch 154: val_accuracy did not improve from 0.94531\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.2187 - accuracy: 0.9141 - sensitivity_at_specificity: 0.9976 - specificity_at_sensitivity: 0.9962 - recall: 0.9144 - precision: 0.9115 - val_loss: 0.1911 - val_accuracy: 0.9312 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.9923 - val_recall: 0.9005 - val_precision: 0.9580\n",
            "Epoch 155/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1911 - accuracy: 0.9156 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9961 - recall: 0.9180 - precision: 0.9122\n",
            "Epoch 155: val_accuracy did not improve from 0.94531\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.1911 - accuracy: 0.9156 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9961 - recall: 0.9180 - precision: 0.9122 - val_loss: 0.2065 - val_accuracy: 0.9234 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 0.9936 - val_recall: 0.9588 - val_precision: 0.8986\n",
            "Epoch 156/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1789 - accuracy: 0.9273 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9961 - recall: 0.9374 - precision: 0.9203\n",
            "Epoch 156: val_accuracy did not improve from 0.94531\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.1789 - accuracy: 0.9273 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9961 - recall: 0.9374 - precision: 0.9203 - val_loss: 0.2096 - val_accuracy: 0.9070 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9783 - val_precision: 0.8575\n",
            "Epoch 157/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1655 - accuracy: 0.9363 - sensitivity_at_specificity: 0.9993 - specificity_at_sensitivity: 0.9975 - recall: 0.9389 - precision: 0.9396\n",
            "Epoch 157: val_accuracy did not improve from 0.94531\n",
            "10/10 [==============================] - 2s 182ms/step - loss: 0.1655 - accuracy: 0.9363 - sensitivity_at_specificity: 0.9993 - specificity_at_sensitivity: 0.9975 - recall: 0.9389 - precision: 0.9396 - val_loss: 0.2296 - val_accuracy: 0.9055 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9908 - val_recall: 0.9651 - val_precision: 0.8602\n",
            "Epoch 158/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2026 - accuracy: 0.9145 - sensitivity_at_specificity: 0.9977 - specificity_at_sensitivity: 0.9960 - recall: 0.9251 - precision: 0.9076\n",
            "Epoch 158: val_accuracy did not improve from 0.94531\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.2026 - accuracy: 0.9145 - sensitivity_at_specificity: 0.9977 - specificity_at_sensitivity: 0.9960 - recall: 0.9251 - precision: 0.9076 - val_loss: 0.1574 - val_accuracy: 0.9414 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9952 - val_recall: 0.9665 - val_precision: 0.9229\n",
            "Epoch 159/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2054 - accuracy: 0.9141 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9939 - recall: 0.9207 - precision: 0.9047\n",
            "Epoch 159: val_accuracy did not improve from 0.94531\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.2054 - accuracy: 0.9141 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9939 - recall: 0.9207 - precision: 0.9047 - val_loss: 0.1939 - val_accuracy: 0.9172 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.9922 - val_recall: 0.8844 - val_precision: 0.9465\n",
            "Epoch 160/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2122 - accuracy: 0.9113 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9937 - recall: 0.9139 - precision: 0.9104\n",
            "Epoch 160: val_accuracy did not improve from 0.94531\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.2122 - accuracy: 0.9113 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9937 - recall: 0.9139 - precision: 0.9104 - val_loss: 0.2432 - val_accuracy: 0.9000 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.9923 - val_recall: 0.9745 - val_precision: 0.8453\n",
            "Epoch 161/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2166 - accuracy: 0.9160 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9938 - recall: 0.9218 - precision: 0.9111\n",
            "Epoch 161: val_accuracy did not improve from 0.94531\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.2166 - accuracy: 0.9160 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9938 - recall: 0.9218 - precision: 0.9111 - val_loss: 0.2221 - val_accuracy: 0.9055 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9940 - val_recall: 0.9804 - val_precision: 0.8460\n",
            "Epoch 162/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1956 - accuracy: 0.9180 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9945 - recall: 0.9219 - precision: 0.9163\n",
            "Epoch 162: val_accuracy did not improve from 0.94531\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.1956 - accuracy: 0.9180 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9945 - recall: 0.9219 - precision: 0.9163 - val_loss: 0.2282 - val_accuracy: 0.9039 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9969 - val_recall: 0.9488 - val_precision: 0.8670\n",
            "Epoch 163/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1898 - accuracy: 0.9281 - sensitivity_at_specificity: 0.9953 - specificity_at_sensitivity: 0.9969 - recall: 0.9407 - precision: 0.9177\n",
            "Epoch 163: val_accuracy did not improve from 0.94531\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.1898 - accuracy: 0.9281 - sensitivity_at_specificity: 0.9953 - specificity_at_sensitivity: 0.9969 - recall: 0.9407 - precision: 0.9177 - val_loss: 0.1652 - val_accuracy: 0.9344 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 0.9918 - val_recall: 0.9340 - val_precision: 0.9397\n",
            "Epoch 164/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1693 - accuracy: 0.9367 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9922 - recall: 0.9467 - precision: 0.9277\n",
            "Epoch 164: val_accuracy did not improve from 0.94531\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.1693 - accuracy: 0.9367 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9922 - recall: 0.9467 - precision: 0.9277 - val_loss: 0.1936 - val_accuracy: 0.9234 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9924 - val_recall: 0.9743 - val_precision: 0.8810\n",
            "Epoch 165/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1766 - accuracy: 0.9258 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9961 - recall: 0.9294 - precision: 0.9222\n",
            "Epoch 165: val_accuracy did not improve from 0.94531\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.1766 - accuracy: 0.9258 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9961 - recall: 0.9294 - precision: 0.9222 - val_loss: 0.1613 - val_accuracy: 0.9414 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.9985 - val_recall: 0.9709 - val_precision: 0.9134\n",
            "Epoch 166/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1691 - accuracy: 0.9383 - sensitivity_at_specificity: 0.9976 - specificity_at_sensitivity: 0.9954 - recall: 0.9354 - precision: 0.9398\n",
            "Epoch 166: val_accuracy did not improve from 0.94531\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.1691 - accuracy: 0.9383 - sensitivity_at_specificity: 0.9976 - specificity_at_sensitivity: 0.9954 - recall: 0.9354 - precision: 0.9398 - val_loss: 0.2197 - val_accuracy: 0.9148 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9954 - val_recall: 0.9807 - val_precision: 0.8630\n",
            "Epoch 167/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1848 - accuracy: 0.9312 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9937 - recall: 0.9374 - precision: 0.9274\n",
            "Epoch 167: val_accuracy did not improve from 0.94531\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.1848 - accuracy: 0.9312 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9937 - recall: 0.9374 - precision: 0.9274 - val_loss: 0.1907 - val_accuracy: 0.9266 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.9984 - val_recall: 0.9717 - val_precision: 0.8906\n",
            "Epoch 168/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1580 - accuracy: 0.9359 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9419 - precision: 0.9302\n",
            "Epoch 168: val_accuracy did not improve from 0.94531\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.1580 - accuracy: 0.9359 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9419 - precision: 0.9302 - val_loss: 0.2176 - val_accuracy: 0.9047 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9984 - val_recall: 0.9843 - val_precision: 0.8480\n",
            "Epoch 169/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.1590 - accuracy: 0.9336 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9974 - recall: 0.9348 - precision: 0.9324\n",
            "Epoch 169: val_accuracy did not improve from 0.94531\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.1578 - accuracy: 0.9340 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9975 - recall: 0.9361 - precision: 0.9322 - val_loss: 0.2109 - val_accuracy: 0.9219 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.9906 - val_recall: 0.9750 - val_precision: 0.8812\n",
            "Epoch 170/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1725 - accuracy: 0.9383 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9922 - recall: 0.9400 - precision: 0.9371\n",
            "Epoch 170: val_accuracy did not improve from 0.94531\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.1725 - accuracy: 0.9383 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9922 - recall: 0.9400 - precision: 0.9371 - val_loss: 0.2021 - val_accuracy: 0.9148 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9984 - val_recall: 0.9770 - val_precision: 0.8716\n",
            "Epoch 171/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1558 - accuracy: 0.9395 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9513 - precision: 0.9287\n",
            "Epoch 171: val_accuracy did not improve from 0.94531\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.1558 - accuracy: 0.9395 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9513 - precision: 0.9287 - val_loss: 0.1489 - val_accuracy: 0.9445 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9953 - val_recall: 0.9470 - val_precision: 0.9426\n",
            "Epoch 172/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1634 - accuracy: 0.9352 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9961 - recall: 0.9415 - precision: 0.9299\n",
            "Epoch 172: val_accuracy did not improve from 0.94531\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.1634 - accuracy: 0.9352 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9961 - recall: 0.9415 - precision: 0.9299 - val_loss: 0.1913 - val_accuracy: 0.9242 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9954 - val_recall: 0.9554 - val_precision: 0.8969\n",
            "Epoch 173/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1934 - accuracy: 0.9227 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9946 - recall: 0.9188 - precision: 0.9246\n",
            "Epoch 173: val_accuracy did not improve from 0.94531\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.1934 - accuracy: 0.9227 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9946 - recall: 0.9188 - precision: 0.9246 - val_loss: 0.2341 - val_accuracy: 0.8961 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9954 - val_recall: 0.9888 - val_precision: 0.8304\n",
            "Epoch 174/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2057 - accuracy: 0.9186 - sensitivity_at_specificity: 0.9975 - specificity_at_sensitivity: 0.9967 - recall: 0.9129 - precision: 0.9236\n",
            "Epoch 174: val_accuracy did not improve from 0.94531\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.2057 - accuracy: 0.9186 - sensitivity_at_specificity: 0.9975 - specificity_at_sensitivity: 0.9967 - recall: 0.9129 - precision: 0.9236 - val_loss: 0.2357 - val_accuracy: 0.8977 - val_sensitivity_at_specificity: 0.9968 - val_specificity_at_sensitivity: 0.9938 - val_recall: 0.8302 - val_precision: 0.9561\n",
            "Epoch 175/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2118 - accuracy: 0.9152 - sensitivity_at_specificity: 0.9976 - specificity_at_sensitivity: 0.9915 - recall: 0.9225 - precision: 0.9074\n",
            "Epoch 175: val_accuracy did not improve from 0.94531\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.2118 - accuracy: 0.9152 - sensitivity_at_specificity: 0.9976 - specificity_at_sensitivity: 0.9915 - recall: 0.9225 - precision: 0.9074 - val_loss: 0.2036 - val_accuracy: 0.9172 - val_sensitivity_at_specificity: 0.9969 - val_specificity_at_sensitivity: 0.9984 - val_recall: 0.9755 - val_precision: 0.8764\n",
            "Epoch 176/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1706 - accuracy: 0.9363 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9969 - recall: 0.9408 - precision: 0.9328\n",
            "Epoch 176: val_accuracy did not improve from 0.94531\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.1706 - accuracy: 0.9363 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9969 - recall: 0.9408 - precision: 0.9328 - val_loss: 0.1829 - val_accuracy: 0.9234 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9969 - val_recall: 0.9470 - val_precision: 0.9046\n",
            "Epoch 177/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1733 - accuracy: 0.9285 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9954 - recall: 0.9282 - precision: 0.9275\n",
            "Epoch 177: val_accuracy did not improve from 0.94531\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.1733 - accuracy: 0.9285 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9954 - recall: 0.9282 - precision: 0.9275 - val_loss: 0.2049 - val_accuracy: 0.9156 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9955 - val_recall: 0.9774 - val_precision: 0.8657\n",
            "Epoch 178/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1519 - accuracy: 0.9465 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9962 - recall: 0.9490 - precision: 0.9423\n",
            "Epoch 178: val_accuracy did not improve from 0.94531\n",
            "10/10 [==============================] - 2s 182ms/step - loss: 0.1519 - accuracy: 0.9465 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9962 - recall: 0.9490 - precision: 0.9423 - val_loss: 0.1559 - val_accuracy: 0.9445 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9952 - val_recall: 0.9708 - val_precision: 0.9240\n",
            "Epoch 179/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1529 - accuracy: 0.9426 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9961 - recall: 0.9487 - precision: 0.9378\n",
            "Epoch 179: val_accuracy did not improve from 0.94531\n",
            "10/10 [==============================] - 2s 174ms/step - loss: 0.1529 - accuracy: 0.9426 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9961 - recall: 0.9487 - precision: 0.9378 - val_loss: 0.1727 - val_accuracy: 0.9281 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.9984 - val_recall: 0.9751 - val_precision: 0.8919\n",
            "Epoch 180/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1705 - accuracy: 0.9273 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 0.9992 - recall: 0.9285 - precision: 0.9285\n",
            "Epoch 180: val_accuracy did not improve from 0.94531\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.1705 - accuracy: 0.9273 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 0.9992 - recall: 0.9285 - precision: 0.9285 - val_loss: 0.1981 - val_accuracy: 0.9219 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9937 - val_recall: 0.9845 - val_precision: 0.8759\n",
            "Epoch 181/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1593 - accuracy: 0.9336 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9970 - recall: 0.9393 - precision: 0.9243\n",
            "Epoch 181: val_accuracy did not improve from 0.94531\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.1593 - accuracy: 0.9336 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9970 - recall: 0.9393 - precision: 0.9243 - val_loss: 0.1436 - val_accuracy: 0.9445 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9984 - val_recall: 0.9614 - val_precision: 0.9311\n",
            "Epoch 182/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1883 - accuracy: 0.9234 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9961 - recall: 0.9274 - precision: 0.9187\n",
            "Epoch 182: val_accuracy did not improve from 0.94531\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.1883 - accuracy: 0.9234 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9961 - recall: 0.9274 - precision: 0.9187 - val_loss: 0.2176 - val_accuracy: 0.9062 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9967 - val_recall: 0.9731 - val_precision: 0.8644\n",
            "Epoch 183/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1999 - accuracy: 0.9191 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9952 - recall: 0.9190 - precision: 0.9225\n",
            "Epoch 183: val_accuracy did not improve from 0.94531\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.1999 - accuracy: 0.9191 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9952 - recall: 0.9190 - precision: 0.9225 - val_loss: 0.1642 - val_accuracy: 0.9391 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9968 - val_recall: 0.9523 - val_precision: 0.9294\n",
            "Epoch 184/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1704 - accuracy: 0.9297 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9970 - recall: 0.9313 - precision: 0.9238\n",
            "Epoch 184: val_accuracy did not improve from 0.94531\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.1704 - accuracy: 0.9297 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9970 - recall: 0.9313 - precision: 0.9238 - val_loss: 0.2113 - val_accuracy: 0.9117 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 0.9952 - val_recall: 0.9769 - val_precision: 0.8663\n",
            "Epoch 185/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1700 - accuracy: 0.9301 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9976 - recall: 0.9355 - precision: 0.9261\n",
            "Epoch 185: val_accuracy improved from 0.94531 to 0.95547, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 221ms/step - loss: 0.1700 - accuracy: 0.9301 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9976 - recall: 0.9355 - precision: 0.9261 - val_loss: 0.1421 - val_accuracy: 0.9555 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 0.9968 - val_recall: 0.9493 - val_precision: 0.9626\n",
            "Epoch 186/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1599 - accuracy: 0.9410 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9953 - recall: 0.9411 - precision: 0.9404\n",
            "Epoch 186: val_accuracy did not improve from 0.95547\n",
            "10/10 [==============================] - 2s 183ms/step - loss: 0.1599 - accuracy: 0.9410 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9953 - recall: 0.9411 - precision: 0.9404 - val_loss: 0.2822 - val_accuracy: 0.8695 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.9969 - val_recall: 0.9829 - val_precision: 0.8020\n",
            "Epoch 187/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1897 - accuracy: 0.9219 - sensitivity_at_specificity: 0.9993 - specificity_at_sensitivity: 0.9925 - recall: 0.9342 - precision: 0.9193\n",
            "Epoch 187: val_accuracy did not improve from 0.95547\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.1897 - accuracy: 0.9219 - sensitivity_at_specificity: 0.9993 - specificity_at_sensitivity: 0.9925 - recall: 0.9342 - precision: 0.9193 - val_loss: 0.1738 - val_accuracy: 0.9398 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.9937 - val_recall: 0.9627 - val_precision: 0.9211\n",
            "Epoch 188/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1810 - accuracy: 0.9262 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9968 - recall: 0.9219 - precision: 0.9339\n",
            "Epoch 188: val_accuracy did not improve from 0.95547\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.1810 - accuracy: 0.9262 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9968 - recall: 0.9219 - precision: 0.9339 - val_loss: 0.2862 - val_accuracy: 0.8805 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9923 - val_recall: 0.9841 - val_precision: 0.8118\n",
            "Epoch 189/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1996 - accuracy: 0.9195 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9946 - recall: 0.9407 - precision: 0.9008\n",
            "Epoch 189: val_accuracy did not improve from 0.95547\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.1996 - accuracy: 0.9195 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9946 - recall: 0.9407 - precision: 0.9008 - val_loss: 0.1469 - val_accuracy: 0.9445 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9348 - val_precision: 0.9540\n",
            "Epoch 190/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1803 - accuracy: 0.9289 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9937 - recall: 0.9189 - precision: 0.9379\n",
            "Epoch 190: val_accuracy did not improve from 0.95547\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.1803 - accuracy: 0.9289 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9937 - recall: 0.9189 - precision: 0.9379 - val_loss: 0.2828 - val_accuracy: 0.8914 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9970 - val_recall: 0.9886 - val_precision: 0.8209\n",
            "Epoch 191/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1736 - accuracy: 0.9320 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9977 - recall: 0.9404 - precision: 0.9244\n",
            "Epoch 191: val_accuracy did not improve from 0.95547\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.1736 - accuracy: 0.9320 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9977 - recall: 0.9404 - precision: 0.9244 - val_loss: 0.1462 - val_accuracy: 0.9438 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 0.9984 - val_recall: 0.9578 - val_precision: 0.9352\n",
            "Epoch 192/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1707 - accuracy: 0.9344 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9968 - recall: 0.9302 - precision: 0.9416\n",
            "Epoch 192: val_accuracy did not improve from 0.95547\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.1707 - accuracy: 0.9344 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9968 - recall: 0.9302 - precision: 0.9416 - val_loss: 0.1863 - val_accuracy: 0.9180 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9967 - val_recall: 0.9777 - val_precision: 0.8795\n",
            "Epoch 193/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1678 - accuracy: 0.9344 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9962 - recall: 0.9346 - precision: 0.9316\n",
            "Epoch 193: val_accuracy did not improve from 0.95547\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.1678 - accuracy: 0.9344 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9962 - recall: 0.9346 - precision: 0.9316 - val_loss: 0.2153 - val_accuracy: 0.9164 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 0.9920 - val_recall: 0.9772 - val_precision: 0.8747\n",
            "Epoch 194/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1639 - accuracy: 0.9371 - sensitivity_at_specificity: 0.9976 - specificity_at_sensitivity: 0.9977 - recall: 0.9490 - precision: 0.9247\n",
            "Epoch 194: val_accuracy did not improve from 0.95547\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.1639 - accuracy: 0.9371 - sensitivity_at_specificity: 0.9976 - specificity_at_sensitivity: 0.9977 - recall: 0.9490 - precision: 0.9247 - val_loss: 0.1300 - val_accuracy: 0.9492 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9800 - val_precision: 0.9244\n",
            "Epoch 195/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1632 - accuracy: 0.9336 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9952 - recall: 0.9327 - precision: 0.9370\n",
            "Epoch 195: val_accuracy did not improve from 0.95547\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.1632 - accuracy: 0.9336 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9952 - recall: 0.9327 - precision: 0.9370 - val_loss: 0.2534 - val_accuracy: 0.8953 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 0.9968 - val_recall: 0.9846 - val_precision: 0.8373\n",
            "Epoch 196/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1665 - accuracy: 0.9298 - sensitivity_at_specificity: 0.9991 - specificity_at_sensitivity: 0.9992 - recall: 0.9384 - precision: 0.9187\n",
            "Epoch 196: val_accuracy did not improve from 0.95547\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.1665 - accuracy: 0.9298 - sensitivity_at_specificity: 0.9991 - specificity_at_sensitivity: 0.9992 - recall: 0.9384 - precision: 0.9187 - val_loss: 0.1360 - val_accuracy: 0.9469 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9985 - val_recall: 0.9123 - val_precision: 0.9757\n",
            "Epoch 197/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1838 - accuracy: 0.9240 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9950 - recall: 0.9140 - precision: 0.9333\n",
            "Epoch 197: val_accuracy did not improve from 0.95547\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.1838 - accuracy: 0.9240 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9950 - recall: 0.9140 - precision: 0.9333 - val_loss: 0.1900 - val_accuracy: 0.9219 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9937 - val_recall: 0.9892 - val_precision: 0.8731\n",
            "Epoch 198/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1723 - accuracy: 0.9324 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 0.9976 - recall: 0.9420 - precision: 0.9271\n",
            "Epoch 198: val_accuracy did not improve from 0.95547\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.1723 - accuracy: 0.9324 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 0.9976 - recall: 0.9420 - precision: 0.9271 - val_loss: 0.1895 - val_accuracy: 0.9203 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.9954 - val_recall: 0.9762 - val_precision: 0.8759\n",
            "Epoch 199/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1486 - accuracy: 0.9431 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9967 - recall: 0.9501 - precision: 0.9368\n",
            "Epoch 199: val_accuracy did not improve from 0.95547\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.1486 - accuracy: 0.9431 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9967 - recall: 0.9501 - precision: 0.9368 - val_loss: 0.1557 - val_accuracy: 0.9414 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 0.9952 - val_recall: 0.9803 - val_precision: 0.9127\n",
            "Epoch 200/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1764 - accuracy: 0.9324 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 0.9944 - recall: 0.9328 - precision: 0.9349\n",
            "Epoch 200: val_accuracy did not improve from 0.95547\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.1764 - accuracy: 0.9324 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 0.9944 - recall: 0.9328 - precision: 0.9349 - val_loss: 0.1989 - val_accuracy: 0.9195 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.9985 - val_recall: 0.9889 - val_precision: 0.8661\n",
            "Epoch 201/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1494 - accuracy: 0.9430 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9546 - precision: 0.9327\n",
            "Epoch 201: val_accuracy did not improve from 0.95547\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.1494 - accuracy: 0.9430 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9546 - precision: 0.9327 - val_loss: 0.1478 - val_accuracy: 0.9414 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9970 - val_recall: 0.9743 - val_precision: 0.9113\n",
            "Epoch 202/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1565 - accuracy: 0.9367 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9985 - recall: 0.9335 - precision: 0.9379\n",
            "Epoch 202: val_accuracy did not improve from 0.95547\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.1565 - accuracy: 0.9367 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9985 - recall: 0.9335 - precision: 0.9379 - val_loss: 0.1094 - val_accuracy: 0.9531 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9571 - val_precision: 0.9481\n",
            "Epoch 203/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1525 - accuracy: 0.9402 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9951 - recall: 0.9494 - precision: 0.9360\n",
            "Epoch 203: val_accuracy did not improve from 0.95547\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.1525 - accuracy: 0.9402 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9951 - recall: 0.9494 - precision: 0.9360 - val_loss: 0.1468 - val_accuracy: 0.9500 - val_sensitivity_at_specificity: 0.9968 - val_specificity_at_sensitivity: 0.9923 - val_recall: 0.9619 - val_precision: 0.9381\n",
            "Epoch 204/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1658 - accuracy: 0.9328 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9977 - recall: 0.9232 - precision: 0.9396\n",
            "Epoch 204: val_accuracy did not improve from 0.95547\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.1658 - accuracy: 0.9328 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9977 - recall: 0.9232 - precision: 0.9396 - val_loss: 0.2000 - val_accuracy: 0.9180 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9969 - val_recall: 0.9810 - val_precision: 0.8692\n",
            "Epoch 205/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1611 - accuracy: 0.9363 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9976 - recall: 0.9446 - precision: 0.9310\n",
            "Epoch 205: val_accuracy did not improve from 0.95547\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.1611 - accuracy: 0.9363 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9976 - recall: 0.9446 - precision: 0.9310 - val_loss: 0.1531 - val_accuracy: 0.9344 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9969 - val_recall: 0.9717 - val_precision: 0.9034\n",
            "Epoch 206/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1622 - accuracy: 0.9422 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9962 - recall: 0.9500 - precision: 0.9337\n",
            "Epoch 206: val_accuracy did not improve from 0.95547\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.1622 - accuracy: 0.9422 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9962 - recall: 0.9500 - precision: 0.9337 - val_loss: 0.1273 - val_accuracy: 0.9531 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9984 - val_recall: 0.9495 - val_precision: 0.9583\n",
            "Epoch 207/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1614 - accuracy: 0.9340 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9969 - recall: 0.9414 - precision: 0.9276\n",
            "Epoch 207: val_accuracy improved from 0.95547 to 0.96328, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 175ms/step - loss: 0.1614 - accuracy: 0.9340 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9969 - recall: 0.9414 - precision: 0.9276 - val_loss: 0.1043 - val_accuracy: 0.9633 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9985 - val_recall: 0.9729 - val_precision: 0.9531\n",
            "Epoch 208/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1411 - accuracy: 0.9391 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9447 - precision: 0.9375\n",
            "Epoch 208: val_accuracy did not improve from 0.96328\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.1411 - accuracy: 0.9391 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9447 - precision: 0.9375 - val_loss: 0.2155 - val_accuracy: 0.9195 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9939 - val_recall: 0.9825 - val_precision: 0.8701\n",
            "Epoch 209/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1641 - accuracy: 0.9312 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9360 - precision: 0.9288\n",
            "Epoch 209: val_accuracy did not improve from 0.96328\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.1641 - accuracy: 0.9312 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9360 - precision: 0.9288 - val_loss: 0.1318 - val_accuracy: 0.9492 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9970 - val_recall: 0.9588 - val_precision: 0.9357\n",
            "Epoch 210/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1584 - accuracy: 0.9398 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9954 - recall: 0.9392 - precision: 0.9392\n",
            "Epoch 210: val_accuracy did not improve from 0.96328\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.1584 - accuracy: 0.9398 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9954 - recall: 0.9392 - precision: 0.9392 - val_loss: 0.1373 - val_accuracy: 0.9477 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9984 - val_recall: 0.9702 - val_precision: 0.9280\n",
            "Epoch 211/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1464 - accuracy: 0.9391 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9977 - recall: 0.9412 - precision: 0.9368\n",
            "Epoch 211: val_accuracy did not improve from 0.96328\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.1464 - accuracy: 0.9391 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9977 - recall: 0.9412 - precision: 0.9368 - val_loss: 0.1168 - val_accuracy: 0.9570 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9953 - val_recall: 0.9735 - val_precision: 0.9427\n",
            "Epoch 212/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1518 - accuracy: 0.9371 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9977 - recall: 0.9363 - precision: 0.9371\n",
            "Epoch 212: val_accuracy did not improve from 0.96328\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.1518 - accuracy: 0.9371 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9977 - recall: 0.9363 - precision: 0.9371 - val_loss: 0.1954 - val_accuracy: 0.9195 - val_sensitivity_at_specificity: 0.9968 - val_specificity_at_sensitivity: 0.9970 - val_recall: 0.9663 - val_precision: 0.8801\n",
            "Epoch 213/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1409 - accuracy: 0.9430 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9985 - recall: 0.9525 - precision: 0.9332\n",
            "Epoch 213: val_accuracy did not improve from 0.96328\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.1409 - accuracy: 0.9430 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9985 - recall: 0.9525 - precision: 0.9332 - val_loss: 0.1584 - val_accuracy: 0.9430 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.9985 - val_recall: 0.9661 - val_precision: 0.9200\n",
            "Epoch 214/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1438 - accuracy: 0.9426 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9977 - recall: 0.9411 - precision: 0.9418\n",
            "Epoch 214: val_accuracy did not improve from 0.96328\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.1438 - accuracy: 0.9426 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9977 - recall: 0.9411 - precision: 0.9418 - val_loss: 0.1595 - val_accuracy: 0.9391 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.9984 - val_recall: 0.9764 - val_precision: 0.9079\n",
            "Epoch 215/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1650 - accuracy: 0.9319 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9958 - recall: 0.9380 - precision: 0.9272\n",
            "Epoch 215: val_accuracy did not improve from 0.96328\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.1650 - accuracy: 0.9319 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9958 - recall: 0.9380 - precision: 0.9272 - val_loss: 0.1103 - val_accuracy: 0.9586 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9984 - val_recall: 0.9583 - val_precision: 0.9598\n",
            "Epoch 216/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1800 - accuracy: 0.9297 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9961 - recall: 0.9237 - precision: 0.9353\n",
            "Epoch 216: val_accuracy did not improve from 0.96328\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.1800 - accuracy: 0.9297 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9961 - recall: 0.9237 - precision: 0.9353 - val_loss: 0.2403 - val_accuracy: 0.9086 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.9907 - val_recall: 0.9921 - val_precision: 0.8484\n",
            "Epoch 217/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1520 - accuracy: 0.9426 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9961 - recall: 0.9511 - precision: 0.9342\n",
            "Epoch 217: val_accuracy did not improve from 0.96328\n",
            "10/10 [==============================] - 2s 174ms/step - loss: 0.1520 - accuracy: 0.9426 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9961 - recall: 0.9511 - precision: 0.9342 - val_loss: 0.1389 - val_accuracy: 0.9445 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9969 - val_recall: 0.9794 - val_precision: 0.9142\n",
            "Epoch 218/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1614 - accuracy: 0.9340 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 0.9968 - recall: 0.9388 - precision: 0.9309\n",
            "Epoch 218: val_accuracy did not improve from 0.96328\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.1614 - accuracy: 0.9340 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 0.9968 - recall: 0.9388 - precision: 0.9309 - val_loss: 0.1302 - val_accuracy: 0.9508 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9968 - val_recall: 0.9447 - val_precision: 0.9579\n",
            "Epoch 219/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1535 - accuracy: 0.9391 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9985 - recall: 0.9333 - precision: 0.9409\n",
            "Epoch 219: val_accuracy did not improve from 0.96328\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.1535 - accuracy: 0.9391 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9985 - recall: 0.9333 - precision: 0.9409 - val_loss: 0.1509 - val_accuracy: 0.9461 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.9970 - val_recall: 0.9854 - val_precision: 0.9103\n",
            "Epoch 220/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1446 - accuracy: 0.9453 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9968 - recall: 0.9512 - precision: 0.9426\n",
            "Epoch 220: val_accuracy did not improve from 0.96328\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.1446 - accuracy: 0.9453 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9968 - recall: 0.9512 - precision: 0.9426 - val_loss: 0.1538 - val_accuracy: 0.9312 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9984 - val_recall: 0.9832 - val_precision: 0.8934\n",
            "Epoch 221/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.1449 - accuracy: 0.9401 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9973 - recall: 0.9457 - precision: 0.9395\n",
            "Epoch 221: val_accuracy did not improve from 0.96328\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.1460 - accuracy: 0.9398 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9966 - recall: 0.9438 - precision: 0.9400 - val_loss: 0.1387 - val_accuracy: 0.9492 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9745 - val_precision: 0.9258\n",
            "Epoch 222/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1419 - accuracy: 0.9473 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9985 - recall: 0.9484 - precision: 0.9446\n",
            "Epoch 222: val_accuracy did not improve from 0.96328\n",
            "10/10 [==============================] - 2s 188ms/step - loss: 0.1419 - accuracy: 0.9473 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9985 - recall: 0.9484 - precision: 0.9446 - val_loss: 0.1972 - val_accuracy: 0.9195 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9968 - val_recall: 0.9712 - val_precision: 0.8840\n",
            "Epoch 223/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1458 - accuracy: 0.9395 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9385 - precision: 0.9392\n",
            "Epoch 223: val_accuracy did not improve from 0.96328\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.1458 - accuracy: 0.9395 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9385 - precision: 0.9392 - val_loss: 0.1502 - val_accuracy: 0.9312 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9969 - val_recall: 0.9811 - val_precision: 0.8913\n",
            "Epoch 224/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1465 - accuracy: 0.9441 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9962 - recall: 0.9469 - precision: 0.9385\n",
            "Epoch 224: val_accuracy did not improve from 0.96328\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.1465 - accuracy: 0.9441 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9962 - recall: 0.9469 - precision: 0.9385 - val_loss: 0.1180 - val_accuracy: 0.9547 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9828 - val_precision: 0.9304\n",
            "Epoch 225/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1364 - accuracy: 0.9484 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9456 - precision: 0.9501\n",
            "Epoch 225: val_accuracy did not improve from 0.96328\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.1364 - accuracy: 0.9484 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9456 - precision: 0.9501 - val_loss: 0.2015 - val_accuracy: 0.9125 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9873 - val_precision: 0.8569\n",
            "Epoch 226/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1413 - accuracy: 0.9461 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9992 - recall: 0.9514 - precision: 0.9410\n",
            "Epoch 226: val_accuracy did not improve from 0.96328\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.1413 - accuracy: 0.9461 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9992 - recall: 0.9514 - precision: 0.9410 - val_loss: 0.1245 - val_accuracy: 0.9547 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9786 - val_precision: 0.9356\n",
            "Epoch 227/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1403 - accuracy: 0.9488 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 0.9984 - recall: 0.9490 - precision: 0.9498\n",
            "Epoch 227: val_accuracy did not improve from 0.96328\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.1403 - accuracy: 0.9488 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 0.9984 - recall: 0.9490 - precision: 0.9498 - val_loss: 0.1509 - val_accuracy: 0.9445 - val_sensitivity_at_specificity: 0.9969 - val_specificity_at_sensitivity: 0.9968 - val_recall: 0.9740 - val_precision: 0.9217\n",
            "Epoch 228/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1394 - accuracy: 0.9453 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9976 - recall: 0.9519 - precision: 0.9403\n",
            "Epoch 228: val_accuracy did not improve from 0.96328\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.1394 - accuracy: 0.9453 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9976 - recall: 0.9519 - precision: 0.9403 - val_loss: 0.1328 - val_accuracy: 0.9508 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.9985 - val_recall: 0.9762 - val_precision: 0.9277\n",
            "Epoch 229/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1315 - accuracy: 0.9527 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9985 - recall: 0.9528 - precision: 0.9505\n",
            "Epoch 229: val_accuracy did not improve from 0.96328\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.1315 - accuracy: 0.9527 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9985 - recall: 0.9528 - precision: 0.9505 - val_loss: 0.1352 - val_accuracy: 0.9438 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9984 - val_recall: 0.9677 - val_precision: 0.9251\n",
            "Epoch 230/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1403 - accuracy: 0.9457 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9985 - recall: 0.9439 - precision: 0.9431\n",
            "Epoch 230: val_accuracy did not improve from 0.96328\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.1403 - accuracy: 0.9457 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9985 - recall: 0.9439 - precision: 0.9431 - val_loss: 0.1207 - val_accuracy: 0.9602 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9566 - val_precision: 0.9641\n",
            "Epoch 231/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1464 - accuracy: 0.9395 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9431 - precision: 0.9410\n",
            "Epoch 231: val_accuracy did not improve from 0.96328\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.1464 - accuracy: 0.9395 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9431 - precision: 0.9410 - val_loss: 0.2131 - val_accuracy: 0.9117 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9743 - val_precision: 0.8622\n",
            "Epoch 232/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1325 - accuracy: 0.9473 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9984 - recall: 0.9477 - precision: 0.9484\n",
            "Epoch 232: val_accuracy did not improve from 0.96328\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.1325 - accuracy: 0.9473 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9984 - recall: 0.9477 - precision: 0.9484 - val_loss: 0.1322 - val_accuracy: 0.9461 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9984 - val_recall: 0.9642 - val_precision: 0.9308\n",
            "Epoch 233/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1392 - accuracy: 0.9488 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9977 - recall: 0.9471 - precision: 0.9494\n",
            "Epoch 233: val_accuracy did not improve from 0.96328\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.1392 - accuracy: 0.9488 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9977 - recall: 0.9471 - precision: 0.9494 - val_loss: 0.1588 - val_accuracy: 0.9414 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 0.9983 - val_recall: 0.9824 - val_precision: 0.9139\n",
            "Epoch 234/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1455 - accuracy: 0.9441 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9985 - recall: 0.9403 - precision: 0.9441\n",
            "Epoch 234: val_accuracy did not improve from 0.96328\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.1455 - accuracy: 0.9441 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9985 - recall: 0.9403 - precision: 0.9441 - val_loss: 0.1428 - val_accuracy: 0.9531 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 0.9937 - val_recall: 0.9907 - val_precision: 0.9223\n",
            "Epoch 235/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1292 - accuracy: 0.9473 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9487 - precision: 0.9449\n",
            "Epoch 235: val_accuracy did not improve from 0.96328\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.1292 - accuracy: 0.9473 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9487 - precision: 0.9449 - val_loss: 0.1315 - val_accuracy: 0.9469 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9554 - val_precision: 0.9375\n",
            "Epoch 236/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1397 - accuracy: 0.9461 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9442 - precision: 0.9472\n",
            "Epoch 236: val_accuracy did not improve from 0.96328\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.1397 - accuracy: 0.9461 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9442 - precision: 0.9472 - val_loss: 0.2227 - val_accuracy: 0.9102 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9985 - val_recall: 0.9823 - val_precision: 0.8547\n",
            "Epoch 237/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1575 - accuracy: 0.9379 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9969 - recall: 0.9399 - precision: 0.9362\n",
            "Epoch 237: val_accuracy did not improve from 0.96328\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.1575 - accuracy: 0.9379 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9969 - recall: 0.9399 - precision: 0.9362 - val_loss: 0.1266 - val_accuracy: 0.9523 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9488 - val_precision: 0.9562\n",
            "Epoch 238/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1512 - accuracy: 0.9426 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9977 - recall: 0.9451 - precision: 0.9399\n",
            "Epoch 238: val_accuracy did not improve from 0.96328\n",
            "10/10 [==============================] - 2s 183ms/step - loss: 0.1512 - accuracy: 0.9426 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9977 - recall: 0.9451 - precision: 0.9399 - val_loss: 0.1146 - val_accuracy: 0.9594 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9984 - val_recall: 0.9792 - val_precision: 0.9454\n",
            "Epoch 239/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1363 - accuracy: 0.9480 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9561 - precision: 0.9422\n",
            "Epoch 239: val_accuracy did not improve from 0.96328\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.1363 - accuracy: 0.9480 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9561 - precision: 0.9422 - val_loss: 0.1481 - val_accuracy: 0.9477 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 0.9984 - val_recall: 0.9804 - val_precision: 0.9232\n",
            "Epoch 240/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1249 - accuracy: 0.9539 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9976 - recall: 0.9472 - precision: 0.9632\n",
            "Epoch 240: val_accuracy did not improve from 0.96328\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.1249 - accuracy: 0.9539 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9976 - recall: 0.9472 - precision: 0.9632 - val_loss: 0.1451 - val_accuracy: 0.9461 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 0.9952 - val_recall: 0.9754 - val_precision: 0.9230\n",
            "Epoch 241/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1381 - accuracy: 0.9480 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9529 - precision: 0.9448\n",
            "Epoch 241: val_accuracy did not improve from 0.96328\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.1381 - accuracy: 0.9480 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9529 - precision: 0.9448 - val_loss: 0.1493 - val_accuracy: 0.9430 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9985 - val_recall: 0.9684 - val_precision: 0.9203\n",
            "Epoch 242/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1523 - accuracy: 0.9457 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9984 - recall: 0.9394 - precision: 0.9506\n",
            "Epoch 242: val_accuracy did not improve from 0.96328\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.1523 - accuracy: 0.9457 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9984 - recall: 0.9394 - precision: 0.9506 - val_loss: 0.1201 - val_accuracy: 0.9484 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9550 - val_precision: 0.9433\n",
            "Epoch 243/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1466 - accuracy: 0.9445 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9552 - precision: 0.9365\n",
            "Epoch 243: val_accuracy improved from 0.96328 to 0.96406, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 176ms/step - loss: 0.1466 - accuracy: 0.9445 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9552 - precision: 0.9365 - val_loss: 0.1119 - val_accuracy: 0.9641 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9578 - val_precision: 0.9724\n",
            "Epoch 244/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1480 - accuracy: 0.9422 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9970 - recall: 0.9310 - precision: 0.9493\n",
            "Epoch 244: val_accuracy did not improve from 0.96406\n",
            "10/10 [==============================] - 2s 200ms/step - loss: 0.1480 - accuracy: 0.9422 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9970 - recall: 0.9310 - precision: 0.9493 - val_loss: 0.2126 - val_accuracy: 0.9055 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9820 - val_precision: 0.8453\n",
            "Epoch 245/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1329 - accuracy: 0.9473 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9507 - precision: 0.9441\n",
            "Epoch 245: val_accuracy did not improve from 0.96406\n",
            "10/10 [==============================] - 2s 199ms/step - loss: 0.1329 - accuracy: 0.9473 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9507 - precision: 0.9441 - val_loss: 0.1179 - val_accuracy: 0.9539 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9776 - val_precision: 0.9313\n",
            "Epoch 246/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1359 - accuracy: 0.9453 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9474 - precision: 0.9430\n",
            "Epoch 246: val_accuracy did not improve from 0.96406\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.1359 - accuracy: 0.9453 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9474 - precision: 0.9430 - val_loss: 0.1436 - val_accuracy: 0.9406 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9823 - val_precision: 0.9037\n",
            "Epoch 247/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1315 - accuracy: 0.9496 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9588 - precision: 0.9437\n",
            "Epoch 247: val_accuracy did not improve from 0.96406\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.1315 - accuracy: 0.9496 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9588 - precision: 0.9437 - val_loss: 0.1316 - val_accuracy: 0.9539 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9845 - val_precision: 0.9286\n",
            "Epoch 248/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1242 - accuracy: 0.9492 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9509 - precision: 0.9479\n",
            "Epoch 248: val_accuracy did not improve from 0.96406\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.1242 - accuracy: 0.9492 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9509 - precision: 0.9479 - val_loss: 0.1232 - val_accuracy: 0.9594 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.9985 - val_recall: 0.9841 - val_precision: 0.9365\n",
            "Epoch 249/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1273 - accuracy: 0.9547 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9969 - recall: 0.9566 - precision: 0.9521\n",
            "Epoch 249: val_accuracy did not improve from 0.96406\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.1273 - accuracy: 0.9547 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9969 - recall: 0.9566 - precision: 0.9521 - val_loss: 0.1653 - val_accuracy: 0.9328 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9985 - val_recall: 0.9539 - val_precision: 0.9089\n",
            "Epoch 250/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1256 - accuracy: 0.9477 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9452 - precision: 0.9467\n",
            "Epoch 250: val_accuracy did not improve from 0.96406\n",
            "10/10 [==============================] - 2s 179ms/step - loss: 0.1256 - accuracy: 0.9477 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9452 - precision: 0.9467 - val_loss: 0.1541 - val_accuracy: 0.9367 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9907 - val_precision: 0.8953\n",
            "Epoch 251/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1237 - accuracy: 0.9504 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9984 - recall: 0.9496 - precision: 0.9504\n",
            "Epoch 251: val_accuracy did not improve from 0.96406\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.1237 - accuracy: 0.9504 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9984 - recall: 0.9496 - precision: 0.9504 - val_loss: 0.1104 - val_accuracy: 0.9547 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9694 - val_precision: 0.9391\n",
            "Epoch 252/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1125 - accuracy: 0.9633 - sensitivity_at_specificity: 0.9977 - specificity_at_sensitivity: 0.9992 - recall: 0.9697 - precision: 0.9578\n",
            "Epoch 252: val_accuracy did not improve from 0.96406\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.1125 - accuracy: 0.9633 - sensitivity_at_specificity: 0.9977 - specificity_at_sensitivity: 0.9992 - recall: 0.9697 - precision: 0.9578 - val_loss: 0.1145 - val_accuracy: 0.9578 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9486 - val_precision: 0.9691\n",
            "Epoch 253/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1507 - accuracy: 0.9379 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9294 - precision: 0.9423\n",
            "Epoch 253: val_accuracy did not improve from 0.96406\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.1507 - accuracy: 0.9379 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9294 - precision: 0.9423 - val_loss: 0.1906 - val_accuracy: 0.9180 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9984 - val_recall: 0.9955 - val_precision: 0.8665\n",
            "Epoch 254/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1462 - accuracy: 0.9387 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9466 - precision: 0.9313\n",
            "Epoch 254: val_accuracy did not improve from 0.96406\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.1462 - accuracy: 0.9387 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9466 - precision: 0.9313 - val_loss: 0.1068 - val_accuracy: 0.9617 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9448 - val_precision: 0.9814\n",
            "Epoch 255/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1483 - accuracy: 0.9398 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9339 - precision: 0.9483\n",
            "Epoch 255: val_accuracy did not improve from 0.96406\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.1483 - accuracy: 0.9398 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9339 - precision: 0.9483 - val_loss: 0.1522 - val_accuracy: 0.9352 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9984 - val_recall: 0.9843 - val_precision: 0.8959\n",
            "Epoch 256/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1428 - accuracy: 0.9426 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9961 - recall: 0.9551 - precision: 0.9327\n",
            "Epoch 256: val_accuracy did not improve from 0.96406\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.1428 - accuracy: 0.9426 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9961 - recall: 0.9551 - precision: 0.9327 - val_loss: 0.1163 - val_accuracy: 0.9602 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9985 - val_recall: 0.9652 - val_precision: 0.9546\n",
            "Epoch 257/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1369 - accuracy: 0.9492 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9970 - recall: 0.9421 - precision: 0.9500\n",
            "Epoch 257: val_accuracy did not improve from 0.96406\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.1369 - accuracy: 0.9492 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9970 - recall: 0.9421 - precision: 0.9500 - val_loss: 0.1526 - val_accuracy: 0.9320 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9862 - val_precision: 0.8915\n",
            "Epoch 258/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1376 - accuracy: 0.9457 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9985 - recall: 0.9554 - precision: 0.9353\n",
            "Epoch 258: val_accuracy did not improve from 0.96406\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.1376 - accuracy: 0.9457 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9985 - recall: 0.9554 - precision: 0.9353 - val_loss: 0.1198 - val_accuracy: 0.9508 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9984 - val_recall: 0.9664 - val_precision: 0.9391\n",
            "Epoch 259/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1263 - accuracy: 0.9527 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9521 - precision: 0.9536\n",
            "Epoch 259: val_accuracy did not improve from 0.96406\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.1263 - accuracy: 0.9527 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9521 - precision: 0.9536 - val_loss: 0.1218 - val_accuracy: 0.9531 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9985 - val_recall: 0.9711 - val_precision: 0.9350\n",
            "Epoch 260/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1371 - accuracy: 0.9473 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9567 - precision: 0.9383\n",
            "Epoch 260: val_accuracy did not improve from 0.96406\n",
            "10/10 [==============================] - 2s 185ms/step - loss: 0.1371 - accuracy: 0.9473 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9567 - precision: 0.9383 - val_loss: 0.1200 - val_accuracy: 0.9531 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9830 - val_precision: 0.9286\n",
            "Epoch 261/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1147 - accuracy: 0.9586 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9606 - precision: 0.9592\n",
            "Epoch 261: val_accuracy did not improve from 0.96406\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.1147 - accuracy: 0.9586 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9606 - precision: 0.9592 - val_loss: 0.1163 - val_accuracy: 0.9516 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9984 - val_recall: 0.9612 - val_precision: 0.9436\n",
            "Epoch 262/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1233 - accuracy: 0.9563 - sensitivity_at_specificity: 0.9976 - specificity_at_sensitivity: 0.9992 - recall: 0.9573 - precision: 0.9543\n",
            "Epoch 262: val_accuracy did not improve from 0.96406\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.1233 - accuracy: 0.9563 - sensitivity_at_specificity: 0.9976 - specificity_at_sensitivity: 0.9992 - recall: 0.9573 - precision: 0.9543 - val_loss: 0.1513 - val_accuracy: 0.9445 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9684 - val_precision: 0.9232\n",
            "Epoch 263/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1167 - accuracy: 0.9539 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9559 - precision: 0.9544\n",
            "Epoch 263: val_accuracy did not improve from 0.96406\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.1167 - accuracy: 0.9539 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9559 - precision: 0.9544 - val_loss: 0.1025 - val_accuracy: 0.9633 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9984 - val_recall: 0.9906 - val_precision: 0.9390\n",
            "Epoch 264/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1178 - accuracy: 0.9563 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9561 - precision: 0.9575\n",
            "Epoch 264: val_accuracy did not improve from 0.96406\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.1178 - accuracy: 0.9563 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9561 - precision: 0.9575 - val_loss: 0.1391 - val_accuracy: 0.9547 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9855 - val_precision: 0.9258\n",
            "Epoch 265/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1414 - accuracy: 0.9445 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9976 - recall: 0.9471 - precision: 0.9457\n",
            "Epoch 265: val_accuracy did not improve from 0.96406\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.1414 - accuracy: 0.9445 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9976 - recall: 0.9471 - precision: 0.9457 - val_loss: 0.1310 - val_accuracy: 0.9500 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9799 - val_precision: 0.9255\n",
            "Epoch 266/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1163 - accuracy: 0.9551 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9569 - precision: 0.9532\n",
            "Epoch 266: val_accuracy did not improve from 0.96406\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.1163 - accuracy: 0.9551 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9569 - precision: 0.9532 - val_loss: 0.1482 - val_accuracy: 0.9375 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9594 - val_precision: 0.9193\n",
            "Epoch 267/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1559 - accuracy: 0.9316 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9976 - recall: 0.9455 - precision: 0.9238\n",
            "Epoch 267: val_accuracy did not improve from 0.96406\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.1559 - accuracy: 0.9316 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9976 - recall: 0.9455 - precision: 0.9238 - val_loss: 0.1449 - val_accuracy: 0.9484 - val_sensitivity_at_specificity: 0.9983 - val_specificity_at_sensitivity: 0.9985 - val_recall: 0.9751 - val_precision: 0.9202\n",
            "Epoch 268/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1379 - accuracy: 0.9469 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9985 - recall: 0.9463 - precision: 0.9448\n",
            "Epoch 268: val_accuracy did not improve from 0.96406\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.1379 - accuracy: 0.9469 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9985 - recall: 0.9463 - precision: 0.9448 - val_loss: 0.1416 - val_accuracy: 0.9445 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9486 - val_precision: 0.9443\n",
            "Epoch 269/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1270 - accuracy: 0.9539 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9547 - precision: 0.9501\n",
            "Epoch 269: val_accuracy improved from 0.96406 to 0.96719, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.1270 - accuracy: 0.9539 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9547 - precision: 0.9501 - val_loss: 0.0965 - val_accuracy: 0.9672 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9654 - val_precision: 0.9684\n",
            "Epoch 270/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1345 - accuracy: 0.9485 - sensitivity_at_specificity: 0.9983 - specificity_at_sensitivity: 0.9976 - recall: 0.9420 - precision: 0.9502\n",
            "Epoch 270: val_accuracy did not improve from 0.96719\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.1345 - accuracy: 0.9485 - sensitivity_at_specificity: 0.9983 - specificity_at_sensitivity: 0.9976 - recall: 0.9420 - precision: 0.9502 - val_loss: 0.2037 - val_accuracy: 0.9273 - val_sensitivity_at_specificity: 0.9969 - val_specificity_at_sensitivity: 0.9953 - val_recall: 0.9733 - val_precision: 0.8906\n",
            "Epoch 271/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.1399 - accuracy: 0.9462 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9991 - recall: 0.9527 - precision: 0.9414\n",
            "Epoch 271: val_accuracy did not improve from 0.96719\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.1398 - accuracy: 0.9460 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9532 - precision: 0.9408 - val_loss: 0.1029 - val_accuracy: 0.9672 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9836 - val_precision: 0.9494\n",
            "Epoch 272/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1332 - accuracy: 0.9484 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9984 - recall: 0.9501 - precision: 0.9486\n",
            "Epoch 272: val_accuracy did not improve from 0.96719\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.1332 - accuracy: 0.9484 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9984 - recall: 0.9501 - precision: 0.9486 - val_loss: 0.1375 - val_accuracy: 0.9523 - val_sensitivity_at_specificity: 0.9968 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9697 - val_precision: 0.9354\n",
            "Epoch 273/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1205 - accuracy: 0.9547 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9976 - recall: 0.9518 - precision: 0.9578\n",
            "Epoch 273: val_accuracy did not improve from 0.96719\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.1205 - accuracy: 0.9547 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9976 - recall: 0.9518 - precision: 0.9578 - val_loss: 0.1692 - val_accuracy: 0.9312 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 0.9984 - val_recall: 0.9772 - val_precision: 0.8980\n",
            "Epoch 274/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1263 - accuracy: 0.9516 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 0.9984 - recall: 0.9522 - precision: 0.9522\n",
            "Epoch 274: val_accuracy did not improve from 0.96719\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.1263 - accuracy: 0.9516 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 0.9984 - recall: 0.9522 - precision: 0.9522 - val_loss: 0.1505 - val_accuracy: 0.9445 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9984 - val_recall: 0.9938 - val_precision: 0.9048\n",
            "Epoch 275/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1240 - accuracy: 0.9535 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9540 - precision: 0.9532\n",
            "Epoch 275: val_accuracy did not improve from 0.96719\n",
            "10/10 [==============================] - 2s 174ms/step - loss: 0.1240 - accuracy: 0.9535 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9540 - precision: 0.9532 - val_loss: 0.1465 - val_accuracy: 0.9438 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.9969 - val_recall: 0.9842 - val_precision: 0.9095\n",
            "Epoch 276/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1088 - accuracy: 0.9555 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9560 - precision: 0.9545\n",
            "Epoch 276: val_accuracy did not improve from 0.96719\n",
            "10/10 [==============================] - 2s 175ms/step - loss: 0.1088 - accuracy: 0.9555 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9560 - precision: 0.9545 - val_loss: 0.1171 - val_accuracy: 0.9578 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9984 - val_recall: 0.9752 - val_precision: 0.9429\n",
            "Epoch 277/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1132 - accuracy: 0.9574 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9537 - precision: 0.9591\n",
            "Epoch 277: val_accuracy did not improve from 0.96719\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.1132 - accuracy: 0.9574 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9537 - precision: 0.9591 - val_loss: 0.1406 - val_accuracy: 0.9422 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9955 - val_recall: 0.9839 - val_precision: 0.9050\n",
            "Epoch 278/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1312 - accuracy: 0.9498 - sensitivity_at_specificity: 0.9975 - specificity_at_sensitivity: 0.9992 - recall: 0.9550 - precision: 0.9448\n",
            "Epoch 278: val_accuracy did not improve from 0.96719\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.1312 - accuracy: 0.9498 - sensitivity_at_specificity: 0.9975 - specificity_at_sensitivity: 0.9992 - recall: 0.9550 - precision: 0.9448 - val_loss: 0.1023 - val_accuracy: 0.9641 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9611 - val_precision: 0.9671\n",
            "Epoch 279/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1174 - accuracy: 0.9547 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9509 - precision: 0.9584\n",
            "Epoch 279: val_accuracy did not improve from 0.96719\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.1174 - accuracy: 0.9547 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9509 - precision: 0.9584 - val_loss: 0.1184 - val_accuracy: 0.9578 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 0.9984 - val_recall: 0.9768 - val_precision: 0.9418\n",
            "Epoch 280/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1116 - accuracy: 0.9598 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9615 - precision: 0.9577\n",
            "Epoch 280: val_accuracy did not improve from 0.96719\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.1116 - accuracy: 0.9598 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9615 - precision: 0.9577 - val_loss: 0.1354 - val_accuracy: 0.9508 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9985 - val_recall: 0.9950 - val_precision: 0.9091\n",
            "Epoch 281/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1344 - accuracy: 0.9410 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9985 - recall: 0.9334 - precision: 0.9448\n",
            "Epoch 281: val_accuracy did not improve from 0.96719\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.1344 - accuracy: 0.9410 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9985 - recall: 0.9334 - precision: 0.9448 - val_loss: 0.1216 - val_accuracy: 0.9523 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9630 - val_precision: 0.9440\n",
            "Epoch 282/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1335 - accuracy: 0.9426 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9448 - precision: 0.9426\n",
            "Epoch 282: val_accuracy did not improve from 0.96719\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.1335 - accuracy: 0.9426 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9448 - precision: 0.9426 - val_loss: 0.1026 - val_accuracy: 0.9664 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9576 - val_precision: 0.9744\n",
            "Epoch 283/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1264 - accuracy: 0.9566 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9561 - precision: 0.9553\n",
            "Epoch 283: val_accuracy did not improve from 0.96719\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.1264 - accuracy: 0.9566 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9561 - precision: 0.9553 - val_loss: 0.1607 - val_accuracy: 0.9352 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 0.9984 - val_recall: 0.9801 - val_precision: 0.9013\n",
            "Epoch 284/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1134 - accuracy: 0.9602 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9655 - precision: 0.9567\n",
            "Epoch 284: val_accuracy did not improve from 0.96719\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.1134 - accuracy: 0.9602 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9655 - precision: 0.9567 - val_loss: 0.1017 - val_accuracy: 0.9633 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9791 - val_precision: 0.9521\n",
            "Epoch 285/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1134 - accuracy: 0.9574 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9558 - precision: 0.9581\n",
            "Epoch 285: val_accuracy did not improve from 0.96719\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.1134 - accuracy: 0.9574 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9558 - precision: 0.9581 - val_loss: 0.1319 - val_accuracy: 0.9555 - val_sensitivity_at_specificity: 0.9968 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9748 - val_precision: 0.9378\n",
            "Epoch 286/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1259 - accuracy: 0.9527 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9559 - precision: 0.9492\n",
            "Epoch 286: val_accuracy did not improve from 0.96719\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.1259 - accuracy: 0.9527 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9559 - precision: 0.9492 - val_loss: 0.1066 - val_accuracy: 0.9578 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9404 - val_precision: 0.9740\n",
            "Epoch 287/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1347 - accuracy: 0.9484 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9960 - recall: 0.9476 - precision: 0.9520\n",
            "Epoch 287: val_accuracy did not improve from 0.96719\n",
            "10/10 [==============================] - 2s 175ms/step - loss: 0.1347 - accuracy: 0.9484 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9960 - recall: 0.9476 - precision: 0.9520 - val_loss: 0.1729 - val_accuracy: 0.9242 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9969 - val_recall: 0.9953 - val_precision: 0.8712\n",
            "Epoch 288/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1326 - accuracy: 0.9488 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9993 - recall: 0.9459 - precision: 0.9467\n",
            "Epoch 288: val_accuracy did not improve from 0.96719\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.1326 - accuracy: 0.9488 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9993 - recall: 0.9459 - precision: 0.9467 - val_loss: 0.1450 - val_accuracy: 0.9398 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9893 - val_precision: 0.9024\n",
            "Epoch 289/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1299 - accuracy: 0.9444 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9983 - recall: 0.9474 - precision: 0.9411\n",
            "Epoch 289: val_accuracy improved from 0.96719 to 0.97031, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.1299 - accuracy: 0.9444 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9983 - recall: 0.9474 - precision: 0.9411 - val_loss: 0.0955 - val_accuracy: 0.9703 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9862 - val_precision: 0.9567\n",
            "Epoch 290/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1100 - accuracy: 0.9613 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 1.0000 - recall: 0.9572 - precision: 0.9668\n",
            "Epoch 290: val_accuracy did not improve from 0.97031\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.1100 - accuracy: 0.9613 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 1.0000 - recall: 0.9572 - precision: 0.9668 - val_loss: 0.1646 - val_accuracy: 0.9344 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 0.9968 - val_recall: 0.9832 - val_precision: 0.8979\n",
            "Epoch 291/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1224 - accuracy: 0.9559 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9608 - precision: 0.9494\n",
            "Epoch 291: val_accuracy improved from 0.97031 to 0.97109, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 176ms/step - loss: 0.1224 - accuracy: 0.9559 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9608 - precision: 0.9494 - val_loss: 0.0861 - val_accuracy: 0.9711 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9535 - val_precision: 0.9867\n",
            "Epoch 292/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1246 - accuracy: 0.9461 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9391 - precision: 0.9512\n",
            "Epoch 292: val_accuracy did not improve from 0.97109\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.1246 - accuracy: 0.9461 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9391 - precision: 0.9512 - val_loss: 0.1017 - val_accuracy: 0.9578 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9826 - val_precision: 0.9353\n",
            "Epoch 293/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1127 - accuracy: 0.9539 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9618 - precision: 0.9470\n",
            "Epoch 293: val_accuracy did not improve from 0.97109\n",
            "10/10 [==============================] - 2s 174ms/step - loss: 0.1127 - accuracy: 0.9539 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9618 - precision: 0.9470 - val_loss: 0.1045 - val_accuracy: 0.9633 - val_sensitivity_at_specificity: 0.9969 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9571 - val_precision: 0.9705\n",
            "Epoch 294/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1095 - accuracy: 0.9598 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9985 - recall: 0.9563 - precision: 0.9602\n",
            "Epoch 294: val_accuracy did not improve from 0.97109\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.1095 - accuracy: 0.9598 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9985 - recall: 0.9563 - precision: 0.9602 - val_loss: 0.0945 - val_accuracy: 0.9648 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9709 - val_precision: 0.9606\n",
            "Epoch 295/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1014 - accuracy: 0.9633 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9614 - precision: 0.9645\n",
            "Epoch 295: val_accuracy did not improve from 0.97109\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.1014 - accuracy: 0.9633 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9614 - precision: 0.9645 - val_loss: 0.1087 - val_accuracy: 0.9625 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.9984 - val_recall: 0.9875 - val_precision: 0.9406\n",
            "Epoch 296/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1139 - accuracy: 0.9566 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9984 - recall: 0.9560 - precision: 0.9582\n",
            "Epoch 296: val_accuracy did not improve from 0.97109\n",
            "10/10 [==============================] - 2s 175ms/step - loss: 0.1139 - accuracy: 0.9566 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9984 - recall: 0.9560 - precision: 0.9582 - val_loss: 0.1379 - val_accuracy: 0.9445 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9844 - val_precision: 0.9116\n",
            "Epoch 297/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1155 - accuracy: 0.9539 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9581 - precision: 0.9507\n",
            "Epoch 297: val_accuracy improved from 0.97109 to 0.97422, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 182ms/step - loss: 0.1155 - accuracy: 0.9539 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9581 - precision: 0.9507 - val_loss: 0.0776 - val_accuracy: 0.9742 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9985 - val_recall: 0.9694 - val_precision: 0.9773\n",
            "Epoch 298/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1069 - accuracy: 0.9570 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9533 - precision: 0.9608\n",
            "Epoch 298: val_accuracy did not improve from 0.97422\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.1069 - accuracy: 0.9570 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9533 - precision: 0.9608 - val_loss: 0.1414 - val_accuracy: 0.9438 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 0.9984 - val_recall: 0.9907 - val_precision: 0.9066\n",
            "Epoch 299/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1213 - accuracy: 0.9555 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9570 - precision: 0.9540\n",
            "Epoch 299: val_accuracy did not improve from 0.97422\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.1213 - accuracy: 0.9555 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9570 - precision: 0.9540 - val_loss: 0.1029 - val_accuracy: 0.9656 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9631 - val_precision: 0.9690\n",
            "Epoch 300/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1243 - accuracy: 0.9492 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 1.0000 - recall: 0.9551 - precision: 0.9448\n",
            "Epoch 300: val_accuracy did not improve from 0.97422\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.1243 - accuracy: 0.9492 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 1.0000 - recall: 0.9551 - precision: 0.9448 - val_loss: 0.1017 - val_accuracy: 0.9648 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9680 - val_precision: 0.9636\n",
            "Epoch 301/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1158 - accuracy: 0.9523 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9985 - recall: 0.9461 - precision: 0.9567\n",
            "Epoch 301: val_accuracy did not improve from 0.97422\n",
            "10/10 [==============================] - 2s 174ms/step - loss: 0.1158 - accuracy: 0.9523 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9985 - recall: 0.9461 - precision: 0.9567 - val_loss: 0.0971 - val_accuracy: 0.9688 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9760 - val_precision: 0.9606\n",
            "Epoch 302/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1237 - accuracy: 0.9520 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9553 - precision: 0.9486\n",
            "Epoch 302: val_accuracy did not improve from 0.97422\n",
            "10/10 [==============================] - 2s 176ms/step - loss: 0.1237 - accuracy: 0.9520 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9553 - precision: 0.9486 - val_loss: 0.1336 - val_accuracy: 0.9484 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9674 - val_precision: 0.9326\n",
            "Epoch 303/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1146 - accuracy: 0.9563 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9587 - precision: 0.9526\n",
            "Epoch 303: val_accuracy did not improve from 0.97422\n",
            "10/10 [==============================] - 2s 218ms/step - loss: 0.1146 - accuracy: 0.9563 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9587 - precision: 0.9526 - val_loss: 0.1145 - val_accuracy: 0.9617 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9969 - val_recall: 0.9841 - val_precision: 0.9405\n",
            "Epoch 304/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1125 - accuracy: 0.9609 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9603 - precision: 0.9618\n",
            "Epoch 304: val_accuracy did not improve from 0.97422\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.1125 - accuracy: 0.9609 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9603 - precision: 0.9618 - val_loss: 0.1039 - val_accuracy: 0.9602 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9659 - val_precision: 0.9555\n",
            "Epoch 305/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1126 - accuracy: 0.9520 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 1.0000 - recall: 0.9535 - precision: 0.9528\n",
            "Epoch 305: val_accuracy did not improve from 0.97422\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.1126 - accuracy: 0.9520 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 1.0000 - recall: 0.9535 - precision: 0.9528 - val_loss: 0.1074 - val_accuracy: 0.9633 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9841 - val_precision: 0.9436\n",
            "Epoch 306/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1268 - accuracy: 0.9469 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 0.9992 - recall: 0.9487 - precision: 0.9487\n",
            "Epoch 306: val_accuracy did not improve from 0.97422\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.1268 - accuracy: 0.9469 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 0.9992 - recall: 0.9487 - precision: 0.9487 - val_loss: 0.1106 - val_accuracy: 0.9586 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9689 - val_precision: 0.9457\n",
            "Epoch 307/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1051 - accuracy: 0.9578 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9572 - precision: 0.9572\n",
            "Epoch 307: val_accuracy did not improve from 0.97422\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.1051 - accuracy: 0.9578 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9572 - precision: 0.9572 - val_loss: 0.1209 - val_accuracy: 0.9516 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 0.9983 - val_recall: 0.9822 - val_precision: 0.9298\n",
            "Epoch 308/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1257 - accuracy: 0.9516 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9464 - precision: 0.9582\n",
            "Epoch 308: val_accuracy did not improve from 0.97422\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.1257 - accuracy: 0.9516 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9464 - precision: 0.9582 - val_loss: 0.1150 - val_accuracy: 0.9625 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.9984 - val_recall: 0.9828 - val_precision: 0.9445\n",
            "Epoch 309/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0993 - accuracy: 0.9629 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9590 - precision: 0.9658\n",
            "Epoch 309: val_accuracy did not improve from 0.97422\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.0993 - accuracy: 0.9629 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9590 - precision: 0.9658 - val_loss: 0.1165 - val_accuracy: 0.9523 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9839 - val_precision: 0.9230\n",
            "Epoch 310/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1230 - accuracy: 0.9566 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 0.9992 - recall: 0.9594 - precision: 0.9558\n",
            "Epoch 310: val_accuracy did not improve from 0.97422\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.1230 - accuracy: 0.9566 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 0.9992 - recall: 0.9594 - precision: 0.9558 - val_loss: 0.1142 - val_accuracy: 0.9633 - val_sensitivity_at_specificity: 0.9968 - val_specificity_at_sensitivity: 0.9985 - val_recall: 0.9601 - val_precision: 0.9647\n",
            "Epoch 311/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1147 - accuracy: 0.9547 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9596 - precision: 0.9509\n",
            "Epoch 311: val_accuracy did not improve from 0.97422\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.1147 - accuracy: 0.9547 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9596 - precision: 0.9509 - val_loss: 0.1274 - val_accuracy: 0.9594 - val_sensitivity_at_specificity: 0.9971 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9883 - val_precision: 0.9391\n",
            "Epoch 312/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0954 - accuracy: 0.9637 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9653 - precision: 0.9631\n",
            "Epoch 312: val_accuracy did not improve from 0.97422\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.0954 - accuracy: 0.9637 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9653 - precision: 0.9631 - val_loss: 0.0798 - val_accuracy: 0.9711 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9751 - val_precision: 0.9675\n",
            "Epoch 313/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0923 - accuracy: 0.9648 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9622 - precision: 0.9654\n",
            "Epoch 313: val_accuracy did not improve from 0.97422\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.0923 - accuracy: 0.9648 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9622 - precision: 0.9654 - val_loss: 0.1031 - val_accuracy: 0.9664 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9686 - val_precision: 0.9641\n",
            "Epoch 314/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1139 - accuracy: 0.9551 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9984 - recall: 0.9602 - precision: 0.9506\n",
            "Epoch 314: val_accuracy did not improve from 0.97422\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.1139 - accuracy: 0.9551 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9984 - recall: 0.9602 - precision: 0.9506 - val_loss: 0.1091 - val_accuracy: 0.9648 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9829 - val_precision: 0.9491\n",
            "Epoch 315/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0942 - accuracy: 0.9656 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9664 - precision: 0.9664\n",
            "Epoch 315: val_accuracy did not improve from 0.97422\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.0942 - accuracy: 0.9656 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9664 - precision: 0.9664 - val_loss: 0.1226 - val_accuracy: 0.9609 - val_sensitivity_at_specificity: 0.9969 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9449 - val_precision: 0.9778\n",
            "Epoch 316/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1101 - accuracy: 0.9578 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9505 - precision: 0.9642\n",
            "Epoch 316: val_accuracy did not improve from 0.97422\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.1101 - accuracy: 0.9578 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9505 - precision: 0.9642 - val_loss: 0.1032 - val_accuracy: 0.9648 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9800 - val_precision: 0.9522\n",
            "Epoch 317/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1053 - accuracy: 0.9590 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9622 - precision: 0.9554\n",
            "Epoch 317: val_accuracy did not improve from 0.97422\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.1053 - accuracy: 0.9590 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9622 - precision: 0.9554 - val_loss: 0.0933 - val_accuracy: 0.9641 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9614 - val_precision: 0.9673\n",
            "Epoch 318/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1194 - accuracy: 0.9566 - sensitivity_at_specificity: 0.9977 - specificity_at_sensitivity: 0.9992 - recall: 0.9548 - precision: 0.9600\n",
            "Epoch 318: val_accuracy did not improve from 0.97422\n",
            "10/10 [==============================] - 2s 174ms/step - loss: 0.1194 - accuracy: 0.9566 - sensitivity_at_specificity: 0.9977 - specificity_at_sensitivity: 0.9992 - recall: 0.9548 - precision: 0.9600 - val_loss: 0.1197 - val_accuracy: 0.9594 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9787 - val_precision: 0.9442\n",
            "Epoch 319/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1003 - accuracy: 0.9668 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9645 - precision: 0.9684\n",
            "Epoch 319: val_accuracy did not improve from 0.97422\n",
            "10/10 [==============================] - 2s 175ms/step - loss: 0.1003 - accuracy: 0.9668 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9645 - precision: 0.9684 - val_loss: 0.1081 - val_accuracy: 0.9563 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9662 - val_precision: 0.9487\n",
            "Epoch 320/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1009 - accuracy: 0.9645 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 0.9976 - recall: 0.9653 - precision: 0.9646\n",
            "Epoch 320: val_accuracy did not improve from 0.97422\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.1009 - accuracy: 0.9645 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 0.9976 - recall: 0.9653 - precision: 0.9646 - val_loss: 0.1122 - val_accuracy: 0.9555 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9735 - val_precision: 0.9398\n",
            "Epoch 321/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1053 - accuracy: 0.9617 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9638 - precision: 0.9609\n",
            "Epoch 321: val_accuracy did not improve from 0.97422\n",
            "10/10 [==============================] - 2s 178ms/step - loss: 0.1053 - accuracy: 0.9617 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9638 - precision: 0.9609 - val_loss: 0.1182 - val_accuracy: 0.9602 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.9984 - val_recall: 0.9560 - val_precision: 0.9635\n",
            "Epoch 322/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1041 - accuracy: 0.9551 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9433 - precision: 0.9659\n",
            "Epoch 322: val_accuracy did not improve from 0.97422\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.1041 - accuracy: 0.9551 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9433 - precision: 0.9659 - val_loss: 0.1039 - val_accuracy: 0.9641 - val_sensitivity_at_specificity: 0.9969 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9781 - val_precision: 0.9513\n",
            "Epoch 323/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0993 - accuracy: 0.9590 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9651 - precision: 0.9522\n",
            "Epoch 323: val_accuracy did not improve from 0.97422\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.0993 - accuracy: 0.9590 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9651 - precision: 0.9522 - val_loss: 0.0722 - val_accuracy: 0.9742 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9615 - val_precision: 0.9852\n",
            "Epoch 324/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1143 - accuracy: 0.9531 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9566 - precision: 0.9522\n",
            "Epoch 324: val_accuracy did not improve from 0.97422\n",
            "10/10 [==============================] - 2s 174ms/step - loss: 0.1143 - accuracy: 0.9531 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9566 - precision: 0.9522 - val_loss: 0.1035 - val_accuracy: 0.9617 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9580 - val_precision: 0.9655\n",
            "Epoch 325/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0946 - accuracy: 0.9664 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9675 - precision: 0.9660\n",
            "Epoch 325: val_accuracy did not improve from 0.97422\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.0946 - accuracy: 0.9664 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9675 - precision: 0.9660 - val_loss: 0.1335 - val_accuracy: 0.9500 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9760 - val_precision: 0.9256\n",
            "Epoch 326/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1159 - accuracy: 0.9539 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9508 - precision: 0.9568\n",
            "Epoch 326: val_accuracy improved from 0.97422 to 0.97578, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 179ms/step - loss: 0.1159 - accuracy: 0.9539 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9508 - precision: 0.9568 - val_loss: 0.0774 - val_accuracy: 0.9758 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9598 - val_precision: 0.9920\n",
            "Epoch 327/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1094 - accuracy: 0.9563 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9533 - precision: 0.9578\n",
            "Epoch 327: val_accuracy did not improve from 0.97578\n",
            "10/10 [==============================] - 2s 174ms/step - loss: 0.1094 - accuracy: 0.9563 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9533 - precision: 0.9578 - val_loss: 0.0980 - val_accuracy: 0.9648 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9984 - val_recall: 0.9875 - val_precision: 0.9449\n",
            "Epoch 328/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0968 - accuracy: 0.9605 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9571 - precision: 0.9625\n",
            "Epoch 328: val_accuracy did not improve from 0.97578\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.0968 - accuracy: 0.9605 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9571 - precision: 0.9625 - val_loss: 0.1091 - val_accuracy: 0.9578 - val_sensitivity_at_specificity: 0.9952 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9681 - val_precision: 0.9469\n",
            "Epoch 329/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1038 - accuracy: 0.9594 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9596 - precision: 0.9611\n",
            "Epoch 329: val_accuracy did not improve from 0.97578\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.1038 - accuracy: 0.9594 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9596 - precision: 0.9611 - val_loss: 0.0895 - val_accuracy: 0.9719 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9639 - val_precision: 0.9793\n",
            "Epoch 330/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1003 - accuracy: 0.9602 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9588 - precision: 0.9646\n",
            "Epoch 330: val_accuracy did not improve from 0.97578\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.1003 - accuracy: 0.9602 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9588 - precision: 0.9646 - val_loss: 0.1607 - val_accuracy: 0.9289 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.9985 - val_recall: 0.9837 - val_precision: 0.8819\n",
            "Epoch 331/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1113 - accuracy: 0.9566 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9586 - precision: 0.9564\n",
            "Epoch 331: val_accuracy did not improve from 0.97578\n",
            "10/10 [==============================] - 2s 174ms/step - loss: 0.1113 - accuracy: 0.9566 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9586 - precision: 0.9564 - val_loss: 0.0974 - val_accuracy: 0.9656 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9534 - val_precision: 0.9777\n",
            "Epoch 332/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0993 - accuracy: 0.9590 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9569 - precision: 0.9607\n",
            "Epoch 332: val_accuracy did not improve from 0.97578\n",
            "10/10 [==============================] - 2s 177ms/step - loss: 0.0993 - accuracy: 0.9590 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9569 - precision: 0.9607 - val_loss: 0.0964 - val_accuracy: 0.9656 - val_sensitivity_at_specificity: 0.9969 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9734 - val_precision: 0.9584\n",
            "Epoch 333/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1024 - accuracy: 0.9633 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9599 - precision: 0.9660\n",
            "Epoch 333: val_accuracy did not improve from 0.97578\n",
            "10/10 [==============================] - 2s 175ms/step - loss: 0.1024 - accuracy: 0.9633 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9599 - precision: 0.9660 - val_loss: 0.0909 - val_accuracy: 0.9641 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9984 - val_recall: 0.9771 - val_precision: 0.9539\n",
            "Epoch 334/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0957 - accuracy: 0.9641 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9634 - precision: 0.9634\n",
            "Epoch 334: val_accuracy did not improve from 0.97578\n",
            "10/10 [==============================] - 2s 179ms/step - loss: 0.0957 - accuracy: 0.9641 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9634 - precision: 0.9634 - val_loss: 0.0833 - val_accuracy: 0.9742 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9830 - val_precision: 0.9666\n",
            "Epoch 335/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1109 - accuracy: 0.9566 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9563 - precision: 0.9556\n",
            "Epoch 335: val_accuracy did not improve from 0.97578\n",
            "10/10 [==============================] - 2s 174ms/step - loss: 0.1109 - accuracy: 0.9566 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9563 - precision: 0.9556 - val_loss: 0.0834 - val_accuracy: 0.9750 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9768 - val_precision: 0.9738\n",
            "Epoch 336/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0964 - accuracy: 0.9609 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9573 - precision: 0.9619\n",
            "Epoch 336: val_accuracy did not improve from 0.97578\n",
            "10/10 [==============================] - 2s 176ms/step - loss: 0.0964 - accuracy: 0.9609 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9573 - precision: 0.9619 - val_loss: 0.0866 - val_accuracy: 0.9719 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 0.9984 - val_recall: 0.9851 - val_precision: 0.9622\n",
            "Epoch 337/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1000 - accuracy: 0.9617 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9668 - precision: 0.9596\n",
            "Epoch 337: val_accuracy did not improve from 0.97578\n",
            "10/10 [==============================] - 2s 177ms/step - loss: 0.1000 - accuracy: 0.9617 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9668 - precision: 0.9596 - val_loss: 0.0856 - val_accuracy: 0.9727 - val_sensitivity_at_specificity: 0.9968 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9824 - val_precision: 0.9623\n",
            "Epoch 338/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0907 - accuracy: 0.9641 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9609 - precision: 0.9655\n",
            "Epoch 338: val_accuracy did not improve from 0.97578\n",
            "10/10 [==============================] - 2s 177ms/step - loss: 0.0907 - accuracy: 0.9641 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9609 - precision: 0.9655 - val_loss: 0.0945 - val_accuracy: 0.9664 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9920 - val_precision: 0.9420\n",
            "Epoch 339/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0887 - accuracy: 0.9695 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9698 - precision: 0.9698\n",
            "Epoch 339: val_accuracy did not improve from 0.97578\n",
            "10/10 [==============================] - 2s 174ms/step - loss: 0.0887 - accuracy: 0.9695 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9698 - precision: 0.9698 - val_loss: 0.1199 - val_accuracy: 0.9500 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9985 - val_recall: 0.9873 - val_precision: 0.9172\n",
            "Epoch 340/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0880 - accuracy: 0.9637 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9659 - precision: 0.9622\n",
            "Epoch 340: val_accuracy did not improve from 0.97578\n",
            "10/10 [==============================] - 2s 174ms/step - loss: 0.0880 - accuracy: 0.9637 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9659 - precision: 0.9622 - val_loss: 0.0825 - val_accuracy: 0.9719 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 0.9984 - val_recall: 0.9707 - val_precision: 0.9737\n",
            "Epoch 341/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0847 - accuracy: 0.9668 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9664 - precision: 0.9671\n",
            "Epoch 341: val_accuracy did not improve from 0.97578\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.0847 - accuracy: 0.9668 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9664 - precision: 0.9671 - val_loss: 0.1472 - val_accuracy: 0.9367 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9984 - val_recall: 0.9780 - val_precision: 0.9026\n",
            "Epoch 342/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1008 - accuracy: 0.9586 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9563 - precision: 0.9636\n",
            "Epoch 342: val_accuracy improved from 0.97578 to 0.97656, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.1008 - accuracy: 0.9586 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9563 - precision: 0.9636 - val_loss: 0.0876 - val_accuracy: 0.9766 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9873 - val_precision: 0.9658\n",
            "Epoch 343/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0888 - accuracy: 0.9656 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9656 - precision: 0.9685\n",
            "Epoch 343: val_accuracy did not improve from 0.97656\n",
            "10/10 [==============================] - 2s 174ms/step - loss: 0.0888 - accuracy: 0.9656 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9656 - precision: 0.9685 - val_loss: 0.0952 - val_accuracy: 0.9664 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9792 - val_precision: 0.9533\n",
            "Epoch 344/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0971 - accuracy: 0.9613 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9600 - precision: 0.9623\n",
            "Epoch 344: val_accuracy did not improve from 0.97656\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.0971 - accuracy: 0.9613 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9600 - precision: 0.9623 - val_loss: 0.0853 - val_accuracy: 0.9648 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9751 - val_precision: 0.9557\n",
            "Epoch 345/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0986 - accuracy: 0.9602 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9557 - precision: 0.9647\n",
            "Epoch 345: val_accuracy did not improve from 0.97656\n",
            "10/10 [==============================] - 2s 177ms/step - loss: 0.0986 - accuracy: 0.9602 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9557 - precision: 0.9647 - val_loss: 0.1226 - val_accuracy: 0.9523 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.9984 - val_recall: 0.9719 - val_precision: 0.9353\n",
            "Epoch 346/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1098 - accuracy: 0.9598 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9658 - precision: 0.9563\n",
            "Epoch 346: val_accuracy did not improve from 0.97656\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.1098 - accuracy: 0.9598 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9658 - precision: 0.9563 - val_loss: 0.0896 - val_accuracy: 0.9680 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9805 - val_precision: 0.9542\n",
            "Epoch 347/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0860 - accuracy: 0.9637 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9557 - precision: 0.9716\n",
            "Epoch 347: val_accuracy did not improve from 0.97656\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.0860 - accuracy: 0.9637 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9557 - precision: 0.9716 - val_loss: 0.1007 - val_accuracy: 0.9633 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9470 - val_precision: 0.9768\n",
            "Epoch 348/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0913 - accuracy: 0.9633 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9626 - precision: 0.9610\n",
            "Epoch 348: val_accuracy did not improve from 0.97656\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.0913 - accuracy: 0.9633 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9626 - precision: 0.9610 - val_loss: 0.0762 - val_accuracy: 0.9750 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9812 - val_precision: 0.9690\n",
            "Epoch 349/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1013 - accuracy: 0.9609 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9549 - precision: 0.9656\n",
            "Epoch 349: val_accuracy did not improve from 0.97656\n",
            "10/10 [==============================] - 2s 175ms/step - loss: 0.1013 - accuracy: 0.9609 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9549 - precision: 0.9656 - val_loss: 0.0739 - val_accuracy: 0.9711 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9740 - val_precision: 0.9696\n",
            "Epoch 350/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1037 - accuracy: 0.9602 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9588 - precision: 0.9588\n",
            "Epoch 350: val_accuracy did not improve from 0.97656\n",
            "10/10 [==============================] - 2s 178ms/step - loss: 0.1037 - accuracy: 0.9602 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9588 - precision: 0.9588 - val_loss: 0.0995 - val_accuracy: 0.9703 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9584 - val_precision: 0.9826\n",
            "Epoch 351/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0974 - accuracy: 0.9586 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9561 - precision: 0.9606\n",
            "Epoch 351: val_accuracy did not improve from 0.97656\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.0974 - accuracy: 0.9586 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9561 - precision: 0.9606 - val_loss: 0.1244 - val_accuracy: 0.9586 - val_sensitivity_at_specificity: 0.9953 - val_specificity_at_sensitivity: 0.9984 - val_recall: 0.9736 - val_precision: 0.9457\n",
            "Epoch 352/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1187 - accuracy: 0.9516 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9485 - precision: 0.9559\n",
            "Epoch 352: val_accuracy did not improve from 0.97656\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.1187 - accuracy: 0.9516 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9485 - precision: 0.9559 - val_loss: 0.0913 - val_accuracy: 0.9719 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9903 - val_precision: 0.9533\n",
            "Epoch 353/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0987 - accuracy: 0.9637 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9711 - precision: 0.9587\n",
            "Epoch 353: val_accuracy did not improve from 0.97656\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.0987 - accuracy: 0.9637 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9711 - precision: 0.9587 - val_loss: 0.0927 - val_accuracy: 0.9742 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9787 - val_precision: 0.9713\n",
            "Epoch 354/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0949 - accuracy: 0.9633 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9639 - precision: 0.9624\n",
            "Epoch 354: val_accuracy did not improve from 0.97656\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.0949 - accuracy: 0.9633 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9639 - precision: 0.9624 - val_loss: 0.0859 - val_accuracy: 0.9719 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9674 - val_precision: 0.9765\n",
            "Epoch 355/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1176 - accuracy: 0.9547 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9992 - recall: 0.9518 - precision: 0.9563\n",
            "Epoch 355: val_accuracy did not improve from 0.97656\n",
            "10/10 [==============================] - 2s 187ms/step - loss: 0.1176 - accuracy: 0.9547 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9992 - recall: 0.9518 - precision: 0.9563 - val_loss: 0.0865 - val_accuracy: 0.9703 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9615 - val_precision: 0.9796\n",
            "Epoch 356/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0893 - accuracy: 0.9645 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9584 - precision: 0.9711\n",
            "Epoch 356: val_accuracy did not improve from 0.97656\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.0893 - accuracy: 0.9645 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9584 - precision: 0.9711 - val_loss: 0.0923 - val_accuracy: 0.9703 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9794 - val_precision: 0.9611\n",
            "Epoch 357/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0861 - accuracy: 0.9648 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9620 - precision: 0.9666\n",
            "Epoch 357: val_accuracy did not improve from 0.97656\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.0861 - accuracy: 0.9648 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9620 - precision: 0.9666 - val_loss: 0.0782 - val_accuracy: 0.9742 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9850 - val_precision: 0.9662\n",
            "Epoch 358/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0844 - accuracy: 0.9688 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9984 - recall: 0.9661 - precision: 0.9735\n",
            "Epoch 358: val_accuracy did not improve from 0.97656\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.0844 - accuracy: 0.9688 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9984 - recall: 0.9661 - precision: 0.9735 - val_loss: 0.0940 - val_accuracy: 0.9656 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9833 - val_precision: 0.9453\n",
            "Epoch 359/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0897 - accuracy: 0.9641 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9660 - precision: 0.9614\n",
            "Epoch 359: val_accuracy did not improve from 0.97656\n",
            "10/10 [==============================] - 2s 176ms/step - loss: 0.0897 - accuracy: 0.9641 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9660 - precision: 0.9614 - val_loss: 0.0866 - val_accuracy: 0.9719 - val_sensitivity_at_specificity: 0.9983 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9683 - val_precision: 0.9716\n",
            "Epoch 360/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0892 - accuracy: 0.9664 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9643 - precision: 0.9674\n",
            "Epoch 360: val_accuracy did not improve from 0.97656\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.0892 - accuracy: 0.9664 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9643 - precision: 0.9674 - val_loss: 0.0981 - val_accuracy: 0.9563 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9362 - val_precision: 0.9735\n",
            "Epoch 361/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0825 - accuracy: 0.9699 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9702 - precision: 0.9694\n",
            "Epoch 361: val_accuracy did not improve from 0.97656\n",
            "10/10 [==============================] - 2s 219ms/step - loss: 0.0825 - accuracy: 0.9699 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9702 - precision: 0.9694 - val_loss: 0.0811 - val_accuracy: 0.9695 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9859 - val_precision: 0.9545\n",
            "Epoch 362/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0906 - accuracy: 0.9660 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9668 - precision: 0.9675\n",
            "Epoch 362: val_accuracy did not improve from 0.97656\n",
            "10/10 [==============================] - 2s 194ms/step - loss: 0.0906 - accuracy: 0.9660 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9668 - precision: 0.9675 - val_loss: 0.1124 - val_accuracy: 0.9531 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9985 - val_recall: 0.9836 - val_precision: 0.9231\n",
            "Epoch 363/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1058 - accuracy: 0.9645 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9976 - recall: 0.9619 - precision: 0.9671\n",
            "Epoch 363: val_accuracy did not improve from 0.97656\n",
            "10/10 [==============================] - 2s 183ms/step - loss: 0.1058 - accuracy: 0.9645 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9976 - recall: 0.9619 - precision: 0.9671 - val_loss: 0.0763 - val_accuracy: 0.9766 - val_sensitivity_at_specificity: 0.9969 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9675 - val_precision: 0.9858\n",
            "Epoch 364/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0989 - accuracy: 0.9609 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9602 - precision: 0.9617\n",
            "Epoch 364: val_accuracy did not improve from 0.97656\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.0989 - accuracy: 0.9609 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9602 - precision: 0.9617 - val_loss: 0.0829 - val_accuracy: 0.9727 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9717 - val_precision: 0.9732\n",
            "Epoch 365/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0901 - accuracy: 0.9641 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9675 - precision: 0.9599\n",
            "Epoch 365: val_accuracy did not improve from 0.97656\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.0901 - accuracy: 0.9641 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9675 - precision: 0.9599 - val_loss: 0.1106 - val_accuracy: 0.9609 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9804 - val_precision: 0.9461\n",
            "Epoch 366/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1106 - accuracy: 0.9508 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9445 - precision: 0.9551\n",
            "Epoch 366: val_accuracy did not improve from 0.97656\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.1106 - accuracy: 0.9508 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9445 - precision: 0.9551 - val_loss: 0.1051 - val_accuracy: 0.9578 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9723 - val_precision: 0.9461\n",
            "Epoch 367/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1107 - accuracy: 0.9566 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9541 - precision: 0.9564\n",
            "Epoch 367: val_accuracy improved from 0.97656 to 0.98125, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 179ms/step - loss: 0.1107 - accuracy: 0.9566 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9541 - precision: 0.9564 - val_loss: 0.0580 - val_accuracy: 0.9812 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9817 - val_precision: 0.9817\n",
            "Epoch 368/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0843 - accuracy: 0.9703 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9690 - precision: 0.9720\n",
            "Epoch 368: val_accuracy did not improve from 0.98125\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.0843 - accuracy: 0.9703 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9690 - precision: 0.9720 - val_loss: 0.0771 - val_accuracy: 0.9742 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 0.9984 - val_recall: 0.9846 - val_precision: 0.9654\n",
            "Epoch 369/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0945 - accuracy: 0.9625 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9635 - precision: 0.9620\n",
            "Epoch 369: val_accuracy did not improve from 0.98125\n",
            "10/10 [==============================] - 2s 175ms/step - loss: 0.0945 - accuracy: 0.9625 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9635 - precision: 0.9620 - val_loss: 0.0795 - val_accuracy: 0.9750 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9720 - val_precision: 0.9781\n",
            "Epoch 370/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0861 - accuracy: 0.9648 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9602 - precision: 0.9679\n",
            "Epoch 370: val_accuracy did not improve from 0.98125\n",
            "10/10 [==============================] - 2s 174ms/step - loss: 0.0861 - accuracy: 0.9648 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9602 - precision: 0.9679 - val_loss: 0.1064 - val_accuracy: 0.9578 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9792 - val_precision: 0.9371\n",
            "Epoch 371/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0832 - accuracy: 0.9695 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9741 - precision: 0.9650\n",
            "Epoch 371: val_accuracy did not improve from 0.98125\n",
            "10/10 [==============================] - 2s 190ms/step - loss: 0.0832 - accuracy: 0.9695 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9741 - precision: 0.9650 - val_loss: 0.0723 - val_accuracy: 0.9766 - val_sensitivity_at_specificity: 0.9969 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9720 - val_precision: 0.9812\n",
            "Epoch 372/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0789 - accuracy: 0.9730 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9710 - precision: 0.9748\n",
            "Epoch 372: val_accuracy did not improve from 0.98125\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.0789 - accuracy: 0.9730 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9710 - precision: 0.9748 - val_loss: 0.0854 - val_accuracy: 0.9773 - val_sensitivity_at_specificity: 0.9953 - val_specificity_at_sensitivity: 0.9984 - val_recall: 0.9748 - val_precision: 0.9795\n",
            "Epoch 373/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1141 - accuracy: 0.9566 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9492 - precision: 0.9622\n",
            "Epoch 373: val_accuracy did not improve from 0.98125\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.1141 - accuracy: 0.9566 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9492 - precision: 0.9622 - val_loss: 0.0912 - val_accuracy: 0.9664 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9483 - val_precision: 0.9837\n",
            "Epoch 374/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0926 - accuracy: 0.9641 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9620 - precision: 0.9665\n",
            "Epoch 374: val_accuracy did not improve from 0.98125\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.0926 - accuracy: 0.9641 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9620 - precision: 0.9665 - val_loss: 0.0696 - val_accuracy: 0.9797 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 0.9984 - val_recall: 0.9815 - val_precision: 0.9784\n",
            "Epoch 375/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1004 - accuracy: 0.9641 - sensitivity_at_specificity: 0.9976 - specificity_at_sensitivity: 0.9992 - recall: 0.9576 - precision: 0.9698\n",
            "Epoch 375: val_accuracy did not improve from 0.98125\n",
            "10/10 [==============================] - 2s 175ms/step - loss: 0.1004 - accuracy: 0.9641 - sensitivity_at_specificity: 0.9976 - specificity_at_sensitivity: 0.9992 - recall: 0.9576 - precision: 0.9698 - val_loss: 0.0753 - val_accuracy: 0.9734 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9760 - val_precision: 0.9731\n",
            "Epoch 376/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0897 - accuracy: 0.9648 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9601 - precision: 0.9678\n",
            "Epoch 376: val_accuracy did not improve from 0.98125\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.0897 - accuracy: 0.9648 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9601 - precision: 0.9678 - val_loss: 0.1013 - val_accuracy: 0.9602 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9985 - val_recall: 0.9663 - val_precision: 0.9526\n",
            "Epoch 377/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1115 - accuracy: 0.9581 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9588 - precision: 0.9563\n",
            "Epoch 377: val_accuracy did not improve from 0.98125\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.1115 - accuracy: 0.9581 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9588 - precision: 0.9563 - val_loss: 0.0987 - val_accuracy: 0.9672 - val_sensitivity_at_specificity: 0.9968 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9650 - val_precision: 0.9681\n",
            "Epoch 378/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1002 - accuracy: 0.9645 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9604 - precision: 0.9687\n",
            "Epoch 378: val_accuracy did not improve from 0.98125\n",
            "10/10 [==============================] - 2s 176ms/step - loss: 0.1002 - accuracy: 0.9645 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9604 - precision: 0.9687 - val_loss: 0.0931 - val_accuracy: 0.9703 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9855 - val_precision: 0.9546\n",
            "Epoch 379/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0919 - accuracy: 0.9625 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9607 - precision: 0.9622\n",
            "Epoch 379: val_accuracy did not improve from 0.98125\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.0919 - accuracy: 0.9625 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9607 - precision: 0.9622 - val_loss: 0.0638 - val_accuracy: 0.9758 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9671 - val_precision: 0.9841\n",
            "Epoch 380/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0859 - accuracy: 0.9652 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9647 - precision: 0.9655\n",
            "Epoch 380: val_accuracy did not improve from 0.98125\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.0859 - accuracy: 0.9652 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9647 - precision: 0.9655 - val_loss: 0.0696 - val_accuracy: 0.9766 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9704 - val_precision: 0.9826\n",
            "Epoch 381/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0879 - accuracy: 0.9660 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9646 - precision: 0.9654\n",
            "Epoch 381: val_accuracy did not improve from 0.98125\n",
            "10/10 [==============================] - 2s 174ms/step - loss: 0.0879 - accuracy: 0.9660 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9646 - precision: 0.9654 - val_loss: 0.0690 - val_accuracy: 0.9773 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9819 - val_precision: 0.9746\n",
            "Epoch 382/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1090 - accuracy: 0.9585 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9983 - recall: 0.9573 - precision: 0.9604\n",
            "Epoch 382: val_accuracy did not improve from 0.98125\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.1090 - accuracy: 0.9585 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9983 - recall: 0.9573 - precision: 0.9604 - val_loss: 0.0848 - val_accuracy: 0.9664 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9388 - val_precision: 0.9934\n",
            "Epoch 383/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1179 - accuracy: 0.9613 - sensitivity_at_specificity: 0.9977 - specificity_at_sensitivity: 1.0000 - recall: 0.9555 - precision: 0.9668\n",
            "Epoch 383: val_accuracy did not improve from 0.98125\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.1179 - accuracy: 0.9613 - sensitivity_at_specificity: 0.9977 - specificity_at_sensitivity: 1.0000 - recall: 0.9555 - precision: 0.9668 - val_loss: 0.0985 - val_accuracy: 0.9633 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9984 - val_recall: 0.9692 - val_precision: 0.9589\n",
            "Epoch 384/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0924 - accuracy: 0.9672 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9695 - precision: 0.9649\n",
            "Epoch 384: val_accuracy did not improve from 0.98125\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.0924 - accuracy: 0.9672 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9695 - precision: 0.9649 - val_loss: 0.0946 - val_accuracy: 0.9594 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9766 - val_precision: 0.9443\n",
            "Epoch 385/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0981 - accuracy: 0.9633 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9650 - precision: 0.9635\n",
            "Epoch 385: val_accuracy did not improve from 0.98125\n",
            "10/10 [==============================] - 2s 176ms/step - loss: 0.0981 - accuracy: 0.9633 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9650 - precision: 0.9635 - val_loss: 0.0852 - val_accuracy: 0.9664 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9892 - val_precision: 0.9471\n",
            "Epoch 386/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0869 - accuracy: 0.9707 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9679 - precision: 0.9732\n",
            "Epoch 386: val_accuracy did not improve from 0.98125\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.0869 - accuracy: 0.9707 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9679 - precision: 0.9732 - val_loss: 0.0942 - val_accuracy: 0.9711 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9704 - val_precision: 0.9719\n",
            "Epoch 387/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0838 - accuracy: 0.9688 - sensitivity_at_specificity: 0.9977 - specificity_at_sensitivity: 1.0000 - recall: 0.9699 - precision: 0.9684\n",
            "Epoch 387: val_accuracy did not improve from 0.98125\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.0838 - accuracy: 0.9688 - sensitivity_at_specificity: 0.9977 - specificity_at_sensitivity: 1.0000 - recall: 0.9699 - precision: 0.9684 - val_loss: 0.0864 - val_accuracy: 0.9750 - val_sensitivity_at_specificity: 0.9969 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9578 - val_precision: 0.9919\n",
            "Epoch 388/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1036 - accuracy: 0.9590 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9536 - precision: 0.9620\n",
            "Epoch 388: val_accuracy did not improve from 0.98125\n",
            "10/10 [==============================] - 2s 174ms/step - loss: 0.1036 - accuracy: 0.9590 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9536 - precision: 0.9620 - val_loss: 0.0873 - val_accuracy: 0.9703 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9571 - val_precision: 0.9842\n",
            "Epoch 389/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0933 - accuracy: 0.9621 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9578 - precision: 0.9688\n",
            "Epoch 389: val_accuracy improved from 0.98125 to 0.98281, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 182ms/step - loss: 0.0933 - accuracy: 0.9621 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9578 - precision: 0.9688 - val_loss: 0.0635 - val_accuracy: 0.9828 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9841 - val_precision: 0.9809\n",
            "Epoch 390/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0873 - accuracy: 0.9668 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9671 - precision: 0.9648\n",
            "Epoch 390: val_accuracy did not improve from 0.98281\n",
            "10/10 [==============================] - 2s 174ms/step - loss: 0.0873 - accuracy: 0.9668 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9671 - precision: 0.9648 - val_loss: 0.0702 - val_accuracy: 0.9766 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9745 - val_precision: 0.9776\n",
            "Epoch 391/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0780 - accuracy: 0.9738 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9743 - precision: 0.9750\n",
            "Epoch 391: val_accuracy did not improve from 0.98281\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.0780 - accuracy: 0.9738 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9743 - precision: 0.9750 - val_loss: 0.0840 - val_accuracy: 0.9742 - val_sensitivity_at_specificity: 0.9969 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9770 - val_precision: 0.9725\n",
            "Epoch 392/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0836 - accuracy: 0.9664 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9629 - precision: 0.9690\n",
            "Epoch 392: val_accuracy did not improve from 0.98281\n",
            "10/10 [==============================] - 2s 189ms/step - loss: 0.0836 - accuracy: 0.9664 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9629 - precision: 0.9690 - val_loss: 0.0597 - val_accuracy: 0.9766 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9809 - val_precision: 0.9716\n",
            "Epoch 393/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0701 - accuracy: 0.9751 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9983 - recall: 0.9722 - precision: 0.9786\n",
            "Epoch 393: val_accuracy did not improve from 0.98281\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.0701 - accuracy: 0.9751 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9983 - recall: 0.9722 - precision: 0.9786 - val_loss: 0.0764 - val_accuracy: 0.9703 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9739 - val_precision: 0.9679\n",
            "Epoch 394/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0911 - accuracy: 0.9703 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9976 - recall: 0.9698 - precision: 0.9713\n",
            "Epoch 394: val_accuracy did not improve from 0.98281\n",
            "10/10 [==============================] - 2s 175ms/step - loss: 0.0911 - accuracy: 0.9703 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9976 - recall: 0.9698 - precision: 0.9713 - val_loss: 0.1020 - val_accuracy: 0.9688 - val_sensitivity_at_specificity: 0.9954 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9429 - val_precision: 0.9951\n",
            "Epoch 395/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0899 - accuracy: 0.9625 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9615 - precision: 0.9658\n",
            "Epoch 395: val_accuracy did not improve from 0.98281\n",
            "10/10 [==============================] - 2s 174ms/step - loss: 0.0899 - accuracy: 0.9625 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9615 - precision: 0.9658 - val_loss: 0.0777 - val_accuracy: 0.9719 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9700 - val_precision: 0.9731\n",
            "Epoch 396/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0900 - accuracy: 0.9660 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9589 - precision: 0.9720\n",
            "Epoch 396: val_accuracy improved from 0.98281 to 0.98516, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 180ms/step - loss: 0.0900 - accuracy: 0.9660 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9589 - precision: 0.9720 - val_loss: 0.0589 - val_accuracy: 0.9852 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9842 - val_precision: 0.9858\n",
            "Epoch 397/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0880 - accuracy: 0.9609 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9638 - precision: 0.9609\n",
            "Epoch 397: val_accuracy did not improve from 0.98516\n",
            "10/10 [==============================] - 2s 191ms/step - loss: 0.0880 - accuracy: 0.9609 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9638 - precision: 0.9609 - val_loss: 0.1117 - val_accuracy: 0.9633 - val_sensitivity_at_specificity: 0.9940 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9384 - val_precision: 0.9905\n",
            "Epoch 398/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0756 - accuracy: 0.9727 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9683 - precision: 0.9786\n",
            "Epoch 398: val_accuracy did not improve from 0.98516\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.0756 - accuracy: 0.9727 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9683 - precision: 0.9786 - val_loss: 0.0751 - val_accuracy: 0.9773 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9985 - val_recall: 0.9745 - val_precision: 0.9792\n",
            "Epoch 399/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0761 - accuracy: 0.9750 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9737 - precision: 0.9767\n",
            "Epoch 399: val_accuracy did not improve from 0.98516\n",
            "10/10 [==============================] - 2s 177ms/step - loss: 0.0761 - accuracy: 0.9750 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9737 - precision: 0.9767 - val_loss: 0.0802 - val_accuracy: 0.9695 - val_sensitivity_at_specificity: 0.9970 - val_specificity_at_sensitivity: 0.9984 - val_recall: 0.9535 - val_precision: 0.9876\n",
            "Epoch 400/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0887 - accuracy: 0.9660 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9630 - precision: 0.9683\n",
            "Epoch 400: val_accuracy did not improve from 0.98516\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.0887 - accuracy: 0.9660 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9630 - precision: 0.9683 - val_loss: 0.0975 - val_accuracy: 0.9672 - val_sensitivity_at_specificity: 0.9968 - val_specificity_at_sensitivity: 0.9985 - val_recall: 0.9778 - val_precision: 0.9567\n",
            "Epoch 401/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0942 - accuracy: 0.9617 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9601 - precision: 0.9616\n",
            "Epoch 401: val_accuracy did not improve from 0.98516\n",
            "10/10 [==============================] - 2s 176ms/step - loss: 0.0942 - accuracy: 0.9617 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9601 - precision: 0.9616 - val_loss: 0.0656 - val_accuracy: 0.9773 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9766 - val_precision: 0.9782\n",
            "Epoch 402/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0873 - accuracy: 0.9660 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9665 - precision: 0.9642\n",
            "Epoch 402: val_accuracy did not improve from 0.98516\n",
            "10/10 [==============================] - 2s 176ms/step - loss: 0.0873 - accuracy: 0.9660 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9665 - precision: 0.9642 - val_loss: 0.0939 - val_accuracy: 0.9609 - val_sensitivity_at_specificity: 0.9970 - val_specificity_at_sensitivity: 0.9984 - val_recall: 0.9369 - val_precision: 0.9873\n",
            "Epoch 403/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0823 - accuracy: 0.9695 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9651 - precision: 0.9728\n",
            "Epoch 403: val_accuracy did not improve from 0.98516\n",
            "10/10 [==============================] - 2s 174ms/step - loss: 0.0823 - accuracy: 0.9695 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9651 - precision: 0.9728 - val_loss: 0.0981 - val_accuracy: 0.9609 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9923 - val_precision: 0.9346\n",
            "Epoch 404/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1004 - accuracy: 0.9637 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9624 - precision: 0.9646\n",
            "Epoch 404: val_accuracy did not improve from 0.98516\n",
            "10/10 [==============================] - 2s 175ms/step - loss: 0.1004 - accuracy: 0.9637 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9624 - precision: 0.9646 - val_loss: 0.0545 - val_accuracy: 0.9805 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9747 - val_precision: 0.9856\n",
            "Epoch 405/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0955 - accuracy: 0.9676 - sensitivity_at_specificity: 0.9976 - specificity_at_sensitivity: 1.0000 - recall: 0.9610 - precision: 0.9726\n",
            "Epoch 405: val_accuracy did not improve from 0.98516\n",
            "10/10 [==============================] - 2s 176ms/step - loss: 0.0955 - accuracy: 0.9676 - sensitivity_at_specificity: 0.9976 - specificity_at_sensitivity: 1.0000 - recall: 0.9610 - precision: 0.9726 - val_loss: 0.0824 - val_accuracy: 0.9633 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9781 - val_precision: 0.9499\n",
            "Epoch 406/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0976 - accuracy: 0.9609 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9621 - precision: 0.9590\n",
            "Epoch 406: val_accuracy did not improve from 0.98516\n",
            "10/10 [==============================] - 2s 177ms/step - loss: 0.0976 - accuracy: 0.9609 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9621 - precision: 0.9590 - val_loss: 0.0603 - val_accuracy: 0.9789 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9723 - val_precision: 0.9860\n",
            "Epoch 407/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1018 - accuracy: 0.9613 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9669 - precision: 0.9555\n",
            "Epoch 407: val_accuracy did not improve from 0.98516\n",
            "10/10 [==============================] - 2s 176ms/step - loss: 0.1018 - accuracy: 0.9613 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9669 - precision: 0.9555 - val_loss: 0.0878 - val_accuracy: 0.9633 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9813 - val_precision: 0.9473\n",
            "Epoch 408/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0912 - accuracy: 0.9622 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9573 - precision: 0.9676\n",
            "Epoch 408: val_accuracy did not improve from 0.98516\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.0912 - accuracy: 0.9622 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9573 - precision: 0.9676 - val_loss: 0.1019 - val_accuracy: 0.9648 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.9985 - val_recall: 0.9904 - val_precision: 0.9407\n",
            "Epoch 409/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0831 - accuracy: 0.9664 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9629 - precision: 0.9690\n",
            "Epoch 409: val_accuracy did not improve from 0.98516\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.0831 - accuracy: 0.9664 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9629 - precision: 0.9690 - val_loss: 0.0812 - val_accuracy: 0.9672 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9817 - val_precision: 0.9556\n",
            "Epoch 410/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0835 - accuracy: 0.9664 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9673 - precision: 0.9658\n",
            "Epoch 410: val_accuracy did not improve from 0.98516\n",
            "10/10 [==============================] - 2s 175ms/step - loss: 0.0835 - accuracy: 0.9664 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9673 - precision: 0.9658 - val_loss: 0.0674 - val_accuracy: 0.9773 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9776 - val_precision: 0.9791\n",
            "Epoch 411/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0916 - accuracy: 0.9699 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9687 - precision: 0.9710\n",
            "Epoch 411: val_accuracy did not improve from 0.98516\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.0916 - accuracy: 0.9699 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9687 - precision: 0.9710 - val_loss: 0.0644 - val_accuracy: 0.9812 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9826 - val_precision: 0.9795\n",
            "Epoch 412/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0742 - accuracy: 0.9715 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9696 - precision: 0.9734\n",
            "Epoch 412: val_accuracy did not improve from 0.98516\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.0742 - accuracy: 0.9715 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9696 - precision: 0.9734 - val_loss: 0.0622 - val_accuracy: 0.9820 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9742 - val_precision: 0.9907\n",
            "Epoch 413/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0838 - accuracy: 0.9711 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9699 - precision: 0.9714\n",
            "Epoch 413: val_accuracy did not improve from 0.98516\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.0838 - accuracy: 0.9711 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9699 - precision: 0.9714 - val_loss: 0.0449 - val_accuracy: 0.9844 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9772 - val_precision: 0.9901\n",
            "Epoch 414/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0781 - accuracy: 0.9727 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9701 - precision: 0.9747\n",
            "Epoch 414: val_accuracy improved from 0.98516 to 0.98672, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 176ms/step - loss: 0.0781 - accuracy: 0.9727 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9701 - precision: 0.9747 - val_loss: 0.0490 - val_accuracy: 0.9867 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9842 - val_precision: 0.9889\n",
            "Epoch 415/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0755 - accuracy: 0.9715 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9691 - precision: 0.9715\n",
            "Epoch 415: val_accuracy did not improve from 0.98672\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.0755 - accuracy: 0.9715 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9691 - precision: 0.9715 - val_loss: 0.0757 - val_accuracy: 0.9758 - val_sensitivity_at_specificity: 0.9968 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9585 - val_precision: 0.9917\n",
            "Epoch 416/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0794 - accuracy: 0.9703 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9695 - precision: 0.9710\n",
            "Epoch 416: val_accuracy did not improve from 0.98672\n",
            "10/10 [==============================] - 2s 174ms/step - loss: 0.0794 - accuracy: 0.9703 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9695 - precision: 0.9710 - val_loss: 0.0601 - val_accuracy: 0.9828 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9880 - val_precision: 0.9791\n",
            "Epoch 417/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0693 - accuracy: 0.9746 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9739 - precision: 0.9762\n",
            "Epoch 417: val_accuracy did not improve from 0.98672\n",
            "10/10 [==============================] - 2s 179ms/step - loss: 0.0693 - accuracy: 0.9746 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9739 - precision: 0.9762 - val_loss: 0.0628 - val_accuracy: 0.9797 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9890 - val_precision: 0.9707\n",
            "Epoch 418/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0710 - accuracy: 0.9715 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9700 - precision: 0.9723\n",
            "Epoch 418: val_accuracy did not improve from 0.98672\n",
            "10/10 [==============================] - 2s 175ms/step - loss: 0.0710 - accuracy: 0.9715 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9700 - precision: 0.9723 - val_loss: 0.0641 - val_accuracy: 0.9789 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9985 - val_recall: 0.9732 - val_precision: 0.9841\n",
            "Epoch 419/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0768 - accuracy: 0.9703 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9675 - precision: 0.9721\n",
            "Epoch 419: val_accuracy did not improve from 0.98672\n",
            "10/10 [==============================] - 2s 175ms/step - loss: 0.0768 - accuracy: 0.9703 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9675 - precision: 0.9721 - val_loss: 0.0900 - val_accuracy: 0.9633 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9825 - val_precision: 0.9450\n",
            "Epoch 420/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0772 - accuracy: 0.9691 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9670 - precision: 0.9693\n",
            "Epoch 420: val_accuracy did not improve from 0.98672\n",
            "10/10 [==============================] - 2s 190ms/step - loss: 0.0772 - accuracy: 0.9691 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9670 - precision: 0.9693 - val_loss: 0.0588 - val_accuracy: 0.9844 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9832 - val_precision: 0.9862\n",
            "Epoch 421/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0692 - accuracy: 0.9755 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9735 - precision: 0.9775\n",
            "Epoch 421: val_accuracy did not improve from 0.98672\n",
            "10/10 [==============================] - 2s 179ms/step - loss: 0.0692 - accuracy: 0.9755 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9735 - precision: 0.9775 - val_loss: 0.0636 - val_accuracy: 0.9812 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9740 - val_precision: 0.9891\n",
            "Epoch 422/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0715 - accuracy: 0.9742 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9732 - precision: 0.9747\n",
            "Epoch 422: val_accuracy did not improve from 0.98672\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.0715 - accuracy: 0.9742 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9732 - precision: 0.9747 - val_loss: 0.0714 - val_accuracy: 0.9789 - val_sensitivity_at_specificity: 0.9968 - val_specificity_at_sensitivity: 0.9985 - val_recall: 0.9792 - val_precision: 0.9776\n",
            "Epoch 423/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0839 - accuracy: 0.9664 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9595 - precision: 0.9705\n",
            "Epoch 423: val_accuracy did not improve from 0.98672\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.0839 - accuracy: 0.9664 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9595 - precision: 0.9705 - val_loss: 0.0846 - val_accuracy: 0.9727 - val_sensitivity_at_specificity: 0.9969 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9469 - val_precision: 0.9984\n",
            "Epoch 424/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0858 - accuracy: 0.9668 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9677 - precision: 0.9669\n",
            "Epoch 424: val_accuracy did not improve from 0.98672\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.0858 - accuracy: 0.9668 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9677 - precision: 0.9669 - val_loss: 0.0678 - val_accuracy: 0.9750 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9689 - val_precision: 0.9811\n",
            "Epoch 425/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0826 - accuracy: 0.9680 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 1.0000 - recall: 0.9654 - precision: 0.9714\n",
            "Epoch 425: val_accuracy did not improve from 0.98672\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.0826 - accuracy: 0.9680 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 1.0000 - recall: 0.9654 - precision: 0.9714 - val_loss: 0.0794 - val_accuracy: 0.9750 - val_sensitivity_at_specificity: 0.9954 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9600 - val_precision: 0.9905\n",
            "Epoch 426/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0965 - accuracy: 0.9602 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9597 - precision: 0.9597\n",
            "Epoch 426: val_accuracy did not improve from 0.98672\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.0965 - accuracy: 0.9602 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9597 - precision: 0.9597 - val_loss: 0.0625 - val_accuracy: 0.9797 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9602 - val_precision: 0.9983\n",
            "Epoch 427/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0853 - accuracy: 0.9660 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 0.9984 - recall: 0.9645 - precision: 0.9682\n",
            "Epoch 427: val_accuracy did not improve from 0.98672\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.0853 - accuracy: 0.9660 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 0.9984 - recall: 0.9645 - precision: 0.9682 - val_loss: 0.0788 - val_accuracy: 0.9750 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9839 - val_precision: 0.9653\n",
            "Epoch 428/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0867 - accuracy: 0.9695 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 1.0000 - recall: 0.9667 - precision: 0.9740\n",
            "Epoch 428: val_accuracy did not improve from 0.98672\n",
            "10/10 [==============================] - 2s 174ms/step - loss: 0.0867 - accuracy: 0.9695 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 1.0000 - recall: 0.9667 - precision: 0.9740 - val_loss: 0.0595 - val_accuracy: 0.9836 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9860 - val_precision: 0.9814\n",
            "Epoch 429/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0626 - accuracy: 0.9766 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9754 - precision: 0.9770\n",
            "Epoch 429: val_accuracy did not improve from 0.98672\n",
            "10/10 [==============================] - 2s 175ms/step - loss: 0.0626 - accuracy: 0.9766 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9754 - precision: 0.9770 - val_loss: 0.0583 - val_accuracy: 0.9742 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9719 - val_precision: 0.9765\n",
            "Epoch 430/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0792 - accuracy: 0.9691 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9695 - precision: 0.9702\n",
            "Epoch 430: val_accuracy did not improve from 0.98672\n",
            "10/10 [==============================] - 2s 175ms/step - loss: 0.0792 - accuracy: 0.9691 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9695 - precision: 0.9702 - val_loss: 0.0927 - val_accuracy: 0.9727 - val_sensitivity_at_specificity: 0.9969 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9739 - val_precision: 0.9724\n",
            "Epoch 431/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1037 - accuracy: 0.9582 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9600 - precision: 0.9578\n",
            "Epoch 431: val_accuracy did not improve from 0.98672\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.1037 - accuracy: 0.9582 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9600 - precision: 0.9578 - val_loss: 0.0717 - val_accuracy: 0.9781 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9985 - val_recall: 0.9807 - val_precision: 0.9744\n",
            "Epoch 432/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0774 - accuracy: 0.9695 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9635 - precision: 0.9756\n",
            "Epoch 432: val_accuracy did not improve from 0.98672\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.0774 - accuracy: 0.9695 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9635 - precision: 0.9756 - val_loss: 0.0838 - val_accuracy: 0.9742 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9906 - val_precision: 0.9590\n",
            "Epoch 433/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0814 - accuracy: 0.9625 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9626 - precision: 0.9626\n",
            "Epoch 433: val_accuracy did not improve from 0.98672\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.0814 - accuracy: 0.9625 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9626 - precision: 0.9626 - val_loss: 0.0573 - val_accuracy: 0.9828 - val_sensitivity_at_specificity: 0.9969 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9813 - val_precision: 0.9844\n",
            "Epoch 434/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0922 - accuracy: 0.9589 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9479 - precision: 0.9708\n",
            "Epoch 434: val_accuracy did not improve from 0.98672\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.0922 - accuracy: 0.9589 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9479 - precision: 0.9708 - val_loss: 0.0631 - val_accuracy: 0.9812 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9868 - val_precision: 0.9740\n",
            "Epoch 435/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0837 - accuracy: 0.9688 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9690 - precision: 0.9690\n",
            "Epoch 435: val_accuracy did not improve from 0.98672\n",
            "10/10 [==============================] - 2s 177ms/step - loss: 0.0837 - accuracy: 0.9688 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9690 - precision: 0.9690 - val_loss: 0.0686 - val_accuracy: 0.9773 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9777 - val_precision: 0.9762\n",
            "Epoch 436/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0795 - accuracy: 0.9684 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9676 - precision: 0.9692\n",
            "Epoch 436: val_accuracy did not improve from 0.98672\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.0795 - accuracy: 0.9684 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9676 - precision: 0.9692 - val_loss: 0.0705 - val_accuracy: 0.9727 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9534 - val_precision: 0.9937\n",
            "Epoch 437/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0985 - accuracy: 0.9664 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9636 - precision: 0.9682\n",
            "Epoch 437: val_accuracy did not improve from 0.98672\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.0985 - accuracy: 0.9664 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9636 - precision: 0.9682 - val_loss: 0.0544 - val_accuracy: 0.9836 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9789 - val_precision: 0.9894\n",
            "Epoch 438/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0954 - accuracy: 0.9629 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9556 - precision: 0.9673\n",
            "Epoch 438: val_accuracy did not improve from 0.98672\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.0954 - accuracy: 0.9629 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9556 - precision: 0.9673 - val_loss: 0.0799 - val_accuracy: 0.9828 - val_sensitivity_at_specificity: 0.9968 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9743 - val_precision: 0.9902\n",
            "Epoch 439/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0835 - accuracy: 0.9660 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9677 - precision: 0.9639\n",
            "Epoch 439: val_accuracy did not improve from 0.98672\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.0835 - accuracy: 0.9660 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9677 - precision: 0.9639 - val_loss: 0.0789 - val_accuracy: 0.9719 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9937 - val_precision: 0.9514\n",
            "Epoch 440/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0828 - accuracy: 0.9695 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9653 - precision: 0.9715\n",
            "Epoch 440: val_accuracy did not improve from 0.98672\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.0828 - accuracy: 0.9695 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9653 - precision: 0.9715 - val_loss: 0.0787 - val_accuracy: 0.9797 - val_sensitivity_at_specificity: 0.9969 - val_specificity_at_sensitivity: 0.9984 - val_recall: 0.9785 - val_precision: 0.9815\n",
            "Epoch 441/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0892 - accuracy: 0.9672 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9671 - precision: 0.9671\n",
            "Epoch 441: val_accuracy did not improve from 0.98672\n",
            "10/10 [==============================] - 2s 176ms/step - loss: 0.0892 - accuracy: 0.9672 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9671 - precision: 0.9671 - val_loss: 0.0637 - val_accuracy: 0.9789 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9741 - val_precision: 0.9846\n",
            "Epoch 442/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0770 - accuracy: 0.9691 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9647 - precision: 0.9731\n",
            "Epoch 442: val_accuracy did not improve from 0.98672\n",
            "10/10 [==============================] - 2s 174ms/step - loss: 0.0770 - accuracy: 0.9691 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9647 - precision: 0.9731 - val_loss: 0.0694 - val_accuracy: 0.9797 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9783 - val_precision: 0.9814\n",
            "Epoch 443/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0741 - accuracy: 0.9715 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9689 - precision: 0.9742\n",
            "Epoch 443: val_accuracy did not improve from 0.98672\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.0741 - accuracy: 0.9715 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9689 - precision: 0.9742 - val_loss: 0.0524 - val_accuracy: 0.9844 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9746 - val_precision: 0.9935\n",
            "Epoch 444/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0637 - accuracy: 0.9742 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9715 - precision: 0.9775\n",
            "Epoch 444: val_accuracy improved from 0.98672 to 0.98828, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 186ms/step - loss: 0.0637 - accuracy: 0.9742 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9715 - precision: 0.9775 - val_loss: 0.0423 - val_accuracy: 0.9883 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9907 - val_precision: 0.9861\n",
            "Epoch 445/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0716 - accuracy: 0.9715 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9702 - precision: 0.9725\n",
            "Epoch 445: val_accuracy did not improve from 0.98828\n",
            "10/10 [==============================] - 2s 177ms/step - loss: 0.0716 - accuracy: 0.9715 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9702 - precision: 0.9725 - val_loss: 0.0780 - val_accuracy: 0.9695 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9838 - val_precision: 0.9543\n",
            "Epoch 446/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0855 - accuracy: 0.9684 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9992 - recall: 0.9631 - precision: 0.9731\n",
            "Epoch 446: val_accuracy did not improve from 0.98828\n",
            "10/10 [==============================] - 2s 175ms/step - loss: 0.0855 - accuracy: 0.9684 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9992 - recall: 0.9631 - precision: 0.9731 - val_loss: 0.0550 - val_accuracy: 0.9859 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9795 - val_precision: 0.9920\n",
            "Epoch 447/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0720 - accuracy: 0.9707 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9713 - precision: 0.9705\n",
            "Epoch 447: val_accuracy did not improve from 0.98828\n",
            "10/10 [==============================] - 2s 176ms/step - loss: 0.0720 - accuracy: 0.9707 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9713 - precision: 0.9705 - val_loss: 0.0651 - val_accuracy: 0.9828 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9878 - val_precision: 0.9788\n",
            "Epoch 448/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0793 - accuracy: 0.9660 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9623 - precision: 0.9705\n",
            "Epoch 448: val_accuracy did not improve from 0.98828\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.0793 - accuracy: 0.9660 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9623 - precision: 0.9705 - val_loss: 0.0695 - val_accuracy: 0.9773 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9727 - val_precision: 0.9806\n",
            "Epoch 449/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0702 - accuracy: 0.9746 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9725 - precision: 0.9777\n",
            "Epoch 449: val_accuracy did not improve from 0.98828\n",
            "10/10 [==============================] - 2s 176ms/step - loss: 0.0702 - accuracy: 0.9746 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9725 - precision: 0.9777 - val_loss: 0.0611 - val_accuracy: 0.9844 - val_sensitivity_at_specificity: 0.9969 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9843 - val_precision: 0.9843\n",
            "Epoch 450/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0834 - accuracy: 0.9688 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9634 - precision: 0.9727\n",
            "Epoch 450: val_accuracy did not improve from 0.98828\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.0834 - accuracy: 0.9688 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9634 - precision: 0.9727 - val_loss: 0.0539 - val_accuracy: 0.9859 - val_sensitivity_at_specificity: 0.9969 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9907 - val_precision: 0.9816\n",
            "Epoch 451/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0742 - accuracy: 0.9742 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9767 - precision: 0.9704\n",
            "Epoch 451: val_accuracy did not improve from 0.98828\n",
            "10/10 [==============================] - 2s 174ms/step - loss: 0.0742 - accuracy: 0.9742 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9767 - precision: 0.9704 - val_loss: 0.0644 - val_accuracy: 0.9805 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9764 - val_precision: 0.9841\n",
            "Epoch 452/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0878 - accuracy: 0.9637 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 1.0000 - recall: 0.9539 - precision: 0.9741\n",
            "Epoch 452: val_accuracy did not improve from 0.98828\n",
            "10/10 [==============================] - 2s 176ms/step - loss: 0.0878 - accuracy: 0.9637 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 1.0000 - recall: 0.9539 - precision: 0.9741 - val_loss: 0.0758 - val_accuracy: 0.9703 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9876 - val_precision: 0.9552\n",
            "Epoch 453/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0743 - accuracy: 0.9711 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9736 - precision: 0.9691\n",
            "Epoch 453: val_accuracy did not improve from 0.98828\n",
            "10/10 [==============================] - 2s 176ms/step - loss: 0.0743 - accuracy: 0.9711 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9736 - precision: 0.9691 - val_loss: 0.0851 - val_accuracy: 0.9789 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.9984 - val_recall: 0.9797 - val_precision: 0.9782\n",
            "Epoch 454/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0571 - accuracy: 0.9789 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9782 - precision: 0.9797\n",
            "Epoch 454: val_accuracy did not improve from 0.98828\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.0571 - accuracy: 0.9789 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9782 - precision: 0.9797 - val_loss: 0.0446 - val_accuracy: 0.9852 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9876 - val_precision: 0.9830\n",
            "Epoch 455/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0748 - accuracy: 0.9719 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 0.9992 - recall: 0.9701 - precision: 0.9760\n",
            "Epoch 455: val_accuracy did not improve from 0.98828\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.0748 - accuracy: 0.9719 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 0.9992 - recall: 0.9701 - precision: 0.9760 - val_loss: 0.0917 - val_accuracy: 0.9625 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9842 - val_precision: 0.9424\n",
            "Epoch 456/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0709 - accuracy: 0.9754 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9742 - precision: 0.9779\n",
            "Epoch 456: val_accuracy did not improve from 0.98828\n",
            "10/10 [==============================] - 2s 175ms/step - loss: 0.0709 - accuracy: 0.9754 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9742 - precision: 0.9779 - val_loss: 0.0635 - val_accuracy: 0.9812 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 0.9984 - val_recall: 0.9909 - val_precision: 0.9731\n",
            "Epoch 457/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0690 - accuracy: 0.9766 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9748 - precision: 0.9779\n",
            "Epoch 457: val_accuracy did not improve from 0.98828\n",
            "10/10 [==============================] - 2s 174ms/step - loss: 0.0690 - accuracy: 0.9766 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9748 - precision: 0.9779 - val_loss: 0.0592 - val_accuracy: 0.9852 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9825 - val_precision: 0.9872\n",
            "Epoch 458/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0755 - accuracy: 0.9688 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9622 - precision: 0.9745\n",
            "Epoch 458: val_accuracy did not improve from 0.98828\n",
            "10/10 [==============================] - 2s 181ms/step - loss: 0.0755 - accuracy: 0.9688 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9622 - precision: 0.9745 - val_loss: 0.0614 - val_accuracy: 0.9758 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9984 - val_recall: 0.9892 - val_precision: 0.9640\n",
            "Epoch 459/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0855 - accuracy: 0.9672 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9620 - precision: 0.9726\n",
            "Epoch 459: val_accuracy did not improve from 0.98828\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.0855 - accuracy: 0.9672 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9620 - precision: 0.9726 - val_loss: 0.0745 - val_accuracy: 0.9805 - val_sensitivity_at_specificity: 0.9969 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9847 - val_precision: 0.9772\n",
            "Epoch 460/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0819 - accuracy: 0.9648 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9716 - precision: 0.9599\n",
            "Epoch 460: val_accuracy did not improve from 0.98828\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.0819 - accuracy: 0.9648 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9716 - precision: 0.9599 - val_loss: 0.0593 - val_accuracy: 0.9766 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9605 - val_precision: 0.9954\n",
            "Epoch 461/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0688 - accuracy: 0.9746 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9711 - precision: 0.9780\n",
            "Epoch 461: val_accuracy did not improve from 0.98828\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.0688 - accuracy: 0.9746 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9711 - precision: 0.9780 - val_loss: 0.0419 - val_accuracy: 0.9852 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9831 - val_precision: 0.9877\n",
            "Epoch 462/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0715 - accuracy: 0.9719 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9721 - precision: 0.9721\n",
            "Epoch 462: val_accuracy did not improve from 0.98828\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.0715 - accuracy: 0.9719 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9721 - precision: 0.9721 - val_loss: 0.0687 - val_accuracy: 0.9758 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9812 - val_precision: 0.9706\n",
            "Epoch 463/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0754 - accuracy: 0.9691 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9711 - precision: 0.9689\n",
            "Epoch 463: val_accuracy did not improve from 0.98828\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.0754 - accuracy: 0.9691 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9711 - precision: 0.9689 - val_loss: 0.0793 - val_accuracy: 0.9773 - val_sensitivity_at_specificity: 0.9968 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9604 - val_precision: 0.9934\n",
            "Epoch 464/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0646 - accuracy: 0.9777 - sensitivity_at_specificity: 0.9993 - specificity_at_sensitivity: 1.0000 - recall: 0.9738 - precision: 0.9834\n",
            "Epoch 464: val_accuracy did not improve from 0.98828\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.0646 - accuracy: 0.9777 - sensitivity_at_specificity: 0.9993 - specificity_at_sensitivity: 1.0000 - recall: 0.9738 - precision: 0.9834 - val_loss: 0.0828 - val_accuracy: 0.9680 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9869 - val_precision: 0.9479\n",
            "Epoch 465/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0914 - accuracy: 0.9621 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9608 - precision: 0.9631\n",
            "Epoch 465: val_accuracy did not improve from 0.98828\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.0914 - accuracy: 0.9621 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9608 - precision: 0.9631 - val_loss: 0.0613 - val_accuracy: 0.9766 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9570 - val_precision: 0.9950\n",
            "Epoch 466/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0651 - accuracy: 0.9738 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9709 - precision: 0.9776\n",
            "Epoch 466: val_accuracy did not improve from 0.98828\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.0651 - accuracy: 0.9738 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9709 - precision: 0.9776 - val_loss: 0.0622 - val_accuracy: 0.9805 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9773 - val_precision: 0.9847\n",
            "Epoch 467/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0706 - accuracy: 0.9734 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9707 - precision: 0.9767\n",
            "Epoch 467: val_accuracy did not improve from 0.98828\n",
            "10/10 [==============================] - 2s 175ms/step - loss: 0.0706 - accuracy: 0.9734 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9707 - precision: 0.9767 - val_loss: 0.0560 - val_accuracy: 0.9875 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9848 - val_precision: 0.9909\n",
            "Epoch 468/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0716 - accuracy: 0.9711 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9720 - precision: 0.9705\n",
            "Epoch 468: val_accuracy did not improve from 0.98828\n",
            "10/10 [==============================] - 2s 174ms/step - loss: 0.0716 - accuracy: 0.9711 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9720 - precision: 0.9705 - val_loss: 0.0665 - val_accuracy: 0.9859 - val_sensitivity_at_specificity: 0.9951 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9788 - val_precision: 0.9917\n",
            "Epoch 469/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0658 - accuracy: 0.9770 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9747 - precision: 0.9800\n",
            "Epoch 469: val_accuracy did not improve from 0.98828\n",
            "10/10 [==============================] - 2s 191ms/step - loss: 0.0658 - accuracy: 0.9770 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9747 - precision: 0.9800 - val_loss: 0.0590 - val_accuracy: 0.9836 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9820 - val_precision: 0.9836\n",
            "Epoch 470/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0607 - accuracy: 0.9742 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9721 - precision: 0.9766\n",
            "Epoch 470: val_accuracy improved from 0.98828 to 0.98906, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 180ms/step - loss: 0.0607 - accuracy: 0.9742 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9721 - precision: 0.9766 - val_loss: 0.0448 - val_accuracy: 0.9891 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9850 - val_precision: 0.9939\n",
            "Epoch 471/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0650 - accuracy: 0.9773 - sensitivity_at_specificity: 0.9976 - specificity_at_sensitivity: 1.0000 - recall: 0.9741 - precision: 0.9802\n",
            "Epoch 471: val_accuracy did not improve from 0.98906\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.0650 - accuracy: 0.9773 - sensitivity_at_specificity: 0.9976 - specificity_at_sensitivity: 1.0000 - recall: 0.9741 - precision: 0.9802 - val_loss: 0.0490 - val_accuracy: 0.9844 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9844 - val_precision: 0.9844\n",
            "Epoch 472/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0827 - accuracy: 0.9668 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9984 - recall: 0.9631 - precision: 0.9700\n",
            "Epoch 472: val_accuracy did not improve from 0.98906\n",
            "10/10 [==============================] - 2s 178ms/step - loss: 0.0827 - accuracy: 0.9668 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9984 - recall: 0.9631 - precision: 0.9700 - val_loss: 0.0844 - val_accuracy: 0.9789 - val_sensitivity_at_specificity: 0.9966 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9883 - val_precision: 0.9672\n",
            "Epoch 473/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0798 - accuracy: 0.9680 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9667 - precision: 0.9706\n",
            "Epoch 473: val_accuracy did not improve from 0.98906\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.0798 - accuracy: 0.9680 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9667 - precision: 0.9706 - val_loss: 0.0695 - val_accuracy: 0.9844 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 0.9984 - val_recall: 0.9878 - val_precision: 0.9818\n",
            "Epoch 474/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0632 - accuracy: 0.9742 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9746 - precision: 0.9746\n",
            "Epoch 474: val_accuracy did not improve from 0.98906\n",
            "10/10 [==============================] - 2s 177ms/step - loss: 0.0632 - accuracy: 0.9742 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9746 - precision: 0.9746 - val_loss: 0.0508 - val_accuracy: 0.9852 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9715 - val_precision: 0.9984\n",
            "Epoch 475/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0829 - accuracy: 0.9664 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9589 - precision: 0.9740\n",
            "Epoch 475: val_accuracy did not improve from 0.98906\n",
            "10/10 [==============================] - 2s 175ms/step - loss: 0.0829 - accuracy: 0.9664 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9589 - precision: 0.9740 - val_loss: 0.0704 - val_accuracy: 0.9789 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9891 - val_precision: 0.9696\n",
            "Epoch 476/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0695 - accuracy: 0.9777 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9758 - precision: 0.9810\n",
            "Epoch 476: val_accuracy did not improve from 0.98906\n",
            "10/10 [==============================] - 2s 176ms/step - loss: 0.0695 - accuracy: 0.9777 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9758 - precision: 0.9810 - val_loss: 0.0607 - val_accuracy: 0.9844 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9850 - val_precision: 0.9850\n",
            "Epoch 477/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0639 - accuracy: 0.9758 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9725 - precision: 0.9787\n",
            "Reached 99% accuracy so cancelling training!\n",
            "\n",
            "Epoch 477: val_accuracy improved from 0.98906 to 0.99063, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 179ms/step - loss: 0.0639 - accuracy: 0.9758 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9725 - precision: 0.9787 - val_loss: 0.0504 - val_accuracy: 0.9906 - val_sensitivity_at_specificity: 0.9983 - val_specificity_at_sensitivity: 1.0000 - val_recall: 0.9851 - val_precision: 0.9950\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Performance Metrics**"
      ],
      "metadata": {
        "id": "ziBnKWqmBU4q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Training_Accuracy=history.history['accuracy']\n",
        "Validation_Accuracy=history.history['val_accuracy']\n",
        "Validation_Specificity=history.history['val_specificity_at_sensitivity']\n",
        "Validation_Sensitivity=history.history['val_sensitivity_at_specificity']\n",
        "Validation_Recall=history.history['val_recall']\n",
        "Validation_Precision=history.history['val_precision']\n",
        "Validation_Loss=history.history['val_loss']\n",
        "\n",
        "print(\"Training Accuracy: \",max(Training_Accuracy))\n",
        "print(\"Validation Accuracy: \",max(Validation_Accuracy))\n",
        "print(\"Validation Specificity: \",max(Validation_Specificity))\n",
        "print(\"Validation Sensitivity: \",max(Validation_Sensitivity))\n",
        "print(\"Validation Recall: \",max(Validation_Recall))\n",
        "print(\"Validation Precision: \",max(Validation_Precision))\n",
        "print(\"Validation Loss: \",min(Validation_Loss))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCdS_0U65A0-",
        "outputId": "9c98cd44-cb57-4102-d99f-d0157487053a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy:  0.9789062738418579\n",
            "Validation Accuracy:  0.9906250238418579\n",
            "Validation Specificity:  1.0\n",
            "Validation Sensitivity:  1.0\n",
            "Validation Recall:  1.0\n",
            "Validation Precision:  0.9983713626861572\n",
            "Validation Loss:  0.04193344712257385\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Accuracy Graph**"
      ],
      "metadata": {
        "id": "gn0ZuIN3BX5q"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLqjG2X-vdLj",
        "outputId": "829b53c7-259a-4505-9536-19736a31212c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        }
      },
      "source": [
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmEAAAGDCAYAAABjkcdfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOydd3Qc1f23n7tNK2nVe7NVLMvdcsPYGDC2wRTTSyih8yMQSgghlCQEeEkogQCBEAgEgoFQTDW4UAzuvfeu3vuqS1vm/ePO7K6KC2AjY+5zjs/szNw7c2csez/6VqFpGgqFQqFQKBSKHxdTXy9AoVAoFAqF4ueIEmEKhUKhUCgUfYASYQqFQqFQKBR9gBJhCoVCoVAoFH2AEmEKhUKhUCgUfYASYQqFQqFQKBR9gBJhCoXimEcIkS6E0IQQlsMYe50QYtmPsS6FQqH4ISgRplAojihCiAIhRKcQIrbb8Y26kErvm5UpFArFsYUSYQqF4miQD1xh7AghhgMhfbecY4PDseQpFIqfD0qEKRSKo8FbwDUB+9cCbwYOEEJECCHeFEJUCyEKhRB/EkKY9HNmIcTTQogaIUQecE4vc18TQpQLIUqFEH8RQpgPZ2FCiA+EEBVCCKcQYokQYmjAuWAhxN/19TiFEMuEEMH6uUlCiBVCiAYhRLEQ4jr9+CIhxE0B1+jiDtWtf7cJIfYCe/Vj/9Cv0SiEWC+EODlgvFkI8QchxH4hRJN+Pk0I8aIQ4u/dnuUzIcRvD+e5FQrFsYcSYQqF4miwCggXQgzWxdHlwNvdxrwARACZwKlI0Xa9fu7/gBnAKGAscEm3uW8AbmCAPuYM4CYOj/lANhAPbAD+F3DuaWAMMBGIBu4FvEKI/vq8F4A4IBfYdJj3A7gAGA8M0ffX6teIBt4BPhBC2PVzdyOtiGcD4cANQCswE7giQKjGAtP0+QqF4ieIEmEKheJoYVjDTgd2AqXGiQBh9oCmaU2aphUAfweu1odcBjynaVqxpml1wOMBcxOQAuUuTdNaNE2rAp7Vr3dINE17Xb9nB/AwMFK3rJmQguc3mqaVaprm0TRthT7uSmCBpmnvaprm0jStVtO07yLCHtc0rU7TtDZ9DW/r13BrmvZ3IAjI0cfeBPxJ07TdmmSzPnYN4ASm6uMuBxZpmlb5HdahUCiOIVR8gkKhOFq8BSwBMujmigRiAStQGHCsEEjRPycDxd3OGfTX55YLIYxjpm7je0UXf38FLkVatLwB6wkC7MD+XqamHeD44dJlbUKIe4Abkc+pIS1eRiLDwe41E/gl8LW+/ccPWJNCoehjlCVMoVAcFTRNK0QG6J8NfNztdA3gQgoqg374rWXlSDESeM6gGOgAYjVNi9T/hGuaNpRDcyVwPtKNFwGk68eFvqZ2IKuXecUHOA7QQtekg8RexmjGBz3+616ktS9K07RIpIXLUJQHu9fbwPlCiJHAYODTA4xTKBQ/AZQIUygUR5MbgSmaprUEHtQ0zQPMAv4qhAjTY67uxh83Ngu4UwiRKoSIAu4PmFsOfAX8XQgRLoQwCSGyhBCnHsZ6wpACrhYpnB4LuK4XeB14RgiRrAfITxBCBCHjxqYJIS4TQliEEDFCiFx96ibgIiFEiBBigP7Mh1qDG6gGLEKIPyMtYQb/AR4VQmQLyQghRIy+xhJkPNlbwEeGe1OhUPw0USJMoVAcNTRN269p2roDnL4DaUXKA5YhA8xf18+9CnwJbEYGz3e3pF0D2IAdQD3wIZB0GEt6E+naLNXnrup2/h5gK1Lo1AFPAiZN04qQFr3f6cc3ASP1Oc8CnUAl0l34Pw7Ol8AXwB59Le10dVc+gxShXwGNwGtAcMD5mcBwpBBTKBQ/YYSmaYcepVAoFIpjAiHEKUiLYX9N/QeuUPykUZYwhUKh+IkghLACvwH+owSYQvHTR4kwhUKh+AkghBgMNCDdrs/18XIUCsURQLkjFQqFQqFQKPoAZQlTKBQKhUKh6AOUCFMoFAqFQqHoA35yFfNjY2O19PT0vl6GQqFQKBQKxSFZv359jaZpcb2d+8mJsPT0dNatO1DZIYVCoVAoFIpjByFE4YHOKXekQqFQKBQKRR+gRJhCoVAoFApFH6BEmEKhUCgUCkUf8JOLCesNl8tFSUkJ7e3tfb2Uo47dbic1NRWr1drXS1EoFAqFQvEDOGoiTAjxOjADqNI0bVgv5wXwD2RT3FbgOk3TNnyfe5WUlBAWFkZ6ejrysscnmqZRW1tLSUkJGRkZfb0chUKhUCgUP4Cj6Y58AzjzIOfPArL1PzcDL33fG7W3txMTE3NcCzAAIQQxMTE/C4ufQqFQKBTHO0dNhGmatgSoO8iQ84E3NckqIFIIkfR973e8CzCDn8tzKhQKhUJxvNOXgfkpQHHAfol+rAdCiJuFEOuEEOuqq6t/lMV9F2pra8nNzSU3N5fExERSUlJ8+52dnQedu27dOu68884faaUKhUKhUCiOFX4Sgfmapr0CvAIwduzYY67jeExMDJs2bQLg4YcfxuFwcM899/jOu91uLJbeX/XYsWMZO3bsj7JOhUKhUCgUxw59aQkrBdIC9lP1Y8cF1113Hbfccgvjx4/n3nvvZc2aNUyYMIFRo0YxceJEdu/eDcCiRYuYMWMGIAXcDTfcwOTJk8nMzOT555/vy0dQKBQKhUJxFOlLS9hnwO1CiPeA8YBT07TyH3rRRz7fzo6yxh+8uECGJIfz0LlDv/O8kpISVqxYgdlsprGxkaVLl2KxWFiwYAF/+MMf+Oijj3rM2bVrFwsXLqSpqYmcnBxuvfVWVY5CoVAoFIrjkKNZouJdYDIQK4QoAR4CrACapr0MzEOWp9iHLFFx/dFaS19x6aWXYjabAXA6nVx77bXs3bsXIQQul6vXOeeccw5BQUEEBQURHx9PZWUlqampP+ayFQqFQqE4/tk5B9JOAEd8ny3hqIkwTdOuOMR5DbjtSN/3+1isjhahoaG+zw8++CCnnXYan3zyCQUFBUyePLnXOUFBQb7PZrMZt9t9tJepUCgUCsXxR2sdVO+G/hN6nmuqhPevgtP+BKf+/sdfm45qW/Qj4XQ6SUmRyZ9vvPFG3y5GoVAoFD9PvN6+u3fVLnh+NNTsPXr3qNgGeYvk52//Av89C+oLe47b+5Xc5hysnOnRR4mwH4l7772XBx54gFGjRinrlkKhUCgOn/YjFOdcsAye7A9Fq4/M9b4rn/8G6vbD/oWw7DmoL5DHNQ02/g/yl/rHetzQ2eLfb2voeq32RjmvO+9eAW+eDwsfhx2fAhpsfMt/n1a9fOmeLyA8FRJ6NPT5URFabw9xDDN27Fht3bp1XY7t3LmTwYMH99GKfnx+bs+rUCgUP1v2fg3vXQW/3fbDYpecJfDvU6G1BqY+BCff3fX8hrfAZIHcg0QS1eyD2AEHv09bA3Q0QmS/rscbiuE5XfCMvRHWvSY/P9QAX9wPq1+G6Cy4Yz0IIZ951xx42Amb3oXP7oA7N0JkGrTUwHPD4bwXYPglAfeuhyfTu943JAbMNrjpG5h1NZSuh2tmw7tXwsjLYcYzB3+eI4AQYr2mab3WolKWMIVCoVAo+pJFT8K6//Z+rnQ9eDp6d6kdLq118P7V4O4AeyRUboNZ1/jddgCf3Q6f3gK1+3u/Rv5S+OeYnla0+ffDin/6rVLz7pECaU43kbf+DRC65CgNMKRsfBvW/kdaper2Q8UWea1dc+T5zlZY/CR4XVCyRh4rXg2uVshf0nONANd+Dv0nQUgsnPkENJXDRzdB6QYwB8Hce8DVAjlnH87bO6ooEaZQKBQKxcFoKIIXxhxYoPxQ1rwCS//eu3utLk9uW2sOPL947YHjrPKXwDNDoGwjXPgypI6FXfNgx2yYfbsUOYHM+S14PT2vU7hcv9cq/7GWWlj9Enz1R1j4mDxmiLQNM8Gtd4zxuKXYGnA6xAyAyu3+a3z1R/C64YxHpSVu28dQu89/fuPbUJ8vP5esh03vQOEKuV++qduzLgZrKKSdCNd8Cr9eBYPPBZsDilZA+iTInAy1eyE4GjJP7f2d/YgoEaZQKBQKxcHYOUcKg6UHcF19cD3M+54Zdm31UmA5i6FqR8/zhghrOUjLvk9+BQsehqJVsG+B/7imwTf/D0Jj4dblMHgGxA0Cd5s87yyG/54JFVsBAWHJUsgsesJ/jV3z4OmBsHue3C/ThU9Hs7TSATgSYOU/pcvTWSyFltcNix6HJ/rJ4PjmChhzLYQlyXMAJ/wK2p1gsUurVP+JsP9bGa9lkL9YbuOHSovZp7fCqn/JY5U7pHUPpJjc/ilknQYWG5it4IgDazDknCXHDL0QBk6XnwefK8f0MUqEKRQKheKnSUtNT0vOkcDdAY0BtcOtdrmt2OI/VrlDuuKKVku33ub3wNOt/qOrXVpu5t/ntwp1J9C6tucLGYzeVOE/Zoiw+gJ5nbZ6Ka4WPiazDTVNutucxfDNo/DFA/65hcuhZC1MugsS9PJN8UPkNmkkXPCSvP/XfwY0GSc29CIpcgxxs+IFaK6E8s3ykUo2ojVXw98HSdejMMEV74GrTXdBavIaAKtekiKrvQGmPAgDz5KCDcAeAaOvkZ/7nSjfcVIuVO+Cfd/4HsFTvg0tJIbm+FHSLQugeXUx54L3ruKZN95jw6f/kGJ2wu0AFNe1smh3FbsqGpnpPh0tcYQUYYPPxZswnN/mjWH2pr5v0vOT6B2pUCgUiuOMLx6A7NMha8qBxxyszhPAU1mQOAJuWdr1eLtTuhATh3+/tX31IKz5N9yzT1pTWmvl8epdMu4oday07rQ3SNdWm55xV7QSMk6RnwtXyOBy49yQ86WlJ5CKbVCix0eFxsG6N2Dn53iaqth26TJGxpn8997+CdTlkW/uR+ros7EuflKKvkm/lfFRjeVgrYfmainMhIA9X4LJCrlX+e8Zryd1ZU6mbcgvsK+fiSjbCMA2p40q+1SmdH4Mu+fLAPuiFdJN6HXTGdYPmzOfvV/9m+zOJuhsktmFKaOltcmwlg0+V7pX3W0w8grpBjUIS5Tb8FQpDEdfgytrOiavhjlxOHg60fIXs1kMIlfbhdlZwH7Rn/9sDOJxKzBoBuyag2vMTVgXPQr7vmaop55EezWkjff9rDw+fyfzt1XoHl4Hk343n6wQBwAbz/6cT15awSfvbcJmNnHW8KTv81NyRFCWMIVCofi5MvceWD/zx7lXWwO8Nl1akLweaSXZ9M6BxxeugGcGS3fZrrkHHhdonTKYdy+8PMlfAgGk1eg/p8syDSDrZb13lcy8644Ra7T6Jbk1yhp4OmHmDFj9bynAAC0wOHx3gBtt2bMyK+/CV/T7d3M1NpbBq6fBl3+Q1qTL3sLbVA5lGzE3lfLIK+/gLAuI89ItYhuWzmPNKt1F11gKzVXyc0uVvKa7zb/eyu3S/WgN9l8ncTiM+z9ahl/NyX/7lh0t4dK6Bry8rolbl4fSKYLgw+tlRqIlGM76Gwgzq+IvAyB1+8sQFCGvl6on/Y3Rm96YrFLoxehZlP38AnpfVTMzt7bLnYgUKRTPe4HzF0Tw6Jwd/He/LHAuNC9fdOb65pW6w/nKM5a9qRfB+S/SeOMKRn4zhPX9b0QTZkaY8kh2FbLDcSJ/nr2NZXtrWLirukuI3a7yJkob2jj/xeUs3CXfWb/oEEKC+tYWpUTYEaC2tpbc3Fxyc3NJTEwkJSXFt9/ZeQATdACLFi1ixYoVP8JKFQrFz5LeAq1B1lEKjCH6rnjcB752d4rXyKDufQukpQpNCiOAguUynqnL2mZLcRKbI+OAnhogBRxI4eQMcCV1X4MheJY/L7cdzfDelTK7btY10gW3Z77MwNvynoxDKl7jnx8SI7drXpVuxJYa6f466S79WWTw+T5vMsKj/x/vSPQHr7fWyWuOuBRGXAZB4f5nNVjxTynqNA9E9of+E/iT/Q88zg14EZzCetZv1K1ktjDftBPEbjpKdOHpLJWuQt970GOtnEVyW7kNEofT6fayYn8Ns9YVM+axRTyq3cDMXYKa5k6WVNt907c32okIC2OpZ6h0+Z3/Ity1BcbdCPfu59XWU1jrHUiwpwlOvBWmPw7jb5WTB0yV1q3YgTLWKn6QPK5b/9weL7+btYn1dbIrjDtUWp9qmjvYUd7Ip5tKeXq9l07dQbfEOwKPLlFik9MxhcXzT8edEBzJprZ4Wl0al++bxryoq0kSUnS+VhDLmysL+eVrq2lzefjzjCE8cNYgTAJ2VzTy2aYyNhc38MaKAuxWEwvvmcypA+PoS5Q78ggQExPDpk3yN6eHH34Yh8PBPffcc9jzFy1ahMPhYOLEiYcerFAoFIdDY5ksC5A1FV4/A67/oqtbT9P0eB3n97/Hf6bK3ntnP3XosZVb5bZ2r99SU7NbCrk39FIBDwespWKbdFed/qgMPHeWwLaPqCSahE9vgUkBJRDq8iA227/f0SS36/8rY5tyzpLlD874Kyx9Gv4zTWbMgcy4+/hmiBtE3hn/pamlhZGGC7CjUV67tRZvWBJPuC7n/pC3MZVuAGCpdzgDTGVy7IBpsPNz+V53fi4F0dCLpLUnbhBU7fQtz91Sj3v1azRHjiC2YQvEDKCqsZ136nKAHE63LeNM01pad+5Hs0cgkkdD3kIA0kzVtNXo7tfGEppqSvBLNB1niRREzZW0xQzmutdWszpfvvN+0SG8tkxmGw5JCqehIQF0i1GtFs69U7N5bPYVJJ9+E4NH+d2YreYwVhe18ivLQ0x1Leb+kTej2RxEBFtlU2iTGS6bKcUbQM45aG311AWlEQP87cvdbC5xcuGIwbAHFlVYefu/a0iJlFa6hlYXYGKPKZUB5gqqg7NwWaMxd9QwIDOLE8KjWas/w/YyWbw2zG7lo4pYzrGBVxN83ZDEFSeksWRPDc0dbq6e0B+r2cT764rZVdFEXYsUzM0dboYmh2M2ie5v7kdHWcKOEuvXr+fUU09lzJgxTJ8+nfJyGeT5/PPPM2TIEEaMGMHll19OQUEBL7/8Ms8++yy5ubksXbr0EFdWKBSKw2DXXFlfacv7cn/Hp13Pu9ulJSZQhO34zF9q4FB0tspg7Q1vHZ6Qq9gmtzX7fO4vPJ3+wPNANE2KtoRhUjjetQX6TaBz5zx++Q+9flRTQOB8hS7wWmqheg80FMKJv4YRv4BNb0tRBJB7pSzamTBUuugGzZBxTS3VaA1F7PzvLfD2JXiaq2XhUJBCsbWGBsJ5ZUke9eZYmekHLPPqxUfDkiFhCHQ4pfhd8rRce/IoeT5+kLTO6f6xyuVvYdfaua7yMooyL4fhl7J8v78ExdvuaQwyFTPas5mG8fdCRCoARZos1jrQvUe+psYyXp23vOf7c5b4RO/7RRGsK6zn/50/lJd/OYav7z6Fj26dwMnZsfxpxmBumCFj2Do0C4nx8ZyXm0weKXzpHUdTu4u9lVLQfr2jkk6Pl2tPzuEDz2SWFbUz5elFvLxIJha8uiSPm7+FufVpcg0jf8GT8U9x4hPf8uicHbyyJI9rJvTnurMn40XwcVEIi3ZX87/VRVhMgiCLlCPveU7jNdd0xmbGYY+Qz2uLTGFcehRlznY2Fzewo7yRlMhg/nbxCLZ6MwDYo6XSqIUwLj2aj389kVm/moDVLK85ODGclXm1bCiq9wmv7HhHz/fWBxx/lrD59/v/QR4pEofDWU8cepyOpmnccccdzJ49m7i4ON5//33++Mc/8vrrr/PEE0+Qn59PUFAQDQ0NREZGcsstt3xn65lCoTiOWPWSjJmKzYadn8Flbx7evPLNsvhmVP+e5wxhZLbJrRE71P28sXW1y4riAKf94dD3rt0HaDIGacssOOH/upwurG3h/bXF/GZaNkEWs3SNAdTsYWd+Ib6eH4UHEBHtTkgMaCkzcDq2rx9kCPJLv7gojzTjXMVWGHYRvHW+////lDEyE3Dzu7JPoD0CgqMgJBquk0Ju744NZOtFQTVnKRke6C8qcDXZMA87X1rPavZAax31DvmOy7zRxCAtLy1JE/DWCkzRmRAlxQDzfi/dgRfOAyHweDVawrMJb6ujsaaMmz4s5Jn6/7LVm85OkcWTlpN4ceRols3aTGSIlXC7lU/rJnHLKUNZ9e1swh0zmN5WSSiwxjYekWQirWg2HqsDs6uZVHcBXovAZJizTFZoKKalQc55caedy8amcc2EdN+rHNM/mrduHC93qqQF0RsSx1OX5hJutzI4MZyPN5Ty3AIZk7b6D1N5bsFechLCuPmUTJ7/di9fbKugsd3Ngl1V3D5lAC8v3o+zzcVXOypxe3MZlx7N68vzcXk0XluWL0XfOUPAYqLhuiUUflrPyWF2lu6tYVBSGBfkptDh9vLUl3JZD2dEw17dLRyWwJkpSby0eD9XvrqKlk4Ppw9JYNqQBNqumELTV+mscEr354B4BwnhdhLC/W7WnMQw5m6Vov3aE/sxc2Uh2Qk97Id9wvEnwo4BOjo62LZtG6effjoAHo+HpCTp/x4xYgRXXXUVF1xwARdccEFfLlOhUBwMI8Psx2DHbCk6jFgmd6esddQdrxdMAQ6M96+WGWEXv9pzrCGuDNdaS7XMptswEwae6e/L19EoswE3BwSod7aALfTga66R1ph2ezy2L//InP0ednfG8vuhjTD0ImauKOP15fnUNHfwt/MHStEWFAGtNcz6ajEPGd8+gTWhlj0HC/8qLWSAN36Y312TNQW+fpAzzWvl49SW+Xw5rhUvYu0/sesv4HE5EJMl48ra6qRVKuDvc0tJA08sbedfWiiRogWT5ibHVIwZL7g72O+KIisiDW/VbkyttdQES8vJ7jYHwwGnOZITB/dnw5JsclPG0WRPJQpg91y8aSdS5MilvqieO97dSFKjlw+skPft69QWJZAalMdHwTczLTWeHWWNtHV6+GpHBdMGJxAfFsSq/DqyJ5/NpUviCPpyL9vb63nQAq7w/ohzf8fz/xAM7Z/B1MJnGWPNp8IbRTituDETHpWMafO72NucfO0ZQ7slkt9MDXDVdke3sgVHJjAyLRKAaYPjeXHRfkwCvBo8OmcH+TUtvHL1GIJtZvrHhPCtHty+taSB/dXN1LZ0cv9Zg/hmZyV//GQbE7JiQIO3bjyBtfl13Dp5ADbd2hWdPoK5d4GzzcWEx79hXHo0N52ciaZpvLx4P03tbsZnxkBZrFxjWBKJEXZm3zaJc55fSkunx2fJOndkMhVJX/HEMysByIzraeGaPjSRlftr+fVpWWTEhvLB+hJOyIg+8Dv5ETn+RNh3sFgdLTRNY+jQoaxcubLHublz57JkyRI+//xz/vrXv7J16xG22ikUPyV2zpH1gQZM6+uVdGX1KzD/93B/MdjDDzhs7pZyokKtTMyKPfQ1NQ2WPCXLBUSkdD3XUuOvgQQy6y06o+uY1jr4WwbMeA7GXi9jnRqKZBba3gWyTMGQ8/zjDRFmuO0aS+HtiyB/CbWL/kXL5P9HP2Pcni+6FgNtrpL3byyTmYCTH5B/Ty21LCv1ckL5W9gqNuLFxOSGB3kz9HlO3fMXhnjDIb8Ulj1LWeS/AZi1roQLIvOYqHllsdBN/2OU0LP+QuNlALtB6XoICvMJx0lvVPLFfS7C7VaW1zk4CRgfVARuiBfSpXmX69fcZfmYlIVPYg2Ng5ZqvAhe2Ojljuk2TFHpUJdHZ3g6V7y0gviwIO6ZnsMlL6+k0+1l2bgnKNy+itu8/5MCTOftLc1cGZmE2LKcAaZWylwhAOR3RIIVRFgCyRHBXNL5EJlbHJR+u5+dQQKT0FjoHsbNzywmKkQK6bWeAZQmTSJn17+4wHwGAJ0ZUxkaF8FXOyr5YH0xTe1ufjEujfG6OBBCMLZ/FAt3V1Ntkj+D1tgMUuOiWZZ6C1/uWc/UIMjSithCFm3YadesmL1WwtrqKNCSWT/6MdacM45gm/nAP5dBYdKaGtCX8renD+T2KVK4DX/4S+ZsKScuLIhpg2WNr4HxYeRVSxHv1fDFmI1Ki2TqoHimP7eEr3dU8uvJWZycHcfJ2b0Hv0cEW5l758nEOmy+Z85JCGNvVTM5CWGy7RD4aoslRtiZecMJ3PL2eqYNSfBdJy42Hq/JRlJYEI5esh1zEsN49+YTffvbH5mO+LF+wToEKibsKBAUFER1dbVPhLlcLrZv347X66W4uJjTTjuNJ598EqfTSXNzM2FhYTQ1NfXxqhWKPuD9q+Dti/t6FT1ZogeaG7FLB+Avc3fw6pI8acla+9rBr1mXJ608G3opCdFao1uf9N/iG4p6jjGOzdPDFpwlgB5c/7+LpSsxMCe/QwYvN1YX+++fv4SSzMuIadlP57d/k8e9binAcq+Cqz6Ux/IW4v38Llpm3QLLn4PtH0NDMdrfc5gz8wlsCx+BnZ9RrMVRQQyPuK8lQmtigCilOv08aCgirvQbzh6eyMi0SFzLXsAbHA3jfwXAaNNevAgYdI7P6gVAZzNEZXBb0jtc5n6EsjYLa/Pr+HB9Cbd/uIcmQol2y2zAaNEMQKE3gRWeIXgqd6K11FBMAp9zKs8uLuHZBXvQYgcCUGZKYn1hPfO3VfDk/F10ur28cMUoZlx8DedcekPPvy7CWVof7Qu8L2oLpn9MCBWaFEkR8f1IirQDgryaFk4ZkkZTkBQy/y7uh8erUdvSwUu/HE1ieDAv2G7E6m3nNstnVJkTOe3EExiSFI6mwZ9nbyczNpTxGdEIIXwCwRD31VG5rPQMIShdConrT0qnXIvxrTUmMQ3P0EuYq53EO5zNYtspXOZ6mKtPG3lwAWYw6pcyPk5HCIHNYsJmMZGrW8dOH5KASY+nGpgoXXnJEXZCbWY+2iAzVQcnh5OdEMY1E9LJigvl9imHaPYNZMSGEmb3V66/c2o2j5w3VN4rsp8skeHwC65hKREsu28Ko/tF+Y6ZTYLkyGAGHGac17EiwECJsKOCyWTiww8/5L777mPkyJHk5uayYsUKPB4Pv/zlLxk+fDijRo3izjvvJDIyknPPPZdPPvlEBeYrfl60Nx79ezhL4PUzZcD2gajdL4PFAzGsQkbKv0HBMlnuAGjr9FDubKe+1QUb3pRxXbvmwed39X4fowq6UZzTwOOWYq+zRcYrgQws747hVkyjSigAACAASURBVPS6mbl0DyV5uuuyI+A9BtbF0i1hIqCEgRYcxa9qr6BaiyCpbbd/bFu9LMtgWEMWP4Vp/X8JLVmMJswyy7J8E8Lr4kqzv5p5BM1MGxzP8o5MlnqGkedN5H+J9+EOS2F6+3yGJkfw1MlmTmU92/tdRV3oADzCQqqooVELxZt5WpdHLK2ooIVg5ubDhFPPxmYx8efZ27nng83Eh9kJiunX47VotlAs8dnYPc0INP7huoDk6/7LxaNTeeHbfcwqkNl3hcgv8phQG9/orrQRqbLWVXpmTo/rThg2kJ2a/377WuyclhPPr88/Wb5XRwJJEf76W9dPTCc4IZsmLZj17gweOncIX951CuPSoxmfGc17eUF85p2ICS/xI6czNj2aoSl+K+stk7N6iIOrJ/Rn3p0nc/3Zp3CF60/kZMq4tNOHJDB19GDcQVIgpWQMYeBlj7I76wYeLx/Ng5a7+fNlk3yZh4dk+l9lS6FeMNx2Zw5N9B0bmCDFzuCkcK4c349Ot5d+0SGE62LKePYQ23d3tp0yMI4LRumW4nE3wa8W+zsWHITHLhzOfWcO+s7362uOP3dkH/Pwww/7Pi9ZsqTH+WXLlvU4NnDgQLZs6aXgoEJxPNNbn7zuVO+GlybCbWtkfM93ZenfZRXzbR/6rDA9+PAGWdfopsB6WbpFyd3uP1SyHt44BybeCWc8SmFdCxNN2whuioPgVilk9syHjf+DGc/64o9K6lu55rU1vDSqgByQLrfA2C6jorq73V8PKtAS5nGjbX6HmhY3hlPny/mfEDvARSrgbnX6/iPfO/+fZI+dJksy6CIsTLT5LlWbdibbt7TRHBZHnKub8AyNk+5BgCZp/XnRfR7TRmaSs/05CpbGkg6MMOX7psz0nMHl4/qxYGcVv3LdTbDJQ+2iQlzmk/i9dRYhlr1kF31NOzYeKZvAxicWs8CWQAal1GuhLG/O5ixNuvAAtOYqNnVGEGQxcd3EdFbl1bI6v45BiWHM/83JiHfSoHZnl2UPTE3k4knJ8L50f2YOGMS49GhGpUUyKTuGrXNk4P+KugiiQqxMzonnow0lhAVZSIuSLkafS66jERCgefjFqSM5bdo58IIstlreGcyo6BCyMqVljbBEkiOlOLCZTYzuH4Xt1N/ywifL8HSYOXt4ki84fHxGDLM3lVEw6GbIX+ezOiXq500CLhmdSnfsVjNDksMZkhzOqgemkhghx1vMJp66LBcaV0p3c7xsSfSPK0ZR39JJalTwEbP2XH6CtOpNzPJb3nL0oPYBCQ5uPjmTd1YXMTwlwndeCIHFfATubwuRsX2HwaTswwgJOAZRIkyhUBycjib5JXWkMYKoTQFNdBc8Asue8deL2vCmtEbtmgMn/ea738OoRxV8gCDcllpZHd3m6D0QP1CE7fxMbl1S1FQW7OId22NUtUeBq78UYS21svhmZ7Pvna0rqCevpoU5yzZIEdbeQMn+raRmj9TX4C9N4BNkgSIsbxHiszvY5RlGnO5ZmmzaTFCTtEZ42px0akGEiA6y9/4H9v5Hvr8AS2OzFkxIRDRzLKdjMQniU9KhoKsIazRHEh4aCwhA4yvPGJ5yX46whpLDc6SWzpengHrNwQkd/yI2PJSF2bGYTQKXCOaWKdl8trmM16vO5CrLAoZvehjRXMb2iMmsqwTQ2OtJJMNcSgNh3DevmCBxAlND8xAt1cQJJ6vbLfxpxhCiQm1MyIphdX4dN5yUIUVFeLdYOuD/pg3HHObv2fjr8ycDUqhcOCqVQdF38vArTbxZEMuo/g5G9Yvkow0lDE4O97nXAIhMk8JV08BZjAiNIyEsigdt93B35yvkacn0jwmByAhZ9yvtREJsFiKCreQkhmG3mmHANPqdlsMVRfVdsvPOGZFEaUMrN52aBZYisMiCpUIIFtx9KtGhtq5r6QVDgHUhPFn+0XEEWXqNifohpEQGc283C1NmnIPLxqZy7ohkYhxBfHDLRKJC+74Z9k8R5Y5UKBQHpnY/PNEfyo+CpdYoWRAc6T+27Bm5NZodG8HlQQcOjgdkj7x1r0tX36KA5BxD1JgP8MWUr7d/6WymubqIcmebdA8auNrlO9A0GfcFrCl0srXESdq6xwFo9trRXK1SfBniqa3Bd4m9VU1YTIIorz++bOXiL7jtnQ28u6ZIxoMZ6GUkWqvy+PPsbTJwfK2s5D7SlIdbWFgvhnKSaRthrSXy1WjthIiAoH7wF2LV2a8lsXTGYt4ojGZCVgyhMWl058U1TmkR1F2iNbYUhiaHs6zajjOkHxbhD1qvsmfiwkJaTCh2q5kBcQ6y4hzcOTWbBXefyju/nsKqwX/C4iyEjkY6RspGzWF2C/s1KRoatFCaO9zsOuVFxBl/kc+Ci8H9k/nleOkGvGxsGjdNyuC8XF1odE9oALJTEyEqHYSuULsJtUH9Epgfej5eTGTGhjKqn/x5G5rc7Wdq6IWyrpgxXxfu+fFnMKr9ZepFOMNTI6Rr7LbVkC2TSe47c1CX7MNLx6bx+EUjulw6ItjK76cPku46XYAZDIh3EB3aSybsMYzZJPjbJSMZplu/hiSHd3HNKg4fZQlTKBQHpqFIiovGMkgacejxB8LVLnvRTfqtrLAOsq8dyKKf3elsBku0P97pUOUS1r0umyu3NciefifcTAMO3FUVxILPeoWmwSe3QO4VkDkZ8hb5LvHW51/xekUGK2/N9v/HuOV9GUg//XGol264kvIylq3I57E62bqmkRC0jhZpJDIKj7Y7adpTQNvcBzi/XaMg6nrOioHSwljMeBhQs4DfNwxDAFeEBIgwTbbf6awp4M2CQvKqWzi1YCuTLBAuWqnwRvOteyi/t86iqrO5yyvwnvRbvli1ibM9C6UFL0CEtWh25mwuo6C2lRtPzoT2ng2Ll1cIdpQ1kmyOJpJakjKGMMoRyeyNZeyIGcWE1iI2egcwyrSPrGHjuE5LZ7oeJ/TQeUO6XGtUvyhG9bsRWi+Emj2MTT6BR+xFJEXY+fod6fatJ4yUyGBunTwAdvldjEPSk30WyeTIYP40I+Da4d1cdsIsRY0QUoh1tvQQOUIITsqK5eONpWTFO8hJCOPi0alckNtN0J38O7n98AaoCveVCOkfE8KyfTC6XxTxYT2tUVeO7xmnplAcLseNJUwLzAo6jvm5PKfiGMGlCySv6+DjDkXldtg9D1473W/lqi/030PTuhYTNdrOGC41t27p2f5J70H2LTVSzBnlJIpWsmHuf3A113R9jsYy2Stw1ctyv2wjJAzXl7ON6qYOdu0OiDky4tbW+TMfI2lmw95i7F6Zoh9CO5pRc8ulb6t3Yf7galwNZTjay3m29QGS6tcSl5zB+uhzGNG2lmRqqG/txNUUUBpCJ9xdgxkPy/bVMCbcL6ZqtTC22GRj43itFneYX0iY4gfhyJLZc/mFBV1KXnhtoczeJOO8JmbFQLgUYd4AC2OtN5yLX1rBtgYpPnJzRzMyNZKmDjcfN0hLz8eeSXRaHFjSJ/LweUNlLShkFl+vZTpCoqHfidgsJq6dmM6UQfEMHzkOgDPGDObbe06VFcxtIf45toNkuBmWMCN2zubwu5DTToCkkb1OO2mAXFtmbCgWs4m/XzbSVxOrB+Nugql/9u2mx8hfAAID0xWKI8VxIcLsdju1tbXHvUDRNI3a2lrs9kNniigURwTDShVYRqA3yjbJml8HQi/sCcDWD6TLr6UazEGAJt2Cc34bcF/dymNYwlxtsh3NB9fBQum6Yucc0Hv40VqL5mrFq1ctd83+DVO2P+Br7IurDU3T2L19vdzPWySv2dEE8YNwWcNI80r33u7dAQkDhkiplfFTO7QMok0tvoxDDyZCRAfC3dWaV/nNi4S46rm28z4u6XgIm9YJTeXYIpMoy7gEAVxgXk5jUwsVJfld5naGJGJC45Gpifzh7EHkOvyuzVotnOzcSdQ4BvKR52S2DQnosmGPZHS2tMp8umh1l2vagsPp9HiJddjIjA2VzagBU6TfimN2xNLm8hCfJF2VUSmDmDIoHotJ8GnrCL5IupXMaTfTescOGPb9yopYzCaumSHdeI7oBFlJH8AaYOk8WPyhsV4jSSPQQnreP+Hy//U67ZwRSdx35iBOOZxmzf0ndqn+PzY9iriwIM4e0dN6qFD8UI4Ld2RqaiolJSVUV/f8jfJ4w263k5raM4tGoTgqGJYdj/vg41a8AMVrIPt0GaAe1s1qULNbuo40jyy/0FIFaBCdCdU7Yd69coyBYVkyLGGuVpl5CLDlA9nUee7vaIgbS+X0l8lprYXOFpYWtHIqYG3r+n+B5mrjj59uw7puAY9YAXcbxRu+IM3VCrZQSs1pjLbkMyUzmvqi7b553s5m32+qTi2ECksyY+2lJNTL+K7WsHTCGyswdROp9vpdtBBEvkjDo2k4w3OIaNwNYUnEJw+kaF08g02FXOH8NWnOii5zC71xZFPBeQOshKdnwjJ/uYr4pFRunpzDsn6f8rv3N/FIQz25xsngSBx6VmdB3m4ICDMKdkRADYztL+tQGSIMRzzU2MBi54oTB7KzvJHs+CFQvxQiUokxmZmcE8eCnVXUjLyV60/spT3SdyUkGq6cJdsKGRyuJSwqHS57S/6MfX5nVxF2oLg/ZJbhrZO/R3Yt0rW69o/HWDFhxXHDcSHCrFYrGRkZhx6oUBxtXG3S6nMAt8ixyGPzdrJkT7UsAdA9O/BwLWHtTimU1r4Gi5+Ae/PBFFAksnqPrOzeVC6FlVEzKyZLijDj+qnjoGSt3x1pWMLc7ZC/RPb/a3dSseJ/JDRXsqe1mKc+Ws8HHY0IIMTj7NW+X1xWxkk77ibG2kqTFowNN1/O+YBrbU0ISzDvtY3jfjGTp8VzVLu3U2VLIt5dTmNdNYbTqsaWwpSRg2DHLs7LAErBHJtNSFPPBtQRopV8bwJ3TBnAzBUFmPuPh627wR5BVpyDfC2RgaKENCp6zN3UHEW2BcK99bI2WGez77kHZWZChJ34cBn3tLHKi6+6kz0SvDKm7NZRdtgOLs2MVXgIj5CFLccZrVoMEWaPlNY+ezi3naYX1mzLkEHq+t/fpWPTWLCzyldT64gwcHrX/S6WsEMU3BxyHuz9Wn4+VKygQnGMc1y4IxWKY4aNb8OrU35YIdLOFtg9/8itqaNZFiyt3N7radfyF7mo5mVW7K+FfQvgnV/4K6/7LGEBIuzDG2Dn5zKeqna/fo8mKZSayqUg04PCfSECNXtkc+qgcCmsDBFmtOZpqoDsM2RLHpDCw+vxl29oroSiVTDuJjR7BDsWzUKgYXM3UVJa6lvaQIe/pMRqrz+gu37/es4xr+FEtrFXS8Epwkixd2D2tFHcJHi5Yzp5I35HdOEX5JiKebv9JAC8RokLwJE0UDaAbqvnysHy91dz3MADvvYWWxy/OiWLjX8+A0eGnozgdZEZF0q+lkSOqaTXebH99HIAexfAU7r1pr9cD6EytskIEF9X4fFPDI70ufIGBcv3Xym7GZIUH8eV4/tx3kg9yzAkWrqC7RHyT2iAmy44qksSxvShiXzzu1MZkXqAGKojQaCYOpglrPuYwxmrUBzDKBGmUBxJGktlXavWXoLHPe6ubWUMFj8lhY3B1g/g3ctlEHl3vJ7erwHyuNfT83hdnixYWrC812nTbVs4z7yClxfvh/0LZR9BI5DdyCoMrBy//VN5rdm3wzePyGMdjXKsMb61jo1F9Qx9cC4b8ipx1+6n3NZfBs63O6FZirBioYsCd5sUA7oVpHztbPh/0b5sQW/tftA8VNgzaQ5OYSTSdRlOKxGaX/BGeBogYRja9McYetUTaPZIvAiCOv3lIToisggNi2BAaBsmNDZXuQm3W0id8QAkjgAE035xBwAOr7+dWEL6EClQNC/U7AWbA2vkgeOEhuUM9LeMGXk5THkQTvoNITYLI0b6XXHPuC5hXs5jvv3TTtQF25b35FaYZXsf8ImlBN0S1qQFuPHsfhEmWxqBxyHfry0knMcuHE5cmJ45KASc97yMfUoe1dU12AtZvTRFPqIEuiMPpyadMSZwnkLxE0SJMIXiSGL0Gmxv6Hrc1Q5/HwhbP+w5p2iljKcyMFrmdLemaRo8N1y2kOmNVS/BC718mRqlClqqepzSNI1QTxPxNLC5sBrNqFmlt+Yx3JFvLttLXn4eeFxSGLnb5Pqa9bV2NPmLlAK01bF/01I2mq9l2YJPsOBleUMUDV47rlYn7oYyvJrgzZ1+Qem2hVPdIS1Mcfmzu6yzo0EGwq8sbqfYG0uMkOIoQrQSLQL6rnY0QvwQxITbcOSciri/kHprEnHC//cxYcLJhIZFEi/ke9lQ3sHZw5Ow2axw2Uz4xVuMGCozJm0iQNRGZ0oRBjJrMiwJUy+uM69R0TQwLs5shVPu8c0fO1pmCHo0wb89M2gbcJZ/bHgSmG1SyDsS4aE6GHgWJAyT7lrwFeRsRq/NZLHL+lVGIkGjtA72z9DrV/VmMRp5OSQMhUtegzMf73n+x8T6HS1hxntX7kjFTxwlwhSKH8iCdTt4c77eospwX3Vv/NxaI79UyzZ0OTxrXTE11eX+QHTwF/oMPGbsN5ZCVde2LT7KN0N9PntK/XWnNE3jm00yM7GirGc/wvpWFw5aMAmNsM4aXI26qKreKetp6c/RVF9Jv7cmwJZZ8ryrXQoxn+hs7Lr21jrc5VsJEm5sJSsAmFsg2FDppaa2msqyQmoJZ3O1X4StKnUz6bm1+sL9hUEBRKtc17ZajS3N/tikCNHK8Khu5TO6WUdswQ6i0MXh2U/DmOvB5sDhktbKNoK44gQ96y46EwafK+OhjEr+wgxZUyHjFL8Iq9whxVIvIsBrlI3onpwQSIyMvyrQEunARnJ0hP9+Noe/fVB0ptyGxsCtyyFeuiqFEPz1wmG8ceMEOd6uuwqDurU9MgqPHirOqq8xW6TwhMNbqyE2lQhT/MRRIkxx7FCwDN67SvbVO5YpXiMrs+tuwUlzT+Oa1efKc4YoaetmCTOOO4u7HJ65ogBPU7Xf/Qd+K1q3Ypx19YbAq6M7ZQ1tNFXLL95rXvyK2mZZI2rBzirmr5Ouu5LiriKsqd1Ffk0LEUKKvSRRi9uoWbVrLmx+Vwo7IIZGLN52f4Nod5sUYm11oGloRgB9m3+NbfXS5ZilSddYqctBEyFo7Y04q4qp0iJpcPtzg3Y1mOjAiksz+6qzf26aQrU1BVuHfH+rSzvZ1R7lm2PBzTVDAhIAoKtVBXA4wny9CRl4pvySDwrDrAu76Mio3oPOLXopmIgUuPpjiEj1izBPhwxuD7DauPQ8J0uMHufmOIgIC0/Ba7azR5OZzqlRwX5BYXP4Yr98IqwXrhrfn5Oz46QgMboOWGSmIx2N0r1rCEHbUWg7daSx6uJZxYQpfkYoEaY4dshbJHsEdvyAoPajjdcrg9z/MxW+fRQAuyaDwTvcHr/YKloJz4/yu+uM4w1+EaZpGgU1LYR5G2VQuxHP1YslrKG1k6te1BtM9xJv9vi8nVSXS5Hl0Jp44dt9nPb0Ip78YhepdhlUb2mrYUeZ/92OeOQrLn5pOeFIAZgsahGGO9KIR9PdWqFCD3j31e1qB1crWls9e4rLEXpphI4muTZPSy1Cd6sOFPKZO2zRWILDsbmbobmCjuB4WvFXN9/XZOaOKdlouhjxxg/lg9QHqPU6MCFFWZNmp9LUVdykeMu7voxu1hHRW7yRzeGLc7thyrDemx1bdRFmDZgf7BeARGd1uZclMlkKnxC90fHBLGEmEx3T/8a/3ediEnpfQFuAi81hWMIOI+vbHuG3hAU+Y0Sa/5rHuiUM/O/ycGLCLDaIHXjYzZ0VimMVJcIUxw6t/sKaxyx1+33B4pRvobXTH7Be1djhF1t7vpQB8dW669BnCZNWIWebi5L6Njydrf6+f4bo6kWEbSpuwOLW97uLsHd+wZN7ziJOk+8vkmbeWFFAfk0L+6qaOSlVurlihZOFu/1xYZoGobT7rE7JohazbsnSDBGmi64Q9DUa8WWdzaB5EJ5Obnlpru+ahghz1lYSjXyONFGNhuDbBy9i5IB+hNFGrFZPenoW4WH+iu1OTfb1swXLY6bQGAYlhtHg8lu6WrRgMgd0bSbsy9A06B6sbQ3oaWd8wQeIkoSYAzT3NixhgfMD+1yOvqaLCBPZZ0i3pTHmYCIMsI+7hu2mbBLD7VjNpgBLWKg/W/EgljAfGadAxsn+/UARZgjCAzUwP5awhsiMTfNhNoK+fS2MveHQ4xSKY5jjok6Y4jjBECquXnoJ/lh4XPJLPX5Q7+fLNsltSAx0NJJX3cIw/VRVUztphpBs0F1/RokFX6xUDd6OFi58UcY+RRMQVO7S2+7o7siKmmoSK7ZB4jC2lDhxCH/mYRf2fEEIYMSDR4gW0OCi0SkkRwQz0rUYCiFOOMmvli5Or1dargwrGMBASwU23arndZYR6OTz3dsX++WPebtztA306hfB7kYQ0FRfRQxyrElodNqisFksJMTFYxUu4mmAxHTuzMmFz+TcRkIYmRrpF0ghMQxMCKNV81cdvX7KcM4ZFgevIN2OrhaoywdLsHSRQg93pE9EWUP9tcsC3VjWA2TYGT0ILYEiTLeEJY2UMWEdAX9/k+6WrsuvH9JfWkLv19URQhAVYiMlSr9+ryLsMCxhZ/+t675PhKVK9+tVHx745/lYwhby07DYKRRHEGUJUxw7GPFEfSnCZt8O/xrfM7DeoHyTtJCknkCTs46XFvutMFV1Tr8QMGjVa28ZGY/Alh07yKtpIa+mhaiAzL6PVu6SH/R75y18C14+CbbMYktJA6HoLsHuIqwbQyK9WM2C30zN5p7pOdhc8h5BuKislpaw+lbpojTiwQBGmP0xY6bWrpmUoaKrJayzyW+NuyDdHxhv1bMJWxuqiDP5ex5awqUgsYYGWJIiUjgz1y8yoqPjiHEE+cVISCwTsmJo10u/e4WZ204fRnpyIkT2hzSZKUhjCUQFVHLvYQnT9wO/4ANdXgcK7u7NEmYJgltXwg1f9Zxr3HfweXDibdJNeAgmZcdySnac/1qWYCkUY7OlaIz+HlXejaD1yDQZ8J59+ne/Rl9gDVUxXoqfHcoSpjh2MIRPZx+KMKM2U2td1/gfg7JNsg5VcBQtjXXMrSrnRf272llb2XN83iKYdw9E+cXGuk0bgWRAdCmv8NrC7YQm53CmbjXrZ5JCSNv5GZtLrmMiusBztUiXbaA4COC8nGCuPm0K8eH6wtr9Yqi5VroZa1ukCAtHF2GWYAa4/T0MRbfsxHibC1ygdTgRgBYoUut7Zl22OavJMjWhh4phcuhCI6BhNOEpYDJJkeRq5bErJ8njNr8lLCUyGC0jEYrAaw3FZMRu/WoxOEulSAVZ36taF7HdRZUhproIr4Av+wOKMN0S1v09J/iLwHaZa1jgUsfIP4fBM5fl+ndsDv/1Rl4hrVj28N4nHgzjHUf8xNqbBYV9v+dVKH7CKEuY4tih9ei4IzvdXm5+cx1bS5wHHxiYldk9u1E/7y7dyAJnEqvKPYRqrfhUBtDc0Evv0pJ1clufj6b/c7up8Pe8HfsmJqExINRf4T2YDu59f72vSr0hkDwVO6lu6iBMBFjZAqxhbaKr5SepI5/4LS/7i7q2O0HIe9vaamho7aSmSVq2pmborr7kUb2/Ex2HSY5va5T3DSKggn5DTxHmcNcTHlBE1ZftF/gla4gE3VIVFqGPMcSSHs+UGifjmSzBAZal4Ch/8DrIeleil2bQAdfvIsKCDscd2UtgfncM0WSyyGDxH0JwpD+ezGT2v7Pvis8d2e/g4441Jt8P0x879DiF4jhCiTDFscNRigkrrm/lqx2VzNnqr0C/cn8tO8u7ZWFW++tvzfx2g8x2DGDFujVY3C1805DE6jIXYaKNv57ld4O1O6UIa9ICLCfN/t6AeV5/jNCk5i/5U9JaRkT773FlbjTTMvxf5OG66LLU78OKm8zwgEr5RgC9pmHS/O7ANs2GY8e7sOAhvzhqd0r3HTI4P7+mhRrdEnZ+ji5Ghl/MwbB55N9JZ0sv4rQXS1im0DMmjXiqEENgdbOEgd+NZ+9W+ylUDyo/UOmCQHdfXE5AduEBAvOPlCUsELNVBpN3F37fh8n3w0Wv/vDrGM8ZmfbDr/VjkjJaJhkoFD8jlAhTHBu4O6FTd80dZnbk0r3VLN7Ti/WpG1WN0oqzs1xev63Tw81vruORz7fz4KfbGPPo18xaVyzLSuis31XAmnwpdJxtLn7x75W8/9kcAK675AKaZCg8Vw32Z3J5mqU7skgLsNAE4DRFMrXjKUa0v4IrKovrYnZywUB/iYapYh1Pup7ode5wkUdWYIiRniFZXe8kCCnCNJsDc2SAC8pICmh3yhgjpAjLq26hpqmDuy2ziNv8ohwzaIZvmlv0zE4zu6UIC6MXgdyLJczIuPSVEDACzQ2BENCiCGuo/GMOKFYK/sw+nzuxmwiz+N8dsQP94qu75conwgIEoLEOYfYXCe3xEIdhCQN53yPRPicqXQqRH0pEqsyGDO3951ChUBw7KBGmODYIbPPTvVK8zhfbKqhs9Lvvnv5qD0/M33XIS1c1yTmG5WvOljKaOtxsKXEye1MptS2dPDpnB1qT32oVIZpZq4uwZ7/ew5qCOq5Mq0MzB5Ez/ASmjpQVz42SEwAupxRhBVrvWXFRMfHs11JwRMRijc3C1FSOCCg3EbnjLazl63udOySoikR7QP9Gfd7eImndq0mfgZj2MLawGP+YknXw0kngLIJI6ZqKNbeyYn8tjY113GKeg7lunxwb0MDZE9Lzy9uoA2YWvfSt7JbEoAVaheL1+Knu7sjwALFoC+lq1QrqJsIOp4hnVPqBx/Xmjgws9tlbjTAIsITZD3xf4xqHEmo/JifeCretlvF2CoXimEb9K1UcGwR+kfdiCXO2ubjl7fU8+Ok237FKOEjlpwAAIABJREFUZzuFtS1oeuxTUW0rb60s6Dqxs9VnCatu6uCpL3fxzNd7EAJaOz00trsZEO+gqd1Ne3s7Rp2HSaZt3L3iBMp3reWtVYVcNb4f44OKEAlDwWxl4lA9a63RL8JCOqUwKtRkfaimoK5iLDZO7p+QES2rrTdVQGst7qBIuuPSZHxTqUk2iB4a2oiDNjo0PZdGjwkrKpOFSkOGniObMQcmE+yeC5X6+wqJBZuDsYkmPttciilvMTYRIOpMZvj1arjoVWyhh87qOxgi90r/TqJewCO0W2B+RIp/jLWbCPNZwnThZu0lsL47JnNAiYfDcEcGHcB1GYjhSj2kJSz02GokbQnqGi+nUCiOWZQIU3w/2uq7ZN39YALLLrhaKG1o4w+fbKWxXbradldIV+JXOyrZU9mEx6tR3dxBa6eHorpWqhrb+feS/Tw4eztVTe3UNHfw/Dsfw2NJRBV94bv0iwv3ExVi4y8XDPMd+8VYGTvjbG4Fm4N2YWe6WQbU1yx4Bk3TuH3yACjfIutDgd+iE2AJm5RixoOJCk0KoVKbLLTp0aSwC4uK565p2Vx/UoYUYS3V0FCIJaZnQU5XqBRsFZ4Iaokgw+YkhDbKtJgu76ugVFrCQiKMopwBIqx8i/+zXlV9RIyGx6uRULHY32jaIH4QjLgM8V3KBBiuvMBioLHZ8Pv9Mr5p2MUy6N9wsxkiLDxAhA2YCjln+vf7nQiZk/3CrTcRZTD2Rphwu/xsiLADuiN7sYQdTGAdTkyYcd8jEROmUCh+digRpvh+fHgjfH7X95ra6fbi8XZzawVYwtztLZz+zGLeWV3Eyv3SurS7wij8CbPWFlPb3OG7xk0z13HOC8tYvq8GOx2UbV3Mh+tL2L5NipBhZR8REeyPc/rs9pO48oR+RIVYiQqxcvoQKXiaWtvAbMWJX4REVq/l/1KLSQxqhw6nv4J5UE8RNiLegslqZ7l3GPvjTmeTkK64nZoevB8cyV3TBjIyLVIW+kSDiq2QOLzHOwqJlXPqvKGUeqNJFrXYva04cdBpCYOWat5Yns+OfP3+hiUpsH1NoIvXFgrBkYR6m7l0TBoTTdtZYR7X476+sYB2OO1jhpwvt4H9LK3B0v044jJZNf7mRf5MSLMFxt0EQy/wj5/0W5j2sH8/4xS4ZrYcC36LVG/icMYz/P/27j1Mzrq++/j7O6c9ZzfnhARygEA4nyJSQCuIinJq1Sq0SrVWWlq1PlWfQlttpfb01Farpe2DPrXaWoWiIu2FBQQ8gpIoB0k4h0BCErI57G72OKff88fvvnfumczuzsbM3rM7n9d15dqZe++dvZPBaz5+f9/7++MNfx783nA5coJhrdGfH9++aLIQVmVOWDWnXQWn/crk54iIVKE5YXJ4BnZCITv1eVW8/eYHOfuY+fzxZZF5S5EP8Rdf3stw1t81+Pxe3x/25O6DdLWmWDm/Hduxkf07Sktpz+zxU+D3UuSBlg+x/O79/O3Cr5AM/vPuHn6edUs7ec8Fazhr1XxSSf//Pd624WjMjJXz20gnjcHhYVwyzYFiC0uDItHR1ssNvX8AWyo+kMPQEwlhZIcgmWZ74mhuXftn5B+5BYDn2k7llLFt5VWqLr/MiCv65vVw4vvKc2DVecHejQ/STwdFZxxX6CVT6GHQtdJrC5i3dzuffOhprjsqBXsphcL2oCKV6SzfADw34gPaSB+//6Z1zP/Zfja1XgjFZ0q9V6EgxFjPqtJy5kRe/+f+mhNJ+J8b/MbWqSlCy6V/O/n3K01WCYvKdPhREZWN9lP1hE1kvBI2xVLjK6+d/PsiIhNQJUwOT24I8mM8tqOPb2+pMqR0Atl8kcd29PP0nsHyb4SVsFQbI8P+e+2ZJM8F5z21+yDrl3WxakE7f7T7Axz/n6855LWvSt7PcvNhbtfO7Vy23leFlrOPqwt38Ma2zSztKt1Rd8ObTuT6xL+Ruv23OGZBOyMjIxQtzYGi/2B2S09m33Fv9ieHeylOGsIGsWQLCzoy7D2Y5ekh/+F95VvfBa//BJwUqf6EIQxg4bpSRWb1BfC6j4/3LI0kuzjqmONoH32ZRG6Ijq4eto518/zWZxgcy3PpuorrOf0qH3IWB9vUrLoALvoonPkOP4NqtI+l6REyVuDiV5wKH3rKT4CPGh9xEMyZSk3SmJ5u9SHkFe+JbHg9RSP7dI2HsCmWScNlwcpG+2p3R6ZafGCbdDmyxkqYiMhhUgiTw5MdgsIYf3fP03zktkfHm+On8uL+IQpFx/6hYBucsUEY2udDmCWhcwn5kUG6WlOcuqKbrXt9470PYfM4dr7/TzYRbKLdkfEN7BefuJRLMw+P/55uhnjV6tKy1Fv2/hP8+1vgJ18ov6DNt8MLD7BmUSejo6PkLUU/QSVo4ToW/lKwL1/Ys1b5gV4WwoYhmWFBR4Yndw/ww/yJPHDqn8GxF8J57y8fvlkWwo4t9RSF5wTVqHdeeAannnQSjA1gAzs5c90xrDvueJayj3VLOlnVEcwZC0PY/NV+uS98nQWr4dUf9gEmqIQR3AXatWilDyOVQ0bD5bxgrMWkTd7Rqtd4I/sRDi3VlhOrWXVe9S16wgpkR6TiZxZMqK+lJ6yBmu5FZE5RCJPDkx2GQo6ndx/kwHCOl4M7EAG27Bzggr++jy07Bzj/r+7jyd2loajP9frlxf2DWdjzBPzlCvjSlZAf8x+2mQ4KY0Ms727l2CWdbO0d5O4tL3NwLM+ru3s5OV0aI5EwOGvVfBZ1Zvjnq0/h/NRTvNDqK0CXrG1haVtpAn42EVQ1BiN7Ivbv8Hc3Dr7M8Us6GBsbZcwl6XdBCOleWQoA4XJpGDRSGV8pKZYGpYbLkQs6MmzeOUCRBNlTriptGh3VvhASaV+N6VlVtl8iUAocrT2lJvbRPsh0suzoY1li/XziihOwsX4fXiv7oMIQFm2ADyphBPPMJtxgOvzdJ17he7OOmmB2lSVKs72gVAGbajlyulI1LkeedQ289f8denzpyXDNHbD2ovLj846CzmWT/N7W8q8iIkeYQliz+u7fwA8+fXg/WyxAfoRCbpSd/X4G15ZdpTslH95+gB0HRrhl44u81DfCo9tLDeJbgxC2byiLu+dj/uDLP4NCLlgeaoPcMMu621i7sJ1XjD7AR275CacvSXHxD97OBU//JQAFEizqbOEP33Qi//CrZ5Ha9VMsN0TxRL/k9/ZTu8ZHXdxZOIfbNnzFh5VCJDRt/3Hw98lxwcokSZdn/yj0BZUw5q0ohbDxSljkA7mlYp+73BCk/HJk6LglE1RvEglfDZu/xjeghxWZsFoThqq2+eV7ALZ0QtdyDMcrF+f9Haqt8w5dggvvLIxW3Fp7/G4E/duD700QQMYDYLe/S3HCYaZt5b93vBJ2hEPLvOX+vZu/+vBfY+0vHjo36x1fh9d+dOKfUSVMROpMIaxZPflf8NS3Du9ng22F8rlS9SucRg9+fhfAA8GdjXsiVbLnen2P11i+SPGgr8gUulbwyLY9DOb9Zs6WG+Go7lbOH7qHmzOf4orCPfz1+WCFMebtexSA/a6LZd2tnLh8HueuXQjbfgAYa151FRDsuxiEsJ53fom3vv41vmoTrVxtf2j84VkLsrRYgb4xR/u8IAh1r/BVrGRmfDhq2QdyZYUkOzxeCQNYt6STlfMn+QBfcZZfQou+bnv5ciRtPX4afDhOItVaqm49+hV44r8PDYNQCmGVlTCA3qf814mWGSvvtEweOkHfX3PF3z8MLUe6EtZzDPzv5/zoiiNp3vLy+WSV1BMmInVW1xBmZpeY2VNm9qyZXV/l+6vM7F4ze8zMvmNmK6u9jtTB2OCEk+mnFPxcMQhh7ZkkWyL7MO4KQlh41+Keg6UQtrW31JDvhn2F7MDBIZ7aeYCBHIwlWkgVR1jW3cq6Yd/jdd0FR7PebS27hEHXytpFkSW4wZd9yOg5BjDfY5YbhkSK845fTiaV8Mt/hciA0u0/Hu/Fah3tZUEr5Eixfk0wUiKc6p5ui9w4EAkeYYgJl7SyQ5Bs8b8LuGDdFBswv+2LcMVn/OOw+tRRsRzZNt/f8fjuO/3fbcXZfhkN4L5P+L0pB6vcGBFWwHoimziHoWrv0z70TdRjdepb4c2fh84gyE0UwirDVrpOPWFQfmfpTFl+mp/4P9v2YBSRWaNuIyrMLAncBLwO2AFsNLM7nHNbIqd9EviSc+6LZnYR8JfAO+t1TRKRHQRXmPq8qj/rQ5jLZ2lLJzn/uEU8sbMUwnZHthaC0rZBzjme3TPI8u5WH9TG/BJmijxnrGgntytF72iKdsY4qruN1FZfsVkxLwU7Hyl7za5kno9GR1xk/aBVEkm/PDfS5x9HK1eJZKkSlh3yw0xPvBy23A6De1jSkeDFXIaTz7sERh/ww0vBv8b4cmTk9X7pH32FzBXhXy/1IyaSGYrB/LLzjp0ihEVlKiphK18Bay8MqmD4itkHf+YfRwfbHnNe9U2PT7wc3vG10t8BIpWwJ30/2ETb9bQvKJ97lagIYZb0/+0cUgmbY5WjZafC7zw49XkiIoepnpWwc4BnnXNbnXNZ4KvAlRXnnATcFzy+v8r3pV5qrIT1RqpYAH3DWXIjQTWrMMapK7s54+getu4dYv+Qnxv28iEhzL/G83uHWDe2mcvXGuBIZn1wa0sUOLo7TZ4kLw1Bq2VZ3pnwjfvgq1C7Hilrol7UkmdhZ2QD5+xgKSC19pQqYdHKVTJd6gnb+bAPEide7p8P7mZpe4INa5fSvuIUeOfXIxPY23y/F5QHj8Un+HAU7ZlKZXj/Rev4qzefysUnTmPrmExHsAdh8PoL1sA1t5cm80dFq0LX3A4X3nDoOck0HHdx+bGwEtb34sRN+dVU9oSFS3gTVcLUyC4iUpN6hrAVwPbI8x3BsahHgWAQE78MdJlZxeRIMLNrzWyTmW3q7e2ty8U2lWLRh4qxwUlPe/ylfl75F9/mGw/7MQyFouONf/99/uKbfkufNAX+9ldO9z1ZwEPP+76p3f3REObGe8Ke27KJr2Y+wW8Mfp4ORjFXJO8SpCjQlihQsDTP9zvaGWN19mnIB68zsNMvoZ3+dt+8D77yFZUbLm9mH+3zPWHRqkwi0hMWNuUfe5EPb4N7oJjDqjWhl/WBVanyJCIF5WSG7vY0V51zDDZRpamas94Fl/xlbeea+V6vda8v9WHVIqyEAXRNJ4RVVMLCEDbXK2EiInUWd2P+h4FfNLOHgV8EXgIOWSNzzt3snNvgnNuwePHimb7GuSecpJ4f8Xc6TuDff/QCRQefve9ZCkXHI9v72NU/ynMv+R6kNHmO7mnltJXdtKWT/GjrfkaCTbF72tOstF62tf4aJw8+gHOONZs+QdoKLN3zAxaYr4LtZx6JYg4r5kmmM/Tl07RZluW93w/mhi3zW/u4Iiw5Gd76L3D61T5MFSrGQ0Sb2Uf6fDCLBqhkqtQT9uKP/VJf+wLf23Vwt3+9ZJUV+mioqBYwoiFlojsJp7LybD9ioVYffByuvmV6vyO6pVHXUbX/XGUIC8Nc5b9FqjUYW3GY/wYiIk2mniHsJSDa0boyODbOObfTOfdm59yZwB8Fx/qQuvne071s2xVp5I5sbbN/KMsdj/rJ8P0H9nPWY3/K+vlFtvYO8e0nXua+J18mmTAuOT6yRFbIkk4m2LB6Prdu2s5Zf3YPABtWzec482/3tYlv0j80wnEHN/JiajU21s/rU/4uxwN0YzjIjZAnxYhroZUsqaf/x98Nt2Ctr4KBv5vtpCtLey1Gl1PLQtj8YDlykkrYnidKm3F3LvPN7YVs9QARXV6rFsISRyCETVcicejIhalEK2Hn/nbtP1f5d2rpAqzKcmTroWMrRERkQvUMYRuBdWa2xswywFXAHdETzGyRmYXXcAPwL3W8nqb10PP7Gc35itf7v/IwX/ru5tI3I0Hm23ffQdtt7+Dx7fv5q899ibfZvdz0qjzz29Pc9fhuXvrZ97jwmCS/ekZkxTjYP/Ly046iqzXFSPB7funMFZy72oe1tbaT3/vi9wDYseJNkMxwmf0AgGK4b2FumMU9nSRbgsrVns1w/Bt8oCoG1avwjr+wuhWMoBj/e0R7wsaXI6OVsKAnrJDzQ1rDuVOdSyYPYeFrJNLVB68eiUrYTEim4drvwvUvTm/m1vhya2RMRqr10OXIE6+Ac687ElcqItIU6hbCnHN54H3AXcATwK3Ouc1mdqOZXRGc9hrgKTN7GlgK/Hm9rqdZ7eof4W3/90H+8yc76B/O0T+SY/eeUl/d3/33T8cfX/L4h3ld8id84e6NDPT5/q5ju43XnLCErT97gE8PfoTrE/9ealKH8RD2tlcczY//8GKWzfMfzOuXzeO3z/EBa4ENsm2Hr4ptOO1kWHoypyX8yIk1q4JxENlhFnR18IE3nlF67fWXQXt00+ugMT+seOUifWGVPWFhY/4hlbA8DLzklzfD8Q2t3TA6ECxHVhnHMD56YYKZX9GfqdwCqNEcdcbks7GqCYNlOLE+1VKqekUde+Hkw09FRKRM3UZUADjn7gTurDj2scjj24Db6nkNze7ZYFbX871DbD/gQ8tA/wEIcsN3H3+eawbHWNTZQlvBD1z94XN7eVMmaIrPDfPaE5ewdLPfc3H1PMqXAYMQFrrj/edzxyM7OXZxB2wtTdF/TceLkIdMu5/lldzpZ4C1dgfBKjcEyeV+k+uxg7D+cr+nYngnYKarFALCMHTIcmQ4W6vHh62hfdAdWRFPpnzQ6nvRP+8JAmC6zffHJdKTV8ImmgQfx3LkTApDZss8GBuAZAusPKe0nCsiIocl7sZ8qbPn9/qgsv3AMNv3+xDW5krLeO2McNfm3YzmCqTxy37JYo7ju4N9F7NDvHp1G69I+L6sFMXyOxPz5SMslnS18puvWuvvDBwptff90UlB9a21u3yAaLhNT7D5NR2L4IL/BYuO88fbFviv8yLb74QztcJKmHNBCIssR4KveFXrCRsPYcF1pFohNxpsnTRZJWyCu/5my3Lk4Qr/fuG4jFQr/Nqt8Au/E981iYjMAQphs8GOTYeEnQnt3wq3/vp4v1S4V+P2/cNsPzDMifYCx1ipMb+dUb75yE6eebnUoJ+yAqs7gz6s3DDzkqWNsBk5UNbMX3aHYqXRfsI+osyB5/yx1nmlChSUhpMG0+0PEVbCovscVlbC8mN+5le4HBlOnXeF8uCUTPu7Qfte9HfxhVv6pNugMOZHYky2HDnRdjwVIyrmnDCYji9HzsG/o4hIDBTCGt3wfvj8a+Fr76nt/Bce8BPggzsKtwaVsB0HRnDbN/Ktlhv4aPrL46eftjjFQ8/v57P3PTN+LEWBFa1B6MsO+4ASCnutQoVJwuFon998OpmBA8/7Yy2REJbuKA9U1QJMe1AJi45UCH/m7o/Ct64vXU+wBVHZptVlE/Mjy5FdR5XCRHj3Y2Hs8JYj53wlLOwJi1TCRETk56YQ1ujGgu2Anviv2s4PB5wGW9s8v9dXrQbH8lz53J8ccvqbT+nh+KWd3L2lVB1b3J5gSSYIV7mhUt9XIu1fN9qLlR+beNbYaL9fGmxfWNrfMLoc2dodCTCuehWqWiUsrHjt2Qw//ic4uKv8eFkIq6yEBSEsuiRadk61EBYOIZ2gMT8xixrzD0c4Oy1cjpyLQVNEJAYKYY0u2n/l3NTn54IQNrKfsXyBHQdGOHH5POYxxLLi7kNOX9yS4wsXG7ef9ej4sa/+xlm05A6Wfn8+CGFdy4LlyEgI+/xr4cYF1a9lpM83ybdHRlq0zCttiNzaXf6BXjWEhT1hVSphocdu9V/DnrDOyHZBZT1hQSWsf7uv0FU7p+pyZPC6E1WAmq4SNo0p/SIiMiGFsEYXXfobiMy63fQF2FRlrFre94I98LNn2LZ3GOfg1esWcZT5kRP7W30FaMj5D9LW4ggrvvFmztjy16XXKOaDfq7g94dLjp1L/eOhvbVd+2i/D1rhkmK6w1dVMh2+F6ysEkb1pviFx8IJl/rthUKZihD28L8Hx4O7IxPJ0tJk5XJkMe+DZdjfBOW9XpOOqJigJ8ys1BeWnIMBJXxfWrv9v3GHdq0QETkSFMIaXbTqtGNj6fFPvuCDWKWggf/Bx5/h9kd8aDt37UJWmL87seP4VwMwZB2M0uKb7CtDTSFXCmHZofJKGED/jlLgmcxoX7AcGTTKRzejXn66n4Y/VRUp3QZX/wcsWhc51lF63DYfhoNQGA1c4XT4aht4F7Ll1Zxor9ekPWGT7IkYBpVqIW62C/9OmU647oHpba8kIiITUghrdNGp8L1PlR4P9uIGXyZXKFY9f74N8pMXDgBw3JJO/ugCX/lpOdaHsI6ubhKtXX4T74XHlb9GsSKEFSpC2MCOUq9W1MAu+Om/lZZNxythwXJkdEjoVV+Gyz9dMWOrxrF10fNWv6r0OBMJZ+ObTEcrYUFPWL6iAb/WSthkDenhz83J5cjg75bKwPxVWo4UETlCFMIaXXQ6fTgawjkY6sUN7uHyv/8OA6ORMRFBJazHBnl0u5/TtXReK2tT+31AWLkBgI6uHjJtXT5kRRvZobwSVrYcGWmOn1dlA+i7boA73gc7f+pfIztY3hPWEqmEpdv8h3lZT9hhBJjVF5Qel4WwKptMj1fCxqZZCZtiYj6UliPnYkAJ/03m4lKriEiMFMIaXbQxP3w82gfFHAkc+/fs5PdveZRiMag+BT1h8znIWL7Ios4WMqmEX0LsXhlMkDe/tJTp9EGpYuq9X4IciTwOK2FLS+ccc+6h1xp+SG+5w28DBBWVsHlVfmaKnrCpLD2l9LhaJSy6mXQiVeqxm7ASVm0D7zCE1VIJm8PLkXPxzk8RkRgphDW66AyssD9ssLT34ysXjfHtJ17mH+5/Njjf3x0533zV7KieIDiEdwSmMr6K1dIFLUEIC8dahIYjjfcTVcJWnV/lYoMguPnr/i5K8BWpjirLkaGynrDDCDBloyaiPWHBculoaeskkunSv+FElbBqA2OnGtYKkZ6wOVgtSszhpVYRkRgphDW6MDR0Lh5fmvzmA4+Mf/u3z+7gmhPh8ftv4eBobjxQ9eBDWLihtq+EBYHldTfCudf5ytHYoF/C7FoOZ7/Lfz+8+zHZEgxrrVIJW3baodca/lzfi/Dy4/5xtBLWUq0SNsWIiol0LYcVZ5cvpUZvFjjtbf7rirNLxxLp0t8lGpamqoTV0pgf9qnNxaAS9sJN9vcXEZFpUwhrdLkRwHyQyQ7xUt8I9zz0+Pi3V2cOcl3rPXwq+Rl+8MxeXD6shPk5X8u7W30f1MHd0B1s03PqW2HNq324yI344Lb8dDjvA/77Q0Glbd5yH/zC5cjoWIdqH8jD+0qP+17wX6M9YdWWIw93y58PPQm/eW95k350uezYC+FP+mDpyZHXn+DcKYe1TjGiIvpzc3HJbtE6uPzv4fhL4r4SEZE5pcbb0SQ2uWEfljIdkB3m3x58gYWUltg6sntpy2RJ2Bj3bdnJxWMjpIFuGyZJgeU9bcH0fFc+xBSCEDbsvxdtkg8rWvNWQP9LpeXIZAuc+U7f3F8ZVopF/3vmrfR3T4abZLd2l5rkp6qEVVsKnEy036uW75fdiRldjpzi7siuZXDcxXD0Kyf+XXN5yc6sVCUVEZEjRpWwRpcd8nO8Mp0Uxgb5jx+/wDlLChRJMJrugcHdJIJlyk1PvcDYSOluym6GfCUsrFBFJ9eDDx9hJSzVWgogYR9Vx2I/0iG8ISDVAlf+g/9ArrwLsJj3vWQL1vjnB4JKWGuPH/J69rvh+Dcc+vf7ee+OBFh6am3nRQNWtGKVmuLuyFQLvONrcNQZk7x2uBw5BxvzRUSkLlQJa3S5YR+W0u30D/RxcCzPecuKJLILae1a5pcZi3kA3Gg/u/f1EU79umBFgrNXzYe+rf5AW8X2QuFyZCLpg0ZYzQlHYYST7kf9qIvyOxmTYAlwwZyysYP+WhesgW3fL6+EJRJ+Jlg1P29jPsBv3lM+T20i0UpbNHhVDnQ9HHO5MV9EROpClbBGlx2CdAcu00FhZJA3nbqc+a7fV6k6gxAWNO9/+BeXkyiOsRd/F+Jn3riQlW15GPGbeVevhA37AJNqLVVzxoIQFt5hGGwGfkjAiD4f2uO/LjjWf+170VeVpmrmPhL7LqbbSoFxMmX9Z5FrTyRKzw83hM3lYa0iIlIXCmGNLjcCmXaGXAutjPELaxfC4B4fwtoX+CpVEJouO6GTNd1JFp4QjI/YfDv8zbHw+Nf882ohzBV85SvaExZWwsLKWThuojJgRJ8fDDYHn7/af82P+CrYVH1b0T6t6faETddEy5FQGlNxuCFqfFirQpiIiNRGIazRBY35+3NpOhhl7aJ23+PVvtA3uo/2l0LT2EEsP4p1LfNh6NGv+JEMW7/rv19ZLQpHLxTzvhI20XLkyAEfMhIV/7lEA8fgy/5r59LSqIiwIX8yR6ISVquJGvOhNKbicK9BlTAREZkmhbBGlx2CTAe9Y0kS5jhufsqHovYFvtI0OuD7scA/zo/6QLH8jPFeMUb7fDCqbKaPLhWmWnyfFxy6HDnaV73XKXosrIS1LywNZa02nLVSIgkW/N56N7VPNKICIpUw9YSJiMjMUAhrRLlReOCzUMiPN+bvHvFBZXFLzoei1h4fclyhdPfj2EDQ39Vy6J18lU35UD5hPtXqlw7DTa6hFMJGDlRfZosGlrAS1rGoNIqirYZKWPR16h3CaqmEHc7WSTC3ty0SEZG6UAhrRNu+D3f/MezY6MdDpDt4aci/VXZwt78jsW1+ZPhpsF3QyAEfytJtsMJv1D0etKo1rpdVwip6opKZ0rLiyIHqFZ5oZW1wD2DBXLBpVMKiv/NwA1CtynrCJqgKajlSRERmiEJYIwq3KsqP+EpYpp0XDgYN7gMv+a9t8w8NOYPBHYqpFlh9AVzzTTj9an+ssik81jeEAAAgAElEQVQfKiph4d2BYYN5q99bEmCkr3q4iIaa7GDQV5YshcNaesKg1NQ+oz1hlcuRYQj7eZcjFcJERKQ2CmGNKJx5lRuF3DB7RpO8NByEsP4d/mvb/EMn0IdjIlJtfmlx7WtKG1zXWgmLhomWSKWt6nJkpJqUHSoFkMOthCXrfXdktCescjny57w7MpmufvOCiIjIBPSJ0YhywYT67BAUsnz72YOk24J9G6MhrLLSNBjs+ZiODB/tXum/Vq2EVTTmQ6kSlGot3ytyquXI3EjpZ8PwVXNPWKb8a73UVAn7OUZUqClfRESmQSGsEQWbcIdDVrf2O654xTp/bNLlyKA5PjoBfrwSNtVyZMXdgakW/zg1yTJd9FhupBRgwgpazZWwoEIVZ0/YeCUweXiv3dJVHlpFRESmoBDWiMJKWHDX4wgtnLL6KH+srBIWWY60BAwFlbBoCJu/xldpwopYVLVKWCJd/jwMFpWhBWD9ZbD6VcE1Dx1aCau1J2y8ElbvuyMjAauyapVu9dcx1XDZiZz/QfjVWw7/2kREpOlo78hGFPaEBdsF5ZNtHLNskT/WH1bCesC50s90LoWDu/zjaLjqXAzXPVjaWDtqqkoY+BA2tKf6Mt0574VFx/u7OXMjh1bAaq2EJWZovEP4exLpQ3u30u0/33Jo52L/R0REpEYKYY0oDGHBcuTiBfNJhncq9m+HdEekh6sFCmPQtbwUwiqrVouPr/57Jq2EBaEsrIRNFFDC4JQdhvYgKIbzxWrZzzH6GvXuCasMmFFnXQNLT6nv7xcREYnQcmQjCpYji0M+hK1YshAyHcE3XSnkQKnaNO+o0rHUFJtmh6rOCasIROGSZ7XgAqXxEtHlyOPfAJd9CpadVtt1jM8Jq/P/J5hsjMSyU+HsX6/v7xcREYlQCGtEQSVsqM832q9dvtgHnDA8VAthXctLxyYKTJUSyVJvVLW7I6G0xDhRlSoMTq5YOifdBht+o/b+qhmrhIUz0HQXo4iIxE8hrBEFISw74BvtzzouaKoPl8uiDfnh45WvKB1L11gJi55buW1POBdsquXIxCSzt2o109sWaaCqiIg0AIWwRhSEsLb8AADptqAf7IIP+q8v/LB0bmu3D1AnXVk6Fr07ciphc361ifkQuTtyip6wysfTEW2Yr6fJesJERERmmEJYIwpCWLuN+edhUFp/OSxYCxd/vHRua7fvF0u3wpKT/LHx/rEajFfCKibGV46omGgQabQS9vNMm7dk/afNj2+PpBAmIiLx092RjSicExbKBCEskYAPPFz+veMuLvWI/cZdsO0Htd+VCIdWwsaX7MIQNlVjfnT21mFWspKZmVkiTFYstYqIiMRIIawBudwwZS3t0Xlelc58h/8Dvj9s/Zum98vSbcHcrCBMTbQcOVHAmmwroFol0/XvB4NDA6aIiEiMtBzZgLIjQ6UnlqxvlSjdVt5DdsjE/PDuyDovR85ECFMlTEREGogqYQ0oNzrEeOTJdBz+Vjq1SLeXLzVO1BNWz8b8pafAwM7D+9npUE+YiIg0EIWwBlMsutIG3jD5UuSRUFkJq5ylNeWIimhP2GFWmM69zv+ptzCEqRImIiINQCGswTy8/QCnuTHGm8IydQ5hJ14OC48rPa/ctqh1BpYjZ0pSPWEiItI4FMIazKMv7OVsK5QO1LsSdsqby59XTq+f8u7II7AcOVMqA6aIiEiM1JjfYF58eV/5gXqHsEqV2xb1HAOv/wSsv6z6+WWVsAavMCUSYAktR4qISENQJazB7NwThLBkCxTG6r8cWany7kgzOO/9k5x/BHrCZlIi3fhhUUREmoIqYQ3m5X0H/INw4Gp6GtPvj4Tpbu1jFrnrsMGXIwHO/DU49qK4r0JERESVsEZyYCjLyMgQtOCn4B/cFWMlbBp9U4k0FPOzoxJ22afivgIRERFAlbDG8dDnaPvns+kgGE/RFlbC2mb2OsIRFdMJVLOpEiYiItIgVAlrFHd+mFag24Jp+e3BfpAzvhwZDmudTiUs3PJoFlTCREREGoQqYY2gf8f4w05G/INwU+64G/NrUTnWQkRERKZU1xBmZpeY2VNm9qyZXV/l+8eY2f1m9rCZPWZm09x9eo544r/GHy5pyfoHYQib8REVFRPza6HlSBERkWmrWwgzsyRwE/BG4CTgajM7qeK0PwZudc6dCVwF/GO9rqehHdg2/nBxS9E/aO32XzMzvBwZLkNOpxctoUqYiIjIdNWzEnYO8KxzbqtzLgt8Fbiy4hwHBCPZ6QZmYBfnBpQdHH84PwxhmU7/daYrYesvhcs+DT2rav+ZsCdsOtUzERGRJlfPxvwVwPbI8x3AKyvO+VPgbjN7P9ABXFzH62lc2aHxhz2ZmENYazdsePf0fma8J0zLkSIiIrWKuzH/auBfnXMrgTcB/2Zmh1yTmV1rZpvMbFNvb++MX2TdRULYvHQYwoJlyJluzD8cicMYayEiItLk6hnCXgKOjjxfGRyLeg9wK4Bz7kGgFVhU+ULOuZudcxuccxsWL15cp8uNUTSEpYLNu1dugHN/F1ZfENNFTYNGVIiIiExbPUPYRmCdma0xswy+8f6OinNeBF4LYGYn4kPYHCx1TSHSE9aZzPsH6Xa45C9KDfqNLKHlSBERkemqWwhzzuWB9wF3AU/g74LcbGY3mtkVwWkfAt5rZo8CXwHe5Zxz9bqmhpUdomh+Sa8jGVTCErNojq6WI0VERKatrp/0zrk7gTsrjn0s8ngLcH49r2FWyA6RS3XSkuujzXL+2GwKYRrWKiIiMm1xN+YLQHaI0aS/G7J1Noaw8Z4wLUeKiIjUSiEsbs5BdnA8hCXdbAxhqoSJiIhMl0JY3PKj4IoMJ/xICsuPAgaJWfTWjPeEaViriIhIrWbRJ/0cFYynGEoEw1nzY7OrCgbaO1JEROQwKITFLRhPMUQwnDU/OvtCWFJ3R4qIiEyXQljcgkrYQQtDmCphIiIizUAhLG5BCBtwbf55frR0t+FskUiDJWffdYuIiMRIISxuQQjrd8EekbO1EqalSBERkWlRCItbEML6imEIm4U9YYmkQpiIiMg0KYTFLQhh+wvhcuQsrIQtWAsLVsd9FSIiIrOKQljcgrsj9xVmcU/YBR+E3/pe3FchIiIyqyiExS2ohO3Lt/rnrjj7KmEiIiIybQphcQtC2N5cZNq8QpiIiMicN2UIM7PLzUxhrV6yg7h0B4M5Kx1TCBMREZnzaglXbweeMbP/Y2br631BTSc7BOl2CkT6wGZbT5iIiIhM25QhzDn3DuBM4DngX83sQTO71sy66n51zaCQo5hMk4++FaqEiYiIzHk1LTM65waA24CvAsuBXwZ+ambvr+O1NQdXwJGoqIQphImIiMx1tfSEXWFm3wC+A6SBc5xzbwROBz5U38trAsU8RUuqEiYiItJkavm0fwvwKedc2SAo59ywmb2nPpfVRIoFnCUploUw9YSJiIjMdbWEsD8FdoVPzKwNWOqc2+acu7deF9Y0inkKJMlrOVJERKSp1NIT9p9AMfK8EByTI8EVKZKgoOVIERGRplJLCEs557Lhk+Cxdms+Uop5CpYEDGdBNUwhTEREZM6rJYT1mtkV4RMzuxLYW79LajLFAkWCQa1h+FJPmIiIyJxXS8nlt4Evm9k/AAZsB66p61U1E1cg73zocokkVkCVMBERkSYw5ae9c+454Fwz6wyeD9b9qppJMT/eD2bjlTCFMBERkbmupk97M7sUOBloNfNLZ865G+t4Xc2jWCzNCEuoJ0xERKRZ1DKs9Z/x+0e+H78c+SvAqjpfV/Mo5sm7BOmkqRImIiLSRGppzD/POXcNcMA593HgF4Dj63tZTcQVKJCkNZVUY76IiEgTqSWEjQZfh83sKCCH3z9SjoRinrwzMqlEJISpEiYiIjLX1fJp/19m1gP8DfBTwAGfq+tVNZOir4Slkwn1hImIiDSRST/tzSwB3Ouc6wO+Zmb/DbQ65/pn5OqaQbGgSpiIiEgTmnQ50jlXBG6KPB9TADvCXIE8SR/CxifmqydMRERkrqulJ+xeM3uLhbMp5MgKesL8cqQqYSIiIs2ilhD2W/gNu8fMbMDMDprZQJ2vq3kU/cR8vxypnjAREZFmUcvE/K6ZuJCmFfSEtagSJiIi0lSm/LQ3s1dXO+6c+96Rv5wm5ArkXMJXwsK3I6kQJiIiMtfV8mn/kcjjVuAc4CfARXW5omZTzJNzRjpp4FQJExERaRa1LEdeHn1uZkcDn67bFTWbYqQSVlBPmIiISLM4nE/7HcCJR/pCmlawd2QmlQSnECYiItIsaukJ+yx+Sj74uynPwE/OlyPBFckWE2SSCSho70gREZFmUUvJZVPkcR74inPuh3W6nuYT9IRlUgZ59YSJiIg0i1o+7W8DRp1zBQAzS5pZu3NuuL6X1iSKBbJF85UwjagQERFpGjVNzAfaIs/bgG/X53KaUDFfaszXsFYREZGmUUsIa3XODYZPgsft9bukJuIcuKASVrZ3pEKYiIjIXFdLCBsys7PCJ2Z2NjBSv0tqIq4IQK6YqNg7Uo35IiIic10tJZcPAv9pZjsBA5YBb6/rVTWLYgGAPAk6U+oJExERaSa1DGvdaGbrgROCQ08553L1vawmUcz7LwQjKtQTJiIi0jSmXI40s98FOpxzjzvnHgc6zex36n9pTcCFlbAkLaqEiYiINJVaesLe65zrC5845w4A763lxc3sEjN7ysyeNbPrq3z/U2b2SPDnaTPrq/Y6c1akEqaeMBERkeZSS8klaWbmnHPg54QBmal+KDjvJuB1+K2ONprZHc65LeE5zrn/FTn//cCZ07z+2a3oG/PzhCMqVAkTERFpFrVUwv4HuMXMXmtmrwW+Anyrhp87B3jWObfVOZcFvgpcOcn5Vwev3TyiPWGaEyYiItJUavm0/wPgWuC3g+eP4e+QnMoKYHvk+Q7gldVONLNVwBrgvhped+6I9ISpMV9ERKS5TFkJc84VgR8D2/DVrYuAJ47wdVwF3BZujVTJzK41s01mtqm3t/cI/+oYBZWwAgnSKfWEiYiINJMJSy5mdjx+ifBqYC9wC4Bz7sIaX/sl4OjI85XBsWquAn53ohdyzt0M3AywYcMGV+Pvb3zBnLCiS9CivSNFRESaymSVsCfxVa/LnHMXOOc+C1StVE1gI7DOzNaYWQYftO6oPCmYQTYfeHAarz03RIa1qjFfRESkuUwWwt4M7ALuN7PPBU35VusLO+fywPuAu/DLl7c65zab2Y1mdkXk1KuAr4Z3XzaVYPVVjfkiIiLNZ8JPe+fc7cDtZtaBv6vxg8ASM/sn4BvOubunenHn3J3AnRXHPlbx/E8P47rnhqAnLE/SzwnTBt4iIiJNo5bG/CHn3H845y7H93U9jL9jUn5excpKmBrzRUREmkUtc8LGOecOOOduds69tl4X1FTGK2Hh3pHqCRMREWkW0wphcoQ5PzG/EFbCkgphIiIizUKf9nEanxMWDGs94VIYHYDOpTFfmIiIiNSbQlhcciOQHQQilbCO5fCq34/5wkRERGQmKITF5Zvvg2fuAaDgkj6EiYiISNPQJ39cDu6GsX4AChipRM0j2ERERGQOUAiLS9APBmDJNGYKYSIiIs1EISwukRCWTGoumIiISLNRCIuLK23DmUiqNU9ERKTZKITFJVIJS6fTMV6IiIiIxEEhLC7FUiWsp7MtxgsRERGROCiExSUSwhYohImIiDQdhbC4RJYjF3S1x3ghIiIiEgeFsLhEQtgihTAREZGmoxAWl2DzboCF3QphIiIizUYhLC6RSthiVcJERESajkJYXKIhTJUwERGRpqMQFpfI3ZGL5imEiYiINBuFsLhEQlhrJhPjhYiIiEgcFMLiElmOJKG9I0VERJqNQlhcIntHktDekSIiIs1GISwmLloJM1XCREREmo1CWBycw7QcKSIi0tQUwuIQGdQKgFk81yEiIiKxUQiLQ+TOSBEREWlOCmFxiC5FioiISFNSCIuDQpiIiEjTUwiLg9NypIiISLNTCIuDesJERESankJYHLQcKSIi0vQUwuKgSpiIiEjTUwiLgyphIiIiTU8hLAaFgkKYiIhIs1MIi8FoNhv3JYiIiEjMFMJiMDo2FvcliIiISMxScV9AMxob85WwbUf/MqtPf3XMVyMiIiJxUCUsBmM5H8L2rnwdbPiNmK9GRERE4qAQFoOxbA6AdCYd85WIiIhIXBTCYpANGvNb0pmYr0RERETiohAWg2xQCcuk1ZInIiLSrBTCYjCWC0JYRpUwERGRZqUQFoNc1o+oaGlpiflKREREJC4KYTHIBpUw9YSJiIg0L4WwGOTCEKa7I0VERJqWQlgM8uM9YQphIiIizUohbKblx8jnfE+YJRTCREREmpVmJMy0L17BRbu3+ceJZKyXIiIiIvFRJWym9W9nfm63f5xQBhYREWlWdQ1hZnaJmT1lZs+a2fUTnPM2M9tiZpvN7D/qeT0NoZgvPVYlTEREpGnVrRRjZkngJuB1wA5go5nd4ZzbEjlnHXADcL5z7oCZLanX9TSMQq702BTCREREmlU9K2HnAM8657Y657LAV4ErK855L3CTc+4AgHNuTx2vpzEUC6XHWo4UERFpWvUMYSuA7ZHnO4JjUccDx5vZD83sR2Z2SbUXMrNrzWyTmW3q7e2t0+XOkLLlSIUwERGRZhV3Y34KWAe8Brga+JyZ9VSe5Jy72Tm3wTm3YfHixTN8iUdYMbIcqZ4wERGRplXPEPYScHTk+crgWNQO4A7nXM459zzwND6UzV1qzBcRERHqG8I2AuvMbI2ZZYCrgDsqzrkdXwXDzBbhlye31vGa4lUsgiuWnms5UkREpGnVLYQ55/LA+4C7gCeAW51zm83sRjO7IjjtLmCfmW0B7gc+4pzbV69ril20CgYKYSIiIk2srinAOXcncGfFsY9FHjvg94M/c19lCNOIChERkaYVd2N+c4k25YN6wkRERJqYQthMiswIK1oSzGK8GBEREYmTQthMikzLd6Z/ehERkWamJDCTIj1hztSULyIi0swUwmaSZoSJiIhIQCFsJmnLIhEREQkohM2kaAjTeAoREZGmphA2kwrRfSNVCRMREWlmCmEzKVoJSyqEiYiINDOFsJkUmRNmaswXERFpagphMykyMd+0HCkiItLUFMJmUmQ50rQcKSIi0tQUwmZSQZUwERER8RTCZlKkJ0wjKkRERJqbQthMKkZHVCiEiYiINDOFsJmkifkiIiISUAibSdo7UkRERAIKYTOpoEqYiIiIeAphM0mVMBEREQkohM2koDG/QEJ3R4qIiDQ5hbCZFFTCxhLtWo4UERFpcgphMymYE7a3dTX0HBPvtYiIiEisFMJmUjAx/9bjPwmX/m3MFyMiIiJxUgibScFyZCrTAmYxX4yIiIjESSFsBhXyWQAy6UzMVyIiIiJxUwibQfm8r4SlMwphIiIizU4hbAaFlbCWdDrmKxEREZG4KYTNoEI+R84laUlrRpiIiEizUwibQYV8jjxJWhXCREREmp5C2Awq5LPkSdKS0j+7iIhIs1MamEHFfD4IYaqEiYiINDuFsBlULOTIk6AlrX92ERGRZqcNDGdQMZ+jSEqVMBEREVEIm0nFQh5HglZVwkRERJqe0sAEtuwcOOKv6Qo58k49YSIiIqIQVtWj2/t402e+z09fPHBEX9f3hOnuSBEREVEIq2pX/wgA2/cPH9kXLuY1J0xEREQAhbCq+kdyAOwbzNb2A8P7YcemKU9zYSVMPWEiIiJNT2mgir7hIIQNjdX2Az/6R/jXy8C5yc8rFsiToFU9YSIiIk1PIayKmiph+THIjQJQHNgF+RHIDk3+woUceVKkk3akLlVERERmKYWwKvqCELa3MoT98DOw7Qf+8TffB7e8A4DtO3YA4Eb7Jn/hYh5nScwUwkRERJqdQlgV/eMhrGI58rt/DQ9/2T/e9wy89BP/eHgfAEMD+6u+Xq5Q5MJPfod9A0MUTKPZRERERCGsqv5qPWGFHGQHYXivfz5yAEb2w/B+WnK+AjbQ58NYvlDk6z/dQaHoe8Q27xzg+b1DmCvgTP1gIiIiohBWVVgJGxo8WDo4GgxvHQpC2HAwQ2zfs3QU+gEYDELYd57q5fdvfZQHnvPnbnzeV8iSFHAJVcJEREREIayqvpEsy9nHj+zdjD7zHX8w7Pca3guFPIz54EXvU3QUfVgbOejD1tN7/PNt+/ycsYe2+eNpCjgtR4qIiAgKYVX1D+c4MbOHjBUYqwxhQ/tKjwFe2kQCv+w4NuirY8/uGQRgx/5hikXHpm2lShgJLUeKiIiIQtghCkXHwbE86+cF/WA7H/FfR4LglRuCgZ2lH9i+cfxhbsif81yvH1Xx4v5hegfHODCcY15rihQFiol03f8OIiIi0vgUwiocHM3hHBzX4bcuau39mR/COto/fs6d3/m+f5BqhT2bx48XR/pwzvFcUAl7cf8wu/v9LLFTV3aTokC2qPEUIiIiUucQZmaXmNlTZvasmV1f5fvvMrNeM3sk+POb9byeWgz072eDPcn6dh+6Wsb2suuL72b0xZ+OnzOy6wn/YM2ry394dICXB8YYHMvTmk7w4r5hdg8EIWxFD0krMlxQ7hURERGoW5e4mSWBm4DXATuAjWZ2h3NuS8Wptzjn3lev65iu4jP3clvLjfT3nTJ+bPm2b1DcVurl6hl+wT9Yfyk8czcAoy5NMjvAI9v9kuR5xy7ivif38MzLvkn/tJXdpCkwmlclTEREROpbCTsHeNY5t9U5lwW+ClxZx993ROxrWQlAV9+THGhbxRfybwAgQWH8nOW5FwHYmN4wfmyHLSM/dIA/+NpjHLOgnbesb+HWzMfZ9fQm/iPz55zBkyQpMFJQCBMREZH6hrAVwPbI8x3BsUpvMbPHzOw2Mzu62guZ2bVmtsnMNvX29tbjWseNdh4DQMLlSfWs5OP5X+fHxfX+e8431a9mF84SfPah0hyxg+lFdNkIqYTx5d98JWflH+WcxFO8bdcnOS+xmWUb/4YWcmTrV3wUERGRWSTuBqX/AlY7504D7gG+WO0k59zNzrkNzrkNixcvrusFnX/yGuhYAkDnwuX85ZtPpXPpsQC85BZRIEm7jVFs6WbrvhE+nX8zDxVPIJ/pYh5D/NkbjuLoBe0sHfgZAKfbswAkFq6l00ZZtGhpXa9fREREZod6hrCXgGhla2VwbJxzbp9zLtwb6PPA2XW8ntotWAuAdSzm6nOOoecoH8KGE50U2hYCMJruYWffCJ/Ov5W3Zf+EE1YdzbGJXbzxW6+CZ75NItxXMhTsL3nZuSfN3N9DREREGlY9Q9hGYJ2ZrTGzDHAVcEf0BDNbHnl6BfBEHa+ndkEIo8MHrkUrjwMg07WA3OoL/bcOPk+wNSQAXZ0dAJgrwK3vhJc2sbP9hNIJ+58HINW+oM4XLyIiIrNB3UKYcy4PvA+4Cx+ubnXObTazG83siuC0D5jZZjN7FPgA8K56Xc+0jIcwv/TZssg/X73iKNKXf5IB18a9LReX/Yhl/RZFXPp34IoA7DjpWm7KX0F/6wo4sM1/v62n7pcvIiIija+uXeLOuTuBOyuOfSzy+Abghnpew2FZsMZ/DUIYPb5Zv6VzAbTP41WpL7CnPw/Adz/yGpwD0mfAMa+EM98JJ/0SbP46S1a9lU/+cDlv6TlI9+77/Wu1zZ/hv4yIiIg0orgb8xvTqvPh6HPhqLP883krIN0OXcsAOGrhPFzwT7dqYQerF3VA9wo46xow88uY57yX1Ut7+NbvvYolSyLN+K2qhImIiIhCWHXzlsN77vJfAZIpeO/9cO51AHz8ipMB+IW1C6d8qfXL5pGILkGqEiYiIiLUeTlyTlmyfvzhaSt72HLjG8hHO/MnE61+tXYf4QsTERGR2Ugh7DC1Z6bxTxdWwlrm+aqaiIiIND0tR86EsBKmfjAREREJKITNhLAS1qalSBEREfEUwmZCWAFTU76IiIgEFMJmQpuWI0VERKScQthMUCVMREREKiiEzYTxnjBVwkRERMTTvISZkG6DV30Y1l8a95WIiIhIg1AImymv/WjcVyAiIiINRMuRIiIiIjFQCBMRERGJgUKYiIiISAwUwkRERERioBAmIiIiEgOFMBEREZEYKISJiIiIxEAhTERERCQGCmEiIiIiMVAIExEREYmBQpiIiIhIDBTCRERERGKgECYiIiISA3POxX0N02JmvcALdf41i4C9df4dcmTovZo99F7NDnqfZg+9V7PDKufc4mrfmHUhbCaY2Sbn3Ia4r0Ompvdq9tB7NTvofZo99F7NflqOFBEREYmBQpiIiIhIDBTCqrs57guQmum9mj30Xs0Oep9mD71Xs5x6wkRERERioEqYiIiISAwUwiqY2SVm9pSZPWtm18d9Pc3OzP7FzPaY2eORYwvM7B4zeyb4Oj84bmb2meC9e8zMzorvypuLmR1tZveb2RYz22xmvxcc13vVYMys1cweMrNHg/fq48HxNWb24+A9ucXMMsHxluD5s8H3V8d5/c3GzJJm9rCZ/XfwXO/THKIQFmFmSeAm4I3AScDVZnZSvFfV9P4VuKTi2PXAvc65dcC9wXPw79u64M+1wD/N0DUK5IEPOedOAs4Ffjf4347eq8YzBlzknDsdOAO4xMzOBf4a+JRz7jjgAPCe4Pz3AAeC458KzpOZ83vAE5Hnep/mEIWwcucAzzrntjrnssBXgStjvqam5pz7HrC/4vCVwBeDx18Efily/EvO+xHQY2bLZ+ZKm5tzbpdz7qfB44P4D40V6L1qOMG/+WDwNB38ccBFwG3B8cr3KnwPbwNea2Y2Q5fb1MxsJXAp8PnguaH3aU5RCCu3Atgeeb4jOCaNZalzblfweDewNHis968BBMsgZwI/Ru9VQwqWuB4B9gD3AM8Bfc65fHBK9P0Yf6+C7/cDCxWf6JsAAAN9SURBVGf2ipvWp4H/DRSD5wvR+zSnKITJrOb87b26xbdBmFkn8DXgg865gej39F41DudcwTl3BrASvwKwPuZLkgpmdhmwxzn3k7ivRepHIazcS8DRkecrg2PSWF4Ol66Cr3uC43r/YmRmaXwA+7Jz7uvBYb1XDcw51wfcD/wCfkk4FXwr+n6Mv1fB97uBfTN8qc3ofOAKM9uGb425CPh79D7NKQph5TYC64K7TzLAVcAdMV+THOoO4NeDx78OfDNy/Jrgzrtzgf7IUpjUUdB78v+AJ5xzfxf5lt6rBmNmi82sJ3jcBrwO38N3P/DW4LTK9yp8D98K3Oc0YLLunHM3OOdWOudW4z+L7nPO/Rp6n+YUDWutYGZvwq/DJ4F/cc79ecyX1NTM7CvAa4BFwMvAnwC3A7cCxwAvAG9zzu0PgsA/4O+mHAbe7ZzbFMd1NxszuwD4PvAzSv0rf4jvC9N71UDM7DR8A3cS/3/Eb3XO3Whma/EVlwXAw8A7nHNjZtYK/Bu+z28/cJVzbms8V9+czOw1wIedc5fpfZpbFMJEREREYqDlSBEREZEYKISJiIiIxEAhTERERCQGCmEiIiIiMVAIExEREYmBQpiIzClmVjCzRyJ/rp/6p2p+7dVm9viRej0RaW6pqU8REZlVRoIteUREGpoqYSLSFMxsm5n9HzP7mZk9ZGbHBcdXm9l9ZvaYmd1rZscEx5ea2TfM7NHgz3nBSyXN7HNmttnM7g6mzouITJtCmIjMNW0Vy5Fvj3yv3zl3Kn5a/6eDY58FvuicOw34MvCZ4PhngO86504HzgI2B8fXATc5504G+oC31PnvIyJzlCbmi8icYmaDzrnOKse3ARc557YGm43vds4tNLO9wHLnXC44vss5t8jMeoGVzrmxyGusBu5xzq0Lnv8BkHbOfaL+fzMRmWtUCRORZuImeDwdY5HHBdRbKyKHSSFMRJrJ2yNfHwwePwBcFTz+NfxG5AD3AtcBmFnSzLpn6iJFpDno/8GJyFzTZmaPRJ7/j3MuHFMx38wew1ezrg6OvR/4gpl9BOgF3h0c/z3gZjN7D77idR2wq+5XLyJNQz1hItIUgp6wDc65vXFfi4gIaDlSREREJBaqhImIiIjEQJUwERERkRgohImIiIjEQCFMREREJAYKYSIiIiIxUAgTERERiYFCmIiIiEgM/j+p6qv36AlM8wAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loss Graph**"
      ],
      "metadata": {
        "id": "HSHo3r2SBZr3"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBSAyVfivvHX",
        "outputId": "235e7648-464f-4e22-ea07-e7f477356a1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        }
      },
      "source": [
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}