{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "7e88OLey6Bgd"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7e88OLey6Bgd"
      },
      "source": [
        "# **Image Classification with Convolutional Neural Networks (CNNs)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsTzc3oi726u"
      },
      "source": [
        "# **Building a Convolutional Neural Network with Keras**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCglDGFy8AhT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "091a1e1a-85d9-4eb4-eaef-901557a99e67"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "tf.__version__\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import matplotlib.image as mpimg\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "import imageio\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.8.2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qf7eW3HC9XVL"
      },
      "source": [
        "**Data Acquisition and ImageDataGenerator**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0BfyGlJbx0l"
      },
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255) #Normalize the pixel values\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hsimgs7aqt6G"
      },
      "source": [
        "#File path to the folder containin images\n",
        "train_dir = os.path.join('/content/spectrograms-200/Train')\n",
        "validation_dir = os.path.join('/content/spectrograms-200/Validation')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NyvlF41oqxEP",
        "outputId": "05278ee8-f024-4eaa-bf30-a7d78d4f0737",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(64,64),\n",
        "    batch_size=256,\n",
        "    shuffle=True,\n",
        "    class_mode='binary')\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    validation_dir,\n",
        "    target_size=(64,64),\n",
        "    batch_size=256,\n",
        "    shuffle=True,\n",
        "    class_mode='binary')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 33128 images belonging to 2 classes.\n",
            "Found 6780 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3yhwpN_-BaS"
      },
      "source": [
        "**Building the Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSzxq4KDtKN6"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "                                    \n",
        "    # First convolution layer \n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(64, 64, 3),use_bias=True),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "\n",
        "    # Second convolution layer \n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu',use_bias=True),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    \n",
        "\n",
        "    # Third convolution layer  \n",
        "    tf.keras.layers.Conv2D(256, (3,3), activation='relu',use_bias=True),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "\n",
        "  # Fourth convolution layer  \n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu',use_bias=True),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "\n",
        "\n",
        "    # Flatten the pooled feature maps\n",
        "    tf.keras.layers.Flatten(),\n",
        "\n",
        "    # Fully connected hidden layer\n",
        "    tf.keras.layers.Dense(8, activation='relu',use_bias=True),\n",
        "\n",
        "\n",
        "    # Output layer\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid',activity_regularizer=regularizers.L1(0.001))   \n",
        "\n",
        "])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDXufVt4-LFY"
      },
      "source": [
        "**Model Summary**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HU0RFGLtNJb",
        "outputId": "08c30a3c-9036-4547-f6ec-6ffdd88b7e8f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 62, 62, 64)        1792      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 31, 31, 64)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 31, 31, 64)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 29, 29, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 14, 14, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 12, 12, 256)       295168    \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 6, 6, 256)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 6, 6, 256)         0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 4, 4, 64)          147520    \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 2, 2, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 2, 2, 64)          0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 8)                 2056      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 520,401\n",
            "Trainable params: 520,401\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THk8lK3G-cdk"
      },
      "source": [
        "**Optimizer Implementation and model training/validation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBN3GBMItPMH"
      },
      "source": [
        "#from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import SensitivityAtSpecificity,SpecificityAtSensitivity,Recall,Precision\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=Adam(learning_rate=0.001),\n",
        "              metrics=['accuracy',SensitivityAtSpecificity(0.5),SpecificityAtSensitivity(0.5),Recall(0.5),Precision(0.5)]) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Q0MPMwh3EgY"
      },
      "source": [
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('val_accuracy')>0.99): \n",
        "      print(\"\\nReached 99% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "callbacks = myCallback()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7f6gDG3dx9sJ",
        "outputId": "75181e57-a1d9-48d7-d878-c71a09be45f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "checkpoint = ModelCheckpoint(\"ECG_Spectrogram_Model.h5\", monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
        "\n",
        "history = model.fit(\n",
        "      train_generator,\n",
        "      steps_per_epoch=10, \n",
        "      epochs=500,\n",
        "      verbose=1,\n",
        "      validation_data = validation_generator,\n",
        "      validation_steps=5,\n",
        "      callbacks = [callbacks,checkpoint]\n",
        ") "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.7135 - accuracy: 0.5141 - sensitivity_at_specificity: 0.5090 - specificity_at_sensitivity: 0.5268 - recall: 0.3443 - precision: 0.5183\n",
            "Epoch 1: val_accuracy improved from -inf to 0.51172, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 18s 230ms/step - loss: 0.7135 - accuracy: 0.5141 - sensitivity_at_specificity: 0.5090 - specificity_at_sensitivity: 0.5268 - recall: 0.3443 - precision: 0.5183 - val_loss: 0.6932 - val_accuracy: 0.5117 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
            "Epoch 2/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6950 - accuracy: 0.4984 - sensitivity_at_specificity: 0.4628 - specificity_at_sensitivity: 0.4217 - recall: 0.0039 - precision: 0.2941\n",
            "Epoch 2: val_accuracy did not improve from 0.51172\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.6950 - accuracy: 0.4984 - sensitivity_at_specificity: 0.4628 - specificity_at_sensitivity: 0.4217 - recall: 0.0039 - precision: 0.2941 - val_loss: 0.6936 - val_accuracy: 0.5000 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
            "Epoch 3/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6934 - accuracy: 0.5090 - sensitivity_at_specificity: 0.0079 - specificity_at_sensitivity: 0.2360 - recall: 0.0087 - precision: 0.5500\n",
            "Epoch 3: val_accuracy did not improve from 0.51172\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.6934 - accuracy: 0.5090 - sensitivity_at_specificity: 0.0079 - specificity_at_sensitivity: 0.2360 - recall: 0.0087 - precision: 0.5500 - val_loss: 0.6937 - val_accuracy: 0.4961 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
            "Epoch 4/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6938 - accuracy: 0.4917 - sensitivity_at_specificity: 0.0033 - specificity_at_sensitivity: 0.1719 - recall: 0.0057 - precision: 0.6364\n",
            "Epoch 4: val_accuracy did not improve from 0.51172\n",
            "10/10 [==============================] - 2s 194ms/step - loss: 0.6938 - accuracy: 0.4917 - sensitivity_at_specificity: 0.0033 - specificity_at_sensitivity: 0.1719 - recall: 0.0057 - precision: 0.6364 - val_loss: 0.6937 - val_accuracy: 0.4875 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
            "Epoch 5/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6937 - accuracy: 0.5086 - sensitivity_at_specificity: 0.0088 - specificity_at_sensitivity: 0.0504 - recall: 0.0096 - precision: 0.3750\n",
            "Epoch 5: val_accuracy did not improve from 0.51172\n",
            "10/10 [==============================] - 2s 157ms/step - loss: 0.6937 - accuracy: 0.5086 - sensitivity_at_specificity: 0.0088 - specificity_at_sensitivity: 0.0504 - recall: 0.0096 - precision: 0.3750 - val_loss: 0.6937 - val_accuracy: 0.4930 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
            "Epoch 6/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6937 - accuracy: 0.4961 - sensitivity_at_specificity: 0.0031 - specificity_at_sensitivity: 0.0512 - recall: 0.0039 - precision: 0.5000\n",
            "Epoch 6: val_accuracy did not improve from 0.51172\n",
            "10/10 [==============================] - 2s 197ms/step - loss: 0.6937 - accuracy: 0.4961 - sensitivity_at_specificity: 0.0031 - specificity_at_sensitivity: 0.0512 - recall: 0.0039 - precision: 0.5000 - val_loss: 0.6937 - val_accuracy: 0.4883 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
            "Epoch 7/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6937 - accuracy: 0.4922 - sensitivity_at_specificity: 0.0015 - specificity_at_sensitivity: 0.0802 - recall: 0.0015 - precision: 0.5000\n",
            "Epoch 7: val_accuracy did not improve from 0.51172\n",
            "10/10 [==============================] - 2s 156ms/step - loss: 0.6937 - accuracy: 0.4922 - sensitivity_at_specificity: 0.0015 - specificity_at_sensitivity: 0.0802 - recall: 0.0015 - precision: 0.5000 - val_loss: 0.6936 - val_accuracy: 0.5016 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
            "Epoch 8/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6937 - accuracy: 0.5113 - sensitivity_at_specificity: 0.0000e+00 - specificity_at_sensitivity: 0.0611 - recall: 0.0000e+00 - precision: 0.0000e+00\n",
            "Epoch 8: val_accuracy improved from 0.51172 to 0.51250, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.6937 - accuracy: 0.5113 - sensitivity_at_specificity: 0.0000e+00 - specificity_at_sensitivity: 0.0611 - recall: 0.0000e+00 - precision: 0.0000e+00 - val_loss: 0.6936 - val_accuracy: 0.5125 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
            "Epoch 9/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6937 - accuracy: 0.4840 - sensitivity_at_specificity: 0.0015 - specificity_at_sensitivity: 0.0413 - recall: 0.0030 - precision: 0.8000\n",
            "Epoch 9: val_accuracy did not improve from 0.51250\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.6937 - accuracy: 0.4840 - sensitivity_at_specificity: 0.0015 - specificity_at_sensitivity: 0.0413 - recall: 0.0030 - precision: 0.8000 - val_loss: 0.6936 - val_accuracy: 0.4898 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
            "Epoch 10/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6936 - accuracy: 0.5164 - sensitivity_at_specificity: 7.6336e-04 - specificity_at_sensitivity: 0.0680 - recall: 0.7634 - precision: 0.5187\n",
            "Epoch 10: val_accuracy did not improve from 0.51250\n",
            "10/10 [==============================] - 2s 157ms/step - loss: 0.6936 - accuracy: 0.5164 - sensitivity_at_specificity: 7.6336e-04 - specificity_at_sensitivity: 0.0680 - recall: 0.7634 - precision: 0.5187 - val_loss: 0.6937 - val_accuracy: 0.4703 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.0000e+00 - val_recall: 1.0000 - val_precision: 0.4703\n",
            "Epoch 11/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6936 - accuracy: 0.5207 - sensitivity_at_specificity: 0.0015 - specificity_at_sensitivity: 0.1109 - recall: 0.7416 - precision: 0.5239\n",
            "Epoch 11: val_accuracy did not improve from 0.51250\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.6936 - accuracy: 0.5207 - sensitivity_at_specificity: 0.0015 - specificity_at_sensitivity: 0.1109 - recall: 0.7416 - precision: 0.5239 - val_loss: 0.6936 - val_accuracy: 0.5078 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.0000e+00 - val_recall: 1.0000 - val_precision: 0.5078\n",
            "Epoch 12/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6937 - accuracy: 0.4957 - sensitivity_at_specificity: 7.7399e-04 - specificity_at_sensitivity: 0.1498 - recall: 0.6649 - precision: 0.5003\n",
            "Epoch 12: val_accuracy did not improve from 0.51250\n",
            "10/10 [==============================] - 2s 157ms/step - loss: 0.6937 - accuracy: 0.4957 - sensitivity_at_specificity: 7.7399e-04 - specificity_at_sensitivity: 0.1498 - recall: 0.6649 - precision: 0.5003 - val_loss: 0.6937 - val_accuracy: 0.4938 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.0000e+00 - val_recall: 1.0000 - val_precision: 0.4938\n",
            "Epoch 13/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6936 - accuracy: 0.5082 - sensitivity_at_specificity: 0.0031 - specificity_at_sensitivity: 0.0441 - recall: 0.8513 - precision: 0.5074\n",
            "Epoch 13: val_accuracy did not improve from 0.51250\n",
            "10/10 [==============================] - 2s 157ms/step - loss: 0.6936 - accuracy: 0.5082 - sensitivity_at_specificity: 0.0031 - specificity_at_sensitivity: 0.0441 - recall: 0.8513 - precision: 0.5074 - val_loss: 0.6938 - val_accuracy: 0.4875 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.0000e+00 - val_recall: 1.0000 - val_precision: 0.4875\n",
            "Epoch 14/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6938 - accuracy: 0.4848 - sensitivity_at_specificity: 0.0016 - specificity_at_sensitivity: 0.0810 - recall: 0.7300 - precision: 0.4922\n",
            "Epoch 14: val_accuracy did not improve from 0.51250\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.6938 - accuracy: 0.4848 - sensitivity_at_specificity: 0.0016 - specificity_at_sensitivity: 0.0810 - recall: 0.7300 - precision: 0.4922 - val_loss: 0.6936 - val_accuracy: 0.5063 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.0000e+00 - val_recall: 1.0000 - val_precision: 0.5063\n",
            "Epoch 15/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6939 - accuracy: 0.4738 - sensitivity_at_specificity: 0.0041 - specificity_at_sensitivity: 0.0052 - recall: 0.9439 - precision: 0.4724\n",
            "Epoch 15: val_accuracy did not improve from 0.51250\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.6939 - accuracy: 0.4738 - sensitivity_at_specificity: 0.0041 - specificity_at_sensitivity: 0.0052 - recall: 0.9439 - precision: 0.4724 - val_loss: 0.6937 - val_accuracy: 0.4930 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.0000e+00 - val_recall: 1.0000 - val_precision: 0.4930\n",
            "Epoch 16/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6937 - accuracy: 0.4949 - sensitivity_at_specificity: 0.0024 - specificity_at_sensitivity: 0.0068 - recall: 0.9149 - precision: 0.4899\n",
            "Epoch 16: val_accuracy improved from 0.51250 to 0.51719, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.6937 - accuracy: 0.4949 - sensitivity_at_specificity: 0.0024 - specificity_at_sensitivity: 0.0068 - recall: 0.9149 - precision: 0.4899 - val_loss: 0.6936 - val_accuracy: 0.5172 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.0000e+00 - val_recall: 1.0000 - val_precision: 0.5172\n",
            "Epoch 17/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6937 - accuracy: 0.4938 - sensitivity_at_specificity: 0.0032 - specificity_at_sensitivity: 0.0147 - recall: 0.7305 - precision: 0.4928\n",
            "Epoch 17: val_accuracy did not improve from 0.51719\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.6937 - accuracy: 0.4938 - sensitivity_at_specificity: 0.0032 - specificity_at_sensitivity: 0.0147 - recall: 0.7305 - precision: 0.4928 - val_loss: 0.6937 - val_accuracy: 0.4805 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
            "Epoch 18/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6936 - accuracy: 0.5082 - sensitivity_at_specificity: 0.0024 - specificity_at_sensitivity: 0.0262 - recall: 0.0024 - precision: 0.7500\n",
            "Epoch 18: val_accuracy did not improve from 0.51719\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.6936 - accuracy: 0.5082 - sensitivity_at_specificity: 0.0024 - specificity_at_sensitivity: 0.0262 - recall: 0.0024 - precision: 0.7500 - val_loss: 0.6937 - val_accuracy: 0.4875 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
            "Epoch 19/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6936 - accuracy: 0.5043 - sensitivity_at_specificity: 0.0031 - specificity_at_sensitivity: 0.0334 - recall: 0.0047 - precision: 0.6000\n",
            "Epoch 19: val_accuracy did not improve from 0.51719\n",
            "10/10 [==============================] - 2s 157ms/step - loss: 0.6936 - accuracy: 0.5043 - sensitivity_at_specificity: 0.0031 - specificity_at_sensitivity: 0.0334 - recall: 0.0047 - precision: 0.6000 - val_loss: 0.6936 - val_accuracy: 0.5016 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
            "Epoch 20/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6937 - accuracy: 0.4957 - sensitivity_at_specificity: 0.0016 - specificity_at_sensitivity: 0.0817 - recall: 0.0016 - precision: 0.2500\n",
            "Epoch 20: val_accuracy improved from 0.51719 to 0.52031, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 179ms/step - loss: 0.6937 - accuracy: 0.4957 - sensitivity_at_specificity: 0.0016 - specificity_at_sensitivity: 0.0817 - recall: 0.0016 - precision: 0.2500 - val_loss: 0.6936 - val_accuracy: 0.5203 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
            "Epoch 21/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6936 - accuracy: 0.5055 - sensitivity_at_specificity: 0.0000e+00 - specificity_at_sensitivity: 0.0887 - recall: 7.9114e-04 - precision: 0.2500\n",
            "Epoch 21: val_accuracy did not improve from 0.52031\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.6936 - accuracy: 0.5055 - sensitivity_at_specificity: 0.0000e+00 - specificity_at_sensitivity: 0.0887 - recall: 7.9114e-04 - precision: 0.2500 - val_loss: 0.6937 - val_accuracy: 0.4945 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
            "Epoch 22/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6935 - accuracy: 0.5148 - sensitivity_at_specificity: 8.0515e-04 - specificity_at_sensitivity: 0.3384 - recall: 8.0515e-04 - precision: 0.5000\n",
            "Epoch 22: val_accuracy did not improve from 0.52031\n",
            "10/10 [==============================] - 2s 157ms/step - loss: 0.6935 - accuracy: 0.5148 - sensitivity_at_specificity: 8.0515e-04 - specificity_at_sensitivity: 0.3384 - recall: 8.0515e-04 - precision: 0.5000 - val_loss: 0.6934 - val_accuracy: 0.5164 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
            "Epoch 23/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6939 - accuracy: 0.4828 - sensitivity_at_specificity: 0.3577 - specificity_at_sensitivity: 0.2445 - recall: 7.5472e-04 - precision: 1.0000    \n",
            "Epoch 23: val_accuracy did not improve from 0.52031\n",
            "10/10 [==============================] - 2s 156ms/step - loss: 0.6939 - accuracy: 0.4828 - sensitivity_at_specificity: 0.3577 - specificity_at_sensitivity: 0.2445 - recall: 7.5472e-04 - precision: 1.0000 - val_loss: 0.6936 - val_accuracy: 0.5047 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
            "Epoch 24/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6935 - accuracy: 0.5070 - sensitivity_at_specificity: 0.0000e+00 - specificity_at_sensitivity: 0.3295 - recall: 0.0000e+00 - precision: 0.0000e+00\n",
            "Epoch 24: val_accuracy did not improve from 0.52031\n",
            "10/10 [==============================] - 2s 210ms/step - loss: 0.6935 - accuracy: 0.5070 - sensitivity_at_specificity: 0.0000e+00 - specificity_at_sensitivity: 0.3295 - recall: 0.0000e+00 - precision: 0.0000e+00 - val_loss: 0.6937 - val_accuracy: 0.4836 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.0113 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
            "Epoch 25/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6936 - accuracy: 0.5125 - sensitivity_at_specificity: 0.0000e+00 - specificity_at_sensitivity: 0.4604 - recall: 0.0000e+00 - precision: 0.0000e+00\n",
            "Epoch 25: val_accuracy did not improve from 0.52031\n",
            "10/10 [==============================] - 2s 154ms/step - loss: 0.6936 - accuracy: 0.5125 - sensitivity_at_specificity: 0.0000e+00 - specificity_at_sensitivity: 0.4604 - recall: 0.0000e+00 - precision: 0.0000e+00 - val_loss: 0.6936 - val_accuracy: 0.4945 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.3254 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
            "Epoch 26/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6938 - accuracy: 0.4918 - sensitivity_at_specificity: 7.6805e-04 - specificity_at_sensitivity: 0.3998 - recall: 7.6805e-04 - precision: 1.0000\n",
            "Epoch 26: val_accuracy did not improve from 0.52031\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.6938 - accuracy: 0.4918 - sensitivity_at_specificity: 7.6805e-04 - specificity_at_sensitivity: 0.3998 - recall: 7.6805e-04 - precision: 1.0000 - val_loss: 0.6937 - val_accuracy: 0.4938 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
            "Epoch 27/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6936 - accuracy: 0.4910 - sensitivity_at_specificity: 7.6687e-04 - specificity_at_sensitivity: 0.1226 - recall: 7.6687e-04 - precision: 1.0000\n",
            "Epoch 27: val_accuracy did not improve from 0.52031\n",
            "10/10 [==============================] - 2s 157ms/step - loss: 0.6936 - accuracy: 0.4910 - sensitivity_at_specificity: 7.6687e-04 - specificity_at_sensitivity: 0.1226 - recall: 7.6687e-04 - precision: 1.0000 - val_loss: 0.6936 - val_accuracy: 0.5117 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
            "Epoch 28/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6937 - accuracy: 0.4953 - sensitivity_at_specificity: 0.0000e+00 - specificity_at_sensitivity: 0.0686 - recall: 0.0000e+00 - precision: 0.0000e+00\n",
            "Epoch 28: val_accuracy did not improve from 0.52031\n",
            "10/10 [==============================] - 2s 156ms/step - loss: 0.6937 - accuracy: 0.4953 - sensitivity_at_specificity: 0.0000e+00 - specificity_at_sensitivity: 0.0686 - recall: 0.0000e+00 - precision: 0.0000e+00 - val_loss: 0.6936 - val_accuracy: 0.5047 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
            "Epoch 29/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6936 - accuracy: 0.5152 - sensitivity_at_specificity: 0.0000e+00 - specificity_at_sensitivity: 0.0696 - recall: 0.0000e+00 - precision: 0.0000e+00\n",
            "Epoch 29: val_accuracy did not improve from 0.52031\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.6936 - accuracy: 0.5152 - sensitivity_at_specificity: 0.0000e+00 - specificity_at_sensitivity: 0.0696 - recall: 0.0000e+00 - precision: 0.0000e+00 - val_loss: 0.6936 - val_accuracy: 0.4828 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.0049 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
            "Epoch 30/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6937 - accuracy: 0.4859 - sensitivity_at_specificity: 0.0000e+00 - specificity_at_sensitivity: 0.3842 - recall: 0.0000e+00 - precision: 0.0000e+00\n",
            "Epoch 30: val_accuracy did not improve from 0.52031\n",
            "10/10 [==============================] - 2s 157ms/step - loss: 0.6937 - accuracy: 0.4859 - sensitivity_at_specificity: 0.0000e+00 - specificity_at_sensitivity: 0.3842 - recall: 0.0000e+00 - precision: 0.0000e+00 - val_loss: 0.6931 - val_accuracy: 0.5047 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4334 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
            "Epoch 31/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6932 - accuracy: 0.5039 - sensitivity_at_specificity: 0.5047 - specificity_at_sensitivity: 0.5249 - recall: 0.0266 - precision: 0.5484\n",
            "Epoch 31: val_accuracy did not improve from 0.52031\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.6932 - accuracy: 0.5039 - sensitivity_at_specificity: 0.5047 - specificity_at_sensitivity: 0.5249 - recall: 0.0266 - precision: 0.5484 - val_loss: 0.6926 - val_accuracy: 0.4812 - val_sensitivity_at_specificity: 0.2289 - val_specificity_at_sensitivity: 0.4756 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
            "Epoch 32/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6918 - accuracy: 0.5105 - sensitivity_at_specificity: 0.2634 - specificity_at_sensitivity: 0.4868 - recall: 0.0841 - precision: 0.5487\n",
            "Epoch 32: val_accuracy did not improve from 0.52031\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.6918 - accuracy: 0.5105 - sensitivity_at_specificity: 0.2634 - specificity_at_sensitivity: 0.4868 - recall: 0.0841 - precision: 0.5487 - val_loss: 0.6896 - val_accuracy: 0.4898 - val_sensitivity_at_specificity: 0.5619 - val_specificity_at_sensitivity: 0.5394 - val_recall: 0.0062 - val_precision: 0.2667\n",
            "Epoch 33/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6890 - accuracy: 0.5195 - sensitivity_at_specificity: 0.4958 - specificity_at_sensitivity: 0.4932 - recall: 0.4205 - precision: 0.5416\n",
            "Epoch 33: val_accuracy improved from 0.52031 to 0.52969, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.6890 - accuracy: 0.5195 - sensitivity_at_specificity: 0.4958 - specificity_at_sensitivity: 0.4932 - recall: 0.4205 - precision: 0.5416 - val_loss: 0.6875 - val_accuracy: 0.5297 - val_sensitivity_at_specificity: 0.5047 - val_specificity_at_sensitivity: 0.5480 - val_recall: 0.4685 - val_precision: 0.5285\n",
            "Epoch 34/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6877 - accuracy: 0.5422 - sensitivity_at_specificity: 0.0031 - specificity_at_sensitivity: 0.4572 - recall: 0.7109 - precision: 0.5403\n",
            "Epoch 34: val_accuracy improved from 0.52969 to 0.54922, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.6877 - accuracy: 0.5422 - sensitivity_at_specificity: 0.0031 - specificity_at_sensitivity: 0.4572 - recall: 0.7109 - precision: 0.5403 - val_loss: 0.6734 - val_accuracy: 0.5492 - val_sensitivity_at_specificity: 0.5744 - val_specificity_at_sensitivity: 0.5206 - val_recall: 0.5888 - val_precision: 0.5349\n",
            "Epoch 35/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6752 - accuracy: 0.5566 - sensitivity_at_specificity: 0.0085 - specificity_at_sensitivity: 0.3888 - recall: 0.7263 - precision: 0.5470\n",
            "Epoch 35: val_accuracy improved from 0.54922 to 0.55391, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.6752 - accuracy: 0.5566 - sensitivity_at_specificity: 0.0085 - specificity_at_sensitivity: 0.3888 - recall: 0.7263 - precision: 0.5470 - val_loss: 0.6721 - val_accuracy: 0.5539 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.3013 - val_recall: 0.7988 - val_precision: 0.5441\n",
            "Epoch 36/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6709 - accuracy: 0.5645 - sensitivity_at_specificity: 0.2125 - specificity_at_sensitivity: 0.3222 - recall: 0.8141 - precision: 0.5418\n",
            "Epoch 36: val_accuracy improved from 0.55391 to 0.58750, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.6709 - accuracy: 0.5645 - sensitivity_at_specificity: 0.2125 - specificity_at_sensitivity: 0.3222 - recall: 0.8141 - precision: 0.5418 - val_loss: 0.6663 - val_accuracy: 0.5875 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.2551 - val_recall: 0.9236 - val_precision: 0.5528\n",
            "Epoch 37/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6670 - accuracy: 0.5758 - sensitivity_at_specificity: 0.4311 - specificity_at_sensitivity: 0.2784 - recall: 0.8814 - precision: 0.5513\n",
            "Epoch 37: val_accuracy improved from 0.58750 to 0.59219, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.6670 - accuracy: 0.5758 - sensitivity_at_specificity: 0.4311 - specificity_at_sensitivity: 0.2784 - recall: 0.8814 - precision: 0.5513 - val_loss: 0.6621 - val_accuracy: 0.5922 - val_sensitivity_at_specificity: 0.0061 - val_specificity_at_sensitivity: 0.2676 - val_recall: 0.9238 - val_precision: 0.5622\n",
            "Epoch 38/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6533 - accuracy: 0.5848 - sensitivity_at_specificity: 0.4918 - specificity_at_sensitivity: 0.4855 - recall: 0.9058 - precision: 0.5527\n",
            "Epoch 38: val_accuracy improved from 0.59219 to 0.60156, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.6533 - accuracy: 0.5848 - sensitivity_at_specificity: 0.4918 - specificity_at_sensitivity: 0.4855 - recall: 0.9058 - precision: 0.5527 - val_loss: 0.6485 - val_accuracy: 0.6016 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.2678 - val_recall: 0.9479 - val_precision: 0.5575\n",
            "Epoch 39/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6539 - accuracy: 0.5773 - sensitivity_at_specificity: 0.4929 - specificity_at_sensitivity: 0.4907 - recall: 0.9237 - precision: 0.5440\n",
            "Epoch 39: val_accuracy did not improve from 0.60156\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.6539 - accuracy: 0.5773 - sensitivity_at_specificity: 0.4929 - specificity_at_sensitivity: 0.4907 - recall: 0.9237 - precision: 0.5440 - val_loss: 0.6475 - val_accuracy: 0.5758 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.2620 - val_recall: 0.9232 - val_precision: 0.5325\n",
            "Epoch 40/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6396 - accuracy: 0.5938 - sensitivity_at_specificity: 0.6498 - specificity_at_sensitivity: 0.5123 - recall: 0.9374 - precision: 0.5518\n",
            "Epoch 40: val_accuracy improved from 0.60156 to 0.61484, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.6396 - accuracy: 0.5938 - sensitivity_at_specificity: 0.6498 - specificity_at_sensitivity: 0.5123 - recall: 0.9374 - precision: 0.5518 - val_loss: 0.6320 - val_accuracy: 0.6148 - val_sensitivity_at_specificity: 0.0125 - val_specificity_at_sensitivity: 0.2875 - val_recall: 0.9484 - val_precision: 0.5689\n",
            "Epoch 41/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6454 - accuracy: 0.6031 - sensitivity_at_specificity: 0.4596 - specificity_at_sensitivity: 0.4551 - recall: 0.9424 - precision: 0.5658\n",
            "Epoch 41: val_accuracy did not improve from 0.61484\n",
            "10/10 [==============================] - 2s 154ms/step - loss: 0.6454 - accuracy: 0.6031 - sensitivity_at_specificity: 0.4596 - specificity_at_sensitivity: 0.4551 - recall: 0.9424 - precision: 0.5658 - val_loss: 0.6458 - val_accuracy: 0.5867 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.2438 - val_recall: 0.9344 - val_precision: 0.5512\n",
            "Epoch 42/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6447 - accuracy: 0.5922 - sensitivity_at_specificity: 0.6202 - specificity_at_sensitivity: 0.5244 - recall: 0.9303 - precision: 0.5482\n",
            "Epoch 42: val_accuracy did not improve from 0.61484\n",
            "10/10 [==============================] - 2s 155ms/step - loss: 0.6447 - accuracy: 0.5922 - sensitivity_at_specificity: 0.6202 - specificity_at_sensitivity: 0.5244 - recall: 0.9303 - precision: 0.5482 - val_loss: 0.6504 - val_accuracy: 0.5906 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.2550 - val_recall: 0.9352 - val_precision: 0.5507\n",
            "Epoch 43/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6510 - accuracy: 0.5934 - sensitivity_at_specificity: 0.4175 - specificity_at_sensitivity: 0.4185 - recall: 0.9417 - precision: 0.5598\n",
            "Epoch 43: val_accuracy did not improve from 0.61484\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.6510 - accuracy: 0.5934 - sensitivity_at_specificity: 0.4175 - specificity_at_sensitivity: 0.4185 - recall: 0.9417 - precision: 0.5598 - val_loss: 0.6463 - val_accuracy: 0.5766 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.2617 - val_recall: 0.9382 - val_precision: 0.5338\n",
            "Epoch 44/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6418 - accuracy: 0.6059 - sensitivity_at_specificity: 0.5687 - specificity_at_sensitivity: 0.5342 - recall: 0.9453 - precision: 0.5706\n",
            "Epoch 44: val_accuracy did not improve from 0.61484\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.6418 - accuracy: 0.6059 - sensitivity_at_specificity: 0.5687 - specificity_at_sensitivity: 0.5342 - recall: 0.9453 - precision: 0.5706 - val_loss: 0.6331 - val_accuracy: 0.5867 - val_sensitivity_at_specificity: 0.1075 - val_specificity_at_sensitivity: 0.2613 - val_recall: 0.9414 - val_precision: 0.5397\n",
            "Epoch 45/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6317 - accuracy: 0.6285 - sensitivity_at_specificity: 0.5374 - specificity_at_sensitivity: 0.5889 - recall: 0.9482 - precision: 0.5925\n",
            "Epoch 45: val_accuracy did not improve from 0.61484\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.6317 - accuracy: 0.6285 - sensitivity_at_specificity: 0.5374 - specificity_at_sensitivity: 0.5889 - recall: 0.9482 - precision: 0.5925 - val_loss: 0.6382 - val_accuracy: 0.6000 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.2562 - val_recall: 0.9544 - val_precision: 0.5569\n",
            "Epoch 46/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6526 - accuracy: 0.5824 - sensitivity_at_specificity: 0.5477 - specificity_at_sensitivity: 0.5773 - recall: 0.9539 - precision: 0.5473\n",
            "Epoch 46: val_accuracy did not improve from 0.61484\n",
            "10/10 [==============================] - 2s 157ms/step - loss: 0.6526 - accuracy: 0.5824 - sensitivity_at_specificity: 0.5477 - specificity_at_sensitivity: 0.5773 - recall: 0.9539 - precision: 0.5473 - val_loss: 0.6436 - val_accuracy: 0.6102 - val_sensitivity_at_specificity: 0.0015 - val_specificity_at_sensitivity: 0.2215 - val_recall: 0.9700 - val_precision: 0.5742\n",
            "Epoch 47/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6470 - accuracy: 0.5941 - sensitivity_at_specificity: 0.3804 - specificity_at_sensitivity: 0.4803 - recall: 0.8579 - precision: 0.5635\n",
            "Epoch 47: val_accuracy did not improve from 0.61484\n",
            "10/10 [==============================] - 2s 157ms/step - loss: 0.6470 - accuracy: 0.5941 - sensitivity_at_specificity: 0.3804 - specificity_at_sensitivity: 0.4803 - recall: 0.8579 - precision: 0.5635 - val_loss: 0.6465 - val_accuracy: 0.6023 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.2309 - val_recall: 0.9617 - val_precision: 0.5644\n",
            "Epoch 48/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6457 - accuracy: 0.5941 - sensitivity_at_specificity: 0.5166 - specificity_at_sensitivity: 0.6025 - recall: 0.9476 - precision: 0.5586\n",
            "Epoch 48: val_accuracy did not improve from 0.61484\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.6457 - accuracy: 0.5941 - sensitivity_at_specificity: 0.5166 - specificity_at_sensitivity: 0.6025 - recall: 0.9476 - precision: 0.5586 - val_loss: 0.6504 - val_accuracy: 0.5867 - val_sensitivity_at_specificity: 0.0110 - val_specificity_at_sensitivity: 0.2271 - val_recall: 0.9545 - val_precision: 0.5487\n",
            "Epoch 49/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6396 - accuracy: 0.5926 - sensitivity_at_specificity: 0.5737 - specificity_at_sensitivity: 0.5385 - recall: 0.9532 - precision: 0.5501\n",
            "Epoch 49: val_accuracy did not improve from 0.61484\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.6396 - accuracy: 0.5926 - sensitivity_at_specificity: 0.5737 - specificity_at_sensitivity: 0.5385 - recall: 0.9532 - precision: 0.5501 - val_loss: 0.6402 - val_accuracy: 0.5836 - val_sensitivity_at_specificity: 0.0049 - val_specificity_at_sensitivity: 0.2541 - val_recall: 0.9493 - val_precision: 0.5360\n",
            "Epoch 50/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6443 - accuracy: 0.5820 - sensitivity_at_specificity: 0.5534 - specificity_at_sensitivity: 0.5460 - recall: 0.9558 - precision: 0.5397\n",
            "Epoch 50: val_accuracy did not improve from 0.61484\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.6443 - accuracy: 0.5820 - sensitivity_at_specificity: 0.5534 - specificity_at_sensitivity: 0.5460 - recall: 0.9558 - precision: 0.5397 - val_loss: 0.6456 - val_accuracy: 0.5969 - val_sensitivity_at_specificity: 0.0016 - val_specificity_at_sensitivity: 0.2488 - val_recall: 0.9498 - val_precision: 0.5556\n",
            "Epoch 51/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6449 - accuracy: 0.6012 - sensitivity_at_specificity: 0.3960 - specificity_at_sensitivity: 0.3491 - recall: 0.9495 - precision: 0.5613\n",
            "Epoch 51: val_accuracy did not improve from 0.61484\n",
            "10/10 [==============================] - 2s 180ms/step - loss: 0.6449 - accuracy: 0.6012 - sensitivity_at_specificity: 0.3960 - specificity_at_sensitivity: 0.3491 - recall: 0.9495 - precision: 0.5613 - val_loss: 0.6609 - val_accuracy: 0.5680 - val_sensitivity_at_specificity: 0.0094 - val_specificity_at_sensitivity: 0.2050 - val_recall: 0.9355 - val_precision: 0.5375\n",
            "Epoch 52/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6351 - accuracy: 0.6238 - sensitivity_at_specificity: 0.5507 - specificity_at_sensitivity: 0.5885 - recall: 0.9565 - precision: 0.5806\n",
            "Epoch 52: val_accuracy did not improve from 0.61484\n",
            "10/10 [==============================] - 3s 238ms/step - loss: 0.6351 - accuracy: 0.6238 - sensitivity_at_specificity: 0.5507 - specificity_at_sensitivity: 0.5885 - recall: 0.9565 - precision: 0.5806 - val_loss: 0.6438 - val_accuracy: 0.6008 - val_sensitivity_at_specificity: 0.0077 - val_specificity_at_sensitivity: 0.2397 - val_recall: 0.9569 - val_precision: 0.5629\n",
            "Epoch 53/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6427 - accuracy: 0.5953 - sensitivity_at_specificity: 0.5844 - specificity_at_sensitivity: 0.5368 - recall: 0.9443 - precision: 0.5511\n",
            "Epoch 53: val_accuracy did not improve from 0.61484\n",
            "10/10 [==============================] - 2s 156ms/step - loss: 0.6427 - accuracy: 0.5953 - sensitivity_at_specificity: 0.5844 - specificity_at_sensitivity: 0.5368 - recall: 0.9443 - precision: 0.5511 - val_loss: 0.6453 - val_accuracy: 0.5867 - val_sensitivity_at_specificity: 0.0080 - val_specificity_at_sensitivity: 0.2386 - val_recall: 0.9582 - val_precision: 0.5423\n",
            "Epoch 54/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6451 - accuracy: 0.6008 - sensitivity_at_specificity: 0.4815 - specificity_at_sensitivity: 0.3857 - recall: 0.9538 - precision: 0.5631\n",
            "Epoch 54: val_accuracy did not improve from 0.61484\n",
            "10/10 [==============================] - 2s 157ms/step - loss: 0.6451 - accuracy: 0.6008 - sensitivity_at_specificity: 0.4815 - specificity_at_sensitivity: 0.3857 - recall: 0.9538 - precision: 0.5631 - val_loss: 0.6455 - val_accuracy: 0.5820 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.2791 - val_recall: 0.9570 - val_precision: 0.5419\n",
            "Epoch 55/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6479 - accuracy: 0.5885 - sensitivity_at_specificity: 0.6096 - specificity_at_sensitivity: 0.5029 - recall: 0.9463 - precision: 0.5487\n",
            "Epoch 55: val_accuracy did not improve from 0.61484\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.6479 - accuracy: 0.5885 - sensitivity_at_specificity: 0.6096 - specificity_at_sensitivity: 0.5029 - recall: 0.9463 - precision: 0.5487 - val_loss: 0.6382 - val_accuracy: 0.6031 - val_sensitivity_at_specificity: 0.3297 - val_specificity_at_sensitivity: 0.2461 - val_recall: 0.9582 - val_precision: 0.5627\n",
            "Epoch 56/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6312 - accuracy: 0.6027 - sensitivity_at_specificity: 0.6135 - specificity_at_sensitivity: 0.5200 - recall: 0.9556 - precision: 0.5561\n",
            "Epoch 56: val_accuracy did not improve from 0.61484\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.6312 - accuracy: 0.6027 - sensitivity_at_specificity: 0.6135 - specificity_at_sensitivity: 0.5200 - recall: 0.9556 - precision: 0.5561 - val_loss: 0.6497 - val_accuracy: 0.5953 - val_sensitivity_at_specificity: 0.1747 - val_specificity_at_sensitivity: 0.2401 - val_recall: 0.9428 - val_precision: 0.5591\n",
            "Epoch 57/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6317 - accuracy: 0.6023 - sensitivity_at_specificity: 0.5723 - specificity_at_sensitivity: 0.5539 - recall: 0.9480 - precision: 0.5545\n",
            "Epoch 57: val_accuracy did not improve from 0.61484\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.6317 - accuracy: 0.6023 - sensitivity_at_specificity: 0.5723 - specificity_at_sensitivity: 0.5539 - recall: 0.9480 - precision: 0.5545 - val_loss: 0.6492 - val_accuracy: 0.5844 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.2461 - val_recall: 0.9279 - val_precision: 0.5492\n",
            "Epoch 58/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6362 - accuracy: 0.5984 - sensitivity_at_specificity: 0.5332 - specificity_at_sensitivity: 0.5546 - recall: 0.9496 - precision: 0.5518\n",
            "Epoch 58: val_accuracy did not improve from 0.61484\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.6362 - accuracy: 0.5984 - sensitivity_at_specificity: 0.5332 - specificity_at_sensitivity: 0.5546 - recall: 0.9496 - precision: 0.5518 - val_loss: 0.6442 - val_accuracy: 0.5930 - val_sensitivity_at_specificity: 0.0171 - val_specificity_at_sensitivity: 0.2288 - val_recall: 0.9579 - val_precision: 0.5546\n",
            "Epoch 59/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6489 - accuracy: 0.5832 - sensitivity_at_specificity: 0.4341 - specificity_at_sensitivity: 0.3972 - recall: 0.9464 - precision: 0.5421\n",
            "Epoch 59: val_accuracy did not improve from 0.61484\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.6489 - accuracy: 0.5832 - sensitivity_at_specificity: 0.4341 - specificity_at_sensitivity: 0.3972 - recall: 0.9464 - precision: 0.5421 - val_loss: 0.6467 - val_accuracy: 0.5922 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.2399 - val_recall: 0.9498 - val_precision: 0.5529\n",
            "Epoch 60/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6434 - accuracy: 0.5926 - sensitivity_at_specificity: 0.4288 - specificity_at_sensitivity: 0.3686 - recall: 0.9440 - precision: 0.5554\n",
            "Epoch 60: val_accuracy did not improve from 0.61484\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.6434 - accuracy: 0.5926 - sensitivity_at_specificity: 0.4288 - specificity_at_sensitivity: 0.3686 - recall: 0.9440 - precision: 0.5554 - val_loss: 0.6490 - val_accuracy: 0.6000 - val_sensitivity_at_specificity: 0.2343 - val_specificity_at_sensitivity: 0.2600 - val_recall: 0.9372 - val_precision: 0.5651\n",
            "Epoch 61/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6415 - accuracy: 0.5945 - sensitivity_at_specificity: 0.5326 - specificity_at_sensitivity: 0.5362 - recall: 0.9480 - precision: 0.5570\n",
            "Epoch 61: val_accuracy did not improve from 0.61484\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.6415 - accuracy: 0.5945 - sensitivity_at_specificity: 0.5326 - specificity_at_sensitivity: 0.5362 - recall: 0.9480 - precision: 0.5570 - val_loss: 0.6387 - val_accuracy: 0.5938 - val_sensitivity_at_specificity: 0.2844 - val_specificity_at_sensitivity: 0.2535 - val_recall: 0.9542 - val_precision: 0.5516\n",
            "Epoch 62/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6346 - accuracy: 0.5949 - sensitivity_at_specificity: 0.5400 - specificity_at_sensitivity: 0.6238 - recall: 0.8754 - precision: 0.5599\n",
            "Epoch 62: val_accuracy did not improve from 0.61484\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.6346 - accuracy: 0.5949 - sensitivity_at_specificity: 0.5400 - specificity_at_sensitivity: 0.6238 - recall: 0.8754 - precision: 0.5599 - val_loss: 0.6306 - val_accuracy: 0.6141 - val_sensitivity_at_specificity: 0.2989 - val_specificity_at_sensitivity: 0.3779 - val_recall: 0.9444 - val_precision: 0.5641\n",
            "Epoch 63/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6261 - accuracy: 0.6207 - sensitivity_at_specificity: 0.6796 - specificity_at_sensitivity: 0.6484 - recall: 0.9432 - precision: 0.5746\n",
            "Epoch 63: val_accuracy did not improve from 0.61484\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.6261 - accuracy: 0.6207 - sensitivity_at_specificity: 0.6796 - specificity_at_sensitivity: 0.6484 - recall: 0.9432 - precision: 0.5746 - val_loss: 0.6320 - val_accuracy: 0.5992 - val_sensitivity_at_specificity: 0.2449 - val_specificity_at_sensitivity: 0.4420 - val_recall: 0.9242 - val_precision: 0.5571\n",
            "Epoch 64/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6347 - accuracy: 0.6137 - sensitivity_at_specificity: 0.6532 - specificity_at_sensitivity: 0.6257 - recall: 0.8882 - precision: 0.5811\n",
            "Epoch 64: val_accuracy did not improve from 0.61484\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.6347 - accuracy: 0.6137 - sensitivity_at_specificity: 0.6532 - specificity_at_sensitivity: 0.6257 - recall: 0.8882 - precision: 0.5811 - val_loss: 0.6406 - val_accuracy: 0.6094 - val_sensitivity_at_specificity: 0.1009 - val_specificity_at_sensitivity: 0.4968 - val_recall: 0.9388 - val_precision: 0.5717\n",
            "Epoch 65/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6301 - accuracy: 0.6047 - sensitivity_at_specificity: 0.6432 - specificity_at_sensitivity: 0.6219 - recall: 0.8956 - precision: 0.5626\n",
            "Epoch 65: val_accuracy did not improve from 0.61484\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.6301 - accuracy: 0.6047 - sensitivity_at_specificity: 0.6432 - specificity_at_sensitivity: 0.6219 - recall: 0.8956 - precision: 0.5626 - val_loss: 0.6309 - val_accuracy: 0.6133 - val_sensitivity_at_specificity: 0.7039 - val_specificity_at_sensitivity: 0.6683 - val_recall: 0.8746 - val_precision: 0.5843\n",
            "Epoch 66/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6264 - accuracy: 0.6145 - sensitivity_at_specificity: 0.6643 - specificity_at_sensitivity: 0.6504 - recall: 0.8695 - precision: 0.5774\n",
            "Epoch 66: val_accuracy improved from 0.61484 to 0.62500, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.6264 - accuracy: 0.6145 - sensitivity_at_specificity: 0.6643 - specificity_at_sensitivity: 0.6504 - recall: 0.8695 - precision: 0.5774 - val_loss: 0.6340 - val_accuracy: 0.6250 - val_sensitivity_at_specificity: 0.6073 - val_specificity_at_sensitivity: 0.5939 - val_recall: 0.9411 - val_precision: 0.5855\n",
            "Epoch 67/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6212 - accuracy: 0.6187 - sensitivity_at_specificity: 0.7289 - specificity_at_sensitivity: 0.6556 - recall: 0.8545 - precision: 0.5771\n",
            "Epoch 67: val_accuracy did not improve from 0.62500\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.6212 - accuracy: 0.6187 - sensitivity_at_specificity: 0.7289 - specificity_at_sensitivity: 0.6556 - recall: 0.8545 - precision: 0.5771 - val_loss: 0.6243 - val_accuracy: 0.6242 - val_sensitivity_at_specificity: 0.7172 - val_specificity_at_sensitivity: 0.5657 - val_recall: 0.8989 - val_precision: 0.5771\n",
            "Epoch 68/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6163 - accuracy: 0.6293 - sensitivity_at_specificity: 0.7405 - specificity_at_sensitivity: 0.6727 - recall: 0.8394 - precision: 0.5918\n",
            "Epoch 68: val_accuracy did not improve from 0.62500\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.6163 - accuracy: 0.6293 - sensitivity_at_specificity: 0.7405 - specificity_at_sensitivity: 0.6727 - recall: 0.8394 - precision: 0.5918 - val_loss: 0.6292 - val_accuracy: 0.6086 - val_sensitivity_at_specificity: 0.6878 - val_specificity_at_sensitivity: 0.6003 - val_recall: 0.9212 - val_precision: 0.5698\n",
            "Epoch 69/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6348 - accuracy: 0.6078 - sensitivity_at_specificity: 0.7136 - specificity_at_sensitivity: 0.6627 - recall: 0.8420 - precision: 0.5746\n",
            "Epoch 69: val_accuracy did not improve from 0.62500\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.6348 - accuracy: 0.6078 - sensitivity_at_specificity: 0.7136 - specificity_at_sensitivity: 0.6627 - recall: 0.8420 - precision: 0.5746 - val_loss: 0.6304 - val_accuracy: 0.6164 - val_sensitivity_at_specificity: 0.7028 - val_specificity_at_sensitivity: 0.6289 - val_recall: 0.7877 - val_precision: 0.5846\n",
            "Epoch 70/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6205 - accuracy: 0.6176 - sensitivity_at_specificity: 0.7488 - specificity_at_sensitivity: 0.6708 - recall: 0.8844 - precision: 0.5708\n",
            "Epoch 70: val_accuracy did not improve from 0.62500\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.6205 - accuracy: 0.6176 - sensitivity_at_specificity: 0.7488 - specificity_at_sensitivity: 0.6708 - recall: 0.8844 - precision: 0.5708 - val_loss: 0.6167 - val_accuracy: 0.6141 - val_sensitivity_at_specificity: 0.7374 - val_specificity_at_sensitivity: 0.7001 - val_recall: 0.7651 - val_precision: 0.5726\n",
            "Epoch 71/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6175 - accuracy: 0.6211 - sensitivity_at_specificity: 0.7465 - specificity_at_sensitivity: 0.6774 - recall: 0.7830 - precision: 0.5931\n",
            "Epoch 71: val_accuracy improved from 0.62500 to 0.64219, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.6175 - accuracy: 0.6211 - sensitivity_at_specificity: 0.7465 - specificity_at_sensitivity: 0.6774 - recall: 0.7830 - precision: 0.5931 - val_loss: 0.6116 - val_accuracy: 0.6422 - val_sensitivity_at_specificity: 0.7581 - val_specificity_at_sensitivity: 0.7480 - val_recall: 0.8031 - val_precision: 0.6101\n",
            "Epoch 72/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6047 - accuracy: 0.6473 - sensitivity_at_specificity: 0.7894 - specificity_at_sensitivity: 0.7007 - recall: 0.8379 - precision: 0.6059\n",
            "Epoch 72: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.6047 - accuracy: 0.6473 - sensitivity_at_specificity: 0.7894 - specificity_at_sensitivity: 0.7007 - recall: 0.8379 - precision: 0.6059 - val_loss: 0.6204 - val_accuracy: 0.6398 - val_sensitivity_at_specificity: 0.7668 - val_specificity_at_sensitivity: 0.7332 - val_recall: 0.6667 - val_precision: 0.6520\n",
            "Epoch 73/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6098 - accuracy: 0.6328 - sensitivity_at_specificity: 0.7697 - specificity_at_sensitivity: 0.7141 - recall: 0.8284 - precision: 0.5903\n",
            "Epoch 73: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.6098 - accuracy: 0.6328 - sensitivity_at_specificity: 0.7697 - specificity_at_sensitivity: 0.7141 - recall: 0.8284 - precision: 0.5903 - val_loss: 0.6055 - val_accuracy: 0.6352 - val_sensitivity_at_specificity: 0.7796 - val_specificity_at_sensitivity: 0.7481 - val_recall: 0.7893 - val_precision: 0.5910\n",
            "Epoch 74/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6016 - accuracy: 0.6487 - sensitivity_at_specificity: 0.7856 - specificity_at_sensitivity: 0.7410 - recall: 0.7627 - precision: 0.6139\n",
            "Epoch 74: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 155ms/step - loss: 0.6016 - accuracy: 0.6487 - sensitivity_at_specificity: 0.7856 - specificity_at_sensitivity: 0.7410 - recall: 0.7627 - precision: 0.6139 - val_loss: 0.6280 - val_accuracy: 0.6141 - val_sensitivity_at_specificity: 0.6970 - val_specificity_at_sensitivity: 0.7154 - val_recall: 0.9356 - val_precision: 0.5682\n",
            "Epoch 75/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5968 - accuracy: 0.6520 - sensitivity_at_specificity: 0.8006 - specificity_at_sensitivity: 0.7619 - recall: 0.7748 - precision: 0.6217\n",
            "Epoch 75: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.5968 - accuracy: 0.6520 - sensitivity_at_specificity: 0.8006 - specificity_at_sensitivity: 0.7619 - recall: 0.7748 - precision: 0.6217 - val_loss: 0.6046 - val_accuracy: 0.6281 - val_sensitivity_at_specificity: 0.7608 - val_specificity_at_sensitivity: 0.7291 - val_recall: 0.8266 - val_precision: 0.5832\n",
            "Epoch 76/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6000 - accuracy: 0.6379 - sensitivity_at_specificity: 0.7508 - specificity_at_sensitivity: 0.7310 - recall: 0.8310 - precision: 0.6034\n",
            "Epoch 76: val_accuracy improved from 0.64219 to 0.65312, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.6000 - accuracy: 0.6379 - sensitivity_at_specificity: 0.7508 - specificity_at_sensitivity: 0.7310 - recall: 0.8310 - precision: 0.6034 - val_loss: 0.6041 - val_accuracy: 0.6531 - val_sensitivity_at_specificity: 0.8097 - val_specificity_at_sensitivity: 0.7449 - val_recall: 0.8643 - val_precision: 0.6081\n",
            "Epoch 77/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6076 - accuracy: 0.6355 - sensitivity_at_specificity: 0.7464 - specificity_at_sensitivity: 0.7225 - recall: 0.7951 - precision: 0.6112\n",
            "Epoch 77: val_accuracy improved from 0.65312 to 0.66641, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.6076 - accuracy: 0.6355 - sensitivity_at_specificity: 0.7464 - specificity_at_sensitivity: 0.7225 - recall: 0.7951 - precision: 0.6112 - val_loss: 0.5997 - val_accuracy: 0.6664 - val_sensitivity_at_specificity: 0.7994 - val_specificity_at_sensitivity: 0.7572 - val_recall: 0.7796 - val_precision: 0.6453\n",
            "Epoch 78/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6012 - accuracy: 0.6539 - sensitivity_at_specificity: 0.8079 - specificity_at_sensitivity: 0.7342 - recall: 0.8326 - precision: 0.6173\n",
            "Epoch 78: val_accuracy did not improve from 0.66641\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.6012 - accuracy: 0.6539 - sensitivity_at_specificity: 0.8079 - specificity_at_sensitivity: 0.7342 - recall: 0.8326 - precision: 0.6173 - val_loss: 0.5953 - val_accuracy: 0.6586 - val_sensitivity_at_specificity: 0.8205 - val_specificity_at_sensitivity: 0.7349 - val_recall: 0.8126 - val_precision: 0.6187\n",
            "Epoch 79/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5990 - accuracy: 0.6555 - sensitivity_at_specificity: 0.7941 - specificity_at_sensitivity: 0.7502 - recall: 0.7815 - precision: 0.6196\n",
            "Epoch 79: val_accuracy improved from 0.66641 to 0.67500, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.5990 - accuracy: 0.6555 - sensitivity_at_specificity: 0.7941 - specificity_at_sensitivity: 0.7502 - recall: 0.7815 - precision: 0.6196 - val_loss: 0.5962 - val_accuracy: 0.6750 - val_sensitivity_at_specificity: 0.8172 - val_specificity_at_sensitivity: 0.7361 - val_recall: 0.7926 - val_precision: 0.6474\n",
            "Epoch 80/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6001 - accuracy: 0.6555 - sensitivity_at_specificity: 0.7895 - specificity_at_sensitivity: 0.7475 - recall: 0.7408 - precision: 0.6308\n",
            "Epoch 80: val_accuracy did not improve from 0.67500\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.6001 - accuracy: 0.6555 - sensitivity_at_specificity: 0.7895 - specificity_at_sensitivity: 0.7475 - recall: 0.7408 - precision: 0.6308 - val_loss: 0.5896 - val_accuracy: 0.6617 - val_sensitivity_at_specificity: 0.8266 - val_specificity_at_sensitivity: 0.7717 - val_recall: 0.8299 - val_precision: 0.6126\n",
            "Epoch 81/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6041 - accuracy: 0.6391 - sensitivity_at_specificity: 0.7688 - specificity_at_sensitivity: 0.7569 - recall: 0.8293 - precision: 0.6029\n",
            "Epoch 81: val_accuracy did not improve from 0.67500\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.6041 - accuracy: 0.6391 - sensitivity_at_specificity: 0.7688 - specificity_at_sensitivity: 0.7569 - recall: 0.8293 - precision: 0.6029 - val_loss: 0.5940 - val_accuracy: 0.6633 - val_sensitivity_at_specificity: 0.8209 - val_specificity_at_sensitivity: 0.7581 - val_recall: 0.8146 - val_precision: 0.6208\n",
            "Epoch 82/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6002 - accuracy: 0.6508 - sensitivity_at_specificity: 0.8012 - specificity_at_sensitivity: 0.7544 - recall: 0.7704 - precision: 0.6266\n",
            "Epoch 82: val_accuracy did not improve from 0.67500\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.6002 - accuracy: 0.6508 - sensitivity_at_specificity: 0.8012 - specificity_at_sensitivity: 0.7544 - recall: 0.7704 - precision: 0.6266 - val_loss: 0.6011 - val_accuracy: 0.6445 - val_sensitivity_at_specificity: 0.7858 - val_specificity_at_sensitivity: 0.7302 - val_recall: 0.8142 - val_precision: 0.6054\n",
            "Epoch 83/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5857 - accuracy: 0.6547 - sensitivity_at_specificity: 0.7990 - specificity_at_sensitivity: 0.7688 - recall: 0.7464 - precision: 0.6232\n",
            "Epoch 83: val_accuracy did not improve from 0.67500\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.5857 - accuracy: 0.6547 - sensitivity_at_specificity: 0.7990 - specificity_at_sensitivity: 0.7688 - recall: 0.7464 - precision: 0.6232 - val_loss: 0.5854 - val_accuracy: 0.6719 - val_sensitivity_at_specificity: 0.8255 - val_specificity_at_sensitivity: 0.7524 - val_recall: 0.7819 - val_precision: 0.6419\n",
            "Epoch 84/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5956 - accuracy: 0.6566 - sensitivity_at_specificity: 0.8074 - specificity_at_sensitivity: 0.7575 - recall: 0.7851 - precision: 0.6294\n",
            "Epoch 84: val_accuracy did not improve from 0.67500\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.5956 - accuracy: 0.6566 - sensitivity_at_specificity: 0.8074 - specificity_at_sensitivity: 0.7575 - recall: 0.7851 - precision: 0.6294 - val_loss: 0.5974 - val_accuracy: 0.6586 - val_sensitivity_at_specificity: 0.8182 - val_specificity_at_sensitivity: 0.7741 - val_recall: 0.8793 - val_precision: 0.6091\n",
            "Epoch 85/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6045 - accuracy: 0.6445 - sensitivity_at_specificity: 0.7772 - specificity_at_sensitivity: 0.7581 - recall: 0.7449 - precision: 0.6175\n",
            "Epoch 85: val_accuracy did not improve from 0.67500\n",
            "10/10 [==============================] - 2s 207ms/step - loss: 0.6045 - accuracy: 0.6445 - sensitivity_at_specificity: 0.7772 - specificity_at_sensitivity: 0.7581 - recall: 0.7449 - precision: 0.6175 - val_loss: 0.5837 - val_accuracy: 0.6602 - val_sensitivity_at_specificity: 0.8093 - val_specificity_at_sensitivity: 0.7417 - val_recall: 0.7550 - val_precision: 0.6374\n",
            "Epoch 86/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5862 - accuracy: 0.6640 - sensitivity_at_specificity: 0.8275 - specificity_at_sensitivity: 0.7825 - recall: 0.7714 - precision: 0.6321\n",
            "Epoch 86: val_accuracy did not improve from 0.67500\n",
            "10/10 [==============================] - 2s 154ms/step - loss: 0.5862 - accuracy: 0.6640 - sensitivity_at_specificity: 0.8275 - specificity_at_sensitivity: 0.7825 - recall: 0.7714 - precision: 0.6321 - val_loss: 0.5881 - val_accuracy: 0.6695 - val_sensitivity_at_specificity: 0.8318 - val_specificity_at_sensitivity: 0.7873 - val_recall: 0.8019 - val_precision: 0.6320\n",
            "Epoch 87/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5969 - accuracy: 0.6539 - sensitivity_at_specificity: 0.7935 - specificity_at_sensitivity: 0.7886 - recall: 0.7670 - precision: 0.6264\n",
            "Epoch 87: val_accuracy did not improve from 0.67500\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.5969 - accuracy: 0.6539 - sensitivity_at_specificity: 0.7935 - specificity_at_sensitivity: 0.7886 - recall: 0.7670 - precision: 0.6264 - val_loss: 0.5986 - val_accuracy: 0.6578 - val_sensitivity_at_specificity: 0.8105 - val_specificity_at_sensitivity: 0.7702 - val_recall: 0.8459 - val_precision: 0.6189\n",
            "Epoch 88/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5890 - accuracy: 0.6633 - sensitivity_at_specificity: 0.8170 - specificity_at_sensitivity: 0.7889 - recall: 0.7605 - precision: 0.6302\n",
            "Epoch 88: val_accuracy did not improve from 0.67500\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.5890 - accuracy: 0.6633 - sensitivity_at_specificity: 0.8170 - specificity_at_sensitivity: 0.7889 - recall: 0.7605 - precision: 0.6302 - val_loss: 0.5887 - val_accuracy: 0.6539 - val_sensitivity_at_specificity: 0.8377 - val_specificity_at_sensitivity: 0.7646 - val_recall: 0.6399 - val_precision: 0.6635\n",
            "Epoch 89/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5774 - accuracy: 0.6848 - sensitivity_at_specificity: 0.8615 - specificity_at_sensitivity: 0.8048 - recall: 0.7854 - precision: 0.6626\n",
            "Epoch 89: val_accuracy improved from 0.67500 to 0.69063, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.5774 - accuracy: 0.6848 - sensitivity_at_specificity: 0.8615 - specificity_at_sensitivity: 0.8048 - recall: 0.7854 - precision: 0.6626 - val_loss: 0.5597 - val_accuracy: 0.6906 - val_sensitivity_at_specificity: 0.8760 - val_specificity_at_sensitivity: 0.8341 - val_recall: 0.8283 - val_precision: 0.6440\n",
            "Epoch 90/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5820 - accuracy: 0.6645 - sensitivity_at_specificity: 0.8233 - specificity_at_sensitivity: 0.7835 - recall: 0.7805 - precision: 0.6348\n",
            "Epoch 90: val_accuracy did not improve from 0.69063\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.5820 - accuracy: 0.6645 - sensitivity_at_specificity: 0.8233 - specificity_at_sensitivity: 0.7835 - recall: 0.7805 - precision: 0.6348 - val_loss: 0.5807 - val_accuracy: 0.6781 - val_sensitivity_at_specificity: 0.8359 - val_specificity_at_sensitivity: 0.8183 - val_recall: 0.7796 - val_precision: 0.6577\n",
            "Epoch 91/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5881 - accuracy: 0.6711 - sensitivity_at_specificity: 0.8110 - specificity_at_sensitivity: 0.7813 - recall: 0.7429 - precision: 0.6585\n",
            "Epoch 91: val_accuracy did not improve from 0.69063\n",
            "10/10 [==============================] - 2s 155ms/step - loss: 0.5881 - accuracy: 0.6711 - sensitivity_at_specificity: 0.8110 - specificity_at_sensitivity: 0.7813 - recall: 0.7429 - precision: 0.6585 - val_loss: 0.5857 - val_accuracy: 0.6672 - val_sensitivity_at_specificity: 0.8516 - val_specificity_at_sensitivity: 0.7922 - val_recall: 0.8875 - val_precision: 0.6161\n",
            "Epoch 92/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5892 - accuracy: 0.6570 - sensitivity_at_specificity: 0.7992 - specificity_at_sensitivity: 0.7946 - recall: 0.7646 - precision: 0.6265\n",
            "Epoch 92: val_accuracy did not improve from 0.69063\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.5892 - accuracy: 0.6570 - sensitivity_at_specificity: 0.7992 - specificity_at_sensitivity: 0.7946 - recall: 0.7646 - precision: 0.6265 - val_loss: 0.5823 - val_accuracy: 0.6742 - val_sensitivity_at_specificity: 0.8333 - val_specificity_at_sensitivity: 0.7866 - val_recall: 0.8634 - val_precision: 0.6382\n",
            "Epoch 93/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5751 - accuracy: 0.6734 - sensitivity_at_specificity: 0.8207 - specificity_at_sensitivity: 0.8264 - recall: 0.7952 - precision: 0.6531\n",
            "Epoch 93: val_accuracy did not improve from 0.69063\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.5751 - accuracy: 0.6734 - sensitivity_at_specificity: 0.8207 - specificity_at_sensitivity: 0.8264 - recall: 0.7952 - precision: 0.6531 - val_loss: 0.5816 - val_accuracy: 0.6695 - val_sensitivity_at_specificity: 0.8312 - val_specificity_at_sensitivity: 0.8144 - val_recall: 0.8121 - val_precision: 0.6258\n",
            "Epoch 94/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5962 - accuracy: 0.6527 - sensitivity_at_specificity: 0.7825 - specificity_at_sensitivity: 0.7791 - recall: 0.7626 - precision: 0.6324\n",
            "Epoch 94: val_accuracy did not improve from 0.69063\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.5962 - accuracy: 0.6527 - sensitivity_at_specificity: 0.7825 - specificity_at_sensitivity: 0.7791 - recall: 0.7626 - precision: 0.6324 - val_loss: 0.5924 - val_accuracy: 0.6570 - val_sensitivity_at_specificity: 0.7837 - val_specificity_at_sensitivity: 0.7930 - val_recall: 0.7132 - val_precision: 0.6485\n",
            "Epoch 95/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5779 - accuracy: 0.6648 - sensitivity_at_specificity: 0.8141 - specificity_at_sensitivity: 0.7952 - recall: 0.7154 - precision: 0.6362\n",
            "Epoch 95: val_accuracy did not improve from 0.69063\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.5779 - accuracy: 0.6648 - sensitivity_at_specificity: 0.8141 - specificity_at_sensitivity: 0.7952 - recall: 0.7154 - precision: 0.6362 - val_loss: 0.5648 - val_accuracy: 0.6797 - val_sensitivity_at_specificity: 0.8538 - val_specificity_at_sensitivity: 0.8028 - val_recall: 0.7814 - val_precision: 0.6471\n",
            "Epoch 96/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5910 - accuracy: 0.6711 - sensitivity_at_specificity: 0.8197 - specificity_at_sensitivity: 0.7895 - recall: 0.7723 - precision: 0.6442\n",
            "Epoch 96: val_accuracy did not improve from 0.69063\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.5910 - accuracy: 0.6711 - sensitivity_at_specificity: 0.8197 - specificity_at_sensitivity: 0.7895 - recall: 0.7723 - precision: 0.6442 - val_loss: 0.5714 - val_accuracy: 0.6852 - val_sensitivity_at_specificity: 0.8488 - val_specificity_at_sensitivity: 0.8357 - val_recall: 0.7024 - val_precision: 0.6758\n",
            "Epoch 97/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5815 - accuracy: 0.6672 - sensitivity_at_specificity: 0.8246 - specificity_at_sensitivity: 0.8069 - recall: 0.7325 - precision: 0.6419\n",
            "Epoch 97: val_accuracy did not improve from 0.69063\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.5815 - accuracy: 0.6672 - sensitivity_at_specificity: 0.8246 - specificity_at_sensitivity: 0.8069 - recall: 0.7325 - precision: 0.6419 - val_loss: 0.6037 - val_accuracy: 0.6547 - val_sensitivity_at_specificity: 0.8158 - val_specificity_at_sensitivity: 0.7685 - val_recall: 0.8320 - val_precision: 0.6038\n",
            "Epoch 98/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5830 - accuracy: 0.6664 - sensitivity_at_specificity: 0.8042 - specificity_at_sensitivity: 0.8029 - recall: 0.7340 - precision: 0.6516\n",
            "Epoch 98: val_accuracy did not improve from 0.69063\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.5830 - accuracy: 0.6664 - sensitivity_at_specificity: 0.8042 - specificity_at_sensitivity: 0.8029 - recall: 0.7340 - precision: 0.6516 - val_loss: 0.5791 - val_accuracy: 0.6672 - val_sensitivity_at_specificity: 0.8416 - val_specificity_at_sensitivity: 0.8061 - val_recall: 0.8208 - val_precision: 0.6203\n",
            "Epoch 99/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5785 - accuracy: 0.6781 - sensitivity_at_specificity: 0.8386 - specificity_at_sensitivity: 0.8172 - recall: 0.7835 - precision: 0.6543\n",
            "Epoch 99: val_accuracy did not improve from 0.69063\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.5785 - accuracy: 0.6781 - sensitivity_at_specificity: 0.8386 - specificity_at_sensitivity: 0.8172 - recall: 0.7835 - precision: 0.6543 - val_loss: 0.5718 - val_accuracy: 0.6734 - val_sensitivity_at_specificity: 0.8452 - val_specificity_at_sensitivity: 0.8155 - val_recall: 0.8375 - val_precision: 0.6335\n",
            "Epoch 100/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5706 - accuracy: 0.6895 - sensitivity_at_specificity: 0.8355 - specificity_at_sensitivity: 0.8229 - recall: 0.7568 - precision: 0.6712\n",
            "Epoch 100: val_accuracy did not improve from 0.69063\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.5706 - accuracy: 0.6895 - sensitivity_at_specificity: 0.8355 - specificity_at_sensitivity: 0.8229 - recall: 0.7568 - precision: 0.6712 - val_loss: 0.5654 - val_accuracy: 0.6898 - val_sensitivity_at_specificity: 0.8687 - val_specificity_at_sensitivity: 0.8141 - val_recall: 0.7188 - val_precision: 0.6795\n",
            "Epoch 101/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5698 - accuracy: 0.6809 - sensitivity_at_specificity: 0.8403 - specificity_at_sensitivity: 0.8062 - recall: 0.7352 - precision: 0.6586\n",
            "Epoch 101: val_accuracy did not improve from 0.69063\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.5698 - accuracy: 0.6809 - sensitivity_at_specificity: 0.8403 - specificity_at_sensitivity: 0.8062 - recall: 0.7352 - precision: 0.6586 - val_loss: 0.5693 - val_accuracy: 0.6711 - val_sensitivity_at_specificity: 0.8239 - val_specificity_at_sensitivity: 0.8018 - val_recall: 0.7658 - val_precision: 0.6320\n",
            "Epoch 102/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5741 - accuracy: 0.6660 - sensitivity_at_specificity: 0.8301 - specificity_at_sensitivity: 0.8014 - recall: 0.7073 - precision: 0.6505\n",
            "Epoch 102: val_accuracy did not improve from 0.69063\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.5741 - accuracy: 0.6660 - sensitivity_at_specificity: 0.8301 - specificity_at_sensitivity: 0.8014 - recall: 0.7073 - precision: 0.6505 - val_loss: 0.5779 - val_accuracy: 0.6766 - val_sensitivity_at_specificity: 0.8209 - val_specificity_at_sensitivity: 0.7947 - val_recall: 0.7710 - val_precision: 0.6496\n",
            "Epoch 103/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5840 - accuracy: 0.6738 - sensitivity_at_specificity: 0.8254 - specificity_at_sensitivity: 0.8029 - recall: 0.7346 - precision: 0.6508\n",
            "Epoch 103: val_accuracy did not improve from 0.69063\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.5840 - accuracy: 0.6738 - sensitivity_at_specificity: 0.8254 - specificity_at_sensitivity: 0.8029 - recall: 0.7346 - precision: 0.6508 - val_loss: 0.5741 - val_accuracy: 0.6742 - val_sensitivity_at_specificity: 0.8384 - val_specificity_at_sensitivity: 0.7817 - val_recall: 0.7952 - val_precision: 0.6323\n",
            "Epoch 104/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5728 - accuracy: 0.6879 - sensitivity_at_specificity: 0.8358 - specificity_at_sensitivity: 0.8274 - recall: 0.7537 - precision: 0.6692\n",
            "Epoch 104: val_accuracy did not improve from 0.69063\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.5728 - accuracy: 0.6879 - sensitivity_at_specificity: 0.8358 - specificity_at_sensitivity: 0.8274 - recall: 0.7537 - precision: 0.6692 - val_loss: 0.5786 - val_accuracy: 0.6805 - val_sensitivity_at_specificity: 0.8328 - val_specificity_at_sensitivity: 0.8189 - val_recall: 0.7098 - val_precision: 0.6667\n",
            "Epoch 105/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5623 - accuracy: 0.6949 - sensitivity_at_specificity: 0.8460 - specificity_at_sensitivity: 0.8269 - recall: 0.7341 - precision: 0.6747\n",
            "Epoch 105: val_accuracy did not improve from 0.69063\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.5623 - accuracy: 0.6949 - sensitivity_at_specificity: 0.8460 - specificity_at_sensitivity: 0.8269 - recall: 0.7341 - precision: 0.6747 - val_loss: 0.5541 - val_accuracy: 0.6820 - val_sensitivity_at_specificity: 0.8428 - val_specificity_at_sensitivity: 0.8558 - val_recall: 0.7473 - val_precision: 0.6662\n",
            "Epoch 106/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5677 - accuracy: 0.6723 - sensitivity_at_specificity: 0.8346 - specificity_at_sensitivity: 0.8310 - recall: 0.7298 - precision: 0.6569\n",
            "Epoch 106: val_accuracy did not improve from 0.69063\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.5677 - accuracy: 0.6723 - sensitivity_at_specificity: 0.8346 - specificity_at_sensitivity: 0.8310 - recall: 0.7298 - precision: 0.6569 - val_loss: 0.5868 - val_accuracy: 0.6680 - val_sensitivity_at_specificity: 0.8610 - val_specificity_at_sensitivity: 0.8242 - val_recall: 0.9425 - val_precision: 0.6027\n",
            "Epoch 107/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5714 - accuracy: 0.6797 - sensitivity_at_specificity: 0.8244 - specificity_at_sensitivity: 0.8155 - recall: 0.7732 - precision: 0.6486\n",
            "Epoch 107: val_accuracy did not improve from 0.69063\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.5714 - accuracy: 0.6797 - sensitivity_at_specificity: 0.8244 - specificity_at_sensitivity: 0.8155 - recall: 0.7732 - precision: 0.6486 - val_loss: 0.5637 - val_accuracy: 0.6727 - val_sensitivity_at_specificity: 0.8406 - val_specificity_at_sensitivity: 0.8155 - val_recall: 0.8034 - val_precision: 0.6400\n",
            "Epoch 108/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5582 - accuracy: 0.6863 - sensitivity_at_specificity: 0.8534 - specificity_at_sensitivity: 0.8410 - recall: 0.7099 - precision: 0.6830\n",
            "Epoch 108: val_accuracy did not improve from 0.69063\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.5582 - accuracy: 0.6863 - sensitivity_at_specificity: 0.8534 - specificity_at_sensitivity: 0.8410 - recall: 0.7099 - precision: 0.6830 - val_loss: 0.5756 - val_accuracy: 0.6766 - val_sensitivity_at_specificity: 0.8547 - val_specificity_at_sensitivity: 0.8161 - val_recall: 0.8483 - val_precision: 0.6281\n",
            "Epoch 109/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5742 - accuracy: 0.6781 - sensitivity_at_specificity: 0.8324 - specificity_at_sensitivity: 0.8324 - recall: 0.7411 - precision: 0.6520\n",
            "Epoch 109: val_accuracy improved from 0.69063 to 0.69141, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.5742 - accuracy: 0.6781 - sensitivity_at_specificity: 0.8324 - specificity_at_sensitivity: 0.8324 - recall: 0.7411 - precision: 0.6520 - val_loss: 0.5808 - val_accuracy: 0.6914 - val_sensitivity_at_specificity: 0.8606 - val_specificity_at_sensitivity: 0.8118 - val_recall: 0.8193 - val_precision: 0.6589\n",
            "Epoch 110/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5591 - accuracy: 0.6941 - sensitivity_at_specificity: 0.8558 - specificity_at_sensitivity: 0.8440 - recall: 0.7695 - precision: 0.6734\n",
            "Epoch 110: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.5591 - accuracy: 0.6941 - sensitivity_at_specificity: 0.8558 - specificity_at_sensitivity: 0.8440 - recall: 0.7695 - precision: 0.6734 - val_loss: 0.5673 - val_accuracy: 0.6734 - val_sensitivity_at_specificity: 0.8398 - val_specificity_at_sensitivity: 0.8323 - val_recall: 0.7589 - val_precision: 0.6355\n",
            "Epoch 111/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5609 - accuracy: 0.6750 - sensitivity_at_specificity: 0.8420 - specificity_at_sensitivity: 0.8187 - recall: 0.6905 - precision: 0.6588\n",
            "Epoch 111: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.5609 - accuracy: 0.6750 - sensitivity_at_specificity: 0.8420 - specificity_at_sensitivity: 0.8187 - recall: 0.6905 - precision: 0.6588 - val_loss: 0.5604 - val_accuracy: 0.6797 - val_sensitivity_at_specificity: 0.8435 - val_specificity_at_sensitivity: 0.8210 - val_recall: 0.7094 - val_precision: 0.6889\n",
            "Epoch 112/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5512 - accuracy: 0.6910 - sensitivity_at_specificity: 0.8449 - specificity_at_sensitivity: 0.8464 - recall: 0.7634 - precision: 0.6586\n",
            "Epoch 112: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.5512 - accuracy: 0.6910 - sensitivity_at_specificity: 0.8449 - specificity_at_sensitivity: 0.8464 - recall: 0.7634 - precision: 0.6586 - val_loss: 0.5764 - val_accuracy: 0.6656 - val_sensitivity_at_specificity: 0.8219 - val_specificity_at_sensitivity: 0.8234 - val_recall: 0.7839 - val_precision: 0.6429\n",
            "Epoch 113/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5563 - accuracy: 0.7039 - sensitivity_at_specificity: 0.8366 - specificity_at_sensitivity: 0.8490 - recall: 0.7477 - precision: 0.7013\n",
            "Epoch 113: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.5563 - accuracy: 0.7039 - sensitivity_at_specificity: 0.8366 - specificity_at_sensitivity: 0.8490 - recall: 0.7477 - precision: 0.7013 - val_loss: 0.5922 - val_accuracy: 0.6578 - val_sensitivity_at_specificity: 0.8331 - val_specificity_at_sensitivity: 0.8120 - val_recall: 0.8702 - val_precision: 0.6140\n",
            "Epoch 114/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5509 - accuracy: 0.6887 - sensitivity_at_specificity: 0.8547 - specificity_at_sensitivity: 0.8440 - recall: 0.7143 - precision: 0.6687\n",
            "Epoch 114: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.5509 - accuracy: 0.6887 - sensitivity_at_specificity: 0.8547 - specificity_at_sensitivity: 0.8440 - recall: 0.7143 - precision: 0.6687 - val_loss: 0.5593 - val_accuracy: 0.6875 - val_sensitivity_at_specificity: 0.8558 - val_specificity_at_sensitivity: 0.8409 - val_recall: 0.8031 - val_precision: 0.6549\n",
            "Epoch 115/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5753 - accuracy: 0.6757 - sensitivity_at_specificity: 0.8281 - specificity_at_sensitivity: 0.8183 - recall: 0.6943 - precision: 0.6613\n",
            "Epoch 115: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 157ms/step - loss: 0.5753 - accuracy: 0.6757 - sensitivity_at_specificity: 0.8281 - specificity_at_sensitivity: 0.8183 - recall: 0.6943 - precision: 0.6613 - val_loss: 0.5869 - val_accuracy: 0.6547 - val_sensitivity_at_specificity: 0.8078 - val_specificity_at_sensitivity: 0.8047 - val_recall: 0.6729 - val_precision: 0.6526\n",
            "Epoch 116/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5540 - accuracy: 0.6945 - sensitivity_at_specificity: 0.8493 - specificity_at_sensitivity: 0.8532 - recall: 0.7215 - precision: 0.6929\n",
            "Epoch 116: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.5540 - accuracy: 0.6945 - sensitivity_at_specificity: 0.8493 - specificity_at_sensitivity: 0.8532 - recall: 0.7215 - precision: 0.6929 - val_loss: 0.5646 - val_accuracy: 0.6727 - val_sensitivity_at_specificity: 0.8425 - val_specificity_at_sensitivity: 0.8221 - val_recall: 0.8098 - val_precision: 0.6519\n",
            "Epoch 117/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5595 - accuracy: 0.6812 - sensitivity_at_specificity: 0.8454 - specificity_at_sensitivity: 0.8515 - recall: 0.7473 - precision: 0.6641\n",
            "Epoch 117: val_accuracy improved from 0.69141 to 0.70625, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.5595 - accuracy: 0.6812 - sensitivity_at_specificity: 0.8454 - specificity_at_sensitivity: 0.8515 - recall: 0.7473 - precision: 0.6641 - val_loss: 0.5620 - val_accuracy: 0.7063 - val_sensitivity_at_specificity: 0.8720 - val_specificity_at_sensitivity: 0.8284 - val_recall: 0.7520 - val_precision: 0.6849\n",
            "Epoch 118/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5617 - accuracy: 0.6910 - sensitivity_at_specificity: 0.8485 - specificity_at_sensitivity: 0.8313 - recall: 0.7438 - precision: 0.6864\n",
            "Epoch 118: val_accuracy did not improve from 0.70625\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.5617 - accuracy: 0.6910 - sensitivity_at_specificity: 0.8485 - specificity_at_sensitivity: 0.8313 - recall: 0.7438 - precision: 0.6864 - val_loss: 0.6053 - val_accuracy: 0.6625 - val_sensitivity_at_specificity: 0.8262 - val_specificity_at_sensitivity: 0.7913 - val_recall: 0.8199 - val_precision: 0.6201\n",
            "Epoch 119/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5574 - accuracy: 0.6949 - sensitivity_at_specificity: 0.8468 - specificity_at_sensitivity: 0.8531 - recall: 0.7452 - precision: 0.6712\n",
            "Epoch 119: val_accuracy did not improve from 0.70625\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.5574 - accuracy: 0.6949 - sensitivity_at_specificity: 0.8468 - specificity_at_sensitivity: 0.8531 - recall: 0.7452 - precision: 0.6712 - val_loss: 0.5628 - val_accuracy: 0.6836 - val_sensitivity_at_specificity: 0.8556 - val_specificity_at_sensitivity: 0.8367 - val_recall: 0.8367 - val_precision: 0.6391\n",
            "Epoch 120/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5479 - accuracy: 0.6934 - sensitivity_at_specificity: 0.8630 - specificity_at_sensitivity: 0.8667 - recall: 0.7244 - precision: 0.6790\n",
            "Epoch 120: val_accuracy did not improve from 0.70625\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.5479 - accuracy: 0.6934 - sensitivity_at_specificity: 0.8630 - specificity_at_sensitivity: 0.8667 - recall: 0.7244 - precision: 0.6790 - val_loss: 0.5573 - val_accuracy: 0.6953 - val_sensitivity_at_specificity: 0.8607 - val_specificity_at_sensitivity: 0.8659 - val_recall: 0.8328 - val_precision: 0.6561\n",
            "Epoch 121/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5313 - accuracy: 0.7266 - sensitivity_at_specificity: 0.8591 - specificity_at_sensitivity: 0.8684 - recall: 0.7366 - precision: 0.7299\n",
            "Epoch 121: val_accuracy did not improve from 0.70625\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.5313 - accuracy: 0.7266 - sensitivity_at_specificity: 0.8591 - specificity_at_sensitivity: 0.8684 - recall: 0.7366 - precision: 0.7299 - val_loss: 0.5843 - val_accuracy: 0.6883 - val_sensitivity_at_specificity: 0.8656 - val_specificity_at_sensitivity: 0.8188 - val_recall: 0.8822 - val_precision: 0.6453\n",
            "Epoch 122/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5618 - accuracy: 0.6910 - sensitivity_at_specificity: 0.8399 - specificity_at_sensitivity: 0.8484 - recall: 0.7151 - precision: 0.6804\n",
            "Epoch 122: val_accuracy did not improve from 0.70625\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.5618 - accuracy: 0.6910 - sensitivity_at_specificity: 0.8399 - specificity_at_sensitivity: 0.8484 - recall: 0.7151 - precision: 0.6804 - val_loss: 0.5724 - val_accuracy: 0.6594 - val_sensitivity_at_specificity: 0.8247 - val_specificity_at_sensitivity: 0.8409 - val_recall: 0.7590 - val_precision: 0.6323\n",
            "Epoch 123/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5470 - accuracy: 0.6964 - sensitivity_at_specificity: 0.8539 - specificity_at_sensitivity: 0.8453 - recall: 0.7494 - precision: 0.6841\n",
            "Epoch 123: val_accuracy did not improve from 0.70625\n",
            "10/10 [==============================] - 2s 154ms/step - loss: 0.5470 - accuracy: 0.6964 - sensitivity_at_specificity: 0.8539 - specificity_at_sensitivity: 0.8453 - recall: 0.7494 - precision: 0.6841 - val_loss: 0.5661 - val_accuracy: 0.6797 - val_sensitivity_at_specificity: 0.8356 - val_specificity_at_sensitivity: 0.8395 - val_recall: 0.8265 - val_precision: 0.6472\n",
            "Epoch 124/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5500 - accuracy: 0.7039 - sensitivity_at_specificity: 0.8426 - specificity_at_sensitivity: 0.8673 - recall: 0.7821 - precision: 0.6739\n",
            "Epoch 124: val_accuracy did not improve from 0.70625\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.5500 - accuracy: 0.7039 - sensitivity_at_specificity: 0.8426 - specificity_at_sensitivity: 0.8673 - recall: 0.7821 - precision: 0.6739 - val_loss: 0.5904 - val_accuracy: 0.6773 - val_sensitivity_at_specificity: 0.8401 - val_specificity_at_sensitivity: 0.8139 - val_recall: 0.8158 - val_precision: 0.6281\n",
            "Epoch 125/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5356 - accuracy: 0.7000 - sensitivity_at_specificity: 0.8668 - specificity_at_sensitivity: 0.8706 - recall: 0.7002 - precision: 0.6913\n",
            "Epoch 125: val_accuracy did not improve from 0.70625\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.5356 - accuracy: 0.7000 - sensitivity_at_specificity: 0.8668 - specificity_at_sensitivity: 0.8706 - recall: 0.7002 - precision: 0.6913 - val_loss: 0.5857 - val_accuracy: 0.6719 - val_sensitivity_at_specificity: 0.8298 - val_specificity_at_sensitivity: 0.8149 - val_recall: 0.8434 - val_precision: 0.6393\n",
            "Epoch 126/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5543 - accuracy: 0.6906 - sensitivity_at_specificity: 0.8299 - specificity_at_sensitivity: 0.8536 - recall: 0.6986 - precision: 0.6714\n",
            "Epoch 126: val_accuracy did not improve from 0.70625\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.5543 - accuracy: 0.6906 - sensitivity_at_specificity: 0.8299 - specificity_at_sensitivity: 0.8536 - recall: 0.6986 - precision: 0.6714 - val_loss: 0.5693 - val_accuracy: 0.6789 - val_sensitivity_at_specificity: 0.8240 - val_specificity_at_sensitivity: 0.8293 - val_recall: 0.7936 - val_precision: 0.6554\n",
            "Epoch 127/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5505 - accuracy: 0.6867 - sensitivity_at_specificity: 0.8350 - specificity_at_sensitivity: 0.8433 - recall: 0.7521 - precision: 0.6717\n",
            "Epoch 127: val_accuracy did not improve from 0.70625\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.5505 - accuracy: 0.6867 - sensitivity_at_specificity: 0.8350 - specificity_at_sensitivity: 0.8433 - recall: 0.7521 - precision: 0.6717 - val_loss: 0.5831 - val_accuracy: 0.6734 - val_sensitivity_at_specificity: 0.8090 - val_specificity_at_sensitivity: 0.8035 - val_recall: 0.7453 - val_precision: 0.6540\n",
            "Epoch 128/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5394 - accuracy: 0.7027 - sensitivity_at_specificity: 0.8447 - specificity_at_sensitivity: 0.8727 - recall: 0.7213 - precision: 0.6802\n",
            "Epoch 128: val_accuracy did not improve from 0.70625\n",
            "10/10 [==============================] - 2s 157ms/step - loss: 0.5394 - accuracy: 0.7027 - sensitivity_at_specificity: 0.8447 - specificity_at_sensitivity: 0.8727 - recall: 0.7213 - precision: 0.6802 - val_loss: 0.5620 - val_accuracy: 0.6883 - val_sensitivity_at_specificity: 0.8498 - val_specificity_at_sensitivity: 0.8346 - val_recall: 0.6729 - val_precision: 0.6935\n",
            "Epoch 129/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5376 - accuracy: 0.7105 - sensitivity_at_specificity: 0.8694 - specificity_at_sensitivity: 0.8573 - recall: 0.7128 - precision: 0.7067\n",
            "Epoch 129: val_accuracy did not improve from 0.70625\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.5376 - accuracy: 0.7105 - sensitivity_at_specificity: 0.8694 - specificity_at_sensitivity: 0.8573 - recall: 0.7128 - precision: 0.7067 - val_loss: 0.5889 - val_accuracy: 0.6727 - val_sensitivity_at_specificity: 0.8307 - val_specificity_at_sensitivity: 0.8180 - val_recall: 0.7588 - val_precision: 0.6393\n",
            "Epoch 130/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5376 - accuracy: 0.7012 - sensitivity_at_specificity: 0.8578 - specificity_at_sensitivity: 0.8691 - recall: 0.7452 - precision: 0.6950\n",
            "Epoch 130: val_accuracy did not improve from 0.70625\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.5376 - accuracy: 0.7012 - sensitivity_at_specificity: 0.8578 - specificity_at_sensitivity: 0.8691 - recall: 0.7452 - precision: 0.6950 - val_loss: 0.5800 - val_accuracy: 0.6656 - val_sensitivity_at_specificity: 0.8375 - val_specificity_at_sensitivity: 0.8375 - val_recall: 0.8628 - val_precision: 0.6160\n",
            "Epoch 131/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5456 - accuracy: 0.7055 - sensitivity_at_specificity: 0.8582 - specificity_at_sensitivity: 0.8669 - recall: 0.7681 - precision: 0.6876\n",
            "Epoch 131: val_accuracy did not improve from 0.70625\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.5456 - accuracy: 0.7055 - sensitivity_at_specificity: 0.8582 - specificity_at_sensitivity: 0.8669 - recall: 0.7681 - precision: 0.6876 - val_loss: 0.5901 - val_accuracy: 0.6648 - val_sensitivity_at_specificity: 0.8040 - val_specificity_at_sensitivity: 0.7975 - val_recall: 0.7068 - val_precision: 0.6571\n",
            "Epoch 132/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5409 - accuracy: 0.7141 - sensitivity_at_specificity: 0.8741 - specificity_at_sensitivity: 0.8712 - recall: 0.6962 - precision: 0.7243\n",
            "Epoch 132: val_accuracy did not improve from 0.70625\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.5409 - accuracy: 0.7141 - sensitivity_at_specificity: 0.8741 - specificity_at_sensitivity: 0.8712 - recall: 0.6962 - precision: 0.7243 - val_loss: 0.5729 - val_accuracy: 0.6852 - val_sensitivity_at_specificity: 0.8511 - val_specificity_at_sensitivity: 0.8311 - val_recall: 0.7005 - val_precision: 0.6605\n",
            "Epoch 133/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5375 - accuracy: 0.7102 - sensitivity_at_specificity: 0.8766 - specificity_at_sensitivity: 0.8574 - recall: 0.7134 - precision: 0.7011\n",
            "Epoch 133: val_accuracy did not improve from 0.70625\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.5375 - accuracy: 0.7102 - sensitivity_at_specificity: 0.8766 - specificity_at_sensitivity: 0.8574 - recall: 0.7134 - precision: 0.7011 - val_loss: 0.5812 - val_accuracy: 0.6594 - val_sensitivity_at_specificity: 0.8278 - val_specificity_at_sensitivity: 0.7994 - val_recall: 0.7416 - val_precision: 0.6292\n",
            "Epoch 134/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5413 - accuracy: 0.6852 - sensitivity_at_specificity: 0.8520 - specificity_at_sensitivity: 0.8595 - recall: 0.7424 - precision: 0.6572\n",
            "Epoch 134: val_accuracy did not improve from 0.70625\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.5413 - accuracy: 0.6852 - sensitivity_at_specificity: 0.8520 - specificity_at_sensitivity: 0.8595 - recall: 0.7424 - precision: 0.6572 - val_loss: 0.5738 - val_accuracy: 0.6781 - val_sensitivity_at_specificity: 0.8317 - val_specificity_at_sensitivity: 0.8154 - val_recall: 0.6667 - val_precision: 0.6752\n",
            "Epoch 135/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5359 - accuracy: 0.7023 - sensitivity_at_specificity: 0.8588 - specificity_at_sensitivity: 0.8833 - recall: 0.7035 - precision: 0.7002\n",
            "Epoch 135: val_accuracy did not improve from 0.70625\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.5359 - accuracy: 0.7023 - sensitivity_at_specificity: 0.8588 - specificity_at_sensitivity: 0.8833 - recall: 0.7035 - precision: 0.7002 - val_loss: 0.5586 - val_accuracy: 0.7047 - val_sensitivity_at_specificity: 0.8633 - val_specificity_at_sensitivity: 0.8465 - val_recall: 0.7363 - val_precision: 0.6815\n",
            "Epoch 136/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5358 - accuracy: 0.7047 - sensitivity_at_specificity: 0.8640 - specificity_at_sensitivity: 0.8650 - recall: 0.7079 - precision: 0.7101\n",
            "Epoch 136: val_accuracy did not improve from 0.70625\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.5358 - accuracy: 0.7047 - sensitivity_at_specificity: 0.8640 - specificity_at_sensitivity: 0.8650 - recall: 0.7079 - precision: 0.7101 - val_loss: 0.6265 - val_accuracy: 0.6383 - val_sensitivity_at_specificity: 0.8033 - val_specificity_at_sensitivity: 0.7910 - val_recall: 0.8520 - val_precision: 0.5848\n",
            "Epoch 137/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5414 - accuracy: 0.6981 - sensitivity_at_specificity: 0.8417 - specificity_at_sensitivity: 0.8715 - recall: 0.7295 - precision: 0.6831\n",
            "Epoch 137: val_accuracy did not improve from 0.70625\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.5414 - accuracy: 0.6981 - sensitivity_at_specificity: 0.8417 - specificity_at_sensitivity: 0.8715 - recall: 0.7295 - precision: 0.6831 - val_loss: 0.5994 - val_accuracy: 0.6539 - val_sensitivity_at_specificity: 0.8050 - val_specificity_at_sensitivity: 0.7997 - val_recall: 0.8223 - val_precision: 0.6131\n",
            "Epoch 138/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5282 - accuracy: 0.7121 - sensitivity_at_specificity: 0.8697 - specificity_at_sensitivity: 0.8875 - recall: 0.7152 - precision: 0.6966\n",
            "Epoch 138: val_accuracy did not improve from 0.70625\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.5282 - accuracy: 0.7121 - sensitivity_at_specificity: 0.8697 - specificity_at_sensitivity: 0.8875 - recall: 0.7152 - precision: 0.6966 - val_loss: 0.5827 - val_accuracy: 0.6883 - val_sensitivity_at_specificity: 0.8560 - val_specificity_at_sensitivity: 0.8117 - val_recall: 0.8196 - val_precision: 0.6451\n",
            "Epoch 139/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5439 - accuracy: 0.7027 - sensitivity_at_specificity: 0.8449 - specificity_at_sensitivity: 0.8732 - recall: 0.6986 - precision: 0.6948\n",
            "Epoch 139: val_accuracy did not improve from 0.70625\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.5439 - accuracy: 0.7027 - sensitivity_at_specificity: 0.8449 - specificity_at_sensitivity: 0.8732 - recall: 0.6986 - precision: 0.6948 - val_loss: 0.5852 - val_accuracy: 0.6719 - val_sensitivity_at_specificity: 0.8364 - val_specificity_at_sensitivity: 0.8275 - val_recall: 0.8302 - val_precision: 0.6344\n",
            "Epoch 140/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5465 - accuracy: 0.7000 - sensitivity_at_specificity: 0.8574 - specificity_at_sensitivity: 0.8583 - recall: 0.7372 - precision: 0.6891\n",
            "Epoch 140: val_accuracy did not improve from 0.70625\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.5465 - accuracy: 0.7000 - sensitivity_at_specificity: 0.8574 - specificity_at_sensitivity: 0.8583 - recall: 0.7372 - precision: 0.6891 - val_loss: 0.5835 - val_accuracy: 0.6805 - val_sensitivity_at_specificity: 0.8115 - val_specificity_at_sensitivity: 0.8072 - val_recall: 0.7710 - val_precision: 0.6539\n",
            "Epoch 141/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5178 - accuracy: 0.7145 - sensitivity_at_specificity: 0.8723 - specificity_at_sensitivity: 0.8877 - recall: 0.7543 - precision: 0.7131\n",
            "Epoch 141: val_accuracy did not improve from 0.70625\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.5178 - accuracy: 0.7145 - sensitivity_at_specificity: 0.8723 - specificity_at_sensitivity: 0.8877 - recall: 0.7543 - precision: 0.7131 - val_loss: 0.5899 - val_accuracy: 0.6945 - val_sensitivity_at_specificity: 0.8547 - val_specificity_at_sensitivity: 0.8246 - val_recall: 0.8408 - val_precision: 0.6538\n",
            "Epoch 142/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5382 - accuracy: 0.6923 - sensitivity_at_specificity: 0.8610 - specificity_at_sensitivity: 0.8599 - recall: 0.7378 - precision: 0.6778\n",
            "Epoch 142: val_accuracy did not improve from 0.70625\n",
            "10/10 [==============================] - 2s 156ms/step - loss: 0.5382 - accuracy: 0.6923 - sensitivity_at_specificity: 0.8610 - specificity_at_sensitivity: 0.8599 - recall: 0.7378 - precision: 0.6778 - val_loss: 0.5748 - val_accuracy: 0.6695 - val_sensitivity_at_specificity: 0.8284 - val_specificity_at_sensitivity: 0.7887 - val_recall: 0.7348 - val_precision: 0.6506\n",
            "Epoch 143/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5384 - accuracy: 0.7023 - sensitivity_at_specificity: 0.8781 - specificity_at_sensitivity: 0.8719 - recall: 0.7329 - precision: 0.6931\n",
            "Epoch 143: val_accuracy did not improve from 0.70625\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.5384 - accuracy: 0.7023 - sensitivity_at_specificity: 0.8781 - specificity_at_sensitivity: 0.8719 - recall: 0.7329 - precision: 0.6931 - val_loss: 0.5731 - val_accuracy: 0.6828 - val_sensitivity_at_specificity: 0.8369 - val_specificity_at_sensitivity: 0.8187 - val_recall: 0.7331 - val_precision: 0.6459\n",
            "Epoch 144/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5270 - accuracy: 0.7188 - sensitivity_at_specificity: 0.8805 - specificity_at_sensitivity: 0.8796 - recall: 0.7176 - precision: 0.7221\n",
            "Epoch 144: val_accuracy did not improve from 0.70625\n",
            "10/10 [==============================] - 2s 190ms/step - loss: 0.5270 - accuracy: 0.7188 - sensitivity_at_specificity: 0.8805 - specificity_at_sensitivity: 0.8796 - recall: 0.7176 - precision: 0.7221 - val_loss: 0.5938 - val_accuracy: 0.6812 - val_sensitivity_at_specificity: 0.8333 - val_specificity_at_sensitivity: 0.8186 - val_recall: 0.7324 - val_precision: 0.6547\n",
            "Epoch 145/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5375 - accuracy: 0.7055 - sensitivity_at_specificity: 0.8684 - specificity_at_sensitivity: 0.8699 - recall: 0.7074 - precision: 0.6985\n",
            "Epoch 145: val_accuracy did not improve from 0.70625\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.5375 - accuracy: 0.7055 - sensitivity_at_specificity: 0.8684 - specificity_at_sensitivity: 0.8699 - recall: 0.7074 - precision: 0.6985 - val_loss: 0.5561 - val_accuracy: 0.6930 - val_sensitivity_at_specificity: 0.8657 - val_specificity_at_sensitivity: 0.8475 - val_recall: 0.7164 - val_precision: 0.7028\n",
            "Epoch 146/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5121 - accuracy: 0.7234 - sensitivity_at_specificity: 0.8836 - specificity_at_sensitivity: 0.8928 - recall: 0.7097 - precision: 0.7212\n",
            "Epoch 146: val_accuracy did not improve from 0.70625\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.5121 - accuracy: 0.7234 - sensitivity_at_specificity: 0.8836 - specificity_at_sensitivity: 0.8928 - recall: 0.7097 - precision: 0.7212 - val_loss: 0.5749 - val_accuracy: 0.7063 - val_sensitivity_at_specificity: 0.8638 - val_specificity_at_sensitivity: 0.8369 - val_recall: 0.7644 - val_precision: 0.6756\n",
            "Epoch 147/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5199 - accuracy: 0.7250 - sensitivity_at_specificity: 0.8934 - specificity_at_sensitivity: 0.8925 - recall: 0.7808 - precision: 0.7186\n",
            "Epoch 147: val_accuracy did not improve from 0.70625\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.5199 - accuracy: 0.7250 - sensitivity_at_specificity: 0.8934 - specificity_at_sensitivity: 0.8925 - recall: 0.7808 - precision: 0.7186 - val_loss: 0.5548 - val_accuracy: 0.6992 - val_sensitivity_at_specificity: 0.8686 - val_specificity_at_sensitivity: 0.8547 - val_recall: 0.7342 - val_precision: 0.6904\n",
            "Epoch 148/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5170 - accuracy: 0.7262 - sensitivity_at_specificity: 0.8813 - specificity_at_sensitivity: 0.8819 - recall: 0.7073 - precision: 0.7298\n",
            "Epoch 148: val_accuracy did not improve from 0.70625\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.5170 - accuracy: 0.7262 - sensitivity_at_specificity: 0.8813 - specificity_at_sensitivity: 0.8819 - recall: 0.7073 - precision: 0.7298 - val_loss: 0.5628 - val_accuracy: 0.6750 - val_sensitivity_at_specificity: 0.8253 - val_specificity_at_sensitivity: 0.8369 - val_recall: 0.7436 - val_precision: 0.6444\n",
            "Epoch 149/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4934 - accuracy: 0.7402 - sensitivity_at_specificity: 0.8905 - specificity_at_sensitivity: 0.9212 - recall: 0.7660 - precision: 0.7279\n",
            "Epoch 149: val_accuracy did not improve from 0.70625\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.4934 - accuracy: 0.7402 - sensitivity_at_specificity: 0.8905 - specificity_at_sensitivity: 0.9212 - recall: 0.7660 - precision: 0.7279 - val_loss: 0.5918 - val_accuracy: 0.6727 - val_sensitivity_at_specificity: 0.7962 - val_specificity_at_sensitivity: 0.8114 - val_recall: 0.6919 - val_precision: 0.6616\n",
            "Epoch 150/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5114 - accuracy: 0.7270 - sensitivity_at_specificity: 0.8800 - specificity_at_sensitivity: 0.8951 - recall: 0.7260 - precision: 0.7311\n",
            "Epoch 150: val_accuracy did not improve from 0.70625\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.5114 - accuracy: 0.7270 - sensitivity_at_specificity: 0.8800 - specificity_at_sensitivity: 0.8951 - recall: 0.7260 - precision: 0.7311 - val_loss: 0.5952 - val_accuracy: 0.6914 - val_sensitivity_at_specificity: 0.8420 - val_specificity_at_sensitivity: 0.8377 - val_recall: 0.7836 - val_precision: 0.6578\n",
            "Epoch 151/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5193 - accuracy: 0.7195 - sensitivity_at_specificity: 0.8600 - specificity_at_sensitivity: 0.8984 - recall: 0.7018 - precision: 0.7246\n",
            "Epoch 151: val_accuracy did not improve from 0.70625\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.5193 - accuracy: 0.7195 - sensitivity_at_specificity: 0.8600 - specificity_at_sensitivity: 0.8984 - recall: 0.7018 - precision: 0.7246 - val_loss: 0.5831 - val_accuracy: 0.6836 - val_sensitivity_at_specificity: 0.8349 - val_specificity_at_sensitivity: 0.8025 - val_recall: 0.6636 - val_precision: 0.6927\n",
            "Epoch 152/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4929 - accuracy: 0.7359 - sensitivity_at_specificity: 0.8979 - specificity_at_sensitivity: 0.9246 - recall: 0.7562 - precision: 0.7297\n",
            "Epoch 152: val_accuracy did not improve from 0.70625\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.4929 - accuracy: 0.7359 - sensitivity_at_specificity: 0.8979 - specificity_at_sensitivity: 0.9246 - recall: 0.7562 - precision: 0.7297 - val_loss: 0.6220 - val_accuracy: 0.6625 - val_sensitivity_at_specificity: 0.8191 - val_specificity_at_sensitivity: 0.7910 - val_recall: 0.7736 - val_precision: 0.6427\n",
            "Epoch 153/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4879 - accuracy: 0.7434 - sensitivity_at_specificity: 0.9109 - specificity_at_sensitivity: 0.9033 - recall: 0.7539 - precision: 0.7348\n",
            "Epoch 153: val_accuracy did not improve from 0.70625\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.4879 - accuracy: 0.7434 - sensitivity_at_specificity: 0.9109 - specificity_at_sensitivity: 0.9033 - recall: 0.7539 - precision: 0.7348 - val_loss: 0.6116 - val_accuracy: 0.6719 - val_sensitivity_at_specificity: 0.8046 - val_specificity_at_sensitivity: 0.8127 - val_recall: 0.7092 - val_precision: 0.6662\n",
            "Epoch 154/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4995 - accuracy: 0.7336 - sensitivity_at_specificity: 0.8809 - specificity_at_sensitivity: 0.9167 - recall: 0.7265 - precision: 0.7357\n",
            "Epoch 154: val_accuracy improved from 0.70625 to 0.71328, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.4995 - accuracy: 0.7336 - sensitivity_at_specificity: 0.8809 - specificity_at_sensitivity: 0.9167 - recall: 0.7265 - precision: 0.7357 - val_loss: 0.5687 - val_accuracy: 0.7133 - val_sensitivity_at_specificity: 0.8685 - val_specificity_at_sensitivity: 0.8521 - val_recall: 0.8130 - val_precision: 0.6732\n",
            "Epoch 155/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4865 - accuracy: 0.7457 - sensitivity_at_specificity: 0.9105 - specificity_at_sensitivity: 0.9224 - recall: 0.7292 - precision: 0.7556\n",
            "Epoch 155: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.4865 - accuracy: 0.7457 - sensitivity_at_specificity: 0.9105 - specificity_at_sensitivity: 0.9224 - recall: 0.7292 - precision: 0.7556 - val_loss: 0.5796 - val_accuracy: 0.7063 - val_sensitivity_at_specificity: 0.8685 - val_specificity_at_sensitivity: 0.8466 - val_recall: 0.7492 - val_precision: 0.6980\n",
            "Epoch 156/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5024 - accuracy: 0.7355 - sensitivity_at_specificity: 0.8939 - specificity_at_sensitivity: 0.9126 - recall: 0.7074 - precision: 0.7376\n",
            "Epoch 156: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.5024 - accuracy: 0.7355 - sensitivity_at_specificity: 0.8939 - specificity_at_sensitivity: 0.9126 - recall: 0.7074 - precision: 0.7376 - val_loss: 0.5918 - val_accuracy: 0.6969 - val_sensitivity_at_specificity: 0.8349 - val_specificity_at_sensitivity: 0.8075 - val_recall: 0.7563 - val_precision: 0.6737\n",
            "Epoch 157/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4849 - accuracy: 0.7504 - sensitivity_at_specificity: 0.9195 - specificity_at_sensitivity: 0.9118 - recall: 0.7748 - precision: 0.7385\n",
            "Epoch 157: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.4849 - accuracy: 0.7504 - sensitivity_at_specificity: 0.9195 - specificity_at_sensitivity: 0.9118 - recall: 0.7748 - precision: 0.7385 - val_loss: 0.6205 - val_accuracy: 0.6633 - val_sensitivity_at_specificity: 0.8357 - val_specificity_at_sensitivity: 0.8099 - val_recall: 0.8373 - val_precision: 0.6177\n",
            "Epoch 158/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5073 - accuracy: 0.7395 - sensitivity_at_specificity: 0.8935 - specificity_at_sensitivity: 0.8940 - recall: 0.7481 - precision: 0.7372\n",
            "Epoch 158: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.5073 - accuracy: 0.7395 - sensitivity_at_specificity: 0.8935 - specificity_at_sensitivity: 0.8940 - recall: 0.7481 - precision: 0.7372 - val_loss: 0.6301 - val_accuracy: 0.6781 - val_sensitivity_at_specificity: 0.8430 - val_specificity_at_sensitivity: 0.7981 - val_recall: 0.8674 - val_precision: 0.6365\n",
            "Epoch 159/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4844 - accuracy: 0.7434 - sensitivity_at_specificity: 0.9065 - specificity_at_sensitivity: 0.9182 - recall: 0.7632 - precision: 0.7469\n",
            "Epoch 159: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.4844 - accuracy: 0.7434 - sensitivity_at_specificity: 0.9065 - specificity_at_sensitivity: 0.9182 - recall: 0.7632 - precision: 0.7469 - val_loss: 0.6119 - val_accuracy: 0.6805 - val_sensitivity_at_specificity: 0.8426 - val_specificity_at_sensitivity: 0.8448 - val_recall: 0.7820 - val_precision: 0.6335\n",
            "Epoch 160/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4874 - accuracy: 0.7504 - sensitivity_at_specificity: 0.9162 - specificity_at_sensitivity: 0.9103 - recall: 0.7492 - precision: 0.7568\n",
            "Epoch 160: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.4874 - accuracy: 0.7504 - sensitivity_at_specificity: 0.9162 - specificity_at_sensitivity: 0.9103 - recall: 0.7492 - precision: 0.7568 - val_loss: 0.5789 - val_accuracy: 0.6844 - val_sensitivity_at_specificity: 0.8341 - val_specificity_at_sensitivity: 0.8457 - val_recall: 0.7721 - val_precision: 0.6596\n",
            "Epoch 161/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5047 - accuracy: 0.7449 - sensitivity_at_specificity: 0.8994 - specificity_at_sensitivity: 0.8983 - recall: 0.7324 - precision: 0.7425\n",
            "Epoch 161: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.5047 - accuracy: 0.7449 - sensitivity_at_specificity: 0.8994 - specificity_at_sensitivity: 0.8983 - recall: 0.7324 - precision: 0.7425 - val_loss: 0.6112 - val_accuracy: 0.6773 - val_sensitivity_at_specificity: 0.8452 - val_specificity_at_sensitivity: 0.8227 - val_recall: 0.7548 - val_precision: 0.6420\n",
            "Epoch 162/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4995 - accuracy: 0.7383 - sensitivity_at_specificity: 0.8994 - specificity_at_sensitivity: 0.9038 - recall: 0.7113 - precision: 0.7558\n",
            "Epoch 162: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.4995 - accuracy: 0.7383 - sensitivity_at_specificity: 0.8994 - specificity_at_sensitivity: 0.9038 - recall: 0.7113 - precision: 0.7558 - val_loss: 0.6578 - val_accuracy: 0.6641 - val_sensitivity_at_specificity: 0.8336 - val_specificity_at_sensitivity: 0.8226 - val_recall: 0.8725 - val_precision: 0.6172\n",
            "Epoch 163/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4959 - accuracy: 0.7492 - sensitivity_at_specificity: 0.9139 - specificity_at_sensitivity: 0.9150 - recall: 0.7831 - precision: 0.7326\n",
            "Epoch 163: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.4959 - accuracy: 0.7492 - sensitivity_at_specificity: 0.9139 - specificity_at_sensitivity: 0.9150 - recall: 0.7831 - precision: 0.7326 - val_loss: 0.6791 - val_accuracy: 0.6547 - val_sensitivity_at_specificity: 0.8167 - val_specificity_at_sensitivity: 0.7964 - val_recall: 0.8408 - val_precision: 0.6039\n",
            "Epoch 164/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4845 - accuracy: 0.7414 - sensitivity_at_specificity: 0.9017 - specificity_at_sensitivity: 0.9325 - recall: 0.7262 - precision: 0.7462\n",
            "Epoch 164: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.4845 - accuracy: 0.7414 - sensitivity_at_specificity: 0.9017 - specificity_at_sensitivity: 0.9325 - recall: 0.7262 - precision: 0.7462 - val_loss: 0.6451 - val_accuracy: 0.6594 - val_sensitivity_at_specificity: 0.8022 - val_specificity_at_sensitivity: 0.7762 - val_recall: 0.7247 - val_precision: 0.6361\n",
            "Epoch 165/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4795 - accuracy: 0.7555 - sensitivity_at_specificity: 0.9127 - specificity_at_sensitivity: 0.9220 - recall: 0.7517 - precision: 0.7680\n",
            "Epoch 165: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.4795 - accuracy: 0.7555 - sensitivity_at_specificity: 0.9127 - specificity_at_sensitivity: 0.9220 - recall: 0.7517 - precision: 0.7680 - val_loss: 0.5963 - val_accuracy: 0.7000 - val_sensitivity_at_specificity: 0.8298 - val_specificity_at_sensitivity: 0.8371 - val_recall: 0.7358 - val_precision: 0.6726\n",
            "Epoch 166/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4798 - accuracy: 0.7438 - sensitivity_at_specificity: 0.9123 - specificity_at_sensitivity: 0.9317 - recall: 0.7492 - precision: 0.7424\n",
            "Epoch 166: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 157ms/step - loss: 0.4798 - accuracy: 0.7438 - sensitivity_at_specificity: 0.9123 - specificity_at_sensitivity: 0.9317 - recall: 0.7492 - precision: 0.7424 - val_loss: 0.6357 - val_accuracy: 0.6820 - val_sensitivity_at_specificity: 0.8501 - val_specificity_at_sensitivity: 0.8024 - val_recall: 0.8089 - val_precision: 0.6279\n",
            "Epoch 167/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4822 - accuracy: 0.7559 - sensitivity_at_specificity: 0.9101 - specificity_at_sensitivity: 0.9300 - recall: 0.7303 - precision: 0.7590\n",
            "Epoch 167: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.4822 - accuracy: 0.7559 - sensitivity_at_specificity: 0.9101 - specificity_at_sensitivity: 0.9300 - recall: 0.7303 - precision: 0.7590 - val_loss: 0.6239 - val_accuracy: 0.7000 - val_sensitivity_at_specificity: 0.8618 - val_specificity_at_sensitivity: 0.8160 - val_recall: 0.7873 - val_precision: 0.6724\n",
            "Epoch 168/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4939 - accuracy: 0.7375 - sensitivity_at_specificity: 0.9041 - specificity_at_sensitivity: 0.9100 - recall: 0.7448 - precision: 0.7379\n",
            "Epoch 168: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.4939 - accuracy: 0.7375 - sensitivity_at_specificity: 0.9041 - specificity_at_sensitivity: 0.9100 - recall: 0.7448 - precision: 0.7379 - val_loss: 0.6465 - val_accuracy: 0.6656 - val_sensitivity_at_specificity: 0.8134 - val_specificity_at_sensitivity: 0.7818 - val_recall: 0.7621 - val_precision: 0.6405\n",
            "Epoch 169/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4674 - accuracy: 0.7525 - sensitivity_at_specificity: 0.9234 - specificity_at_sensitivity: 0.9412 - recall: 0.7419 - precision: 0.7570\n",
            "Epoch 169: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 157ms/step - loss: 0.4674 - accuracy: 0.7525 - sensitivity_at_specificity: 0.9234 - specificity_at_sensitivity: 0.9412 - recall: 0.7419 - precision: 0.7570 - val_loss: 0.6092 - val_accuracy: 0.6758 - val_sensitivity_at_specificity: 0.8437 - val_specificity_at_sensitivity: 0.8328 - val_recall: 0.7941 - val_precision: 0.6453\n",
            "Epoch 170/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4770 - accuracy: 0.7512 - sensitivity_at_specificity: 0.9151 - specificity_at_sensitivity: 0.9233 - recall: 0.7629 - precision: 0.7496\n",
            "Epoch 170: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.4770 - accuracy: 0.7512 - sensitivity_at_specificity: 0.9151 - specificity_at_sensitivity: 0.9233 - recall: 0.7629 - precision: 0.7496 - val_loss: 0.6291 - val_accuracy: 0.6898 - val_sensitivity_at_specificity: 0.8320 - val_specificity_at_sensitivity: 0.7876 - val_recall: 0.6872 - val_precision: 0.6969\n",
            "Epoch 171/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4865 - accuracy: 0.7539 - sensitivity_at_specificity: 0.8988 - specificity_at_sensitivity: 0.9364 - recall: 0.7466 - precision: 0.7502\n",
            "Epoch 171: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.4865 - accuracy: 0.7539 - sensitivity_at_specificity: 0.8988 - specificity_at_sensitivity: 0.9364 - recall: 0.7466 - precision: 0.7502 - val_loss: 0.6045 - val_accuracy: 0.6922 - val_sensitivity_at_specificity: 0.8451 - val_specificity_at_sensitivity: 0.8276 - val_recall: 0.6952 - val_precision: 0.6688\n",
            "Epoch 172/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4774 - accuracy: 0.7676 - sensitivity_at_specificity: 0.9208 - specificity_at_sensitivity: 0.9221 - recall: 0.7335 - precision: 0.7657\n",
            "Epoch 172: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.4774 - accuracy: 0.7676 - sensitivity_at_specificity: 0.9208 - specificity_at_sensitivity: 0.9221 - recall: 0.7335 - precision: 0.7657 - val_loss: 0.6406 - val_accuracy: 0.6750 - val_sensitivity_at_specificity: 0.8353 - val_specificity_at_sensitivity: 0.7961 - val_recall: 0.7689 - val_precision: 0.6593\n",
            "Epoch 173/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4624 - accuracy: 0.7531 - sensitivity_at_specificity: 0.9197 - specificity_at_sensitivity: 0.9314 - recall: 0.7269 - precision: 0.7755\n",
            "Epoch 173: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.4624 - accuracy: 0.7531 - sensitivity_at_specificity: 0.9197 - specificity_at_sensitivity: 0.9314 - recall: 0.7269 - precision: 0.7755 - val_loss: 0.7301 - val_accuracy: 0.6430 - val_sensitivity_at_specificity: 0.8097 - val_specificity_at_sensitivity: 0.7950 - val_recall: 0.8424 - val_precision: 0.6027\n",
            "Epoch 174/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4712 - accuracy: 0.7605 - sensitivity_at_specificity: 0.9313 - specificity_at_sensitivity: 0.9297 - recall: 0.7701 - precision: 0.7517\n",
            "Epoch 174: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.4712 - accuracy: 0.7605 - sensitivity_at_specificity: 0.9313 - specificity_at_sensitivity: 0.9297 - recall: 0.7701 - precision: 0.7517 - val_loss: 0.6269 - val_accuracy: 0.6617 - val_sensitivity_at_specificity: 0.8156 - val_specificity_at_sensitivity: 0.8031 - val_recall: 0.7344 - val_precision: 0.6412\n",
            "Epoch 175/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4556 - accuracy: 0.7598 - sensitivity_at_specificity: 0.9307 - specificity_at_sensitivity: 0.9451 - recall: 0.7414 - precision: 0.7709\n",
            "Epoch 175: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.4556 - accuracy: 0.7598 - sensitivity_at_specificity: 0.9307 - specificity_at_sensitivity: 0.9451 - recall: 0.7414 - precision: 0.7709 - val_loss: 0.6451 - val_accuracy: 0.6469 - val_sensitivity_at_specificity: 0.8062 - val_specificity_at_sensitivity: 0.7669 - val_recall: 0.6248 - val_precision: 0.6574\n",
            "Epoch 176/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4786 - accuracy: 0.7473 - sensitivity_at_specificity: 0.9134 - specificity_at_sensitivity: 0.9225 - recall: 0.7433 - precision: 0.7462\n",
            "Epoch 176: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.4786 - accuracy: 0.7473 - sensitivity_at_specificity: 0.9134 - specificity_at_sensitivity: 0.9225 - recall: 0.7433 - precision: 0.7462 - val_loss: 0.6335 - val_accuracy: 0.6641 - val_sensitivity_at_specificity: 0.8132 - val_specificity_at_sensitivity: 0.8072 - val_recall: 0.8069 - val_precision: 0.6261\n",
            "Epoch 177/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4633 - accuracy: 0.7699 - sensitivity_at_specificity: 0.9318 - specificity_at_sensitivity: 0.9338 - recall: 0.7586 - precision: 0.7750\n",
            "Epoch 177: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.4633 - accuracy: 0.7699 - sensitivity_at_specificity: 0.9318 - specificity_at_sensitivity: 0.9338 - recall: 0.7586 - precision: 0.7750 - val_loss: 0.6378 - val_accuracy: 0.6633 - val_sensitivity_at_specificity: 0.8218 - val_specificity_at_sensitivity: 0.8140 - val_recall: 0.8034 - val_precision: 0.6332\n",
            "Epoch 178/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4524 - accuracy: 0.7684 - sensitivity_at_specificity: 0.9351 - specificity_at_sensitivity: 0.9414 - recall: 0.7490 - precision: 0.7741\n",
            "Epoch 178: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.4524 - accuracy: 0.7684 - sensitivity_at_specificity: 0.9351 - specificity_at_sensitivity: 0.9414 - recall: 0.7490 - precision: 0.7741 - val_loss: 0.6519 - val_accuracy: 0.6594 - val_sensitivity_at_specificity: 0.8066 - val_specificity_at_sensitivity: 0.7879 - val_recall: 0.7361 - val_precision: 0.6538\n",
            "Epoch 179/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4535 - accuracy: 0.7676 - sensitivity_at_specificity: 0.9319 - specificity_at_sensitivity: 0.9353 - recall: 0.7565 - precision: 0.7728\n",
            "Epoch 179: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.4535 - accuracy: 0.7676 - sensitivity_at_specificity: 0.9319 - specificity_at_sensitivity: 0.9353 - recall: 0.7565 - precision: 0.7728 - val_loss: 0.6447 - val_accuracy: 0.6930 - val_sensitivity_at_specificity: 0.8595 - val_specificity_at_sensitivity: 0.8260 - val_recall: 0.8449 - val_precision: 0.6378\n",
            "Epoch 180/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4293 - accuracy: 0.7805 - sensitivity_at_specificity: 0.9437 - specificity_at_sensitivity: 0.9633 - recall: 0.7514 - precision: 0.7975\n",
            "Epoch 180: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.4293 - accuracy: 0.7805 - sensitivity_at_specificity: 0.9437 - specificity_at_sensitivity: 0.9633 - recall: 0.7514 - precision: 0.7975 - val_loss: 0.6581 - val_accuracy: 0.6859 - val_sensitivity_at_specificity: 0.8310 - val_specificity_at_sensitivity: 0.8157 - val_recall: 0.7798 - val_precision: 0.6592\n",
            "Epoch 181/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4484 - accuracy: 0.7734 - sensitivity_at_specificity: 0.9283 - specificity_at_sensitivity: 0.9525 - recall: 0.7494 - precision: 0.7922\n",
            "Epoch 181: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.4484 - accuracy: 0.7734 - sensitivity_at_specificity: 0.9283 - specificity_at_sensitivity: 0.9525 - recall: 0.7494 - precision: 0.7922 - val_loss: 0.7314 - val_accuracy: 0.6539 - val_sensitivity_at_specificity: 0.8387 - val_specificity_at_sensitivity: 0.7901 - val_recall: 0.8725 - val_precision: 0.6121\n",
            "Epoch 182/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4521 - accuracy: 0.7672 - sensitivity_at_specificity: 0.9240 - specificity_at_sensitivity: 0.9488 - recall: 0.7868 - precision: 0.7597\n",
            "Epoch 182: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.4521 - accuracy: 0.7672 - sensitivity_at_specificity: 0.9240 - specificity_at_sensitivity: 0.9488 - recall: 0.7868 - precision: 0.7597 - val_loss: 0.6155 - val_accuracy: 0.6969 - val_sensitivity_at_specificity: 0.8667 - val_specificity_at_sensitivity: 0.8446 - val_recall: 0.7630 - val_precision: 0.6931\n",
            "Epoch 183/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4475 - accuracy: 0.7750 - sensitivity_at_specificity: 0.9323 - specificity_at_sensitivity: 0.9443 - recall: 0.7706 - precision: 0.7791\n",
            "Epoch 183: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.4475 - accuracy: 0.7750 - sensitivity_at_specificity: 0.9323 - specificity_at_sensitivity: 0.9443 - recall: 0.7706 - precision: 0.7791 - val_loss: 0.6925 - val_accuracy: 0.6656 - val_sensitivity_at_specificity: 0.8050 - val_specificity_at_sensitivity: 0.7918 - val_recall: 0.7957 - val_precision: 0.6346\n",
            "Epoch 184/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4449 - accuracy: 0.7555 - sensitivity_at_specificity: 0.9271 - specificity_at_sensitivity: 0.9642 - recall: 0.7412 - precision: 0.7615\n",
            "Epoch 184: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.4449 - accuracy: 0.7555 - sensitivity_at_specificity: 0.9271 - specificity_at_sensitivity: 0.9642 - recall: 0.7412 - precision: 0.7615 - val_loss: 0.6738 - val_accuracy: 0.6742 - val_sensitivity_at_specificity: 0.8465 - val_specificity_at_sensitivity: 0.8063 - val_recall: 0.7752 - val_precision: 0.6477\n",
            "Epoch 185/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4435 - accuracy: 0.7738 - sensitivity_at_specificity: 0.9378 - specificity_at_sensitivity: 0.9466 - recall: 0.7584 - precision: 0.7846\n",
            "Epoch 185: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.4435 - accuracy: 0.7738 - sensitivity_at_specificity: 0.9378 - specificity_at_sensitivity: 0.9466 - recall: 0.7584 - precision: 0.7846 - val_loss: 0.6519 - val_accuracy: 0.6953 - val_sensitivity_at_specificity: 0.8663 - val_specificity_at_sensitivity: 0.8257 - val_recall: 0.8212 - val_precision: 0.6575\n",
            "Epoch 186/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4346 - accuracy: 0.7820 - sensitivity_at_specificity: 0.9413 - specificity_at_sensitivity: 0.9631 - recall: 0.7905 - precision: 0.7721\n",
            "Epoch 186: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.4346 - accuracy: 0.7820 - sensitivity_at_specificity: 0.9413 - specificity_at_sensitivity: 0.9631 - recall: 0.7905 - precision: 0.7721 - val_loss: 0.7258 - val_accuracy: 0.6766 - val_sensitivity_at_specificity: 0.8355 - val_specificity_at_sensitivity: 0.8076 - val_recall: 0.8000 - val_precision: 0.6310\n",
            "Epoch 187/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4382 - accuracy: 0.7785 - sensitivity_at_specificity: 0.9360 - specificity_at_sensitivity: 0.9551 - recall: 0.7561 - precision: 0.8006\n",
            "Epoch 187: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.4382 - accuracy: 0.7785 - sensitivity_at_specificity: 0.9360 - specificity_at_sensitivity: 0.9551 - recall: 0.7561 - precision: 0.8006 - val_loss: 0.6720 - val_accuracy: 0.6555 - val_sensitivity_at_specificity: 0.8108 - val_specificity_at_sensitivity: 0.7988 - val_recall: 0.8124 - val_precision: 0.6127\n",
            "Epoch 188/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4506 - accuracy: 0.7668 - sensitivity_at_specificity: 0.9272 - specificity_at_sensitivity: 0.9591 - recall: 0.7751 - precision: 0.7577\n",
            "Epoch 188: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.4506 - accuracy: 0.7668 - sensitivity_at_specificity: 0.9272 - specificity_at_sensitivity: 0.9591 - recall: 0.7751 - precision: 0.7577 - val_loss: 0.6527 - val_accuracy: 0.6680 - val_sensitivity_at_specificity: 0.8278 - val_specificity_at_sensitivity: 0.8130 - val_recall: 0.7235 - val_precision: 0.6469\n",
            "Epoch 189/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4291 - accuracy: 0.7807 - sensitivity_at_specificity: 0.9465 - specificity_at_sensitivity: 0.9661 - recall: 0.7260 - precision: 0.8129\n",
            "Epoch 189: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.4291 - accuracy: 0.7807 - sensitivity_at_specificity: 0.9465 - specificity_at_sensitivity: 0.9661 - recall: 0.7260 - precision: 0.8129 - val_loss: 0.6805 - val_accuracy: 0.6734 - val_sensitivity_at_specificity: 0.8227 - val_specificity_at_sensitivity: 0.8085 - val_recall: 0.7698 - val_precision: 0.6471\n",
            "Epoch 190/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4305 - accuracy: 0.7852 - sensitivity_at_specificity: 0.9311 - specificity_at_sensitivity: 0.9676 - recall: 0.7514 - precision: 0.8008\n",
            "Epoch 190: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.4305 - accuracy: 0.7852 - sensitivity_at_specificity: 0.9311 - specificity_at_sensitivity: 0.9676 - recall: 0.7514 - precision: 0.8008 - val_loss: 0.8042 - val_accuracy: 0.6406 - val_sensitivity_at_specificity: 0.8530 - val_specificity_at_sensitivity: 0.7943 - val_recall: 0.8966 - val_precision: 0.5836\n",
            "Epoch 191/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4418 - accuracy: 0.7750 - sensitivity_at_specificity: 0.9473 - specificity_at_sensitivity: 0.9550 - recall: 0.7736 - precision: 0.7736\n",
            "Epoch 191: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.4418 - accuracy: 0.7750 - sensitivity_at_specificity: 0.9473 - specificity_at_sensitivity: 0.9550 - recall: 0.7736 - precision: 0.7736 - val_loss: 0.6937 - val_accuracy: 0.6703 - val_sensitivity_at_specificity: 0.8225 - val_specificity_at_sensitivity: 0.8059 - val_recall: 0.8051 - val_precision: 0.6295\n",
            "Epoch 192/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4337 - accuracy: 0.7867 - sensitivity_at_specificity: 0.9444 - specificity_at_sensitivity: 0.9562 - recall: 0.7857 - precision: 0.7820\n",
            "Epoch 192: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.4337 - accuracy: 0.7867 - sensitivity_at_specificity: 0.9444 - specificity_at_sensitivity: 0.9562 - recall: 0.7857 - precision: 0.7820 - val_loss: 0.6660 - val_accuracy: 0.6758 - val_sensitivity_at_specificity: 0.8406 - val_specificity_at_sensitivity: 0.8281 - val_recall: 0.7578 - val_precision: 0.6510\n",
            "Epoch 193/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4277 - accuracy: 0.7793 - sensitivity_at_specificity: 0.9556 - specificity_at_sensitivity: 0.9554 - recall: 0.7262 - precision: 0.8062\n",
            "Epoch 193: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.4277 - accuracy: 0.7793 - sensitivity_at_specificity: 0.9556 - specificity_at_sensitivity: 0.9554 - recall: 0.7262 - precision: 0.8062 - val_loss: 0.6608 - val_accuracy: 0.6680 - val_sensitivity_at_specificity: 0.8211 - val_specificity_at_sensitivity: 0.8131 - val_recall: 0.7966 - val_precision: 0.6408\n",
            "Epoch 194/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4526 - accuracy: 0.7785 - sensitivity_at_specificity: 0.9261 - specificity_at_sensitivity: 0.9466 - recall: 0.7838 - precision: 0.7772\n",
            "Epoch 194: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.4526 - accuracy: 0.7785 - sensitivity_at_specificity: 0.9261 - specificity_at_sensitivity: 0.9466 - recall: 0.7838 - precision: 0.7772 - val_loss: 0.6897 - val_accuracy: 0.6781 - val_sensitivity_at_specificity: 0.8567 - val_specificity_at_sensitivity: 0.8098 - val_recall: 0.8599 - val_precision: 0.6250\n",
            "Epoch 195/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4321 - accuracy: 0.7937 - sensitivity_at_specificity: 0.9428 - specificity_at_sensitivity: 0.9572 - recall: 0.7853 - precision: 0.7978\n",
            "Epoch 195: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.4321 - accuracy: 0.7937 - sensitivity_at_specificity: 0.9428 - specificity_at_sensitivity: 0.9572 - recall: 0.7853 - precision: 0.7978 - val_loss: 0.7686 - val_accuracy: 0.6539 - val_sensitivity_at_specificity: 0.8144 - val_specificity_at_sensitivity: 0.7664 - val_recall: 0.7456 - val_precision: 0.6213\n",
            "Epoch 196/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4407 - accuracy: 0.7762 - sensitivity_at_specificity: 0.9360 - specificity_at_sensitivity: 0.9462 - recall: 0.7631 - precision: 0.7880\n",
            "Epoch 196: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.4407 - accuracy: 0.7762 - sensitivity_at_specificity: 0.9360 - specificity_at_sensitivity: 0.9462 - recall: 0.7631 - precision: 0.7880 - val_loss: 0.6291 - val_accuracy: 0.6734 - val_sensitivity_at_specificity: 0.8318 - val_specificity_at_sensitivity: 0.8276 - val_recall: 0.8567 - val_precision: 0.6279\n",
            "Epoch 197/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4345 - accuracy: 0.7820 - sensitivity_at_specificity: 0.9372 - specificity_at_sensitivity: 0.9657 - recall: 0.8146 - precision: 0.7708\n",
            "Epoch 197: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.4345 - accuracy: 0.7820 - sensitivity_at_specificity: 0.9372 - specificity_at_sensitivity: 0.9657 - recall: 0.8146 - precision: 0.7708 - val_loss: 0.7412 - val_accuracy: 0.6742 - val_sensitivity_at_specificity: 0.8569 - val_specificity_at_sensitivity: 0.8289 - val_recall: 0.9067 - val_precision: 0.6202\n",
            "Epoch 198/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4244 - accuracy: 0.7859 - sensitivity_at_specificity: 0.9461 - specificity_at_sensitivity: 0.9600 - recall: 0.7716 - precision: 0.7891\n",
            "Epoch 198: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.4244 - accuracy: 0.7859 - sensitivity_at_specificity: 0.9461 - specificity_at_sensitivity: 0.9600 - recall: 0.7716 - precision: 0.7891 - val_loss: 0.7178 - val_accuracy: 0.6531 - val_sensitivity_at_specificity: 0.8137 - val_specificity_at_sensitivity: 0.8221 - val_recall: 0.8057 - val_precision: 0.6111\n",
            "Epoch 199/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4224 - accuracy: 0.7961 - sensitivity_at_specificity: 0.9498 - specificity_at_sensitivity: 0.9662 - recall: 0.7818 - precision: 0.8026\n",
            "Epoch 199: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 157ms/step - loss: 0.4224 - accuracy: 0.7961 - sensitivity_at_specificity: 0.9498 - specificity_at_sensitivity: 0.9662 - recall: 0.7818 - precision: 0.8026 - val_loss: 0.7180 - val_accuracy: 0.6641 - val_sensitivity_at_specificity: 0.8084 - val_specificity_at_sensitivity: 0.8166 - val_recall: 0.7788 - val_precision: 0.6345\n",
            "Epoch 200/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4166 - accuracy: 0.7930 - sensitivity_at_specificity: 0.9451 - specificity_at_sensitivity: 0.9712 - recall: 0.7774 - precision: 0.8013\n",
            "Epoch 200: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.4166 - accuracy: 0.7930 - sensitivity_at_specificity: 0.9451 - specificity_at_sensitivity: 0.9712 - recall: 0.7774 - precision: 0.8013 - val_loss: 0.7886 - val_accuracy: 0.6586 - val_sensitivity_at_specificity: 0.7958 - val_specificity_at_sensitivity: 0.7801 - val_recall: 0.7883 - val_precision: 0.6395\n",
            "Epoch 201/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3963 - accuracy: 0.8105 - sensitivity_at_specificity: 0.9556 - specificity_at_sensitivity: 0.9808 - recall: 0.7740 - precision: 0.8299\n",
            "Epoch 201: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.3963 - accuracy: 0.8105 - sensitivity_at_specificity: 0.9556 - specificity_at_sensitivity: 0.9808 - recall: 0.7740 - precision: 0.8299 - val_loss: 0.8434 - val_accuracy: 0.6398 - val_sensitivity_at_specificity: 0.8114 - val_specificity_at_sensitivity: 0.7889 - val_recall: 0.8700 - val_precision: 0.5916\n",
            "Epoch 202/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4136 - accuracy: 0.8000 - sensitivity_at_specificity: 0.9558 - specificity_at_sensitivity: 0.9675 - recall: 0.7828 - precision: 0.8070\n",
            "Epoch 202: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.4136 - accuracy: 0.8000 - sensitivity_at_specificity: 0.9558 - specificity_at_sensitivity: 0.9675 - recall: 0.7828 - precision: 0.8070 - val_loss: 0.7684 - val_accuracy: 0.6523 - val_sensitivity_at_specificity: 0.8095 - val_specificity_at_sensitivity: 0.7853 - val_recall: 0.8277 - val_precision: 0.6206\n",
            "Epoch 203/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4254 - accuracy: 0.7949 - sensitivity_at_specificity: 0.9421 - specificity_at_sensitivity: 0.9689 - recall: 0.7699 - precision: 0.8002\n",
            "Epoch 203: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.4254 - accuracy: 0.7949 - sensitivity_at_specificity: 0.9421 - specificity_at_sensitivity: 0.9689 - recall: 0.7699 - precision: 0.8002 - val_loss: 0.7663 - val_accuracy: 0.6633 - val_sensitivity_at_specificity: 0.8146 - val_specificity_at_sensitivity: 0.7680 - val_recall: 0.7757 - val_precision: 0.6344\n",
            "Epoch 204/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4116 - accuracy: 0.7957 - sensitivity_at_specificity: 0.9476 - specificity_at_sensitivity: 0.9797 - recall: 0.7670 - precision: 0.8134\n",
            "Epoch 204: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.4116 - accuracy: 0.7957 - sensitivity_at_specificity: 0.9476 - specificity_at_sensitivity: 0.9797 - recall: 0.7670 - precision: 0.8134 - val_loss: 0.7101 - val_accuracy: 0.6695 - val_sensitivity_at_specificity: 0.8310 - val_specificity_at_sensitivity: 0.8126 - val_recall: 0.7721 - val_precision: 0.6434\n",
            "Epoch 205/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4122 - accuracy: 0.7945 - sensitivity_at_specificity: 0.9457 - specificity_at_sensitivity: 0.9690 - recall: 0.7781 - precision: 0.8021\n",
            "Epoch 205: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 193ms/step - loss: 0.4122 - accuracy: 0.7945 - sensitivity_at_specificity: 0.9457 - specificity_at_sensitivity: 0.9690 - recall: 0.7781 - precision: 0.8021 - val_loss: 0.6968 - val_accuracy: 0.6953 - val_sensitivity_at_specificity: 0.8298 - val_specificity_at_sensitivity: 0.8377 - val_recall: 0.7831 - val_precision: 0.6789\n",
            "Epoch 206/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4164 - accuracy: 0.7945 - sensitivity_at_specificity: 0.9517 - specificity_at_sensitivity: 0.9679 - recall: 0.7857 - precision: 0.8006\n",
            "Epoch 206: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 200ms/step - loss: 0.4164 - accuracy: 0.7945 - sensitivity_at_specificity: 0.9517 - specificity_at_sensitivity: 0.9679 - recall: 0.7857 - precision: 0.8006 - val_loss: 0.6970 - val_accuracy: 0.6750 - val_sensitivity_at_specificity: 0.8432 - val_specificity_at_sensitivity: 0.8244 - val_recall: 0.8240 - val_precision: 0.6273\n",
            "Epoch 207/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4067 - accuracy: 0.8062 - sensitivity_at_specificity: 0.9500 - specificity_at_sensitivity: 0.9692 - recall: 0.7906 - precision: 0.8112\n",
            "Epoch 207: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.4067 - accuracy: 0.8062 - sensitivity_at_specificity: 0.9500 - specificity_at_sensitivity: 0.9692 - recall: 0.7906 - precision: 0.8112 - val_loss: 0.7760 - val_accuracy: 0.6797 - val_sensitivity_at_specificity: 0.8373 - val_specificity_at_sensitivity: 0.8003 - val_recall: 0.8449 - val_precision: 0.6463\n",
            "Epoch 208/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3862 - accuracy: 0.8121 - sensitivity_at_specificity: 0.9534 - specificity_at_sensitivity: 0.9853 - recall: 0.7978 - precision: 0.8178\n",
            "Epoch 208: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.3862 - accuracy: 0.8121 - sensitivity_at_specificity: 0.9534 - specificity_at_sensitivity: 0.9853 - recall: 0.7978 - precision: 0.8178 - val_loss: 0.8388 - val_accuracy: 0.6469 - val_sensitivity_at_specificity: 0.7906 - val_specificity_at_sensitivity: 0.7674 - val_recall: 0.8661 - val_precision: 0.5998\n",
            "Epoch 209/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3882 - accuracy: 0.8215 - sensitivity_at_specificity: 0.9562 - specificity_at_sensitivity: 0.9789 - recall: 0.8083 - precision: 0.8407\n",
            "Epoch 209: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.3882 - accuracy: 0.8215 - sensitivity_at_specificity: 0.9562 - specificity_at_sensitivity: 0.9789 - recall: 0.8083 - precision: 0.8407 - val_loss: 0.6916 - val_accuracy: 0.6828 - val_sensitivity_at_specificity: 0.8409 - val_specificity_at_sensitivity: 0.8216 - val_recall: 0.7691 - val_precision: 0.6565\n",
            "Epoch 210/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3896 - accuracy: 0.8207 - sensitivity_at_specificity: 0.9528 - specificity_at_sensitivity: 0.9818 - recall: 0.7935 - precision: 0.8424\n",
            "Epoch 210: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.3896 - accuracy: 0.8207 - sensitivity_at_specificity: 0.9528 - specificity_at_sensitivity: 0.9818 - recall: 0.7935 - precision: 0.8424 - val_loss: 0.8119 - val_accuracy: 0.6695 - val_sensitivity_at_specificity: 0.8267 - val_specificity_at_sensitivity: 0.7990 - val_recall: 0.8222 - val_precision: 0.6387\n",
            "Epoch 211/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3844 - accuracy: 0.8141 - sensitivity_at_specificity: 0.9656 - specificity_at_sensitivity: 0.9809 - recall: 0.7926 - precision: 0.8202\n",
            "Epoch 211: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.3844 - accuracy: 0.8141 - sensitivity_at_specificity: 0.9656 - specificity_at_sensitivity: 0.9809 - recall: 0.7926 - precision: 0.8202 - val_loss: 0.8028 - val_accuracy: 0.6664 - val_sensitivity_at_specificity: 0.8240 - val_specificity_at_sensitivity: 0.7924 - val_recall: 0.7792 - val_precision: 0.6276\n",
            "Epoch 212/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3842 - accuracy: 0.8156 - sensitivity_at_specificity: 0.9599 - specificity_at_sensitivity: 0.9819 - recall: 0.8021 - precision: 0.8356\n",
            "Epoch 212: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.3842 - accuracy: 0.8156 - sensitivity_at_specificity: 0.9599 - specificity_at_sensitivity: 0.9819 - recall: 0.8021 - precision: 0.8356 - val_loss: 0.8997 - val_accuracy: 0.6289 - val_sensitivity_at_specificity: 0.8469 - val_specificity_at_sensitivity: 0.8085 - val_recall: 0.9368 - val_precision: 0.5630\n",
            "Epoch 213/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3981 - accuracy: 0.8027 - sensitivity_at_specificity: 0.9491 - specificity_at_sensitivity: 0.9796 - recall: 0.7835 - precision: 0.8036\n",
            "Epoch 213: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.3981 - accuracy: 0.8027 - sensitivity_at_specificity: 0.9491 - specificity_at_sensitivity: 0.9796 - recall: 0.7835 - precision: 0.8036 - val_loss: 0.7867 - val_accuracy: 0.6602 - val_sensitivity_at_specificity: 0.8198 - val_specificity_at_sensitivity: 0.8080 - val_recall: 0.8107 - val_precision: 0.6306\n",
            "Epoch 214/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3937 - accuracy: 0.8121 - sensitivity_at_specificity: 0.9562 - specificity_at_sensitivity: 0.9813 - recall: 0.7887 - precision: 0.8269\n",
            "Epoch 214: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.3937 - accuracy: 0.8121 - sensitivity_at_specificity: 0.9562 - specificity_at_sensitivity: 0.9813 - recall: 0.7887 - precision: 0.8269 - val_loss: 0.7782 - val_accuracy: 0.6445 - val_sensitivity_at_specificity: 0.7923 - val_specificity_at_sensitivity: 0.7768 - val_recall: 0.7380 - val_precision: 0.6135\n",
            "Epoch 215/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3880 - accuracy: 0.8152 - sensitivity_at_specificity: 0.9635 - specificity_at_sensitivity: 0.9788 - recall: 0.8219 - precision: 0.8125\n",
            "Epoch 215: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.3880 - accuracy: 0.8152 - sensitivity_at_specificity: 0.9635 - specificity_at_sensitivity: 0.9788 - recall: 0.8219 - precision: 0.8125 - val_loss: 0.6815 - val_accuracy: 0.6703 - val_sensitivity_at_specificity: 0.8145 - val_specificity_at_sensitivity: 0.7981 - val_recall: 0.7830 - val_precision: 0.6368\n",
            "Epoch 216/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3827 - accuracy: 0.8223 - sensitivity_at_specificity: 0.9651 - specificity_at_sensitivity: 0.9792 - recall: 0.7921 - precision: 0.8380\n",
            "Epoch 216: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.3827 - accuracy: 0.8223 - sensitivity_at_specificity: 0.9651 - specificity_at_sensitivity: 0.9792 - recall: 0.7921 - precision: 0.8380 - val_loss: 0.7695 - val_accuracy: 0.6461 - val_sensitivity_at_specificity: 0.7937 - val_specificity_at_sensitivity: 0.8141 - val_recall: 0.7906 - val_precision: 0.6133\n",
            "Epoch 217/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3831 - accuracy: 0.8137 - sensitivity_at_specificity: 0.9619 - specificity_at_sensitivity: 0.9843 - recall: 0.7986 - precision: 0.8249\n",
            "Epoch 217: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.3831 - accuracy: 0.8137 - sensitivity_at_specificity: 0.9619 - specificity_at_sensitivity: 0.9843 - recall: 0.7986 - precision: 0.8249 - val_loss: 0.8378 - val_accuracy: 0.6656 - val_sensitivity_at_specificity: 0.8263 - val_specificity_at_sensitivity: 0.7738 - val_recall: 0.8310 - val_precision: 0.6240\n",
            "Epoch 218/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3753 - accuracy: 0.8219 - sensitivity_at_specificity: 0.9627 - specificity_at_sensitivity: 0.9819 - recall: 0.8096 - precision: 0.8316\n",
            "Epoch 218: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.3753 - accuracy: 0.8219 - sensitivity_at_specificity: 0.9627 - specificity_at_sensitivity: 0.9819 - recall: 0.8096 - precision: 0.8316 - val_loss: 0.7425 - val_accuracy: 0.6672 - val_sensitivity_at_specificity: 0.8273 - val_specificity_at_sensitivity: 0.8258 - val_recall: 0.8455 - val_precision: 0.6327\n",
            "Epoch 219/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3669 - accuracy: 0.8254 - sensitivity_at_specificity: 0.9655 - specificity_at_sensitivity: 0.9880 - recall: 0.8276 - precision: 0.8295\n",
            "Epoch 219: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.3669 - accuracy: 0.8254 - sensitivity_at_specificity: 0.9655 - specificity_at_sensitivity: 0.9880 - recall: 0.8276 - precision: 0.8295 - val_loss: 0.8930 - val_accuracy: 0.6383 - val_sensitivity_at_specificity: 0.7705 - val_specificity_at_sensitivity: 0.7733 - val_recall: 0.8131 - val_precision: 0.6114\n",
            "Epoch 220/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3802 - accuracy: 0.8184 - sensitivity_at_specificity: 0.9615 - specificity_at_sensitivity: 0.9833 - recall: 0.8015 - precision: 0.8343\n",
            "Epoch 220: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.3802 - accuracy: 0.8184 - sensitivity_at_specificity: 0.9615 - specificity_at_sensitivity: 0.9833 - recall: 0.8015 - precision: 0.8343 - val_loss: 0.8343 - val_accuracy: 0.6594 - val_sensitivity_at_specificity: 0.8243 - val_specificity_at_sensitivity: 0.7928 - val_recall: 0.8709 - val_precision: 0.6134\n",
            "Epoch 221/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3455 - accuracy: 0.8383 - sensitivity_at_specificity: 0.9768 - specificity_at_sensitivity: 0.9881 - recall: 0.8371 - precision: 0.8423\n",
            "Epoch 221: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.3455 - accuracy: 0.8383 - sensitivity_at_specificity: 0.9768 - specificity_at_sensitivity: 0.9881 - recall: 0.8371 - precision: 0.8423 - val_loss: 0.9092 - val_accuracy: 0.6438 - val_sensitivity_at_specificity: 0.7846 - val_specificity_at_sensitivity: 0.7609 - val_recall: 0.7799 - val_precision: 0.6108\n",
            "Epoch 222/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3441 - accuracy: 0.8395 - sensitivity_at_specificity: 0.9708 - specificity_at_sensitivity: 0.9915 - recall: 0.8186 - precision: 0.8515\n",
            "Epoch 222: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.3441 - accuracy: 0.8395 - sensitivity_at_specificity: 0.9708 - specificity_at_sensitivity: 0.9915 - recall: 0.8186 - precision: 0.8515 - val_loss: 0.7467 - val_accuracy: 0.6758 - val_sensitivity_at_specificity: 0.8417 - val_specificity_at_sensitivity: 0.8146 - val_recall: 0.8119 - val_precision: 0.6371\n",
            "Epoch 223/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3794 - accuracy: 0.8188 - sensitivity_at_specificity: 0.9627 - specificity_at_sensitivity: 0.9811 - recall: 0.8042 - precision: 0.8300\n",
            "Epoch 223: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.3794 - accuracy: 0.8188 - sensitivity_at_specificity: 0.9627 - specificity_at_sensitivity: 0.9811 - recall: 0.8042 - precision: 0.8300 - val_loss: 0.8159 - val_accuracy: 0.6531 - val_sensitivity_at_specificity: 0.8072 - val_specificity_at_sensitivity: 0.8069 - val_recall: 0.8354 - val_precision: 0.6112\n",
            "Epoch 224/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3664 - accuracy: 0.8270 - sensitivity_at_specificity: 0.9587 - specificity_at_sensitivity: 0.9904 - recall: 0.8231 - precision: 0.8353\n",
            "Epoch 224: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.3664 - accuracy: 0.8270 - sensitivity_at_specificity: 0.9587 - specificity_at_sensitivity: 0.9904 - recall: 0.8231 - precision: 0.8353 - val_loss: 0.8342 - val_accuracy: 0.6516 - val_sensitivity_at_specificity: 0.8073 - val_specificity_at_sensitivity: 0.8099 - val_recall: 0.8104 - val_precision: 0.6114\n",
            "Epoch 225/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3672 - accuracy: 0.8250 - sensitivity_at_specificity: 0.9691 - specificity_at_sensitivity: 0.9823 - recall: 0.8049 - precision: 0.8340\n",
            "Epoch 225: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.3672 - accuracy: 0.8250 - sensitivity_at_specificity: 0.9691 - specificity_at_sensitivity: 0.9823 - recall: 0.8049 - precision: 0.8340 - val_loss: 0.7613 - val_accuracy: 0.6414 - val_sensitivity_at_specificity: 0.7587 - val_specificity_at_sensitivity: 0.7755 - val_recall: 0.7366 - val_precision: 0.6153\n",
            "Epoch 226/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3631 - accuracy: 0.8398 - sensitivity_at_specificity: 0.9696 - specificity_at_sensitivity: 0.9859 - recall: 0.8287 - precision: 0.8485\n",
            "Epoch 226: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.3631 - accuracy: 0.8398 - sensitivity_at_specificity: 0.9696 - specificity_at_sensitivity: 0.9859 - recall: 0.8287 - precision: 0.8485 - val_loss: 0.7576 - val_accuracy: 0.6734 - val_sensitivity_at_specificity: 0.8257 - val_specificity_at_sensitivity: 0.8168 - val_recall: 0.7590 - val_precision: 0.6332\n",
            "Epoch 227/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3605 - accuracy: 0.8297 - sensitivity_at_specificity: 0.9720 - specificity_at_sensitivity: 0.9870 - recall: 0.8053 - precision: 0.8389\n",
            "Epoch 227: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.3605 - accuracy: 0.8297 - sensitivity_at_specificity: 0.9720 - specificity_at_sensitivity: 0.9870 - recall: 0.8053 - precision: 0.8389 - val_loss: 0.8017 - val_accuracy: 0.6625 - val_sensitivity_at_specificity: 0.8294 - val_specificity_at_sensitivity: 0.7972 - val_recall: 0.8419 - val_precision: 0.6191\n",
            "Epoch 228/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3663 - accuracy: 0.8320 - sensitivity_at_specificity: 0.9641 - specificity_at_sensitivity: 0.9914 - recall: 0.7973 - precision: 0.8575\n",
            "Epoch 228: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.3663 - accuracy: 0.8320 - sensitivity_at_specificity: 0.9641 - specificity_at_sensitivity: 0.9914 - recall: 0.7973 - precision: 0.8575 - val_loss: 0.9568 - val_accuracy: 0.6328 - val_sensitivity_at_specificity: 0.7911 - val_specificity_at_sensitivity: 0.7703 - val_recall: 0.8868 - val_precision: 0.5822\n",
            "Epoch 229/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3606 - accuracy: 0.8281 - sensitivity_at_specificity: 0.9663 - specificity_at_sensitivity: 0.9896 - recall: 0.8370 - precision: 0.8282\n",
            "Epoch 229: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.3606 - accuracy: 0.8281 - sensitivity_at_specificity: 0.9663 - specificity_at_sensitivity: 0.9896 - recall: 0.8370 - precision: 0.8282 - val_loss: 0.8862 - val_accuracy: 0.6555 - val_sensitivity_at_specificity: 0.8300 - val_specificity_at_sensitivity: 0.8120 - val_recall: 0.9119 - val_precision: 0.6057\n",
            "Epoch 230/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3650 - accuracy: 0.8270 - sensitivity_at_specificity: 0.9635 - specificity_at_sensitivity: 0.9874 - recall: 0.8095 - precision: 0.8402\n",
            "Epoch 230: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.3650 - accuracy: 0.8270 - sensitivity_at_specificity: 0.9635 - specificity_at_sensitivity: 0.9874 - recall: 0.8095 - precision: 0.8402 - val_loss: 0.8250 - val_accuracy: 0.6562 - val_sensitivity_at_specificity: 0.8131 - val_specificity_at_sensitivity: 0.7768 - val_recall: 0.7732 - val_precision: 0.6189\n",
            "Epoch 231/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3405 - accuracy: 0.8453 - sensitivity_at_specificity: 0.9735 - specificity_at_sensitivity: 0.9909 - recall: 0.8082 - precision: 0.8651\n",
            "Epoch 231: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.3405 - accuracy: 0.8453 - sensitivity_at_specificity: 0.9735 - specificity_at_sensitivity: 0.9909 - recall: 0.8082 - precision: 0.8651 - val_loss: 0.7666 - val_accuracy: 0.7016 - val_sensitivity_at_specificity: 0.8739 - val_specificity_at_sensitivity: 0.8225 - val_recall: 0.8559 - val_precision: 0.6659\n",
            "Epoch 232/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3475 - accuracy: 0.8314 - sensitivity_at_specificity: 0.9695 - specificity_at_sensitivity: 0.9902 - recall: 0.7995 - precision: 0.8483\n",
            "Epoch 232: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.3475 - accuracy: 0.8314 - sensitivity_at_specificity: 0.9695 - specificity_at_sensitivity: 0.9902 - recall: 0.7995 - precision: 0.8483 - val_loss: 0.8482 - val_accuracy: 0.6516 - val_sensitivity_at_specificity: 0.8018 - val_specificity_at_sensitivity: 0.8060 - val_recall: 0.8172 - val_precision: 0.6193\n",
            "Epoch 233/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3665 - accuracy: 0.8242 - sensitivity_at_specificity: 0.9650 - specificity_at_sensitivity: 0.9824 - recall: 0.8105 - precision: 0.8276\n",
            "Epoch 233: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.3665 - accuracy: 0.8242 - sensitivity_at_specificity: 0.9650 - specificity_at_sensitivity: 0.9824 - recall: 0.8105 - precision: 0.8276 - val_loss: 0.8168 - val_accuracy: 0.6531 - val_sensitivity_at_specificity: 0.8118 - val_specificity_at_sensitivity: 0.7688 - val_recall: 0.8134 - val_precision: 0.6093\n",
            "Epoch 234/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3516 - accuracy: 0.8301 - sensitivity_at_specificity: 0.9751 - specificity_at_sensitivity: 0.9906 - recall: 0.8231 - precision: 0.8354\n",
            "Epoch 234: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.3516 - accuracy: 0.8301 - sensitivity_at_specificity: 0.9751 - specificity_at_sensitivity: 0.9906 - recall: 0.8231 - precision: 0.8354 - val_loss: 0.8659 - val_accuracy: 0.6625 - val_sensitivity_at_specificity: 0.8447 - val_specificity_at_sensitivity: 0.7870 - val_recall: 0.8463 - val_precision: 0.6081\n",
            "Epoch 235/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3603 - accuracy: 0.8297 - sensitivity_at_specificity: 0.9655 - specificity_at_sensitivity: 0.9865 - recall: 0.8198 - precision: 0.8417\n",
            "Epoch 235: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.3603 - accuracy: 0.8297 - sensitivity_at_specificity: 0.9655 - specificity_at_sensitivity: 0.9865 - recall: 0.8198 - precision: 0.8417 - val_loss: 0.8580 - val_accuracy: 0.6547 - val_sensitivity_at_specificity: 0.8100 - val_specificity_at_sensitivity: 0.7846 - val_recall: 0.8571 - val_precision: 0.6184\n",
            "Epoch 236/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3382 - accuracy: 0.8422 - sensitivity_at_specificity: 0.9680 - specificity_at_sensitivity: 0.9906 - recall: 0.8289 - precision: 0.8515\n",
            "Epoch 236: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.3382 - accuracy: 0.8422 - sensitivity_at_specificity: 0.9680 - specificity_at_sensitivity: 0.9906 - recall: 0.8289 - precision: 0.8515 - val_loss: 0.8776 - val_accuracy: 0.6617 - val_sensitivity_at_specificity: 0.8262 - val_specificity_at_sensitivity: 0.8009 - val_recall: 0.8166 - val_precision: 0.6169\n",
            "Epoch 237/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3465 - accuracy: 0.8414 - sensitivity_at_specificity: 0.9717 - specificity_at_sensitivity: 0.9888 - recall: 0.8296 - precision: 0.8558\n",
            "Epoch 237: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.3465 - accuracy: 0.8414 - sensitivity_at_specificity: 0.9717 - specificity_at_sensitivity: 0.9888 - recall: 0.8296 - precision: 0.8558 - val_loss: 0.8323 - val_accuracy: 0.6695 - val_sensitivity_at_specificity: 0.8415 - val_specificity_at_sensitivity: 0.8013 - val_recall: 0.8735 - val_precision: 0.6276\n",
            "Epoch 238/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3435 - accuracy: 0.8387 - sensitivity_at_specificity: 0.9697 - specificity_at_sensitivity: 0.9906 - recall: 0.8275 - precision: 0.8479\n",
            "Epoch 238: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.3435 - accuracy: 0.8387 - sensitivity_at_specificity: 0.9697 - specificity_at_sensitivity: 0.9906 - recall: 0.8275 - precision: 0.8479 - val_loss: 0.9254 - val_accuracy: 0.6531 - val_sensitivity_at_specificity: 0.8028 - val_specificity_at_sensitivity: 0.7907 - val_recall: 0.8654 - val_precision: 0.6139\n",
            "Epoch 239/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3570 - accuracy: 0.8328 - sensitivity_at_specificity: 0.9702 - specificity_at_sensitivity: 0.9852 - recall: 0.8197 - precision: 0.8408\n",
            "Epoch 239: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.3570 - accuracy: 0.8328 - sensitivity_at_specificity: 0.9702 - specificity_at_sensitivity: 0.9852 - recall: 0.8197 - precision: 0.8408 - val_loss: 0.8696 - val_accuracy: 0.6578 - val_sensitivity_at_specificity: 0.8452 - val_specificity_at_sensitivity: 0.7991 - val_recall: 0.8910 - val_precision: 0.6045\n",
            "Epoch 240/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3284 - accuracy: 0.8543 - sensitivity_at_specificity: 0.9794 - specificity_at_sensitivity: 0.9931 - recall: 0.8399 - precision: 0.8611\n",
            "Epoch 240: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.3284 - accuracy: 0.8543 - sensitivity_at_specificity: 0.9794 - specificity_at_sensitivity: 0.9931 - recall: 0.8399 - precision: 0.8611 - val_loss: 0.8750 - val_accuracy: 0.6758 - val_sensitivity_at_specificity: 0.8514 - val_specificity_at_sensitivity: 0.7808 - val_recall: 0.8746 - val_precision: 0.6285\n",
            "Epoch 241/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3283 - accuracy: 0.8492 - sensitivity_at_specificity: 0.9796 - specificity_at_sensitivity: 0.9953 - recall: 0.8331 - precision: 0.8600\n",
            "Epoch 241: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.3283 - accuracy: 0.8492 - sensitivity_at_specificity: 0.9796 - specificity_at_sensitivity: 0.9953 - recall: 0.8331 - precision: 0.8600 - val_loss: 0.8297 - val_accuracy: 0.6852 - val_sensitivity_at_specificity: 0.8656 - val_specificity_at_sensitivity: 0.8137 - val_recall: 0.8464 - val_precision: 0.6328\n",
            "Epoch 242/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3222 - accuracy: 0.8512 - sensitivity_at_specificity: 0.9816 - specificity_at_sensitivity: 0.9912 - recall: 0.8415 - precision: 0.8633\n",
            "Epoch 242: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.3222 - accuracy: 0.8512 - sensitivity_at_specificity: 0.9816 - specificity_at_sensitivity: 0.9912 - recall: 0.8415 - precision: 0.8633 - val_loss: 0.9744 - val_accuracy: 0.6523 - val_sensitivity_at_specificity: 0.8333 - val_specificity_at_sensitivity: 0.8142 - val_recall: 0.8900 - val_precision: 0.5933\n",
            "Epoch 243/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3155 - accuracy: 0.8570 - sensitivity_at_specificity: 0.9796 - specificity_at_sensitivity: 0.9977 - recall: 0.8407 - precision: 0.8679\n",
            "Epoch 243: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.3155 - accuracy: 0.8570 - sensitivity_at_specificity: 0.9796 - specificity_at_sensitivity: 0.9977 - recall: 0.8407 - precision: 0.8679 - val_loss: 0.9894 - val_accuracy: 0.6391 - val_sensitivity_at_specificity: 0.8038 - val_specificity_at_sensitivity: 0.7636 - val_recall: 0.8697 - val_precision: 0.5938\n",
            "Epoch 244/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3202 - accuracy: 0.8551 - sensitivity_at_specificity: 0.9770 - specificity_at_sensitivity: 0.9912 - recall: 0.8539 - precision: 0.8611\n",
            "Epoch 244: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.3202 - accuracy: 0.8551 - sensitivity_at_specificity: 0.9770 - specificity_at_sensitivity: 0.9912 - recall: 0.8539 - precision: 0.8611 - val_loss: 0.9356 - val_accuracy: 0.6656 - val_sensitivity_at_specificity: 0.8286 - val_specificity_at_sensitivity: 0.7769 - val_recall: 0.8254 - val_precision: 0.6205\n",
            "Epoch 245/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3192 - accuracy: 0.8535 - sensitivity_at_specificity: 0.9787 - specificity_at_sensitivity: 0.9946 - recall: 0.8322 - precision: 0.8670\n",
            "Epoch 245: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.3192 - accuracy: 0.8535 - sensitivity_at_specificity: 0.9787 - specificity_at_sensitivity: 0.9946 - recall: 0.8322 - precision: 0.8670 - val_loss: 0.9164 - val_accuracy: 0.6516 - val_sensitivity_at_specificity: 0.8076 - val_specificity_at_sensitivity: 0.7581 - val_recall: 0.8364 - val_precision: 0.6202\n",
            "Epoch 246/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3267 - accuracy: 0.8574 - sensitivity_at_specificity: 0.9742 - specificity_at_sensitivity: 0.9937 - recall: 0.8445 - precision: 0.8669\n",
            "Epoch 246: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.3267 - accuracy: 0.8574 - sensitivity_at_specificity: 0.9742 - specificity_at_sensitivity: 0.9937 - recall: 0.8445 - precision: 0.8669 - val_loss: 0.9022 - val_accuracy: 0.6578 - val_sensitivity_at_specificity: 0.8166 - val_specificity_at_sensitivity: 0.8114 - val_recall: 0.8336 - val_precision: 0.6211\n",
            "Epoch 247/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3272 - accuracy: 0.8402 - sensitivity_at_specificity: 0.9739 - specificity_at_sensitivity: 0.9984 - recall: 0.8299 - precision: 0.8528\n",
            "Epoch 247: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.3272 - accuracy: 0.8402 - sensitivity_at_specificity: 0.9739 - specificity_at_sensitivity: 0.9984 - recall: 0.8299 - precision: 0.8528 - val_loss: 0.8651 - val_accuracy: 0.6812 - val_sensitivity_at_specificity: 0.8436 - val_specificity_at_sensitivity: 0.7978 - val_recall: 0.8160 - val_precision: 0.6488\n",
            "Epoch 248/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3274 - accuracy: 0.8551 - sensitivity_at_specificity: 0.9715 - specificity_at_sensitivity: 0.9937 - recall: 0.8364 - precision: 0.8721\n",
            "Epoch 248: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.3274 - accuracy: 0.8551 - sensitivity_at_specificity: 0.9715 - specificity_at_sensitivity: 0.9937 - recall: 0.8364 - precision: 0.8721 - val_loss: 0.8921 - val_accuracy: 0.6617 - val_sensitivity_at_specificity: 0.8466 - val_specificity_at_sensitivity: 0.7847 - val_recall: 0.8717 - val_precision: 0.6134\n",
            "Epoch 249/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2981 - accuracy: 0.8684 - sensitivity_at_specificity: 0.9799 - specificity_at_sensitivity: 0.9976 - recall: 0.8561 - precision: 0.8800\n",
            "Epoch 249: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.2981 - accuracy: 0.8684 - sensitivity_at_specificity: 0.9799 - specificity_at_sensitivity: 0.9976 - recall: 0.8561 - precision: 0.8800 - val_loss: 1.0343 - val_accuracy: 0.6633 - val_sensitivity_at_specificity: 0.8447 - val_specificity_at_sensitivity: 0.8066 - val_recall: 0.8997 - val_precision: 0.6011\n",
            "Epoch 250/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3229 - accuracy: 0.8625 - sensitivity_at_specificity: 0.9806 - specificity_at_sensitivity: 0.9917 - recall: 0.8492 - precision: 0.8645\n",
            "Epoch 250: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.3229 - accuracy: 0.8625 - sensitivity_at_specificity: 0.9806 - specificity_at_sensitivity: 0.9917 - recall: 0.8492 - precision: 0.8645 - val_loss: 0.9164 - val_accuracy: 0.6422 - val_sensitivity_at_specificity: 0.7832 - val_specificity_at_sensitivity: 0.7668 - val_recall: 0.7816 - val_precision: 0.6117\n",
            "Epoch 251/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3218 - accuracy: 0.8602 - sensitivity_at_specificity: 0.9741 - specificity_at_sensitivity: 0.9922 - recall: 0.8327 - precision: 0.8797\n",
            "Epoch 251: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.3218 - accuracy: 0.8602 - sensitivity_at_specificity: 0.9741 - specificity_at_sensitivity: 0.9922 - recall: 0.8327 - precision: 0.8797 - val_loss: 0.8374 - val_accuracy: 0.6461 - val_sensitivity_at_specificity: 0.7994 - val_specificity_at_sensitivity: 0.7991 - val_recall: 0.8042 - val_precision: 0.5995\n",
            "Epoch 252/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2995 - accuracy: 0.8645 - sensitivity_at_specificity: 0.9897 - specificity_at_sensitivity: 0.9969 - recall: 0.8470 - precision: 0.8753\n",
            "Epoch 252: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.2995 - accuracy: 0.8645 - sensitivity_at_specificity: 0.9897 - specificity_at_sensitivity: 0.9969 - recall: 0.8470 - precision: 0.8753 - val_loss: 0.9841 - val_accuracy: 0.6477 - val_sensitivity_at_specificity: 0.7950 - val_specificity_at_sensitivity: 0.7566 - val_recall: 0.8357 - val_precision: 0.6068\n",
            "Epoch 253/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3130 - accuracy: 0.8656 - sensitivity_at_specificity: 0.9780 - specificity_at_sensitivity: 0.9932 - recall: 0.8378 - precision: 0.8764\n",
            "Epoch 253: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.3130 - accuracy: 0.8656 - sensitivity_at_specificity: 0.9780 - specificity_at_sensitivity: 0.9932 - recall: 0.8378 - precision: 0.8764 - val_loss: 0.8759 - val_accuracy: 0.6703 - val_sensitivity_at_specificity: 0.8487 - val_specificity_at_sensitivity: 0.8206 - val_recall: 0.8217 - val_precision: 0.6247\n",
            "Epoch 254/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2979 - accuracy: 0.8703 - sensitivity_at_specificity: 0.9805 - specificity_at_sensitivity: 0.9976 - recall: 0.8545 - precision: 0.8833\n",
            "Epoch 254: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 183ms/step - loss: 0.2979 - accuracy: 0.8703 - sensitivity_at_specificity: 0.9805 - specificity_at_sensitivity: 0.9976 - recall: 0.8545 - precision: 0.8833 - val_loss: 1.0178 - val_accuracy: 0.6555 - val_sensitivity_at_specificity: 0.8176 - val_specificity_at_sensitivity: 0.7852 - val_recall: 0.8903 - val_precision: 0.6089\n",
            "Epoch 255/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3152 - accuracy: 0.8652 - sensitivity_at_specificity: 0.9757 - specificity_at_sensitivity: 0.9945 - recall: 0.8590 - precision: 0.8693\n",
            "Epoch 255: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.3152 - accuracy: 0.8652 - sensitivity_at_specificity: 0.9757 - specificity_at_sensitivity: 0.9945 - recall: 0.8590 - precision: 0.8693 - val_loss: 0.9295 - val_accuracy: 0.6578 - val_sensitivity_at_specificity: 0.8273 - val_specificity_at_sensitivity: 0.7750 - val_recall: 0.8700 - val_precision: 0.6066\n",
            "Epoch 256/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2946 - accuracy: 0.8723 - sensitivity_at_specificity: 0.9852 - specificity_at_sensitivity: 0.9977 - recall: 0.8729 - precision: 0.8722\n",
            "Epoch 256: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.2946 - accuracy: 0.8723 - sensitivity_at_specificity: 0.9852 - specificity_at_sensitivity: 0.9977 - recall: 0.8729 - precision: 0.8722 - val_loss: 0.9573 - val_accuracy: 0.6523 - val_sensitivity_at_specificity: 0.8043 - val_specificity_at_sensitivity: 0.7845 - val_recall: 0.8428 - val_precision: 0.6146\n",
            "Epoch 257/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3092 - accuracy: 0.8641 - sensitivity_at_specificity: 0.9732 - specificity_at_sensitivity: 0.9977 - recall: 0.8312 - precision: 0.8797\n",
            "Epoch 257: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.3092 - accuracy: 0.8641 - sensitivity_at_specificity: 0.9732 - specificity_at_sensitivity: 0.9977 - recall: 0.8312 - precision: 0.8797 - val_loss: 0.9100 - val_accuracy: 0.6617 - val_sensitivity_at_specificity: 0.8196 - val_specificity_at_sensitivity: 0.7732 - val_recall: 0.8226 - val_precision: 0.6292\n",
            "Epoch 258/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3230 - accuracy: 0.8523 - sensitivity_at_specificity: 0.9731 - specificity_at_sensitivity: 0.9952 - recall: 0.8449 - precision: 0.8621\n",
            "Epoch 258: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.3230 - accuracy: 0.8523 - sensitivity_at_specificity: 0.9731 - specificity_at_sensitivity: 0.9952 - recall: 0.8449 - precision: 0.8621 - val_loss: 0.8179 - val_accuracy: 0.6906 - val_sensitivity_at_specificity: 0.8672 - val_specificity_at_sensitivity: 0.8531 - val_recall: 0.8547 - val_precision: 0.6435\n",
            "Epoch 259/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2998 - accuracy: 0.8699 - sensitivity_at_specificity: 0.9767 - specificity_at_sensitivity: 0.9961 - recall: 0.8424 - precision: 0.8930\n",
            "Epoch 259: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.2998 - accuracy: 0.8699 - sensitivity_at_specificity: 0.9767 - specificity_at_sensitivity: 0.9961 - recall: 0.8424 - precision: 0.8930 - val_loss: 0.9638 - val_accuracy: 0.6414 - val_sensitivity_at_specificity: 0.7968 - val_specificity_at_sensitivity: 0.7344 - val_recall: 0.8736 - val_precision: 0.5896\n",
            "Epoch 260/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2984 - accuracy: 0.8598 - sensitivity_at_specificity: 0.9794 - specificity_at_sensitivity: 0.9961 - recall: 0.8502 - precision: 0.8632\n",
            "Epoch 260: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.2984 - accuracy: 0.8598 - sensitivity_at_specificity: 0.9794 - specificity_at_sensitivity: 0.9961 - recall: 0.8502 - precision: 0.8632 - val_loss: 0.9600 - val_accuracy: 0.6422 - val_sensitivity_at_specificity: 0.7972 - val_specificity_at_sensitivity: 0.7655 - val_recall: 0.8302 - val_precision: 0.6014\n",
            "Epoch 261/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2895 - accuracy: 0.8676 - sensitivity_at_specificity: 0.9857 - specificity_at_sensitivity: 0.9962 - recall: 0.8457 - precision: 0.8800\n",
            "Epoch 261: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.2895 - accuracy: 0.8676 - sensitivity_at_specificity: 0.9857 - specificity_at_sensitivity: 0.9962 - recall: 0.8457 - precision: 0.8800 - val_loss: 0.9743 - val_accuracy: 0.6492 - val_sensitivity_at_specificity: 0.8038 - val_specificity_at_sensitivity: 0.7917 - val_recall: 0.8134 - val_precision: 0.6057\n",
            "Epoch 262/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3064 - accuracy: 0.8625 - sensitivity_at_specificity: 0.9831 - specificity_at_sensitivity: 0.9962 - recall: 0.8459 - precision: 0.8682\n",
            "Epoch 262: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.3064 - accuracy: 0.8625 - sensitivity_at_specificity: 0.9831 - specificity_at_sensitivity: 0.9962 - recall: 0.8459 - precision: 0.8682 - val_loss: 0.9484 - val_accuracy: 0.6336 - val_sensitivity_at_specificity: 0.8156 - val_specificity_at_sensitivity: 0.7680 - val_recall: 0.8633 - val_precision: 0.5864\n",
            "Epoch 263/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3069 - accuracy: 0.8586 - sensitivity_at_specificity: 0.9837 - specificity_at_sensitivity: 0.9984 - recall: 0.8498 - precision: 0.8673\n",
            "Epoch 263: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.3069 - accuracy: 0.8586 - sensitivity_at_specificity: 0.9837 - specificity_at_sensitivity: 0.9984 - recall: 0.8498 - precision: 0.8673 - val_loss: 0.9937 - val_accuracy: 0.6539 - val_sensitivity_at_specificity: 0.7855 - val_specificity_at_sensitivity: 0.7589 - val_recall: 0.8610 - val_precision: 0.6189\n",
            "Epoch 264/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2938 - accuracy: 0.8715 - sensitivity_at_specificity: 0.9792 - specificity_at_sensitivity: 0.9960 - recall: 0.8565 - precision: 0.8859\n",
            "Epoch 264: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.2938 - accuracy: 0.8715 - sensitivity_at_specificity: 0.9792 - specificity_at_sensitivity: 0.9960 - recall: 0.8565 - precision: 0.8859 - val_loss: 1.0101 - val_accuracy: 0.6328 - val_sensitivity_at_specificity: 0.7881 - val_specificity_at_sensitivity: 0.7489 - val_recall: 0.8475 - val_precision: 0.5847\n",
            "Epoch 265/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2979 - accuracy: 0.8711 - sensitivity_at_specificity: 0.9820 - specificity_at_sensitivity: 0.9945 - recall: 0.8582 - precision: 0.8802\n",
            "Epoch 265: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.2979 - accuracy: 0.8711 - sensitivity_at_specificity: 0.9820 - specificity_at_sensitivity: 0.9945 - recall: 0.8582 - precision: 0.8802 - val_loss: 0.9276 - val_accuracy: 0.6680 - val_sensitivity_at_specificity: 0.8578 - val_specificity_at_sensitivity: 0.7875 - val_recall: 0.8722 - val_precision: 0.6128\n",
            "Epoch 266/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2926 - accuracy: 0.8730 - sensitivity_at_specificity: 0.9833 - specificity_at_sensitivity: 0.9985 - recall: 0.8503 - precision: 0.8863\n",
            "Epoch 266: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 196ms/step - loss: 0.2926 - accuracy: 0.8730 - sensitivity_at_specificity: 0.9833 - specificity_at_sensitivity: 0.9985 - recall: 0.8503 - precision: 0.8863 - val_loss: 1.0079 - val_accuracy: 0.6453 - val_sensitivity_at_specificity: 0.7848 - val_specificity_at_sensitivity: 0.7539 - val_recall: 0.8050 - val_precision: 0.6132\n",
            "Epoch 267/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2924 - accuracy: 0.8727 - sensitivity_at_specificity: 0.9867 - specificity_at_sensitivity: 0.9930 - recall: 0.8519 - precision: 0.8893\n",
            "Epoch 267: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 198ms/step - loss: 0.2924 - accuracy: 0.8727 - sensitivity_at_specificity: 0.9867 - specificity_at_sensitivity: 0.9930 - recall: 0.8519 - precision: 0.8893 - val_loss: 1.0447 - val_accuracy: 0.6336 - val_sensitivity_at_specificity: 0.7950 - val_specificity_at_sensitivity: 0.7461 - val_recall: 0.8691 - val_precision: 0.5880\n",
            "Epoch 268/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2916 - accuracy: 0.8734 - sensitivity_at_specificity: 0.9815 - specificity_at_sensitivity: 0.9970 - recall: 0.8565 - precision: 0.8791\n",
            "Epoch 268: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.2916 - accuracy: 0.8734 - sensitivity_at_specificity: 0.9815 - specificity_at_sensitivity: 0.9970 - recall: 0.8565 - precision: 0.8791 - val_loss: 1.1104 - val_accuracy: 0.6359 - val_sensitivity_at_specificity: 0.7773 - val_specificity_at_sensitivity: 0.7295 - val_recall: 0.8515 - val_precision: 0.5917\n",
            "Epoch 269/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2769 - accuracy: 0.8848 - sensitivity_at_specificity: 0.9835 - specificity_at_sensitivity: 0.9992 - recall: 0.8686 - precision: 0.8961\n",
            "Epoch 269: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.2769 - accuracy: 0.8848 - sensitivity_at_specificity: 0.9835 - specificity_at_sensitivity: 0.9992 - recall: 0.8686 - precision: 0.8961 - val_loss: 0.9993 - val_accuracy: 0.6617 - val_sensitivity_at_specificity: 0.8357 - val_specificity_at_sensitivity: 0.7972 - val_recall: 0.9124 - val_precision: 0.6073\n",
            "Epoch 270/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2933 - accuracy: 0.8777 - sensitivity_at_specificity: 0.9814 - specificity_at_sensitivity: 0.9953 - recall: 0.8712 - precision: 0.8843\n",
            "Epoch 270: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.2933 - accuracy: 0.8777 - sensitivity_at_specificity: 0.9814 - specificity_at_sensitivity: 0.9953 - recall: 0.8712 - precision: 0.8843 - val_loss: 1.0552 - val_accuracy: 0.6250 - val_sensitivity_at_specificity: 0.7840 - val_specificity_at_sensitivity: 0.7913 - val_recall: 0.8746 - val_precision: 0.5932\n",
            "Epoch 271/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2838 - accuracy: 0.8742 - sensitivity_at_specificity: 0.9844 - specificity_at_sensitivity: 0.9976 - recall: 0.8654 - precision: 0.8818\n",
            "Epoch 271: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.2838 - accuracy: 0.8742 - sensitivity_at_specificity: 0.9844 - specificity_at_sensitivity: 0.9976 - recall: 0.8654 - precision: 0.8818 - val_loss: 1.0122 - val_accuracy: 0.6734 - val_sensitivity_at_specificity: 0.8737 - val_specificity_at_sensitivity: 0.8049 - val_recall: 0.9173 - val_precision: 0.6269\n",
            "Epoch 272/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2789 - accuracy: 0.8766 - sensitivity_at_specificity: 0.9804 - specificity_at_sensitivity: 0.9978 - recall: 0.8414 - precision: 0.8940\n",
            "Epoch 272: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.2789 - accuracy: 0.8766 - sensitivity_at_specificity: 0.9804 - specificity_at_sensitivity: 0.9978 - recall: 0.8414 - precision: 0.8940 - val_loss: 1.0866 - val_accuracy: 0.6508 - val_sensitivity_at_specificity: 0.7997 - val_specificity_at_sensitivity: 0.7878 - val_recall: 0.8951 - val_precision: 0.6008\n",
            "Epoch 273/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2623 - accuracy: 0.8918 - sensitivity_at_specificity: 0.9876 - specificity_at_sensitivity: 0.9992 - recall: 0.8818 - precision: 0.9020\n",
            "Epoch 273: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.2623 - accuracy: 0.8918 - sensitivity_at_specificity: 0.9876 - specificity_at_sensitivity: 0.9992 - recall: 0.8818 - precision: 0.9020 - val_loss: 1.1065 - val_accuracy: 0.6445 - val_sensitivity_at_specificity: 0.8053 - val_specificity_at_sensitivity: 0.7867 - val_recall: 0.9104 - val_precision: 0.5974\n",
            "Epoch 274/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2639 - accuracy: 0.8863 - sensitivity_at_specificity: 0.9885 - specificity_at_sensitivity: 0.9968 - recall: 0.8752 - precision: 0.8993\n",
            "Epoch 274: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.2639 - accuracy: 0.8863 - sensitivity_at_specificity: 0.9885 - specificity_at_sensitivity: 0.9968 - recall: 0.8752 - precision: 0.8993 - val_loss: 1.1223 - val_accuracy: 0.6313 - val_sensitivity_at_specificity: 0.7953 - val_specificity_at_sensitivity: 0.7488 - val_recall: 0.8787 - val_precision: 0.5855\n",
            "Epoch 275/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2576 - accuracy: 0.8879 - sensitivity_at_specificity: 0.9886 - specificity_at_sensitivity: 0.9992 - recall: 0.8818 - precision: 0.8988\n",
            "Epoch 275: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.2576 - accuracy: 0.8879 - sensitivity_at_specificity: 0.9886 - specificity_at_sensitivity: 0.9992 - recall: 0.8818 - precision: 0.8988 - val_loss: 1.0397 - val_accuracy: 0.6508 - val_sensitivity_at_specificity: 0.8047 - val_specificity_at_sensitivity: 0.7953 - val_recall: 0.8453 - val_precision: 0.6085\n",
            "Epoch 276/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2979 - accuracy: 0.8738 - sensitivity_at_specificity: 0.9782 - specificity_at_sensitivity: 0.9976 - recall: 0.8551 - precision: 0.8891\n",
            "Epoch 276: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.2979 - accuracy: 0.8738 - sensitivity_at_specificity: 0.9782 - specificity_at_sensitivity: 0.9976 - recall: 0.8551 - precision: 0.8891 - val_loss: 1.0835 - val_accuracy: 0.6281 - val_sensitivity_at_specificity: 0.7515 - val_specificity_at_sensitivity: 0.7834 - val_recall: 0.8804 - val_precision: 0.5905\n",
            "Epoch 277/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2771 - accuracy: 0.8773 - sensitivity_at_specificity: 0.9859 - specificity_at_sensitivity: 1.0000 - recall: 0.8596 - precision: 0.8903\n",
            "Epoch 277: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.2771 - accuracy: 0.8773 - sensitivity_at_specificity: 0.9859 - specificity_at_sensitivity: 1.0000 - recall: 0.8596 - precision: 0.8903 - val_loss: 1.0609 - val_accuracy: 0.6406 - val_sensitivity_at_specificity: 0.7953 - val_specificity_at_sensitivity: 0.7843 - val_recall: 0.8977 - val_precision: 0.5951\n",
            "Epoch 278/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2822 - accuracy: 0.8777 - sensitivity_at_specificity: 0.9874 - specificity_at_sensitivity: 0.9953 - recall: 0.8665 - precision: 0.8852\n",
            "Epoch 278: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.2822 - accuracy: 0.8777 - sensitivity_at_specificity: 0.9874 - specificity_at_sensitivity: 0.9953 - recall: 0.8665 - precision: 0.8852 - val_loss: 1.1018 - val_accuracy: 0.6398 - val_sensitivity_at_specificity: 0.8086 - val_specificity_at_sensitivity: 0.7927 - val_recall: 0.8951 - val_precision: 0.5961\n",
            "Epoch 279/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2741 - accuracy: 0.8858 - sensitivity_at_specificity: 0.9859 - specificity_at_sensitivity: 0.9958 - recall: 0.8754 - precision: 0.8940\n",
            "Epoch 279: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.2741 - accuracy: 0.8858 - sensitivity_at_specificity: 0.9859 - specificity_at_sensitivity: 0.9958 - recall: 0.8754 - precision: 0.8940 - val_loss: 1.0579 - val_accuracy: 0.6359 - val_sensitivity_at_specificity: 0.8141 - val_specificity_at_sensitivity: 0.7766 - val_recall: 0.8625 - val_precision: 0.5935\n",
            "Epoch 280/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2709 - accuracy: 0.8813 - sensitivity_at_specificity: 0.9866 - specificity_at_sensitivity: 0.9983 - recall: 0.8858 - precision: 0.8884\n",
            "Epoch 280: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.2709 - accuracy: 0.8813 - sensitivity_at_specificity: 0.9866 - specificity_at_sensitivity: 0.9983 - recall: 0.8858 - precision: 0.8884 - val_loss: 0.9527 - val_accuracy: 0.6539 - val_sensitivity_at_specificity: 0.8090 - val_specificity_at_sensitivity: 0.7972 - val_recall: 0.8463 - val_precision: 0.6130\n",
            "Epoch 281/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2664 - accuracy: 0.8926 - sensitivity_at_specificity: 0.9835 - specificity_at_sensitivity: 0.9977 - recall: 0.8724 - precision: 0.9075\n",
            "Epoch 281: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.2664 - accuracy: 0.8926 - sensitivity_at_specificity: 0.9835 - specificity_at_sensitivity: 0.9977 - recall: 0.8724 - precision: 0.9075 - val_loss: 0.9417 - val_accuracy: 0.6438 - val_sensitivity_at_specificity: 0.7950 - val_specificity_at_sensitivity: 0.7925 - val_recall: 0.8216 - val_precision: 0.6055\n",
            "Epoch 282/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2636 - accuracy: 0.8895 - sensitivity_at_specificity: 0.9884 - specificity_at_sensitivity: 0.9976 - recall: 0.8824 - precision: 0.8969\n",
            "Epoch 282: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.2636 - accuracy: 0.8895 - sensitivity_at_specificity: 0.9884 - specificity_at_sensitivity: 0.9976 - recall: 0.8824 - precision: 0.8969 - val_loss: 1.1359 - val_accuracy: 0.6273 - val_sensitivity_at_specificity: 0.7898 - val_specificity_at_sensitivity: 0.7812 - val_recall: 0.8712 - val_precision: 0.5617\n",
            "Epoch 283/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2712 - accuracy: 0.8820 - sensitivity_at_specificity: 0.9782 - specificity_at_sensitivity: 1.0000 - recall: 0.8663 - precision: 0.8955\n",
            "Epoch 283: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.2712 - accuracy: 0.8820 - sensitivity_at_specificity: 0.9782 - specificity_at_sensitivity: 1.0000 - recall: 0.8663 - precision: 0.8955 - val_loss: 1.0682 - val_accuracy: 0.6406 - val_sensitivity_at_specificity: 0.8248 - val_specificity_at_sensitivity: 0.7791 - val_recall: 0.8885 - val_precision: 0.5886\n",
            "Epoch 284/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2512 - accuracy: 0.8902 - sensitivity_at_specificity: 0.9924 - specificity_at_sensitivity: 0.9968 - recall: 0.8841 - precision: 0.8999\n",
            "Epoch 284: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.2512 - accuracy: 0.8902 - sensitivity_at_specificity: 0.9924 - specificity_at_sensitivity: 0.9968 - recall: 0.8841 - precision: 0.8999 - val_loss: 1.1438 - val_accuracy: 0.6469 - val_sensitivity_at_specificity: 0.8000 - val_specificity_at_sensitivity: 0.7766 - val_recall: 0.8938 - val_precision: 0.5983\n",
            "Epoch 285/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2650 - accuracy: 0.8918 - sensitivity_at_specificity: 0.9842 - specificity_at_sensitivity: 0.9977 - recall: 0.8791 - precision: 0.8998\n",
            "Epoch 285: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.2650 - accuracy: 0.8918 - sensitivity_at_specificity: 0.9842 - specificity_at_sensitivity: 0.9977 - recall: 0.8791 - precision: 0.8998 - val_loss: 1.0650 - val_accuracy: 0.6477 - val_sensitivity_at_specificity: 0.8351 - val_specificity_at_sensitivity: 0.7956 - val_recall: 0.8752 - val_precision: 0.6055\n",
            "Epoch 286/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2581 - accuracy: 0.8859 - sensitivity_at_specificity: 0.9840 - specificity_at_sensitivity: 0.9985 - recall: 0.8729 - precision: 0.8914\n",
            "Epoch 286: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.2581 - accuracy: 0.8859 - sensitivity_at_specificity: 0.9840 - specificity_at_sensitivity: 0.9985 - recall: 0.8729 - precision: 0.8914 - val_loss: 1.0881 - val_accuracy: 0.6586 - val_sensitivity_at_specificity: 0.8299 - val_specificity_at_sensitivity: 0.7876 - val_recall: 0.8504 - val_precision: 0.6122\n",
            "Epoch 287/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2623 - accuracy: 0.8895 - sensitivity_at_specificity: 0.9877 - specificity_at_sensitivity: 0.9976 - recall: 0.8740 - precision: 0.9053\n",
            "Epoch 287: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.2623 - accuracy: 0.8895 - sensitivity_at_specificity: 0.9877 - specificity_at_sensitivity: 0.9976 - recall: 0.8740 - precision: 0.9053 - val_loss: 0.9057 - val_accuracy: 0.6695 - val_sensitivity_at_specificity: 0.8433 - val_specificity_at_sensitivity: 0.8271 - val_recall: 0.8495 - val_precision: 0.6237\n",
            "Epoch 288/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2284 - accuracy: 0.9043 - sensitivity_at_specificity: 0.9898 - specificity_at_sensitivity: 0.9977 - recall: 0.8917 - precision: 0.9139\n",
            "Epoch 288: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.2284 - accuracy: 0.9043 - sensitivity_at_specificity: 0.9898 - specificity_at_sensitivity: 0.9977 - recall: 0.8917 - precision: 0.9139 - val_loss: 1.0425 - val_accuracy: 0.6539 - val_sensitivity_at_specificity: 0.7893 - val_specificity_at_sensitivity: 0.7392 - val_recall: 0.8458 - val_precision: 0.6183\n",
            "Epoch 289/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2557 - accuracy: 0.8871 - sensitivity_at_specificity: 0.9885 - specificity_at_sensitivity: 0.9976 - recall: 0.8777 - precision: 0.8977\n",
            "Epoch 289: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.2557 - accuracy: 0.8871 - sensitivity_at_specificity: 0.9885 - specificity_at_sensitivity: 0.9976 - recall: 0.8777 - precision: 0.8977 - val_loss: 1.0914 - val_accuracy: 0.6336 - val_sensitivity_at_specificity: 0.8366 - val_specificity_at_sensitivity: 0.7982 - val_recall: 0.8845 - val_precision: 0.5733\n",
            "Epoch 290/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2375 - accuracy: 0.8984 - sensitivity_at_specificity: 0.9932 - specificity_at_sensitivity: 0.9968 - recall: 0.8878 - precision: 0.9140\n",
            "Epoch 290: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.2375 - accuracy: 0.8984 - sensitivity_at_specificity: 0.9932 - specificity_at_sensitivity: 0.9968 - recall: 0.8878 - precision: 0.9140 - val_loss: 1.0449 - val_accuracy: 0.6422 - val_sensitivity_at_specificity: 0.7800 - val_specificity_at_sensitivity: 0.7571 - val_recall: 0.8369 - val_precision: 0.6071\n",
            "Epoch 291/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2379 - accuracy: 0.9070 - sensitivity_at_specificity: 0.9834 - specificity_at_sensitivity: 0.9992 - recall: 0.8970 - precision: 0.9129\n",
            "Epoch 291: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.2379 - accuracy: 0.9070 - sensitivity_at_specificity: 0.9834 - specificity_at_sensitivity: 0.9992 - recall: 0.8970 - precision: 0.9129 - val_loss: 1.1881 - val_accuracy: 0.6367 - val_sensitivity_at_specificity: 0.7822 - val_specificity_at_sensitivity: 0.7696 - val_recall: 0.8839 - val_precision: 0.5865\n",
            "Epoch 292/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2515 - accuracy: 0.8980 - sensitivity_at_specificity: 0.9873 - specificity_at_sensitivity: 0.9969 - recall: 0.8789 - precision: 0.9113\n",
            "Epoch 292: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.2515 - accuracy: 0.8980 - sensitivity_at_specificity: 0.9873 - specificity_at_sensitivity: 0.9969 - recall: 0.8789 - precision: 0.9113 - val_loss: 1.3248 - val_accuracy: 0.6352 - val_sensitivity_at_specificity: 0.7765 - val_specificity_at_sensitivity: 0.7458 - val_recall: 0.9208 - val_precision: 0.5822\n",
            "Epoch 293/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2326 - accuracy: 0.9059 - sensitivity_at_specificity: 0.9902 - specificity_at_sensitivity: 0.9992 - recall: 0.8955 - precision: 0.9198\n",
            "Epoch 293: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.2326 - accuracy: 0.9059 - sensitivity_at_specificity: 0.9902 - specificity_at_sensitivity: 0.9992 - recall: 0.8955 - precision: 0.9198 - val_loss: 1.3497 - val_accuracy: 0.6258 - val_sensitivity_at_specificity: 0.7950 - val_specificity_at_sensitivity: 0.7343 - val_recall: 0.9270 - val_precision: 0.5802\n",
            "Epoch 294/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2542 - accuracy: 0.8867 - sensitivity_at_specificity: 0.9888 - specificity_at_sensitivity: 0.9992 - recall: 0.8668 - precision: 0.8983\n",
            "Epoch 294: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.2542 - accuracy: 0.8867 - sensitivity_at_specificity: 0.9888 - specificity_at_sensitivity: 0.9992 - recall: 0.8668 - precision: 0.8983 - val_loss: 1.2480 - val_accuracy: 0.6305 - val_sensitivity_at_specificity: 0.7855 - val_specificity_at_sensitivity: 0.7430 - val_recall: 0.9085 - val_precision: 0.5812\n",
            "Epoch 295/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2419 - accuracy: 0.8934 - sensitivity_at_specificity: 0.9929 - specificity_at_sensitivity: 1.0000 - recall: 0.8836 - precision: 0.8998\n",
            "Epoch 295: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.2419 - accuracy: 0.8934 - sensitivity_at_specificity: 0.9929 - specificity_at_sensitivity: 1.0000 - recall: 0.8836 - precision: 0.8998 - val_loss: 1.1348 - val_accuracy: 0.6391 - val_sensitivity_at_specificity: 0.7879 - val_specificity_at_sensitivity: 0.7571 - val_recall: 0.8607 - val_precision: 0.5991\n",
            "Epoch 296/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2547 - accuracy: 0.8852 - sensitivity_at_specificity: 0.9898 - specificity_at_sensitivity: 0.9977 - recall: 0.8766 - precision: 0.8906\n",
            "Epoch 296: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.2547 - accuracy: 0.8852 - sensitivity_at_specificity: 0.9898 - specificity_at_sensitivity: 0.9977 - recall: 0.8766 - precision: 0.8906 - val_loss: 1.0866 - val_accuracy: 0.6406 - val_sensitivity_at_specificity: 0.8222 - val_specificity_at_sensitivity: 0.7826 - val_recall: 0.8369 - val_precision: 0.5876\n",
            "Epoch 297/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2500 - accuracy: 0.8977 - sensitivity_at_specificity: 0.9895 - specificity_at_sensitivity: 0.9967 - recall: 0.8923 - precision: 0.9100\n",
            "Epoch 297: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.2500 - accuracy: 0.8977 - sensitivity_at_specificity: 0.9895 - specificity_at_sensitivity: 0.9967 - recall: 0.8923 - precision: 0.9100 - val_loss: 1.1234 - val_accuracy: 0.6562 - val_sensitivity_at_specificity: 0.8333 - val_specificity_at_sensitivity: 0.7606 - val_recall: 0.8904 - val_precision: 0.6177\n",
            "Epoch 298/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2389 - accuracy: 0.8977 - sensitivity_at_specificity: 0.9929 - specificity_at_sensitivity: 0.9992 - recall: 0.8785 - precision: 0.9103\n",
            "Epoch 298: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.2389 - accuracy: 0.8977 - sensitivity_at_specificity: 0.9929 - specificity_at_sensitivity: 0.9992 - recall: 0.8785 - precision: 0.9103 - val_loss: 1.1810 - val_accuracy: 0.6555 - val_sensitivity_at_specificity: 0.8304 - val_specificity_at_sensitivity: 0.7695 - val_recall: 0.9008 - val_precision: 0.5977\n",
            "Epoch 299/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2610 - accuracy: 0.8906 - sensitivity_at_specificity: 0.9835 - specificity_at_sensitivity: 0.9984 - recall: 0.8742 - precision: 0.9026\n",
            "Epoch 299: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.2610 - accuracy: 0.8906 - sensitivity_at_specificity: 0.9835 - specificity_at_sensitivity: 0.9984 - recall: 0.8742 - precision: 0.9026 - val_loss: 0.9453 - val_accuracy: 0.6367 - val_sensitivity_at_specificity: 0.7584 - val_specificity_at_sensitivity: 0.7774 - val_recall: 0.8574 - val_precision: 0.6161\n",
            "Epoch 300/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2379 - accuracy: 0.8984 - sensitivity_at_specificity: 0.9899 - specificity_at_sensitivity: 0.9984 - recall: 0.8923 - precision: 0.9036\n",
            "Epoch 300: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.2379 - accuracy: 0.8984 - sensitivity_at_specificity: 0.9899 - specificity_at_sensitivity: 0.9984 - recall: 0.8923 - precision: 0.9036 - val_loss: 1.2234 - val_accuracy: 0.6453 - val_sensitivity_at_specificity: 0.7785 - val_specificity_at_sensitivity: 0.7444 - val_recall: 0.8585 - val_precision: 0.6065\n",
            "Epoch 301/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2592 - accuracy: 0.8902 - sensitivity_at_specificity: 0.9883 - specificity_at_sensitivity: 0.9992 - recall: 0.8732 - precision: 0.9048\n",
            "Epoch 301: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 185ms/step - loss: 0.2592 - accuracy: 0.8902 - sensitivity_at_specificity: 0.9883 - specificity_at_sensitivity: 0.9992 - recall: 0.8732 - precision: 0.9048 - val_loss: 1.0676 - val_accuracy: 0.6445 - val_sensitivity_at_specificity: 0.8092 - val_specificity_at_sensitivity: 0.7937 - val_recall: 0.8800 - val_precision: 0.6027\n",
            "Epoch 302/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2630 - accuracy: 0.8867 - sensitivity_at_specificity: 0.9856 - specificity_at_sensitivity: 0.9977 - recall: 0.8771 - precision: 0.8899\n",
            "Epoch 302: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.2630 - accuracy: 0.8867 - sensitivity_at_specificity: 0.9856 - specificity_at_sensitivity: 0.9977 - recall: 0.8771 - precision: 0.8899 - val_loss: 0.9499 - val_accuracy: 0.6773 - val_sensitivity_at_specificity: 0.8396 - val_specificity_at_sensitivity: 0.8013 - val_recall: 0.8351 - val_precision: 0.6449\n",
            "Epoch 303/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2790 - accuracy: 0.8676 - sensitivity_at_specificity: 0.9874 - specificity_at_sensitivity: 1.0000 - recall: 0.8493 - precision: 0.8791\n",
            "Epoch 303: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.2790 - accuracy: 0.8676 - sensitivity_at_specificity: 0.9874 - specificity_at_sensitivity: 1.0000 - recall: 0.8493 - precision: 0.8791 - val_loss: 1.0055 - val_accuracy: 0.6422 - val_sensitivity_at_specificity: 0.8307 - val_specificity_at_sensitivity: 0.7654 - val_recall: 0.8908 - val_precision: 0.5914\n",
            "Epoch 304/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2366 - accuracy: 0.9047 - sensitivity_at_specificity: 0.9897 - specificity_at_sensitivity: 1.0000 - recall: 0.8926 - precision: 0.9128\n",
            "Epoch 304: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.2366 - accuracy: 0.9047 - sensitivity_at_specificity: 0.9897 - specificity_at_sensitivity: 1.0000 - recall: 0.8926 - precision: 0.9128 - val_loss: 1.2111 - val_accuracy: 0.6133 - val_sensitivity_at_specificity: 0.7636 - val_specificity_at_sensitivity: 0.7752 - val_recall: 0.8738 - val_precision: 0.5680\n",
            "Epoch 305/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2275 - accuracy: 0.9066 - sensitivity_at_specificity: 0.9920 - specificity_at_sensitivity: 0.9992 - recall: 0.8907 - precision: 0.9163\n",
            "Epoch 305: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.2275 - accuracy: 0.9066 - sensitivity_at_specificity: 0.9920 - specificity_at_sensitivity: 0.9992 - recall: 0.8907 - precision: 0.9163 - val_loss: 1.2415 - val_accuracy: 0.6500 - val_sensitivity_at_specificity: 0.8220 - val_specificity_at_sensitivity: 0.7697 - val_recall: 0.9226 - val_precision: 0.5996\n",
            "Epoch 306/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2230 - accuracy: 0.9099 - sensitivity_at_specificity: 0.9902 - specificity_at_sensitivity: 0.9992 - recall: 0.8966 - precision: 0.9231\n",
            "Epoch 306: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.2230 - accuracy: 0.9099 - sensitivity_at_specificity: 0.9902 - specificity_at_sensitivity: 0.9992 - recall: 0.8966 - precision: 0.9231 - val_loss: 1.3028 - val_accuracy: 0.6367 - val_sensitivity_at_specificity: 0.8299 - val_specificity_at_sensitivity: 0.7702 - val_recall: 0.9230 - val_precision: 0.5796\n",
            "Epoch 307/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2201 - accuracy: 0.9109 - sensitivity_at_specificity: 0.9915 - specificity_at_sensitivity: 0.9992 - recall: 0.8982 - precision: 0.9226\n",
            "Epoch 307: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.2201 - accuracy: 0.9109 - sensitivity_at_specificity: 0.9915 - specificity_at_sensitivity: 0.9992 - recall: 0.8982 - precision: 0.9226 - val_loss: 1.1444 - val_accuracy: 0.6297 - val_sensitivity_at_specificity: 0.7937 - val_specificity_at_sensitivity: 0.7672 - val_recall: 0.8891 - val_precision: 0.5854\n",
            "Epoch 308/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2340 - accuracy: 0.9004 - sensitivity_at_specificity: 0.9913 - specificity_at_sensitivity: 0.9992 - recall: 0.8899 - precision: 0.9064\n",
            "Epoch 308: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.2340 - accuracy: 0.9004 - sensitivity_at_specificity: 0.9913 - specificity_at_sensitivity: 0.9992 - recall: 0.8899 - precision: 0.9064 - val_loss: 1.3969 - val_accuracy: 0.6320 - val_sensitivity_at_specificity: 0.7868 - val_specificity_at_sensitivity: 0.7368 - val_recall: 0.9201 - val_precision: 0.5829\n",
            "Epoch 309/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2241 - accuracy: 0.9129 - sensitivity_at_specificity: 0.9898 - specificity_at_sensitivity: 0.9984 - recall: 0.9001 - precision: 0.9226\n",
            "Epoch 309: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.2241 - accuracy: 0.9129 - sensitivity_at_specificity: 0.9898 - specificity_at_sensitivity: 0.9984 - recall: 0.9001 - precision: 0.9226 - val_loss: 1.2829 - val_accuracy: 0.6273 - val_sensitivity_at_specificity: 0.7733 - val_specificity_at_sensitivity: 0.7783 - val_recall: 0.8432 - val_precision: 0.5909\n",
            "Epoch 310/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2218 - accuracy: 0.9109 - sensitivity_at_specificity: 0.9901 - specificity_at_sensitivity: 0.9992 - recall: 0.8970 - precision: 0.9267\n",
            "Epoch 310: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.2218 - accuracy: 0.9109 - sensitivity_at_specificity: 0.9901 - specificity_at_sensitivity: 0.9992 - recall: 0.8970 - precision: 0.9267 - val_loss: 1.2485 - val_accuracy: 0.6484 - val_sensitivity_at_specificity: 0.8031 - val_specificity_at_sensitivity: 0.7559 - val_recall: 0.8868 - val_precision: 0.6027\n",
            "Epoch 311/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2222 - accuracy: 0.9027 - sensitivity_at_specificity: 0.9929 - specificity_at_sensitivity: 1.0000 - recall: 0.8959 - precision: 0.9066\n",
            "Epoch 311: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.2222 - accuracy: 0.9027 - sensitivity_at_specificity: 0.9929 - specificity_at_sensitivity: 1.0000 - recall: 0.8959 - precision: 0.9066 - val_loss: 1.3668 - val_accuracy: 0.6445 - val_sensitivity_at_specificity: 0.7869 - val_specificity_at_sensitivity: 0.7331 - val_recall: 0.9036 - val_precision: 0.5965\n",
            "Epoch 312/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2348 - accuracy: 0.9055 - sensitivity_at_specificity: 0.9911 - specificity_at_sensitivity: 1.0000 - recall: 0.8958 - precision: 0.9219\n",
            "Epoch 312: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.2348 - accuracy: 0.9055 - sensitivity_at_specificity: 0.9911 - specificity_at_sensitivity: 1.0000 - recall: 0.8958 - precision: 0.9219 - val_loss: 1.3905 - val_accuracy: 0.6117 - val_sensitivity_at_specificity: 0.7928 - val_specificity_at_sensitivity: 0.7571 - val_recall: 0.9315 - val_precision: 0.5565\n",
            "Epoch 313/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2274 - accuracy: 0.9102 - sensitivity_at_specificity: 0.9908 - specificity_at_sensitivity: 1.0000 - recall: 0.8984 - precision: 0.9225\n",
            "Epoch 313: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.2274 - accuracy: 0.9102 - sensitivity_at_specificity: 0.9908 - specificity_at_sensitivity: 1.0000 - recall: 0.8984 - precision: 0.9225 - val_loss: 1.3352 - val_accuracy: 0.6187 - val_sensitivity_at_specificity: 0.7906 - val_specificity_at_sensitivity: 0.7500 - val_recall: 0.9219 - val_precision: 0.5739\n",
            "Epoch 314/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2188 - accuracy: 0.9102 - sensitivity_at_specificity: 0.9911 - specificity_at_sensitivity: 0.9985 - recall: 0.8925 - precision: 0.9192\n",
            "Epoch 314: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.2188 - accuracy: 0.9102 - sensitivity_at_specificity: 0.9911 - specificity_at_sensitivity: 0.9985 - recall: 0.8925 - precision: 0.9192 - val_loss: 1.1916 - val_accuracy: 0.6555 - val_sensitivity_at_specificity: 0.8141 - val_specificity_at_sensitivity: 0.7806 - val_recall: 0.9094 - val_precision: 0.6078\n",
            "Epoch 315/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2174 - accuracy: 0.9082 - sensitivity_at_specificity: 0.9921 - specificity_at_sensitivity: 1.0000 - recall: 0.8915 - precision: 0.9212\n",
            "Epoch 315: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.2174 - accuracy: 0.9082 - sensitivity_at_specificity: 0.9921 - specificity_at_sensitivity: 1.0000 - recall: 0.8915 - precision: 0.9212 - val_loss: 1.2683 - val_accuracy: 0.6562 - val_sensitivity_at_specificity: 0.8269 - val_specificity_at_sensitivity: 0.7729 - val_recall: 0.9071 - val_precision: 0.5970\n",
            "Epoch 316/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2231 - accuracy: 0.9086 - sensitivity_at_specificity: 0.9955 - specificity_at_sensitivity: 1.0000 - recall: 0.9004 - precision: 0.9212\n",
            "Epoch 316: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.2231 - accuracy: 0.9086 - sensitivity_at_specificity: 0.9955 - specificity_at_sensitivity: 1.0000 - recall: 0.9004 - precision: 0.9212 - val_loss: 1.2988 - val_accuracy: 0.6438 - val_sensitivity_at_specificity: 0.7820 - val_specificity_at_sensitivity: 0.7724 - val_recall: 0.9268 - val_precision: 0.5984\n",
            "Epoch 317/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2295 - accuracy: 0.9047 - sensitivity_at_specificity: 0.9899 - specificity_at_sensitivity: 0.9992 - recall: 0.8915 - precision: 0.9171\n",
            "Epoch 317: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 175ms/step - loss: 0.2295 - accuracy: 0.9047 - sensitivity_at_specificity: 0.9899 - specificity_at_sensitivity: 0.9992 - recall: 0.8915 - precision: 0.9171 - val_loss: 1.4393 - val_accuracy: 0.6094 - val_sensitivity_at_specificity: 0.7500 - val_specificity_at_sensitivity: 0.7394 - val_recall: 0.9290 - val_precision: 0.5581\n",
            "Epoch 318/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2325 - accuracy: 0.9035 - sensitivity_at_specificity: 0.9914 - specificity_at_sensitivity: 0.9969 - recall: 0.8872 - precision: 0.9167\n",
            "Epoch 318: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.2325 - accuracy: 0.9035 - sensitivity_at_specificity: 0.9914 - specificity_at_sensitivity: 0.9969 - recall: 0.8872 - precision: 0.9167 - val_loss: 1.3776 - val_accuracy: 0.6180 - val_sensitivity_at_specificity: 0.7716 - val_specificity_at_sensitivity: 0.7416 - val_recall: 0.9233 - val_precision: 0.5672\n",
            "Epoch 319/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2006 - accuracy: 0.9182 - sensitivity_at_specificity: 0.9919 - specificity_at_sensitivity: 0.9991 - recall: 0.9123 - precision: 0.9266\n",
            "Epoch 319: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.2006 - accuracy: 0.9182 - sensitivity_at_specificity: 0.9919 - specificity_at_sensitivity: 0.9991 - recall: 0.9123 - precision: 0.9266 - val_loss: 1.4058 - val_accuracy: 0.6281 - val_sensitivity_at_specificity: 0.7981 - val_specificity_at_sensitivity: 0.7461 - val_recall: 0.9290 - val_precision: 0.5775\n",
            "Epoch 320/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2015 - accuracy: 0.9164 - sensitivity_at_specificity: 0.9970 - specificity_at_sensitivity: 1.0000 - recall: 0.9023 - precision: 0.9346\n",
            "Epoch 320: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.2015 - accuracy: 0.9164 - sensitivity_at_specificity: 0.9970 - specificity_at_sensitivity: 1.0000 - recall: 0.9023 - precision: 0.9346 - val_loss: 1.3457 - val_accuracy: 0.6375 - val_sensitivity_at_specificity: 0.8149 - val_specificity_at_sensitivity: 0.7708 - val_recall: 0.9471 - val_precision: 0.5861\n",
            "Epoch 321/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2027 - accuracy: 0.9195 - sensitivity_at_specificity: 0.9955 - specificity_at_sensitivity: 0.9992 - recall: 0.9225 - precision: 0.9225\n",
            "Epoch 321: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.2027 - accuracy: 0.9195 - sensitivity_at_specificity: 0.9955 - specificity_at_sensitivity: 0.9992 - recall: 0.9225 - precision: 0.9225 - val_loss: 1.3671 - val_accuracy: 0.6508 - val_sensitivity_at_specificity: 0.8056 - val_specificity_at_sensitivity: 0.7326 - val_recall: 0.8997 - val_precision: 0.6041\n",
            "Epoch 322/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1908 - accuracy: 0.9180 - sensitivity_at_specificity: 0.9976 - specificity_at_sensitivity: 1.0000 - recall: 0.9051 - precision: 0.9271\n",
            "Epoch 322: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 174ms/step - loss: 0.1908 - accuracy: 0.9180 - sensitivity_at_specificity: 0.9976 - specificity_at_sensitivity: 1.0000 - recall: 0.9051 - precision: 0.9271 - val_loss: 1.1542 - val_accuracy: 0.6586 - val_sensitivity_at_specificity: 0.8230 - val_specificity_at_sensitivity: 0.7641 - val_recall: 0.8953 - val_precision: 0.6238\n",
            "Epoch 323/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2043 - accuracy: 0.9184 - sensitivity_at_specificity: 0.9944 - specificity_at_sensitivity: 0.9985 - recall: 0.9174 - precision: 0.9167\n",
            "Epoch 323: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.2043 - accuracy: 0.9184 - sensitivity_at_specificity: 0.9944 - specificity_at_sensitivity: 0.9985 - recall: 0.9174 - precision: 0.9167 - val_loss: 1.3515 - val_accuracy: 0.6281 - val_sensitivity_at_specificity: 0.7762 - val_specificity_at_sensitivity: 0.7314 - val_recall: 0.8760 - val_precision: 0.5769\n",
            "Epoch 324/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1986 - accuracy: 0.9176 - sensitivity_at_specificity: 0.9935 - specificity_at_sensitivity: 0.9985 - recall: 0.8965 - precision: 0.9304\n",
            "Epoch 324: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.1986 - accuracy: 0.9176 - sensitivity_at_specificity: 0.9935 - specificity_at_sensitivity: 0.9985 - recall: 0.8965 - precision: 0.9304 - val_loss: 1.3151 - val_accuracy: 0.6453 - val_sensitivity_at_specificity: 0.8175 - val_specificity_at_sensitivity: 0.7596 - val_recall: 0.9126 - val_precision: 0.5998\n",
            "Epoch 325/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2140 - accuracy: 0.9121 - sensitivity_at_specificity: 0.9930 - specificity_at_sensitivity: 0.9984 - recall: 0.8998 - precision: 0.9222\n",
            "Epoch 325: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 205ms/step - loss: 0.2140 - accuracy: 0.9121 - sensitivity_at_specificity: 0.9930 - specificity_at_sensitivity: 0.9984 - recall: 0.8998 - precision: 0.9222 - val_loss: 1.3310 - val_accuracy: 0.6281 - val_sensitivity_at_specificity: 0.8194 - val_specificity_at_sensitivity: 0.7712 - val_recall: 0.9258 - val_precision: 0.5717\n",
            "Epoch 326/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2094 - accuracy: 0.9145 - sensitivity_at_specificity: 0.9944 - specificity_at_sensitivity: 0.9985 - recall: 0.9040 - precision: 0.9208\n",
            "Epoch 326: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 203ms/step - loss: 0.2094 - accuracy: 0.9145 - sensitivity_at_specificity: 0.9944 - specificity_at_sensitivity: 0.9985 - recall: 0.9040 - precision: 0.9208 - val_loss: 1.3524 - val_accuracy: 0.6320 - val_sensitivity_at_specificity: 0.7902 - val_specificity_at_sensitivity: 0.7786 - val_recall: 0.9148 - val_precision: 0.5817\n",
            "Epoch 327/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2180 - accuracy: 0.9117 - sensitivity_at_specificity: 0.9910 - specificity_at_sensitivity: 0.9992 - recall: 0.9106 - precision: 0.9189\n",
            "Epoch 327: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.2180 - accuracy: 0.9117 - sensitivity_at_specificity: 0.9910 - specificity_at_sensitivity: 0.9992 - recall: 0.9106 - precision: 0.9189 - val_loss: 1.2565 - val_accuracy: 0.6375 - val_sensitivity_at_specificity: 0.8266 - val_specificity_at_sensitivity: 0.7587 - val_recall: 0.9118 - val_precision: 0.5914\n",
            "Epoch 328/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2034 - accuracy: 0.9180 - sensitivity_at_specificity: 0.9946 - specificity_at_sensitivity: 0.9992 - recall: 0.9110 - precision: 0.9266\n",
            "Epoch 328: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.2034 - accuracy: 0.9180 - sensitivity_at_specificity: 0.9946 - specificity_at_sensitivity: 0.9992 - recall: 0.9110 - precision: 0.9266 - val_loss: 1.3900 - val_accuracy: 0.6281 - val_sensitivity_at_specificity: 0.7856 - val_specificity_at_sensitivity: 0.7629 - val_recall: 0.9092 - val_precision: 0.5816\n",
            "Epoch 329/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2017 - accuracy: 0.9178 - sensitivity_at_specificity: 0.9950 - specificity_at_sensitivity: 0.9992 - recall: 0.8983 - precision: 0.9328\n",
            "Epoch 329: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.2017 - accuracy: 0.9178 - sensitivity_at_specificity: 0.9950 - specificity_at_sensitivity: 0.9992 - recall: 0.8983 - precision: 0.9328 - val_loss: 1.3493 - val_accuracy: 0.6195 - val_sensitivity_at_specificity: 0.7593 - val_specificity_at_sensitivity: 0.7013 - val_recall: 0.8991 - val_precision: 0.5784\n",
            "Epoch 330/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2003 - accuracy: 0.9184 - sensitivity_at_specificity: 0.9938 - specificity_at_sensitivity: 0.9992 - recall: 0.9121 - precision: 0.9243\n",
            "Epoch 330: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.2003 - accuracy: 0.9184 - sensitivity_at_specificity: 0.9938 - specificity_at_sensitivity: 0.9992 - recall: 0.9121 - precision: 0.9243 - val_loss: 1.3452 - val_accuracy: 0.6352 - val_sensitivity_at_specificity: 0.7829 - val_specificity_at_sensitivity: 0.7444 - val_recall: 0.8884 - val_precision: 0.5959\n",
            "Epoch 331/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1999 - accuracy: 0.9160 - sensitivity_at_specificity: 0.9937 - specificity_at_sensitivity: 1.0000 - recall: 0.9223 - precision: 0.9101\n",
            "Epoch 331: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.1999 - accuracy: 0.9160 - sensitivity_at_specificity: 0.9937 - specificity_at_sensitivity: 1.0000 - recall: 0.9223 - precision: 0.9101 - val_loss: 1.2688 - val_accuracy: 0.6516 - val_sensitivity_at_specificity: 0.8312 - val_specificity_at_sensitivity: 0.7669 - val_recall: 0.8949 - val_precision: 0.5966\n",
            "Epoch 332/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2239 - accuracy: 0.9094 - sensitivity_at_specificity: 0.9893 - specificity_at_sensitivity: 0.9984 - recall: 0.8959 - precision: 0.9242\n",
            "Epoch 332: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.2239 - accuracy: 0.9094 - sensitivity_at_specificity: 0.9893 - specificity_at_sensitivity: 0.9984 - recall: 0.8959 - precision: 0.9242 - val_loss: 1.1605 - val_accuracy: 0.6578 - val_sensitivity_at_specificity: 0.8277 - val_specificity_at_sensitivity: 0.7556 - val_recall: 0.9062 - val_precision: 0.6097\n",
            "Epoch 333/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1773 - accuracy: 0.9332 - sensitivity_at_specificity: 0.9976 - specificity_at_sensitivity: 1.0000 - recall: 0.9242 - precision: 0.9384\n",
            "Epoch 333: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.1773 - accuracy: 0.9332 - sensitivity_at_specificity: 0.9976 - specificity_at_sensitivity: 1.0000 - recall: 0.9242 - precision: 0.9384 - val_loss: 1.2979 - val_accuracy: 0.6555 - val_sensitivity_at_specificity: 0.8031 - val_specificity_at_sensitivity: 0.7698 - val_recall: 0.9400 - val_precision: 0.6032\n",
            "Epoch 334/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2129 - accuracy: 0.9176 - sensitivity_at_specificity: 0.9908 - specificity_at_sensitivity: 0.9968 - recall: 0.9002 - precision: 0.9354\n",
            "Epoch 334: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.2129 - accuracy: 0.9176 - sensitivity_at_specificity: 0.9908 - specificity_at_sensitivity: 0.9968 - recall: 0.9002 - precision: 0.9354 - val_loss: 1.4889 - val_accuracy: 0.6141 - val_sensitivity_at_specificity: 0.7991 - val_specificity_at_sensitivity: 0.7527 - val_recall: 0.9372 - val_precision: 0.5680\n",
            "Epoch 335/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2063 - accuracy: 0.9152 - sensitivity_at_specificity: 0.9914 - specificity_at_sensitivity: 0.9992 - recall: 0.9075 - precision: 0.9212\n",
            "Epoch 335: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.2063 - accuracy: 0.9152 - sensitivity_at_specificity: 0.9914 - specificity_at_sensitivity: 0.9992 - recall: 0.9075 - precision: 0.9212 - val_loss: 1.3889 - val_accuracy: 0.6422 - val_sensitivity_at_specificity: 0.8435 - val_specificity_at_sensitivity: 0.7584 - val_recall: 0.9169 - val_precision: 0.5857\n",
            "Epoch 336/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1990 - accuracy: 0.9238 - sensitivity_at_specificity: 0.9923 - specificity_at_sensitivity: 1.0000 - recall: 0.9145 - precision: 0.9340\n",
            "Epoch 336: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.1990 - accuracy: 0.9238 - sensitivity_at_specificity: 0.9923 - specificity_at_sensitivity: 1.0000 - recall: 0.9145 - precision: 0.9340 - val_loss: 1.4765 - val_accuracy: 0.6305 - val_sensitivity_at_specificity: 0.7762 - val_specificity_at_sensitivity: 0.7363 - val_recall: 0.8920 - val_precision: 0.5852\n",
            "Epoch 337/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2050 - accuracy: 0.9160 - sensitivity_at_specificity: 0.9902 - specificity_at_sensitivity: 1.0000 - recall: 0.9066 - precision: 0.9297\n",
            "Epoch 337: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.2050 - accuracy: 0.9160 - sensitivity_at_specificity: 0.9902 - specificity_at_sensitivity: 1.0000 - recall: 0.9066 - precision: 0.9297 - val_loss: 1.2240 - val_accuracy: 0.6477 - val_sensitivity_at_specificity: 0.8018 - val_specificity_at_sensitivity: 0.7916 - val_recall: 0.9077 - val_precision: 0.6061\n",
            "Epoch 338/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2079 - accuracy: 0.9164 - sensitivity_at_specificity: 0.9920 - specificity_at_sensitivity: 0.9992 - recall: 0.9079 - precision: 0.9196\n",
            "Epoch 338: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.2079 - accuracy: 0.9164 - sensitivity_at_specificity: 0.9920 - specificity_at_sensitivity: 0.9992 - recall: 0.9079 - precision: 0.9196 - val_loss: 1.4573 - val_accuracy: 0.6180 - val_sensitivity_at_specificity: 0.7997 - val_specificity_at_sensitivity: 0.7337 - val_recall: 0.9073 - val_precision: 0.5586\n",
            "Epoch 339/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1864 - accuracy: 0.9238 - sensitivity_at_specificity: 0.9954 - specificity_at_sensitivity: 1.0000 - recall: 0.9158 - precision: 0.9323\n",
            "Epoch 339: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.1864 - accuracy: 0.9238 - sensitivity_at_specificity: 0.9954 - specificity_at_sensitivity: 1.0000 - recall: 0.9158 - precision: 0.9323 - val_loss: 1.3765 - val_accuracy: 0.6313 - val_sensitivity_at_specificity: 0.8276 - val_specificity_at_sensitivity: 0.7556 - val_recall: 0.9015 - val_precision: 0.5713\n",
            "Epoch 340/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1880 - accuracy: 0.9219 - sensitivity_at_specificity: 0.9941 - specificity_at_sensitivity: 1.0000 - recall: 0.9215 - precision: 0.9298\n",
            "Epoch 340: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.1880 - accuracy: 0.9219 - sensitivity_at_specificity: 0.9941 - specificity_at_sensitivity: 1.0000 - recall: 0.9215 - precision: 0.9298 - val_loss: 1.3848 - val_accuracy: 0.6352 - val_sensitivity_at_specificity: 0.7774 - val_specificity_at_sensitivity: 0.7836 - val_recall: 0.9181 - val_precision: 0.5893\n",
            "Epoch 341/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1932 - accuracy: 0.9215 - sensitivity_at_specificity: 0.9931 - specificity_at_sensitivity: 1.0000 - recall: 0.9115 - precision: 0.9323\n",
            "Epoch 341: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.1932 - accuracy: 0.9215 - sensitivity_at_specificity: 0.9931 - specificity_at_sensitivity: 1.0000 - recall: 0.9115 - precision: 0.9323 - val_loss: 1.3341 - val_accuracy: 0.6367 - val_sensitivity_at_specificity: 0.8245 - val_specificity_at_sensitivity: 0.7804 - val_recall: 0.9091 - val_precision: 0.5876\n",
            "Epoch 342/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1887 - accuracy: 0.9242 - sensitivity_at_specificity: 0.9954 - specificity_at_sensitivity: 1.0000 - recall: 0.9125 - precision: 0.9370\n",
            "Epoch 342: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.1887 - accuracy: 0.9242 - sensitivity_at_specificity: 0.9954 - specificity_at_sensitivity: 1.0000 - recall: 0.9125 - precision: 0.9370 - val_loss: 1.3372 - val_accuracy: 0.6492 - val_sensitivity_at_specificity: 0.7975 - val_specificity_at_sensitivity: 0.7712 - val_recall: 0.9128 - val_precision: 0.5986\n",
            "Epoch 343/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2014 - accuracy: 0.9164 - sensitivity_at_specificity: 0.9921 - specificity_at_sensitivity: 1.0000 - recall: 0.9017 - precision: 0.9280\n",
            "Epoch 343: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 185ms/step - loss: 0.2014 - accuracy: 0.9164 - sensitivity_at_specificity: 0.9921 - specificity_at_sensitivity: 1.0000 - recall: 0.9017 - precision: 0.9280 - val_loss: 1.4846 - val_accuracy: 0.6117 - val_sensitivity_at_specificity: 0.7787 - val_specificity_at_sensitivity: 0.7531 - val_recall: 0.9188 - val_precision: 0.5640\n",
            "Epoch 344/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1880 - accuracy: 0.9301 - sensitivity_at_specificity: 0.9930 - specificity_at_sensitivity: 1.0000 - recall: 0.9122 - precision: 0.9468\n",
            "Epoch 344: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.1880 - accuracy: 0.9301 - sensitivity_at_specificity: 0.9930 - specificity_at_sensitivity: 1.0000 - recall: 0.9122 - precision: 0.9468 - val_loss: 1.4369 - val_accuracy: 0.6406 - val_sensitivity_at_specificity: 0.7918 - val_specificity_at_sensitivity: 0.7299 - val_recall: 0.9331 - val_precision: 0.5961\n",
            "Epoch 345/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1825 - accuracy: 0.9309 - sensitivity_at_specificity: 0.9959 - specificity_at_sensitivity: 1.0000 - recall: 0.9117 - precision: 0.9430\n",
            "Epoch 345: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 184ms/step - loss: 0.1825 - accuracy: 0.9309 - sensitivity_at_specificity: 0.9959 - specificity_at_sensitivity: 1.0000 - recall: 0.9117 - precision: 0.9430 - val_loss: 1.4732 - val_accuracy: 0.6242 - val_sensitivity_at_specificity: 0.7971 - val_specificity_at_sensitivity: 0.7365 - val_recall: 0.9002 - val_precision: 0.5761\n",
            "Epoch 346/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1580 - accuracy: 0.9410 - sensitivity_at_specificity: 0.9977 - specificity_at_sensitivity: 1.0000 - recall: 0.9331 - precision: 0.9486\n",
            "Epoch 346: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.1580 - accuracy: 0.9410 - sensitivity_at_specificity: 0.9977 - specificity_at_sensitivity: 1.0000 - recall: 0.9331 - precision: 0.9486 - val_loss: 1.2634 - val_accuracy: 0.6398 - val_sensitivity_at_specificity: 0.7820 - val_specificity_at_sensitivity: 0.7512 - val_recall: 0.8887 - val_precision: 0.6043\n",
            "Epoch 347/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1810 - accuracy: 0.9254 - sensitivity_at_specificity: 0.9969 - specificity_at_sensitivity: 1.0000 - recall: 0.9172 - precision: 0.9352\n",
            "Epoch 347: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.1810 - accuracy: 0.9254 - sensitivity_at_specificity: 0.9969 - specificity_at_sensitivity: 1.0000 - recall: 0.9172 - precision: 0.9352 - val_loss: 1.5995 - val_accuracy: 0.6234 - val_sensitivity_at_specificity: 0.8082 - val_specificity_at_sensitivity: 0.7381 - val_recall: 0.9319 - val_precision: 0.5725\n",
            "Epoch 348/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1931 - accuracy: 0.9145 - sensitivity_at_specificity: 0.9961 - specificity_at_sensitivity: 1.0000 - recall: 0.9028 - precision: 0.9264\n",
            "Epoch 348: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.1931 - accuracy: 0.9145 - sensitivity_at_specificity: 0.9961 - specificity_at_sensitivity: 1.0000 - recall: 0.9028 - precision: 0.9264 - val_loss: 1.3286 - val_accuracy: 0.6211 - val_sensitivity_at_specificity: 0.7863 - val_specificity_at_sensitivity: 0.7706 - val_recall: 0.8744 - val_precision: 0.5678\n",
            "Epoch 349/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1982 - accuracy: 0.9137 - sensitivity_at_specificity: 0.9968 - specificity_at_sensitivity: 0.9992 - recall: 0.9069 - precision: 0.9164\n",
            "Epoch 349: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.1982 - accuracy: 0.9137 - sensitivity_at_specificity: 0.9968 - specificity_at_sensitivity: 0.9992 - recall: 0.9069 - precision: 0.9164 - val_loss: 1.4392 - val_accuracy: 0.6281 - val_sensitivity_at_specificity: 0.7872 - val_specificity_at_sensitivity: 0.7520 - val_recall: 0.9061 - val_precision: 0.5819\n",
            "Epoch 350/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1805 - accuracy: 0.9254 - sensitivity_at_specificity: 0.9976 - specificity_at_sensitivity: 0.9992 - recall: 0.9152 - precision: 0.9335\n",
            "Epoch 350: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.1805 - accuracy: 0.9254 - sensitivity_at_specificity: 0.9976 - specificity_at_sensitivity: 0.9992 - recall: 0.9152 - precision: 0.9335 - val_loss: 1.5490 - val_accuracy: 0.6297 - val_sensitivity_at_specificity: 0.8080 - val_specificity_at_sensitivity: 0.7481 - val_recall: 0.9008 - val_precision: 0.5774\n",
            "Epoch 351/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1941 - accuracy: 0.9246 - sensitivity_at_specificity: 0.9930 - specificity_at_sensitivity: 0.9992 - recall: 0.9140 - precision: 0.9337\n",
            "Epoch 351: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.1941 - accuracy: 0.9246 - sensitivity_at_specificity: 0.9930 - specificity_at_sensitivity: 0.9992 - recall: 0.9140 - precision: 0.9337 - val_loss: 1.3344 - val_accuracy: 0.6219 - val_sensitivity_at_specificity: 0.7401 - val_specificity_at_sensitivity: 0.7154 - val_recall: 0.8602 - val_precision: 0.5908\n",
            "Epoch 352/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.1784 - accuracy: 0.9280 - sensitivity_at_specificity: 0.9939 - specificity_at_sensitivity: 0.9991 - recall: 0.9254 - precision: 0.9286\n",
            "Epoch 352: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.1796 - accuracy: 0.9273 - sensitivity_at_specificity: 0.9941 - specificity_at_sensitivity: 0.9992 - recall: 0.9238 - precision: 0.9293 - val_loss: 1.4308 - val_accuracy: 0.6398 - val_sensitivity_at_specificity: 0.8066 - val_specificity_at_sensitivity: 0.7825 - val_recall: 0.9204 - val_precision: 0.5900\n",
            "Epoch 353/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1747 - accuracy: 0.9289 - sensitivity_at_specificity: 0.9952 - specificity_at_sensitivity: 1.0000 - recall: 0.9261 - precision: 0.9290\n",
            "Epoch 353: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.1747 - accuracy: 0.9289 - sensitivity_at_specificity: 0.9952 - specificity_at_sensitivity: 1.0000 - recall: 0.9261 - precision: 0.9290 - val_loss: 1.5016 - val_accuracy: 0.6320 - val_sensitivity_at_specificity: 0.8129 - val_specificity_at_sensitivity: 0.7547 - val_recall: 0.9308 - val_precision: 0.5810\n",
            "Epoch 354/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1717 - accuracy: 0.9324 - sensitivity_at_specificity: 0.9968 - specificity_at_sensitivity: 0.9992 - recall: 0.9225 - precision: 0.9396\n",
            "Epoch 354: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.1717 - accuracy: 0.9324 - sensitivity_at_specificity: 0.9968 - specificity_at_sensitivity: 0.9992 - recall: 0.9225 - precision: 0.9396 - val_loss: 1.4194 - val_accuracy: 0.6219 - val_sensitivity_at_specificity: 0.8152 - val_specificity_at_sensitivity: 0.7944 - val_recall: 0.8957 - val_precision: 0.5756\n",
            "Epoch 355/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1798 - accuracy: 0.9273 - sensitivity_at_specificity: 0.9922 - specificity_at_sensitivity: 0.9992 - recall: 0.9125 - precision: 0.9404\n",
            "Epoch 355: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 175ms/step - loss: 0.1798 - accuracy: 0.9273 - sensitivity_at_specificity: 0.9922 - specificity_at_sensitivity: 0.9992 - recall: 0.9125 - precision: 0.9404 - val_loss: 1.5200 - val_accuracy: 0.6141 - val_sensitivity_at_specificity: 0.7685 - val_specificity_at_sensitivity: 0.7271 - val_recall: 0.9181 - val_precision: 0.5688\n",
            "Epoch 356/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1738 - accuracy: 0.9285 - sensitivity_at_specificity: 0.9944 - specificity_at_sensitivity: 0.9992 - recall: 0.9167 - precision: 0.9355\n",
            "Epoch 356: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 179ms/step - loss: 0.1738 - accuracy: 0.9285 - sensitivity_at_specificity: 0.9944 - specificity_at_sensitivity: 0.9992 - recall: 0.9167 - precision: 0.9355 - val_loss: 1.4352 - val_accuracy: 0.6234 - val_sensitivity_at_specificity: 0.7596 - val_specificity_at_sensitivity: 0.7713 - val_recall: 0.9167 - val_precision: 0.5709\n",
            "Epoch 357/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1629 - accuracy: 0.9328 - sensitivity_at_specificity: 0.9976 - specificity_at_sensitivity: 1.0000 - recall: 0.9228 - precision: 0.9406\n",
            "Epoch 357: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.1629 - accuracy: 0.9328 - sensitivity_at_specificity: 0.9976 - specificity_at_sensitivity: 1.0000 - recall: 0.9228 - precision: 0.9406 - val_loss: 1.5466 - val_accuracy: 0.6203 - val_sensitivity_at_specificity: 0.7571 - val_specificity_at_sensitivity: 0.7134 - val_recall: 0.8809 - val_precision: 0.5782\n",
            "Epoch 358/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1864 - accuracy: 0.9244 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9202 - precision: 0.9294\n",
            "Epoch 358: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.1864 - accuracy: 0.9244 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9202 - precision: 0.9294 - val_loss: 1.3160 - val_accuracy: 0.6313 - val_sensitivity_at_specificity: 0.7935 - val_specificity_at_sensitivity: 0.7288 - val_recall: 0.8790 - val_precision: 0.5786\n",
            "Epoch 359/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1589 - accuracy: 0.9371 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 1.0000 - recall: 0.9377 - precision: 0.9412\n",
            "Epoch 359: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.1589 - accuracy: 0.9371 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 1.0000 - recall: 0.9377 - precision: 0.9412 - val_loss: 1.6639 - val_accuracy: 0.6297 - val_sensitivity_at_specificity: 0.7820 - val_specificity_at_sensitivity: 0.7172 - val_recall: 0.9368 - val_precision: 0.5774\n",
            "Epoch 360/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1829 - accuracy: 0.9266 - sensitivity_at_specificity: 0.9931 - specificity_at_sensitivity: 1.0000 - recall: 0.9192 - precision: 0.9351\n",
            "Epoch 360: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.1829 - accuracy: 0.9266 - sensitivity_at_specificity: 0.9931 - specificity_at_sensitivity: 1.0000 - recall: 0.9192 - precision: 0.9351 - val_loss: 1.3573 - val_accuracy: 0.6453 - val_sensitivity_at_specificity: 0.8131 - val_specificity_at_sensitivity: 0.7665 - val_recall: 0.9034 - val_precision: 0.5967\n",
            "Epoch 361/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1888 - accuracy: 0.9227 - sensitivity_at_specificity: 0.9968 - specificity_at_sensitivity: 1.0000 - recall: 0.9160 - precision: 0.9249\n",
            "Epoch 361: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.1888 - accuracy: 0.9227 - sensitivity_at_specificity: 0.9968 - specificity_at_sensitivity: 1.0000 - recall: 0.9160 - precision: 0.9249 - val_loss: 1.4230 - val_accuracy: 0.6234 - val_sensitivity_at_specificity: 0.7396 - val_specificity_at_sensitivity: 0.7940 - val_recall: 0.9353 - val_precision: 0.5798\n",
            "Epoch 362/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1934 - accuracy: 0.9176 - sensitivity_at_specificity: 0.9969 - specificity_at_sensitivity: 1.0000 - recall: 0.9145 - precision: 0.9224\n",
            "Epoch 362: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 174ms/step - loss: 0.1934 - accuracy: 0.9176 - sensitivity_at_specificity: 0.9969 - specificity_at_sensitivity: 1.0000 - recall: 0.9145 - precision: 0.9224 - val_loss: 1.4115 - val_accuracy: 0.6414 - val_sensitivity_at_specificity: 0.8146 - val_specificity_at_sensitivity: 0.7596 - val_recall: 0.9398 - val_precision: 0.5848\n",
            "Epoch 363/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1932 - accuracy: 0.9246 - sensitivity_at_specificity: 0.9952 - specificity_at_sensitivity: 1.0000 - recall: 0.9085 - precision: 0.9348\n",
            "Epoch 363: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.1932 - accuracy: 0.9246 - sensitivity_at_specificity: 0.9952 - specificity_at_sensitivity: 1.0000 - recall: 0.9085 - precision: 0.9348 - val_loss: 1.5662 - val_accuracy: 0.6156 - val_sensitivity_at_specificity: 0.7861 - val_specificity_at_sensitivity: 0.7242 - val_recall: 0.9429 - val_precision: 0.5661\n",
            "Epoch 364/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1752 - accuracy: 0.9270 - sensitivity_at_specificity: 0.9976 - specificity_at_sensitivity: 1.0000 - recall: 0.9167 - precision: 0.9338\n",
            "Epoch 364: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.1752 - accuracy: 0.9270 - sensitivity_at_specificity: 0.9976 - specificity_at_sensitivity: 1.0000 - recall: 0.9167 - precision: 0.9338 - val_loss: 1.6553 - val_accuracy: 0.6141 - val_sensitivity_at_specificity: 0.7837 - val_specificity_at_sensitivity: 0.7523 - val_recall: 0.9154 - val_precision: 0.5703\n",
            "Epoch 365/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1775 - accuracy: 0.9289 - sensitivity_at_specificity: 0.9969 - specificity_at_sensitivity: 0.9992 - recall: 0.9160 - precision: 0.9434\n",
            "Epoch 365: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.1775 - accuracy: 0.9289 - sensitivity_at_specificity: 0.9969 - specificity_at_sensitivity: 0.9992 - recall: 0.9160 - precision: 0.9434 - val_loss: 1.5178 - val_accuracy: 0.6570 - val_sensitivity_at_specificity: 0.8328 - val_specificity_at_sensitivity: 0.7539 - val_recall: 0.9334 - val_precision: 0.6036\n",
            "Epoch 366/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1752 - accuracy: 0.9254 - sensitivity_at_specificity: 0.9977 - specificity_at_sensitivity: 0.9992 - recall: 0.9184 - precision: 0.9335\n",
            "Epoch 366: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.1752 - accuracy: 0.9254 - sensitivity_at_specificity: 0.9977 - specificity_at_sensitivity: 0.9992 - recall: 0.9184 - precision: 0.9335 - val_loss: 1.2215 - val_accuracy: 0.6367 - val_sensitivity_at_specificity: 0.8190 - val_specificity_at_sensitivity: 0.7887 - val_recall: 0.9048 - val_precision: 0.5894\n",
            "Epoch 367/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1651 - accuracy: 0.9332 - sensitivity_at_specificity: 0.9969 - specificity_at_sensitivity: 1.0000 - recall: 0.9335 - precision: 0.9328\n",
            "Epoch 367: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.1651 - accuracy: 0.9332 - sensitivity_at_specificity: 0.9969 - specificity_at_sensitivity: 1.0000 - recall: 0.9335 - precision: 0.9328 - val_loss: 1.4455 - val_accuracy: 0.6258 - val_sensitivity_at_specificity: 0.7804 - val_specificity_at_sensitivity: 0.7434 - val_recall: 0.8878 - val_precision: 0.5794\n",
            "Epoch 368/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1627 - accuracy: 0.9402 - sensitivity_at_specificity: 0.9962 - specificity_at_sensitivity: 1.0000 - recall: 0.9280 - precision: 0.9548\n",
            "Epoch 368: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.1627 - accuracy: 0.9402 - sensitivity_at_specificity: 0.9962 - specificity_at_sensitivity: 1.0000 - recall: 0.9280 - precision: 0.9548 - val_loss: 1.5752 - val_accuracy: 0.6414 - val_sensitivity_at_specificity: 0.8006 - val_specificity_at_sensitivity: 0.6932 - val_recall: 0.9453 - val_precision: 0.6026\n",
            "Epoch 369/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1561 - accuracy: 0.9363 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9318 - precision: 0.9413\n",
            "Epoch 369: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.1561 - accuracy: 0.9363 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9318 - precision: 0.9413 - val_loss: 1.4767 - val_accuracy: 0.6281 - val_sensitivity_at_specificity: 0.7764 - val_specificity_at_sensitivity: 0.7608 - val_recall: 0.9250 - val_precision: 0.5858\n",
            "Epoch 370/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1660 - accuracy: 0.9363 - sensitivity_at_specificity: 0.9953 - specificity_at_sensitivity: 1.0000 - recall: 0.9328 - precision: 0.9380\n",
            "Epoch 370: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.1660 - accuracy: 0.9363 - sensitivity_at_specificity: 0.9953 - specificity_at_sensitivity: 1.0000 - recall: 0.9328 - precision: 0.9380 - val_loss: 1.5085 - val_accuracy: 0.6422 - val_sensitivity_at_specificity: 0.8071 - val_specificity_at_sensitivity: 0.7112 - val_recall: 0.9273 - val_precision: 0.6044\n",
            "Epoch 371/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1580 - accuracy: 0.9359 - sensitivity_at_specificity: 0.9953 - specificity_at_sensitivity: 0.9992 - recall: 0.9315 - precision: 0.9389\n",
            "Epoch 371: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 190ms/step - loss: 0.1580 - accuracy: 0.9359 - sensitivity_at_specificity: 0.9953 - specificity_at_sensitivity: 0.9992 - recall: 0.9315 - precision: 0.9389 - val_loss: 1.3653 - val_accuracy: 0.6531 - val_sensitivity_at_specificity: 0.8153 - val_specificity_at_sensitivity: 0.7824 - val_recall: 0.9405 - val_precision: 0.6033\n",
            "Epoch 372/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1657 - accuracy: 0.9336 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9992 - recall: 0.9137 - precision: 0.9510\n",
            "Epoch 372: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.1657 - accuracy: 0.9336 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9992 - recall: 0.9137 - precision: 0.9510 - val_loss: 1.6321 - val_accuracy: 0.6156 - val_sensitivity_at_specificity: 0.7616 - val_specificity_at_sensitivity: 0.7003 - val_recall: 0.9334 - val_precision: 0.5732\n",
            "Epoch 373/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1640 - accuracy: 0.9305 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9985 - recall: 0.9194 - precision: 0.9387\n",
            "Epoch 373: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.1640 - accuracy: 0.9305 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9985 - recall: 0.9194 - precision: 0.9387 - val_loss: 1.6421 - val_accuracy: 0.5930 - val_sensitivity_at_specificity: 0.7711 - val_specificity_at_sensitivity: 0.7530 - val_recall: 0.9351 - val_precision: 0.5449\n",
            "Epoch 374/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1591 - accuracy: 0.9359 - sensitivity_at_specificity: 0.9937 - specificity_at_sensitivity: 0.9992 - recall: 0.9390 - precision: 0.9317\n",
            "Epoch 374: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.1591 - accuracy: 0.9359 - sensitivity_at_specificity: 0.9937 - specificity_at_sensitivity: 0.9992 - recall: 0.9390 - precision: 0.9317 - val_loss: 1.3998 - val_accuracy: 0.6367 - val_sensitivity_at_specificity: 0.8116 - val_specificity_at_sensitivity: 0.7605 - val_recall: 0.8948 - val_precision: 0.5888\n",
            "Epoch 375/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1616 - accuracy: 0.9327 - sensitivity_at_specificity: 0.9976 - specificity_at_sensitivity: 1.0000 - recall: 0.9273 - precision: 0.9396\n",
            "Epoch 375: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.1616 - accuracy: 0.9327 - sensitivity_at_specificity: 0.9976 - specificity_at_sensitivity: 1.0000 - recall: 0.9273 - precision: 0.9396 - val_loss: 1.7959 - val_accuracy: 0.6148 - val_sensitivity_at_specificity: 0.7399 - val_specificity_at_sensitivity: 0.7156 - val_recall: 0.9225 - val_precision: 0.5620\n",
            "Epoch 376/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1563 - accuracy: 0.9383 - sensitivity_at_specificity: 0.9960 - specificity_at_sensitivity: 1.0000 - recall: 0.9312 - precision: 0.9431\n",
            "Epoch 376: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 174ms/step - loss: 0.1563 - accuracy: 0.9383 - sensitivity_at_specificity: 0.9960 - specificity_at_sensitivity: 1.0000 - recall: 0.9312 - precision: 0.9431 - val_loss: 1.5798 - val_accuracy: 0.6164 - val_sensitivity_at_specificity: 0.7695 - val_specificity_at_sensitivity: 0.7542 - val_recall: 0.9444 - val_precision: 0.5657\n",
            "Epoch 377/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1569 - accuracy: 0.9383 - sensitivity_at_specificity: 0.9945 - specificity_at_sensitivity: 1.0000 - recall: 0.9319 - precision: 0.9437\n",
            "Epoch 377: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.1569 - accuracy: 0.9383 - sensitivity_at_specificity: 0.9945 - specificity_at_sensitivity: 1.0000 - recall: 0.9319 - precision: 0.9437 - val_loss: 1.4690 - val_accuracy: 0.6398 - val_sensitivity_at_specificity: 0.8318 - val_specificity_at_sensitivity: 0.7873 - val_recall: 0.9387 - val_precision: 0.5859\n",
            "Epoch 378/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1447 - accuracy: 0.9435 - sensitivity_at_specificity: 0.9983 - specificity_at_sensitivity: 1.0000 - recall: 0.9305 - precision: 0.9531\n",
            "Epoch 378: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.1447 - accuracy: 0.9435 - sensitivity_at_specificity: 0.9983 - specificity_at_sensitivity: 1.0000 - recall: 0.9305 - precision: 0.9531 - val_loss: 1.6510 - val_accuracy: 0.6281 - val_sensitivity_at_specificity: 0.7771 - val_specificity_at_sensitivity: 0.7408 - val_recall: 0.9649 - val_precision: 0.5825\n",
            "Epoch 379/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1540 - accuracy: 0.9426 - sensitivity_at_specificity: 0.9944 - specificity_at_sensitivity: 1.0000 - recall: 0.9345 - precision: 0.9474\n",
            "Epoch 379: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.1540 - accuracy: 0.9426 - sensitivity_at_specificity: 0.9944 - specificity_at_sensitivity: 1.0000 - recall: 0.9345 - precision: 0.9474 - val_loss: 1.9737 - val_accuracy: 0.6047 - val_sensitivity_at_specificity: 0.7660 - val_specificity_at_sensitivity: 0.7465 - val_recall: 0.9626 - val_precision: 0.5614\n",
            "Epoch 380/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1339 - accuracy: 0.9500 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9401 - precision: 0.9582\n",
            "Epoch 380: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.1339 - accuracy: 0.9500 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9401 - precision: 0.9582 - val_loss: 1.8696 - val_accuracy: 0.6016 - val_sensitivity_at_specificity: 0.7454 - val_specificity_at_sensitivity: 0.6959 - val_recall: 0.9279 - val_precision: 0.5665\n",
            "Epoch 381/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1504 - accuracy: 0.9355 - sensitivity_at_specificity: 0.9954 - specificity_at_sensitivity: 1.0000 - recall: 0.9368 - precision: 0.9375\n",
            "Epoch 381: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 174ms/step - loss: 0.1504 - accuracy: 0.9355 - sensitivity_at_specificity: 0.9954 - specificity_at_sensitivity: 1.0000 - recall: 0.9368 - precision: 0.9375 - val_loss: 1.4604 - val_accuracy: 0.6320 - val_sensitivity_at_specificity: 0.8262 - val_specificity_at_sensitivity: 0.7317 - val_recall: 0.9015 - val_precision: 0.5901\n",
            "Epoch 382/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1703 - accuracy: 0.9324 - sensitivity_at_specificity: 0.9977 - specificity_at_sensitivity: 0.9992 - recall: 0.9216 - precision: 0.9428\n",
            "Epoch 382: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.1703 - accuracy: 0.9324 - sensitivity_at_specificity: 0.9977 - specificity_at_sensitivity: 0.9992 - recall: 0.9216 - precision: 0.9428 - val_loss: 1.5404 - val_accuracy: 0.6375 - val_sensitivity_at_specificity: 0.8175 - val_specificity_at_sensitivity: 0.7621 - val_recall: 0.9267 - val_precision: 0.5875\n",
            "Epoch 383/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1530 - accuracy: 0.9402 - sensitivity_at_specificity: 0.9952 - specificity_at_sensitivity: 1.0000 - recall: 0.9357 - precision: 0.9479\n",
            "Epoch 383: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.1530 - accuracy: 0.9402 - sensitivity_at_specificity: 0.9952 - specificity_at_sensitivity: 1.0000 - recall: 0.9357 - precision: 0.9479 - val_loss: 1.6655 - val_accuracy: 0.6125 - val_sensitivity_at_specificity: 0.7703 - val_specificity_at_sensitivity: 0.7219 - val_recall: 0.9234 - val_precision: 0.5694\n",
            "Epoch 384/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1578 - accuracy: 0.9406 - sensitivity_at_specificity: 0.9960 - specificity_at_sensitivity: 0.9992 - recall: 0.9294 - precision: 0.9489\n",
            "Epoch 384: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.1578 - accuracy: 0.9406 - sensitivity_at_specificity: 0.9960 - specificity_at_sensitivity: 0.9992 - recall: 0.9294 - precision: 0.9489 - val_loss: 1.6204 - val_accuracy: 0.6203 - val_sensitivity_at_specificity: 0.7717 - val_specificity_at_sensitivity: 0.7464 - val_recall: 0.9376 - val_precision: 0.5806\n",
            "Epoch 385/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1490 - accuracy: 0.9387 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 1.0000 - recall: 0.9308 - precision: 0.9476\n",
            "Epoch 385: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 212ms/step - loss: 0.1490 - accuracy: 0.9387 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 1.0000 - recall: 0.9308 - precision: 0.9476 - val_loss: 1.8434 - val_accuracy: 0.5930 - val_sensitivity_at_specificity: 0.7556 - val_specificity_at_sensitivity: 0.7280 - val_recall: 0.9228 - val_precision: 0.5482\n",
            "Epoch 386/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1353 - accuracy: 0.9523 - sensitivity_at_specificity: 0.9977 - specificity_at_sensitivity: 0.9992 - recall: 0.9471 - precision: 0.9589\n",
            "Epoch 386: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.1353 - accuracy: 0.9523 - sensitivity_at_specificity: 0.9977 - specificity_at_sensitivity: 0.9992 - recall: 0.9471 - precision: 0.9589 - val_loss: 1.5162 - val_accuracy: 0.6273 - val_sensitivity_at_specificity: 0.8095 - val_specificity_at_sensitivity: 0.7969 - val_recall: 0.9206 - val_precision: 0.5760\n",
            "Epoch 387/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1413 - accuracy: 0.9465 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9441 - precision: 0.9493\n",
            "Epoch 387: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.1413 - accuracy: 0.9465 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9441 - precision: 0.9493 - val_loss: 1.4891 - val_accuracy: 0.6383 - val_sensitivity_at_specificity: 0.8049 - val_specificity_at_sensitivity: 0.7821 - val_recall: 0.9405 - val_precision: 0.5927\n",
            "Epoch 388/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1489 - accuracy: 0.9422 - sensitivity_at_specificity: 0.9977 - specificity_at_sensitivity: 1.0000 - recall: 0.9416 - precision: 0.9431\n",
            "Epoch 388: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.1489 - accuracy: 0.9422 - sensitivity_at_specificity: 0.9977 - specificity_at_sensitivity: 1.0000 - recall: 0.9416 - precision: 0.9431 - val_loss: 1.5481 - val_accuracy: 0.6313 - val_sensitivity_at_specificity: 0.7904 - val_specificity_at_sensitivity: 0.7704 - val_recall: 0.9379 - val_precision: 0.5830\n",
            "Epoch 389/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1439 - accuracy: 0.9473 - sensitivity_at_specificity: 0.9954 - specificity_at_sensitivity: 1.0000 - recall: 0.9394 - precision: 0.9563\n",
            "Epoch 389: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.1439 - accuracy: 0.9473 - sensitivity_at_specificity: 0.9954 - specificity_at_sensitivity: 1.0000 - recall: 0.9394 - precision: 0.9563 - val_loss: 1.7221 - val_accuracy: 0.6094 - val_sensitivity_at_specificity: 0.7466 - val_specificity_at_sensitivity: 0.7008 - val_recall: 0.9435 - val_precision: 0.5717\n",
            "Epoch 390/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1588 - accuracy: 0.9391 - sensitivity_at_specificity: 0.9937 - specificity_at_sensitivity: 0.9992 - recall: 0.9278 - precision: 0.9487\n",
            "Epoch 390: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.1588 - accuracy: 0.9391 - sensitivity_at_specificity: 0.9937 - specificity_at_sensitivity: 0.9992 - recall: 0.9278 - precision: 0.9487 - val_loss: 1.6716 - val_accuracy: 0.6352 - val_sensitivity_at_specificity: 0.7608 - val_specificity_at_sensitivity: 0.7117 - val_recall: 0.9435 - val_precision: 0.5968\n",
            "Epoch 391/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1350 - accuracy: 0.9477 - sensitivity_at_specificity: 0.9960 - specificity_at_sensitivity: 1.0000 - recall: 0.9414 - precision: 0.9519\n",
            "Epoch 391: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.1350 - accuracy: 0.9477 - sensitivity_at_specificity: 0.9960 - specificity_at_sensitivity: 1.0000 - recall: 0.9414 - precision: 0.9519 - val_loss: 1.8374 - val_accuracy: 0.5820 - val_sensitivity_at_specificity: 0.7610 - val_specificity_at_sensitivity: 0.7128 - val_recall: 0.9089 - val_precision: 0.5385\n",
            "Epoch 392/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1474 - accuracy: 0.9355 - sensitivity_at_specificity: 0.9969 - specificity_at_sensitivity: 1.0000 - recall: 0.9290 - precision: 0.9415\n",
            "Epoch 392: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.1474 - accuracy: 0.9355 - sensitivity_at_specificity: 0.9969 - specificity_at_sensitivity: 1.0000 - recall: 0.9290 - precision: 0.9415 - val_loss: 1.6195 - val_accuracy: 0.6461 - val_sensitivity_at_specificity: 0.7984 - val_specificity_at_sensitivity: 0.7071 - val_recall: 0.9395 - val_precision: 0.5941\n",
            "Epoch 393/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1463 - accuracy: 0.9398 - sensitivity_at_specificity: 0.9976 - specificity_at_sensitivity: 1.0000 - recall: 0.9395 - precision: 0.9380\n",
            "Epoch 393: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.1463 - accuracy: 0.9398 - sensitivity_at_specificity: 0.9976 - specificity_at_sensitivity: 1.0000 - recall: 0.9395 - precision: 0.9380 - val_loss: 1.5102 - val_accuracy: 0.6414 - val_sensitivity_at_specificity: 0.8441 - val_specificity_at_sensitivity: 0.7953 - val_recall: 0.8992 - val_precision: 0.5911\n",
            "Epoch 394/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1476 - accuracy: 0.9469 - sensitivity_at_specificity: 0.9968 - specificity_at_sensitivity: 1.0000 - recall: 0.9338 - precision: 0.9567\n",
            "Epoch 394: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.1476 - accuracy: 0.9469 - sensitivity_at_specificity: 0.9968 - specificity_at_sensitivity: 1.0000 - recall: 0.9338 - precision: 0.9567 - val_loss: 1.5342 - val_accuracy: 0.6273 - val_sensitivity_at_specificity: 0.7695 - val_specificity_at_sensitivity: 0.7524 - val_recall: 0.9206 - val_precision: 0.5811\n",
            "Epoch 395/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1399 - accuracy: 0.9480 - sensitivity_at_specificity: 0.9977 - specificity_at_sensitivity: 1.0000 - recall: 0.9414 - precision: 0.9554\n",
            "Epoch 395: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.1399 - accuracy: 0.9480 - sensitivity_at_specificity: 0.9977 - specificity_at_sensitivity: 1.0000 - recall: 0.9414 - precision: 0.9554 - val_loss: 1.5218 - val_accuracy: 0.6367 - val_sensitivity_at_specificity: 0.7788 - val_specificity_at_sensitivity: 0.7581 - val_recall: 0.9152 - val_precision: 0.5962\n",
            "Epoch 396/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1503 - accuracy: 0.9469 - sensitivity_at_specificity: 0.9953 - specificity_at_sensitivity: 1.0000 - recall: 0.9375 - precision: 0.9554\n",
            "Epoch 396: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.1503 - accuracy: 0.9469 - sensitivity_at_specificity: 0.9953 - specificity_at_sensitivity: 1.0000 - recall: 0.9375 - precision: 0.9554 - val_loss: 1.7183 - val_accuracy: 0.6211 - val_sensitivity_at_specificity: 0.7812 - val_specificity_at_sensitivity: 0.7195 - val_recall: 0.9091 - val_precision: 0.5807\n",
            "Epoch 397/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1578 - accuracy: 0.9367 - sensitivity_at_specificity: 0.9954 - specificity_at_sensitivity: 1.0000 - recall: 0.9228 - precision: 0.9507\n",
            "Epoch 397: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.1578 - accuracy: 0.9367 - sensitivity_at_specificity: 0.9954 - specificity_at_sensitivity: 1.0000 - recall: 0.9228 - precision: 0.9507 - val_loss: 1.3660 - val_accuracy: 0.6422 - val_sensitivity_at_specificity: 0.8053 - val_specificity_at_sensitivity: 0.7496 - val_recall: 0.9105 - val_precision: 0.5912\n",
            "Epoch 398/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1628 - accuracy: 0.9348 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9984 - recall: 0.9337 - precision: 0.9359\n",
            "Epoch 398: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.1628 - accuracy: 0.9348 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9984 - recall: 0.9337 - precision: 0.9359 - val_loss: 1.5027 - val_accuracy: 0.6273 - val_sensitivity_at_specificity: 0.7973 - val_specificity_at_sensitivity: 0.7708 - val_recall: 0.9451 - val_precision: 0.5844\n",
            "Epoch 399/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1267 - accuracy: 0.9547 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9494 - precision: 0.9625\n",
            "Epoch 399: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.1267 - accuracy: 0.9547 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9494 - precision: 0.9625 - val_loss: 1.8868 - val_accuracy: 0.6117 - val_sensitivity_at_specificity: 0.7722 - val_specificity_at_sensitivity: 0.7083 - val_recall: 0.9525 - val_precision: 0.5631\n",
            "Epoch 400/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1331 - accuracy: 0.9535 - sensitivity_at_specificity: 0.9967 - specificity_at_sensitivity: 1.0000 - recall: 0.9448 - precision: 0.9609\n",
            "Epoch 400: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.1331 - accuracy: 0.9535 - sensitivity_at_specificity: 0.9967 - specificity_at_sensitivity: 1.0000 - recall: 0.9448 - precision: 0.9609 - val_loss: 1.8942 - val_accuracy: 0.6141 - val_sensitivity_at_specificity: 0.7643 - val_specificity_at_sensitivity: 0.7227 - val_recall: 0.9414 - val_precision: 0.5726\n",
            "Epoch 401/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1376 - accuracy: 0.9469 - sensitivity_at_specificity: 0.9969 - specificity_at_sensitivity: 0.9992 - recall: 0.9395 - precision: 0.9556\n",
            "Epoch 401: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.1376 - accuracy: 0.9469 - sensitivity_at_specificity: 0.9969 - specificity_at_sensitivity: 0.9992 - recall: 0.9395 - precision: 0.9556 - val_loss: 1.5775 - val_accuracy: 0.6414 - val_sensitivity_at_specificity: 0.8156 - val_specificity_at_sensitivity: 0.7656 - val_recall: 0.9484 - val_precision: 0.5876\n",
            "Epoch 402/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1724 - accuracy: 0.9281 - sensitivity_at_specificity: 0.9928 - specificity_at_sensitivity: 1.0000 - recall: 0.9297 - precision: 0.9238\n",
            "Epoch 402: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.1724 - accuracy: 0.9281 - sensitivity_at_specificity: 0.9928 - specificity_at_sensitivity: 1.0000 - recall: 0.9297 - precision: 0.9238 - val_loss: 1.6044 - val_accuracy: 0.6242 - val_sensitivity_at_specificity: 0.8083 - val_specificity_at_sensitivity: 0.7188 - val_recall: 0.9212 - val_precision: 0.5809\n",
            "Epoch 403/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1384 - accuracy: 0.9448 - sensitivity_at_specificity: 0.9975 - specificity_at_sensitivity: 1.0000 - recall: 0.9308 - precision: 0.9584\n",
            "Epoch 403: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.1384 - accuracy: 0.9448 - sensitivity_at_specificity: 0.9975 - specificity_at_sensitivity: 1.0000 - recall: 0.9308 - precision: 0.9584 - val_loss: 1.8026 - val_accuracy: 0.6125 - val_sensitivity_at_specificity: 0.7702 - val_specificity_at_sensitivity: 0.6980 - val_recall: 0.9398 - val_precision: 0.5642\n",
            "Epoch 404/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1386 - accuracy: 0.9496 - sensitivity_at_specificity: 0.9953 - specificity_at_sensitivity: 1.0000 - recall: 0.9438 - precision: 0.9550\n",
            "Epoch 404: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.1386 - accuracy: 0.9496 - sensitivity_at_specificity: 0.9953 - specificity_at_sensitivity: 1.0000 - recall: 0.9438 - precision: 0.9550 - val_loss: 1.5770 - val_accuracy: 0.6289 - val_sensitivity_at_specificity: 0.8057 - val_specificity_at_sensitivity: 0.7546 - val_recall: 0.9268 - val_precision: 0.5757\n",
            "Epoch 405/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1270 - accuracy: 0.9477 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9376 - precision: 0.9557\n",
            "Epoch 405: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.1270 - accuracy: 0.9477 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9376 - precision: 0.9557 - val_loss: 1.6889 - val_accuracy: 0.6344 - val_sensitivity_at_specificity: 0.7916 - val_specificity_at_sensitivity: 0.7221 - val_recall: 0.9393 - val_precision: 0.5847\n",
            "Epoch 406/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1330 - accuracy: 0.9426 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 1.0000 - recall: 0.9380 - precision: 0.9489\n",
            "Epoch 406: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.1330 - accuracy: 0.9426 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 1.0000 - recall: 0.9380 - precision: 0.9489 - val_loss: 1.6284 - val_accuracy: 0.6297 - val_sensitivity_at_specificity: 0.7767 - val_specificity_at_sensitivity: 0.7626 - val_recall: 0.9234 - val_precision: 0.5761\n",
            "Epoch 407/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1408 - accuracy: 0.9445 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9985 - recall: 0.9351 - precision: 0.9517\n",
            "Epoch 407: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.1408 - accuracy: 0.9445 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9985 - recall: 0.9351 - precision: 0.9517 - val_loss: 1.6867 - val_accuracy: 0.6273 - val_sensitivity_at_specificity: 0.7626 - val_specificity_at_sensitivity: 0.7352 - val_recall: 0.9265 - val_precision: 0.5851\n",
            "Epoch 408/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1218 - accuracy: 0.9531 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9446 - precision: 0.9598\n",
            "Epoch 408: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.1218 - accuracy: 0.9531 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9446 - precision: 0.9598 - val_loss: 1.6227 - val_accuracy: 0.6328 - val_sensitivity_at_specificity: 0.7826 - val_specificity_at_sensitivity: 0.7516 - val_recall: 0.9286 - val_precision: 0.5851\n",
            "Epoch 409/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1308 - accuracy: 0.9477 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9992 - recall: 0.9390 - precision: 0.9514\n",
            "Epoch 409: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.1308 - accuracy: 0.9477 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9992 - recall: 0.9390 - precision: 0.9514 - val_loss: 1.6739 - val_accuracy: 0.6539 - val_sensitivity_at_specificity: 0.7769 - val_specificity_at_sensitivity: 0.7230 - val_recall: 0.9287 - val_precision: 0.6071\n",
            "Epoch 410/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1384 - accuracy: 0.9457 - sensitivity_at_specificity: 0.9976 - specificity_at_sensitivity: 0.9992 - recall: 0.9440 - precision: 0.9462\n",
            "Epoch 410: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 177ms/step - loss: 0.1384 - accuracy: 0.9457 - sensitivity_at_specificity: 0.9976 - specificity_at_sensitivity: 0.9992 - recall: 0.9440 - precision: 0.9462 - val_loss: 1.4332 - val_accuracy: 0.6602 - val_sensitivity_at_specificity: 0.8185 - val_specificity_at_sensitivity: 0.7738 - val_recall: 0.9228 - val_precision: 0.6137\n",
            "Epoch 411/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1252 - accuracy: 0.9527 - sensitivity_at_specificity: 0.9976 - specificity_at_sensitivity: 1.0000 - recall: 0.9463 - precision: 0.9576\n",
            "Epoch 411: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.1252 - accuracy: 0.9527 - sensitivity_at_specificity: 0.9976 - specificity_at_sensitivity: 1.0000 - recall: 0.9463 - precision: 0.9576 - val_loss: 1.7010 - val_accuracy: 0.6430 - val_sensitivity_at_specificity: 0.8246 - val_specificity_at_sensitivity: 0.7743 - val_recall: 0.9479 - val_precision: 0.5859\n",
            "Epoch 412/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1338 - accuracy: 0.9480 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9426 - precision: 0.9509\n",
            "Epoch 412: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 190ms/step - loss: 0.1338 - accuracy: 0.9480 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9426 - precision: 0.9509 - val_loss: 1.6023 - val_accuracy: 0.6320 - val_sensitivity_at_specificity: 0.8025 - val_specificity_at_sensitivity: 0.7441 - val_recall: 0.9347 - val_precision: 0.5835\n",
            "Epoch 413/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1190 - accuracy: 0.9516 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9444 - precision: 0.9592\n",
            "Epoch 413: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.1190 - accuracy: 0.9516 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9444 - precision: 0.9592 - val_loss: 1.8369 - val_accuracy: 0.6203 - val_sensitivity_at_specificity: 0.8074 - val_specificity_at_sensitivity: 0.7306 - val_recall: 0.9445 - val_precision: 0.5767\n",
            "Epoch 414/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1291 - accuracy: 0.9520 - sensitivity_at_specificity: 0.9969 - specificity_at_sensitivity: 1.0000 - recall: 0.9484 - precision: 0.9551\n",
            "Epoch 414: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.1291 - accuracy: 0.9520 - sensitivity_at_specificity: 0.9969 - specificity_at_sensitivity: 1.0000 - recall: 0.9484 - precision: 0.9551 - val_loss: 1.7308 - val_accuracy: 0.6195 - val_sensitivity_at_specificity: 0.7910 - val_specificity_at_sensitivity: 0.7089 - val_recall: 0.9267 - val_precision: 0.5745\n",
            "Epoch 415/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1356 - accuracy: 0.9473 - sensitivity_at_specificity: 0.9969 - specificity_at_sensitivity: 1.0000 - recall: 0.9357 - precision: 0.9575\n",
            "Epoch 415: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.1356 - accuracy: 0.9473 - sensitivity_at_specificity: 0.9969 - specificity_at_sensitivity: 1.0000 - recall: 0.9357 - precision: 0.9575 - val_loss: 1.7302 - val_accuracy: 0.6336 - val_sensitivity_at_specificity: 0.7767 - val_specificity_at_sensitivity: 0.7158 - val_recall: 0.9418 - val_precision: 0.5810\n",
            "Epoch 416/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1359 - accuracy: 0.9460 - sensitivity_at_specificity: 0.9975 - specificity_at_sensitivity: 1.0000 - recall: 0.9576 - precision: 0.9358\n",
            "Epoch 416: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.1359 - accuracy: 0.9460 - sensitivity_at_specificity: 0.9975 - specificity_at_sensitivity: 1.0000 - recall: 0.9576 - precision: 0.9358 - val_loss: 1.5373 - val_accuracy: 0.6422 - val_sensitivity_at_specificity: 0.8476 - val_specificity_at_sensitivity: 0.7523 - val_recall: 0.9254 - val_precision: 0.5865\n",
            "Epoch 417/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1348 - accuracy: 0.9473 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9376 - precision: 0.9549\n",
            "Epoch 417: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.1348 - accuracy: 0.9473 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9376 - precision: 0.9549 - val_loss: 1.6568 - val_accuracy: 0.6273 - val_sensitivity_at_specificity: 0.7575 - val_specificity_at_sensitivity: 0.7159 - val_recall: 0.9352 - val_precision: 0.5886\n",
            "Epoch 418/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1347 - accuracy: 0.9484 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9437 - precision: 0.9498\n",
            "Epoch 418: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 175ms/step - loss: 0.1347 - accuracy: 0.9484 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9437 - precision: 0.9498 - val_loss: 1.8051 - val_accuracy: 0.6320 - val_sensitivity_at_specificity: 0.7905 - val_specificity_at_sensitivity: 0.7444 - val_recall: 0.9327 - val_precision: 0.5882\n",
            "Epoch 419/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1327 - accuracy: 0.9453 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9335 - precision: 0.9534\n",
            "Epoch 419: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 174ms/step - loss: 0.1327 - accuracy: 0.9453 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9335 - precision: 0.9534 - val_loss: 1.9213 - val_accuracy: 0.6195 - val_sensitivity_at_specificity: 0.7584 - val_specificity_at_sensitivity: 0.7364 - val_recall: 0.9373 - val_precision: 0.5788\n",
            "Epoch 420/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1258 - accuracy: 0.9508 - sensitivity_at_specificity: 0.9968 - specificity_at_sensitivity: 1.0000 - recall: 0.9422 - precision: 0.9560\n",
            "Epoch 420: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 174ms/step - loss: 0.1258 - accuracy: 0.9508 - sensitivity_at_specificity: 0.9968 - specificity_at_sensitivity: 1.0000 - recall: 0.9422 - precision: 0.9560 - val_loss: 1.8117 - val_accuracy: 0.6016 - val_sensitivity_at_specificity: 0.7729 - val_specificity_at_sensitivity: 0.7208 - val_recall: 0.9533 - val_precision: 0.5517\n",
            "Epoch 421/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1209 - accuracy: 0.9512 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 1.0000 - recall: 0.9479 - precision: 0.9560\n",
            "Epoch 421: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.1209 - accuracy: 0.9512 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 1.0000 - recall: 0.9479 - precision: 0.9560 - val_loss: 1.9893 - val_accuracy: 0.6000 - val_sensitivity_at_specificity: 0.8213 - val_specificity_at_sensitivity: 0.7223 - val_recall: 0.9404 - val_precision: 0.5515\n",
            "Epoch 422/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1270 - accuracy: 0.9512 - sensitivity_at_specificity: 0.9952 - specificity_at_sensitivity: 1.0000 - recall: 0.9390 - precision: 0.9598\n",
            "Epoch 422: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.1270 - accuracy: 0.9512 - sensitivity_at_specificity: 0.9952 - specificity_at_sensitivity: 1.0000 - recall: 0.9390 - precision: 0.9598 - val_loss: 1.7342 - val_accuracy: 0.6172 - val_sensitivity_at_specificity: 0.7962 - val_specificity_at_sensitivity: 0.7316 - val_recall: 0.9315 - val_precision: 0.5669\n",
            "Epoch 423/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1379 - accuracy: 0.9473 - sensitivity_at_specificity: 0.9961 - specificity_at_sensitivity: 1.0000 - recall: 0.9474 - precision: 0.9481\n",
            "Epoch 423: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.1379 - accuracy: 0.9473 - sensitivity_at_specificity: 0.9961 - specificity_at_sensitivity: 1.0000 - recall: 0.9474 - precision: 0.9481 - val_loss: 1.5213 - val_accuracy: 0.6320 - val_sensitivity_at_specificity: 0.7847 - val_specificity_at_sensitivity: 0.7402 - val_recall: 0.9329 - val_precision: 0.5828\n",
            "Epoch 424/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1471 - accuracy: 0.9414 - sensitivity_at_specificity: 0.9977 - specificity_at_sensitivity: 1.0000 - recall: 0.9400 - precision: 0.9429\n",
            "Epoch 424: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.1471 - accuracy: 0.9414 - sensitivity_at_specificity: 0.9977 - specificity_at_sensitivity: 1.0000 - recall: 0.9400 - precision: 0.9429 - val_loss: 1.6999 - val_accuracy: 0.6258 - val_sensitivity_at_specificity: 0.8086 - val_specificity_at_sensitivity: 0.7263 - val_recall: 0.9414 - val_precision: 0.5804\n",
            "Epoch 425/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1198 - accuracy: 0.9520 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9524 - precision: 0.9531\n",
            "Epoch 425: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.1198 - accuracy: 0.9520 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9524 - precision: 0.9531 - val_loss: 1.6824 - val_accuracy: 0.6180 - val_sensitivity_at_specificity: 0.8135 - val_specificity_at_sensitivity: 0.7964 - val_recall: 0.9486 - val_precision: 0.5635\n",
            "Epoch 426/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1318 - accuracy: 0.9477 - sensitivity_at_specificity: 0.9969 - specificity_at_sensitivity: 1.0000 - recall: 0.9362 - precision: 0.9586\n",
            "Epoch 426: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.1318 - accuracy: 0.9477 - sensitivity_at_specificity: 0.9969 - specificity_at_sensitivity: 1.0000 - recall: 0.9362 - precision: 0.9586 - val_loss: 2.3957 - val_accuracy: 0.5766 - val_sensitivity_at_specificity: 0.7381 - val_specificity_at_sensitivity: 0.6562 - val_recall: 0.9542 - val_precision: 0.5314\n",
            "Epoch 427/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1316 - accuracy: 0.9465 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9451 - precision: 0.9502\n",
            "Epoch 427: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.1316 - accuracy: 0.9465 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9451 - precision: 0.9502 - val_loss: 1.8194 - val_accuracy: 0.6164 - val_sensitivity_at_specificity: 0.7677 - val_specificity_at_sensitivity: 0.7190 - val_recall: 0.9277 - val_precision: 0.5759\n",
            "Epoch 428/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1330 - accuracy: 0.9438 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9454 - precision: 0.9424\n",
            "Epoch 428: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.1330 - accuracy: 0.9438 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9454 - precision: 0.9424 - val_loss: 1.7054 - val_accuracy: 0.6281 - val_sensitivity_at_specificity: 0.7883 - val_specificity_at_sensitivity: 0.7388 - val_recall: 0.9242 - val_precision: 0.5775\n",
            "Epoch 429/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1265 - accuracy: 0.9531 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9463 - precision: 0.9597\n",
            "Epoch 429: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.1265 - accuracy: 0.9531 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9463 - precision: 0.9597 - val_loss: 1.6247 - val_accuracy: 0.6453 - val_sensitivity_at_specificity: 0.8131 - val_specificity_at_sensitivity: 0.7382 - val_recall: 0.9159 - val_precision: 0.5951\n",
            "Epoch 430/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1350 - accuracy: 0.9457 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 0.9992 - recall: 0.9366 - precision: 0.9551\n",
            "Epoch 430: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 178ms/step - loss: 0.1350 - accuracy: 0.9457 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 0.9992 - recall: 0.9366 - precision: 0.9551 - val_loss: 1.5703 - val_accuracy: 0.6164 - val_sensitivity_at_specificity: 0.7382 - val_specificity_at_sensitivity: 0.7009 - val_recall: 0.9107 - val_precision: 0.5724\n",
            "Epoch 431/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1269 - accuracy: 0.9563 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9477 - precision: 0.9630\n",
            "Epoch 431: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 187ms/step - loss: 0.1269 - accuracy: 0.9563 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9477 - precision: 0.9630 - val_loss: 1.8977 - val_accuracy: 0.6406 - val_sensitivity_at_specificity: 0.8118 - val_specificity_at_sensitivity: 0.7037 - val_recall: 0.9666 - val_precision: 0.5926\n",
            "Epoch 432/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1296 - accuracy: 0.9508 - sensitivity_at_specificity: 0.9968 - specificity_at_sensitivity: 1.0000 - recall: 0.9467 - precision: 0.9528\n",
            "Epoch 432: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.1296 - accuracy: 0.9508 - sensitivity_at_specificity: 0.9968 - specificity_at_sensitivity: 1.0000 - recall: 0.9467 - precision: 0.9528 - val_loss: 1.7580 - val_accuracy: 0.6375 - val_sensitivity_at_specificity: 0.7923 - val_specificity_at_sensitivity: 0.7360 - val_recall: 0.9629 - val_precision: 0.5965\n",
            "Epoch 433/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1426 - accuracy: 0.9410 - sensitivity_at_specificity: 0.9960 - specificity_at_sensitivity: 1.0000 - recall: 0.9311 - precision: 0.9470\n",
            "Epoch 433: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.1426 - accuracy: 0.9410 - sensitivity_at_specificity: 0.9960 - specificity_at_sensitivity: 1.0000 - recall: 0.9311 - precision: 0.9470 - val_loss: 1.6219 - val_accuracy: 0.6352 - val_sensitivity_at_specificity: 0.8125 - val_specificity_at_sensitivity: 0.7805 - val_recall: 0.9311 - val_precision: 0.5781\n",
            "Epoch 434/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1289 - accuracy: 0.9516 - sensitivity_at_specificity: 0.9976 - specificity_at_sensitivity: 1.0000 - recall: 0.9515 - precision: 0.9500\n",
            "Epoch 434: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.1289 - accuracy: 0.9516 - sensitivity_at_specificity: 0.9976 - specificity_at_sensitivity: 1.0000 - recall: 0.9515 - precision: 0.9500 - val_loss: 1.6282 - val_accuracy: 0.6406 - val_sensitivity_at_specificity: 0.8281 - val_specificity_at_sensitivity: 0.7344 - val_recall: 0.9359 - val_precision: 0.5884\n",
            "Epoch 435/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1356 - accuracy: 0.9500 - sensitivity_at_specificity: 0.9969 - specificity_at_sensitivity: 1.0000 - recall: 0.9411 - precision: 0.9589\n",
            "Epoch 435: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.1356 - accuracy: 0.9500 - sensitivity_at_specificity: 0.9969 - specificity_at_sensitivity: 1.0000 - recall: 0.9411 - precision: 0.9589 - val_loss: 1.8717 - val_accuracy: 0.6062 - val_sensitivity_at_specificity: 0.7610 - val_specificity_at_sensitivity: 0.7384 - val_recall: 0.9467 - val_precision: 0.5701\n",
            "Epoch 436/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1250 - accuracy: 0.9523 - sensitivity_at_specificity: 0.9969 - specificity_at_sensitivity: 0.9992 - recall: 0.9435 - precision: 0.9626\n",
            "Epoch 436: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 174ms/step - loss: 0.1250 - accuracy: 0.9523 - sensitivity_at_specificity: 0.9969 - specificity_at_sensitivity: 0.9992 - recall: 0.9435 - precision: 0.9626 - val_loss: 1.7543 - val_accuracy: 0.6359 - val_sensitivity_at_specificity: 0.8252 - val_specificity_at_sensitivity: 0.7500 - val_recall: 0.9632 - val_precision: 0.5869\n",
            "Epoch 437/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1238 - accuracy: 0.9531 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 1.0000 - recall: 0.9483 - precision: 0.9587\n",
            "Epoch 437: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.1238 - accuracy: 0.9531 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 1.0000 - recall: 0.9483 - precision: 0.9587 - val_loss: 1.8239 - val_accuracy: 0.6172 - val_sensitivity_at_specificity: 0.7648 - val_specificity_at_sensitivity: 0.7221 - val_recall: 0.9312 - val_precision: 0.5656\n",
            "Epoch 438/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1442 - accuracy: 0.9465 - sensitivity_at_specificity: 0.9976 - specificity_at_sensitivity: 0.9992 - recall: 0.9419 - precision: 0.9487\n",
            "Epoch 438: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.1442 - accuracy: 0.9465 - sensitivity_at_specificity: 0.9976 - specificity_at_sensitivity: 0.9992 - recall: 0.9419 - precision: 0.9487 - val_loss: 1.9170 - val_accuracy: 0.6180 - val_sensitivity_at_specificity: 0.7823 - val_specificity_at_sensitivity: 0.7268 - val_recall: 0.9502 - val_precision: 0.5721\n",
            "Epoch 439/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1244 - accuracy: 0.9473 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9389 - precision: 0.9533\n",
            "Epoch 439: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.1244 - accuracy: 0.9473 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9389 - precision: 0.9533 - val_loss: 1.7082 - val_accuracy: 0.6227 - val_sensitivity_at_specificity: 0.8053 - val_specificity_at_sensitivity: 0.7335 - val_recall: 0.9455 - val_precision: 0.5754\n",
            "Epoch 440/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1334 - accuracy: 0.9527 - sensitivity_at_specificity: 0.9951 - specificity_at_sensitivity: 1.0000 - recall: 0.9510 - precision: 0.9502\n",
            "Epoch 440: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.1334 - accuracy: 0.9527 - sensitivity_at_specificity: 0.9951 - specificity_at_sensitivity: 1.0000 - recall: 0.9510 - precision: 0.9502 - val_loss: 1.6245 - val_accuracy: 0.6289 - val_sensitivity_at_specificity: 0.7762 - val_specificity_at_sensitivity: 0.7323 - val_recall: 0.9159 - val_precision: 0.5776\n",
            "Epoch 441/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1098 - accuracy: 0.9543 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9418 - precision: 0.9641\n",
            "Epoch 441: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 190ms/step - loss: 0.1098 - accuracy: 0.9543 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9418 - precision: 0.9641 - val_loss: 1.8412 - val_accuracy: 0.6023 - val_sensitivity_at_specificity: 0.7963 - val_specificity_at_sensitivity: 0.7201 - val_recall: 0.9596 - val_precision: 0.5403\n",
            "Epoch 442/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1121 - accuracy: 0.9594 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9494 - precision: 0.9665\n",
            "Epoch 442: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.1121 - accuracy: 0.9594 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9494 - precision: 0.9665 - val_loss: 1.8070 - val_accuracy: 0.6328 - val_sensitivity_at_specificity: 0.8305 - val_specificity_at_sensitivity: 0.7614 - val_recall: 0.9580 - val_precision: 0.5817\n",
            "Epoch 443/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0999 - accuracy: 0.9594 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9571 - precision: 0.9602\n",
            "Epoch 443: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 209ms/step - loss: 0.0999 - accuracy: 0.9594 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9571 - precision: 0.9602 - val_loss: 1.8728 - val_accuracy: 0.6258 - val_sensitivity_at_specificity: 0.7735 - val_specificity_at_sensitivity: 0.7306 - val_recall: 0.9384 - val_precision: 0.5811\n",
            "Epoch 444/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1079 - accuracy: 0.9590 - sensitivity_at_specificity: 0.9977 - specificity_at_sensitivity: 1.0000 - recall: 0.9572 - precision: 0.9610\n",
            "Epoch 444: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.1079 - accuracy: 0.9590 - sensitivity_at_specificity: 0.9977 - specificity_at_sensitivity: 1.0000 - recall: 0.9572 - precision: 0.9610 - val_loss: 1.5615 - val_accuracy: 0.6367 - val_sensitivity_at_specificity: 0.8365 - val_specificity_at_sensitivity: 0.7329 - val_recall: 0.9308 - val_precision: 0.5844\n",
            "Epoch 445/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1262 - accuracy: 0.9508 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9522 - precision: 0.9492\n",
            "Epoch 445: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 191ms/step - loss: 0.1262 - accuracy: 0.9508 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9522 - precision: 0.9492 - val_loss: 1.8668 - val_accuracy: 0.6258 - val_sensitivity_at_specificity: 0.7863 - val_specificity_at_sensitivity: 0.7387 - val_recall: 0.9454 - val_precision: 0.5771\n",
            "Epoch 446/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1256 - accuracy: 0.9512 - sensitivity_at_specificity: 0.9969 - specificity_at_sensitivity: 0.9992 - recall: 0.9450 - precision: 0.9589\n",
            "Epoch 446: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.1256 - accuracy: 0.9512 - sensitivity_at_specificity: 0.9969 - specificity_at_sensitivity: 0.9992 - recall: 0.9450 - precision: 0.9589 - val_loss: 1.8824 - val_accuracy: 0.6141 - val_sensitivity_at_specificity: 0.8089 - val_specificity_at_sensitivity: 0.7623 - val_recall: 0.9325 - val_precision: 0.5554\n",
            "Epoch 447/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1226 - accuracy: 0.9539 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9992 - recall: 0.9433 - precision: 0.9604\n",
            "Epoch 447: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.1226 - accuracy: 0.9539 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9992 - recall: 0.9433 - precision: 0.9604 - val_loss: 1.8584 - val_accuracy: 0.6102 - val_sensitivity_at_specificity: 0.7756 - val_specificity_at_sensitivity: 0.7173 - val_recall: 0.9398 - val_precision: 0.5558\n",
            "Epoch 448/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1269 - accuracy: 0.9500 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9421 - precision: 0.9571\n",
            "Epoch 448: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 175ms/step - loss: 0.1269 - accuracy: 0.9500 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9421 - precision: 0.9571 - val_loss: 1.9303 - val_accuracy: 0.6148 - val_sensitivity_at_specificity: 0.7634 - val_specificity_at_sensitivity: 0.7377 - val_recall: 0.9462 - val_precision: 0.5736\n",
            "Epoch 449/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1138 - accuracy: 0.9555 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9506 - precision: 0.9582\n",
            "Epoch 449: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.1138 - accuracy: 0.9555 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9506 - precision: 0.9582 - val_loss: 1.7598 - val_accuracy: 0.6359 - val_sensitivity_at_specificity: 0.8220 - val_specificity_at_sensitivity: 0.7603 - val_recall: 0.9412 - val_precision: 0.5869\n",
            "Epoch 450/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1147 - accuracy: 0.9563 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9508 - precision: 0.9585\n",
            "Epoch 450: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.1147 - accuracy: 0.9563 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9508 - precision: 0.9585 - val_loss: 1.9052 - val_accuracy: 0.6187 - val_sensitivity_at_specificity: 0.7862 - val_specificity_at_sensitivity: 0.7345 - val_recall: 0.9497 - val_precision: 0.5698\n",
            "Epoch 451/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1073 - accuracy: 0.9598 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9502 - precision: 0.9652\n",
            "Epoch 451: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.1073 - accuracy: 0.9598 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9502 - precision: 0.9652 - val_loss: 1.8156 - val_accuracy: 0.5938 - val_sensitivity_at_specificity: 0.7896 - val_specificity_at_sensitivity: 0.7613 - val_recall: 0.9417 - val_precision: 0.5460\n",
            "Epoch 452/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1189 - accuracy: 0.9539 - sensitivity_at_specificity: 0.9976 - specificity_at_sensitivity: 0.9992 - recall: 0.9493 - precision: 0.9569\n",
            "Epoch 452: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.1189 - accuracy: 0.9539 - sensitivity_at_specificity: 0.9976 - specificity_at_sensitivity: 0.9992 - recall: 0.9493 - precision: 0.9569 - val_loss: 1.8573 - val_accuracy: 0.6055 - val_sensitivity_at_specificity: 0.7674 - val_specificity_at_sensitivity: 0.7083 - val_recall: 0.9399 - val_precision: 0.5598\n",
            "Epoch 453/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1094 - accuracy: 0.9625 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 1.0000 - recall: 0.9632 - precision: 0.9632\n",
            "Epoch 453: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.1094 - accuracy: 0.9625 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 1.0000 - recall: 0.9632 - precision: 0.9632 - val_loss: 1.9982 - val_accuracy: 0.6086 - val_sensitivity_at_specificity: 0.7682 - val_specificity_at_sensitivity: 0.7046 - val_recall: 0.9397 - val_precision: 0.5682\n",
            "Epoch 454/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1263 - accuracy: 0.9543 - sensitivity_at_specificity: 0.9945 - specificity_at_sensitivity: 1.0000 - recall: 0.9501 - precision: 0.9583\n",
            "Epoch 454: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.1263 - accuracy: 0.9543 - sensitivity_at_specificity: 0.9945 - specificity_at_sensitivity: 1.0000 - recall: 0.9501 - precision: 0.9583 - val_loss: 1.9137 - val_accuracy: 0.6047 - val_sensitivity_at_specificity: 0.7706 - val_specificity_at_sensitivity: 0.7656 - val_recall: 0.9340 - val_precision: 0.5484\n",
            "Epoch 455/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0978 - accuracy: 0.9625 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9621 - precision: 0.9636\n",
            "Epoch 455: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.0978 - accuracy: 0.9625 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9621 - precision: 0.9636 - val_loss: 1.7449 - val_accuracy: 0.6391 - val_sensitivity_at_specificity: 0.7972 - val_specificity_at_sensitivity: 0.7043 - val_recall: 0.9186 - val_precision: 0.5938\n",
            "Epoch 456/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1145 - accuracy: 0.9539 - sensitivity_at_specificity: 0.9976 - specificity_at_sensitivity: 1.0000 - recall: 0.9474 - precision: 0.9581\n",
            "Epoch 456: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.1145 - accuracy: 0.9539 - sensitivity_at_specificity: 0.9976 - specificity_at_sensitivity: 1.0000 - recall: 0.9474 - precision: 0.9581 - val_loss: 1.9717 - val_accuracy: 0.6172 - val_sensitivity_at_specificity: 0.7702 - val_specificity_at_sensitivity: 0.7154 - val_recall: 0.9519 - val_precision: 0.5718\n",
            "Epoch 457/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1071 - accuracy: 0.9625 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9508 - precision: 0.9724\n",
            "Epoch 457: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.1071 - accuracy: 0.9625 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9508 - precision: 0.9724 - val_loss: 2.0335 - val_accuracy: 0.6297 - val_sensitivity_at_specificity: 0.7719 - val_specificity_at_sensitivity: 0.6893 - val_recall: 0.9653 - val_precision: 0.5862\n",
            "Epoch 458/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1237 - accuracy: 0.9520 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9480 - precision: 0.9548\n",
            "Epoch 458: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 174ms/step - loss: 0.1237 - accuracy: 0.9520 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9480 - precision: 0.9548 - val_loss: 1.9419 - val_accuracy: 0.6117 - val_sensitivity_at_specificity: 0.7737 - val_specificity_at_sensitivity: 0.7253 - val_recall: 0.9430 - val_precision: 0.5639\n",
            "Epoch 459/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1084 - accuracy: 0.9609 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 1.0000 - recall: 0.9515 - precision: 0.9710\n",
            "Epoch 459: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 175ms/step - loss: 0.1084 - accuracy: 0.9609 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 1.0000 - recall: 0.9515 - precision: 0.9710 - val_loss: 1.7606 - val_accuracy: 0.6453 - val_sensitivity_at_specificity: 0.7938 - val_specificity_at_sensitivity: 0.7421 - val_recall: 0.9543 - val_precision: 0.6050\n",
            "Epoch 460/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1002 - accuracy: 0.9617 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9509 - precision: 0.9721\n",
            "Epoch 460: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.1002 - accuracy: 0.9617 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9509 - precision: 0.9721 - val_loss: 2.0132 - val_accuracy: 0.6172 - val_sensitivity_at_specificity: 0.7628 - val_specificity_at_sensitivity: 0.7296 - val_recall: 0.9671 - val_precision: 0.5553\n",
            "Epoch 461/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1249 - accuracy: 0.9512 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9992 - recall: 0.9469 - precision: 0.9537\n",
            "Epoch 461: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.1249 - accuracy: 0.9512 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9992 - recall: 0.9469 - precision: 0.9537 - val_loss: 1.7841 - val_accuracy: 0.6203 - val_sensitivity_at_specificity: 0.7930 - val_specificity_at_sensitivity: 0.7132 - val_recall: 0.9411 - val_precision: 0.5683\n",
            "Epoch 462/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1079 - accuracy: 0.9614 - sensitivity_at_specificity: 0.9991 - specificity_at_sensitivity: 1.0000 - recall: 0.9556 - precision: 0.9647\n",
            "Epoch 462: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.1079 - accuracy: 0.9614 - sensitivity_at_specificity: 0.9991 - specificity_at_sensitivity: 1.0000 - recall: 0.9556 - precision: 0.9647 - val_loss: 2.0235 - val_accuracy: 0.6180 - val_sensitivity_at_specificity: 0.7906 - val_specificity_at_sensitivity: 0.7085 - val_recall: 0.9514 - val_precision: 0.5784\n",
            "Epoch 463/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1040 - accuracy: 0.9637 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9581 - precision: 0.9666\n",
            "Epoch 463: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.1040 - accuracy: 0.9637 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9581 - precision: 0.9666 - val_loss: 1.8116 - val_accuracy: 0.6250 - val_sensitivity_at_specificity: 0.8519 - val_specificity_at_sensitivity: 0.7484 - val_recall: 0.9522 - val_precision: 0.5788\n",
            "Epoch 464/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1048 - accuracy: 0.9590 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9542 - precision: 0.9625\n",
            "Epoch 464: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.1048 - accuracy: 0.9590 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9542 - precision: 0.9625 - val_loss: 2.0061 - val_accuracy: 0.6062 - val_sensitivity_at_specificity: 0.7584 - val_specificity_at_sensitivity: 0.7093 - val_recall: 0.9450 - val_precision: 0.5691\n",
            "Epoch 465/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1283 - accuracy: 0.9516 - sensitivity_at_specificity: 0.9976 - specificity_at_sensitivity: 1.0000 - recall: 0.9402 - precision: 0.9601\n",
            "Epoch 465: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 181ms/step - loss: 0.1283 - accuracy: 0.9516 - sensitivity_at_specificity: 0.9976 - specificity_at_sensitivity: 1.0000 - recall: 0.9402 - precision: 0.9601 - val_loss: 1.6929 - val_accuracy: 0.6031 - val_sensitivity_at_specificity: 0.7984 - val_specificity_at_sensitivity: 0.7138 - val_recall: 0.9333 - val_precision: 0.5579\n",
            "Epoch 466/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1113 - accuracy: 0.9551 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9533 - precision: 0.9540\n",
            "Epoch 466: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.1113 - accuracy: 0.9551 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9533 - precision: 0.9540 - val_loss: 2.0285 - val_accuracy: 0.5984 - val_sensitivity_at_specificity: 0.7852 - val_specificity_at_sensitivity: 0.7104 - val_recall: 0.9574 - val_precision: 0.5448\n",
            "Epoch 467/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1137 - accuracy: 0.9566 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 1.0000 - recall: 0.9572 - precision: 0.9579\n",
            "Epoch 467: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.1137 - accuracy: 0.9566 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 1.0000 - recall: 0.9572 - precision: 0.9579 - val_loss: 1.9526 - val_accuracy: 0.6203 - val_sensitivity_at_specificity: 0.7673 - val_specificity_at_sensitivity: 0.7391 - val_recall: 0.9513 - val_precision: 0.5708\n",
            "Epoch 468/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1089 - accuracy: 0.9609 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9564 - precision: 0.9641\n",
            "Epoch 468: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.1089 - accuracy: 0.9609 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9564 - precision: 0.9641 - val_loss: 2.0348 - val_accuracy: 0.6211 - val_sensitivity_at_specificity: 0.7949 - val_specificity_at_sensitivity: 0.7149 - val_recall: 0.9439 - val_precision: 0.5669\n",
            "Epoch 469/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1186 - accuracy: 0.9527 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9415 - precision: 0.9633\n",
            "Epoch 469: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.1186 - accuracy: 0.9527 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9415 - precision: 0.9633 - val_loss: 2.0374 - val_accuracy: 0.6172 - val_sensitivity_at_specificity: 0.7774 - val_specificity_at_sensitivity: 0.6998 - val_recall: 0.9598 - val_precision: 0.5724\n",
            "Epoch 470/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1134 - accuracy: 0.9563 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 1.0000 - recall: 0.9466 - precision: 0.9660\n",
            "Epoch 470: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.1134 - accuracy: 0.9563 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 1.0000 - recall: 0.9466 - precision: 0.9660 - val_loss: 1.8142 - val_accuracy: 0.6195 - val_sensitivity_at_specificity: 0.7786 - val_specificity_at_sensitivity: 0.6956 - val_recall: 0.9458 - val_precision: 0.5748\n",
            "Epoch 471/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1126 - accuracy: 0.9555 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9509 - precision: 0.9599\n",
            "Epoch 471: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 175ms/step - loss: 0.1126 - accuracy: 0.9555 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9509 - precision: 0.9599 - val_loss: 1.7522 - val_accuracy: 0.6484 - val_sensitivity_at_specificity: 0.7946 - val_specificity_at_sensitivity: 0.7056 - val_recall: 0.9345 - val_precision: 0.6074\n",
            "Epoch 472/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1210 - accuracy: 0.9563 - sensitivity_at_specificity: 0.9976 - specificity_at_sensitivity: 1.0000 - recall: 0.9465 - precision: 0.9634\n",
            "Epoch 472: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.1210 - accuracy: 0.9563 - sensitivity_at_specificity: 0.9976 - specificity_at_sensitivity: 1.0000 - recall: 0.9465 - precision: 0.9634 - val_loss: 1.7492 - val_accuracy: 0.6398 - val_sensitivity_at_specificity: 0.7988 - val_specificity_at_sensitivity: 0.7532 - val_recall: 0.9588 - val_precision: 0.5917\n",
            "Epoch 473/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1125 - accuracy: 0.9563 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9543 - precision: 0.9587\n",
            "Epoch 473: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.1125 - accuracy: 0.9563 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9543 - precision: 0.9587 - val_loss: 1.9741 - val_accuracy: 0.6406 - val_sensitivity_at_specificity: 0.8110 - val_specificity_at_sensitivity: 0.6971 - val_recall: 0.9680 - val_precision: 0.5912\n",
            "Epoch 474/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1012 - accuracy: 0.9629 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9552 - precision: 0.9697\n",
            "Epoch 474: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 174ms/step - loss: 0.1012 - accuracy: 0.9629 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9552 - precision: 0.9697 - val_loss: 2.0427 - val_accuracy: 0.6297 - val_sensitivity_at_specificity: 0.8321 - val_specificity_at_sensitivity: 0.6800 - val_recall: 0.9618 - val_precision: 0.5839\n",
            "Epoch 475/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0968 - accuracy: 0.9641 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9635 - precision: 0.9650\n",
            "Epoch 475: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.0968 - accuracy: 0.9641 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9635 - precision: 0.9650 - val_loss: 2.0740 - val_accuracy: 0.6211 - val_sensitivity_at_specificity: 0.8094 - val_specificity_at_sensitivity: 0.7047 - val_recall: 0.9469 - val_precision: 0.5733\n",
            "Epoch 476/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1031 - accuracy: 0.9629 - sensitivity_at_specificity: 0.9976 - specificity_at_sensitivity: 1.0000 - recall: 0.9581 - precision: 0.9651\n",
            "Epoch 476: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.1031 - accuracy: 0.9629 - sensitivity_at_specificity: 0.9976 - specificity_at_sensitivity: 1.0000 - recall: 0.9581 - precision: 0.9651 - val_loss: 2.4715 - val_accuracy: 0.5922 - val_sensitivity_at_specificity: 0.7190 - val_specificity_at_sensitivity: 0.6205 - val_recall: 0.9623 - val_precision: 0.5518\n",
            "Epoch 477/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1005 - accuracy: 0.9605 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9590 - precision: 0.9613\n",
            "Epoch 477: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.1005 - accuracy: 0.9605 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9590 - precision: 0.9613 - val_loss: 1.9986 - val_accuracy: 0.5883 - val_sensitivity_at_specificity: 0.7548 - val_specificity_at_sensitivity: 0.7362 - val_recall: 0.9252 - val_precision: 0.5476\n",
            "Epoch 478/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0869 - accuracy: 0.9656 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9605 - precision: 0.9710\n",
            "Epoch 478: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.0869 - accuracy: 0.9656 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9605 - precision: 0.9710 - val_loss: 1.8928 - val_accuracy: 0.6359 - val_sensitivity_at_specificity: 0.8215 - val_specificity_at_sensitivity: 0.7264 - val_recall: 0.9421 - val_precision: 0.5768\n",
            "Epoch 479/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1057 - accuracy: 0.9590 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9567 - precision: 0.9605\n",
            "Epoch 479: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.1057 - accuracy: 0.9590 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9567 - precision: 0.9605 - val_loss: 2.0282 - val_accuracy: 0.6258 - val_sensitivity_at_specificity: 0.8018 - val_specificity_at_sensitivity: 0.7138 - val_recall: 0.9432 - val_precision: 0.5814\n",
            "Epoch 480/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1051 - accuracy: 0.9617 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9977 - recall: 0.9518 - precision: 0.9702\n",
            "Epoch 480: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.1051 - accuracy: 0.9617 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9977 - recall: 0.9518 - precision: 0.9702 - val_loss: 2.1860 - val_accuracy: 0.6125 - val_sensitivity_at_specificity: 0.7753 - val_specificity_at_sensitivity: 0.6636 - val_recall: 0.9541 - val_precision: 0.5636\n",
            "Epoch 481/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0948 - accuracy: 0.9637 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9992 - recall: 0.9584 - precision: 0.9669\n",
            "Epoch 481: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.0948 - accuracy: 0.9637 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9992 - recall: 0.9584 - precision: 0.9669 - val_loss: 2.0085 - val_accuracy: 0.6219 - val_sensitivity_at_specificity: 0.7897 - val_specificity_at_sensitivity: 0.7184 - val_recall: 0.9551 - val_precision: 0.5661\n",
            "Epoch 482/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1074 - accuracy: 0.9586 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9542 - precision: 0.9604\n",
            "Epoch 482: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.1074 - accuracy: 0.9586 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9542 - precision: 0.9604 - val_loss: 2.0877 - val_accuracy: 0.5828 - val_sensitivity_at_specificity: 0.7521 - val_specificity_at_sensitivity: 0.7079 - val_recall: 0.9409 - val_precision: 0.5350\n",
            "Epoch 483/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1039 - accuracy: 0.9625 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9535 - precision: 0.9704\n",
            "Epoch 483: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.1039 - accuracy: 0.9625 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9535 - precision: 0.9704 - val_loss: 2.1009 - val_accuracy: 0.6062 - val_sensitivity_at_specificity: 0.7866 - val_specificity_at_sensitivity: 0.7177 - val_recall: 0.9528 - val_precision: 0.5519\n",
            "Epoch 484/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0983 - accuracy: 0.9645 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9598 - precision: 0.9682\n",
            "Epoch 484: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 174ms/step - loss: 0.0983 - accuracy: 0.9645 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9598 - precision: 0.9682 - val_loss: 2.0197 - val_accuracy: 0.6117 - val_sensitivity_at_specificity: 0.7496 - val_specificity_at_sensitivity: 0.7134 - val_recall: 0.9393 - val_precision: 0.5753\n",
            "Epoch 485/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1084 - accuracy: 0.9601 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9585 - precision: 0.9602\n",
            "Epoch 485: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.1084 - accuracy: 0.9601 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9585 - precision: 0.9602 - val_loss: 1.7946 - val_accuracy: 0.6367 - val_sensitivity_at_specificity: 0.8073 - val_specificity_at_sensitivity: 0.7375 - val_recall: 0.9636 - val_precision: 0.5901\n",
            "Epoch 486/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1119 - accuracy: 0.9570 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9543 - precision: 0.9603\n",
            "Epoch 486: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.1119 - accuracy: 0.9570 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9543 - precision: 0.9603 - val_loss: 2.0457 - val_accuracy: 0.6094 - val_sensitivity_at_specificity: 0.8050 - val_specificity_at_sensitivity: 0.6925 - val_recall: 0.9528 - val_precision: 0.5632\n",
            "Epoch 487/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1151 - accuracy: 0.9578 - sensitivity_at_specificity: 0.9977 - specificity_at_sensitivity: 0.9984 - recall: 0.9557 - precision: 0.9616\n",
            "Epoch 487: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.1151 - accuracy: 0.9578 - sensitivity_at_specificity: 0.9977 - specificity_at_sensitivity: 0.9984 - recall: 0.9557 - precision: 0.9616 - val_loss: 1.8685 - val_accuracy: 0.6211 - val_sensitivity_at_specificity: 0.8123 - val_specificity_at_sensitivity: 0.7461 - val_recall: 0.9574 - val_precision: 0.5700\n",
            "Epoch 488/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1149 - accuracy: 0.9598 - sensitivity_at_specificity: 0.9976 - specificity_at_sensitivity: 0.9992 - recall: 0.9556 - precision: 0.9625\n",
            "Epoch 488: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.1149 - accuracy: 0.9598 - sensitivity_at_specificity: 0.9976 - specificity_at_sensitivity: 0.9992 - recall: 0.9556 - precision: 0.9625 - val_loss: 2.1186 - val_accuracy: 0.6109 - val_sensitivity_at_specificity: 0.7716 - val_specificity_at_sensitivity: 0.7049 - val_recall: 0.9345 - val_precision: 0.5614\n",
            "Epoch 489/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1015 - accuracy: 0.9613 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9510 - precision: 0.9689\n",
            "Epoch 489: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.1015 - accuracy: 0.9613 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9510 - precision: 0.9689 - val_loss: 2.0143 - val_accuracy: 0.6313 - val_sensitivity_at_specificity: 0.8088 - val_specificity_at_sensitivity: 0.6791 - val_recall: 0.9671 - val_precision: 0.5777\n",
            "Epoch 490/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1041 - accuracy: 0.9590 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9555 - precision: 0.9622\n",
            "Epoch 490: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.1041 - accuracy: 0.9590 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9555 - precision: 0.9622 - val_loss: 2.1684 - val_accuracy: 0.6219 - val_sensitivity_at_specificity: 0.7579 - val_specificity_at_sensitivity: 0.6537 - val_recall: 0.9701 - val_precision: 0.5702\n",
            "Epoch 491/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0965 - accuracy: 0.9609 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9538 - precision: 0.9688\n",
            "Epoch 491: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 174ms/step - loss: 0.0965 - accuracy: 0.9609 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9538 - precision: 0.9688 - val_loss: 2.2121 - val_accuracy: 0.6055 - val_sensitivity_at_specificity: 0.7535 - val_specificity_at_sensitivity: 0.6688 - val_recall: 0.9384 - val_precision: 0.5670\n",
            "Epoch 492/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.1105 - accuracy: 0.9575 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9991 - recall: 0.9549 - precision: 0.9599\n",
            "Epoch 492: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.1100 - accuracy: 0.9572 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9541 - precision: 0.9597 - val_loss: 2.1076 - val_accuracy: 0.6148 - val_sensitivity_at_specificity: 0.7755 - val_specificity_at_sensitivity: 0.7050 - val_recall: 0.9582 - val_precision: 0.5705\n",
            "Epoch 493/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0992 - accuracy: 0.9590 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9466 - precision: 0.9702\n",
            "Epoch 493: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.0992 - accuracy: 0.9590 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9466 - precision: 0.9702 - val_loss: 2.1385 - val_accuracy: 0.6086 - val_sensitivity_at_specificity: 0.7429 - val_specificity_at_sensitivity: 0.7025 - val_recall: 0.9436 - val_precision: 0.5642\n",
            "Epoch 494/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1187 - accuracy: 0.9523 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9484 - precision: 0.9545\n",
            "Epoch 494: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 174ms/step - loss: 0.1187 - accuracy: 0.9523 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9484 - precision: 0.9545 - val_loss: 2.1715 - val_accuracy: 0.6094 - val_sensitivity_at_specificity: 0.7622 - val_specificity_at_sensitivity: 0.6827 - val_recall: 0.9573 - val_precision: 0.5709\n",
            "Epoch 495/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1018 - accuracy: 0.9621 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9586 - precision: 0.9654\n",
            "Epoch 495: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.1018 - accuracy: 0.9621 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9586 - precision: 0.9654 - val_loss: 2.1376 - val_accuracy: 0.6234 - val_sensitivity_at_specificity: 0.7811 - val_specificity_at_sensitivity: 0.6981 - val_recall: 0.9550 - val_precision: 0.5758\n",
            "Epoch 496/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1132 - accuracy: 0.9598 - sensitivity_at_specificity: 0.9977 - specificity_at_sensitivity: 0.9992 - recall: 0.9532 - precision: 0.9660\n",
            "Epoch 496: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.1132 - accuracy: 0.9598 - sensitivity_at_specificity: 0.9977 - specificity_at_sensitivity: 0.9992 - recall: 0.9532 - precision: 0.9660 - val_loss: 2.0496 - val_accuracy: 0.6086 - val_sensitivity_at_specificity: 0.7839 - val_specificity_at_sensitivity: 0.6924 - val_recall: 0.9565 - val_precision: 0.5558\n",
            "Epoch 497/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0985 - accuracy: 0.9621 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9586 - precision: 0.9667\n",
            "Epoch 497: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.0985 - accuracy: 0.9621 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9586 - precision: 0.9667 - val_loss: 1.9963 - val_accuracy: 0.6305 - val_sensitivity_at_specificity: 0.8071 - val_specificity_at_sensitivity: 0.6962 - val_recall: 0.9599 - val_precision: 0.5819\n",
            "Epoch 498/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0981 - accuracy: 0.9605 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9599 - precision: 0.9591\n",
            "Epoch 498: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.0981 - accuracy: 0.9605 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9599 - precision: 0.9591 - val_loss: 1.8396 - val_accuracy: 0.6211 - val_sensitivity_at_specificity: 0.7732 - val_specificity_at_sensitivity: 0.7034 - val_recall: 0.9185 - val_precision: 0.5699\n",
            "Epoch 499/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0863 - accuracy: 0.9688 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9667 - precision: 0.9712\n",
            "Epoch 499: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 174ms/step - loss: 0.0863 - accuracy: 0.9688 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9667 - precision: 0.9712 - val_loss: 1.9335 - val_accuracy: 0.6328 - val_sensitivity_at_specificity: 0.8562 - val_specificity_at_sensitivity: 0.7202 - val_recall: 0.9473 - val_precision: 0.5757\n",
            "Epoch 500/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0915 - accuracy: 0.9648 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 0.9992 - recall: 0.9592 - precision: 0.9711\n",
            "Epoch 500: val_accuracy did not improve from 0.71328\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.0915 - accuracy: 0.9648 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 0.9992 - recall: 0.9592 - precision: 0.9711 - val_loss: 2.2944 - val_accuracy: 0.6156 - val_sensitivity_at_specificity: 0.8132 - val_specificity_at_sensitivity: 0.6510 - val_recall: 0.9742 - val_precision: 0.5597\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Performance Metrics**"
      ],
      "metadata": {
        "id": "8omq97NTIhkW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Training_Accuracy=history.history['accuracy']\n",
        "Validation_Accuracy=history.history['val_accuracy']\n",
        "Validation_Specificity=history.history['val_specificity_at_sensitivity']\n",
        "Validation_Sensitivity=history.history['val_sensitivity_at_specificity']\n",
        "Validation_Recall=history.history['val_recall']\n",
        "Validation_Precision=history.history['val_precision']\n",
        "Validation_Loss=history.history['val_loss']\n",
        "\n",
        "print(\"Training Accuracy: \",max(Training_Accuracy))\n",
        "print(\"Validation Accuracy: \",max(Validation_Accuracy))\n",
        "print(\"Validation Specificity: \",max(Validation_Specificity))\n",
        "print(\"Validation Sensitivity: \",max(Validation_Sensitivity))\n",
        "print(\"Validation Recall: \",max(Validation_Recall))\n",
        "print(\"Validation Precision: \",max(Validation_Precision))\n",
        "print(\"Validation Loss: \",min(Validation_Loss))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCdS_0U65A0-",
        "outputId": "f37c35e0-8677-404a-ad9e-1fdfd609ddb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy:  0.96875\n",
            "Validation Accuracy:  0.7132812738418579\n",
            "Validation Specificity:  0.8659306168556213\n",
            "Validation Sensitivity:  0.8759936690330505\n",
            "Validation Recall:  1.0\n",
            "Validation Precision:  0.7027818560600281\n",
            "Validation Loss:  0.5541038513183594\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Accuracy Graph**"
      ],
      "metadata": {
        "id": "QJMnWUXxIkVn"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLqjG2X-vdLj",
        "outputId": "6e2465d0-d1c9-440c-a75f-85bbcb5e26ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        }
      },
      "source": [
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loss Graph**"
      ],
      "metadata": {
        "id": "uO95fHQHImYN"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBSAyVfivvHX",
        "outputId": "ce654402-37b2-4c34-c550-9381bd0cb0eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        }
      },
      "source": [
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}