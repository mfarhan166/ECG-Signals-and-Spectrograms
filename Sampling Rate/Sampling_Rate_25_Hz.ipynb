{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sampling Rate 25 Hz.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "7e88OLey6Bgd"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7e88OLey6Bgd"
      },
      "source": [
        "# **Image Classification with Convolutional Neural Networks (CNNs)**\n",
        "\n",
        "Convolutional neural networks (CNNs) are commonly used in data science domain especially for computer vision and image classification tasks. Consider an image classification task. Images consist of pixels which are represented with numbers. In the convolution layer of CNNs, filters (or feature detectors) are applied to the image to extract distinctive features of the image by preserving the spatial relationships among pixels.\n",
        "\n",
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "In a convolution layer, not just one filter is used. Many different filters are applied to the image. Each filter is aimed to capture a different feature such as edges, horizontol lines and so on.\n",
        "\n",
        "Images are highly non-linear so we need to increase the non-linearity in convolution layer. In the convolution layer, rectifier function is applied to increase the non-linearity in the image. Rectifier function acts as an additional filter to break up linearity.\n",
        "\n",
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "Then we have Pooling layer which reduces the size of the feature maps while maintaining the preserved features of the image.\n",
        "\n",
        "In the pooling layer, a box with a specified size is captured and the maximum value in that box is taken. This is maximum pooling. We can also take the sum or mean of values in the box. This box scans through the entire feature map. \n",
        "\n",
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "The advantages of pooling:\n",
        "\n",
        "\n",
        "*   Reducing the size while preserving the features\n",
        "*   Eliminating parts that are not significant\n",
        "*   Introducing spatial variance\n",
        "*   Reducing the number of features and thus reducing the risk of overfitting\n",
        "\n",
        "Now, we need to flatten pooled feature maps in order to feed them to a fully connected layer. After the flattening step, the structure of the remaining part of a convolutional neural network is just like a feed-forward neural network.\n",
        "\n",
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "The resulting array after flattening is used as the input to a Dense layer. The pooled feature maps are flattened and fed through a dense layer.\n",
        "\n",
        "Let's go through an implementation with Keras.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsTzc3oi726u"
      },
      "source": [
        "# **Building a Convolutional Neural Network with Keras**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import Libraries**"
      ],
      "metadata": {
        "id": "S97kMe5kLfSr"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCglDGFy8AhT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "8ddc3450-6742-49c8-c1b4-0449ff4629fa"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "tf.__version__\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import matplotlib.image as mpimg\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "import imageio\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.8.2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#RAR LIBRARY INSTALLATION\n",
        "!pip install patool"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MATi3Uvk6aiS",
        "outputId": "fe4d4dbe-6246-4449-82f3-435107602440"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting patool\n",
            "  Downloading patool-1.12-py2.py3-none-any.whl (77 kB)\n",
            "\u001b[K     || 77 kB 1.1 MB/s \n",
            "\u001b[?25hInstalling collected packages: patool\n",
            "Successfully installed patool-1.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#DATASET EXTRACTION\n",
        "import patoolib\n",
        "patoolib.extract_archive(\"/content/dataset-colab-25.rar\", outdir=\"/content/\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "S5L-5n2q6eGb",
        "outputId": "ce6bac67-420d-4c3c-8026-9d5bcf057d73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "patool: Extracting /content/dataset-colab-25.rar ...\n",
            "patool: running /usr/bin/unrar x -- /content/dataset-colab-25.rar\n",
            "patool:     with cwd='/content/'\n",
            "patool: ... /content/dataset-colab-25.rar extracted to `/content/'.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qf7eW3HC9XVL"
      },
      "source": [
        "**ImageDataGenerator**\n",
        "\n",
        "ImageDataGenerator generates batches of tensor image data with real-time data augmentation. ImageDataGenerator creates many batches of the images by applying random selections and transformations (such as rotating and shifting) in batches. So it increases the diversity of the dataset. Data augmentation increases the diversity of data which is very useful especially when the number of images is limited. Increasing the diversity of the dataset helps to get more accurate results and also prevents the model from overfitting.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0BfyGlJbx0l"
      },
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255) #Normalize the pixel values\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hsimgs7aqt6G"
      },
      "source": [
        "#File path to the folder containin images\n",
        "train_dir = os.path.join('/content/dataset-colab-25/Train')\n",
        "validation_dir = os.path.join('/content/dataset-colab-25/Validation')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NyvlF41oqxEP",
        "outputId": "c765b712-15b8-4e76-df54-a02134e8144d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(64,64),\n",
        "    batch_size=256,\n",
        "    shuffle=True,\n",
        "    class_mode='binary')\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    validation_dir,\n",
        "    target_size=(64,64),\n",
        "    batch_size=256,\n",
        "    shuffle=True,\n",
        "    class_mode='binary')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 33128 images belonging to 2 classes.\n",
            "Found 6780 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3yhwpN_-BaS"
      },
      "source": [
        "**Building the Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSzxq4KDtKN6"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "                                    \n",
        "    # First convolution layer \n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(64, 64, 3),use_bias=True),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "\n",
        "    # Second convolution layer \n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu',use_bias=True),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    \n",
        "\n",
        "    # Third convolution layer  \n",
        "    tf.keras.layers.Conv2D(256, (3,3), activation='relu',use_bias=True),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "\n",
        "  # Fourth convolution layer  \n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu',use_bias=True),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "\n",
        "\n",
        "    # Flatten the pooled feature maps\n",
        "    tf.keras.layers.Flatten(),\n",
        "\n",
        "    # Fully connected hidden layer\n",
        "    tf.keras.layers.Dense(8, activation='relu',use_bias=True),\n",
        "\n",
        "\n",
        "    # Output layer\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid',activity_regularizer=regularizers.L1(0.001))   \n",
        "\n",
        "])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDXufVt4-LFY"
      },
      "source": [
        "**Model Summary**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HU0RFGLtNJb",
        "outputId": "08c30a3c-9036-4547-f6ec-6ffdd88b7e8f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 62, 62, 64)        1792      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 31, 31, 64)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 31, 31, 64)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 29, 29, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 14, 14, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 12, 12, 256)       295168    \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 6, 6, 256)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 6, 6, 256)         0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 4, 4, 64)          147520    \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 2, 2, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 2, 2, 64)          0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 8)                 2056      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 520,401\n",
            "Trainable params: 520,401\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THk8lK3G-cdk"
      },
      "source": [
        "**Optimizer Implementation and model training/validation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBN3GBMItPMH"
      },
      "source": [
        "#from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import SensitivityAtSpecificity,SpecificityAtSensitivity,Recall,Precision\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=Adam(learning_rate=0.001),\n",
        "              metrics=['accuracy',SensitivityAtSpecificity(0.5),SpecificityAtSensitivity(0.5),Recall(0.5),Precision(0.5)])  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Q0MPMwh3EgY"
      },
      "source": [
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('val_accuracy')>0.99): \n",
        "      print(\"\\nReached 99% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "callbacks = myCallback()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7f6gDG3dx9sJ",
        "outputId": "78aab25c-8ae1-43ce-f61b-e733fa4ee002",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "checkpoint = ModelCheckpoint(\"ECG_Spectrogram_Model.h5\", monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
        "\n",
        "history = model.fit(\n",
        "      train_generator,\n",
        "      steps_per_epoch=10, \n",
        "      epochs=500,\n",
        "      verbose=1,\n",
        "      validation_data = validation_generator,\n",
        "      validation_steps=5,\n",
        "      callbacks = [callbacks,checkpoint]\n",
        ") "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6867 - accuracy: 0.5410 - sensitivity_at_specificity: 0.5884 - specificity_at_sensitivity: 0.5521 - recall: 0.3702 - precision: 0.5477\n",
            "Epoch 1: val_accuracy improved from -inf to 0.65312, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 17s 241ms/step - loss: 0.6867 - accuracy: 0.5410 - sensitivity_at_specificity: 0.5884 - specificity_at_sensitivity: 0.5521 - recall: 0.3702 - precision: 0.5477 - val_loss: 0.6646 - val_accuracy: 0.6531 - val_sensitivity_at_specificity: 0.7738 - val_specificity_at_sensitivity: 0.7083 - val_recall: 0.7934 - val_precision: 0.6315\n",
            "Epoch 2/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5155 - accuracy: 0.7488 - sensitivity_at_specificity: 0.9753 - specificity_at_sensitivity: 0.8246 - recall: 0.7975 - precision: 0.7304\n",
            "Epoch 2: val_accuracy improved from 0.65312 to 0.67344, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.5155 - accuracy: 0.7488 - sensitivity_at_specificity: 0.9753 - specificity_at_sensitivity: 0.8246 - recall: 0.7975 - precision: 0.7304 - val_loss: 0.6099 - val_accuracy: 0.6734 - val_sensitivity_at_specificity: 0.8055 - val_specificity_at_sensitivity: 0.7106 - val_recall: 0.9301 - val_precision: 0.6220\n",
            "Epoch 3/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4127 - accuracy: 0.8125 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8577 - recall: 0.9569 - precision: 0.7496\n",
            "Epoch 3: val_accuracy did not improve from 0.67344\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.4127 - accuracy: 0.8125 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8577 - recall: 0.9569 - precision: 0.7496 - val_loss: 0.6198 - val_accuracy: 0.6328 - val_sensitivity_at_specificity: 0.7337 - val_specificity_at_sensitivity: 0.6625 - val_recall: 0.9783 - val_precision: 0.5809\n",
            "Epoch 4/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3912 - accuracy: 0.8246 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8505 - recall: 0.9768 - precision: 0.7574\n",
            "Epoch 4: val_accuracy did not improve from 0.67344\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.3912 - accuracy: 0.8246 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8505 - recall: 0.9768 - precision: 0.7574 - val_loss: 0.6135 - val_accuracy: 0.6461 - val_sensitivity_at_specificity: 0.7723 - val_specificity_at_sensitivity: 0.7365 - val_recall: 0.9523 - val_precision: 0.5946\n",
            "Epoch 5/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3956 - accuracy: 0.8239 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8384 - recall: 0.9750 - precision: 0.7482\n",
            "Epoch 5: val_accuracy did not improve from 0.67344\n",
            "10/10 [==============================] - 2s 207ms/step - loss: 0.3956 - accuracy: 0.8239 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8384 - recall: 0.9750 - precision: 0.7482 - val_loss: 0.5902 - val_accuracy: 0.6555 - val_sensitivity_at_specificity: 0.7904 - val_specificity_at_sensitivity: 0.5723 - val_recall: 0.9658 - val_precision: 0.5975\n",
            "Epoch 6/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3955 - accuracy: 0.8207 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8356 - recall: 0.9847 - precision: 0.7351\n",
            "Epoch 6: val_accuracy did not improve from 0.67344\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.3955 - accuracy: 0.8207 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8356 - recall: 0.9847 - precision: 0.7351 - val_loss: 0.6186 - val_accuracy: 0.6328 - val_sensitivity_at_specificity: 0.7660 - val_specificity_at_sensitivity: 0.5681 - val_recall: 0.9766 - val_precision: 0.5791\n",
            "Epoch 7/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4088 - accuracy: 0.8109 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8023 - recall: 0.9780 - precision: 0.7322\n",
            "Epoch 7: val_accuracy did not improve from 0.67344\n",
            "10/10 [==============================] - 2s 177ms/step - loss: 0.4088 - accuracy: 0.8109 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8023 - recall: 0.9780 - precision: 0.7322 - val_loss: 0.6165 - val_accuracy: 0.6242 - val_sensitivity_at_specificity: 0.7233 - val_specificity_at_sensitivity: 0.5823 - val_recall: 0.9827 - val_precision: 0.5708\n",
            "Epoch 8/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3858 - accuracy: 0.8293 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8428 - recall: 0.9842 - precision: 0.7591\n",
            "Epoch 8: val_accuracy did not improve from 0.67344\n",
            "10/10 [==============================] - 2s 175ms/step - loss: 0.3858 - accuracy: 0.8293 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8428 - recall: 0.9842 - precision: 0.7591 - val_loss: 0.6423 - val_accuracy: 0.6219 - val_sensitivity_at_specificity: 0.8007 - val_specificity_at_sensitivity: 0.6931 - val_recall: 0.9722 - val_precision: 0.5603\n",
            "Epoch 9/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3971 - accuracy: 0.8160 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8546 - recall: 0.9740 - precision: 0.7380\n",
            "Epoch 9: val_accuracy did not improve from 0.67344\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.3971 - accuracy: 0.8160 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8546 - recall: 0.9740 - precision: 0.7380 - val_loss: 0.6246 - val_accuracy: 0.6242 - val_sensitivity_at_specificity: 0.6425 - val_specificity_at_sensitivity: 0.6498 - val_recall: 0.9877 - val_precision: 0.5754\n",
            "Epoch 10/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3945 - accuracy: 0.8246 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8320 - recall: 0.9906 - precision: 0.7428\n",
            "Epoch 10: val_accuracy did not improve from 0.67344\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.3945 - accuracy: 0.8246 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8320 - recall: 0.9906 - precision: 0.7428 - val_loss: 0.6271 - val_accuracy: 0.6219 - val_sensitivity_at_specificity: 0.7500 - val_specificity_at_sensitivity: 0.6104 - val_recall: 0.9873 - val_precision: 0.5657\n",
            "Epoch 11/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3772 - accuracy: 0.8335 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8470 - recall: 0.9829 - precision: 0.7601\n",
            "Epoch 11: val_accuracy did not improve from 0.67344\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.3772 - accuracy: 0.8335 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8470 - recall: 0.9829 - precision: 0.7601 - val_loss: 0.6238 - val_accuracy: 0.6367 - val_sensitivity_at_specificity: 0.7714 - val_specificity_at_sensitivity: 0.5677 - val_recall: 0.9905 - val_precision: 0.5762\n",
            "Epoch 12/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3737 - accuracy: 0.8293 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8780 - recall: 0.9752 - precision: 0.7500\n",
            "Epoch 12: val_accuracy did not improve from 0.67344\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.3737 - accuracy: 0.8293 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8780 - recall: 0.9752 - precision: 0.7500 - val_loss: 0.6050 - val_accuracy: 0.6461 - val_sensitivity_at_specificity: 0.7550 - val_specificity_at_sensitivity: 0.6651 - val_recall: 0.9862 - val_precision: 0.5919\n",
            "Epoch 13/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3703 - accuracy: 0.8332 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8629 - recall: 0.9860 - precision: 0.7558\n",
            "Epoch 13: val_accuracy did not improve from 0.67344\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.3703 - accuracy: 0.8332 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8629 - recall: 0.9860 - precision: 0.7558 - val_loss: 0.5957 - val_accuracy: 0.6508 - val_sensitivity_at_specificity: 0.8103 - val_specificity_at_sensitivity: 0.6838 - val_recall: 0.9906 - val_precision: 0.5890\n",
            "Epoch 14/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3796 - accuracy: 0.8246 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8745 - recall: 0.9854 - precision: 0.7375\n",
            "Epoch 14: val_accuracy did not improve from 0.67344\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.3796 - accuracy: 0.8246 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8745 - recall: 0.9854 - precision: 0.7375 - val_loss: 0.6119 - val_accuracy: 0.6258 - val_sensitivity_at_specificity: 0.8098 - val_specificity_at_sensitivity: 0.7474 - val_recall: 0.9756 - val_precision: 0.5639\n",
            "Epoch 15/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3845 - accuracy: 0.8246 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8579 - recall: 0.9682 - precision: 0.7586\n",
            "Epoch 15: val_accuracy did not improve from 0.67344\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.3845 - accuracy: 0.8246 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8579 - recall: 0.9682 - precision: 0.7586 - val_loss: 0.5858 - val_accuracy: 0.6562 - val_sensitivity_at_specificity: 0.8439 - val_specificity_at_sensitivity: 0.7773 - val_recall: 0.9845 - val_precision: 0.5970\n",
            "Epoch 16/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3842 - accuracy: 0.8301 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8468 - recall: 0.9946 - precision: 0.7513\n",
            "Epoch 16: val_accuracy did not improve from 0.67344\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.3842 - accuracy: 0.8301 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8468 - recall: 0.9946 - precision: 0.7513 - val_loss: 0.5859 - val_accuracy: 0.6508 - val_sensitivity_at_specificity: 0.8138 - val_specificity_at_sensitivity: 0.7410 - val_recall: 0.9797 - val_precision: 0.5906\n",
            "Epoch 17/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3836 - accuracy: 0.8297 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8440 - recall: 0.9876 - precision: 0.7522\n",
            "Epoch 17: val_accuracy did not improve from 0.67344\n",
            "10/10 [==============================] - 2s 181ms/step - loss: 0.3836 - accuracy: 0.8297 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8440 - recall: 0.9876 - precision: 0.7522 - val_loss: 0.6009 - val_accuracy: 0.6406 - val_sensitivity_at_specificity: 0.8143 - val_specificity_at_sensitivity: 0.7523 - val_recall: 0.9788 - val_precision: 0.5735\n",
            "Epoch 18/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3747 - accuracy: 0.8305 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8754 - recall: 0.9890 - precision: 0.7503\n",
            "Epoch 18: val_accuracy did not improve from 0.67344\n",
            "10/10 [==============================] - 2s 183ms/step - loss: 0.3747 - accuracy: 0.8305 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8754 - recall: 0.9890 - precision: 0.7503 - val_loss: 0.6061 - val_accuracy: 0.6367 - val_sensitivity_at_specificity: 0.8544 - val_specificity_at_sensitivity: 0.7855 - val_recall: 0.9842 - val_precision: 0.5775\n",
            "Epoch 19/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3802 - accuracy: 0.8270 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8763 - recall: 0.9758 - precision: 0.7585\n",
            "Epoch 19: val_accuracy did not improve from 0.67344\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.3802 - accuracy: 0.8270 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8763 - recall: 0.9758 - precision: 0.7585 - val_loss: 0.6607 - val_accuracy: 0.6187 - val_sensitivity_at_specificity: 0.7698 - val_specificity_at_sensitivity: 0.6876 - val_recall: 1.0000 - val_precision: 0.5685\n",
            "Epoch 20/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3750 - accuracy: 0.8344 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8521 - recall: 0.9891 - precision: 0.7557\n",
            "Epoch 20: val_accuracy did not improve from 0.67344\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.3750 - accuracy: 0.8344 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8521 - recall: 0.9891 - precision: 0.7557 - val_loss: 0.6138 - val_accuracy: 0.6406 - val_sensitivity_at_specificity: 0.8069 - val_specificity_at_sensitivity: 0.7163 - val_recall: 0.9922 - val_precision: 0.5833\n",
            "Epoch 21/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3851 - accuracy: 0.8227 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8746 - recall: 0.9840 - precision: 0.7413\n",
            "Epoch 21: val_accuracy did not improve from 0.67344\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.3851 - accuracy: 0.8227 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8746 - recall: 0.9840 - precision: 0.7413 - val_loss: 0.6496 - val_accuracy: 0.6195 - val_sensitivity_at_specificity: 0.8145 - val_specificity_at_sensitivity: 0.7727 - val_recall: 0.9984 - val_precision: 0.5602\n",
            "Epoch 22/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3711 - accuracy: 0.8277 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8789 - recall: 0.9904 - precision: 0.7434\n",
            "Epoch 22: val_accuracy did not improve from 0.67344\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.3711 - accuracy: 0.8277 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8789 - recall: 0.9904 - precision: 0.7434 - val_loss: 0.6020 - val_accuracy: 0.6547 - val_sensitivity_at_specificity: 0.8460 - val_specificity_at_sensitivity: 0.7933 - val_recall: 0.9939 - val_precision: 0.5982\n",
            "Epoch 23/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3816 - accuracy: 0.8242 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8738 - recall: 0.9781 - precision: 0.7473\n",
            "Epoch 23: val_accuracy did not improve from 0.67344\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.3816 - accuracy: 0.8242 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8738 - recall: 0.9781 - precision: 0.7473 - val_loss: 0.6081 - val_accuracy: 0.6227 - val_sensitivity_at_specificity: 0.8433 - val_specificity_at_sensitivity: 0.7588 - val_recall: 0.9817 - val_precision: 0.5551\n",
            "Epoch 24/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3752 - accuracy: 0.8258 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8760 - recall: 0.9827 - precision: 0.7464\n",
            "Epoch 24: val_accuracy did not improve from 0.67344\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.3752 - accuracy: 0.8258 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8760 - recall: 0.9827 - precision: 0.7464 - val_loss: 0.5854 - val_accuracy: 0.6570 - val_sensitivity_at_specificity: 0.7854 - val_specificity_at_sensitivity: 0.7619 - val_recall: 0.9806 - val_precision: 0.6070\n",
            "Epoch 25/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3745 - accuracy: 0.8238 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8878 - recall: 0.9842 - precision: 0.7433\n",
            "Epoch 25: val_accuracy did not improve from 0.67344\n",
            "10/10 [==============================] - 2s 182ms/step - loss: 0.3745 - accuracy: 0.8238 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8878 - recall: 0.9842 - precision: 0.7433 - val_loss: 0.6258 - val_accuracy: 0.6250 - val_sensitivity_at_specificity: 0.8245 - val_specificity_at_sensitivity: 0.7695 - val_recall: 0.9953 - val_precision: 0.5710\n",
            "Epoch 26/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3692 - accuracy: 0.8281 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8836 - recall: 0.9857 - precision: 0.7469\n",
            "Epoch 26: val_accuracy did not improve from 0.67344\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.3692 - accuracy: 0.8281 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8836 - recall: 0.9857 - precision: 0.7469 - val_loss: 0.6056 - val_accuracy: 0.6570 - val_sensitivity_at_specificity: 0.7997 - val_specificity_at_sensitivity: 0.7250 - val_recall: 0.9970 - val_precision: 0.6042\n",
            "Epoch 27/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3738 - accuracy: 0.8277 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8693 - recall: 0.9805 - precision: 0.7513\n",
            "Epoch 27: val_accuracy did not improve from 0.67344\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.3738 - accuracy: 0.8277 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8693 - recall: 0.9805 - precision: 0.7513 - val_loss: 0.6389 - val_accuracy: 0.6367 - val_sensitivity_at_specificity: 0.8695 - val_specificity_at_sensitivity: 0.6747 - val_recall: 0.9985 - val_precision: 0.5865\n",
            "Epoch 28/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3677 - accuracy: 0.8301 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8714 - recall: 0.9880 - precision: 0.7468\n",
            "Epoch 28: val_accuracy did not improve from 0.67344\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.3677 - accuracy: 0.8301 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8714 - recall: 0.9880 - precision: 0.7468 - val_loss: 0.6375 - val_accuracy: 0.6250 - val_sensitivity_at_specificity: 0.8109 - val_specificity_at_sensitivity: 0.7256 - val_recall: 1.0000 - val_precision: 0.5652\n",
            "Epoch 29/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3724 - accuracy: 0.8281 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8780 - recall: 0.9880 - precision: 0.7437\n",
            "Epoch 29: val_accuracy did not improve from 0.67344\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.3724 - accuracy: 0.8281 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8780 - recall: 0.9880 - precision: 0.7437 - val_loss: 0.5851 - val_accuracy: 0.6516 - val_sensitivity_at_specificity: 0.8627 - val_specificity_at_sensitivity: 0.7919 - val_recall: 0.9813 - val_precision: 0.5917\n",
            "Epoch 30/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3689 - accuracy: 0.8310 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8931 - recall: 0.9803 - precision: 0.7574\n",
            "Epoch 30: val_accuracy did not improve from 0.67344\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.3689 - accuracy: 0.8310 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8931 - recall: 0.9803 - precision: 0.7574 - val_loss: 0.5784 - val_accuracy: 0.6531 - val_sensitivity_at_specificity: 0.8813 - val_specificity_at_sensitivity: 0.8009 - val_recall: 0.9636 - val_precision: 0.5913\n",
            "Epoch 31/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3657 - accuracy: 0.8316 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8932 - recall: 0.9833 - precision: 0.7511\n",
            "Epoch 31: val_accuracy did not improve from 0.67344\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.3657 - accuracy: 0.8316 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8932 - recall: 0.9833 - precision: 0.7511 - val_loss: 0.6156 - val_accuracy: 0.6320 - val_sensitivity_at_specificity: 0.8386 - val_specificity_at_sensitivity: 0.7819 - val_recall: 0.9890 - val_precision: 0.5763\n",
            "Epoch 32/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3540 - accuracy: 0.8363 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9057 - recall: 0.9809 - precision: 0.7572\n",
            "Epoch 32: val_accuracy did not improve from 0.67344\n",
            "10/10 [==============================] - 2s 181ms/step - loss: 0.3540 - accuracy: 0.8363 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9057 - recall: 0.9809 - precision: 0.7572 - val_loss: 0.5875 - val_accuracy: 0.6602 - val_sensitivity_at_specificity: 0.8752 - val_specificity_at_sensitivity: 0.7971 - val_recall: 0.9815 - val_precision: 0.6009\n",
            "Epoch 33/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3705 - accuracy: 0.8305 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8857 - recall: 0.9814 - precision: 0.7555\n",
            "Epoch 33: val_accuracy did not improve from 0.67344\n",
            "10/10 [==============================] - 2s 174ms/step - loss: 0.3705 - accuracy: 0.8305 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8857 - recall: 0.9814 - precision: 0.7555 - val_loss: 0.6221 - val_accuracy: 0.6305 - val_sensitivity_at_specificity: 0.8182 - val_specificity_at_sensitivity: 0.7512 - val_recall: 0.9954 - val_precision: 0.5789\n",
            "Epoch 34/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3907 - accuracy: 0.8125 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8757 - recall: 0.9804 - precision: 0.7328\n",
            "Epoch 34: val_accuracy did not improve from 0.67344\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.3907 - accuracy: 0.8125 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8757 - recall: 0.9804 - precision: 0.7328 - val_loss: 0.5831 - val_accuracy: 0.6555 - val_sensitivity_at_specificity: 0.8414 - val_specificity_at_sensitivity: 0.7714 - val_recall: 0.9733 - val_precision: 0.5939\n",
            "Epoch 35/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3605 - accuracy: 0.8395 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8933 - recall: 0.9907 - precision: 0.7628\n",
            "Epoch 35: val_accuracy did not improve from 0.67344\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.3605 - accuracy: 0.8395 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8933 - recall: 0.9907 - precision: 0.7628 - val_loss: 0.5935 - val_accuracy: 0.6531 - val_sensitivity_at_specificity: 0.8768 - val_specificity_at_sensitivity: 0.7944 - val_recall: 0.9858 - val_precision: 0.5892\n",
            "Epoch 36/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3626 - accuracy: 0.8320 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8878 - recall: 0.9782 - precision: 0.7644\n",
            "Epoch 36: val_accuracy did not improve from 0.67344\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.3626 - accuracy: 0.8320 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8878 - recall: 0.9782 - precision: 0.7644 - val_loss: 0.6015 - val_accuracy: 0.6523 - val_sensitivity_at_specificity: 0.8393 - val_specificity_at_sensitivity: 0.7296 - val_recall: 0.9775 - val_precision: 0.6022\n",
            "Epoch 37/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3623 - accuracy: 0.8309 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8994 - recall: 0.9834 - precision: 0.7517\n",
            "Epoch 37: val_accuracy did not improve from 0.67344\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.3623 - accuracy: 0.8309 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8994 - recall: 0.9834 - precision: 0.7517 - val_loss: 0.6267 - val_accuracy: 0.6367 - val_sensitivity_at_specificity: 0.8313 - val_specificity_at_sensitivity: 0.7161 - val_recall: 0.9985 - val_precision: 0.5816\n",
            "Epoch 38/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3799 - accuracy: 0.8258 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8732 - recall: 0.9678 - precision: 0.7529\n",
            "Epoch 38: val_accuracy did not improve from 0.67344\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.3799 - accuracy: 0.8258 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8732 - recall: 0.9678 - precision: 0.7529 - val_loss: 0.6485 - val_accuracy: 0.6406 - val_sensitivity_at_specificity: 0.8034 - val_specificity_at_sensitivity: 0.6449 - val_recall: 1.0000 - val_precision: 0.6024\n",
            "Epoch 39/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3736 - accuracy: 0.8340 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8644 - recall: 0.9929 - precision: 0.7518\n",
            "Epoch 39: val_accuracy did not improve from 0.67344\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.3736 - accuracy: 0.8340 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8644 - recall: 0.9929 - precision: 0.7518 - val_loss: 0.6143 - val_accuracy: 0.6320 - val_sensitivity_at_specificity: 0.8489 - val_specificity_at_sensitivity: 0.7351 - val_recall: 0.9969 - val_precision: 0.5771\n",
            "Epoch 40/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3696 - accuracy: 0.8324 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8874 - recall: 0.9808 - precision: 0.7592\n",
            "Epoch 40: val_accuracy did not improve from 0.67344\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.3696 - accuracy: 0.8324 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8874 - recall: 0.9808 - precision: 0.7592 - val_loss: 0.5943 - val_accuracy: 0.6461 - val_sensitivity_at_specificity: 0.8186 - val_specificity_at_sensitivity: 0.7709 - val_recall: 0.9590 - val_precision: 0.5874\n",
            "Epoch 41/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3707 - accuracy: 0.8324 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8814 - recall: 0.9868 - precision: 0.7551\n",
            "Epoch 41: val_accuracy did not improve from 0.67344\n",
            "10/10 [==============================] - 2s 174ms/step - loss: 0.3707 - accuracy: 0.8324 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8814 - recall: 0.9868 - precision: 0.7551 - val_loss: 0.6172 - val_accuracy: 0.6305 - val_sensitivity_at_specificity: 0.8373 - val_specificity_at_sensitivity: 0.7764 - val_recall: 0.9968 - val_precision: 0.5703\n",
            "Epoch 42/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3643 - accuracy: 0.8289 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8954 - recall: 0.9807 - precision: 0.7462\n",
            "Epoch 42: val_accuracy did not improve from 0.67344\n",
            "10/10 [==============================] - 2s 176ms/step - loss: 0.3643 - accuracy: 0.8289 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8954 - recall: 0.9807 - precision: 0.7462 - val_loss: 0.5802 - val_accuracy: 0.6633 - val_sensitivity_at_specificity: 0.8669 - val_specificity_at_sensitivity: 0.7618 - val_recall: 0.9675 - val_precision: 0.6039\n",
            "Epoch 43/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3713 - accuracy: 0.8266 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8836 - recall: 0.9841 - precision: 0.7443\n",
            "Epoch 43: val_accuracy did not improve from 0.67344\n",
            "10/10 [==============================] - 2s 174ms/step - loss: 0.3713 - accuracy: 0.8266 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8836 - recall: 0.9841 - precision: 0.7443 - val_loss: 0.5933 - val_accuracy: 0.6484 - val_sensitivity_at_specificity: 0.8722 - val_specificity_at_sensitivity: 0.7931 - val_recall: 0.9887 - val_precision: 0.5797\n",
            "Epoch 44/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3557 - accuracy: 0.8375 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8974 - recall: 0.9715 - precision: 0.7637\n",
            "Epoch 44: val_accuracy did not improve from 0.67344\n",
            "10/10 [==============================] - 2s 175ms/step - loss: 0.3557 - accuracy: 0.8375 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8974 - recall: 0.9715 - precision: 0.7637 - val_loss: 0.5727 - val_accuracy: 0.6719 - val_sensitivity_at_specificity: 0.8857 - val_specificity_at_sensitivity: 0.7740 - val_recall: 0.9805 - val_precision: 0.6157\n",
            "Epoch 45/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3571 - accuracy: 0.8395 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8764 - recall: 0.9815 - precision: 0.7584\n",
            "Epoch 45: val_accuracy did not improve from 0.67344\n",
            "10/10 [==============================] - 2s 187ms/step - loss: 0.3571 - accuracy: 0.8395 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8764 - recall: 0.9815 - precision: 0.7584 - val_loss: 0.5947 - val_accuracy: 0.6547 - val_sensitivity_at_specificity: 0.8513 - val_specificity_at_sensitivity: 0.7239 - val_recall: 0.9953 - val_precision: 0.5916\n",
            "Epoch 46/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3633 - accuracy: 0.8383 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8802 - recall: 0.9771 - precision: 0.7690\n",
            "Epoch 46: val_accuracy did not improve from 0.67344\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.3633 - accuracy: 0.8383 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8802 - recall: 0.9771 - precision: 0.7690 - val_loss: 0.5898 - val_accuracy: 0.6578 - val_sensitivity_at_specificity: 0.8681 - val_specificity_at_sensitivity: 0.7543 - val_recall: 0.9812 - val_precision: 0.5947\n",
            "Epoch 47/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3700 - accuracy: 0.8395 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8629 - recall: 0.9938 - precision: 0.7610\n",
            "Epoch 47: val_accuracy did not improve from 0.67344\n",
            "10/10 [==============================] - 2s 175ms/step - loss: 0.3700 - accuracy: 0.8395 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8629 - recall: 0.9938 - precision: 0.7610 - val_loss: 0.5717 - val_accuracy: 0.6703 - val_sensitivity_at_specificity: 0.8186 - val_specificity_at_sensitivity: 0.7684 - val_recall: 0.9730 - val_precision: 0.6163\n",
            "Epoch 48/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3676 - accuracy: 0.8316 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8810 - recall: 0.9864 - precision: 0.7599\n",
            "Epoch 48: val_accuracy improved from 0.67344 to 0.68203, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.3676 - accuracy: 0.8316 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8810 - recall: 0.9864 - precision: 0.7599 - val_loss: 0.5700 - val_accuracy: 0.6820 - val_sensitivity_at_specificity: 0.8535 - val_specificity_at_sensitivity: 0.7832 - val_recall: 0.9668 - val_precision: 0.6244\n",
            "Epoch 49/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3599 - accuracy: 0.8324 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8921 - recall: 0.9699 - precision: 0.7579\n",
            "Epoch 49: val_accuracy did not improve from 0.68203\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.3599 - accuracy: 0.8324 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8921 - recall: 0.9699 - precision: 0.7579 - val_loss: 0.6209 - val_accuracy: 0.6367 - val_sensitivity_at_specificity: 0.8325 - val_specificity_at_sensitivity: 0.7218 - val_recall: 0.9821 - val_precision: 0.5709\n",
            "Epoch 50/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3712 - accuracy: 0.8258 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8872 - recall: 0.9826 - precision: 0.7458\n",
            "Epoch 50: val_accuracy did not improve from 0.68203\n",
            "10/10 [==============================] - 2s 175ms/step - loss: 0.3712 - accuracy: 0.8258 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8872 - recall: 0.9826 - precision: 0.7458 - val_loss: 0.5956 - val_accuracy: 0.6586 - val_sensitivity_at_specificity: 0.8110 - val_specificity_at_sensitivity: 0.7533 - val_recall: 0.9911 - val_precision: 0.6071\n",
            "Epoch 51/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3485 - accuracy: 0.8477 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8817 - recall: 0.9882 - precision: 0.7706\n",
            "Epoch 51: val_accuracy did not improve from 0.68203\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.3485 - accuracy: 0.8477 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8817 - recall: 0.9882 - precision: 0.7706 - val_loss: 0.6181 - val_accuracy: 0.6531 - val_sensitivity_at_specificity: 0.8674 - val_specificity_at_sensitivity: 0.7869 - val_recall: 0.9893 - val_precision: 0.5976\n",
            "Epoch 52/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3496 - accuracy: 0.8461 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8869 - recall: 0.9866 - precision: 0.7686\n",
            "Epoch 52: val_accuracy did not improve from 0.68203\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.3496 - accuracy: 0.8461 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8869 - recall: 0.9866 - precision: 0.7686 - val_loss: 0.6221 - val_accuracy: 0.6430 - val_sensitivity_at_specificity: 0.8435 - val_specificity_at_sensitivity: 0.7749 - val_recall: 0.9954 - val_precision: 0.5906\n",
            "Epoch 53/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3569 - accuracy: 0.8418 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8726 - recall: 0.9877 - precision: 0.7669\n",
            "Epoch 53: val_accuracy did not improve from 0.68203\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.3569 - accuracy: 0.8418 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8726 - recall: 0.9877 - precision: 0.7669 - val_loss: 0.6451 - val_accuracy: 0.6227 - val_sensitivity_at_specificity: 0.8280 - val_specificity_at_sensitivity: 0.7469 - val_recall: 0.9904 - val_precision: 0.5660\n",
            "Epoch 54/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3724 - accuracy: 0.8234 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8863 - recall: 0.9734 - precision: 0.7482\n",
            "Epoch 54: val_accuracy did not improve from 0.68203\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.3724 - accuracy: 0.8234 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8863 - recall: 0.9734 - precision: 0.7482 - val_loss: 0.6241 - val_accuracy: 0.6422 - val_sensitivity_at_specificity: 0.8460 - val_specificity_at_sensitivity: 0.7237 - val_recall: 0.9876 - val_precision: 0.5853\n",
            "Epoch 55/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3418 - accuracy: 0.8504 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8984 - recall: 0.9814 - precision: 0.7791\n",
            "Epoch 55: val_accuracy did not improve from 0.68203\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.3418 - accuracy: 0.8504 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8984 - recall: 0.9814 - precision: 0.7791 - val_loss: 0.5857 - val_accuracy: 0.6664 - val_sensitivity_at_specificity: 0.8525 - val_specificity_at_sensitivity: 0.7838 - val_recall: 0.9631 - val_precision: 0.6087\n",
            "Epoch 56/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3589 - accuracy: 0.8297 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9029 - recall: 0.9509 - precision: 0.7590\n",
            "Epoch 56: val_accuracy did not improve from 0.68203\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.3589 - accuracy: 0.8297 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9029 - recall: 0.9509 - precision: 0.7590 - val_loss: 0.6416 - val_accuracy: 0.6336 - val_sensitivity_at_specificity: 0.8482 - val_specificity_at_sensitivity: 0.7737 - val_recall: 0.9904 - val_precision: 0.5725\n",
            "Epoch 57/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3546 - accuracy: 0.8516 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8806 - recall: 0.9918 - precision: 0.7835\n",
            "Epoch 57: val_accuracy did not improve from 0.68203\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.3546 - accuracy: 0.8516 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8806 - recall: 0.9918 - precision: 0.7835 - val_loss: 0.6369 - val_accuracy: 0.6180 - val_sensitivity_at_specificity: 0.8220 - val_specificity_at_sensitivity: 0.7395 - val_recall: 0.9921 - val_precision: 0.5655\n",
            "Epoch 58/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3523 - accuracy: 0.8414 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9076 - recall: 0.9908 - precision: 0.7616\n",
            "Epoch 58: val_accuracy improved from 0.68203 to 0.68750, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.3523 - accuracy: 0.8414 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9076 - recall: 0.9908 - precision: 0.7616 - val_loss: 0.5634 - val_accuracy: 0.6875 - val_sensitivity_at_specificity: 0.8716 - val_specificity_at_sensitivity: 0.7787 - val_recall: 0.9537 - val_precision: 0.6339\n",
            "Epoch 59/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3623 - accuracy: 0.8293 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8961 - recall: 0.9548 - precision: 0.7601\n",
            "Epoch 59: val_accuracy did not improve from 0.68750\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.3623 - accuracy: 0.8293 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8961 - recall: 0.9548 - precision: 0.7601 - val_loss: 0.6619 - val_accuracy: 0.6180 - val_sensitivity_at_specificity: 0.8125 - val_specificity_at_sensitivity: 0.7703 - val_recall: 0.9906 - val_precision: 0.5676\n",
            "Epoch 60/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3563 - accuracy: 0.8363 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9080 - recall: 0.9775 - precision: 0.7635\n",
            "Epoch 60: val_accuracy improved from 0.68750 to 0.69141, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 176ms/step - loss: 0.3563 - accuracy: 0.8363 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9080 - recall: 0.9775 - precision: 0.7635 - val_loss: 0.5637 - val_accuracy: 0.6914 - val_sensitivity_at_specificity: 0.8874 - val_specificity_at_sensitivity: 0.7719 - val_recall: 0.9659 - val_precision: 0.6367\n",
            "Epoch 61/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3587 - accuracy: 0.8402 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8904 - recall: 0.9576 - precision: 0.7745\n",
            "Epoch 61: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.3587 - accuracy: 0.8402 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8904 - recall: 0.9576 - precision: 0.7745 - val_loss: 0.6450 - val_accuracy: 0.6070 - val_sensitivity_at_specificity: 0.8464 - val_specificity_at_sensitivity: 0.6755 - val_recall: 0.9750 - val_precision: 0.5448\n",
            "Epoch 62/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3595 - accuracy: 0.8409 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8889 - recall: 0.9862 - precision: 0.7681\n",
            "Epoch 62: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.3595 - accuracy: 0.8409 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8889 - recall: 0.9862 - precision: 0.7681 - val_loss: 0.6005 - val_accuracy: 0.6531 - val_sensitivity_at_specificity: 0.8368 - val_specificity_at_sensitivity: 0.7231 - val_recall: 0.9564 - val_precision: 0.5867\n",
            "Epoch 63/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3565 - accuracy: 0.8402 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8917 - recall: 0.9804 - precision: 0.7653\n",
            "Epoch 63: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.3565 - accuracy: 0.8402 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8917 - recall: 0.9804 - precision: 0.7653 - val_loss: 0.6220 - val_accuracy: 0.6453 - val_sensitivity_at_specificity: 0.8605 - val_specificity_at_sensitivity: 0.7386 - val_recall: 0.9814 - val_precision: 0.5888\n",
            "Epoch 64/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3612 - accuracy: 0.8379 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8916 - recall: 0.9671 - precision: 0.7682\n",
            "Epoch 64: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.3612 - accuracy: 0.8379 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8916 - recall: 0.9671 - precision: 0.7682 - val_loss: 0.6086 - val_accuracy: 0.6562 - val_sensitivity_at_specificity: 0.8617 - val_specificity_at_sensitivity: 0.7412 - val_recall: 0.9818 - val_precision: 0.6015\n",
            "Epoch 65/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3494 - accuracy: 0.8414 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9086 - recall: 0.9777 - precision: 0.7715\n",
            "Epoch 65: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.3494 - accuracy: 0.8414 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9086 - recall: 0.9777 - precision: 0.7715 - val_loss: 0.6070 - val_accuracy: 0.6500 - val_sensitivity_at_specificity: 0.8685 - val_specificity_at_sensitivity: 0.7473 - val_recall: 0.9572 - val_precision: 0.5893\n",
            "Epoch 66/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3431 - accuracy: 0.8449 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9138 - recall: 0.9654 - precision: 0.7769\n",
            "Epoch 66: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.3431 - accuracy: 0.8449 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9138 - recall: 0.9654 - precision: 0.7769 - val_loss: 0.6065 - val_accuracy: 0.6406 - val_sensitivity_at_specificity: 0.8569 - val_specificity_at_sensitivity: 0.7477 - val_recall: 0.9566 - val_precision: 0.5788\n",
            "Epoch 67/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3676 - accuracy: 0.8309 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8926 - recall: 0.9805 - precision: 0.7623\n",
            "Epoch 67: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 174ms/step - loss: 0.3676 - accuracy: 0.8309 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8926 - recall: 0.9805 - precision: 0.7623 - val_loss: 0.5935 - val_accuracy: 0.6570 - val_sensitivity_at_specificity: 0.8517 - val_specificity_at_sensitivity: 0.7561 - val_recall: 0.9516 - val_precision: 0.6071\n",
            "Epoch 68/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3588 - accuracy: 0.8395 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9031 - recall: 0.9637 - precision: 0.7781\n",
            "Epoch 68: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 176ms/step - loss: 0.3588 - accuracy: 0.8395 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9031 - recall: 0.9637 - precision: 0.7781 - val_loss: 0.6155 - val_accuracy: 0.6516 - val_sensitivity_at_specificity: 0.8313 - val_specificity_at_sensitivity: 0.7106 - val_recall: 0.9392 - val_precision: 0.6035\n",
            "Epoch 69/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3534 - accuracy: 0.8422 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8928 - recall: 0.9674 - precision: 0.7795\n",
            "Epoch 69: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.3534 - accuracy: 0.8422 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8928 - recall: 0.9674 - precision: 0.7795 - val_loss: 0.5989 - val_accuracy: 0.6594 - val_sensitivity_at_specificity: 0.8398 - val_specificity_at_sensitivity: 0.7211 - val_recall: 0.9630 - val_precision: 0.6027\n",
            "Epoch 70/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3478 - accuracy: 0.8469 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8942 - recall: 0.9755 - precision: 0.7737\n",
            "Epoch 70: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.3478 - accuracy: 0.8469 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8942 - recall: 0.9755 - precision: 0.7737 - val_loss: 0.6251 - val_accuracy: 0.6547 - val_sensitivity_at_specificity: 0.8576 - val_specificity_at_sensitivity: 0.7145 - val_recall: 0.9828 - val_precision: 0.5930\n",
            "Epoch 71/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3601 - accuracy: 0.8328 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8886 - recall: 0.9605 - precision: 0.7630\n",
            "Epoch 71: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 174ms/step - loss: 0.3601 - accuracy: 0.8328 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8886 - recall: 0.9605 - precision: 0.7630 - val_loss: 0.6492 - val_accuracy: 0.6195 - val_sensitivity_at_specificity: 0.8372 - val_specificity_at_sensitivity: 0.6942 - val_recall: 0.9844 - val_precision: 0.5687\n",
            "Epoch 72/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3458 - accuracy: 0.8422 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9105 - recall: 0.9712 - precision: 0.7729\n",
            "Epoch 72: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.3458 - accuracy: 0.8422 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9105 - recall: 0.9712 - precision: 0.7729 - val_loss: 0.6138 - val_accuracy: 0.6617 - val_sensitivity_at_specificity: 0.8341 - val_specificity_at_sensitivity: 0.7601 - val_recall: 0.9442 - val_precision: 0.6125\n",
            "Epoch 73/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3622 - accuracy: 0.8277 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8992 - recall: 0.9339 - precision: 0.7686\n",
            "Epoch 73: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.3622 - accuracy: 0.8277 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8992 - recall: 0.9339 - precision: 0.7686 - val_loss: 0.6070 - val_accuracy: 0.6500 - val_sensitivity_at_specificity: 0.8457 - val_specificity_at_sensitivity: 0.7581 - val_recall: 0.9748 - val_precision: 0.5890\n",
            "Epoch 74/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3558 - accuracy: 0.8320 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9043 - recall: 0.9799 - precision: 0.7506\n",
            "Epoch 74: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.3558 - accuracy: 0.8320 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9043 - recall: 0.9799 - precision: 0.7506 - val_loss: 0.6144 - val_accuracy: 0.6531 - val_sensitivity_at_specificity: 0.8522 - val_specificity_at_sensitivity: 0.7158 - val_recall: 0.9796 - val_precision: 0.5911\n",
            "Epoch 75/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3531 - accuracy: 0.8410 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8950 - recall: 0.9747 - precision: 0.7725\n",
            "Epoch 75: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.3531 - accuracy: 0.8410 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8950 - recall: 0.9747 - precision: 0.7725 - val_loss: 0.6579 - val_accuracy: 0.6297 - val_sensitivity_at_specificity: 0.8341 - val_specificity_at_sensitivity: 0.7657 - val_recall: 0.9825 - val_precision: 0.5709\n",
            "Epoch 76/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3501 - accuracy: 0.8395 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9076 - recall: 0.9629 - precision: 0.7657\n",
            "Epoch 76: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.3501 - accuracy: 0.8395 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9076 - recall: 0.9629 - precision: 0.7657 - val_loss: 0.6661 - val_accuracy: 0.6484 - val_sensitivity_at_specificity: 0.8488 - val_specificity_at_sensitivity: 0.6978 - val_recall: 0.9969 - val_precision: 0.5905\n",
            "Epoch 77/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3202 - accuracy: 0.8504 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9252 - recall: 0.9628 - precision: 0.7793\n",
            "Epoch 77: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.3202 - accuracy: 0.8504 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9252 - recall: 0.9628 - precision: 0.7793 - val_loss: 0.6653 - val_accuracy: 0.6406 - val_sensitivity_at_specificity: 0.8515 - val_specificity_at_sensitivity: 0.7097 - val_recall: 0.9908 - val_precision: 0.5876\n",
            "Epoch 78/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3393 - accuracy: 0.8488 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9190 - recall: 0.9710 - precision: 0.7797\n",
            "Epoch 78: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.3393 - accuracy: 0.8488 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9190 - recall: 0.9710 - precision: 0.7797 - val_loss: 0.6381 - val_accuracy: 0.6406 - val_sensitivity_at_specificity: 0.8398 - val_specificity_at_sensitivity: 0.7639 - val_recall: 0.9676 - val_precision: 0.5886\n",
            "Epoch 79/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3407 - accuracy: 0.8445 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9141 - recall: 0.9680 - precision: 0.7763\n",
            "Epoch 79: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.3407 - accuracy: 0.8445 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9141 - recall: 0.9680 - precision: 0.7763 - val_loss: 0.6557 - val_accuracy: 0.6445 - val_sensitivity_at_specificity: 0.8281 - val_specificity_at_sensitivity: 0.7094 - val_recall: 0.9875 - val_precision: 0.5857\n",
            "Epoch 80/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3458 - accuracy: 0.8379 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9159 - recall: 0.9601 - precision: 0.7671\n",
            "Epoch 80: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 175ms/step - loss: 0.3458 - accuracy: 0.8379 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9159 - recall: 0.9601 - precision: 0.7671 - val_loss: 0.6448 - val_accuracy: 0.6344 - val_sensitivity_at_specificity: 0.8273 - val_specificity_at_sensitivity: 0.7026 - val_recall: 0.9588 - val_precision: 0.5778\n",
            "Epoch 81/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3513 - accuracy: 0.8371 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9130 - recall: 0.9511 - precision: 0.7656\n",
            "Epoch 81: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.3513 - accuracy: 0.8371 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9130 - recall: 0.9511 - precision: 0.7656 - val_loss: 0.6508 - val_accuracy: 0.6477 - val_sensitivity_at_specificity: 0.7854 - val_specificity_at_sensitivity: 0.6709 - val_recall: 0.9528 - val_precision: 0.5985\n",
            "Epoch 82/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3335 - accuracy: 0.8516 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9192 - recall: 0.9690 - precision: 0.7817\n",
            "Epoch 82: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.3335 - accuracy: 0.8516 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9192 - recall: 0.9690 - precision: 0.7817 - val_loss: 0.6346 - val_accuracy: 0.6469 - val_sensitivity_at_specificity: 0.8061 - val_specificity_at_sensitivity: 0.7027 - val_recall: 0.9535 - val_precision: 0.5845\n",
            "Epoch 83/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3285 - accuracy: 0.8566 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9228 - recall: 0.9571 - precision: 0.8042\n",
            "Epoch 83: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.3285 - accuracy: 0.8566 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9228 - recall: 0.9571 - precision: 0.8042 - val_loss: 0.7239 - val_accuracy: 0.6266 - val_sensitivity_at_specificity: 0.8598 - val_specificity_at_sensitivity: 0.6977 - val_recall: 0.9953 - val_precision: 0.5709\n",
            "Epoch 84/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3534 - accuracy: 0.8406 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9090 - recall: 0.9707 - precision: 0.7678\n",
            "Epoch 84: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.3534 - accuracy: 0.8406 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9090 - recall: 0.9707 - precision: 0.7678 - val_loss: 0.7279 - val_accuracy: 0.6070 - val_sensitivity_at_specificity: 0.7840 - val_specificity_at_sensitivity: 0.6519 - val_recall: 0.9952 - val_precision: 0.5544\n",
            "Epoch 85/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3299 - accuracy: 0.8516 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9221 - recall: 0.9804 - precision: 0.7790\n",
            "Epoch 85: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.3299 - accuracy: 0.8516 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9221 - recall: 0.9804 - precision: 0.7790 - val_loss: 0.6810 - val_accuracy: 0.6391 - val_sensitivity_at_specificity: 0.8376 - val_specificity_at_sensitivity: 0.7198 - val_recall: 0.9848 - val_precision: 0.5895\n",
            "Epoch 86/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3374 - accuracy: 0.8500 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9248 - recall: 0.9517 - precision: 0.7913\n",
            "Epoch 86: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.3374 - accuracy: 0.8500 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9248 - recall: 0.9517 - precision: 0.7913 - val_loss: 0.7423 - val_accuracy: 0.6234 - val_sensitivity_at_specificity: 0.7828 - val_specificity_at_sensitivity: 0.6734 - val_recall: 0.9719 - val_precision: 0.5727\n",
            "Epoch 87/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3452 - accuracy: 0.8418 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9167 - recall: 0.9692 - precision: 0.7752\n",
            "Epoch 87: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.3452 - accuracy: 0.8418 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9167 - recall: 0.9692 - precision: 0.7752 - val_loss: 0.6165 - val_accuracy: 0.6438 - val_sensitivity_at_specificity: 0.8654 - val_specificity_at_sensitivity: 0.7530 - val_recall: 0.9824 - val_precision: 0.5794\n",
            "Epoch 88/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3405 - accuracy: 0.8480 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9249 - recall: 0.9610 - precision: 0.7841\n",
            "Epoch 88: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.3405 - accuracy: 0.8480 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9249 - recall: 0.9610 - precision: 0.7841 - val_loss: 0.6483 - val_accuracy: 0.6531 - val_sensitivity_at_specificity: 0.8647 - val_specificity_at_sensitivity: 0.7253 - val_recall: 0.9501 - val_precision: 0.5882\n",
            "Epoch 89/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3157 - accuracy: 0.8605 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9311 - recall: 0.9618 - precision: 0.8001\n",
            "Epoch 89: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.3157 - accuracy: 0.8605 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9311 - recall: 0.9618 - precision: 0.8001 - val_loss: 0.6442 - val_accuracy: 0.6523 - val_sensitivity_at_specificity: 0.8297 - val_specificity_at_sensitivity: 0.7250 - val_recall: 0.9203 - val_precision: 0.5992\n",
            "Epoch 90/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3239 - accuracy: 0.8562 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9252 - recall: 0.9486 - precision: 0.7983\n",
            "Epoch 90: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 174ms/step - loss: 0.3239 - accuracy: 0.8562 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9252 - recall: 0.9486 - precision: 0.7983 - val_loss: 0.6273 - val_accuracy: 0.6570 - val_sensitivity_at_specificity: 0.8333 - val_specificity_at_sensitivity: 0.7290 - val_recall: 0.9439 - val_precision: 0.6078\n",
            "Epoch 91/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3245 - accuracy: 0.8527 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9353 - recall: 0.9588 - precision: 0.7883\n",
            "Epoch 91: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.3245 - accuracy: 0.8527 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9353 - recall: 0.9588 - precision: 0.7883 - val_loss: 0.6590 - val_accuracy: 0.6391 - val_sensitivity_at_specificity: 0.8206 - val_specificity_at_sensitivity: 0.6969 - val_recall: 0.9381 - val_precision: 0.5828\n",
            "Epoch 92/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3335 - accuracy: 0.8477 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9205 - recall: 0.9519 - precision: 0.7892\n",
            "Epoch 92: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.3335 - accuracy: 0.8477 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9205 - recall: 0.9519 - precision: 0.7892 - val_loss: 0.6862 - val_accuracy: 0.6406 - val_sensitivity_at_specificity: 0.8257 - val_specificity_at_sensitivity: 0.6734 - val_recall: 0.9733 - val_precision: 0.5833\n",
            "Epoch 93/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3191 - accuracy: 0.8530 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9369 - recall: 0.9461 - precision: 0.7949\n",
            "Epoch 93: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.3191 - accuracy: 0.8530 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9369 - recall: 0.9461 - precision: 0.7949 - val_loss: 0.6900 - val_accuracy: 0.6359 - val_sensitivity_at_specificity: 0.8480 - val_specificity_at_sensitivity: 0.6869 - val_recall: 0.9671 - val_precision: 0.5810\n",
            "Epoch 94/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3346 - accuracy: 0.8543 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9245 - recall: 0.9615 - precision: 0.7869\n",
            "Epoch 94: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 175ms/step - loss: 0.3346 - accuracy: 0.8543 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9245 - recall: 0.9615 - precision: 0.7869 - val_loss: 0.6809 - val_accuracy: 0.6398 - val_sensitivity_at_specificity: 0.8381 - val_specificity_at_sensitivity: 0.6875 - val_recall: 0.9487 - val_precision: 0.5798\n",
            "Epoch 95/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3277 - accuracy: 0.8504 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9257 - recall: 0.9490 - precision: 0.7887\n",
            "Epoch 95: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.3277 - accuracy: 0.8504 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9257 - recall: 0.9490 - precision: 0.7887 - val_loss: 0.6060 - val_accuracy: 0.6617 - val_sensitivity_at_specificity: 0.8265 - val_specificity_at_sensitivity: 0.7287 - val_recall: 0.9041 - val_precision: 0.6162\n",
            "Epoch 96/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3152 - accuracy: 0.8496 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9493 - recall: 0.9380 - precision: 0.7937\n",
            "Epoch 96: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.3152 - accuracy: 0.8496 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9493 - recall: 0.9380 - precision: 0.7937 - val_loss: 0.6294 - val_accuracy: 0.6719 - val_sensitivity_at_specificity: 0.8492 - val_specificity_at_sensitivity: 0.7460 - val_recall: 0.9077 - val_precision: 0.6211\n",
            "Epoch 97/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3271 - accuracy: 0.8543 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9294 - recall: 0.9459 - precision: 0.7959\n",
            "Epoch 97: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.3271 - accuracy: 0.8543 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9294 - recall: 0.9459 - precision: 0.7959 - val_loss: 0.6971 - val_accuracy: 0.6336 - val_sensitivity_at_specificity: 0.8058 - val_specificity_at_sensitivity: 0.6918 - val_recall: 0.9612 - val_precision: 0.5717\n",
            "Epoch 98/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3184 - accuracy: 0.8559 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9446 - recall: 0.9703 - precision: 0.7893\n",
            "Epoch 98: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.3184 - accuracy: 0.8559 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9446 - recall: 0.9703 - precision: 0.7893 - val_loss: 0.6690 - val_accuracy: 0.6570 - val_sensitivity_at_specificity: 0.8279 - val_specificity_at_sensitivity: 0.7176 - val_recall: 0.9421 - val_precision: 0.5996\n",
            "Epoch 99/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3077 - accuracy: 0.8641 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9373 - recall: 0.9424 - precision: 0.8129\n",
            "Epoch 99: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.3077 - accuracy: 0.8641 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9373 - recall: 0.9424 - precision: 0.8129 - val_loss: 0.7297 - val_accuracy: 0.6516 - val_sensitivity_at_specificity: 0.8359 - val_specificity_at_sensitivity: 0.6956 - val_recall: 0.9644 - val_precision: 0.5956\n",
            "Epoch 100/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2980 - accuracy: 0.8617 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9550 - recall: 0.9527 - precision: 0.8012\n",
            "Epoch 100: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.2980 - accuracy: 0.8617 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9550 - recall: 0.9527 - precision: 0.8012 - val_loss: 0.7304 - val_accuracy: 0.6141 - val_sensitivity_at_specificity: 0.8224 - val_specificity_at_sensitivity: 0.7054 - val_recall: 0.9441 - val_precision: 0.5551\n",
            "Epoch 101/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3293 - accuracy: 0.8527 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9370 - recall: 0.9294 - precision: 0.8050\n",
            "Epoch 101: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.3293 - accuracy: 0.8527 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9370 - recall: 0.9294 - precision: 0.8050 - val_loss: 0.7566 - val_accuracy: 0.6313 - val_sensitivity_at_specificity: 0.6998 - val_specificity_at_sensitivity: 0.6091 - val_recall: 0.9751 - val_precision: 0.5789\n",
            "Epoch 102/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2949 - accuracy: 0.8684 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9551 - recall: 0.9597 - precision: 0.8129\n",
            "Epoch 102: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.2949 - accuracy: 0.8684 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9551 - recall: 0.9597 - precision: 0.8129 - val_loss: 0.6817 - val_accuracy: 0.6562 - val_sensitivity_at_specificity: 0.8126 - val_specificity_at_sensitivity: 0.7043 - val_recall: 0.9263 - val_precision: 0.6060\n",
            "Epoch 103/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3047 - accuracy: 0.8672 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9525 - recall: 0.9373 - precision: 0.8214\n",
            "Epoch 103: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.3047 - accuracy: 0.8672 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9525 - recall: 0.9373 - precision: 0.8214 - val_loss: 0.7345 - val_accuracy: 0.6305 - val_sensitivity_at_specificity: 0.7853 - val_specificity_at_sensitivity: 0.6677 - val_recall: 0.9439 - val_precision: 0.5735\n",
            "Epoch 104/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2982 - accuracy: 0.8621 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9601 - recall: 0.9388 - precision: 0.8106\n",
            "Epoch 104: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.2982 - accuracy: 0.8621 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9601 - recall: 0.9388 - precision: 0.8106 - val_loss: 0.8320 - val_accuracy: 0.6328 - val_sensitivity_at_specificity: 0.7590 - val_specificity_at_sensitivity: 0.6630 - val_recall: 0.9812 - val_precision: 0.5779\n",
            "Epoch 105/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3137 - accuracy: 0.8543 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9441 - recall: 0.9322 - precision: 0.8022\n",
            "Epoch 105: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.3137 - accuracy: 0.8543 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9441 - recall: 0.9322 - precision: 0.8022 - val_loss: 0.8032 - val_accuracy: 0.6422 - val_sensitivity_at_specificity: 0.7855 - val_specificity_at_sensitivity: 0.6455 - val_recall: 0.9558 - val_precision: 0.5849\n",
            "Epoch 106/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2999 - accuracy: 0.8637 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9561 - recall: 0.9502 - precision: 0.8106\n",
            "Epoch 106: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.2999 - accuracy: 0.8637 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9561 - recall: 0.9502 - precision: 0.8106 - val_loss: 0.7101 - val_accuracy: 0.6383 - val_sensitivity_at_specificity: 0.7766 - val_specificity_at_sensitivity: 0.6815 - val_recall: 0.9276 - val_precision: 0.5914\n",
            "Epoch 107/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2971 - accuracy: 0.8703 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9466 - recall: 0.9425 - precision: 0.8272\n",
            "Epoch 107: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 183ms/step - loss: 0.2971 - accuracy: 0.8703 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9466 - recall: 0.9425 - precision: 0.8272 - val_loss: 0.8519 - val_accuracy: 0.6461 - val_sensitivity_at_specificity: 0.7469 - val_specificity_at_sensitivity: 0.6321 - val_recall: 0.9736 - val_precision: 0.5898\n",
            "Epoch 108/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2953 - accuracy: 0.8711 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9475 - recall: 0.9447 - precision: 0.8239\n",
            "Epoch 108: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.2953 - accuracy: 0.8711 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9475 - recall: 0.9447 - precision: 0.8239 - val_loss: 0.7274 - val_accuracy: 0.6156 - val_sensitivity_at_specificity: 0.8078 - val_specificity_at_sensitivity: 0.6856 - val_recall: 0.9696 - val_precision: 0.5481\n",
            "Epoch 109/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2873 - accuracy: 0.8746 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9581 - recall: 0.9568 - precision: 0.8239\n",
            "Epoch 109: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.2873 - accuracy: 0.8746 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9581 - recall: 0.9568 - precision: 0.8239 - val_loss: 0.7891 - val_accuracy: 0.6531 - val_sensitivity_at_specificity: 0.8138 - val_specificity_at_sensitivity: 0.6730 - val_recall: 0.9615 - val_precision: 0.5987\n",
            "Epoch 110/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3059 - accuracy: 0.8656 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9521 - recall: 0.9384 - precision: 0.8171\n",
            "Epoch 110: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.3059 - accuracy: 0.8656 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9521 - recall: 0.9384 - precision: 0.8171 - val_loss: 0.7000 - val_accuracy: 0.6633 - val_sensitivity_at_specificity: 0.8176 - val_specificity_at_sensitivity: 0.6646 - val_recall: 0.9434 - val_precision: 0.6030\n",
            "Epoch 111/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2911 - accuracy: 0.8660 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9627 - recall: 0.9450 - precision: 0.8067\n",
            "Epoch 111: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.2911 - accuracy: 0.8660 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9627 - recall: 0.9450 - precision: 0.8067 - val_loss: 0.6977 - val_accuracy: 0.6469 - val_sensitivity_at_specificity: 0.8219 - val_specificity_at_sensitivity: 0.7189 - val_recall: 0.8903 - val_precision: 0.5938\n",
            "Epoch 112/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2782 - accuracy: 0.8844 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9523 - recall: 0.9501 - precision: 0.8428\n",
            "Epoch 112: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.2782 - accuracy: 0.8844 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9523 - recall: 0.9501 - precision: 0.8428 - val_loss: 0.8282 - val_accuracy: 0.6406 - val_sensitivity_at_specificity: 0.7562 - val_specificity_at_sensitivity: 0.6399 - val_recall: 0.9674 - val_precision: 0.5866\n",
            "Epoch 113/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2738 - accuracy: 0.8824 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9664 - recall: 0.9617 - precision: 0.8302\n",
            "Epoch 113: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.2738 - accuracy: 0.8824 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9664 - recall: 0.9617 - precision: 0.8302 - val_loss: 0.7881 - val_accuracy: 0.6336 - val_sensitivity_at_specificity: 0.7808 - val_specificity_at_sensitivity: 0.6765 - val_recall: 0.9290 - val_precision: 0.5814\n",
            "Epoch 114/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2995 - accuracy: 0.8656 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9584 - recall: 0.9295 - precision: 0.8216\n",
            "Epoch 114: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.2995 - accuracy: 0.8656 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9584 - recall: 0.9295 - precision: 0.8216 - val_loss: 0.6890 - val_accuracy: 0.6453 - val_sensitivity_at_specificity: 0.7636 - val_specificity_at_sensitivity: 0.6558 - val_recall: 0.9217 - val_precision: 0.6036\n",
            "Epoch 115/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2828 - accuracy: 0.8813 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9588 - recall: 0.9445 - precision: 0.8409\n",
            "Epoch 115: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 175ms/step - loss: 0.2828 - accuracy: 0.8813 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9588 - recall: 0.9445 - precision: 0.8409 - val_loss: 0.9329 - val_accuracy: 0.6242 - val_sensitivity_at_specificity: 0.7011 - val_specificity_at_sensitivity: 0.6303 - val_recall: 0.9781 - val_precision: 0.5723\n",
            "Epoch 116/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2835 - accuracy: 0.8700 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9681 - recall: 0.9391 - precision: 0.8269\n",
            "Epoch 116: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.2835 - accuracy: 0.8700 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9681 - recall: 0.9391 - precision: 0.8269 - val_loss: 0.7388 - val_accuracy: 0.6648 - val_sensitivity_at_specificity: 0.7885 - val_specificity_at_sensitivity: 0.6537 - val_recall: 0.9215 - val_precision: 0.6180\n",
            "Epoch 117/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3129 - accuracy: 0.8590 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9551 - recall: 0.9314 - precision: 0.8118\n",
            "Epoch 117: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.3129 - accuracy: 0.8590 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9551 - recall: 0.9314 - precision: 0.8118 - val_loss: 0.7915 - val_accuracy: 0.6422 - val_sensitivity_at_specificity: 0.7749 - val_specificity_at_sensitivity: 0.6571 - val_recall: 0.9296 - val_precision: 0.5957\n",
            "Epoch 118/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2837 - accuracy: 0.8695 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9683 - recall: 0.9369 - precision: 0.8139\n",
            "Epoch 118: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.2837 - accuracy: 0.8695 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9683 - recall: 0.9369 - precision: 0.8139 - val_loss: 0.7418 - val_accuracy: 0.6344 - val_sensitivity_at_specificity: 0.7818 - val_specificity_at_sensitivity: 0.6703 - val_recall: 0.9294 - val_precision: 0.5833\n",
            "Epoch 119/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2726 - accuracy: 0.8773 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9726 - recall: 0.9379 - precision: 0.8258\n",
            "Epoch 119: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.2726 - accuracy: 0.8773 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9726 - recall: 0.9379 - precision: 0.8258 - val_loss: 0.8282 - val_accuracy: 0.6172 - val_sensitivity_at_specificity: 0.7810 - val_specificity_at_sensitivity: 0.6557 - val_recall: 0.9183 - val_precision: 0.5609\n",
            "Epoch 120/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2636 - accuracy: 0.8836 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9702 - recall: 0.9400 - precision: 0.8451\n",
            "Epoch 120: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.2636 - accuracy: 0.8836 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9702 - recall: 0.9400 - precision: 0.8451 - val_loss: 0.7358 - val_accuracy: 0.6484 - val_sensitivity_at_specificity: 0.8038 - val_specificity_at_sensitivity: 0.6719 - val_recall: 0.9074 - val_precision: 0.5965\n",
            "Epoch 121/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2661 - accuracy: 0.8801 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9768 - recall: 0.9504 - precision: 0.8317\n",
            "Epoch 121: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 175ms/step - loss: 0.2661 - accuracy: 0.8801 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9768 - recall: 0.9504 - precision: 0.8317 - val_loss: 0.8720 - val_accuracy: 0.6469 - val_sensitivity_at_specificity: 0.8138 - val_specificity_at_sensitivity: 0.6984 - val_recall: 0.9369 - val_precision: 0.5971\n",
            "Epoch 122/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2577 - accuracy: 0.8840 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9763 - recall: 0.9297 - precision: 0.8478\n",
            "Epoch 122: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.2577 - accuracy: 0.8840 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9763 - recall: 0.9297 - precision: 0.8478 - val_loss: 0.9300 - val_accuracy: 0.6109 - val_sensitivity_at_specificity: 0.7477 - val_specificity_at_sensitivity: 0.6379 - val_recall: 0.9611 - val_precision: 0.5661\n",
            "Epoch 123/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2828 - accuracy: 0.8725 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9718 - recall: 0.9434 - precision: 0.8312\n",
            "Epoch 123: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.2828 - accuracy: 0.8725 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9718 - recall: 0.9434 - precision: 0.8312 - val_loss: 0.7847 - val_accuracy: 0.6469 - val_sensitivity_at_specificity: 0.7346 - val_specificity_at_sensitivity: 0.6558 - val_recall: 0.9670 - val_precision: 0.6000\n",
            "Epoch 124/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2512 - accuracy: 0.8926 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9791 - recall: 0.9535 - precision: 0.8486\n",
            "Epoch 124: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.2512 - accuracy: 0.8926 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9791 - recall: 0.9535 - precision: 0.8486 - val_loss: 0.8861 - val_accuracy: 0.6391 - val_sensitivity_at_specificity: 0.7508 - val_specificity_at_sensitivity: 0.6492 - val_recall: 0.9476 - val_precision: 0.5819\n",
            "Epoch 125/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2635 - accuracy: 0.8902 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9767 - recall: 0.9481 - precision: 0.8486\n",
            "Epoch 125: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.2635 - accuracy: 0.8902 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9767 - recall: 0.9481 - precision: 0.8486 - val_loss: 1.0354 - val_accuracy: 0.6055 - val_sensitivity_at_specificity: 0.6320 - val_specificity_at_sensitivity: 0.6168 - val_recall: 0.9584 - val_precision: 0.5557\n",
            "Epoch 126/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2497 - accuracy: 0.8891 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9857 - recall: 0.9415 - precision: 0.8454\n",
            "Epoch 126: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.2497 - accuracy: 0.8891 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9857 - recall: 0.9415 - precision: 0.8454 - val_loss: 0.9552 - val_accuracy: 0.6477 - val_sensitivity_at_specificity: 0.6677 - val_specificity_at_sensitivity: 0.6200 - val_recall: 0.9757 - val_precision: 0.5965\n",
            "Epoch 127/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2514 - accuracy: 0.8895 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9741 - recall: 0.9418 - precision: 0.8536\n",
            "Epoch 127: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.2514 - accuracy: 0.8895 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9741 - recall: 0.9418 - precision: 0.8536 - val_loss: 0.9288 - val_accuracy: 0.6227 - val_sensitivity_at_specificity: 0.7508 - val_specificity_at_sensitivity: 0.6480 - val_recall: 0.9545 - val_precision: 0.5729\n",
            "Epoch 128/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2418 - accuracy: 0.8969 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9815 - recall: 0.9525 - precision: 0.8551\n",
            "Epoch 128: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.2418 - accuracy: 0.8969 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9815 - recall: 0.9525 - precision: 0.8551 - val_loss: 0.9026 - val_accuracy: 0.6398 - val_sensitivity_at_specificity: 0.7621 - val_specificity_at_sensitivity: 0.6735 - val_recall: 0.9487 - val_precision: 0.5877\n",
            "Epoch 129/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2326 - accuracy: 0.8953 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9856 - recall: 0.9297 - precision: 0.8640\n",
            "Epoch 129: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.2326 - accuracy: 0.8953 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9856 - recall: 0.9297 - precision: 0.8640 - val_loss: 0.9839 - val_accuracy: 0.6273 - val_sensitivity_at_specificity: 0.6872 - val_specificity_at_sensitivity: 0.6198 - val_recall: 0.9242 - val_precision: 0.5769\n",
            "Epoch 130/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2443 - accuracy: 0.8930 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9807 - recall: 0.9498 - precision: 0.8571\n",
            "Epoch 130: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.2443 - accuracy: 0.8930 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9807 - recall: 0.9498 - precision: 0.8571 - val_loss: 1.0356 - val_accuracy: 0.6367 - val_sensitivity_at_specificity: 0.6889 - val_specificity_at_sensitivity: 0.5969 - val_recall: 0.9571 - val_precision: 0.5793\n",
            "Epoch 131/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2486 - accuracy: 0.8949 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9756 - recall: 0.9472 - precision: 0.8535\n",
            "Epoch 131: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.2486 - accuracy: 0.8949 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9756 - recall: 0.9472 - precision: 0.8535 - val_loss: 1.0052 - val_accuracy: 0.6242 - val_sensitivity_at_specificity: 0.6929 - val_specificity_at_sensitivity: 0.6062 - val_recall: 0.9669 - val_precision: 0.5717\n",
            "Epoch 132/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2500 - accuracy: 0.8879 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9829 - recall: 0.9504 - precision: 0.8436\n",
            "Epoch 132: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.2500 - accuracy: 0.8879 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9829 - recall: 0.9504 - precision: 0.8436 - val_loss: 0.8612 - val_accuracy: 0.6250 - val_sensitivity_at_specificity: 0.7690 - val_specificity_at_sensitivity: 0.6636 - val_recall: 0.9304 - val_precision: 0.5742\n",
            "Epoch 133/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2254 - accuracy: 0.9082 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9847 - recall: 0.9411 - precision: 0.8802\n",
            "Epoch 133: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.2254 - accuracy: 0.9082 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9847 - recall: 0.9411 - precision: 0.8802 - val_loss: 0.9797 - val_accuracy: 0.6539 - val_sensitivity_at_specificity: 0.6768 - val_specificity_at_sensitivity: 0.5978 - val_recall: 0.9604 - val_precision: 0.6017\n",
            "Epoch 134/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2266 - accuracy: 0.9066 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9882 - recall: 0.9526 - precision: 0.8733\n",
            "Epoch 134: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.2266 - accuracy: 0.9066 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9882 - recall: 0.9526 - precision: 0.8733 - val_loss: 0.9423 - val_accuracy: 0.6766 - val_sensitivity_at_specificity: 0.8278 - val_specificity_at_sensitivity: 0.6895 - val_recall: 0.9820 - val_precision: 0.6200\n",
            "Epoch 135/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2358 - accuracy: 0.8934 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9886 - recall: 0.9371 - precision: 0.8564\n",
            "Epoch 135: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.2358 - accuracy: 0.8934 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9886 - recall: 0.9371 - precision: 0.8564 - val_loss: 1.0525 - val_accuracy: 0.6430 - val_sensitivity_at_specificity: 0.6988 - val_specificity_at_sensitivity: 0.6294 - val_recall: 0.9648 - val_precision: 0.5925\n",
            "Epoch 136/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2284 - accuracy: 0.9047 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9892 - recall: 0.9571 - precision: 0.8638\n",
            "Epoch 136: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 174ms/step - loss: 0.2284 - accuracy: 0.9047 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9892 - recall: 0.9571 - precision: 0.8638 - val_loss: 0.9970 - val_accuracy: 0.6398 - val_sensitivity_at_specificity: 0.7324 - val_specificity_at_sensitivity: 0.6616 - val_recall: 0.9423 - val_precision: 0.5805\n",
            "Epoch 137/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2101 - accuracy: 0.9145 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9909 - recall: 0.9478 - precision: 0.8846\n",
            "Epoch 137: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.2101 - accuracy: 0.9145 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9909 - recall: 0.9478 - precision: 0.8846 - val_loss: 1.1364 - val_accuracy: 0.6430 - val_sensitivity_at_specificity: 0.6754 - val_specificity_at_sensitivity: 0.5940 - val_recall: 0.9691 - val_precision: 0.5893\n",
            "Epoch 138/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2151 - accuracy: 0.9078 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9929 - recall: 0.9465 - precision: 0.8796\n",
            "Epoch 138: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.2151 - accuracy: 0.9078 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9929 - recall: 0.9465 - precision: 0.8796 - val_loss: 1.0404 - val_accuracy: 0.6273 - val_sensitivity_at_specificity: 0.7067 - val_specificity_at_sensitivity: 0.6072 - val_recall: 0.9392 - val_precision: 0.5788\n",
            "Epoch 139/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2281 - accuracy: 0.9027 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9865 - recall: 0.9455 - precision: 0.8738\n",
            "Epoch 139: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.2281 - accuracy: 0.9027 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9865 - recall: 0.9455 - precision: 0.8738 - val_loss: 1.0910 - val_accuracy: 0.6445 - val_sensitivity_at_specificity: 0.7308 - val_specificity_at_sensitivity: 0.6505 - val_recall: 0.9656 - val_precision: 0.5876\n",
            "Epoch 140/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2121 - accuracy: 0.9105 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9882 - recall: 0.9535 - precision: 0.8792\n",
            "Epoch 140: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.2121 - accuracy: 0.9105 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9882 - recall: 0.9535 - precision: 0.8792 - val_loss: 1.1550 - val_accuracy: 0.6406 - val_sensitivity_at_specificity: 0.7092 - val_specificity_at_sensitivity: 0.6436 - val_recall: 0.9440 - val_precision: 0.5887\n",
            "Epoch 141/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2258 - accuracy: 0.9039 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9878 - recall: 0.9345 - precision: 0.8771\n",
            "Epoch 141: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 184ms/step - loss: 0.2258 - accuracy: 0.9039 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9878 - recall: 0.9345 - precision: 0.8771 - val_loss: 0.9829 - val_accuracy: 0.6477 - val_sensitivity_at_specificity: 0.7257 - val_specificity_at_sensitivity: 0.6403 - val_recall: 0.9738 - val_precision: 0.5929\n",
            "Epoch 142/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1967 - accuracy: 0.9257 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9883 - recall: 0.9662 - precision: 0.8946\n",
            "Epoch 142: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.1967 - accuracy: 0.9257 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9883 - recall: 0.9662 - precision: 0.8946 - val_loss: 1.1512 - val_accuracy: 0.6273 - val_sensitivity_at_specificity: 0.7134 - val_specificity_at_sensitivity: 0.6380 - val_recall: 0.9586 - val_precision: 0.5717\n",
            "Epoch 143/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2059 - accuracy: 0.9156 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9929 - recall: 0.9477 - precision: 0.8928\n",
            "Epoch 143: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.2059 - accuracy: 0.9156 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9929 - recall: 0.9477 - precision: 0.8928 - val_loss: 1.3276 - val_accuracy: 0.6031 - val_sensitivity_at_specificity: 0.6511 - val_specificity_at_sensitivity: 0.6064 - val_recall: 0.9469 - val_precision: 0.5536\n",
            "Epoch 144/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1873 - accuracy: 0.9254 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9961 - recall: 0.9671 - precision: 0.8922\n",
            "Epoch 144: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 174ms/step - loss: 0.1873 - accuracy: 0.9254 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9961 - recall: 0.9671 - precision: 0.8922 - val_loss: 0.9928 - val_accuracy: 0.6617 - val_sensitivity_at_specificity: 0.7119 - val_specificity_at_sensitivity: 0.6197 - val_recall: 0.9493 - val_precision: 0.6145\n",
            "Epoch 145/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2103 - accuracy: 0.9152 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9898 - recall: 0.9486 - precision: 0.8896\n",
            "Epoch 145: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.2103 - accuracy: 0.9152 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9898 - recall: 0.9486 - precision: 0.8896 - val_loss: 1.1948 - val_accuracy: 0.6234 - val_sensitivity_at_specificity: 0.6651 - val_specificity_at_sensitivity: 0.6000 - val_recall: 0.9581 - val_precision: 0.5760\n",
            "Epoch 146/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1867 - accuracy: 0.9223 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9968 - recall: 0.9605 - precision: 0.8957\n",
            "Epoch 146: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.1867 - accuracy: 0.9223 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9968 - recall: 0.9605 - precision: 0.8957 - val_loss: 1.4149 - val_accuracy: 0.6234 - val_sensitivity_at_specificity: 0.5913 - val_specificity_at_sensitivity: 0.5900 - val_recall: 0.9693 - val_precision: 0.5644\n",
            "Epoch 147/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2014 - accuracy: 0.9132 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9960 - recall: 0.9403 - precision: 0.8881\n",
            "Epoch 147: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.2014 - accuracy: 0.9132 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9960 - recall: 0.9403 - precision: 0.8881 - val_loss: 1.2715 - val_accuracy: 0.6172 - val_sensitivity_at_specificity: 0.7143 - val_specificity_at_sensitivity: 0.6138 - val_recall: 0.9508 - val_precision: 0.5662\n",
            "Epoch 148/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1866 - accuracy: 0.9246 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9945 - recall: 0.9673 - precision: 0.8917\n",
            "Epoch 148: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 174ms/step - loss: 0.1866 - accuracy: 0.9246 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9945 - recall: 0.9673 - precision: 0.8917 - val_loss: 1.1148 - val_accuracy: 0.6438 - val_sensitivity_at_specificity: 0.7570 - val_specificity_at_sensitivity: 0.6230 - val_recall: 0.9613 - val_precision: 0.5903\n",
            "Epoch 149/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1999 - accuracy: 0.9066 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9946 - recall: 0.9435 - precision: 0.8781\n",
            "Epoch 149: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.1999 - accuracy: 0.9066 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9946 - recall: 0.9435 - precision: 0.8781 - val_loss: 1.3755 - val_accuracy: 0.6289 - val_sensitivity_at_specificity: 0.6130 - val_specificity_at_sensitivity: 0.5726 - val_recall: 0.9536 - val_precision: 0.5806\n",
            "Epoch 150/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2062 - accuracy: 0.9113 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9952 - recall: 0.9488 - precision: 0.8858\n",
            "Epoch 150: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.2062 - accuracy: 0.9113 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9952 - recall: 0.9488 - precision: 0.8858 - val_loss: 1.2161 - val_accuracy: 0.6297 - val_sensitivity_at_specificity: 0.7464 - val_specificity_at_sensitivity: 0.6401 - val_recall: 0.9601 - val_precision: 0.5728\n",
            "Epoch 151/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2103 - accuracy: 0.9109 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9939 - recall: 0.9467 - precision: 0.8807\n",
            "Epoch 151: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.2103 - accuracy: 0.9109 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9939 - recall: 0.9467 - precision: 0.8807 - val_loss: 1.1865 - val_accuracy: 0.6586 - val_sensitivity_at_specificity: 0.7370 - val_specificity_at_sensitivity: 0.6474 - val_recall: 0.9495 - val_precision: 0.6132\n",
            "Epoch 152/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1841 - accuracy: 0.9211 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9961 - recall: 0.9484 - precision: 0.8993\n",
            "Epoch 152: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 174ms/step - loss: 0.1841 - accuracy: 0.9211 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9961 - recall: 0.9484 - precision: 0.8993 - val_loss: 1.2861 - val_accuracy: 0.6281 - val_sensitivity_at_specificity: 0.7189 - val_specificity_at_sensitivity: 0.5930 - val_recall: 0.9354 - val_precision: 0.5704\n",
            "Epoch 153/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1869 - accuracy: 0.9184 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9977 - recall: 0.9599 - precision: 0.8828\n",
            "Epoch 153: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 184ms/step - loss: 0.1869 - accuracy: 0.9184 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9977 - recall: 0.9599 - precision: 0.8828 - val_loss: 1.3844 - val_accuracy: 0.6117 - val_sensitivity_at_specificity: 0.6801 - val_specificity_at_sensitivity: 0.5973 - val_recall: 0.9614 - val_precision: 0.5584\n",
            "Epoch 154/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1790 - accuracy: 0.9262 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9946 - recall: 0.9489 - precision: 0.9049\n",
            "Epoch 154: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 174ms/step - loss: 0.1790 - accuracy: 0.9262 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9946 - recall: 0.9489 - precision: 0.9049 - val_loss: 1.3124 - val_accuracy: 0.6445 - val_sensitivity_at_specificity: 0.7045 - val_specificity_at_sensitivity: 0.6226 - val_recall: 0.9758 - val_precision: 0.5946\n",
            "Epoch 155/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1612 - accuracy: 0.9383 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9952 - recall: 0.9730 - precision: 0.9112\n",
            "Epoch 155: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 175ms/step - loss: 0.1612 - accuracy: 0.9383 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9952 - recall: 0.9730 - precision: 0.9112 - val_loss: 1.3911 - val_accuracy: 0.6508 - val_sensitivity_at_specificity: 0.7307 - val_specificity_at_sensitivity: 0.6199 - val_recall: 0.9598 - val_precision: 0.5956\n",
            "Epoch 156/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1879 - accuracy: 0.9191 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9969 - recall: 0.9497 - precision: 0.8942\n",
            "Epoch 156: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.1879 - accuracy: 0.9191 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9969 - recall: 0.9497 - precision: 0.8942 - val_loss: 1.1815 - val_accuracy: 0.6445 - val_sensitivity_at_specificity: 0.7606 - val_specificity_at_sensitivity: 0.6209 - val_recall: 0.9468 - val_precision: 0.5897\n",
            "Epoch 157/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1821 - accuracy: 0.9254 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9952 - recall: 0.9510 - precision: 0.9072\n",
            "Epoch 157: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.1821 - accuracy: 0.9254 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9952 - recall: 0.9510 - precision: 0.9072 - val_loss: 1.3809 - val_accuracy: 0.6164 - val_sensitivity_at_specificity: 0.6672 - val_specificity_at_sensitivity: 0.6009 - val_recall: 0.9427 - val_precision: 0.5729\n",
            "Epoch 158/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1757 - accuracy: 0.9232 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9966 - recall: 0.9532 - precision: 0.9006\n",
            "Epoch 158: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.1757 - accuracy: 0.9232 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9966 - recall: 0.9532 - precision: 0.9006 - val_loss: 1.2512 - val_accuracy: 0.6258 - val_sensitivity_at_specificity: 0.6336 - val_specificity_at_sensitivity: 0.5808 - val_recall: 0.9298 - val_precision: 0.5845\n",
            "Epoch 159/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1963 - accuracy: 0.9164 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 0.9921 - recall: 0.9483 - precision: 0.8932\n",
            "Epoch 159: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.1963 - accuracy: 0.9164 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 0.9921 - recall: 0.9483 - precision: 0.8932 - val_loss: 1.1558 - val_accuracy: 0.6328 - val_sensitivity_at_specificity: 0.6328 - val_specificity_at_sensitivity: 0.5797 - val_recall: 0.9344 - val_precision: 0.5828\n",
            "Epoch 160/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1847 - accuracy: 0.9238 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9946 - recall: 0.9404 - precision: 0.9079\n",
            "Epoch 160: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.1847 - accuracy: 0.9238 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9946 - recall: 0.9404 - precision: 0.9079 - val_loss: 1.3774 - val_accuracy: 0.6422 - val_sensitivity_at_specificity: 0.7551 - val_specificity_at_sensitivity: 0.6461 - val_recall: 0.9747 - val_precision: 0.5826\n",
            "Epoch 161/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1858 - accuracy: 0.9242 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9936 - recall: 0.9658 - precision: 0.8951\n",
            "Epoch 161: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.1858 - accuracy: 0.9242 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9936 - recall: 0.9658 - precision: 0.8951 - val_loss: 1.3545 - val_accuracy: 0.6195 - val_sensitivity_at_specificity: 0.6589 - val_specificity_at_sensitivity: 0.6094 - val_recall: 0.9535 - val_precision: 0.5737\n",
            "Epoch 162/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1969 - accuracy: 0.9152 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9963 - recall: 0.9411 - precision: 0.8881\n",
            "Epoch 162: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.1969 - accuracy: 0.9152 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9963 - recall: 0.9411 - precision: 0.8881 - val_loss: 1.3719 - val_accuracy: 0.6313 - val_sensitivity_at_specificity: 0.6169 - val_specificity_at_sensitivity: 0.5841 - val_recall: 0.9646 - val_precision: 0.5827\n",
            "Epoch 163/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1861 - accuracy: 0.9223 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9945 - recall: 0.9522 - precision: 0.9001\n",
            "Epoch 163: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.1861 - accuracy: 0.9223 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9945 - recall: 0.9522 - precision: 0.9001 - val_loss: 1.7145 - val_accuracy: 0.6195 - val_sensitivity_at_specificity: 0.6286 - val_specificity_at_sensitivity: 0.5821 - val_recall: 0.9839 - val_precision: 0.5620\n",
            "Epoch 164/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1557 - accuracy: 0.9426 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9969 - recall: 0.9635 - precision: 0.9231\n",
            "Epoch 164: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.1557 - accuracy: 0.9426 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9969 - recall: 0.9635 - precision: 0.9231 - val_loss: 1.6423 - val_accuracy: 0.6195 - val_sensitivity_at_specificity: 0.7500 - val_specificity_at_sensitivity: 0.6488 - val_recall: 0.9605 - val_precision: 0.5578\n",
            "Epoch 165/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1784 - accuracy: 0.9270 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9960 - recall: 0.9561 - precision: 0.9052\n",
            "Epoch 165: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 175ms/step - loss: 0.1784 - accuracy: 0.9270 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9960 - recall: 0.9561 - precision: 0.9052 - val_loss: 1.3804 - val_accuracy: 0.6266 - val_sensitivity_at_specificity: 0.6260 - val_specificity_at_sensitivity: 0.5814 - val_recall: 0.9614 - val_precision: 0.5786\n",
            "Epoch 166/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1734 - accuracy: 0.9285 - sensitivity_at_specificity: 0.9977 - specificity_at_sensitivity: 1.0000 - recall: 0.9540 - precision: 0.9100\n",
            "Epoch 166: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.1734 - accuracy: 0.9285 - sensitivity_at_specificity: 0.9977 - specificity_at_sensitivity: 1.0000 - recall: 0.9540 - precision: 0.9100 - val_loss: 1.6155 - val_accuracy: 0.6102 - val_sensitivity_at_specificity: 0.6464 - val_specificity_at_sensitivity: 0.5847 - val_recall: 0.9664 - val_precision: 0.5582\n",
            "Epoch 167/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1540 - accuracy: 0.9379 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9992 - recall: 0.9696 - precision: 0.9122\n",
            "Epoch 167: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 174ms/step - loss: 0.1540 - accuracy: 0.9379 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9992 - recall: 0.9696 - precision: 0.9122 - val_loss: 1.4766 - val_accuracy: 0.6398 - val_sensitivity_at_specificity: 0.6915 - val_specificity_at_sensitivity: 0.6389 - val_recall: 0.9747 - val_precision: 0.5806\n",
            "Epoch 168/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1681 - accuracy: 0.9332 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9969 - recall: 0.9632 - precision: 0.9085\n",
            "Epoch 168: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.1681 - accuracy: 0.9332 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9969 - recall: 0.9632 - precision: 0.9085 - val_loss: 1.7907 - val_accuracy: 0.6742 - val_sensitivity_at_specificity: 0.6755 - val_specificity_at_sensitivity: 0.6110 - val_recall: 0.9809 - val_precision: 0.6231\n",
            "Epoch 169/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1500 - accuracy: 0.9387 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9559 - precision: 0.9251\n",
            "Epoch 169: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.1500 - accuracy: 0.9387 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9559 - precision: 0.9251 - val_loss: 1.6699 - val_accuracy: 0.6234 - val_sensitivity_at_specificity: 0.5827 - val_specificity_at_sensitivity: 0.5419 - val_recall: 0.9583 - val_precision: 0.5670\n",
            "Epoch 170/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1754 - accuracy: 0.9211 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9977 - recall: 0.9524 - precision: 0.8942\n",
            "Epoch 170: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.1754 - accuracy: 0.9211 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9977 - recall: 0.9524 - precision: 0.8942 - val_loss: 1.7333 - val_accuracy: 0.6258 - val_sensitivity_at_specificity: 0.6146 - val_specificity_at_sensitivity: 0.5910 - val_recall: 0.9772 - val_precision: 0.5638\n",
            "Epoch 171/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1525 - accuracy: 0.9359 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9961 - recall: 0.9679 - precision: 0.9094\n",
            "Epoch 171: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.1525 - accuracy: 0.9359 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9961 - recall: 0.9679 - precision: 0.9094 - val_loss: 1.5890 - val_accuracy: 0.6234 - val_sensitivity_at_specificity: 0.6034 - val_specificity_at_sensitivity: 0.5808 - val_recall: 0.9533 - val_precision: 0.5756\n",
            "Epoch 172/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1580 - accuracy: 0.9371 - sensitivity_at_specificity: 0.9993 - specificity_at_sensitivity: 1.0000 - recall: 0.9670 - precision: 0.9169\n",
            "Epoch 172: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.1580 - accuracy: 0.9371 - sensitivity_at_specificity: 0.9993 - specificity_at_sensitivity: 1.0000 - recall: 0.9670 - precision: 0.9169 - val_loss: 1.8335 - val_accuracy: 0.6398 - val_sensitivity_at_specificity: 0.7217 - val_specificity_at_sensitivity: 0.6102 - val_recall: 0.9874 - val_precision: 0.5809\n",
            "Epoch 173/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1521 - accuracy: 0.9336 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9491 - precision: 0.9220\n",
            "Epoch 173: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.1521 - accuracy: 0.9336 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9491 - precision: 0.9220 - val_loss: 2.0908 - val_accuracy: 0.6227 - val_sensitivity_at_specificity: 0.5639 - val_specificity_at_sensitivity: 0.5520 - val_recall: 0.9840 - val_precision: 0.5657\n",
            "Epoch 174/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1463 - accuracy: 0.9465 - sensitivity_at_specificity: 0.9993 - specificity_at_sensitivity: 1.0000 - recall: 0.9694 - precision: 0.9311\n",
            "Epoch 174: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.1463 - accuracy: 0.9465 - sensitivity_at_specificity: 0.9993 - specificity_at_sensitivity: 1.0000 - recall: 0.9694 - precision: 0.9311 - val_loss: 1.7312 - val_accuracy: 0.6367 - val_sensitivity_at_specificity: 0.6102 - val_specificity_at_sensitivity: 0.5582 - val_recall: 0.9783 - val_precision: 0.5828\n",
            "Epoch 175/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1455 - accuracy: 0.9390 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9657 - precision: 0.9131\n",
            "Epoch 175: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.1455 - accuracy: 0.9390 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9657 - precision: 0.9131 - val_loss: 1.9090 - val_accuracy: 0.6148 - val_sensitivity_at_specificity: 0.6285 - val_specificity_at_sensitivity: 0.5859 - val_recall: 0.9820 - val_precision: 0.5545\n",
            "Epoch 176/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1603 - accuracy: 0.9371 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9565 - precision: 0.9215\n",
            "Epoch 176: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.1603 - accuracy: 0.9371 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9565 - precision: 0.9215 - val_loss: 1.8621 - val_accuracy: 0.6242 - val_sensitivity_at_specificity: 0.6598 - val_specificity_at_sensitivity: 0.6093 - val_recall: 0.9827 - val_precision: 0.5704\n",
            "Epoch 177/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1616 - accuracy: 0.9336 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9619 - precision: 0.9110\n",
            "Epoch 177: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.1616 - accuracy: 0.9336 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9619 - precision: 0.9110 - val_loss: 1.5458 - val_accuracy: 0.6281 - val_sensitivity_at_specificity: 0.5951 - val_specificity_at_sensitivity: 0.5795 - val_recall: 0.9528 - val_precision: 0.5845\n",
            "Epoch 178/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1477 - accuracy: 0.9438 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9970 - recall: 0.9599 - precision: 0.9251\n",
            "Epoch 178: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.1477 - accuracy: 0.9438 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9970 - recall: 0.9599 - precision: 0.9251 - val_loss: 1.7571 - val_accuracy: 0.6242 - val_sensitivity_at_specificity: 0.6736 - val_specificity_at_sensitivity: 0.6033 - val_recall: 0.9630 - val_precision: 0.5667\n",
            "Epoch 179/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1449 - accuracy: 0.9461 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9976 - recall: 0.9682 - precision: 0.9279\n",
            "Epoch 179: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.1449 - accuracy: 0.9461 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9976 - recall: 0.9682 - precision: 0.9279 - val_loss: 1.7602 - val_accuracy: 0.6461 - val_sensitivity_at_specificity: 0.6401 - val_specificity_at_sensitivity: 0.6113 - val_recall: 0.9705 - val_precision: 0.6031\n",
            "Epoch 180/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1335 - accuracy: 0.9477 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9977 - recall: 0.9711 - precision: 0.9276\n",
            "Epoch 180: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.1335 - accuracy: 0.9477 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9977 - recall: 0.9711 - precision: 0.9276 - val_loss: 1.7553 - val_accuracy: 0.6133 - val_sensitivity_at_specificity: 0.6651 - val_specificity_at_sensitivity: 0.6129 - val_recall: 0.9720 - val_precision: 0.5668\n",
            "Epoch 181/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1462 - accuracy: 0.9457 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9558 - precision: 0.9376\n",
            "Epoch 181: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.1462 - accuracy: 0.9457 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9558 - precision: 0.9376 - val_loss: 1.7318 - val_accuracy: 0.6383 - val_sensitivity_at_specificity: 0.6583 - val_specificity_at_sensitivity: 0.6103 - val_recall: 0.9844 - val_precision: 0.5821\n",
            "Epoch 182/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1386 - accuracy: 0.9430 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9627 - precision: 0.9268\n",
            "Epoch 182: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.1386 - accuracy: 0.9430 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9627 - precision: 0.9268 - val_loss: 1.8335 - val_accuracy: 0.6133 - val_sensitivity_at_specificity: 0.5670 - val_specificity_at_sensitivity: 0.5372 - val_recall: 0.9784 - val_precision: 0.5690\n",
            "Epoch 183/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1428 - accuracy: 0.9438 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9665 - precision: 0.9270\n",
            "Epoch 183: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.1428 - accuracy: 0.9438 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9665 - precision: 0.9270 - val_loss: 1.6359 - val_accuracy: 0.6547 - val_sensitivity_at_specificity: 0.6722 - val_specificity_at_sensitivity: 0.6258 - val_recall: 0.9671 - val_precision: 0.6060\n",
            "Epoch 184/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1388 - accuracy: 0.9427 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9558 - precision: 0.9290\n",
            "Epoch 184: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.1388 - accuracy: 0.9427 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9558 - precision: 0.9290 - val_loss: 1.8559 - val_accuracy: 0.6000 - val_sensitivity_at_specificity: 0.6065 - val_specificity_at_sensitivity: 0.6015 - val_recall: 0.9545 - val_precision: 0.5481\n",
            "Epoch 185/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1588 - accuracy: 0.9328 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9977 - recall: 0.9535 - precision: 0.9146\n",
            "Epoch 185: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.1588 - accuracy: 0.9328 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9977 - recall: 0.9535 - precision: 0.9146 - val_loss: 1.9232 - val_accuracy: 0.6258 - val_sensitivity_at_specificity: 0.6512 - val_specificity_at_sensitivity: 0.5893 - val_recall: 0.9680 - val_precision: 0.5686\n",
            "Epoch 186/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1334 - accuracy: 0.9496 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9764 - precision: 0.9261\n",
            "Epoch 186: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.1334 - accuracy: 0.9496 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9764 - precision: 0.9261 - val_loss: 1.8327 - val_accuracy: 0.6070 - val_sensitivity_at_specificity: 0.6731 - val_specificity_at_sensitivity: 0.6103 - val_recall: 0.9693 - val_precision: 0.5531\n",
            "Epoch 187/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1379 - accuracy: 0.9445 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9730 - precision: 0.9218\n",
            "Epoch 187: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 184ms/step - loss: 0.1379 - accuracy: 0.9445 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9730 - precision: 0.9218 - val_loss: 1.8973 - val_accuracy: 0.6484 - val_sensitivity_at_specificity: 0.6845 - val_specificity_at_sensitivity: 0.5991 - val_recall: 0.9811 - val_precision: 0.5868\n",
            "Epoch 188/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1294 - accuracy: 0.9496 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9754 - precision: 0.9290\n",
            "Epoch 188: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 174ms/step - loss: 0.1294 - accuracy: 0.9496 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9754 - precision: 0.9290 - val_loss: 2.1508 - val_accuracy: 0.6133 - val_sensitivity_at_specificity: 0.5965 - val_specificity_at_sensitivity: 0.5620 - val_recall: 0.9649 - val_precision: 0.5612\n",
            "Epoch 189/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1346 - accuracy: 0.9473 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9632 - precision: 0.9332\n",
            "Epoch 189: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.1346 - accuracy: 0.9473 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9632 - precision: 0.9332 - val_loss: 2.1272 - val_accuracy: 0.6297 - val_sensitivity_at_specificity: 0.6834 - val_specificity_at_sensitivity: 0.6248 - val_recall: 0.9709 - val_precision: 0.5686\n",
            "Epoch 190/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1124 - accuracy: 0.9570 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9746 - precision: 0.9427\n",
            "Epoch 190: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 175ms/step - loss: 0.1124 - accuracy: 0.9570 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9746 - precision: 0.9427 - val_loss: 1.8613 - val_accuracy: 0.6227 - val_sensitivity_at_specificity: 0.6352 - val_specificity_at_sensitivity: 0.6087 - val_recall: 0.9686 - val_precision: 0.5709\n",
            "Epoch 191/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1130 - accuracy: 0.9566 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9789 - precision: 0.9399\n",
            "Epoch 191: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 175ms/step - loss: 0.1130 - accuracy: 0.9566 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9789 - precision: 0.9399 - val_loss: 2.2147 - val_accuracy: 0.6187 - val_sensitivity_at_specificity: 0.5828 - val_specificity_at_sensitivity: 0.5589 - val_recall: 0.9847 - val_precision: 0.5732\n",
            "Epoch 192/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1118 - accuracy: 0.9531 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9697 - precision: 0.9368\n",
            "Epoch 192: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 176ms/step - loss: 0.1118 - accuracy: 0.9531 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9697 - precision: 0.9368 - val_loss: 2.0563 - val_accuracy: 0.6234 - val_sensitivity_at_specificity: 0.6085 - val_specificity_at_sensitivity: 0.6087 - val_recall: 0.9858 - val_precision: 0.5700\n",
            "Epoch 193/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1195 - accuracy: 0.9512 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9718 - precision: 0.9304\n",
            "Epoch 193: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.1195 - accuracy: 0.9512 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9718 - precision: 0.9304 - val_loss: 1.9413 - val_accuracy: 0.6305 - val_sensitivity_at_specificity: 0.6785 - val_specificity_at_sensitivity: 0.5991 - val_recall: 0.9515 - val_precision: 0.5707\n",
            "Epoch 194/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1273 - accuracy: 0.9477 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9682 - precision: 0.9306\n",
            "Epoch 194: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 174ms/step - loss: 0.1273 - accuracy: 0.9477 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9682 - precision: 0.9306 - val_loss: 1.5577 - val_accuracy: 0.6344 - val_sensitivity_at_specificity: 0.6849 - val_specificity_at_sensitivity: 0.6116 - val_recall: 0.9239 - val_precision: 0.5922\n",
            "Epoch 195/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1362 - accuracy: 0.9445 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9707 - precision: 0.9210\n",
            "Epoch 195: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 175ms/step - loss: 0.1362 - accuracy: 0.9445 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9707 - precision: 0.9210 - val_loss: 2.4382 - val_accuracy: 0.6070 - val_sensitivity_at_specificity: 0.5670 - val_specificity_at_sensitivity: 0.5552 - val_recall: 0.9645 - val_precision: 0.5538\n",
            "Epoch 196/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1236 - accuracy: 0.9527 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9985 - recall: 0.9648 - precision: 0.9400\n",
            "Epoch 196: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.1236 - accuracy: 0.9527 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9985 - recall: 0.9648 - precision: 0.9400 - val_loss: 2.0702 - val_accuracy: 0.6039 - val_sensitivity_at_specificity: 0.5463 - val_specificity_at_sensitivity: 0.5272 - val_recall: 0.9733 - val_precision: 0.5586\n",
            "Epoch 197/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1332 - accuracy: 0.9434 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9651 - precision: 0.9278\n",
            "Epoch 197: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.1332 - accuracy: 0.9434 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9651 - precision: 0.9278 - val_loss: 2.2808 - val_accuracy: 0.5992 - val_sensitivity_at_specificity: 0.6548 - val_specificity_at_sensitivity: 0.5822 - val_recall: 0.9433 - val_precision: 0.5491\n",
            "Epoch 198/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1319 - accuracy: 0.9410 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9640 - precision: 0.9215\n",
            "Epoch 198: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.1319 - accuracy: 0.9410 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9640 - precision: 0.9215 - val_loss: 2.3277 - val_accuracy: 0.6016 - val_sensitivity_at_specificity: 0.5461 - val_specificity_at_sensitivity: 0.5402 - val_recall: 0.9655 - val_precision: 0.5455\n",
            "Epoch 199/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1049 - accuracy: 0.9559 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9680 - precision: 0.9471\n",
            "Epoch 199: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.1049 - accuracy: 0.9559 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9680 - precision: 0.9471 - val_loss: 2.2036 - val_accuracy: 0.6398 - val_sensitivity_at_specificity: 0.6438 - val_specificity_at_sensitivity: 0.5987 - val_recall: 0.9726 - val_precision: 0.5906\n",
            "Epoch 200/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1263 - accuracy: 0.9496 - sensitivity_at_specificity: 0.9968 - specificity_at_sensitivity: 0.9992 - recall: 0.9639 - precision: 0.9347\n",
            "Epoch 200: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 174ms/step - loss: 0.1263 - accuracy: 0.9496 - sensitivity_at_specificity: 0.9968 - specificity_at_sensitivity: 0.9992 - recall: 0.9639 - precision: 0.9347 - val_loss: 1.8173 - val_accuracy: 0.6391 - val_sensitivity_at_specificity: 0.6204 - val_specificity_at_sensitivity: 0.5753 - val_recall: 0.9695 - val_precision: 0.5900\n",
            "Epoch 201/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1235 - accuracy: 0.9492 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9720 - precision: 0.9275\n",
            "Epoch 201: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.1235 - accuracy: 0.9492 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9720 - precision: 0.9275 - val_loss: 2.1654 - val_accuracy: 0.6078 - val_sensitivity_at_specificity: 0.5844 - val_specificity_at_sensitivity: 0.5767 - val_recall: 0.9729 - val_precision: 0.5575\n",
            "Epoch 202/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1325 - accuracy: 0.9480 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9705 - precision: 0.9269\n",
            "Epoch 202: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 174ms/step - loss: 0.1325 - accuracy: 0.9480 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9705 - precision: 0.9269 - val_loss: 2.0237 - val_accuracy: 0.6117 - val_sensitivity_at_specificity: 0.5678 - val_specificity_at_sensitivity: 0.5588 - val_recall: 0.9543 - val_precision: 0.5638\n",
            "Epoch 203/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1097 - accuracy: 0.9520 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9637 - precision: 0.9426\n",
            "Epoch 203: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 174ms/step - loss: 0.1097 - accuracy: 0.9520 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9637 - precision: 0.9426 - val_loss: 2.1281 - val_accuracy: 0.6422 - val_sensitivity_at_specificity: 0.6907 - val_specificity_at_sensitivity: 0.6220 - val_recall: 0.9694 - val_precision: 0.5910\n",
            "Epoch 204/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1068 - accuracy: 0.9551 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9651 - precision: 0.9467\n",
            "Epoch 204: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.1068 - accuracy: 0.9551 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9651 - precision: 0.9467 - val_loss: 2.5873 - val_accuracy: 0.6180 - val_sensitivity_at_specificity: 0.6069 - val_specificity_at_sensitivity: 0.5997 - val_recall: 0.9886 - val_precision: 0.5570\n",
            "Epoch 205/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1138 - accuracy: 0.9543 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9731 - precision: 0.9368\n",
            "Epoch 205: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.1138 - accuracy: 0.9543 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9731 - precision: 0.9368 - val_loss: 2.2966 - val_accuracy: 0.5992 - val_sensitivity_at_specificity: 0.5797 - val_specificity_at_sensitivity: 0.5675 - val_recall: 0.9791 - val_precision: 0.5487\n",
            "Epoch 206/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1123 - accuracy: 0.9551 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9722 - precision: 0.9409\n",
            "Epoch 206: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.1123 - accuracy: 0.9551 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9722 - precision: 0.9409 - val_loss: 2.3272 - val_accuracy: 0.6234 - val_sensitivity_at_specificity: 0.5861 - val_specificity_at_sensitivity: 0.5744 - val_recall: 0.9683 - val_precision: 0.5817\n",
            "Epoch 207/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1004 - accuracy: 0.9602 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9729 - precision: 0.9494\n",
            "Epoch 207: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.1004 - accuracy: 0.9602 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9729 - precision: 0.9494 - val_loss: 2.1945 - val_accuracy: 0.6000 - val_sensitivity_at_specificity: 0.5896 - val_specificity_at_sensitivity: 0.5455 - val_recall: 0.9694 - val_precision: 0.5627\n",
            "Epoch 208/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1202 - accuracy: 0.9520 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9682 - precision: 0.9384\n",
            "Epoch 208: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 174ms/step - loss: 0.1202 - accuracy: 0.9520 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9682 - precision: 0.9384 - val_loss: 2.1576 - val_accuracy: 0.6227 - val_sensitivity_at_specificity: 0.6435 - val_specificity_at_sensitivity: 0.5649 - val_recall: 0.9614 - val_precision: 0.5763\n",
            "Epoch 209/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0985 - accuracy: 0.9637 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9767 - precision: 0.9524\n",
            "Epoch 209: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 189ms/step - loss: 0.0985 - accuracy: 0.9637 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9767 - precision: 0.9524 - val_loss: 2.5023 - val_accuracy: 0.5930 - val_sensitivity_at_specificity: 0.5906 - val_specificity_at_sensitivity: 0.5775 - val_recall: 0.9715 - val_precision: 0.5346\n",
            "Epoch 210/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1033 - accuracy: 0.9617 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9744 - precision: 0.9529\n",
            "Epoch 210: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 199ms/step - loss: 0.1033 - accuracy: 0.9617 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9744 - precision: 0.9529 - val_loss: 2.0991 - val_accuracy: 0.6164 - val_sensitivity_at_specificity: 0.6499 - val_specificity_at_sensitivity: 0.5958 - val_recall: 0.9822 - val_precision: 0.5580\n",
            "Epoch 211/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1040 - accuracy: 0.9590 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9777 - precision: 0.9410\n",
            "Epoch 211: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 3s 303ms/step - loss: 0.1040 - accuracy: 0.9590 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9777 - precision: 0.9410 - val_loss: 2.1611 - val_accuracy: 0.6273 - val_sensitivity_at_specificity: 0.6783 - val_specificity_at_sensitivity: 0.6006 - val_recall: 0.9666 - val_precision: 0.5833\n",
            "Epoch 212/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0914 - accuracy: 0.9639 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9778 - precision: 0.9519\n",
            "Epoch 212: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 232ms/step - loss: 0.0914 - accuracy: 0.9639 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9778 - precision: 0.9519 - val_loss: 2.2875 - val_accuracy: 0.6383 - val_sensitivity_at_specificity: 0.6190 - val_specificity_at_sensitivity: 0.5856 - val_recall: 0.9736 - val_precision: 0.5840\n",
            "Epoch 213/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1084 - accuracy: 0.9590 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9985 - recall: 0.9658 - precision: 0.9515\n",
            "Epoch 213: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.1084 - accuracy: 0.9590 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9985 - recall: 0.9658 - precision: 0.9515 - val_loss: 2.4644 - val_accuracy: 0.6203 - val_sensitivity_at_specificity: 0.6575 - val_specificity_at_sensitivity: 0.5889 - val_recall: 0.9724 - val_precision: 0.5609\n",
            "Epoch 214/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0844 - accuracy: 0.9684 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9829 - precision: 0.9554\n",
            "Epoch 214: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 174ms/step - loss: 0.0844 - accuracy: 0.9684 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9829 - precision: 0.9554 - val_loss: 2.0862 - val_accuracy: 0.6484 - val_sensitivity_at_specificity: 0.7212 - val_specificity_at_sensitivity: 0.5984 - val_recall: 0.9727 - val_precision: 0.5978\n",
            "Epoch 215/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1030 - accuracy: 0.9586 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9762 - precision: 0.9442\n",
            "Epoch 215: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.1030 - accuracy: 0.9586 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9762 - precision: 0.9442 - val_loss: 2.0959 - val_accuracy: 0.6523 - val_sensitivity_at_specificity: 0.6992 - val_specificity_at_sensitivity: 0.6520 - val_recall: 0.9674 - val_precision: 0.5954\n",
            "Epoch 216/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1018 - accuracy: 0.9586 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9708 - precision: 0.9468\n",
            "Epoch 216: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 177ms/step - loss: 0.1018 - accuracy: 0.9586 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9708 - precision: 0.9468 - val_loss: 2.3968 - val_accuracy: 0.6258 - val_sensitivity_at_specificity: 0.6129 - val_specificity_at_sensitivity: 0.5685 - val_recall: 0.9796 - val_precision: 0.5729\n",
            "Epoch 217/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1067 - accuracy: 0.9547 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9659 - precision: 0.9434\n",
            "Epoch 217: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.1067 - accuracy: 0.9547 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9659 - precision: 0.9434 - val_loss: 2.6341 - val_accuracy: 0.6219 - val_sensitivity_at_specificity: 0.6308 - val_specificity_at_sensitivity: 0.6012 - val_recall: 0.9823 - val_precision: 0.5641\n",
            "Epoch 218/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1020 - accuracy: 0.9559 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9652 - precision: 0.9465\n",
            "Epoch 218: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.1020 - accuracy: 0.9559 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9652 - precision: 0.9465 - val_loss: 2.0761 - val_accuracy: 0.6289 - val_sensitivity_at_specificity: 0.6930 - val_specificity_at_sensitivity: 0.6252 - val_recall: 0.9535 - val_precision: 0.5802\n",
            "Epoch 219/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1113 - accuracy: 0.9500 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9648 - precision: 0.9349\n",
            "Epoch 219: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 175ms/step - loss: 0.1113 - accuracy: 0.9500 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9648 - precision: 0.9349 - val_loss: 1.9069 - val_accuracy: 0.6484 - val_sensitivity_at_specificity: 0.6351 - val_specificity_at_sensitivity: 0.5744 - val_recall: 0.9649 - val_precision: 0.5968\n",
            "Epoch 220/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1145 - accuracy: 0.9602 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9799 - precision: 0.9434\n",
            "Epoch 220: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 176ms/step - loss: 0.1145 - accuracy: 0.9602 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9799 - precision: 0.9434 - val_loss: 2.4876 - val_accuracy: 0.6297 - val_sensitivity_at_specificity: 0.6393 - val_specificity_at_sensitivity: 0.5615 - val_recall: 0.9791 - val_precision: 0.5688\n",
            "Epoch 221/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0962 - accuracy: 0.9605 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9755 - precision: 0.9464\n",
            "Epoch 221: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 175ms/step - loss: 0.0962 - accuracy: 0.9605 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9755 - precision: 0.9464 - val_loss: 1.9844 - val_accuracy: 0.6586 - val_sensitivity_at_specificity: 0.6433 - val_specificity_at_sensitivity: 0.5934 - val_recall: 0.9746 - val_precision: 0.6086\n",
            "Epoch 222/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0913 - accuracy: 0.9648 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9744 - precision: 0.9566\n",
            "Epoch 222: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 174ms/step - loss: 0.0913 - accuracy: 0.9648 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9744 - precision: 0.9566 - val_loss: 2.7554 - val_accuracy: 0.6195 - val_sensitivity_at_specificity: 0.5537 - val_specificity_at_sensitivity: 0.5016 - val_recall: 0.9831 - val_precision: 0.5739\n",
            "Epoch 223/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0955 - accuracy: 0.9626 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9755 - precision: 0.9499\n",
            "Epoch 223: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.0955 - accuracy: 0.9626 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9755 - precision: 0.9499 - val_loss: 2.3143 - val_accuracy: 0.6281 - val_sensitivity_at_specificity: 0.6759 - val_specificity_at_sensitivity: 0.5949 - val_recall: 0.9769 - val_precision: 0.5786\n",
            "Epoch 224/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0964 - accuracy: 0.9652 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9781 - precision: 0.9534\n",
            "Epoch 224: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 176ms/step - loss: 0.0964 - accuracy: 0.9652 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9781 - precision: 0.9534 - val_loss: 2.3330 - val_accuracy: 0.6414 - val_sensitivity_at_specificity: 0.6915 - val_specificity_at_sensitivity: 0.6003 - val_recall: 0.9810 - val_precision: 0.5811\n",
            "Epoch 225/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0863 - accuracy: 0.9668 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9794 - precision: 0.9545\n",
            "Epoch 225: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 177ms/step - loss: 0.0863 - accuracy: 0.9668 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9794 - precision: 0.9545 - val_loss: 2.9283 - val_accuracy: 0.5953 - val_sensitivity_at_specificity: 0.5978 - val_specificity_at_sensitivity: 0.5774 - val_recall: 0.9826 - val_precision: 0.5513\n",
            "Epoch 226/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0924 - accuracy: 0.9590 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9684 - precision: 0.9477\n",
            "Epoch 226: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.0924 - accuracy: 0.9590 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9684 - precision: 0.9477 - val_loss: 2.8163 - val_accuracy: 0.6227 - val_sensitivity_at_specificity: 0.6135 - val_specificity_at_sensitivity: 0.5710 - val_recall: 0.9828 - val_precision: 0.5709\n",
            "Epoch 227/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0892 - accuracy: 0.9645 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9715 - precision: 0.9589\n",
            "Epoch 227: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 177ms/step - loss: 0.0892 - accuracy: 0.9645 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9715 - precision: 0.9589 - val_loss: 2.5375 - val_accuracy: 0.6234 - val_sensitivity_at_specificity: 0.6302 - val_specificity_at_sensitivity: 0.5721 - val_recall: 0.9738 - val_precision: 0.5761\n",
            "Epoch 228/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0978 - accuracy: 0.9578 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9715 - precision: 0.9466\n",
            "Epoch 228: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.0978 - accuracy: 0.9578 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9715 - precision: 0.9466 - val_loss: 2.1493 - val_accuracy: 0.6258 - val_sensitivity_at_specificity: 0.6481 - val_specificity_at_sensitivity: 0.5859 - val_recall: 0.9761 - val_precision: 0.5692\n",
            "Epoch 229/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1031 - accuracy: 0.9570 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9730 - precision: 0.9416\n",
            "Epoch 229: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 175ms/step - loss: 0.1031 - accuracy: 0.9570 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9730 - precision: 0.9416 - val_loss: 2.6360 - val_accuracy: 0.6094 - val_sensitivity_at_specificity: 0.5824 - val_specificity_at_sensitivity: 0.5505 - val_recall: 0.9874 - val_precision: 0.5611\n",
            "Epoch 230/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0924 - accuracy: 0.9668 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9756 - precision: 0.9583\n",
            "Epoch 230: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.0924 - accuracy: 0.9668 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9756 - precision: 0.9583 - val_loss: 2.5571 - val_accuracy: 0.6523 - val_sensitivity_at_specificity: 0.6824 - val_specificity_at_sensitivity: 0.6176 - val_recall: 0.9786 - val_precision: 0.5979\n",
            "Epoch 231/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1057 - accuracy: 0.9574 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9685 - precision: 0.9469\n",
            "Epoch 231: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 174ms/step - loss: 0.1057 - accuracy: 0.9574 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9685 - precision: 0.9469 - val_loss: 2.2058 - val_accuracy: 0.6242 - val_sensitivity_at_specificity: 0.6028 - val_specificity_at_sensitivity: 0.5764 - val_recall: 0.9479 - val_precision: 0.5803\n",
            "Epoch 232/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0883 - accuracy: 0.9680 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9785 - precision: 0.9572\n",
            "Epoch 232: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 175ms/step - loss: 0.0883 - accuracy: 0.9680 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9785 - precision: 0.9572 - val_loss: 2.9101 - val_accuracy: 0.5797 - val_sensitivity_at_specificity: 0.5919 - val_specificity_at_sensitivity: 0.5579 - val_recall: 0.9870 - val_precision: 0.5339\n",
            "Epoch 233/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1065 - accuracy: 0.9559 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9680 - precision: 0.9451\n",
            "Epoch 233: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 174ms/step - loss: 0.1065 - accuracy: 0.9559 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9680 - precision: 0.9451 - val_loss: 2.6619 - val_accuracy: 0.6305 - val_sensitivity_at_specificity: 0.6439 - val_specificity_at_sensitivity: 0.5730 - val_recall: 0.9813 - val_precision: 0.5778\n",
            "Epoch 234/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1109 - accuracy: 0.9523 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9657 - precision: 0.9407\n",
            "Epoch 234: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 176ms/step - loss: 0.1109 - accuracy: 0.9523 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9657 - precision: 0.9407 - val_loss: 2.4922 - val_accuracy: 0.6320 - val_sensitivity_at_specificity: 0.6535 - val_specificity_at_sensitivity: 0.5814 - val_recall: 0.9622 - val_precision: 0.5775\n",
            "Epoch 235/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0987 - accuracy: 0.9609 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9764 - precision: 0.9490\n",
            "Epoch 235: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 177ms/step - loss: 0.0987 - accuracy: 0.9609 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9764 - precision: 0.9490 - val_loss: 2.2110 - val_accuracy: 0.6281 - val_sensitivity_at_specificity: 0.5972 - val_specificity_at_sensitivity: 0.5714 - val_recall: 0.9705 - val_precision: 0.5772\n",
            "Epoch 236/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0911 - accuracy: 0.9590 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9748 - precision: 0.9467\n",
            "Epoch 236: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.0911 - accuracy: 0.9590 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9748 - precision: 0.9467 - val_loss: 2.3921 - val_accuracy: 0.6352 - val_sensitivity_at_specificity: 0.6829 - val_specificity_at_sensitivity: 0.6143 - val_recall: 0.9812 - val_precision: 0.5787\n",
            "Epoch 237/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0856 - accuracy: 0.9629 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9766 - precision: 0.9528\n",
            "Epoch 237: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 176ms/step - loss: 0.0856 - accuracy: 0.9629 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9766 - precision: 0.9528 - val_loss: 2.4617 - val_accuracy: 0.6367 - val_sensitivity_at_specificity: 0.6775 - val_specificity_at_sensitivity: 0.6021 - val_recall: 0.9821 - val_precision: 0.5705\n",
            "Epoch 238/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0982 - accuracy: 0.9590 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9773 - precision: 0.9426\n",
            "Epoch 238: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 177ms/step - loss: 0.0982 - accuracy: 0.9590 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9773 - precision: 0.9426 - val_loss: 2.6083 - val_accuracy: 0.6242 - val_sensitivity_at_specificity: 0.6250 - val_specificity_at_sensitivity: 0.5889 - val_recall: 0.9545 - val_precision: 0.5648\n",
            "Epoch 239/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0943 - accuracy: 0.9617 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9717 - precision: 0.9522\n",
            "Epoch 239: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 174ms/step - loss: 0.0943 - accuracy: 0.9617 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9717 - precision: 0.9522 - val_loss: 2.8801 - val_accuracy: 0.5945 - val_sensitivity_at_specificity: 0.6313 - val_specificity_at_sensitivity: 0.5802 - val_recall: 0.9739 - val_precision: 0.5427\n",
            "Epoch 240/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0827 - accuracy: 0.9676 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9754 - precision: 0.9593\n",
            "Epoch 240: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 176ms/step - loss: 0.0827 - accuracy: 0.9676 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9754 - precision: 0.9593 - val_loss: 2.8654 - val_accuracy: 0.6297 - val_sensitivity_at_specificity: 0.6892 - val_specificity_at_sensitivity: 0.5770 - val_recall: 0.9655 - val_precision: 0.5764\n",
            "Epoch 241/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0843 - accuracy: 0.9617 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9754 - precision: 0.9459\n",
            "Epoch 241: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 176ms/step - loss: 0.0843 - accuracy: 0.9617 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9754 - precision: 0.9459 - val_loss: 2.4177 - val_accuracy: 0.6391 - val_sensitivity_at_specificity: 0.7104 - val_specificity_at_sensitivity: 0.6042 - val_recall: 0.9854 - val_precision: 0.5734\n",
            "Epoch 242/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0786 - accuracy: 0.9672 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9767 - precision: 0.9589\n",
            "Epoch 242: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.0786 - accuracy: 0.9672 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9767 - precision: 0.9589 - val_loss: 2.7294 - val_accuracy: 0.6109 - val_sensitivity_at_specificity: 0.6223 - val_specificity_at_sensitivity: 0.5442 - val_recall: 0.9737 - val_precision: 0.5667\n",
            "Epoch 243/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0745 - accuracy: 0.9723 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9842 - precision: 0.9606\n",
            "Epoch 243: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.0745 - accuracy: 0.9723 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9842 - precision: 0.9606 - val_loss: 2.7238 - val_accuracy: 0.6078 - val_sensitivity_at_specificity: 0.6787 - val_specificity_at_sensitivity: 0.5810 - val_recall: 0.9753 - val_precision: 0.5487\n",
            "Epoch 244/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0866 - accuracy: 0.9668 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9752 - precision: 0.9575\n",
            "Epoch 244: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 179ms/step - loss: 0.0866 - accuracy: 0.9668 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9752 - precision: 0.9575 - val_loss: 2.6326 - val_accuracy: 0.6289 - val_sensitivity_at_specificity: 0.6201 - val_specificity_at_sensitivity: 0.5782 - val_recall: 0.9820 - val_precision: 0.5855\n",
            "Epoch 245/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0903 - accuracy: 0.9656 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9984 - recall: 0.9763 - precision: 0.9573\n",
            "Epoch 245: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 189ms/step - loss: 0.0903 - accuracy: 0.9656 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9984 - recall: 0.9763 - precision: 0.9573 - val_loss: 2.7492 - val_accuracy: 0.6086 - val_sensitivity_at_specificity: 0.6202 - val_specificity_at_sensitivity: 0.5774 - val_recall: 0.9862 - val_precision: 0.5669\n",
            "Epoch 246/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0779 - accuracy: 0.9691 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9782 - precision: 0.9611\n",
            "Epoch 246: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 174ms/step - loss: 0.0779 - accuracy: 0.9691 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9782 - precision: 0.9611 - val_loss: 2.4070 - val_accuracy: 0.6078 - val_sensitivity_at_specificity: 0.7194 - val_specificity_at_sensitivity: 0.5967 - val_recall: 0.9674 - val_precision: 0.5516\n",
            "Epoch 247/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0870 - accuracy: 0.9645 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9763 - precision: 0.9530\n",
            "Epoch 247: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.0870 - accuracy: 0.9645 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9763 - precision: 0.9530 - val_loss: 2.5882 - val_accuracy: 0.6187 - val_sensitivity_at_specificity: 0.5716 - val_specificity_at_sensitivity: 0.5449 - val_recall: 0.9787 - val_precision: 0.5753\n",
            "Epoch 248/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0802 - accuracy: 0.9688 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9842 - precision: 0.9541\n",
            "Epoch 248: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 174ms/step - loss: 0.0802 - accuracy: 0.9688 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9842 - precision: 0.9541 - val_loss: 2.7758 - val_accuracy: 0.6234 - val_sensitivity_at_specificity: 0.6096 - val_specificity_at_sensitivity: 0.5495 - val_recall: 0.9891 - val_precision: 0.5725\n",
            "Epoch 249/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0855 - accuracy: 0.9647 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9768 - precision: 0.9562\n",
            "Epoch 249: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.0855 - accuracy: 0.9647 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9768 - precision: 0.9562 - val_loss: 3.1472 - val_accuracy: 0.6391 - val_sensitivity_at_specificity: 0.6334 - val_specificity_at_sensitivity: 0.5211 - val_recall: 0.9922 - val_precision: 0.5819\n",
            "Epoch 250/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0831 - accuracy: 0.9660 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9779 - precision: 0.9546\n",
            "Epoch 250: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 176ms/step - loss: 0.0831 - accuracy: 0.9660 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9779 - precision: 0.9546 - val_loss: 2.7466 - val_accuracy: 0.6227 - val_sensitivity_at_specificity: 0.6464 - val_specificity_at_sensitivity: 0.5846 - val_recall: 0.9798 - val_precision: 0.5723\n",
            "Epoch 251/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0829 - accuracy: 0.9668 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9703 - precision: 0.9651\n",
            "Epoch 251: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.0829 - accuracy: 0.9668 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9703 - precision: 0.9651 - val_loss: 2.8770 - val_accuracy: 0.6109 - val_sensitivity_at_specificity: 0.5890 - val_specificity_at_sensitivity: 0.5446 - val_recall: 0.9831 - val_precision: 0.5683\n",
            "Epoch 252/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0815 - accuracy: 0.9668 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9809 - precision: 0.9553\n",
            "Epoch 252: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.0815 - accuracy: 0.9668 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9809 - precision: 0.9553 - val_loss: 2.4220 - val_accuracy: 0.6469 - val_sensitivity_at_specificity: 0.7005 - val_specificity_at_sensitivity: 0.6009 - val_recall: 0.9516 - val_precision: 0.5917\n",
            "Epoch 253/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1082 - accuracy: 0.9590 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9985 - recall: 0.9672 - precision: 0.9497\n",
            "Epoch 253: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 177ms/step - loss: 0.1082 - accuracy: 0.9590 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9985 - recall: 0.9672 - precision: 0.9497 - val_loss: 2.6557 - val_accuracy: 0.6133 - val_sensitivity_at_specificity: 0.5643 - val_specificity_at_sensitivity: 0.5354 - val_recall: 0.9659 - val_precision: 0.5684\n",
            "Epoch 254/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0876 - accuracy: 0.9633 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 0.9992 - recall: 0.9693 - precision: 0.9591\n",
            "Epoch 254: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 179ms/step - loss: 0.0876 - accuracy: 0.9633 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 0.9992 - recall: 0.9693 - precision: 0.9591 - val_loss: 3.2923 - val_accuracy: 0.5867 - val_sensitivity_at_specificity: 0.5566 - val_specificity_at_sensitivity: 0.5069 - val_recall: 0.9825 - val_precision: 0.5432\n",
            "Epoch 255/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0800 - accuracy: 0.9684 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9818 - precision: 0.9566\n",
            "Epoch 255: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.0800 - accuracy: 0.9684 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9818 - precision: 0.9566 - val_loss: 2.6203 - val_accuracy: 0.6305 - val_sensitivity_at_specificity: 0.6449 - val_specificity_at_sensitivity: 0.5588 - val_recall: 0.9757 - val_precision: 0.5845\n",
            "Epoch 256/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0999 - accuracy: 0.9578 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9628 - precision: 0.9505\n",
            "Epoch 256: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.0999 - accuracy: 0.9578 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9628 - precision: 0.9505 - val_loss: 2.8019 - val_accuracy: 0.6281 - val_sensitivity_at_specificity: 0.6442 - val_specificity_at_sensitivity: 0.5561 - val_recall: 0.9859 - val_precision: 0.5739\n",
            "Epoch 257/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0894 - accuracy: 0.9637 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9691 - precision: 0.9577\n",
            "Epoch 257: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 174ms/step - loss: 0.0894 - accuracy: 0.9637 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9691 - precision: 0.9577 - val_loss: 2.3855 - val_accuracy: 0.6469 - val_sensitivity_at_specificity: 0.7102 - val_specificity_at_sensitivity: 0.6189 - val_recall: 0.9760 - val_precision: 0.5985\n",
            "Epoch 258/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0762 - accuracy: 0.9684 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9794 - precision: 0.9575\n",
            "Epoch 258: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.0762 - accuracy: 0.9684 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9794 - precision: 0.9575 - val_loss: 2.7379 - val_accuracy: 0.6313 - val_sensitivity_at_specificity: 0.5934 - val_specificity_at_sensitivity: 0.5666 - val_recall: 0.9774 - val_precision: 0.5868\n",
            "Epoch 259/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0944 - accuracy: 0.9660 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9771 - precision: 0.9574\n",
            "Epoch 259: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 174ms/step - loss: 0.0944 - accuracy: 0.9660 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9771 - precision: 0.9574 - val_loss: 2.8379 - val_accuracy: 0.6180 - val_sensitivity_at_specificity: 0.6150 - val_specificity_at_sensitivity: 0.5719 - val_recall: 0.9840 - val_precision: 0.5626\n",
            "Epoch 260/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0703 - accuracy: 0.9715 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9803 - precision: 0.9629\n",
            "Epoch 260: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 178ms/step - loss: 0.0703 - accuracy: 0.9715 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9803 - precision: 0.9629 - val_loss: 2.6587 - val_accuracy: 0.6273 - val_sensitivity_at_specificity: 0.6322 - val_specificity_at_sensitivity: 0.5659 - val_recall: 0.9787 - val_precision: 0.5818\n",
            "Epoch 261/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0821 - accuracy: 0.9707 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9779 - precision: 0.9635\n",
            "Epoch 261: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.0821 - accuracy: 0.9707 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9779 - precision: 0.9635 - val_loss: 2.4902 - val_accuracy: 0.6516 - val_sensitivity_at_specificity: 0.6897 - val_specificity_at_sensitivity: 0.5971 - val_recall: 0.9670 - val_precision: 0.6034\n",
            "Epoch 262/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0744 - accuracy: 0.9688 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9805 - precision: 0.9603\n",
            "Epoch 262: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.0744 - accuracy: 0.9688 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9805 - precision: 0.9603 - val_loss: 2.6414 - val_accuracy: 0.5992 - val_sensitivity_at_specificity: 0.5632 - val_specificity_at_sensitivity: 0.5618 - val_recall: 0.9657 - val_precision: 0.5577\n",
            "Epoch 263/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0847 - accuracy: 0.9645 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9689 - precision: 0.9590\n",
            "Epoch 263: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 174ms/step - loss: 0.0847 - accuracy: 0.9645 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9689 - precision: 0.9590 - val_loss: 2.8369 - val_accuracy: 0.6258 - val_sensitivity_at_specificity: 0.5864 - val_specificity_at_sensitivity: 0.5403 - val_recall: 0.9864 - val_precision: 0.5807\n",
            "Epoch 264/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0752 - accuracy: 0.9695 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9810 - precision: 0.9606\n",
            "Epoch 264: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 176ms/step - loss: 0.0752 - accuracy: 0.9695 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9810 - precision: 0.9606 - val_loss: 2.5391 - val_accuracy: 0.6383 - val_sensitivity_at_specificity: 0.6201 - val_specificity_at_sensitivity: 0.5619 - val_recall: 0.9730 - val_precision: 0.5929\n",
            "Epoch 265/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0713 - accuracy: 0.9723 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9771 - precision: 0.9671\n",
            "Epoch 265: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 179ms/step - loss: 0.0713 - accuracy: 0.9723 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9771 - precision: 0.9671 - val_loss: 3.2112 - val_accuracy: 0.6266 - val_sensitivity_at_specificity: 0.6261 - val_specificity_at_sensitivity: 0.5016 - val_recall: 0.9833 - val_precision: 0.5808\n",
            "Epoch 266/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0750 - accuracy: 0.9727 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9822 - precision: 0.9643\n",
            "Epoch 266: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.0750 - accuracy: 0.9727 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9822 - precision: 0.9643 - val_loss: 3.0910 - val_accuracy: 0.6078 - val_sensitivity_at_specificity: 0.6260 - val_specificity_at_sensitivity: 0.5586 - val_recall: 0.9856 - val_precision: 0.5547\n",
            "Epoch 267/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0730 - accuracy: 0.9699 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9782 - precision: 0.9603\n",
            "Epoch 267: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 175ms/step - loss: 0.0730 - accuracy: 0.9699 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9782 - precision: 0.9603 - val_loss: 3.1090 - val_accuracy: 0.5961 - val_sensitivity_at_specificity: 0.6034 - val_specificity_at_sensitivity: 0.5475 - val_recall: 0.9784 - val_precision: 0.5576\n",
            "Epoch 268/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0801 - accuracy: 0.9699 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9985 - recall: 0.9763 - precision: 0.9634\n",
            "Epoch 268: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 175ms/step - loss: 0.0801 - accuracy: 0.9699 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9985 - recall: 0.9763 - precision: 0.9634 - val_loss: 2.8153 - val_accuracy: 0.6328 - val_sensitivity_at_specificity: 0.6494 - val_specificity_at_sensitivity: 0.5683 - val_recall: 0.9733 - val_precision: 0.5774\n",
            "Epoch 269/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0708 - accuracy: 0.9715 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9828 - precision: 0.9610\n",
            "Epoch 269: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 189ms/step - loss: 0.0708 - accuracy: 0.9715 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9828 - precision: 0.9610 - val_loss: 2.6387 - val_accuracy: 0.6336 - val_sensitivity_at_specificity: 0.6516 - val_specificity_at_sensitivity: 0.5746 - val_recall: 0.9798 - val_precision: 0.5801\n",
            "Epoch 270/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0728 - accuracy: 0.9723 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9817 - precision: 0.9625\n",
            "Epoch 270: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 182ms/step - loss: 0.0728 - accuracy: 0.9723 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9817 - precision: 0.9625 - val_loss: 3.4413 - val_accuracy: 0.5992 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4887 - val_recall: 0.9919 - val_precision: 0.5472\n",
            "Epoch 271/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0627 - accuracy: 0.9746 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9859 - precision: 0.9640\n",
            "Epoch 271: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 175ms/step - loss: 0.0627 - accuracy: 0.9746 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9859 - precision: 0.9640 - val_loss: 3.1785 - val_accuracy: 0.6266 - val_sensitivity_at_specificity: 0.6212 - val_specificity_at_sensitivity: 0.5223 - val_recall: 0.9877 - val_precision: 0.5781\n",
            "Epoch 272/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0607 - accuracy: 0.9785 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9864 - precision: 0.9702\n",
            "Epoch 272: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 175ms/step - loss: 0.0607 - accuracy: 0.9785 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9864 - precision: 0.9702 - val_loss: 3.1567 - val_accuracy: 0.6234 - val_sensitivity_at_specificity: 0.5781 - val_specificity_at_sensitivity: 0.5087 - val_recall: 0.9753 - val_precision: 0.5752\n",
            "Epoch 273/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0729 - accuracy: 0.9707 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9798 - precision: 0.9627\n",
            "Epoch 273: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 176ms/step - loss: 0.0729 - accuracy: 0.9707 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9798 - precision: 0.9627 - val_loss: 3.1913 - val_accuracy: 0.6062 - val_sensitivity_at_specificity: 0.5726 - val_specificity_at_sensitivity: 0.5130 - val_recall: 0.9825 - val_precision: 0.5555\n",
            "Epoch 274/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0748 - accuracy: 0.9703 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9814 - precision: 0.9606\n",
            "Epoch 274: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 175ms/step - loss: 0.0748 - accuracy: 0.9703 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9814 - precision: 0.9606 - val_loss: 3.4612 - val_accuracy: 0.6086 - val_sensitivity_at_specificity: 0.5945 - val_specificity_at_sensitivity: 0.5234 - val_recall: 0.9838 - val_precision: 0.5536\n",
            "Epoch 275/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0676 - accuracy: 0.9772 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9851 - precision: 0.9699\n",
            "Epoch 275: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 176ms/step - loss: 0.0676 - accuracy: 0.9772 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9851 - precision: 0.9699 - val_loss: 3.5370 - val_accuracy: 0.6055 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4908 - val_recall: 0.9778 - val_precision: 0.5565\n",
            "Epoch 276/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0624 - accuracy: 0.9785 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9833 - precision: 0.9732\n",
            "Epoch 276: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 174ms/step - loss: 0.0624 - accuracy: 0.9785 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9833 - precision: 0.9732 - val_loss: 2.9774 - val_accuracy: 0.6609 - val_sensitivity_at_specificity: 0.6823 - val_specificity_at_sensitivity: 0.5477 - val_recall: 0.9849 - val_precision: 0.6056\n",
            "Epoch 277/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0636 - accuracy: 0.9789 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9854 - precision: 0.9734\n",
            "Epoch 277: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.0636 - accuracy: 0.9789 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9854 - precision: 0.9734 - val_loss: 3.2810 - val_accuracy: 0.6422 - val_sensitivity_at_specificity: 0.6043 - val_specificity_at_sensitivity: 0.5088 - val_recall: 0.9848 - val_precision: 0.5909\n",
            "Epoch 278/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0606 - accuracy: 0.9758 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9822 - precision: 0.9702\n",
            "Epoch 278: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.0606 - accuracy: 0.9758 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9822 - precision: 0.9702 - val_loss: 3.1074 - val_accuracy: 0.6422 - val_sensitivity_at_specificity: 0.6862 - val_specificity_at_sensitivity: 0.5397 - val_recall: 0.9800 - val_precision: 0.5887\n",
            "Epoch 279/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0635 - accuracy: 0.9746 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9800 - precision: 0.9683\n",
            "Epoch 279: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 175ms/step - loss: 0.0635 - accuracy: 0.9746 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9800 - precision: 0.9683 - val_loss: 3.7000 - val_accuracy: 0.5891 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4703 - val_recall: 0.9891 - val_precision: 0.5495\n",
            "Epoch 280/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0596 - accuracy: 0.9762 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9846 - precision: 0.9689\n",
            "Epoch 280: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.0596 - accuracy: 0.9762 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9846 - precision: 0.9689 - val_loss: 3.0385 - val_accuracy: 0.6430 - val_sensitivity_at_specificity: 0.6912 - val_specificity_at_sensitivity: 0.5374 - val_recall: 0.9831 - val_precision: 0.5893\n",
            "Epoch 281/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0599 - accuracy: 0.9758 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9833 - precision: 0.9680\n",
            "Epoch 281: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 177ms/step - loss: 0.0599 - accuracy: 0.9758 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9833 - precision: 0.9680 - val_loss: 2.9779 - val_accuracy: 0.6203 - val_sensitivity_at_specificity: 0.6132 - val_specificity_at_sensitivity: 0.5556 - val_recall: 0.9791 - val_precision: 0.5633\n",
            "Epoch 282/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0685 - accuracy: 0.9699 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9814 - precision: 0.9573\n",
            "Epoch 282: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 175ms/step - loss: 0.0685 - accuracy: 0.9699 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9814 - precision: 0.9573 - val_loss: 3.1870 - val_accuracy: 0.6258 - val_sensitivity_at_specificity: 0.6171 - val_specificity_at_sensitivity: 0.5102 - val_recall: 0.9845 - val_precision: 0.5752\n",
            "Epoch 283/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0632 - accuracy: 0.9777 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9819 - precision: 0.9735\n",
            "Epoch 283: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 180ms/step - loss: 0.0632 - accuracy: 0.9777 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9819 - precision: 0.9735 - val_loss: 2.6448 - val_accuracy: 0.6430 - val_sensitivity_at_specificity: 0.6856 - val_specificity_at_sensitivity: 0.6019 - val_recall: 0.9678 - val_precision: 0.5914\n",
            "Epoch 284/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0669 - accuracy: 0.9727 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9819 - precision: 0.9637\n",
            "Epoch 284: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 178ms/step - loss: 0.0669 - accuracy: 0.9727 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9819 - precision: 0.9637 - val_loss: 3.6027 - val_accuracy: 0.6289 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4691 - val_recall: 0.9826 - val_precision: 0.5724\n",
            "Epoch 285/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0738 - accuracy: 0.9719 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9846 - precision: 0.9610\n",
            "Epoch 285: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.0738 - accuracy: 0.9719 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9846 - precision: 0.9610 - val_loss: 2.7776 - val_accuracy: 0.6469 - val_sensitivity_at_specificity: 0.6208 - val_specificity_at_sensitivity: 0.5680 - val_recall: 0.9789 - val_precision: 0.5967\n",
            "Epoch 286/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0637 - accuracy: 0.9750 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9782 - precision: 0.9722\n",
            "Epoch 286: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.0637 - accuracy: 0.9750 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9782 - precision: 0.9722 - val_loss: 3.0604 - val_accuracy: 0.6422 - val_sensitivity_at_specificity: 0.7070 - val_specificity_at_sensitivity: 0.5491 - val_recall: 0.9889 - val_precision: 0.5793\n",
            "Epoch 287/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0659 - accuracy: 0.9738 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9899 - precision: 0.9593\n",
            "Epoch 287: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.0659 - accuracy: 0.9738 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9899 - precision: 0.9593 - val_loss: 2.7985 - val_accuracy: 0.6227 - val_sensitivity_at_specificity: 0.6579 - val_specificity_at_sensitivity: 0.5770 - val_recall: 0.9722 - val_precision: 0.5604\n",
            "Epoch 288/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0641 - accuracy: 0.9742 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9844 - precision: 0.9672\n",
            "Epoch 288: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.0641 - accuracy: 0.9742 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9844 - precision: 0.9672 - val_loss: 3.1727 - val_accuracy: 0.6383 - val_sensitivity_at_specificity: 0.6813 - val_specificity_at_sensitivity: 0.5365 - val_recall: 0.9874 - val_precision: 0.5803\n",
            "Epoch 289/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0614 - accuracy: 0.9773 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9852 - precision: 0.9700\n",
            "Epoch 289: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 175ms/step - loss: 0.0614 - accuracy: 0.9773 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9852 - precision: 0.9700 - val_loss: 3.0522 - val_accuracy: 0.6383 - val_sensitivity_at_specificity: 0.6683 - val_specificity_at_sensitivity: 0.5640 - val_recall: 0.9872 - val_precision: 0.5752\n",
            "Epoch 290/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.0650 - accuracy: 0.9748 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9822 - precision: 0.9690\n",
            "Epoch 290: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.0645 - accuracy: 0.9747 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9829 - precision: 0.9678 - val_loss: 3.0501 - val_accuracy: 0.6398 - val_sensitivity_at_specificity: 0.6636 - val_specificity_at_sensitivity: 0.5431 - val_recall: 0.9862 - val_precision: 0.5880\n",
            "Epoch 291/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0593 - accuracy: 0.9785 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9795 - precision: 0.9772\n",
            "Epoch 291: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 177ms/step - loss: 0.0593 - accuracy: 0.9785 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9795 - precision: 0.9772 - val_loss: 3.4279 - val_accuracy: 0.6211 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4902 - val_recall: 0.9887 - val_precision: 0.5615\n",
            "Epoch 292/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0639 - accuracy: 0.9805 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9865 - precision: 0.9741\n",
            "Epoch 292: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 185ms/step - loss: 0.0639 - accuracy: 0.9805 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9865 - precision: 0.9741 - val_loss: 2.8672 - val_accuracy: 0.6430 - val_sensitivity_at_specificity: 0.6555 - val_specificity_at_sensitivity: 0.5411 - val_recall: 0.9879 - val_precision: 0.5918\n",
            "Epoch 293/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0662 - accuracy: 0.9762 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9842 - precision: 0.9682\n",
            "Epoch 293: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 176ms/step - loss: 0.0662 - accuracy: 0.9762 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9842 - precision: 0.9682 - val_loss: 3.3516 - val_accuracy: 0.6164 - val_sensitivity_at_specificity: 0.6383 - val_specificity_at_sensitivity: 0.5024 - val_recall: 0.9799 - val_precision: 0.5701\n",
            "Epoch 294/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0597 - accuracy: 0.9738 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9791 - precision: 0.9675\n",
            "Epoch 294: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 175ms/step - loss: 0.0597 - accuracy: 0.9738 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9791 - precision: 0.9675 - val_loss: 2.7036 - val_accuracy: 0.6539 - val_sensitivity_at_specificity: 0.6348 - val_specificity_at_sensitivity: 0.5919 - val_recall: 0.9742 - val_precision: 0.6015\n",
            "Epoch 295/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0585 - accuracy: 0.9754 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9813 - precision: 0.9700\n",
            "Epoch 295: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 174ms/step - loss: 0.0585 - accuracy: 0.9754 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9813 - precision: 0.9700 - val_loss: 3.5551 - val_accuracy: 0.6141 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4694 - val_recall: 0.9840 - val_precision: 0.5600\n",
            "Epoch 296/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0569 - accuracy: 0.9809 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9992 - recall: 0.9837 - precision: 0.9784\n",
            "Epoch 296: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 175ms/step - loss: 0.0569 - accuracy: 0.9809 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9992 - recall: 0.9837 - precision: 0.9784 - val_loss: 3.4775 - val_accuracy: 0.6375 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4915 - val_recall: 0.9700 - val_precision: 0.5798\n",
            "Epoch 297/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0620 - accuracy: 0.9773 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9883 - precision: 0.9672\n",
            "Epoch 297: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 179ms/step - loss: 0.0620 - accuracy: 0.9773 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9883 - precision: 0.9672 - val_loss: 3.1806 - val_accuracy: 0.6242 - val_sensitivity_at_specificity: 0.6223 - val_specificity_at_sensitivity: 0.5347 - val_recall: 0.9752 - val_precision: 0.5753\n",
            "Epoch 298/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0498 - accuracy: 0.9805 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9873 - precision: 0.9735\n",
            "Epoch 298: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 179ms/step - loss: 0.0498 - accuracy: 0.9805 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9873 - precision: 0.9735 - val_loss: 3.7395 - val_accuracy: 0.6125 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4604 - val_recall: 0.9840 - val_precision: 0.5582\n",
            "Epoch 299/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0533 - accuracy: 0.9820 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 1.0000 - recall: 0.9866 - precision: 0.9793\n",
            "Epoch 299: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 177ms/step - loss: 0.0533 - accuracy: 0.9820 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 1.0000 - recall: 0.9866 - precision: 0.9793 - val_loss: 3.3607 - val_accuracy: 0.6195 - val_sensitivity_at_specificity: 0.6188 - val_specificity_at_sensitivity: 0.5040 - val_recall: 0.9788 - val_precision: 0.5777\n",
            "Epoch 300/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0709 - accuracy: 0.9738 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9796 - precision: 0.9682\n",
            "Epoch 300: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 174ms/step - loss: 0.0709 - accuracy: 0.9738 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9796 - precision: 0.9682 - val_loss: 3.2375 - val_accuracy: 0.6141 - val_sensitivity_at_specificity: 0.7059 - val_specificity_at_sensitivity: 0.5606 - val_recall: 0.9782 - val_precision: 0.5475\n",
            "Epoch 301/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0616 - accuracy: 0.9738 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9816 - precision: 0.9662\n",
            "Epoch 301: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.0616 - accuracy: 0.9738 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9816 - precision: 0.9662 - val_loss: 3.1449 - val_accuracy: 0.6047 - val_sensitivity_at_specificity: 0.6075 - val_specificity_at_sensitivity: 0.5329 - val_recall: 0.9766 - val_precision: 0.5608\n",
            "Epoch 302/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0631 - accuracy: 0.9762 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9813 - precision: 0.9715\n",
            "Epoch 302: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 176ms/step - loss: 0.0631 - accuracy: 0.9762 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9813 - precision: 0.9715 - val_loss: 3.4578 - val_accuracy: 0.6297 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4920 - val_recall: 0.9742 - val_precision: 0.5838\n",
            "Epoch 303/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0661 - accuracy: 0.9777 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9845 - precision: 0.9717\n",
            "Epoch 303: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 176ms/step - loss: 0.0661 - accuracy: 0.9777 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9845 - precision: 0.9717 - val_loss: 3.0540 - val_accuracy: 0.5984 - val_sensitivity_at_specificity: 0.5404 - val_specificity_at_sensitivity: 0.5316 - val_recall: 0.9588 - val_precision: 0.5535\n",
            "Epoch 304/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0680 - accuracy: 0.9727 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9761 - precision: 0.9702\n",
            "Epoch 304: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 178ms/step - loss: 0.0680 - accuracy: 0.9727 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9761 - precision: 0.9702 - val_loss: 3.1040 - val_accuracy: 0.6461 - val_sensitivity_at_specificity: 0.7038 - val_specificity_at_sensitivity: 0.5264 - val_recall: 0.9908 - val_precision: 0.5922\n",
            "Epoch 305/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0693 - accuracy: 0.9742 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9978 - recall: 0.9820 - precision: 0.9646\n",
            "Epoch 305: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.0693 - accuracy: 0.9742 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9978 - recall: 0.9820 - precision: 0.9646 - val_loss: 3.0375 - val_accuracy: 0.6094 - val_sensitivity_at_specificity: 0.5678 - val_specificity_at_sensitivity: 0.5139 - val_recall: 0.9826 - val_precision: 0.5603\n",
            "Epoch 306/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0577 - accuracy: 0.9789 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9870 - precision: 0.9722\n",
            "Epoch 306: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 175ms/step - loss: 0.0577 - accuracy: 0.9789 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9870 - precision: 0.9722 - val_loss: 3.4399 - val_accuracy: 0.6328 - val_sensitivity_at_specificity: 0.6411 - val_specificity_at_sensitivity: 0.5047 - val_recall: 0.9906 - val_precision: 0.5766\n",
            "Epoch 307/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0546 - accuracy: 0.9793 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9820 - precision: 0.9766\n",
            "Epoch 307: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 178ms/step - loss: 0.0546 - accuracy: 0.9793 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9820 - precision: 0.9766 - val_loss: 3.6449 - val_accuracy: 0.6180 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4628 - val_recall: 0.9653 - val_precision: 0.5783\n",
            "Epoch 308/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0482 - accuracy: 0.9828 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9884 - precision: 0.9778\n",
            "Epoch 308: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 178ms/step - loss: 0.0482 - accuracy: 0.9828 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9884 - precision: 0.9778 - val_loss: 3.3100 - val_accuracy: 0.6383 - val_sensitivity_at_specificity: 0.6382 - val_specificity_at_sensitivity: 0.5264 - val_recall: 0.9756 - val_precision: 0.5884\n",
            "Epoch 309/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0432 - accuracy: 0.9824 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9898 - precision: 0.9752\n",
            "Epoch 309: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 176ms/step - loss: 0.0432 - accuracy: 0.9824 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9898 - precision: 0.9752 - val_loss: 3.5921 - val_accuracy: 0.6242 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4810 - val_recall: 0.9830 - val_precision: 0.5754\n",
            "Epoch 310/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0620 - accuracy: 0.9754 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9789 - precision: 0.9738\n",
            "Epoch 310: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 177ms/step - loss: 0.0620 - accuracy: 0.9754 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9789 - precision: 0.9738 - val_loss: 3.4920 - val_accuracy: 0.6445 - val_sensitivity_at_specificity: 0.6217 - val_specificity_at_sensitivity: 0.5163 - val_recall: 0.9749 - val_precision: 0.5858\n",
            "Epoch 311/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0613 - accuracy: 0.9777 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9844 - precision: 0.9715\n",
            "Epoch 311: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 178ms/step - loss: 0.0613 - accuracy: 0.9777 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9844 - precision: 0.9715 - val_loss: 3.4715 - val_accuracy: 0.6078 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4712 - val_recall: 0.9922 - val_precision: 0.5598\n",
            "Epoch 312/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0663 - accuracy: 0.9758 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9829 - precision: 0.9693\n",
            "Epoch 312: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 177ms/step - loss: 0.0663 - accuracy: 0.9758 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9829 - precision: 0.9693 - val_loss: 3.4092 - val_accuracy: 0.6102 - val_sensitivity_at_specificity: 0.6738 - val_specificity_at_sensitivity: 0.5052 - val_recall: 0.9753 - val_precision: 0.5502\n",
            "Epoch 313/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0503 - accuracy: 0.9809 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9835 - precision: 0.9782\n",
            "Epoch 313: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 177ms/step - loss: 0.0503 - accuracy: 0.9809 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9835 - precision: 0.9782 - val_loss: 3.8798 - val_accuracy: 0.6031 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4379 - val_recall: 0.9831 - val_precision: 0.5633\n",
            "Epoch 314/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0682 - accuracy: 0.9754 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9764 - precision: 0.9741\n",
            "Epoch 314: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 175ms/step - loss: 0.0682 - accuracy: 0.9754 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9764 - precision: 0.9741 - val_loss: 3.1001 - val_accuracy: 0.6250 - val_sensitivity_at_specificity: 0.6555 - val_specificity_at_sensitivity: 0.5222 - val_recall: 0.9825 - val_precision: 0.5677\n",
            "Epoch 315/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0467 - accuracy: 0.9836 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9929 - precision: 0.9744\n",
            "Epoch 315: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 177ms/step - loss: 0.0467 - accuracy: 0.9836 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9929 - precision: 0.9744 - val_loss: 3.5642 - val_accuracy: 0.6148 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4639 - val_recall: 0.9891 - val_precision: 0.5665\n",
            "Epoch 316/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0494 - accuracy: 0.9820 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9888 - precision: 0.9749\n",
            "Epoch 316: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 178ms/step - loss: 0.0494 - accuracy: 0.9820 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9888 - precision: 0.9749 - val_loss: 3.8191 - val_accuracy: 0.6125 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4847 - val_recall: 0.9777 - val_precision: 0.5602\n",
            "Epoch 317/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0469 - accuracy: 0.9812 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9899 - precision: 0.9733\n",
            "Epoch 317: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 180ms/step - loss: 0.0469 - accuracy: 0.9812 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9899 - precision: 0.9733 - val_loss: 3.7394 - val_accuracy: 0.6109 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4853 - val_recall: 0.9810 - val_precision: 0.5610\n",
            "Epoch 318/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0489 - accuracy: 0.9824 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9851 - precision: 0.9798\n",
            "Epoch 318: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 176ms/step - loss: 0.0489 - accuracy: 0.9824 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9851 - precision: 0.9798 - val_loss: 3.4977 - val_accuracy: 0.6492 - val_sensitivity_at_specificity: 0.6868 - val_specificity_at_sensitivity: 0.5087 - val_recall: 0.9829 - val_precision: 0.5914\n",
            "Epoch 319/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0669 - accuracy: 0.9762 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9861 - precision: 0.9674\n",
            "Epoch 319: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 177ms/step - loss: 0.0669 - accuracy: 0.9762 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9861 - precision: 0.9674 - val_loss: 3.6087 - val_accuracy: 0.6156 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4718 - val_recall: 0.9848 - val_precision: 0.5738\n",
            "Epoch 320/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0538 - accuracy: 0.9797 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9789 - precision: 0.9819\n",
            "Epoch 320: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 178ms/step - loss: 0.0538 - accuracy: 0.9797 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9789 - precision: 0.9819 - val_loss: 3.9840 - val_accuracy: 0.6242 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4355 - val_recall: 0.9953 - val_precision: 0.5728\n",
            "Epoch 321/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0538 - accuracy: 0.9812 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9923 - precision: 0.9713\n",
            "Epoch 321: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 177ms/step - loss: 0.0538 - accuracy: 0.9812 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9923 - precision: 0.9713 - val_loss: 3.1633 - val_accuracy: 0.6398 - val_sensitivity_at_specificity: 0.6383 - val_specificity_at_sensitivity: 0.5254 - val_recall: 0.9761 - val_precision: 0.5947\n",
            "Epoch 322/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0599 - accuracy: 0.9789 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9860 - precision: 0.9724\n",
            "Epoch 322: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 177ms/step - loss: 0.0599 - accuracy: 0.9789 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9860 - precision: 0.9724 - val_loss: 3.3467 - val_accuracy: 0.6055 - val_sensitivity_at_specificity: 0.5925 - val_specificity_at_sensitivity: 0.5181 - val_recall: 0.9578 - val_precision: 0.5519\n",
            "Epoch 323/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0598 - accuracy: 0.9785 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9861 - precision: 0.9718\n",
            "Epoch 323: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.0598 - accuracy: 0.9785 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9861 - precision: 0.9718 - val_loss: 3.1165 - val_accuracy: 0.6484 - val_sensitivity_at_specificity: 0.6537 - val_specificity_at_sensitivity: 0.5188 - val_recall: 0.9895 - val_precision: 0.5984\n",
            "Epoch 324/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0550 - accuracy: 0.9793 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9852 - precision: 0.9738\n",
            "Epoch 324: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 179ms/step - loss: 0.0550 - accuracy: 0.9793 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9852 - precision: 0.9738 - val_loss: 3.2394 - val_accuracy: 0.6359 - val_sensitivity_at_specificity: 0.6350 - val_specificity_at_sensitivity: 0.5048 - val_recall: 0.9678 - val_precision: 0.5864\n",
            "Epoch 325/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0482 - accuracy: 0.9805 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9842 - precision: 0.9764\n",
            "Epoch 325: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 182ms/step - loss: 0.0482 - accuracy: 0.9805 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9842 - precision: 0.9764 - val_loss: 3.5042 - val_accuracy: 0.6102 - val_sensitivity_at_specificity: 0.6645 - val_specificity_at_sensitivity: 0.5153 - val_recall: 0.9633 - val_precision: 0.5589\n",
            "Epoch 326/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0483 - accuracy: 0.9809 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9869 - precision: 0.9756\n",
            "Epoch 326: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 179ms/step - loss: 0.0483 - accuracy: 0.9809 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9869 - precision: 0.9756 - val_loss: 3.7923 - val_accuracy: 0.6281 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4642 - val_recall: 0.9796 - val_precision: 0.5744\n",
            "Epoch 327/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0546 - accuracy: 0.9789 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9884 - precision: 0.9703\n",
            "Epoch 327: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 177ms/step - loss: 0.0546 - accuracy: 0.9789 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9884 - precision: 0.9703 - val_loss: 2.9728 - val_accuracy: 0.6141 - val_sensitivity_at_specificity: 0.6368 - val_specificity_at_sensitivity: 0.5588 - val_recall: 0.9552 - val_precision: 0.5616\n",
            "Epoch 328/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0642 - accuracy: 0.9762 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9817 - precision: 0.9720\n",
            "Epoch 328: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 175ms/step - loss: 0.0642 - accuracy: 0.9762 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9817 - precision: 0.9720 - val_loss: 3.7238 - val_accuracy: 0.6219 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4909 - val_recall: 0.9822 - val_precision: 0.5620\n",
            "Epoch 329/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0500 - accuracy: 0.9801 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9848 - precision: 0.9747\n",
            "Epoch 329: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 178ms/step - loss: 0.0500 - accuracy: 0.9801 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9848 - precision: 0.9747 - val_loss: 3.4788 - val_accuracy: 0.6266 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4759 - val_recall: 0.9848 - val_precision: 0.5806\n",
            "Epoch 330/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0642 - accuracy: 0.9742 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9791 - precision: 0.9682\n",
            "Epoch 330: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.0642 - accuracy: 0.9742 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9791 - precision: 0.9682 - val_loss: 3.3809 - val_accuracy: 0.6383 - val_sensitivity_at_specificity: 0.6353 - val_specificity_at_sensitivity: 0.5145 - val_recall: 0.9726 - val_precision: 0.5899\n",
            "Epoch 331/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0638 - accuracy: 0.9773 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9977 - recall: 0.9839 - precision: 0.9698\n",
            "Epoch 331: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 177ms/step - loss: 0.0638 - accuracy: 0.9773 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9977 - recall: 0.9839 - precision: 0.9698 - val_loss: 3.7684 - val_accuracy: 0.5922 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4685 - val_recall: 0.9762 - val_precision: 0.5477\n",
            "Epoch 332/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0496 - accuracy: 0.9805 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9837 - precision: 0.9777\n",
            "Epoch 332: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 176ms/step - loss: 0.0496 - accuracy: 0.9805 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9837 - precision: 0.9777 - val_loss: 3.4937 - val_accuracy: 0.6320 - val_sensitivity_at_specificity: 0.6925 - val_specificity_at_sensitivity: 0.5173 - val_recall: 0.9767 - val_precision: 0.5797\n",
            "Epoch 333/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0552 - accuracy: 0.9805 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9841 - precision: 0.9781\n",
            "Epoch 333: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 177ms/step - loss: 0.0552 - accuracy: 0.9805 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9841 - precision: 0.9781 - val_loss: 3.2954 - val_accuracy: 0.5914 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4913 - val_recall: 0.9660 - val_precision: 0.5551\n",
            "Epoch 334/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0477 - accuracy: 0.9832 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9901 - precision: 0.9775\n",
            "Epoch 334: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 176ms/step - loss: 0.0477 - accuracy: 0.9832 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9901 - precision: 0.9775 - val_loss: 3.2169 - val_accuracy: 0.6172 - val_sensitivity_at_specificity: 0.6345 - val_specificity_at_sensitivity: 0.5212 - val_recall: 0.9689 - val_precision: 0.5700\n",
            "Epoch 335/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0491 - accuracy: 0.9816 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9888 - precision: 0.9740\n",
            "Epoch 335: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 176ms/step - loss: 0.0491 - accuracy: 0.9816 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9888 - precision: 0.9740 - val_loss: 3.3842 - val_accuracy: 0.6477 - val_sensitivity_at_specificity: 0.6641 - val_specificity_at_sensitivity: 0.5241 - val_recall: 0.9812 - val_precision: 0.5874\n",
            "Epoch 336/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0574 - accuracy: 0.9742 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9777 - precision: 0.9700\n",
            "Epoch 336: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 177ms/step - loss: 0.0574 - accuracy: 0.9742 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9777 - precision: 0.9700 - val_loss: 3.2345 - val_accuracy: 0.6352 - val_sensitivity_at_specificity: 0.6810 - val_specificity_at_sensitivity: 0.5420 - val_recall: 0.9661 - val_precision: 0.5849\n",
            "Epoch 337/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0612 - accuracy: 0.9762 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9823 - precision: 0.9690\n",
            "Epoch 337: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 177ms/step - loss: 0.0612 - accuracy: 0.9762 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9823 - precision: 0.9690 - val_loss: 3.6570 - val_accuracy: 0.6102 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4733 - val_recall: 0.9872 - val_precision: 0.5569\n",
            "Epoch 338/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0567 - accuracy: 0.9773 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9763 - precision: 0.9778\n",
            "Epoch 338: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 181ms/step - loss: 0.0567 - accuracy: 0.9773 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9763 - precision: 0.9778 - val_loss: 4.1248 - val_accuracy: 0.5961 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4398 - val_recall: 0.9794 - val_precision: 0.5512\n",
            "Epoch 339/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0600 - accuracy: 0.9781 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9845 - precision: 0.9725\n",
            "Epoch 339: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 179ms/step - loss: 0.0600 - accuracy: 0.9781 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9845 - precision: 0.9725 - val_loss: 3.6104 - val_accuracy: 0.6234 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4884 - val_recall: 0.9843 - val_precision: 0.5697\n",
            "Epoch 340/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0497 - accuracy: 0.9789 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9846 - precision: 0.9741\n",
            "Epoch 340: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 181ms/step - loss: 0.0497 - accuracy: 0.9789 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9846 - precision: 0.9741 - val_loss: 3.4772 - val_accuracy: 0.6336 - val_sensitivity_at_specificity: 0.7267 - val_specificity_at_sensitivity: 0.5094 - val_recall: 0.9829 - val_precision: 0.5802\n",
            "Epoch 341/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0518 - accuracy: 0.9797 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9840 - precision: 0.9750\n",
            "Epoch 341: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.0518 - accuracy: 0.9797 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9840 - precision: 0.9750 - val_loss: 3.7123 - val_accuracy: 0.5898 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4895 - val_recall: 0.9756 - val_precision: 0.5401\n",
            "Epoch 342/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0514 - accuracy: 0.9809 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9868 - precision: 0.9755\n",
            "Epoch 342: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 178ms/step - loss: 0.0514 - accuracy: 0.9809 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9868 - precision: 0.9755 - val_loss: 3.7454 - val_accuracy: 0.6227 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4961 - val_recall: 0.9749 - val_precision: 0.5708\n",
            "Epoch 343/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0535 - accuracy: 0.9777 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9805 - precision: 0.9752\n",
            "Epoch 343: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 176ms/step - loss: 0.0535 - accuracy: 0.9777 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9805 - precision: 0.9752 - val_loss: 4.2775 - val_accuracy: 0.5891 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4385 - val_recall: 0.9855 - val_precision: 0.5421\n",
            "Epoch 344/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0610 - accuracy: 0.9777 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9868 - precision: 0.9694\n",
            "Epoch 344: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 176ms/step - loss: 0.0610 - accuracy: 0.9777 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9868 - precision: 0.9694 - val_loss: 3.5892 - val_accuracy: 0.6289 - val_sensitivity_at_specificity: 0.6420 - val_specificity_at_sensitivity: 0.5047 - val_recall: 0.9722 - val_precision: 0.5796\n",
            "Epoch 345/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0556 - accuracy: 0.9766 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9780 - precision: 0.9749\n",
            "Epoch 345: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 175ms/step - loss: 0.0556 - accuracy: 0.9766 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9780 - precision: 0.9749 - val_loss: 3.9151 - val_accuracy: 0.6172 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4663 - val_recall: 0.9857 - val_precision: 0.5627\n",
            "Epoch 346/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0675 - accuracy: 0.9754 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9826 - precision: 0.9680\n",
            "Epoch 346: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 178ms/step - loss: 0.0675 - accuracy: 0.9754 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9826 - precision: 0.9680 - val_loss: 3.5610 - val_accuracy: 0.6148 - val_sensitivity_at_specificity: 0.6656 - val_specificity_at_sensitivity: 0.5053 - val_recall: 0.9696 - val_precision: 0.5611\n",
            "Epoch 347/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0514 - accuracy: 0.9801 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9892 - precision: 0.9718\n",
            "Epoch 347: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 180ms/step - loss: 0.0514 - accuracy: 0.9801 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9892 - precision: 0.9718 - val_loss: 3.7135 - val_accuracy: 0.6039 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4852 - val_recall: 0.9922 - val_precision: 0.5573\n",
            "Epoch 348/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0564 - accuracy: 0.9793 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9878 - precision: 0.9722\n",
            "Epoch 348: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 180ms/step - loss: 0.0564 - accuracy: 0.9793 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9878 - precision: 0.9722 - val_loss: 3.5058 - val_accuracy: 0.6094 - val_sensitivity_at_specificity: 0.6567 - val_specificity_at_sensitivity: 0.5016 - val_recall: 0.9718 - val_precision: 0.5626\n",
            "Epoch 349/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0457 - accuracy: 0.9805 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9848 - precision: 0.9754\n",
            "Epoch 349: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 176ms/step - loss: 0.0457 - accuracy: 0.9805 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9848 - precision: 0.9754 - val_loss: 3.5561 - val_accuracy: 0.6250 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4648 - val_recall: 0.9906 - val_precision: 0.5726\n",
            "Epoch 350/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0400 - accuracy: 0.9867 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9897 - precision: 0.9835\n",
            "Epoch 350: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 178ms/step - loss: 0.0400 - accuracy: 0.9867 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9897 - precision: 0.9835 - val_loss: 3.8082 - val_accuracy: 0.6094 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4467 - val_recall: 0.9905 - val_precision: 0.5593\n",
            "Epoch 351/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0441 - accuracy: 0.9828 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9835 - precision: 0.9819\n",
            "Epoch 351: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 178ms/step - loss: 0.0441 - accuracy: 0.9828 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9835 - precision: 0.9819 - val_loss: 3.5764 - val_accuracy: 0.6359 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4786 - val_recall: 0.9846 - val_precision: 0.5836\n",
            "Epoch 352/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0446 - accuracy: 0.9863 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9985 - recall: 0.9913 - precision: 0.9812\n",
            "Epoch 352: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 181ms/step - loss: 0.0446 - accuracy: 0.9863 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9985 - recall: 0.9913 - precision: 0.9812 - val_loss: 3.7638 - val_accuracy: 0.6078 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4758 - val_recall: 0.9773 - val_precision: 0.5531\n",
            "Epoch 353/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0392 - accuracy: 0.9852 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9885 - precision: 0.9825\n",
            "Epoch 353: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 195ms/step - loss: 0.0392 - accuracy: 0.9852 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9885 - precision: 0.9825 - val_loss: 4.5191 - val_accuracy: 0.5922 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4000 - val_recall: 0.9921 - val_precision: 0.5493\n",
            "Epoch 354/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0459 - accuracy: 0.9832 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9819 - precision: 0.9842\n",
            "Epoch 354: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 193ms/step - loss: 0.0459 - accuracy: 0.9832 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9819 - precision: 0.9842 - val_loss: 4.1258 - val_accuracy: 0.6156 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4410 - val_recall: 0.9858 - val_precision: 0.5649\n",
            "Epoch 355/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0424 - accuracy: 0.9840 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9863 - precision: 0.9808\n",
            "Epoch 355: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 179ms/step - loss: 0.0424 - accuracy: 0.9840 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9863 - precision: 0.9808 - val_loss: 4.0060 - val_accuracy: 0.6016 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4807 - val_recall: 0.9686 - val_precision: 0.5445\n",
            "Epoch 356/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0367 - accuracy: 0.9867 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9890 - precision: 0.9843\n",
            "Epoch 356: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 177ms/step - loss: 0.0367 - accuracy: 0.9867 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9890 - precision: 0.9843 - val_loss: 3.9443 - val_accuracy: 0.6211 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4541 - val_recall: 0.9697 - val_precision: 0.5788\n",
            "Epoch 357/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0439 - accuracy: 0.9844 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9883 - precision: 0.9807\n",
            "Epoch 357: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 179ms/step - loss: 0.0439 - accuracy: 0.9844 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9883 - precision: 0.9807 - val_loss: 3.7087 - val_accuracy: 0.6219 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4875 - val_recall: 0.9626 - val_precision: 0.5733\n",
            "Epoch 358/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0443 - accuracy: 0.9801 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9818 - precision: 0.9780\n",
            "Epoch 358: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 178ms/step - loss: 0.0443 - accuracy: 0.9801 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9818 - precision: 0.9780 - val_loss: 4.3887 - val_accuracy: 0.5945 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.3976 - val_recall: 0.9840 - val_precision: 0.5476\n",
            "Epoch 359/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0531 - accuracy: 0.9824 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9885 - precision: 0.9772\n",
            "Epoch 359: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 175ms/step - loss: 0.0531 - accuracy: 0.9824 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9885 - precision: 0.9772 - val_loss: 3.8863 - val_accuracy: 0.6141 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4249 - val_recall: 0.9818 - val_precision: 0.5738\n",
            "Epoch 360/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0430 - accuracy: 0.9842 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9858 - precision: 0.9825\n",
            "Epoch 360: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.0430 - accuracy: 0.9842 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9858 - precision: 0.9825 - val_loss: 3.4652 - val_accuracy: 0.6148 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4937 - val_recall: 0.9738 - val_precision: 0.5700\n",
            "Epoch 361/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0470 - accuracy: 0.9824 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9860 - precision: 0.9791\n",
            "Epoch 361: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 178ms/step - loss: 0.0470 - accuracy: 0.9824 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9860 - precision: 0.9791 - val_loss: 4.1538 - val_accuracy: 0.6133 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4336 - val_recall: 0.9842 - val_precision: 0.5619\n",
            "Epoch 362/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0525 - accuracy: 0.9797 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9811 - precision: 0.9780\n",
            "Epoch 362: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 178ms/step - loss: 0.0525 - accuracy: 0.9797 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9811 - precision: 0.9780 - val_loss: 3.9691 - val_accuracy: 0.6453 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4715 - val_recall: 0.9910 - val_precision: 0.5960\n",
            "Epoch 363/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0491 - accuracy: 0.9805 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9859 - precision: 0.9730\n",
            "Epoch 363: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 177ms/step - loss: 0.0491 - accuracy: 0.9805 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9859 - precision: 0.9730 - val_loss: 4.0809 - val_accuracy: 0.6062 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4225 - val_recall: 0.9844 - val_precision: 0.5609\n",
            "Epoch 364/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0433 - accuracy: 0.9828 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9882 - precision: 0.9775\n",
            "Epoch 364: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 179ms/step - loss: 0.0433 - accuracy: 0.9828 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9882 - precision: 0.9775 - val_loss: 4.1507 - val_accuracy: 0.6062 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4277 - val_recall: 0.9780 - val_precision: 0.5597\n",
            "Epoch 365/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0450 - accuracy: 0.9840 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9878 - precision: 0.9811\n",
            "Epoch 365: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 192ms/step - loss: 0.0450 - accuracy: 0.9840 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9878 - precision: 0.9811 - val_loss: 3.4108 - val_accuracy: 0.6508 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4840 - val_recall: 0.9694 - val_precision: 0.6099\n",
            "Epoch 366/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0435 - accuracy: 0.9816 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9862 - precision: 0.9780\n",
            "Epoch 366: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 177ms/step - loss: 0.0435 - accuracy: 0.9816 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9862 - precision: 0.9780 - val_loss: 3.7580 - val_accuracy: 0.6352 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4882 - val_recall: 0.9815 - val_precision: 0.5826\n",
            "Epoch 367/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0474 - accuracy: 0.9816 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9822 - precision: 0.9815\n",
            "Epoch 367: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 180ms/step - loss: 0.0474 - accuracy: 0.9816 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9822 - precision: 0.9815 - val_loss: 3.4536 - val_accuracy: 0.6336 - val_sensitivity_at_specificity: 0.6910 - val_specificity_at_sensitivity: 0.5162 - val_recall: 0.9715 - val_precision: 0.5761\n",
            "Epoch 368/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0440 - accuracy: 0.9852 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9867 - precision: 0.9836\n",
            "Epoch 368: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 191ms/step - loss: 0.0440 - accuracy: 0.9852 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9867 - precision: 0.9836 - val_loss: 4.1170 - val_accuracy: 0.6125 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4443 - val_recall: 0.9874 - val_precision: 0.5619\n",
            "Epoch 369/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0425 - accuracy: 0.9832 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9885 - precision: 0.9788\n",
            "Epoch 369: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 178ms/step - loss: 0.0425 - accuracy: 0.9832 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9885 - precision: 0.9788 - val_loss: 3.6225 - val_accuracy: 0.6102 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4961 - val_recall: 0.9716 - val_precision: 0.5611\n",
            "Epoch 370/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0493 - accuracy: 0.9785 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9836 - precision: 0.9737\n",
            "Epoch 370: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 176ms/step - loss: 0.0493 - accuracy: 0.9785 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9836 - precision: 0.9737 - val_loss: 3.8375 - val_accuracy: 0.6125 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4519 - val_recall: 0.9776 - val_precision: 0.5590\n",
            "Epoch 371/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0429 - accuracy: 0.9836 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9859 - precision: 0.9813\n",
            "Epoch 371: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 177ms/step - loss: 0.0429 - accuracy: 0.9836 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9859 - precision: 0.9813 - val_loss: 4.0706 - val_accuracy: 0.6234 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4465 - val_recall: 0.9814 - val_precision: 0.5735\n",
            "Epoch 372/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0453 - accuracy: 0.9801 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9842 - precision: 0.9757\n",
            "Epoch 372: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 176ms/step - loss: 0.0453 - accuracy: 0.9801 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9842 - precision: 0.9757 - val_loss: 3.5208 - val_accuracy: 0.6398 - val_sensitivity_at_specificity: 0.6575 - val_specificity_at_sensitivity: 0.5112 - val_recall: 0.9740 - val_precision: 0.5893\n",
            "Epoch 373/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0419 - accuracy: 0.9832 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9857 - precision: 0.9802\n",
            "Epoch 373: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 177ms/step - loss: 0.0419 - accuracy: 0.9832 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9857 - precision: 0.9802 - val_loss: 3.7540 - val_accuracy: 0.6305 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4587 - val_recall: 0.9831 - val_precision: 0.5804\n",
            "Epoch 374/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0482 - accuracy: 0.9824 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9875 - precision: 0.9775\n",
            "Epoch 374: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 178ms/step - loss: 0.0482 - accuracy: 0.9824 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9875 - precision: 0.9775 - val_loss: 3.9902 - val_accuracy: 0.6461 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4579 - val_recall: 0.9924 - val_precision: 0.5946\n",
            "Epoch 375/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0397 - accuracy: 0.9887 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9930 - precision: 0.9845\n",
            "Epoch 375: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 174ms/step - loss: 0.0397 - accuracy: 0.9887 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9930 - precision: 0.9845 - val_loss: 3.9782 - val_accuracy: 0.6172 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4554 - val_recall: 0.9719 - val_precision: 0.5689\n",
            "Epoch 376/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0395 - accuracy: 0.9832 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9828 - precision: 0.9836\n",
            "Epoch 376: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 178ms/step - loss: 0.0395 - accuracy: 0.9832 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9828 - precision: 0.9836 - val_loss: 4.2264 - val_accuracy: 0.6016 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4159 - val_recall: 0.9800 - val_precision: 0.5617\n",
            "Epoch 377/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0617 - accuracy: 0.9758 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9772 - precision: 0.9758\n",
            "Epoch 377: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 194ms/step - loss: 0.0617 - accuracy: 0.9758 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9772 - precision: 0.9758 - val_loss: 3.9591 - val_accuracy: 0.6219 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4589 - val_recall: 0.9811 - val_precision: 0.5689\n",
            "Epoch 378/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0540 - accuracy: 0.9801 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9850 - precision: 0.9750\n",
            "Epoch 378: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 180ms/step - loss: 0.0540 - accuracy: 0.9801 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9850 - precision: 0.9750 - val_loss: 3.8524 - val_accuracy: 0.6180 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4453 - val_recall: 0.9738 - val_precision: 0.5725\n",
            "Epoch 379/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0499 - accuracy: 0.9824 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9846 - precision: 0.9808\n",
            "Epoch 379: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.0499 - accuracy: 0.9824 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9846 - precision: 0.9808 - val_loss: 3.7906 - val_accuracy: 0.6250 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4609 - val_recall: 0.9844 - val_precision: 0.5727\n",
            "Epoch 380/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0487 - accuracy: 0.9832 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9881 - precision: 0.9780\n",
            "Epoch 380: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 179ms/step - loss: 0.0487 - accuracy: 0.9832 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9881 - precision: 0.9780 - val_loss: 3.1424 - val_accuracy: 0.6492 - val_sensitivity_at_specificity: 0.6997 - val_specificity_at_sensitivity: 0.5331 - val_recall: 0.9675 - val_precision: 0.5935\n",
            "Epoch 381/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0369 - accuracy: 0.9855 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9845 - precision: 0.9869\n",
            "Epoch 381: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.0369 - accuracy: 0.9855 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9845 - precision: 0.9869 - val_loss: 3.9023 - val_accuracy: 0.6047 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4325 - val_recall: 0.9807 - val_precision: 0.5521\n",
            "Epoch 382/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0623 - accuracy: 0.9751 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9975 - recall: 0.9840 - precision: 0.9661\n",
            "Epoch 382: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 180ms/step - loss: 0.0623 - accuracy: 0.9751 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9975 - recall: 0.9840 - precision: 0.9661 - val_loss: 3.4527 - val_accuracy: 0.6250 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4984 - val_recall: 0.9733 - val_precision: 0.5721\n",
            "Epoch 383/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0541 - accuracy: 0.9840 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9836 - precision: 0.9844\n",
            "Epoch 383: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 177ms/step - loss: 0.0541 - accuracy: 0.9840 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9836 - precision: 0.9844 - val_loss: 4.1844 - val_accuracy: 0.6070 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4335 - val_recall: 0.9861 - val_precision: 0.5640\n",
            "Epoch 384/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0584 - accuracy: 0.9805 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9976 - recall: 0.9840 - precision: 0.9780\n",
            "Epoch 384: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 178ms/step - loss: 0.0584 - accuracy: 0.9805 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9976 - recall: 0.9840 - precision: 0.9780 - val_loss: 3.3757 - val_accuracy: 0.6195 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4883 - val_recall: 0.9781 - val_precision: 0.5692\n",
            "Epoch 385/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0605 - accuracy: 0.9785 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9806 - precision: 0.9768\n",
            "Epoch 385: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 178ms/step - loss: 0.0605 - accuracy: 0.9785 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9806 - precision: 0.9768 - val_loss: 3.9095 - val_accuracy: 0.5992 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4207 - val_recall: 0.9922 - val_precision: 0.5567\n",
            "Epoch 386/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0494 - accuracy: 0.9820 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9985 - recall: 0.9889 - precision: 0.9750\n",
            "Epoch 386: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 180ms/step - loss: 0.0494 - accuracy: 0.9820 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9985 - recall: 0.9889 - precision: 0.9750 - val_loss: 3.0748 - val_accuracy: 0.6375 - val_sensitivity_at_specificity: 0.6454 - val_specificity_at_sensitivity: 0.5169 - val_recall: 0.9680 - val_precision: 0.5894\n",
            "Epoch 387/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0394 - accuracy: 0.9867 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9896 - precision: 0.9833\n",
            "Epoch 387: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 175ms/step - loss: 0.0394 - accuracy: 0.9867 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9896 - precision: 0.9833 - val_loss: 3.3146 - val_accuracy: 0.6258 - val_sensitivity_at_specificity: 0.6767 - val_specificity_at_sensitivity: 0.5155 - val_recall: 0.9874 - val_precision: 0.5706\n",
            "Epoch 388/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0586 - accuracy: 0.9762 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9818 - precision: 0.9704\n",
            "Epoch 388: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 179ms/step - loss: 0.0586 - accuracy: 0.9762 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9818 - precision: 0.9704 - val_loss: 3.5090 - val_accuracy: 0.6203 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4859 - val_recall: 0.9751 - val_precision: 0.5712\n",
            "Epoch 389/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0438 - accuracy: 0.9852 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9882 - precision: 0.9820\n",
            "Epoch 389: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 175ms/step - loss: 0.0438 - accuracy: 0.9852 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9882 - precision: 0.9820 - val_loss: 3.6695 - val_accuracy: 0.6180 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4587 - val_recall: 0.9844 - val_precision: 0.5677\n",
            "Epoch 390/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0394 - accuracy: 0.9863 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9861 - precision: 0.9853\n",
            "Epoch 390: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 175ms/step - loss: 0.0394 - accuracy: 0.9863 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9861 - precision: 0.9853 - val_loss: 3.6509 - val_accuracy: 0.6180 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4819 - val_recall: 0.9789 - val_precision: 0.5589\n",
            "Epoch 391/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0370 - accuracy: 0.9852 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9879 - precision: 0.9816\n",
            "Epoch 391: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 178ms/step - loss: 0.0370 - accuracy: 0.9852 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9879 - precision: 0.9816 - val_loss: 3.6662 - val_accuracy: 0.6211 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4867 - val_recall: 0.9703 - val_precision: 0.5709\n",
            "Epoch 392/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0457 - accuracy: 0.9836 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9837 - precision: 0.9837\n",
            "Epoch 392: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 175ms/step - loss: 0.0457 - accuracy: 0.9836 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9837 - precision: 0.9837 - val_loss: 4.5375 - val_accuracy: 0.6008 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.3665 - val_recall: 0.9892 - val_precision: 0.5594\n",
            "Epoch 393/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0458 - accuracy: 0.9836 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9985 - recall: 0.9864 - precision: 0.9802\n",
            "Epoch 393: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 178ms/step - loss: 0.0458 - accuracy: 0.9836 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9985 - recall: 0.9864 - precision: 0.9802 - val_loss: 3.6627 - val_accuracy: 0.6328 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4724 - val_recall: 0.9753 - val_precision: 0.5816\n",
            "Epoch 394/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0389 - accuracy: 0.9812 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9829 - precision: 0.9799\n",
            "Epoch 394: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 181ms/step - loss: 0.0389 - accuracy: 0.9812 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9829 - precision: 0.9799 - val_loss: 4.4891 - val_accuracy: 0.6117 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4225 - val_recall: 0.9860 - val_precision: 0.5643\n",
            "Epoch 395/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0513 - accuracy: 0.9824 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9886 - precision: 0.9775\n",
            "Epoch 395: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 176ms/step - loss: 0.0513 - accuracy: 0.9824 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9886 - precision: 0.9775 - val_loss: 3.3325 - val_accuracy: 0.6211 - val_sensitivity_at_specificity: 0.6032 - val_specificity_at_sensitivity: 0.5121 - val_recall: 0.9645 - val_precision: 0.5636\n",
            "Epoch 396/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0398 - accuracy: 0.9859 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9899 - precision: 0.9823\n",
            "Epoch 396: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 177ms/step - loss: 0.0398 - accuracy: 0.9859 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9899 - precision: 0.9823 - val_loss: 4.0217 - val_accuracy: 0.6109 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4580 - val_recall: 0.9840 - val_precision: 0.5576\n",
            "Epoch 397/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0393 - accuracy: 0.9871 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9899 - precision: 0.9846\n",
            "Epoch 397: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 175ms/step - loss: 0.0393 - accuracy: 0.9871 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9899 - precision: 0.9846 - val_loss: 4.0693 - val_accuracy: 0.6156 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4577 - val_recall: 0.9838 - val_precision: 0.5578\n",
            "Epoch 398/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0319 - accuracy: 0.9888 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9895 - precision: 0.9887\n",
            "Epoch 398: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.0319 - accuracy: 0.9888 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9895 - precision: 0.9887 - val_loss: 3.8824 - val_accuracy: 0.6219 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4739 - val_recall: 0.9830 - val_precision: 0.5735\n",
            "Epoch 399/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0363 - accuracy: 0.9879 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9923 - precision: 0.9839\n",
            "Epoch 399: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.0363 - accuracy: 0.9879 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9923 - precision: 0.9839 - val_loss: 4.0357 - val_accuracy: 0.6086 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4393 - val_recall: 0.9843 - val_precision: 0.5612\n",
            "Epoch 400/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0359 - accuracy: 0.9883 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9897 - precision: 0.9866\n",
            "Epoch 400: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 177ms/step - loss: 0.0359 - accuracy: 0.9883 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9897 - precision: 0.9866 - val_loss: 4.1418 - val_accuracy: 0.6297 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4578 - val_recall: 0.9703 - val_precision: 0.5771\n",
            "Epoch 401/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0440 - accuracy: 0.9828 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9849 - precision: 0.9802\n",
            "Epoch 401: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 176ms/step - loss: 0.0440 - accuracy: 0.9828 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9849 - precision: 0.9802 - val_loss: 4.1578 - val_accuracy: 0.6078 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4209 - val_recall: 0.9861 - val_precision: 0.5645\n",
            "Epoch 402/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0454 - accuracy: 0.9824 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9877 - precision: 0.9780\n",
            "Epoch 402: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 176ms/step - loss: 0.0454 - accuracy: 0.9824 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9877 - precision: 0.9780 - val_loss: 4.0306 - val_accuracy: 0.6242 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4495 - val_recall: 0.9749 - val_precision: 0.5718\n",
            "Epoch 403/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0374 - accuracy: 0.9859 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9900 - precision: 0.9824\n",
            "Epoch 403: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 178ms/step - loss: 0.0374 - accuracy: 0.9859 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9900 - precision: 0.9824 - val_loss: 4.1017 - val_accuracy: 0.6227 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4369 - val_recall: 0.9668 - val_precision: 0.5813\n",
            "Epoch 404/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0343 - accuracy: 0.9859 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9914 - precision: 0.9806\n",
            "Epoch 404: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 177ms/step - loss: 0.0343 - accuracy: 0.9859 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9914 - precision: 0.9806 - val_loss: 4.4243 - val_accuracy: 0.5961 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4281 - val_recall: 0.9856 - val_precision: 0.5484\n",
            "Epoch 405/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0378 - accuracy: 0.9863 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9854 - precision: 0.9877\n",
            "Epoch 405: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 177ms/step - loss: 0.0378 - accuracy: 0.9863 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9854 - precision: 0.9877 - val_loss: 4.1166 - val_accuracy: 0.6242 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4415 - val_recall: 0.9753 - val_precision: 0.5761\n",
            "Epoch 406/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0382 - accuracy: 0.9863 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9900 - precision: 0.9831\n",
            "Epoch 406: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 182ms/step - loss: 0.0382 - accuracy: 0.9863 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9900 - precision: 0.9831 - val_loss: 3.8608 - val_accuracy: 0.6289 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4490 - val_recall: 0.9816 - val_precision: 0.5802\n",
            "Epoch 407/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0440 - accuracy: 0.9848 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9922 - precision: 0.9776\n",
            "Epoch 407: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 177ms/step - loss: 0.0440 - accuracy: 0.9848 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9922 - precision: 0.9776 - val_loss: 3.8182 - val_accuracy: 0.6297 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4626 - val_recall: 0.9760 - val_precision: 0.5706\n",
            "Epoch 408/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0375 - accuracy: 0.9863 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9854 - precision: 0.9876\n",
            "Epoch 408: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.0375 - accuracy: 0.9863 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9854 - precision: 0.9876 - val_loss: 4.8497 - val_accuracy: 0.6203 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4191 - val_recall: 0.9952 - val_precision: 0.5605\n",
            "Epoch 409/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0408 - accuracy: 0.9844 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9892 - precision: 0.9802\n",
            "Epoch 409: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.0408 - accuracy: 0.9844 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9892 - precision: 0.9802 - val_loss: 4.2680 - val_accuracy: 0.6086 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4238 - val_recall: 0.9872 - val_precision: 0.5555\n",
            "Epoch 410/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0390 - accuracy: 0.9871 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9932 - precision: 0.9820\n",
            "Epoch 410: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 178ms/step - loss: 0.0390 - accuracy: 0.9871 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9932 - precision: 0.9820 - val_loss: 4.7189 - val_accuracy: 0.6031 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4073 - val_recall: 0.9871 - val_precision: 0.5512\n",
            "Epoch 411/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0369 - accuracy: 0.9844 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9865 - precision: 0.9818\n",
            "Epoch 411: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 175ms/step - loss: 0.0369 - accuracy: 0.9844 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9865 - precision: 0.9818 - val_loss: 3.8528 - val_accuracy: 0.6141 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4493 - val_recall: 0.9765 - val_precision: 0.5657\n",
            "Epoch 412/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0451 - accuracy: 0.9859 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9984 - recall: 0.9867 - precision: 0.9852\n",
            "Epoch 412: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 179ms/step - loss: 0.0451 - accuracy: 0.9859 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9984 - recall: 0.9867 - precision: 0.9852 - val_loss: 3.3160 - val_accuracy: 0.6516 - val_sensitivity_at_specificity: 0.6889 - val_specificity_at_sensitivity: 0.5024 - val_recall: 0.9788 - val_precision: 0.5989\n",
            "Epoch 413/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0427 - accuracy: 0.9871 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9992 - recall: 0.9860 - precision: 0.9883\n",
            "Epoch 413: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 177ms/step - loss: 0.0427 - accuracy: 0.9871 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9992 - recall: 0.9860 - precision: 0.9883 - val_loss: 4.1010 - val_accuracy: 0.6187 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4448 - val_recall: 0.9861 - val_precision: 0.5708\n",
            "Epoch 414/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0383 - accuracy: 0.9891 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9938 - precision: 0.9847\n",
            "Epoch 414: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 178ms/step - loss: 0.0383 - accuracy: 0.9891 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9938 - precision: 0.9847 - val_loss: 3.7397 - val_accuracy: 0.6398 - val_sensitivity_at_specificity: 0.7050 - val_specificity_at_sensitivity: 0.5068 - val_recall: 0.9854 - val_precision: 0.5736\n",
            "Epoch 415/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0317 - accuracy: 0.9902 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9898 - precision: 0.9905\n",
            "Epoch 415: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 178ms/step - loss: 0.0317 - accuracy: 0.9902 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9898 - precision: 0.9905 - val_loss: 4.1369 - val_accuracy: 0.6086 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4457 - val_recall: 0.9827 - val_precision: 0.5605\n",
            "Epoch 416/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0305 - accuracy: 0.9883 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9935 - precision: 0.9824\n",
            "Epoch 416: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.0305 - accuracy: 0.9883 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9935 - precision: 0.9824 - val_loss: 4.4521 - val_accuracy: 0.6086 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4028 - val_recall: 0.9892 - val_precision: 0.5644\n",
            "Epoch 417/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0371 - accuracy: 0.9863 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9850 - precision: 0.9873\n",
            "Epoch 417: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 175ms/step - loss: 0.0371 - accuracy: 0.9863 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9850 - precision: 0.9873 - val_loss: 4.3382 - val_accuracy: 0.6250 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4306 - val_recall: 0.9876 - val_precision: 0.5748\n",
            "Epoch 418/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0413 - accuracy: 0.9859 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9880 - precision: 0.9833\n",
            "Epoch 418: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 179ms/step - loss: 0.0413 - accuracy: 0.9859 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9880 - precision: 0.9833 - val_loss: 3.5484 - val_accuracy: 0.6383 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4859 - val_recall: 0.9813 - val_precision: 0.5828\n",
            "Epoch 419/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0383 - accuracy: 0.9867 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9985 - recall: 0.9897 - precision: 0.9835\n",
            "Epoch 419: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 179ms/step - loss: 0.0383 - accuracy: 0.9867 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9985 - recall: 0.9897 - precision: 0.9835 - val_loss: 3.9278 - val_accuracy: 0.6242 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4520 - val_recall: 0.9921 - val_precision: 0.5692\n",
            "Epoch 420/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0294 - accuracy: 0.9883 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9890 - precision: 0.9874\n",
            "Epoch 420: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 177ms/step - loss: 0.0294 - accuracy: 0.9883 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9890 - precision: 0.9874 - val_loss: 3.7863 - val_accuracy: 0.6305 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4453 - val_recall: 0.9833 - val_precision: 0.5834\n",
            "Epoch 421/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0401 - accuracy: 0.9859 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9901 - precision: 0.9826\n",
            "Epoch 421: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 180ms/step - loss: 0.0401 - accuracy: 0.9859 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9901 - precision: 0.9826 - val_loss: 4.1824 - val_accuracy: 0.6172 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4225 - val_recall: 0.9892 - val_precision: 0.5703\n",
            "Epoch 422/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0314 - accuracy: 0.9891 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9914 - precision: 0.9867\n",
            "Epoch 422: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 175ms/step - loss: 0.0314 - accuracy: 0.9891 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9914 - precision: 0.9867 - val_loss: 4.1495 - val_accuracy: 0.6305 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4207 - val_recall: 0.9849 - val_precision: 0.5848\n",
            "Epoch 423/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0291 - accuracy: 0.9883 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9874 - precision: 0.9889\n",
            "Epoch 423: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 177ms/step - loss: 0.0291 - accuracy: 0.9883 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9874 - precision: 0.9889 - val_loss: 4.5362 - val_accuracy: 0.6102 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4151 - val_recall: 0.9873 - val_precision: 0.5596\n",
            "Epoch 424/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0390 - accuracy: 0.9828 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9867 - precision: 0.9791\n",
            "Epoch 424: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 176ms/step - loss: 0.0390 - accuracy: 0.9828 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9867 - precision: 0.9791 - val_loss: 4.7479 - val_accuracy: 0.6180 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.3919 - val_recall: 0.9922 - val_precision: 0.5663\n",
            "Epoch 425/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0491 - accuracy: 0.9844 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9977 - recall: 0.9843 - precision: 0.9843\n",
            "Epoch 425: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 174ms/step - loss: 0.0491 - accuracy: 0.9844 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9977 - recall: 0.9843 - precision: 0.9843 - val_loss: 4.1998 - val_accuracy: 0.6070 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4137 - val_recall: 0.9817 - val_precision: 0.5666\n",
            "Epoch 426/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0429 - accuracy: 0.9836 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9913 - precision: 0.9759\n",
            "Epoch 426: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 175ms/step - loss: 0.0429 - accuracy: 0.9836 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9913 - precision: 0.9759 - val_loss: 3.5937 - val_accuracy: 0.6102 - val_sensitivity_at_specificity: 0.6640 - val_specificity_at_sensitivity: 0.5108 - val_recall: 0.9795 - val_precision: 0.5610\n",
            "Epoch 427/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0342 - accuracy: 0.9855 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9822 - precision: 0.9891\n",
            "Epoch 427: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 177ms/step - loss: 0.0342 - accuracy: 0.9855 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9822 - precision: 0.9891 - val_loss: 3.9498 - val_accuracy: 0.6203 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4617 - val_recall: 0.9906 - val_precision: 0.5695\n",
            "Epoch 428/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0336 - accuracy: 0.9855 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9931 - precision: 0.9789\n",
            "Epoch 428: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 175ms/step - loss: 0.0336 - accuracy: 0.9855 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9931 - precision: 0.9789 - val_loss: 3.5869 - val_accuracy: 0.6242 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4938 - val_recall: 0.9844 - val_precision: 0.5722\n",
            "Epoch 429/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0345 - accuracy: 0.9879 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9875 - precision: 0.9883\n",
            "Epoch 429: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 175ms/step - loss: 0.0345 - accuracy: 0.9879 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9875 - precision: 0.9883 - val_loss: 4.2341 - val_accuracy: 0.6219 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4559 - val_recall: 0.9853 - val_precision: 0.5590\n",
            "Epoch 430/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0382 - accuracy: 0.9863 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9891 - precision: 0.9838\n",
            "Epoch 430: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.0382 - accuracy: 0.9863 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9891 - precision: 0.9838 - val_loss: 3.9618 - val_accuracy: 0.6359 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4844 - val_recall: 0.9828 - val_precision: 0.5803\n",
            "Epoch 431/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0413 - accuracy: 0.9844 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9890 - precision: 0.9798\n",
            "Epoch 431: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 178ms/step - loss: 0.0413 - accuracy: 0.9844 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9890 - precision: 0.9798 - val_loss: 3.9616 - val_accuracy: 0.6070 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4633 - val_recall: 0.9797 - val_precision: 0.5609\n",
            "Epoch 432/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0393 - accuracy: 0.9836 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9796 - precision: 0.9860\n",
            "Epoch 432: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 175ms/step - loss: 0.0393 - accuracy: 0.9836 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9796 - precision: 0.9860 - val_loss: 3.9599 - val_accuracy: 0.6344 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4548 - val_recall: 0.9784 - val_precision: 0.5831\n",
            "Epoch 433/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0346 - accuracy: 0.9867 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9921 - precision: 0.9813\n",
            "Epoch 433: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 180ms/step - loss: 0.0346 - accuracy: 0.9867 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9921 - precision: 0.9813 - val_loss: 4.3734 - val_accuracy: 0.5914 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4255 - val_recall: 0.9807 - val_precision: 0.5442\n",
            "Epoch 434/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0331 - accuracy: 0.9879 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9880 - precision: 0.9872\n",
            "Epoch 434: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 178ms/step - loss: 0.0331 - accuracy: 0.9879 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9880 - precision: 0.9872 - val_loss: 4.4419 - val_accuracy: 0.6250 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4025 - val_recall: 0.9877 - val_precision: 0.5759\n",
            "Epoch 435/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0385 - accuracy: 0.9863 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 0.9992 - recall: 0.9861 - precision: 0.9869\n",
            "Epoch 435: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 174ms/step - loss: 0.0385 - accuracy: 0.9863 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 0.9992 - recall: 0.9861 - precision: 0.9869 - val_loss: 4.1070 - val_accuracy: 0.6219 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4409 - val_recall: 0.9809 - val_precision: 0.5666\n",
            "Epoch 436/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0363 - accuracy: 0.9863 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9889 - precision: 0.9835\n",
            "Epoch 436: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 188ms/step - loss: 0.0363 - accuracy: 0.9863 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9889 - precision: 0.9835 - val_loss: 4.1731 - val_accuracy: 0.6281 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4164 - val_recall: 0.9878 - val_precision: 0.5814\n",
            "Epoch 437/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0350 - accuracy: 0.9867 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9891 - precision: 0.9845\n",
            "Epoch 437: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 177ms/step - loss: 0.0350 - accuracy: 0.9867 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9891 - precision: 0.9845 - val_loss: 4.3212 - val_accuracy: 0.6125 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4381 - val_recall: 0.9887 - val_precision: 0.5555\n",
            "Epoch 438/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0420 - accuracy: 0.9836 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9859 - precision: 0.9813\n",
            "Epoch 438: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 180ms/step - loss: 0.0420 - accuracy: 0.9836 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9859 - precision: 0.9813 - val_loss: 3.8381 - val_accuracy: 0.6148 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4814 - val_recall: 0.9802 - val_precision: 0.5530\n",
            "Epoch 439/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0418 - accuracy: 0.9855 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9865 - precision: 0.9841\n",
            "Epoch 439: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 188ms/step - loss: 0.0418 - accuracy: 0.9855 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9865 - precision: 0.9841 - val_loss: 4.3445 - val_accuracy: 0.6187 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4226 - val_recall: 0.9858 - val_precision: 0.5661\n",
            "Epoch 440/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0363 - accuracy: 0.9906 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9969 - precision: 0.9844\n",
            "Epoch 440: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 181ms/step - loss: 0.0363 - accuracy: 0.9906 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9969 - precision: 0.9844 - val_loss: 3.6464 - val_accuracy: 0.6125 - val_sensitivity_at_specificity: 0.7252 - val_specificity_at_sensitivity: 0.5038 - val_recall: 0.9756 - val_precision: 0.5550\n",
            "Epoch 441/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0370 - accuracy: 0.9855 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9808 - precision: 0.9907\n",
            "Epoch 441: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 177ms/step - loss: 0.0370 - accuracy: 0.9855 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9808 - precision: 0.9907 - val_loss: 4.3662 - val_accuracy: 0.6203 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.3994 - val_recall: 0.9864 - val_precision: 0.5786\n",
            "Epoch 442/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0362 - accuracy: 0.9879 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9985 - recall: 0.9937 - precision: 0.9821\n",
            "Epoch 442: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 179ms/step - loss: 0.0362 - accuracy: 0.9879 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9985 - recall: 0.9937 - precision: 0.9821 - val_loss: 3.8769 - val_accuracy: 0.6227 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4436 - val_recall: 0.9813 - val_precision: 0.5722\n",
            "Epoch 443/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0293 - accuracy: 0.9898 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9908 - precision: 0.9893\n",
            "Epoch 443: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 175ms/step - loss: 0.0293 - accuracy: 0.9898 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9908 - precision: 0.9893 - val_loss: 4.7651 - val_accuracy: 0.5945 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.3658 - val_recall: 0.9782 - val_precision: 0.5547\n",
            "Epoch 444/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0294 - accuracy: 0.9888 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9924 - precision: 0.9849\n",
            "Epoch 444: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 184ms/step - loss: 0.0294 - accuracy: 0.9888 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9924 - precision: 0.9849 - val_loss: 4.5307 - val_accuracy: 0.6227 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.3907 - val_recall: 0.9909 - val_precision: 0.5775\n",
            "Epoch 445/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0296 - accuracy: 0.9906 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9921 - precision: 0.9890\n",
            "Epoch 445: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 176ms/step - loss: 0.0296 - accuracy: 0.9906 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9921 - precision: 0.9890 - val_loss: 4.4303 - val_accuracy: 0.6180 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4095 - val_recall: 0.9862 - val_precision: 0.5718\n",
            "Epoch 446/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0336 - accuracy: 0.9887 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9904 - precision: 0.9865\n",
            "Epoch 446: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 176ms/step - loss: 0.0336 - accuracy: 0.9887 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9904 - precision: 0.9865 - val_loss: 4.6567 - val_accuracy: 0.6180 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.3904 - val_recall: 0.9878 - val_precision: 0.5736\n",
            "Epoch 447/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0319 - accuracy: 0.9914 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9961 - precision: 0.9869\n",
            "Epoch 447: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 179ms/step - loss: 0.0319 - accuracy: 0.9914 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9961 - precision: 0.9869 - val_loss: 4.1205 - val_accuracy: 0.6180 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4434 - val_recall: 0.9845 - val_precision: 0.5696\n",
            "Epoch 448/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0286 - accuracy: 0.9898 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9896 - precision: 0.9896\n",
            "Epoch 448: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 178ms/step - loss: 0.0286 - accuracy: 0.9898 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9896 - precision: 0.9896 - val_loss: 4.2609 - val_accuracy: 0.6055 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4387 - val_recall: 0.9713 - val_precision: 0.5561\n",
            "Epoch 449/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0361 - accuracy: 0.9879 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9985 - recall: 0.9881 - precision: 0.9873\n",
            "Epoch 449: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 178ms/step - loss: 0.0361 - accuracy: 0.9879 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9985 - recall: 0.9881 - precision: 0.9873 - val_loss: 4.2789 - val_accuracy: 0.6125 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4203 - val_recall: 0.9844 - val_precision: 0.5645\n",
            "Epoch 450/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0280 - accuracy: 0.9906 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9921 - precision: 0.9890\n",
            "Epoch 450: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 180ms/step - loss: 0.0280 - accuracy: 0.9906 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9921 - precision: 0.9890 - val_loss: 4.2724 - val_accuracy: 0.6094 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4092 - val_recall: 0.9876 - val_precision: 0.5650\n",
            "Epoch 451/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0291 - accuracy: 0.9906 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9925 - precision: 0.9895\n",
            "Epoch 451: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 177ms/step - loss: 0.0291 - accuracy: 0.9906 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9925 - precision: 0.9895 - val_loss: 4.0858 - val_accuracy: 0.6187 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4381 - val_recall: 0.9890 - val_precision: 0.5659\n",
            "Epoch 452/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0294 - accuracy: 0.9902 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9913 - precision: 0.9889\n",
            "Epoch 452: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 178ms/step - loss: 0.0294 - accuracy: 0.9902 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9913 - precision: 0.9889 - val_loss: 4.9803 - val_accuracy: 0.6031 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.3812 - val_recall: 0.9937 - val_precision: 0.5579\n",
            "Epoch 453/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0255 - accuracy: 0.9906 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9931 - precision: 0.9885\n",
            "Epoch 453: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 175ms/step - loss: 0.0255 - accuracy: 0.9906 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9931 - precision: 0.9885 - val_loss: 4.7911 - val_accuracy: 0.5906 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.3927 - val_recall: 0.9839 - val_precision: 0.5439\n",
            "Epoch 454/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0396 - accuracy: 0.9844 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9845 - precision: 0.9845\n",
            "Epoch 454: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 180ms/step - loss: 0.0396 - accuracy: 0.9844 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9845 - precision: 0.9845 - val_loss: 4.6232 - val_accuracy: 0.5969 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4157 - val_recall: 0.9719 - val_precision: 0.5405\n",
            "Epoch 455/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0302 - accuracy: 0.9887 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9938 - precision: 0.9839\n",
            "Epoch 455: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 180ms/step - loss: 0.0302 - accuracy: 0.9887 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9938 - precision: 0.9839 - val_loss: 4.1896 - val_accuracy: 0.6273 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4365 - val_recall: 0.9890 - val_precision: 0.5716\n",
            "Epoch 456/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0409 - accuracy: 0.9875 - sensitivity_at_specificity: 0.9983 - specificity_at_sensitivity: 1.0000 - recall: 0.9892 - precision: 0.9860\n",
            "Epoch 456: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.0409 - accuracy: 0.9875 - sensitivity_at_specificity: 0.9983 - specificity_at_sensitivity: 1.0000 - recall: 0.9892 - precision: 0.9860 - val_loss: 4.1888 - val_accuracy: 0.6180 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4277 - val_recall: 0.9746 - val_precision: 0.5649\n",
            "Epoch 457/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0326 - accuracy: 0.9875 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9902 - precision: 0.9857\n",
            "Epoch 457: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 176ms/step - loss: 0.0326 - accuracy: 0.9875 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9902 - precision: 0.9857 - val_loss: 4.8838 - val_accuracy: 0.5906 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4370 - val_recall: 0.9783 - val_precision: 0.5338\n",
            "Epoch 458/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0488 - accuracy: 0.9824 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9867 - precision: 0.9784\n",
            "Epoch 458: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 182ms/step - loss: 0.0488 - accuracy: 0.9824 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9867 - precision: 0.9784 - val_loss: 3.9180 - val_accuracy: 0.6211 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4592 - val_recall: 0.9873 - val_precision: 0.5664\n",
            "Epoch 459/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0379 - accuracy: 0.9871 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9843 - precision: 0.9897\n",
            "Epoch 459: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 177ms/step - loss: 0.0379 - accuracy: 0.9871 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9843 - precision: 0.9897 - val_loss: 4.5298 - val_accuracy: 0.5984 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4195 - val_recall: 0.9854 - val_precision: 0.5455\n",
            "Epoch 460/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.0265 - accuracy: 0.9926 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9974 - precision: 0.9879\n",
            "Epoch 460: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 174ms/step - loss: 0.0287 - accuracy: 0.9917 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9950 - precision: 0.9884 - val_loss: 4.0945 - val_accuracy: 0.6211 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4357 - val_recall: 0.9798 - val_precision: 0.5713\n",
            "Epoch 461/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0336 - accuracy: 0.9863 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9909 - precision: 0.9828\n",
            "Epoch 461: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 174ms/step - loss: 0.0336 - accuracy: 0.9863 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9909 - precision: 0.9828 - val_loss: 4.8944 - val_accuracy: 0.5914 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4135 - val_recall: 0.9870 - val_precision: 0.5410\n",
            "Epoch 462/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0442 - accuracy: 0.9848 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9985 - recall: 0.9834 - precision: 0.9857\n",
            "Epoch 462: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 182ms/step - loss: 0.0442 - accuracy: 0.9848 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9985 - recall: 0.9834 - precision: 0.9857 - val_loss: 4.4168 - val_accuracy: 0.6234 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4439 - val_recall: 0.9793 - val_precision: 0.5677\n",
            "Epoch 463/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0329 - accuracy: 0.9879 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9938 - precision: 0.9823\n",
            "Epoch 463: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 176ms/step - loss: 0.0329 - accuracy: 0.9879 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9938 - precision: 0.9823 - val_loss: 4.3440 - val_accuracy: 0.6125 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4362 - val_recall: 0.9829 - val_precision: 0.5666\n",
            "Epoch 464/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0395 - accuracy: 0.9832 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9811 - precision: 0.9850\n",
            "Epoch 464: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 176ms/step - loss: 0.0395 - accuracy: 0.9832 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9811 - precision: 0.9850 - val_loss: 4.3761 - val_accuracy: 0.5984 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4357 - val_recall: 0.9790 - val_precision: 0.5474\n",
            "Epoch 465/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0328 - accuracy: 0.9896 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9877 - precision: 0.9918\n",
            "Epoch 465: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.0328 - accuracy: 0.9896 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9877 - precision: 0.9918 - val_loss: 4.3509 - val_accuracy: 0.6156 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4360 - val_recall: 0.9840 - val_precision: 0.5602\n",
            "Epoch 466/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0304 - accuracy: 0.9875 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9896 - precision: 0.9848\n",
            "Epoch 466: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 177ms/step - loss: 0.0304 - accuracy: 0.9875 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9896 - precision: 0.9848 - val_loss: 3.8921 - val_accuracy: 0.6430 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4492 - val_recall: 0.9761 - val_precision: 0.5973\n",
            "Epoch 467/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0389 - accuracy: 0.9875 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9888 - precision: 0.9857\n",
            "Epoch 467: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 176ms/step - loss: 0.0389 - accuracy: 0.9875 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9888 - precision: 0.9857 - val_loss: 4.2877 - val_accuracy: 0.6219 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4132 - val_recall: 0.9878 - val_precision: 0.5773\n",
            "Epoch 468/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0435 - accuracy: 0.9836 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9891 - precision: 0.9785\n",
            "Epoch 468: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 176ms/step - loss: 0.0435 - accuracy: 0.9836 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9891 - precision: 0.9785 - val_loss: 4.0680 - val_accuracy: 0.6313 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4659 - val_recall: 0.9694 - val_precision: 0.5706\n",
            "Epoch 469/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0503 - accuracy: 0.9832 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9985 - recall: 0.9823 - precision: 0.9831\n",
            "Epoch 469: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 175ms/step - loss: 0.0503 - accuracy: 0.9832 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9985 - recall: 0.9823 - precision: 0.9831 - val_loss: 4.1229 - val_accuracy: 0.6094 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4324 - val_recall: 0.9829 - val_precision: 0.5642\n",
            "Epoch 470/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0339 - accuracy: 0.9883 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9899 - precision: 0.9868\n",
            "Epoch 470: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 174ms/step - loss: 0.0339 - accuracy: 0.9883 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9899 - precision: 0.9868 - val_loss: 3.6887 - val_accuracy: 0.6266 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4838 - val_recall: 0.9763 - val_precision: 0.5717\n",
            "Epoch 471/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0359 - accuracy: 0.9852 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9884 - precision: 0.9823\n",
            "Epoch 471: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 184ms/step - loss: 0.0359 - accuracy: 0.9852 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9884 - precision: 0.9823 - val_loss: 4.3045 - val_accuracy: 0.6266 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4347 - val_recall: 0.9841 - val_precision: 0.5695\n",
            "Epoch 472/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0296 - accuracy: 0.9922 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9960 - precision: 0.9882\n",
            "Epoch 472: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 178ms/step - loss: 0.0296 - accuracy: 0.9922 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9960 - precision: 0.9882 - val_loss: 4.2395 - val_accuracy: 0.6219 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.3935 - val_recall: 0.9742 - val_precision: 0.5793\n",
            "Epoch 473/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0414 - accuracy: 0.9832 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9810 - precision: 0.9862\n",
            "Epoch 473: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 181ms/step - loss: 0.0414 - accuracy: 0.9832 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9810 - precision: 0.9862 - val_loss: 4.3362 - val_accuracy: 0.6156 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4266 - val_recall: 0.9822 - val_precision: 0.5583\n",
            "Epoch 474/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0382 - accuracy: 0.9871 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9883 - precision: 0.9860\n",
            "Epoch 474: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 178ms/step - loss: 0.0382 - accuracy: 0.9871 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9883 - precision: 0.9860 - val_loss: 4.3680 - val_accuracy: 0.6133 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4156 - val_recall: 0.9809 - val_precision: 0.5605\n",
            "Epoch 475/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0291 - accuracy: 0.9883 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9850 - precision: 0.9912\n",
            "Epoch 475: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 179ms/step - loss: 0.0291 - accuracy: 0.9883 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9850 - precision: 0.9912 - val_loss: 4.4418 - val_accuracy: 0.6313 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4439 - val_recall: 0.9830 - val_precision: 0.5798\n",
            "Epoch 476/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0432 - accuracy: 0.9848 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9890 - precision: 0.9805\n",
            "Epoch 476: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 185ms/step - loss: 0.0432 - accuracy: 0.9848 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9890 - precision: 0.9805 - val_loss: 3.7964 - val_accuracy: 0.6297 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4916 - val_recall: 0.9663 - val_precision: 0.5706\n",
            "Epoch 477/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0300 - accuracy: 0.9883 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9882 - precision: 0.9882\n",
            "Epoch 477: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 184ms/step - loss: 0.0300 - accuracy: 0.9883 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9882 - precision: 0.9882 - val_loss: 4.8340 - val_accuracy: 0.6453 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.3907 - val_recall: 0.9939 - val_precision: 0.5905\n",
            "Epoch 478/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0349 - accuracy: 0.9871 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9915 - precision: 0.9832\n",
            "Epoch 478: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 194ms/step - loss: 0.0349 - accuracy: 0.9871 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9915 - precision: 0.9832 - val_loss: 3.8183 - val_accuracy: 0.6172 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4894 - val_recall: 0.9726 - val_precision: 0.5604\n",
            "Epoch 479/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0439 - accuracy: 0.9832 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9803 - precision: 0.9843\n",
            "Epoch 479: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 182ms/step - loss: 0.0439 - accuracy: 0.9832 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9803 - precision: 0.9843 - val_loss: 4.3612 - val_accuracy: 0.5906 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4246 - val_recall: 0.9868 - val_precision: 0.5360\n",
            "Epoch 480/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0348 - accuracy: 0.9883 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9985 - recall: 0.9889 - precision: 0.9874\n",
            "Epoch 480: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 180ms/step - loss: 0.0348 - accuracy: 0.9883 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9985 - recall: 0.9889 - precision: 0.9874 - val_loss: 4.1157 - val_accuracy: 0.6203 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4552 - val_recall: 0.9731 - val_precision: 0.5673\n",
            "Epoch 481/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0421 - accuracy: 0.9840 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9867 - precision: 0.9814\n",
            "Epoch 481: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 184ms/step - loss: 0.0421 - accuracy: 0.9840 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9867 - precision: 0.9814 - val_loss: 4.1370 - val_accuracy: 0.6242 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4493 - val_recall: 0.9703 - val_precision: 0.5730\n",
            "Epoch 482/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0328 - accuracy: 0.9891 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9923 - precision: 0.9863\n",
            "Epoch 482: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 195ms/step - loss: 0.0328 - accuracy: 0.9891 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9923 - precision: 0.9863 - val_loss: 4.2616 - val_accuracy: 0.6359 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4418 - val_recall: 0.9832 - val_precision: 0.5852\n",
            "Epoch 483/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0348 - accuracy: 0.9859 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9900 - precision: 0.9824\n",
            "Epoch 483: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 185ms/step - loss: 0.0348 - accuracy: 0.9859 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9900 - precision: 0.9824 - val_loss: 4.5682 - val_accuracy: 0.6367 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4124 - val_recall: 0.9862 - val_precision: 0.5851\n",
            "Epoch 484/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0323 - accuracy: 0.9891 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9885 - precision: 0.9900\n",
            "Epoch 484: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 182ms/step - loss: 0.0323 - accuracy: 0.9891 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9885 - precision: 0.9900 - val_loss: 4.4611 - val_accuracy: 0.6453 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4448 - val_recall: 0.9937 - val_precision: 0.5845\n",
            "Epoch 485/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0345 - accuracy: 0.9875 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9899 - precision: 0.9853\n",
            "Epoch 485: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 177ms/step - loss: 0.0345 - accuracy: 0.9875 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9899 - precision: 0.9853 - val_loss: 3.9280 - val_accuracy: 0.6359 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4758 - val_recall: 0.9765 - val_precision: 0.5805\n",
            "Epoch 486/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0371 - accuracy: 0.9871 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9851 - precision: 0.9890\n",
            "Epoch 486: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 177ms/step - loss: 0.0371 - accuracy: 0.9871 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9851 - precision: 0.9890 - val_loss: 4.7774 - val_accuracy: 0.5945 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4129 - val_recall: 0.9842 - val_precision: 0.5496\n",
            "Epoch 487/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0405 - accuracy: 0.9852 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9985 - recall: 0.9850 - precision: 0.9850\n",
            "Epoch 487: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 179ms/step - loss: 0.0405 - accuracy: 0.9852 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9985 - recall: 0.9850 - precision: 0.9850 - val_loss: 3.8568 - val_accuracy: 0.6266 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4685 - val_recall: 0.9809 - val_precision: 0.5697\n",
            "Epoch 488/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0378 - accuracy: 0.9863 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9898 - precision: 0.9829\n",
            "Epoch 488: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 195ms/step - loss: 0.0378 - accuracy: 0.9863 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9898 - precision: 0.9829 - val_loss: 4.0964 - val_accuracy: 0.6117 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4387 - val_recall: 0.9809 - val_precision: 0.5595\n",
            "Epoch 489/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0239 - accuracy: 0.9902 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9915 - precision: 0.9892\n",
            "Epoch 489: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 181ms/step - loss: 0.0239 - accuracy: 0.9902 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9915 - precision: 0.9892 - val_loss: 4.8158 - val_accuracy: 0.6109 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.3921 - val_recall: 0.9860 - val_precision: 0.5653\n",
            "Epoch 490/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0245 - accuracy: 0.9914 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9943 - precision: 0.9878\n",
            "Epoch 490: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 185ms/step - loss: 0.0245 - accuracy: 0.9914 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9943 - precision: 0.9878 - val_loss: 4.6683 - val_accuracy: 0.6133 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4238 - val_recall: 0.9919 - val_precision: 0.5554\n",
            "Epoch 491/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0292 - accuracy: 0.9887 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9875 - precision: 0.9898\n",
            "Epoch 491: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 182ms/step - loss: 0.0292 - accuracy: 0.9887 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9875 - precision: 0.9898 - val_loss: 4.6965 - val_accuracy: 0.6281 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4581 - val_recall: 0.9833 - val_precision: 0.5583\n",
            "Epoch 492/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0273 - accuracy: 0.9887 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9895 - precision: 0.9872\n",
            "Epoch 492: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 180ms/step - loss: 0.0273 - accuracy: 0.9887 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9895 - precision: 0.9872 - val_loss: 4.6130 - val_accuracy: 0.6398 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4199 - val_recall: 0.9863 - val_precision: 0.5887\n",
            "Epoch 493/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0258 - accuracy: 0.9898 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9922 - precision: 0.9876\n",
            "Epoch 493: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 180ms/step - loss: 0.0258 - accuracy: 0.9898 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9922 - precision: 0.9876 - val_loss: 4.9072 - val_accuracy: 0.6203 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4056 - val_recall: 0.9826 - val_precision: 0.5674\n",
            "Epoch 494/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0338 - accuracy: 0.9895 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9937 - precision: 0.9852\n",
            "Epoch 494: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 180ms/step - loss: 0.0338 - accuracy: 0.9895 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9937 - precision: 0.9852 - val_loss: 4.4663 - val_accuracy: 0.6273 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4137 - val_recall: 0.9862 - val_precision: 0.5795\n",
            "Epoch 495/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0319 - accuracy: 0.9871 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9835 - precision: 0.9905\n",
            "Epoch 495: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 182ms/step - loss: 0.0319 - accuracy: 0.9871 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9835 - precision: 0.9905 - val_loss: 4.6105 - val_accuracy: 0.6469 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4200 - val_recall: 0.9892 - val_precision: 0.5906\n",
            "Epoch 496/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0386 - accuracy: 0.9836 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9901 - precision: 0.9781\n",
            "Epoch 496: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 180ms/step - loss: 0.0386 - accuracy: 0.9836 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9901 - precision: 0.9781 - val_loss: 4.5250 - val_accuracy: 0.6242 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4438 - val_recall: 0.9826 - val_precision: 0.5688\n",
            "Epoch 497/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0322 - accuracy: 0.9871 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9911 - precision: 0.9823\n",
            "Epoch 497: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 182ms/step - loss: 0.0322 - accuracy: 0.9871 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9911 - precision: 0.9823 - val_loss: 4.3624 - val_accuracy: 0.6266 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4265 - val_recall: 0.9799 - val_precision: 0.5769\n",
            "Epoch 498/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0295 - accuracy: 0.9906 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9938 - precision: 0.9876\n",
            "Epoch 498: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 180ms/step - loss: 0.0295 - accuracy: 0.9906 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9938 - precision: 0.9876 - val_loss: 4.8642 - val_accuracy: 0.6359 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4148 - val_recall: 0.9802 - val_precision: 0.5874\n",
            "Epoch 499/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0328 - accuracy: 0.9879 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9893 - precision: 0.9870\n",
            "Epoch 499: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 182ms/step - loss: 0.0328 - accuracy: 0.9879 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9893 - precision: 0.9870 - val_loss: 4.4572 - val_accuracy: 0.6297 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4439 - val_recall: 0.9753 - val_precision: 0.5794\n",
            "Epoch 500/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0297 - accuracy: 0.9895 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9913 - precision: 0.9874\n",
            "Epoch 500: val_accuracy did not improve from 0.69141\n",
            "10/10 [==============================] - 2s 180ms/step - loss: 0.0297 - accuracy: 0.9895 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9913 - precision: 0.9874 - val_loss: 4.2711 - val_accuracy: 0.6367 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4256 - val_recall: 0.9728 - val_precision: 0.5903\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Performance Metrics**"
      ],
      "metadata": {
        "id": "_IqP0zp9LTVS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Training_Accuracy=history.history['accuracy']\n",
        "Validation_Accuracy=history.history['val_accuracy']\n",
        "Validation_Specificity=history.history['val_specificity_at_sensitivity']\n",
        "Validation_Sensitivity=history.history['val_sensitivity_at_specificity']\n",
        "Validation_Recall=history.history['val_recall']\n",
        "Validation_Precision=history.history['val_precision']\n",
        "Validation_Loss=history.history['val_loss']\n",
        "\n",
        "print(\"Training Accuracy: \",max(Training_Accuracy))\n",
        "print(\"Validation Accuracy: \",max(Validation_Accuracy))\n",
        "print(\"Validation Specificity: \",max(Validation_Specificity))\n",
        "print(\"Validation Sensitivity: \",max(Validation_Sensitivity))\n",
        "print(\"Validation Recall: \",max(Validation_Recall))\n",
        "print(\"Validation Precision: \",max(Validation_Precision))\n",
        "print(\"Validation Loss: \",min(Validation_Loss))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCdS_0U65A0-",
        "outputId": "571651ba-6e1f-4918-eee4-25ebbe599c44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy:  0.9921875\n",
            "Validation Accuracy:  0.69140625\n",
            "Validation Specificity:  0.8009259104728699\n",
            "Validation Sensitivity:  0.8874074220657349\n",
            "Validation Recall:  1.0\n",
            "Validation Precision:  0.63671875\n",
            "Validation Loss:  0.5633885860443115\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Accuracy Graph**"
      ],
      "metadata": {
        "id": "ytCD-ni-LV3i"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLqjG2X-vdLj",
        "outputId": "957ca40c-a395-44e4-f241-048644526954",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        }
      },
      "source": [
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loss Graph**"
      ],
      "metadata": {
        "id": "G2Pw17D4LXmb"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBSAyVfivvHX",
        "outputId": "51510247-5675-4a68-cb5c-0f2ec2c5d4ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        }
      },
      "source": [
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}