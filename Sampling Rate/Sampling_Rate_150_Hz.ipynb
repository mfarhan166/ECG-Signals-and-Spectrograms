{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "7e88OLey6Bgd"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7e88OLey6Bgd"
      },
      "source": [
        "# **Image Classification with Convolutional Neural Networks (CNNs)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsTzc3oi726u"
      },
      "source": [
        "# **Building a Convolutional Neural Network with Keras**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCglDGFy8AhT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "693b8631-c07d-4fa5-a7fc-f4ff1d0aaa5f"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "tf.__version__\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import matplotlib.image as mpimg\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "import imageio\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.8.2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qf7eW3HC9XVL"
      },
      "source": [
        "**Data Acquisition and ImageDataGenerator**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0BfyGlJbx0l"
      },
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255) #Normalize the pixel values\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hsimgs7aqt6G"
      },
      "source": [
        "#File path to the folder containin images\n",
        "train_dir = os.path.join('/content/spectrograms-150/Train')\n",
        "validation_dir = os.path.join('/content/spectrograms-150/Validation')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NyvlF41oqxEP",
        "outputId": "1319a09d-c6f8-4e33-c3ed-56a3ac7d49d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(64,64),\n",
        "    batch_size=256,\n",
        "    shuffle=True,\n",
        "    class_mode='binary')\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    validation_dir,\n",
        "    target_size=(64,64),\n",
        "    batch_size=256,\n",
        "    shuffle=True,\n",
        "    class_mode='binary')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 33128 images belonging to 2 classes.\n",
            "Found 6780 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3yhwpN_-BaS"
      },
      "source": [
        "**Building the Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSzxq4KDtKN6"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "                                    \n",
        "    # First convolution layer \n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(64, 64, 3),use_bias=True),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "\n",
        "    # Second convolution layer \n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu',use_bias=True),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    \n",
        "\n",
        "    # Third convolution layer  \n",
        "    tf.keras.layers.Conv2D(256, (3,3), activation='relu',use_bias=True),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "\n",
        "  # Fourth convolution layer  \n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu',use_bias=True),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "\n",
        "\n",
        "    # Flatten the pooled feature maps\n",
        "    tf.keras.layers.Flatten(),\n",
        "\n",
        "    # Fully connected hidden layer\n",
        "    tf.keras.layers.Dense(8, activation='relu',use_bias=True),\n",
        "\n",
        "\n",
        "    # Output layer\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid',activity_regularizer=regularizers.L1(0.001))   \n",
        "\n",
        "])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDXufVt4-LFY"
      },
      "source": [
        "**Model Summary**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HU0RFGLtNJb",
        "outputId": "08c30a3c-9036-4547-f6ec-6ffdd88b7e8f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 62, 62, 64)        1792      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 31, 31, 64)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 31, 31, 64)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 29, 29, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 14, 14, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 12, 12, 256)       295168    \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 6, 6, 256)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 6, 6, 256)         0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 4, 4, 64)          147520    \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 2, 2, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 2, 2, 64)          0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 8)                 2056      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 520,401\n",
            "Trainable params: 520,401\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THk8lK3G-cdk"
      },
      "source": [
        "**Optimizer Implementation and model training/validation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBN3GBMItPMH"
      },
      "source": [
        "#from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import SensitivityAtSpecificity,SpecificityAtSensitivity,Recall,Precision\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=Adam(learning_rate=0.001),\n",
        "              metrics=['accuracy',SensitivityAtSpecificity(0.5),SpecificityAtSensitivity(0.5),Recall(0.5),Precision(0.5)]) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Q0MPMwh3EgY"
      },
      "source": [
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('val_accuracy')>0.99): \n",
        "      print(\"\\nReached 99% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "callbacks = myCallback()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7f6gDG3dx9sJ",
        "outputId": "0a216034-4da7-4bf2-aa1f-894003ab966b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "checkpoint = ModelCheckpoint(\"ECG_Spectrogram_Model.h5\", monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
        "\n",
        "history = model.fit(\n",
        "      train_generator,\n",
        "      steps_per_epoch=10,  \n",
        "      epochs=500,\n",
        "      verbose=1,\n",
        "      validation_data = validation_generator,\n",
        "      callbacks = [callbacks,checkpoint]\n",
        ") "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.7020 - accuracy: 0.4914 - sensitivity_at_specificity: 0.4606 - specificity_at_sensitivity: 0.4660 - recall: 0.7713 - precision: 0.4947\n",
            "Epoch 1: val_accuracy improved from -inf to 0.48750, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 17s 222ms/step - loss: 0.7020 - accuracy: 0.4914 - sensitivity_at_specificity: 0.4606 - specificity_at_sensitivity: 0.4660 - recall: 0.7713 - precision: 0.4947 - val_loss: 0.6937 - val_accuracy: 0.4875 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
            "Epoch 2/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6942 - accuracy: 0.5027 - sensitivity_at_specificity: 0.0827 - specificity_at_sensitivity: 0.0636 - recall: 0.1110 - precision: 0.4947\n",
            "Epoch 2: val_accuracy improved from 0.48750 to 0.50781, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 182ms/step - loss: 0.6942 - accuracy: 0.5027 - sensitivity_at_specificity: 0.0827 - specificity_at_sensitivity: 0.0636 - recall: 0.1110 - precision: 0.4947 - val_loss: 0.6936 - val_accuracy: 0.5078 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
            "Epoch 3/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6941 - accuracy: 0.5137 - sensitivity_at_specificity: 0.0239 - specificity_at_sensitivity: 0.0658 - recall: 0.0463 - precision: 0.5370\n",
            "Epoch 3: val_accuracy improved from 0.50781 to 0.51953, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.6941 - accuracy: 0.5137 - sensitivity_at_specificity: 0.0239 - specificity_at_sensitivity: 0.0658 - recall: 0.0463 - precision: 0.5370 - val_loss: 0.6935 - val_accuracy: 0.5195 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
            "Epoch 4/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6935 - accuracy: 0.4945 - sensitivity_at_specificity: 0.0132 - specificity_at_sensitivity: 0.0291 - recall: 0.0388 - precision: 0.4762\n",
            "Epoch 4: val_accuracy did not improve from 0.51953\n",
            "10/10 [==============================] - 2s 156ms/step - loss: 0.6935 - accuracy: 0.4945 - sensitivity_at_specificity: 0.0132 - specificity_at_sensitivity: 0.0291 - recall: 0.0388 - precision: 0.4762 - val_loss: 0.6936 - val_accuracy: 0.5109 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
            "Epoch 5/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6852 - accuracy: 0.4922 - sensitivity_at_specificity: 0.5683 - specificity_at_sensitivity: 0.5581 - recall: 0.0115 - precision: 0.5769\n",
            "Epoch 5: val_accuracy did not improve from 0.51953\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.6852 - accuracy: 0.4922 - sensitivity_at_specificity: 0.5683 - specificity_at_sensitivity: 0.5581 - recall: 0.0115 - precision: 0.5769 - val_loss: 0.6866 - val_accuracy: 0.4961 - val_sensitivity_at_specificity: 0.6403 - val_specificity_at_sensitivity: 0.6142 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
            "Epoch 6/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6071 - accuracy: 0.5637 - sensitivity_at_specificity: 0.9240 - specificity_at_sensitivity: 0.7972 - recall: 0.2130 - precision: 0.6862\n",
            "Epoch 6: val_accuracy improved from 0.51953 to 0.56484, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.6071 - accuracy: 0.5637 - sensitivity_at_specificity: 0.9240 - specificity_at_sensitivity: 0.7972 - recall: 0.2130 - precision: 0.6862 - val_loss: 0.6931 - val_accuracy: 0.5648 - val_sensitivity_at_specificity: 0.5463 - val_specificity_at_sensitivity: 0.5854 - val_recall: 0.7068 - val_precision: 0.5552\n",
            "Epoch 7/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5574 - accuracy: 0.7469 - sensitivity_at_specificity: 0.9553 - specificity_at_sensitivity: 0.8008 - recall: 0.8643 - precision: 0.6988\n",
            "Epoch 7: val_accuracy did not improve from 0.56484\n",
            "10/10 [==============================] - 2s 153ms/step - loss: 0.5574 - accuracy: 0.7469 - sensitivity_at_specificity: 0.9553 - specificity_at_sensitivity: 0.8008 - recall: 0.8643 - precision: 0.6988 - val_loss: 0.7076 - val_accuracy: 0.5570 - val_sensitivity_at_specificity: 0.0973 - val_specificity_at_sensitivity: 0.3499 - val_recall: 0.8713 - val_precision: 0.5337\n",
            "Epoch 8/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5326 - accuracy: 0.7400 - sensitivity_at_specificity: 0.9521 - specificity_at_sensitivity: 0.7441 - recall: 0.9323 - precision: 0.6750\n",
            "Epoch 8: val_accuracy improved from 0.56484 to 0.57500, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 197ms/step - loss: 0.5326 - accuracy: 0.7400 - sensitivity_at_specificity: 0.9521 - specificity_at_sensitivity: 0.7441 - recall: 0.9323 - precision: 0.6750 - val_loss: 0.6793 - val_accuracy: 0.5750 - val_sensitivity_at_specificity: 0.1811 - val_specificity_at_sensitivity: 0.3107 - val_recall: 0.9536 - val_precision: 0.5451\n",
            "Epoch 9/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5259 - accuracy: 0.7402 - sensitivity_at_specificity: 0.9562 - specificity_at_sensitivity: 0.7527 - recall: 0.9030 - precision: 0.6808\n",
            "Epoch 9: val_accuracy improved from 0.57500 to 0.59141, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.5259 - accuracy: 0.7402 - sensitivity_at_specificity: 0.9562 - specificity_at_sensitivity: 0.7527 - recall: 0.9030 - precision: 0.6808 - val_loss: 0.6604 - val_accuracy: 0.5914 - val_sensitivity_at_specificity: 0.0664 - val_specificity_at_sensitivity: 0.4668 - val_recall: 0.8910 - val_precision: 0.5540\n",
            "Epoch 10/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4804 - accuracy: 0.7750 - sensitivity_at_specificity: 0.9867 - specificity_at_sensitivity: 0.7896 - recall: 0.9280 - precision: 0.7100\n",
            "Epoch 10: val_accuracy improved from 0.59141 to 0.60312, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.4804 - accuracy: 0.7750 - sensitivity_at_specificity: 0.9867 - specificity_at_sensitivity: 0.7896 - recall: 0.9280 - precision: 0.7100 - val_loss: 0.6518 - val_accuracy: 0.6031 - val_sensitivity_at_specificity: 0.0614 - val_specificity_at_sensitivity: 0.4357 - val_recall: 0.9228 - val_precision: 0.5608\n",
            "Epoch 11/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4696 - accuracy: 0.7789 - sensitivity_at_specificity: 0.9855 - specificity_at_sensitivity: 0.7971 - recall: 0.9220 - precision: 0.7098\n",
            "Epoch 11: val_accuracy improved from 0.60312 to 0.61094, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.4696 - accuracy: 0.7789 - sensitivity_at_specificity: 0.9855 - specificity_at_sensitivity: 0.7971 - recall: 0.9220 - precision: 0.7098 - val_loss: 0.6406 - val_accuracy: 0.6109 - val_sensitivity_at_specificity: 0.0515 - val_specificity_at_sensitivity: 0.4601 - val_recall: 0.9516 - val_precision: 0.5664\n",
            "Epoch 12/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4495 - accuracy: 0.7875 - sensitivity_at_specificity: 0.9969 - specificity_at_sensitivity: 0.7919 - recall: 0.9319 - precision: 0.7225\n",
            "Epoch 12: val_accuracy did not improve from 0.61094\n",
            "10/10 [==============================] - 2s 153ms/step - loss: 0.4495 - accuracy: 0.7875 - sensitivity_at_specificity: 0.9969 - specificity_at_sensitivity: 0.7919 - recall: 0.9319 - precision: 0.7225 - val_loss: 0.7095 - val_accuracy: 0.5578 - val_sensitivity_at_specificity: 0.0388 - val_specificity_at_sensitivity: 0.4471 - val_recall: 0.9935 - val_precision: 0.5221\n",
            "Epoch 13/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4716 - accuracy: 0.7750 - sensitivity_at_specificity: 0.9920 - specificity_at_sensitivity: 0.7989 - recall: 0.9419 - precision: 0.7018\n",
            "Epoch 13: val_accuracy did not improve from 0.61094\n",
            "10/10 [==============================] - 2s 153ms/step - loss: 0.4716 - accuracy: 0.7750 - sensitivity_at_specificity: 0.9920 - specificity_at_sensitivity: 0.7989 - recall: 0.9419 - precision: 0.7018 - val_loss: 0.6918 - val_accuracy: 0.5516 - val_sensitivity_at_specificity: 0.4335 - val_specificity_at_sensitivity: 0.2022 - val_recall: 0.9968 - val_precision: 0.5241\n",
            "Epoch 14/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4434 - accuracy: 0.7891 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.8015 - recall: 0.9518 - precision: 0.7117\n",
            "Epoch 14: val_accuracy did not improve from 0.61094\n",
            "10/10 [==============================] - 2s 152ms/step - loss: 0.4434 - accuracy: 0.7891 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.8015 - recall: 0.9518 - precision: 0.7117 - val_loss: 0.6668 - val_accuracy: 0.5820 - val_sensitivity_at_specificity: 0.1389 - val_specificity_at_sensitivity: 0.3189 - val_recall: 0.9886 - val_precision: 0.5340\n",
            "Epoch 15/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4237 - accuracy: 0.8008 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8112 - recall: 0.9678 - precision: 0.7243\n",
            "Epoch 15: val_accuracy improved from 0.61094 to 0.63359, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.4237 - accuracy: 0.8008 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8112 - recall: 0.9678 - precision: 0.7243 - val_loss: 0.6337 - val_accuracy: 0.6336 - val_sensitivity_at_specificity: 0.0699 - val_specificity_at_sensitivity: 0.4737 - val_recall: 0.9821 - val_precision: 0.5909\n",
            "Epoch 16/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4221 - accuracy: 0.8039 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8099 - recall: 0.9647 - precision: 0.7338\n",
            "Epoch 16: val_accuracy did not improve from 0.63359\n",
            "10/10 [==============================] - 2s 156ms/step - loss: 0.4221 - accuracy: 0.8039 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8099 - recall: 0.9647 - precision: 0.7338 - val_loss: 0.6667 - val_accuracy: 0.5938 - val_sensitivity_at_specificity: 0.2904 - val_specificity_at_sensitivity: 0.4090 - val_recall: 0.9890 - val_precision: 0.5512\n",
            "Epoch 17/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3918 - accuracy: 0.8215 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8319 - recall: 0.9719 - precision: 0.7414\n",
            "Epoch 17: val_accuracy did not improve from 0.63359\n",
            "10/10 [==============================] - 2s 154ms/step - loss: 0.3918 - accuracy: 0.8215 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8319 - recall: 0.9719 - precision: 0.7414 - val_loss: 0.6773 - val_accuracy: 0.6031 - val_sensitivity_at_specificity: 0.6931 - val_specificity_at_sensitivity: 0.5016 - val_recall: 1.0000 - val_precision: 0.5583\n",
            "Epoch 18/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4067 - accuracy: 0.8145 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8270 - recall: 0.9783 - precision: 0.7381\n",
            "Epoch 18: val_accuracy did not improve from 0.63359\n",
            "10/10 [==============================] - 2s 154ms/step - loss: 0.4067 - accuracy: 0.8145 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8270 - recall: 0.9783 - precision: 0.7381 - val_loss: 0.6332 - val_accuracy: 0.6305 - val_sensitivity_at_specificity: 0.4545 - val_specificity_at_sensitivity: 0.4007 - val_recall: 0.9985 - val_precision: 0.5867\n",
            "Epoch 19/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4095 - accuracy: 0.8129 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7927 - recall: 0.9786 - precision: 0.7392\n",
            "Epoch 19: val_accuracy improved from 0.63359 to 0.63516, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.4095 - accuracy: 0.8129 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7927 - recall: 0.9786 - precision: 0.7392 - val_loss: 0.6208 - val_accuracy: 0.6352 - val_sensitivity_at_specificity: 0.4273 - val_specificity_at_sensitivity: 0.4419 - val_recall: 0.9727 - val_precision: 0.5885\n",
            "Epoch 20/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4178 - accuracy: 0.8043 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8259 - recall: 0.9722 - precision: 0.7304\n",
            "Epoch 20: val_accuracy did not improve from 0.63516\n",
            "10/10 [==============================] - 2s 155ms/step - loss: 0.4178 - accuracy: 0.8043 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8259 - recall: 0.9722 - precision: 0.7304 - val_loss: 0.6245 - val_accuracy: 0.6305 - val_sensitivity_at_specificity: 0.3833 - val_specificity_at_sensitivity: 0.4969 - val_recall: 0.9890 - val_precision: 0.5737\n",
            "Epoch 21/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4041 - accuracy: 0.8152 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8254 - recall: 0.9882 - precision: 0.7328\n",
            "Epoch 21: val_accuracy did not improve from 0.63516\n",
            "10/10 [==============================] - 2s 156ms/step - loss: 0.4041 - accuracy: 0.8152 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8254 - recall: 0.9882 - precision: 0.7328 - val_loss: 0.6245 - val_accuracy: 0.6313 - val_sensitivity_at_specificity: 0.5982 - val_specificity_at_sensitivity: 0.5874 - val_recall: 0.9653 - val_precision: 0.5873\n",
            "Epoch 22/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4104 - accuracy: 0.8065 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8438 - recall: 0.9662 - precision: 0.7288\n",
            "Epoch 22: val_accuracy did not improve from 0.63516\n",
            "10/10 [==============================] - 1s 148ms/step - loss: 0.4104 - accuracy: 0.8065 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8438 - recall: 0.9662 - precision: 0.7288 - val_loss: 0.6607 - val_accuracy: 0.6047 - val_sensitivity_at_specificity: 0.6527 - val_specificity_at_sensitivity: 0.5339 - val_recall: 0.9798 - val_precision: 0.5618\n",
            "Epoch 23/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4172 - accuracy: 0.8082 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.8278 - recall: 0.9690 - precision: 0.7297\n",
            "Epoch 23: val_accuracy did not improve from 0.63516\n",
            "10/10 [==============================] - 2s 155ms/step - loss: 0.4172 - accuracy: 0.8082 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.8278 - recall: 0.9690 - precision: 0.7297 - val_loss: 0.7202 - val_accuracy: 0.5555 - val_sensitivity_at_specificity: 0.5378 - val_specificity_at_sensitivity: 0.5159 - val_recall: 1.0000 - val_precision: 0.5218\n",
            "Epoch 24/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4233 - accuracy: 0.8012 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8200 - recall: 0.9805 - precision: 0.7220\n",
            "Epoch 24: val_accuracy did not improve from 0.63516\n",
            "10/10 [==============================] - 2s 154ms/step - loss: 0.4233 - accuracy: 0.8012 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8200 - recall: 0.9805 - precision: 0.7220 - val_loss: 0.7014 - val_accuracy: 0.5633 - val_sensitivity_at_specificity: 0.5948 - val_specificity_at_sensitivity: 0.5219 - val_recall: 1.0000 - val_precision: 0.5247\n",
            "Epoch 25/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4044 - accuracy: 0.8156 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.8319 - recall: 0.9837 - precision: 0.7373\n",
            "Epoch 25: val_accuracy did not improve from 0.63516\n",
            "10/10 [==============================] - 2s 153ms/step - loss: 0.4044 - accuracy: 0.8156 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.8319 - recall: 0.9837 - precision: 0.7373 - val_loss: 0.6430 - val_accuracy: 0.6242 - val_sensitivity_at_specificity: 0.4711 - val_specificity_at_sensitivity: 0.4867 - val_recall: 0.9969 - val_precision: 0.5716\n",
            "Epoch 26/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4101 - accuracy: 0.8098 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8221 - recall: 0.9832 - precision: 0.7251\n",
            "Epoch 26: val_accuracy improved from 0.63516 to 0.65547, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 156ms/step - loss: 0.4101 - accuracy: 0.8098 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8221 - recall: 0.9832 - precision: 0.7251 - val_loss: 0.6102 - val_accuracy: 0.6555 - val_sensitivity_at_specificity: 0.6105 - val_specificity_at_sensitivity: 0.5946 - val_recall: 0.9531 - val_precision: 0.6142\n",
            "Epoch 27/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3997 - accuracy: 0.8168 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8337 - recall: 0.9746 - precision: 0.7377\n",
            "Epoch 27: val_accuracy did not improve from 0.65547\n",
            "10/10 [==============================] - 2s 155ms/step - loss: 0.3997 - accuracy: 0.8168 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8337 - recall: 0.9746 - precision: 0.7377 - val_loss: 0.6511 - val_accuracy: 0.6086 - val_sensitivity_at_specificity: 0.5132 - val_specificity_at_sensitivity: 0.6472 - val_recall: 0.9907 - val_precision: 0.5635\n",
            "Epoch 28/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3991 - accuracy: 0.8199 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8485 - recall: 0.9869 - precision: 0.7419\n",
            "Epoch 28: val_accuracy did not improve from 0.65547\n",
            "10/10 [==============================] - 2s 155ms/step - loss: 0.3991 - accuracy: 0.8199 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8485 - recall: 0.9869 - precision: 0.7419 - val_loss: 0.6202 - val_accuracy: 0.6430 - val_sensitivity_at_specificity: 0.6822 - val_specificity_at_sensitivity: 0.6461 - val_recall: 0.9864 - val_precision: 0.5938\n",
            "Epoch 29/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4077 - accuracy: 0.8066 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.8265 - recall: 0.9711 - precision: 0.7250\n",
            "Epoch 29: val_accuracy improved from 0.65547 to 0.66094, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 157ms/step - loss: 0.4077 - accuracy: 0.8066 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.8265 - recall: 0.9711 - precision: 0.7250 - val_loss: 0.5954 - val_accuracy: 0.6609 - val_sensitivity_at_specificity: 0.7488 - val_specificity_at_sensitivity: 0.6976 - val_recall: 0.9597 - val_precision: 0.6027\n",
            "Epoch 30/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4102 - accuracy: 0.8137 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8282 - recall: 0.9743 - precision: 0.7382\n",
            "Epoch 30: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 153ms/step - loss: 0.4102 - accuracy: 0.8137 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8282 - recall: 0.9743 - precision: 0.7382 - val_loss: 0.6167 - val_accuracy: 0.6375 - val_sensitivity_at_specificity: 0.7206 - val_specificity_at_sensitivity: 0.6610 - val_recall: 0.9498 - val_precision: 0.5834\n",
            "Epoch 31/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3920 - accuracy: 0.8211 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8471 - recall: 0.9681 - precision: 0.7489\n",
            "Epoch 31: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 156ms/step - loss: 0.3920 - accuracy: 0.8211 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8471 - recall: 0.9681 - precision: 0.7489 - val_loss: 0.6260 - val_accuracy: 0.6414 - val_sensitivity_at_specificity: 0.7349 - val_specificity_at_sensitivity: 0.6378 - val_recall: 0.9690 - val_precision: 0.5874\n",
            "Epoch 32/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4003 - accuracy: 0.8203 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8393 - recall: 0.9654 - precision: 0.7559\n",
            "Epoch 32: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 155ms/step - loss: 0.4003 - accuracy: 0.8203 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8393 - recall: 0.9654 - precision: 0.7559 - val_loss: 0.6249 - val_accuracy: 0.6453 - val_sensitivity_at_specificity: 0.6962 - val_specificity_at_sensitivity: 0.6877 - val_recall: 0.9838 - val_precision: 0.6009\n",
            "Epoch 33/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3917 - accuracy: 0.8230 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8562 - recall: 0.9794 - precision: 0.7504\n",
            "Epoch 33: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 154ms/step - loss: 0.3917 - accuracy: 0.8230 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8562 - recall: 0.9794 - precision: 0.7504 - val_loss: 0.6691 - val_accuracy: 0.6000 - val_sensitivity_at_specificity: 0.6629 - val_specificity_at_sensitivity: 0.6499 - val_recall: 0.9856 - val_precision: 0.5497\n",
            "Epoch 34/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4104 - accuracy: 0.8051 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8394 - recall: 0.9791 - precision: 0.7280\n",
            "Epoch 34: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 153ms/step - loss: 0.4104 - accuracy: 0.8051 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8394 - recall: 0.9791 - precision: 0.7280 - val_loss: 0.6344 - val_accuracy: 0.6305 - val_sensitivity_at_specificity: 0.7023 - val_specificity_at_sensitivity: 0.7008 - val_recall: 0.9925 - val_precision: 0.5851\n",
            "Epoch 35/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3887 - accuracy: 0.8234 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8541 - recall: 0.9809 - precision: 0.7500\n",
            "Epoch 35: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 153ms/step - loss: 0.3887 - accuracy: 0.8234 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8541 - recall: 0.9809 - precision: 0.7500 - val_loss: 0.6359 - val_accuracy: 0.6391 - val_sensitivity_at_specificity: 0.7065 - val_specificity_at_sensitivity: 0.7060 - val_recall: 0.9939 - val_precision: 0.5892\n",
            "Epoch 36/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4073 - accuracy: 0.8105 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8463 - recall: 0.9772 - precision: 0.7316\n",
            "Epoch 36: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 155ms/step - loss: 0.4073 - accuracy: 0.8105 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8463 - recall: 0.9772 - precision: 0.7316 - val_loss: 0.6056 - val_accuracy: 0.6469 - val_sensitivity_at_specificity: 0.7512 - val_specificity_at_sensitivity: 0.7441 - val_recall: 0.9645 - val_precision: 0.5926\n",
            "Epoch 37/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4016 - accuracy: 0.8129 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.8699 - recall: 0.9764 - precision: 0.7340\n",
            "Epoch 37: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 153ms/step - loss: 0.4016 - accuracy: 0.8129 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.8699 - recall: 0.9764 - precision: 0.7340 - val_loss: 0.6173 - val_accuracy: 0.6320 - val_sensitivity_at_specificity: 0.7727 - val_specificity_at_sensitivity: 0.6589 - val_recall: 0.9702 - val_precision: 0.5780\n",
            "Epoch 38/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3992 - accuracy: 0.8129 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8509 - recall: 0.9750 - precision: 0.7361\n",
            "Epoch 38: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 157ms/step - loss: 0.3992 - accuracy: 0.8129 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8509 - recall: 0.9750 - precision: 0.7361 - val_loss: 0.6757 - val_accuracy: 0.6023 - val_sensitivity_at_specificity: 0.7116 - val_specificity_at_sensitivity: 0.7290 - val_recall: 1.0000 - val_precision: 0.5562\n",
            "Epoch 39/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4014 - accuracy: 0.8160 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8542 - recall: 0.9915 - precision: 0.7367\n",
            "Epoch 39: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 1s 151ms/step - loss: 0.4014 - accuracy: 0.8160 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8542 - recall: 0.9915 - precision: 0.7367 - val_loss: 0.6434 - val_accuracy: 0.6148 - val_sensitivity_at_specificity: 0.7442 - val_specificity_at_sensitivity: 0.7480 - val_recall: 0.9954 - val_precision: 0.5687\n",
            "Epoch 40/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4085 - accuracy: 0.8055 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8449 - recall: 0.9812 - precision: 0.7255\n",
            "Epoch 40: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 154ms/step - loss: 0.4085 - accuracy: 0.8055 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8449 - recall: 0.9812 - precision: 0.7255 - val_loss: 0.6829 - val_accuracy: 0.5836 - val_sensitivity_at_specificity: 0.7036 - val_specificity_at_sensitivity: 0.6952 - val_recall: 1.0000 - val_precision: 0.5353\n",
            "Epoch 41/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3996 - accuracy: 0.8135 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8714 - recall: 0.9823 - precision: 0.7315\n",
            "Epoch 41: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 1s 149ms/step - loss: 0.3996 - accuracy: 0.8135 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8714 - recall: 0.9823 - precision: 0.7315 - val_loss: 0.5985 - val_accuracy: 0.6523 - val_sensitivity_at_specificity: 0.8076 - val_specificity_at_sensitivity: 0.7910 - val_recall: 0.9890 - val_precision: 0.5887\n",
            "Epoch 42/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4199 - accuracy: 0.7998 - sensitivity_at_specificity: 0.9983 - specificity_at_sensitivity: 0.8554 - recall: 0.9716 - precision: 0.7221\n",
            "Epoch 42: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 1s 157ms/step - loss: 0.4199 - accuracy: 0.7998 - sensitivity_at_specificity: 0.9983 - specificity_at_sensitivity: 0.8554 - recall: 0.9716 - precision: 0.7221 - val_loss: 0.6251 - val_accuracy: 0.6125 - val_sensitivity_at_specificity: 0.7698 - val_specificity_at_sensitivity: 0.7938 - val_recall: 0.9952 - val_precision: 0.5598\n",
            "Epoch 43/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3906 - accuracy: 0.8164 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8586 - recall: 0.9806 - precision: 0.7393\n",
            "Epoch 43: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 156ms/step - loss: 0.3906 - accuracy: 0.8164 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8586 - recall: 0.9806 - precision: 0.7393 - val_loss: 0.6176 - val_accuracy: 0.6477 - val_sensitivity_at_specificity: 0.7756 - val_specificity_at_sensitivity: 0.7565 - val_recall: 0.9849 - val_precision: 0.5973\n",
            "Epoch 44/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3976 - accuracy: 0.8121 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8747 - recall: 0.9763 - precision: 0.7328\n",
            "Epoch 44: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 157ms/step - loss: 0.3976 - accuracy: 0.8121 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8747 - recall: 0.9763 - precision: 0.7328 - val_loss: 0.6348 - val_accuracy: 0.6281 - val_sensitivity_at_specificity: 0.7073 - val_specificity_at_sensitivity: 0.6771 - val_recall: 0.9941 - val_precision: 0.5863\n",
            "Epoch 45/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3879 - accuracy: 0.8242 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8657 - recall: 0.9768 - precision: 0.7506\n",
            "Epoch 45: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 154ms/step - loss: 0.3879 - accuracy: 0.8242 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8657 - recall: 0.9768 - precision: 0.7506 - val_loss: 0.6214 - val_accuracy: 0.6359 - val_sensitivity_at_specificity: 0.8021 - val_specificity_at_sensitivity: 0.7834 - val_recall: 0.9985 - val_precision: 0.5833\n",
            "Epoch 46/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4021 - accuracy: 0.8078 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.8819 - recall: 0.9783 - precision: 0.7312\n",
            "Epoch 46: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 155ms/step - loss: 0.4021 - accuracy: 0.8078 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.8819 - recall: 0.9783 - precision: 0.7312 - val_loss: 0.6457 - val_accuracy: 0.6055 - val_sensitivity_at_specificity: 0.7691 - val_specificity_at_sensitivity: 0.7209 - val_recall: 0.9936 - val_precision: 0.5547\n",
            "Epoch 47/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3880 - accuracy: 0.8215 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8771 - recall: 0.9796 - precision: 0.7509\n",
            "Epoch 47: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 157ms/step - loss: 0.3880 - accuracy: 0.8215 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8771 - recall: 0.9796 - precision: 0.7509 - val_loss: 0.6270 - val_accuracy: 0.6102 - val_sensitivity_at_specificity: 0.7765 - val_specificity_at_sensitivity: 0.7675 - val_recall: 0.9727 - val_precision: 0.5566\n",
            "Epoch 48/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3861 - accuracy: 0.8160 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8932 - recall: 0.9724 - precision: 0.7447\n",
            "Epoch 48: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 156ms/step - loss: 0.3861 - accuracy: 0.8160 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8932 - recall: 0.9724 - precision: 0.7447 - val_loss: 0.5887 - val_accuracy: 0.6477 - val_sensitivity_at_specificity: 0.8247 - val_specificity_at_sensitivity: 0.8019 - val_recall: 0.9703 - val_precision: 0.5894\n",
            "Epoch 49/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3947 - accuracy: 0.8117 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8923 - recall: 0.9748 - precision: 0.7394\n",
            "Epoch 49: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 156ms/step - loss: 0.3947 - accuracy: 0.8117 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8923 - recall: 0.9748 - precision: 0.7394 - val_loss: 0.6883 - val_accuracy: 0.6008 - val_sensitivity_at_specificity: 0.7388 - val_specificity_at_sensitivity: 0.7346 - val_recall: 0.9969 - val_precision: 0.5589\n",
            "Epoch 50/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3828 - accuracy: 0.8211 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8894 - recall: 0.9843 - precision: 0.7414\n",
            "Epoch 50: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 157ms/step - loss: 0.3828 - accuracy: 0.8211 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8894 - recall: 0.9843 - precision: 0.7414 - val_loss: 0.7166 - val_accuracy: 0.5641 - val_sensitivity_at_specificity: 0.7744 - val_specificity_at_sensitivity: 0.7259 - val_recall: 0.9966 - val_precision: 0.5157\n",
            "Epoch 51/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3797 - accuracy: 0.8227 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8878 - recall: 0.9798 - precision: 0.7463\n",
            "Epoch 51: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.3797 - accuracy: 0.8227 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8878 - recall: 0.9798 - precision: 0.7463 - val_loss: 0.7411 - val_accuracy: 0.5672 - val_sensitivity_at_specificity: 0.7555 - val_specificity_at_sensitivity: 0.7585 - val_recall: 1.0000 - val_precision: 0.5337\n",
            "Epoch 52/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4072 - accuracy: 0.8055 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.8679 - recall: 0.9777 - precision: 0.7235\n",
            "Epoch 52: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 156ms/step - loss: 0.4072 - accuracy: 0.8055 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.8679 - recall: 0.9777 - precision: 0.7235 - val_loss: 0.6674 - val_accuracy: 0.6031 - val_sensitivity_at_specificity: 0.7621 - val_specificity_at_sensitivity: 0.7316 - val_recall: 0.9907 - val_precision: 0.5593\n",
            "Epoch 53/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3683 - accuracy: 0.8258 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9095 - recall: 0.9771 - precision: 0.7550\n",
            "Epoch 53: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 156ms/step - loss: 0.3683 - accuracy: 0.8258 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9095 - recall: 0.9771 - precision: 0.7550 - val_loss: 0.7615 - val_accuracy: 0.5750 - val_sensitivity_at_specificity: 0.7684 - val_specificity_at_sensitivity: 0.7451 - val_recall: 0.9967 - val_precision: 0.5299\n",
            "Epoch 54/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3790 - accuracy: 0.8223 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8819 - recall: 0.9783 - precision: 0.7472\n",
            "Epoch 54: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.3790 - accuracy: 0.8223 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8819 - recall: 0.9783 - precision: 0.7472 - val_loss: 0.6252 - val_accuracy: 0.6148 - val_sensitivity_at_specificity: 0.8167 - val_specificity_at_sensitivity: 0.7508 - val_recall: 0.9855 - val_precision: 0.5588\n",
            "Epoch 55/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3798 - accuracy: 0.8106 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9169 - recall: 0.9765 - precision: 0.7312\n",
            "Epoch 55: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 1s 151ms/step - loss: 0.3798 - accuracy: 0.8106 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9169 - recall: 0.9765 - precision: 0.7312 - val_loss: 0.7002 - val_accuracy: 0.5922 - val_sensitivity_at_specificity: 0.7624 - val_specificity_at_sensitivity: 0.7752 - val_recall: 0.9984 - val_precision: 0.5524\n",
            "Epoch 56/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3717 - accuracy: 0.8289 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9010 - recall: 0.9801 - precision: 0.7529\n",
            "Epoch 56: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 155ms/step - loss: 0.3717 - accuracy: 0.8289 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9010 - recall: 0.9801 - precision: 0.7529 - val_loss: 0.6599 - val_accuracy: 0.5898 - val_sensitivity_at_specificity: 0.8251 - val_specificity_at_sensitivity: 0.8464 - val_recall: 0.9952 - val_precision: 0.5453\n",
            "Epoch 57/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3739 - accuracy: 0.8262 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9005 - recall: 0.9818 - precision: 0.7462\n",
            "Epoch 57: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.3739 - accuracy: 0.8262 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9005 - recall: 0.9818 - precision: 0.7462 - val_loss: 0.6346 - val_accuracy: 0.6047 - val_sensitivity_at_specificity: 0.8157 - val_specificity_at_sensitivity: 0.8109 - val_recall: 1.0000 - val_precision: 0.5565\n",
            "Epoch 58/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3855 - accuracy: 0.8148 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8853 - recall: 0.9850 - precision: 0.7333\n",
            "Epoch 58: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 156ms/step - loss: 0.3855 - accuracy: 0.8148 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8853 - recall: 0.9850 - precision: 0.7333 - val_loss: 0.5790 - val_accuracy: 0.6320 - val_sensitivity_at_specificity: 0.8678 - val_specificity_at_sensitivity: 0.8650 - val_recall: 0.9798 - val_precision: 0.5790\n",
            "Epoch 59/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3514 - accuracy: 0.8293 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9179 - recall: 0.9793 - precision: 0.7497\n",
            "Epoch 59: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.3514 - accuracy: 0.8293 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9179 - recall: 0.9793 - precision: 0.7497 - val_loss: 0.6692 - val_accuracy: 0.6094 - val_sensitivity_at_specificity: 0.8626 - val_specificity_at_sensitivity: 0.8083 - val_recall: 0.9968 - val_precision: 0.5589\n",
            "Epoch 60/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3655 - accuracy: 0.8242 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9219 - recall: 0.9838 - precision: 0.7478\n",
            "Epoch 60: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 156ms/step - loss: 0.3655 - accuracy: 0.8242 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9219 - recall: 0.9838 - precision: 0.7478 - val_loss: 0.5947 - val_accuracy: 0.6250 - val_sensitivity_at_specificity: 0.8785 - val_specificity_at_sensitivity: 0.8492 - val_recall: 0.9938 - val_precision: 0.5758\n",
            "Epoch 61/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4169 - accuracy: 0.7840 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8818 - recall: 0.9562 - precision: 0.7071\n",
            "Epoch 61: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 156ms/step - loss: 0.4169 - accuracy: 0.7840 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8818 - recall: 0.9562 - precision: 0.7071 - val_loss: 0.5913 - val_accuracy: 0.6289 - val_sensitivity_at_specificity: 0.8587 - val_specificity_at_sensitivity: 0.8251 - val_recall: 0.9985 - val_precision: 0.5783\n",
            "Epoch 62/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3774 - accuracy: 0.8211 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9076 - recall: 0.9854 - precision: 0.7454\n",
            "Epoch 62: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 154ms/step - loss: 0.3774 - accuracy: 0.8211 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9076 - recall: 0.9854 - precision: 0.7454 - val_loss: 0.5834 - val_accuracy: 0.6344 - val_sensitivity_at_specificity: 0.8783 - val_specificity_at_sensitivity: 0.8082 - val_recall: 0.9923 - val_precision: 0.5818\n",
            "Epoch 63/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.3807 - accuracy: 0.8242 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8856 - recall: 0.9899 - precision: 0.7490\n",
            "Epoch 63: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 153ms/step - loss: 0.3805 - accuracy: 0.8239 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8865 - recall: 0.9904 - precision: 0.7495 - val_loss: 0.6149 - val_accuracy: 0.6391 - val_sensitivity_at_specificity: 0.8416 - val_specificity_at_sensitivity: 0.7909 - val_recall: 0.9970 - val_precision: 0.5897\n",
            "Epoch 64/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3699 - accuracy: 0.8243 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9026 - recall: 0.9809 - precision: 0.7475\n",
            "Epoch 64: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 1s 150ms/step - loss: 0.3699 - accuracy: 0.8243 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9026 - recall: 0.9809 - precision: 0.7475 - val_loss: 0.6362 - val_accuracy: 0.6219 - val_sensitivity_at_specificity: 0.8550 - val_specificity_at_sensitivity: 0.8123 - val_recall: 1.0000 - val_precision: 0.5777\n",
            "Epoch 65/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3659 - accuracy: 0.8223 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9220 - recall: 0.9837 - precision: 0.7453\n",
            "Epoch 65: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 154ms/step - loss: 0.3659 - accuracy: 0.8223 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9220 - recall: 0.9837 - precision: 0.7453 - val_loss: 0.6090 - val_accuracy: 0.6156 - val_sensitivity_at_specificity: 0.8303 - val_specificity_at_sensitivity: 0.8179 - val_recall: 0.9954 - val_precision: 0.5711\n",
            "Epoch 66/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3866 - accuracy: 0.8051 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9025 - recall: 0.9703 - precision: 0.7290\n",
            "Epoch 66: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 154ms/step - loss: 0.3866 - accuracy: 0.8051 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9025 - recall: 0.9703 - precision: 0.7290 - val_loss: 0.6593 - val_accuracy: 0.5977 - val_sensitivity_at_specificity: 0.8355 - val_specificity_at_sensitivity: 0.8333 - val_recall: 0.9968 - val_precision: 0.5488\n",
            "Epoch 67/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3891 - accuracy: 0.8020 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9000 - recall: 0.9760 - precision: 0.7189\n",
            "Epoch 67: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 155ms/step - loss: 0.3891 - accuracy: 0.8020 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9000 - recall: 0.9760 - precision: 0.7189 - val_loss: 0.6747 - val_accuracy: 0.5688 - val_sensitivity_at_specificity: 0.8328 - val_specificity_at_sensitivity: 0.8055 - val_recall: 1.0000 - val_precision: 0.5298\n",
            "Epoch 68/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3815 - accuracy: 0.8062 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9010 - recall: 0.9791 - precision: 0.7221\n",
            "Epoch 68: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.3815 - accuracy: 0.8062 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9010 - recall: 0.9791 - precision: 0.7221 - val_loss: 0.6899 - val_accuracy: 0.5977 - val_sensitivity_at_specificity: 0.8272 - val_specificity_at_sensitivity: 0.7880 - val_recall: 0.9969 - val_precision: 0.5574\n",
            "Epoch 69/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3726 - accuracy: 0.8203 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9158 - recall: 0.9762 - precision: 0.7475\n",
            "Epoch 69: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 156ms/step - loss: 0.3726 - accuracy: 0.8203 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9158 - recall: 0.9762 - precision: 0.7475 - val_loss: 0.6873 - val_accuracy: 0.5938 - val_sensitivity_at_specificity: 0.7888 - val_specificity_at_sensitivity: 0.7910 - val_recall: 1.0000 - val_precision: 0.5586\n",
            "Epoch 70/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3776 - accuracy: 0.8180 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9089 - recall: 0.9892 - precision: 0.7395\n",
            "Epoch 70: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 157ms/step - loss: 0.3776 - accuracy: 0.8180 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9089 - recall: 0.9892 - precision: 0.7395 - val_loss: 0.6147 - val_accuracy: 0.6297 - val_sensitivity_at_specificity: 0.8595 - val_specificity_at_sensitivity: 0.8112 - val_recall: 0.9969 - val_precision: 0.5804\n",
            "Epoch 71/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3573 - accuracy: 0.8230 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9347 - recall: 0.9822 - precision: 0.7465\n",
            "Epoch 71: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 156ms/step - loss: 0.3573 - accuracy: 0.8230 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9347 - recall: 0.9822 - precision: 0.7465 - val_loss: 0.5659 - val_accuracy: 0.6555 - val_sensitivity_at_specificity: 0.8703 - val_specificity_at_sensitivity: 0.8379 - val_recall: 0.9804 - val_precision: 0.6030\n",
            "Epoch 72/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3619 - accuracy: 0.8238 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9233 - recall: 0.9815 - precision: 0.7487\n",
            "Epoch 72: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 155ms/step - loss: 0.3619 - accuracy: 0.8238 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9233 - recall: 0.9815 - precision: 0.7487 - val_loss: 0.6249 - val_accuracy: 0.6047 - val_sensitivity_at_specificity: 0.8604 - val_specificity_at_sensitivity: 0.8052 - val_recall: 1.0000 - val_precision: 0.5518\n",
            "Epoch 73/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3712 - accuracy: 0.8184 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9149 - recall: 0.9953 - precision: 0.7333\n",
            "Epoch 73: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 156ms/step - loss: 0.3712 - accuracy: 0.8184 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9149 - recall: 0.9953 - precision: 0.7333 - val_loss: 0.5987 - val_accuracy: 0.6203 - val_sensitivity_at_specificity: 0.8804 - val_specificity_at_sensitivity: 0.8439 - val_recall: 0.9985 - val_precision: 0.5731\n",
            "Epoch 74/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3601 - accuracy: 0.8258 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9116 - recall: 0.9862 - precision: 0.7503\n",
            "Epoch 74: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 156ms/step - loss: 0.3601 - accuracy: 0.8258 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9116 - recall: 0.9862 - precision: 0.7503 - val_loss: 0.6539 - val_accuracy: 0.6031 - val_sensitivity_at_specificity: 0.8136 - val_specificity_at_sensitivity: 0.8130 - val_recall: 0.9938 - val_precision: 0.5614\n",
            "Epoch 75/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3668 - accuracy: 0.8172 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9359 - recall: 0.9907 - precision: 0.7381\n",
            "Epoch 75: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 157ms/step - loss: 0.3668 - accuracy: 0.8172 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9359 - recall: 0.9907 - precision: 0.7381 - val_loss: 0.6088 - val_accuracy: 0.6086 - val_sensitivity_at_specificity: 0.8959 - val_specificity_at_sensitivity: 0.8256 - val_recall: 0.9951 - val_precision: 0.5514\n",
            "Epoch 76/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3663 - accuracy: 0.8246 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9047 - recall: 0.9898 - precision: 0.7440\n",
            "Epoch 76: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 156ms/step - loss: 0.3663 - accuracy: 0.8246 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9047 - recall: 0.9898 - precision: 0.7440 - val_loss: 0.6209 - val_accuracy: 0.6164 - val_sensitivity_at_specificity: 0.8542 - val_specificity_at_sensitivity: 0.8197 - val_recall: 0.9984 - val_precision: 0.5625\n",
            "Epoch 77/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3634 - accuracy: 0.8281 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9129 - recall: 0.9870 - precision: 0.7534\n",
            "Epoch 77: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 153ms/step - loss: 0.3634 - accuracy: 0.8281 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9129 - recall: 0.9870 - precision: 0.7534 - val_loss: 0.6399 - val_accuracy: 0.5992 - val_sensitivity_at_specificity: 0.8148 - val_specificity_at_sensitivity: 0.7900 - val_recall: 0.9984 - val_precision: 0.5540\n",
            "Epoch 78/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3753 - accuracy: 0.8062 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9233 - recall: 0.9929 - precision: 0.7214\n",
            "Epoch 78: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 153ms/step - loss: 0.3753 - accuracy: 0.8062 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9233 - recall: 0.9929 - precision: 0.7214 - val_loss: 0.6078 - val_accuracy: 0.6234 - val_sensitivity_at_specificity: 0.8748 - val_specificity_at_sensitivity: 0.8378 - val_recall: 0.9937 - val_precision: 0.5705\n",
            "Epoch 79/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3694 - accuracy: 0.8172 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9095 - recall: 0.9705 - precision: 0.7442\n",
            "Epoch 79: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.3694 - accuracy: 0.8172 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9095 - recall: 0.9705 - precision: 0.7442 - val_loss: 0.5552 - val_accuracy: 0.6531 - val_sensitivity_at_specificity: 0.8840 - val_specificity_at_sensitivity: 0.8629 - val_recall: 0.9812 - val_precision: 0.5917\n",
            "Epoch 80/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3691 - accuracy: 0.8180 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9139 - recall: 0.9807 - precision: 0.7421\n",
            "Epoch 80: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 157ms/step - loss: 0.3691 - accuracy: 0.8180 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9139 - recall: 0.9807 - precision: 0.7421 - val_loss: 0.5937 - val_accuracy: 0.6234 - val_sensitivity_at_specificity: 0.8515 - val_specificity_at_sensitivity: 0.8331 - val_recall: 0.9953 - val_precision: 0.5681\n",
            "Epoch 81/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3584 - accuracy: 0.8277 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9100 - recall: 0.9907 - precision: 0.7493\n",
            "Epoch 81: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 157ms/step - loss: 0.3584 - accuracy: 0.8277 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9100 - recall: 0.9907 - precision: 0.7493 - val_loss: 0.6119 - val_accuracy: 0.6234 - val_sensitivity_at_specificity: 0.8831 - val_specificity_at_sensitivity: 0.8192 - val_recall: 0.9953 - val_precision: 0.5681\n",
            "Epoch 82/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3606 - accuracy: 0.8387 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9097 - recall: 0.9908 - precision: 0.7637\n",
            "Epoch 82: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 156ms/step - loss: 0.3606 - accuracy: 0.8387 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9097 - recall: 0.9908 - precision: 0.7637 - val_loss: 0.6158 - val_accuracy: 0.6336 - val_sensitivity_at_specificity: 0.8769 - val_specificity_at_sensitivity: 0.8399 - val_recall: 0.9970 - val_precision: 0.5900\n",
            "Epoch 83/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3709 - accuracy: 0.8211 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9064 - recall: 0.9878 - precision: 0.7454\n",
            "Epoch 83: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 155ms/step - loss: 0.3709 - accuracy: 0.8211 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9064 - recall: 0.9878 - precision: 0.7454 - val_loss: 0.5953 - val_accuracy: 0.6047 - val_sensitivity_at_specificity: 0.9227 - val_specificity_at_sensitivity: 0.8527 - val_recall: 0.9951 - val_precision: 0.5460\n",
            "Epoch 84/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3595 - accuracy: 0.8195 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9146 - recall: 0.9788 - precision: 0.7333\n",
            "Epoch 84: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 157ms/step - loss: 0.3595 - accuracy: 0.8195 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9146 - recall: 0.9788 - precision: 0.7333 - val_loss: 0.6213 - val_accuracy: 0.6125 - val_sensitivity_at_specificity: 0.8825 - val_specificity_at_sensitivity: 0.8123 - val_recall: 0.9968 - val_precision: 0.5597\n",
            "Epoch 85/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3587 - accuracy: 0.8273 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9243 - recall: 0.9917 - precision: 0.7522\n",
            "Epoch 85: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 157ms/step - loss: 0.3587 - accuracy: 0.8273 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9243 - recall: 0.9917 - precision: 0.7522 - val_loss: 0.5685 - val_accuracy: 0.6547 - val_sensitivity_at_specificity: 0.8964 - val_specificity_at_sensitivity: 0.8355 - val_recall: 0.9895 - val_precision: 0.6024\n",
            "Epoch 86/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3721 - accuracy: 0.8211 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9126 - recall: 0.9742 - precision: 0.7457\n",
            "Epoch 86: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 156ms/step - loss: 0.3721 - accuracy: 0.8211 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9126 - recall: 0.9742 - precision: 0.7457 - val_loss: 0.5925 - val_accuracy: 0.6070 - val_sensitivity_at_specificity: 0.8852 - val_specificity_at_sensitivity: 0.8484 - val_recall: 0.9904 - val_precision: 0.5555\n",
            "Epoch 87/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3594 - accuracy: 0.8199 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9247 - recall: 0.9860 - precision: 0.7409\n",
            "Epoch 87: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 155ms/step - loss: 0.3594 - accuracy: 0.8199 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9247 - recall: 0.9860 - precision: 0.7409 - val_loss: 0.6598 - val_accuracy: 0.6094 - val_sensitivity_at_specificity: 0.8892 - val_specificity_at_sensitivity: 0.8204 - val_recall: 0.9936 - val_precision: 0.5552\n",
            "Epoch 88/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3547 - accuracy: 0.8227 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9301 - recall: 0.9827 - precision: 0.7433\n",
            "Epoch 88: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.3547 - accuracy: 0.8227 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9301 - recall: 0.9827 - precision: 0.7433 - val_loss: 0.6483 - val_accuracy: 0.6133 - val_sensitivity_at_specificity: 0.8586 - val_specificity_at_sensitivity: 0.8109 - val_recall: 0.9955 - val_precision: 0.5762\n",
            "Epoch 89/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3676 - accuracy: 0.8152 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9177 - recall: 0.9776 - precision: 0.7405\n",
            "Epoch 89: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.3676 - accuracy: 0.8152 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9177 - recall: 0.9776 - precision: 0.7405 - val_loss: 0.6860 - val_accuracy: 0.5938 - val_sensitivity_at_specificity: 0.8237 - val_specificity_at_sensitivity: 0.7559 - val_recall: 0.9938 - val_precision: 0.5525\n",
            "Epoch 90/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3633 - accuracy: 0.8238 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9222 - recall: 0.9767 - precision: 0.7493\n",
            "Epoch 90: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.3633 - accuracy: 0.8238 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9222 - recall: 0.9767 - precision: 0.7493 - val_loss: 0.6525 - val_accuracy: 0.6070 - val_sensitivity_at_specificity: 0.8558 - val_specificity_at_sensitivity: 0.8259 - val_recall: 0.9984 - val_precision: 0.5565\n",
            "Epoch 91/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3716 - accuracy: 0.8137 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9138 - recall: 0.9784 - precision: 0.7383\n",
            "Epoch 91: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 156ms/step - loss: 0.3716 - accuracy: 0.8137 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9138 - recall: 0.9784 - precision: 0.7383 - val_loss: 0.6131 - val_accuracy: 0.6086 - val_sensitivity_at_specificity: 0.8493 - val_specificity_at_sensitivity: 0.8103 - val_recall: 0.9859 - val_precision: 0.5607\n",
            "Epoch 92/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3458 - accuracy: 0.8331 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9338 - recall: 0.9650 - precision: 0.7628\n",
            "Epoch 92: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 1s 150ms/step - loss: 0.3458 - accuracy: 0.8331 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9338 - recall: 0.9650 - precision: 0.7628 - val_loss: 0.6311 - val_accuracy: 0.6320 - val_sensitivity_at_specificity: 0.8926 - val_specificity_at_sensitivity: 0.8415 - val_recall: 0.9776 - val_precision: 0.5717\n",
            "Epoch 93/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3500 - accuracy: 0.8336 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9139 - recall: 0.9706 - precision: 0.7640\n",
            "Epoch 93: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.3500 - accuracy: 0.8336 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9139 - recall: 0.9706 - precision: 0.7640 - val_loss: 0.6263 - val_accuracy: 0.6094 - val_sensitivity_at_specificity: 0.8470 - val_specificity_at_sensitivity: 0.8120 - val_recall: 0.9985 - val_precision: 0.5642\n",
            "Epoch 94/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3536 - accuracy: 0.8242 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9282 - recall: 0.9890 - precision: 0.7435\n",
            "Epoch 94: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.3536 - accuracy: 0.8242 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9282 - recall: 0.9890 - precision: 0.7435 - val_loss: 0.5840 - val_accuracy: 0.6266 - val_sensitivity_at_specificity: 0.8927 - val_specificity_at_sensitivity: 0.8375 - val_recall: 0.9937 - val_precision: 0.5707\n",
            "Epoch 95/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3571 - accuracy: 0.8202 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9301 - recall: 0.9803 - precision: 0.7453\n",
            "Epoch 95: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 153ms/step - loss: 0.3571 - accuracy: 0.8202 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9301 - recall: 0.9803 - precision: 0.7453 - val_loss: 0.6425 - val_accuracy: 0.6078 - val_sensitivity_at_specificity: 0.8454 - val_specificity_at_sensitivity: 0.7910 - val_recall: 0.9968 - val_precision: 0.5583\n",
            "Epoch 96/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3616 - accuracy: 0.8141 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9249 - recall: 0.9882 - precision: 0.7312\n",
            "Epoch 96: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.3616 - accuracy: 0.8141 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9249 - recall: 0.9882 - precision: 0.7312 - val_loss: 0.5691 - val_accuracy: 0.6359 - val_sensitivity_at_specificity: 0.8899 - val_specificity_at_sensitivity: 0.8525 - val_recall: 0.9940 - val_precision: 0.5879\n",
            "Epoch 97/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3343 - accuracy: 0.8340 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9424 - recall: 0.9914 - precision: 0.7533\n",
            "Epoch 97: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 176ms/step - loss: 0.3343 - accuracy: 0.8340 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9424 - recall: 0.9914 - precision: 0.7533 - val_loss: 0.5784 - val_accuracy: 0.6320 - val_sensitivity_at_specificity: 0.8581 - val_specificity_at_sensitivity: 0.8499 - val_recall: 0.9888 - val_precision: 0.5720\n",
            "Epoch 98/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3401 - accuracy: 0.8316 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9458 - recall: 0.9824 - precision: 0.7587\n",
            "Epoch 98: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.3401 - accuracy: 0.8316 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9458 - recall: 0.9824 - precision: 0.7587 - val_loss: 0.6378 - val_accuracy: 0.6164 - val_sensitivity_at_specificity: 0.8805 - val_specificity_at_sensitivity: 0.8183 - val_recall: 0.9890 - val_precision: 0.5651\n",
            "Epoch 99/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3544 - accuracy: 0.8258 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9197 - recall: 0.9853 - precision: 0.7485\n",
            "Epoch 99: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 157ms/step - loss: 0.3544 - accuracy: 0.8258 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9197 - recall: 0.9853 - precision: 0.7485 - val_loss: 0.6423 - val_accuracy: 0.6086 - val_sensitivity_at_specificity: 0.8464 - val_specificity_at_sensitivity: 0.8115 - val_recall: 1.0000 - val_precision: 0.5601\n",
            "Epoch 100/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3721 - accuracy: 0.8156 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9154 - recall: 0.9871 - precision: 0.7410\n",
            "Epoch 100: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.3721 - accuracy: 0.8156 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9154 - recall: 0.9871 - precision: 0.7410 - val_loss: 0.6129 - val_accuracy: 0.6227 - val_sensitivity_at_specificity: 0.8636 - val_specificity_at_sensitivity: 0.8032 - val_recall: 0.9970 - val_precision: 0.5777\n",
            "Epoch 101/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3594 - accuracy: 0.8195 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9290 - recall: 0.9907 - precision: 0.7399\n",
            "Epoch 101: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.3594 - accuracy: 0.8195 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9290 - recall: 0.9907 - precision: 0.7399 - val_loss: 0.5996 - val_accuracy: 0.6203 - val_sensitivity_at_specificity: 0.8896 - val_specificity_at_sensitivity: 0.8153 - val_recall: 0.9952 - val_precision: 0.5629\n",
            "Epoch 102/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3421 - accuracy: 0.8352 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9349 - recall: 0.9785 - precision: 0.7565\n",
            "Epoch 102: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.3421 - accuracy: 0.8352 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9349 - recall: 0.9785 - precision: 0.7565 - val_loss: 0.5909 - val_accuracy: 0.6250 - val_sensitivity_at_specificity: 0.8958 - val_specificity_at_sensitivity: 0.8415 - val_recall: 0.9952 - val_precision: 0.5656\n",
            "Epoch 103/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3582 - accuracy: 0.8223 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9263 - recall: 0.9914 - precision: 0.7414\n",
            "Epoch 103: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.3582 - accuracy: 0.8223 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9263 - recall: 0.9914 - precision: 0.7414 - val_loss: 0.6282 - val_accuracy: 0.6047 - val_sensitivity_at_specificity: 0.8631 - val_specificity_at_sensitivity: 0.7912 - val_recall: 1.0000 - val_precision: 0.5596\n",
            "Epoch 104/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3562 - accuracy: 0.8219 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9307 - recall: 0.9890 - precision: 0.7406\n",
            "Epoch 104: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.3562 - accuracy: 0.8219 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9307 - recall: 0.9890 - precision: 0.7406 - val_loss: 0.6116 - val_accuracy: 0.6094 - val_sensitivity_at_specificity: 0.8648 - val_specificity_at_sensitivity: 0.8453 - val_recall: 0.9886 - val_precision: 0.5518\n",
            "Epoch 105/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3477 - accuracy: 0.8270 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9361 - recall: 0.9812 - precision: 0.7493\n",
            "Epoch 105: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.3477 - accuracy: 0.8270 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9361 - recall: 0.9812 - precision: 0.7493 - val_loss: 0.6767 - val_accuracy: 0.5711 - val_sensitivity_at_specificity: 0.8299 - val_specificity_at_sensitivity: 0.8158 - val_recall: 1.0000 - val_precision: 0.5316\n",
            "Epoch 106/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3622 - accuracy: 0.8137 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9299 - recall: 0.9865 - precision: 0.7300\n",
            "Epoch 106: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 157ms/step - loss: 0.3622 - accuracy: 0.8137 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9299 - recall: 0.9865 - precision: 0.7300 - val_loss: 0.6082 - val_accuracy: 0.6219 - val_sensitivity_at_specificity: 0.8716 - val_specificity_at_sensitivity: 0.8417 - val_recall: 0.9839 - val_precision: 0.5639\n",
            "Epoch 107/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3707 - accuracy: 0.8012 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9320 - recall: 0.9897 - precision: 0.7162\n",
            "Epoch 107: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.3707 - accuracy: 0.8012 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9320 - recall: 0.9897 - precision: 0.7162 - val_loss: 0.6098 - val_accuracy: 0.6062 - val_sensitivity_at_specificity: 0.8574 - val_specificity_at_sensitivity: 0.8193 - val_recall: 0.9953 - val_precision: 0.5590\n",
            "Epoch 108/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.3598 - accuracy: 0.8212 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9215 - recall: 0.9853 - precision: 0.7428\n",
            "Epoch 108: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 154ms/step - loss: 0.3593 - accuracy: 0.8210 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9233 - recall: 0.9851 - precision: 0.7425 - val_loss: 0.6016 - val_accuracy: 0.6250 - val_sensitivity_at_specificity: 0.8828 - val_specificity_at_sensitivity: 0.8328 - val_recall: 0.9969 - val_precision: 0.5717\n",
            "Epoch 109/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3552 - accuracy: 0.8273 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9255 - recall: 0.9953 - precision: 0.7456\n",
            "Epoch 109: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.3552 - accuracy: 0.8273 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9255 - recall: 0.9953 - precision: 0.7456 - val_loss: 0.5950 - val_accuracy: 0.6453 - val_sensitivity_at_specificity: 0.8853 - val_specificity_at_sensitivity: 0.8482 - val_recall: 1.0000 - val_precision: 0.5903\n",
            "Epoch 110/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3589 - accuracy: 0.8188 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9290 - recall: 0.9799 - precision: 0.7430\n",
            "Epoch 110: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.3589 - accuracy: 0.8188 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9290 - recall: 0.9799 - precision: 0.7430 - val_loss: 0.6572 - val_accuracy: 0.6008 - val_sensitivity_at_specificity: 0.8680 - val_specificity_at_sensitivity: 0.8240 - val_recall: 0.9984 - val_precision: 0.5487\n",
            "Epoch 111/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3534 - accuracy: 0.8137 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9385 - recall: 0.9922 - precision: 0.7305\n",
            "Epoch 111: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 157ms/step - loss: 0.3534 - accuracy: 0.8137 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9385 - recall: 0.9922 - precision: 0.7305 - val_loss: 0.6147 - val_accuracy: 0.6359 - val_sensitivity_at_specificity: 0.8593 - val_specificity_at_sensitivity: 0.8450 - val_recall: 1.0000 - val_precision: 0.5839\n",
            "Epoch 112/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3517 - accuracy: 0.8270 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9236 - recall: 0.9897 - precision: 0.7442\n",
            "Epoch 112: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.3517 - accuracy: 0.8270 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9236 - recall: 0.9897 - precision: 0.7442 - val_loss: 0.6391 - val_accuracy: 0.6070 - val_sensitivity_at_specificity: 0.8718 - val_specificity_at_sensitivity: 0.8241 - val_recall: 0.9968 - val_precision: 0.5570\n",
            "Epoch 113/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3530 - accuracy: 0.8168 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9380 - recall: 0.9882 - precision: 0.7342\n",
            "Epoch 113: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 157ms/step - loss: 0.3530 - accuracy: 0.8168 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9380 - recall: 0.9882 - precision: 0.7342 - val_loss: 0.5802 - val_accuracy: 0.6297 - val_sensitivity_at_specificity: 0.8875 - val_specificity_at_sensitivity: 0.8663 - val_recall: 0.9855 - val_precision: 0.5686\n",
            "Epoch 114/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3579 - accuracy: 0.8141 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9205 - recall: 0.9850 - precision: 0.7317\n",
            "Epoch 114: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 157ms/step - loss: 0.3579 - accuracy: 0.8141 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9205 - recall: 0.9850 - precision: 0.7317 - val_loss: 0.6335 - val_accuracy: 0.6031 - val_sensitivity_at_specificity: 0.8822 - val_specificity_at_sensitivity: 0.8344 - val_recall: 0.9984 - val_precision: 0.5529\n",
            "Epoch 115/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3415 - accuracy: 0.8250 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9421 - recall: 0.9913 - precision: 0.7416\n",
            "Epoch 115: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 157ms/step - loss: 0.3415 - accuracy: 0.8250 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9421 - recall: 0.9913 - precision: 0.7416 - val_loss: 0.6337 - val_accuracy: 0.6250 - val_sensitivity_at_specificity: 0.8807 - val_specificity_at_sensitivity: 0.8403 - val_recall: 1.0000 - val_precision: 0.5767\n",
            "Epoch 116/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3523 - accuracy: 0.8223 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9366 - recall: 0.9977 - precision: 0.7436\n",
            "Epoch 116: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.3523 - accuracy: 0.8223 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9366 - recall: 0.9977 - precision: 0.7436 - val_loss: 0.5770 - val_accuracy: 0.6258 - val_sensitivity_at_specificity: 0.9048 - val_specificity_at_sensitivity: 0.8815 - val_recall: 0.9905 - val_precision: 0.5688\n",
            "Epoch 117/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3405 - accuracy: 0.8293 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9429 - recall: 0.9846 - precision: 0.7541\n",
            "Epoch 117: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.3405 - accuracy: 0.8293 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9429 - recall: 0.9846 - precision: 0.7541 - val_loss: 0.7138 - val_accuracy: 0.5883 - val_sensitivity_at_specificity: 0.8418 - val_specificity_at_sensitivity: 0.8362 - val_recall: 0.9985 - val_precision: 0.5527\n",
            "Epoch 118/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3344 - accuracy: 0.8336 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9397 - recall: 0.9867 - precision: 0.7557\n",
            "Epoch 118: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.3344 - accuracy: 0.8336 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9397 - recall: 0.9867 - precision: 0.7557 - val_loss: 0.7778 - val_accuracy: 0.5578 - val_sensitivity_at_specificity: 0.8504 - val_specificity_at_sensitivity: 0.8150 - val_recall: 0.9935 - val_precision: 0.5209\n",
            "Epoch 119/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3494 - accuracy: 0.8305 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9327 - recall: 0.9764 - precision: 0.7605\n",
            "Epoch 119: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.3494 - accuracy: 0.8305 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9327 - recall: 0.9764 - precision: 0.7605 - val_loss: 0.7631 - val_accuracy: 0.5891 - val_sensitivity_at_specificity: 0.8467 - val_specificity_at_sensitivity: 0.7729 - val_recall: 1.0000 - val_precision: 0.5512\n",
            "Epoch 120/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3776 - accuracy: 0.8098 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9272 - recall: 0.9834 - precision: 0.7280\n",
            "Epoch 120: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.3776 - accuracy: 0.8098 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9272 - recall: 0.9834 - precision: 0.7280 - val_loss: 0.5917 - val_accuracy: 0.6195 - val_sensitivity_at_specificity: 0.8782 - val_specificity_at_sensitivity: 0.8459 - val_recall: 0.9985 - val_precision: 0.5744\n",
            "Epoch 121/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3659 - accuracy: 0.8137 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9198 - recall: 0.9747 - precision: 0.7282\n",
            "Epoch 121: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.3659 - accuracy: 0.8137 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9198 - recall: 0.9747 - precision: 0.7282 - val_loss: 0.6490 - val_accuracy: 0.5820 - val_sensitivity_at_specificity: 0.8502 - val_specificity_at_sensitivity: 0.7887 - val_recall: 0.9984 - val_precision: 0.5451\n",
            "Epoch 122/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3684 - accuracy: 0.8160 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9229 - recall: 0.9937 - precision: 0.7305\n",
            "Epoch 122: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.3684 - accuracy: 0.8160 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9229 - recall: 0.9937 - precision: 0.7305 - val_loss: 0.6412 - val_accuracy: 0.6055 - val_sensitivity_at_specificity: 0.8456 - val_specificity_at_sensitivity: 0.7981 - val_recall: 0.9938 - val_precision: 0.5598\n",
            "Epoch 123/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3523 - accuracy: 0.8203 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9377 - recall: 0.9837 - precision: 0.7431\n",
            "Epoch 123: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.3523 - accuracy: 0.8203 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9377 - recall: 0.9837 - precision: 0.7431 - val_loss: 0.6107 - val_accuracy: 0.6250 - val_sensitivity_at_specificity: 0.8972 - val_specificity_at_sensitivity: 0.8296 - val_recall: 0.9831 - val_precision: 0.5775\n",
            "Epoch 124/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3436 - accuracy: 0.8258 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9314 - recall: 0.9718 - precision: 0.7517\n",
            "Epoch 124: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.3436 - accuracy: 0.8258 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9314 - recall: 0.9718 - precision: 0.7517 - val_loss: 0.6423 - val_accuracy: 0.6187 - val_sensitivity_at_specificity: 0.8820 - val_specificity_at_sensitivity: 0.8506 - val_recall: 0.9907 - val_precision: 0.5696\n",
            "Epoch 125/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3381 - accuracy: 0.8238 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9513 - recall: 0.9806 - precision: 0.7476\n",
            "Epoch 125: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 155ms/step - loss: 0.3381 - accuracy: 0.8238 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9513 - recall: 0.9806 - precision: 0.7476 - val_loss: 0.6430 - val_accuracy: 0.6180 - val_sensitivity_at_specificity: 0.8645 - val_specificity_at_sensitivity: 0.8386 - val_recall: 0.9938 - val_precision: 0.5681\n",
            "Epoch 126/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3583 - accuracy: 0.8160 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9331 - recall: 0.9783 - precision: 0.7400\n",
            "Epoch 126: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.3583 - accuracy: 0.8160 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9331 - recall: 0.9783 - precision: 0.7400 - val_loss: 0.6550 - val_accuracy: 0.5789 - val_sensitivity_at_specificity: 0.8778 - val_specificity_at_sensitivity: 0.8462 - val_recall: 1.0000 - val_precision: 0.5389\n",
            "Epoch 127/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3550 - accuracy: 0.8176 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9222 - recall: 0.9744 - precision: 0.7429\n",
            "Epoch 127: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 157ms/step - loss: 0.3550 - accuracy: 0.8176 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9222 - recall: 0.9744 - precision: 0.7429 - val_loss: 0.5870 - val_accuracy: 0.6430 - val_sensitivity_at_specificity: 0.9027 - val_specificity_at_sensitivity: 0.8569 - val_recall: 0.9863 - val_precision: 0.5916\n",
            "Epoch 128/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3393 - accuracy: 0.8281 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9441 - recall: 0.9748 - precision: 0.7524\n",
            "Epoch 128: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.3393 - accuracy: 0.8281 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9441 - recall: 0.9748 - precision: 0.7524 - val_loss: 0.7224 - val_accuracy: 0.6102 - val_sensitivity_at_specificity: 0.8508 - val_specificity_at_sensitivity: 0.7785 - val_recall: 0.9893 - val_precision: 0.5692\n",
            "Epoch 129/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3524 - accuracy: 0.8242 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9259 - recall: 0.9621 - precision: 0.7561\n",
            "Epoch 129: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.3524 - accuracy: 0.8242 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9259 - recall: 0.9621 - precision: 0.7561 - val_loss: 0.6892 - val_accuracy: 0.6008 - val_sensitivity_at_specificity: 0.8465 - val_specificity_at_sensitivity: 0.8185 - val_recall: 0.9952 - val_precision: 0.5480\n",
            "Epoch 130/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3435 - accuracy: 0.8289 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9425 - recall: 0.9679 - precision: 0.7616\n",
            "Epoch 130: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.3435 - accuracy: 0.8289 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9425 - recall: 0.9679 - precision: 0.7616 - val_loss: 0.6988 - val_accuracy: 0.5758 - val_sensitivity_at_specificity: 0.8434 - val_specificity_at_sensitivity: 0.8205 - val_recall: 1.0000 - val_precision: 0.5429\n",
            "Epoch 131/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3489 - accuracy: 0.8168 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9435 - recall: 0.9743 - precision: 0.7417\n",
            "Epoch 131: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.3489 - accuracy: 0.8168 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9435 - recall: 0.9743 - precision: 0.7417 - val_loss: 0.6320 - val_accuracy: 0.6359 - val_sensitivity_at_specificity: 0.8882 - val_specificity_at_sensitivity: 0.8382 - val_recall: 0.9834 - val_precision: 0.5886\n",
            "Epoch 132/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3496 - accuracy: 0.8238 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9371 - recall: 0.9827 - precision: 0.7446\n",
            "Epoch 132: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 157ms/step - loss: 0.3496 - accuracy: 0.8238 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9371 - recall: 0.9827 - precision: 0.7446 - val_loss: 0.5971 - val_accuracy: 0.6313 - val_sensitivity_at_specificity: 0.8831 - val_specificity_at_sensitivity: 0.8303 - val_recall: 0.9895 - val_precision: 0.5867\n",
            "Epoch 133/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3639 - accuracy: 0.8137 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9239 - recall: 0.9821 - precision: 0.7354\n",
            "Epoch 133: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 156ms/step - loss: 0.3639 - accuracy: 0.8137 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9239 - recall: 0.9821 - precision: 0.7354 - val_loss: 0.6165 - val_accuracy: 0.6125 - val_sensitivity_at_specificity: 0.8876 - val_specificity_at_sensitivity: 0.8333 - val_recall: 0.9919 - val_precision: 0.5536\n",
            "Epoch 134/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3421 - accuracy: 0.8250 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9467 - recall: 0.9844 - precision: 0.7470\n",
            "Epoch 134: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.3421 - accuracy: 0.8250 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9467 - recall: 0.9844 - precision: 0.7470 - val_loss: 0.6677 - val_accuracy: 0.6187 - val_sensitivity_at_specificity: 0.8673 - val_specificity_at_sensitivity: 0.8418 - val_recall: 0.9938 - val_precision: 0.5709\n",
            "Epoch 135/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3552 - accuracy: 0.8188 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9275 - recall: 0.9792 - precision: 0.7365\n",
            "Epoch 135: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.3552 - accuracy: 0.8188 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9275 - recall: 0.9792 - precision: 0.7365 - val_loss: 0.6866 - val_accuracy: 0.6195 - val_sensitivity_at_specificity: 0.8671 - val_specificity_at_sensitivity: 0.8041 - val_recall: 0.9954 - val_precision: 0.5709\n",
            "Epoch 136/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3567 - accuracy: 0.8145 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9302 - recall: 0.9751 - precision: 0.7388\n",
            "Epoch 136: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.3567 - accuracy: 0.8145 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9302 - recall: 0.9751 - precision: 0.7388 - val_loss: 0.6958 - val_accuracy: 0.5867 - val_sensitivity_at_specificity: 0.8504 - val_specificity_at_sensitivity: 0.8016 - val_recall: 1.0000 - val_precision: 0.5455\n",
            "Epoch 137/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3447 - accuracy: 0.8254 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9333 - recall: 0.9850 - precision: 0.7451\n",
            "Epoch 137: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.3447 - accuracy: 0.8254 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9333 - recall: 0.9850 - precision: 0.7451 - val_loss: 0.6257 - val_accuracy: 0.6203 - val_sensitivity_at_specificity: 0.8519 - val_specificity_at_sensitivity: 0.8256 - val_recall: 0.9985 - val_precision: 0.5742\n",
            "Epoch 138/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3421 - accuracy: 0.8199 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9546 - recall: 0.9849 - precision: 0.7375\n",
            "Epoch 138: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 157ms/step - loss: 0.3421 - accuracy: 0.8199 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9546 - recall: 0.9849 - precision: 0.7375 - val_loss: 0.6662 - val_accuracy: 0.5891 - val_sensitivity_at_specificity: 0.8608 - val_specificity_at_sensitivity: 0.8302 - val_recall: 1.0000 - val_precision: 0.5458\n",
            "Epoch 139/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3326 - accuracy: 0.8352 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9519 - recall: 0.9772 - precision: 0.7660\n",
            "Epoch 139: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.3326 - accuracy: 0.8352 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9519 - recall: 0.9772 - precision: 0.7660 - val_loss: 0.6607 - val_accuracy: 0.6055 - val_sensitivity_at_specificity: 0.8535 - val_specificity_at_sensitivity: 0.7592 - val_recall: 0.9904 - val_precision: 0.5549\n",
            "Epoch 140/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3467 - accuracy: 0.8242 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9288 - recall: 0.9709 - precision: 0.7440\n",
            "Epoch 140: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 176ms/step - loss: 0.3467 - accuracy: 0.8242 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9288 - recall: 0.9709 - precision: 0.7440 - val_loss: 0.5883 - val_accuracy: 0.6336 - val_sensitivity_at_specificity: 0.8868 - val_specificity_at_sensitivity: 0.8346 - val_recall: 0.9777 - val_precision: 0.5740\n",
            "Epoch 141/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3321 - accuracy: 0.8305 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9553 - recall: 0.9839 - precision: 0.7568\n",
            "Epoch 141: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.3321 - accuracy: 0.8305 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9553 - recall: 0.9839 - precision: 0.7568 - val_loss: 0.6866 - val_accuracy: 0.6070 - val_sensitivity_at_specificity: 0.8502 - val_specificity_at_sensitivity: 0.8018 - val_recall: 0.9984 - val_precision: 0.5498\n",
            "Epoch 142/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3384 - accuracy: 0.8266 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9406 - recall: 0.9805 - precision: 0.7415\n",
            "Epoch 142: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 157ms/step - loss: 0.3384 - accuracy: 0.8266 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9406 - recall: 0.9805 - precision: 0.7415 - val_loss: 0.6804 - val_accuracy: 0.5977 - val_sensitivity_at_specificity: 0.8511 - val_specificity_at_sensitivity: 0.8053 - val_recall: 0.9969 - val_precision: 0.5535\n",
            "Epoch 143/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3347 - accuracy: 0.8160 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9592 - recall: 0.9637 - precision: 0.7403\n",
            "Epoch 143: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 155ms/step - loss: 0.3347 - accuracy: 0.8160 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9592 - recall: 0.9637 - precision: 0.7403 - val_loss: 0.6372 - val_accuracy: 0.6234 - val_sensitivity_at_specificity: 0.8655 - val_specificity_at_sensitivity: 0.8152 - val_recall: 0.9907 - val_precision: 0.5739\n",
            "Epoch 144/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3471 - accuracy: 0.8266 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9422 - recall: 0.9699 - precision: 0.7565\n",
            "Epoch 144: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 156ms/step - loss: 0.3471 - accuracy: 0.8266 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9422 - recall: 0.9699 - precision: 0.7565 - val_loss: 0.6760 - val_accuracy: 0.5992 - val_sensitivity_at_specificity: 0.8410 - val_specificity_at_sensitivity: 0.8203 - val_recall: 0.9968 - val_precision: 0.5510\n",
            "Epoch 145/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3412 - accuracy: 0.8195 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9502 - recall: 0.9825 - precision: 0.7368\n",
            "Epoch 145: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 156ms/step - loss: 0.3412 - accuracy: 0.8195 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9502 - recall: 0.9825 - precision: 0.7368 - val_loss: 0.6290 - val_accuracy: 0.6281 - val_sensitivity_at_specificity: 0.8810 - val_specificity_at_sensitivity: 0.8294 - val_recall: 0.9923 - val_precision: 0.5768\n",
            "Epoch 146/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3445 - accuracy: 0.8164 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9508 - recall: 0.9908 - precision: 0.7377\n",
            "Epoch 146: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.3445 - accuracy: 0.8164 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9508 - recall: 0.9908 - precision: 0.7377 - val_loss: 0.6046 - val_accuracy: 0.6281 - val_sensitivity_at_specificity: 0.9058 - val_specificity_at_sensitivity: 0.8367 - val_recall: 0.9874 - val_precision: 0.5734\n",
            "Epoch 147/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3602 - accuracy: 0.8098 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9329 - recall: 0.9851 - precision: 0.7290\n",
            "Epoch 147: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.3602 - accuracy: 0.8098 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9329 - recall: 0.9851 - precision: 0.7290 - val_loss: 0.6543 - val_accuracy: 0.6078 - val_sensitivity_at_specificity: 0.8380 - val_specificity_at_sensitivity: 0.7790 - val_recall: 1.0000 - val_precision: 0.5612\n",
            "Epoch 148/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3450 - accuracy: 0.8207 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9336 - recall: 0.9787 - precision: 0.7413\n",
            "Epoch 148: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.3450 - accuracy: 0.8207 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9336 - recall: 0.9787 - precision: 0.7413 - val_loss: 0.6244 - val_accuracy: 0.6297 - val_sensitivity_at_specificity: 0.8569 - val_specificity_at_sensitivity: 0.8052 - val_recall: 0.9985 - val_precision: 0.5836\n",
            "Epoch 149/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3374 - accuracy: 0.8242 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9507 - recall: 0.9889 - precision: 0.7409\n",
            "Epoch 149: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.3374 - accuracy: 0.8242 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9507 - recall: 0.9889 - precision: 0.7409 - val_loss: 0.6221 - val_accuracy: 0.6211 - val_sensitivity_at_specificity: 0.8841 - val_specificity_at_sensitivity: 0.8600 - val_recall: 0.9905 - val_precision: 0.5657\n",
            "Epoch 150/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3406 - accuracy: 0.8285 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9436 - recall: 0.9680 - precision: 0.7573\n",
            "Epoch 150: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.3406 - accuracy: 0.8285 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9436 - recall: 0.9680 - precision: 0.7573 - val_loss: 0.6061 - val_accuracy: 0.6352 - val_sensitivity_at_specificity: 0.8882 - val_specificity_at_sensitivity: 0.8182 - val_recall: 0.9908 - val_precision: 0.5839\n",
            "Epoch 151/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3371 - accuracy: 0.8258 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9536 - recall: 0.9660 - precision: 0.7522\n",
            "Epoch 151: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.3371 - accuracy: 0.8258 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9536 - recall: 0.9660 - precision: 0.7522 - val_loss: 0.6413 - val_accuracy: 0.6359 - val_sensitivity_at_specificity: 0.8728 - val_specificity_at_sensitivity: 0.8429 - val_recall: 0.9827 - val_precision: 0.5791\n",
            "Epoch 152/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3427 - accuracy: 0.8281 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9476 - recall: 0.9690 - precision: 0.7594\n",
            "Epoch 152: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 152ms/step - loss: 0.3427 - accuracy: 0.8281 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9476 - recall: 0.9690 - precision: 0.7594 - val_loss: 0.6151 - val_accuracy: 0.6367 - val_sensitivity_at_specificity: 0.8580 - val_specificity_at_sensitivity: 0.8265 - val_recall: 0.9671 - val_precision: 0.5936\n",
            "Epoch 153/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3278 - accuracy: 0.8262 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9621 - recall: 0.9435 - precision: 0.7662\n",
            "Epoch 153: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 157ms/step - loss: 0.3278 - accuracy: 0.8262 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9621 - recall: 0.9435 - precision: 0.7662 - val_loss: 0.7107 - val_accuracy: 0.6187 - val_sensitivity_at_specificity: 0.8565 - val_specificity_at_sensitivity: 0.7979 - val_recall: 0.9777 - val_precision: 0.5639\n",
            "Epoch 154/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.3287 - accuracy: 0.8342 - sensitivity_at_specificity: 0.9991 - specificity_at_sensitivity: 0.9496 - recall: 0.9633 - precision: 0.7691\n",
            "Epoch 154: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 155ms/step - loss: 0.3265 - accuracy: 0.8339 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9533 - recall: 0.9651 - precision: 0.7689 - val_loss: 0.6629 - val_accuracy: 0.6242 - val_sensitivity_at_specificity: 0.8653 - val_specificity_at_sensitivity: 0.8186 - val_recall: 0.9955 - val_precision: 0.5818\n",
            "Epoch 155/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3414 - accuracy: 0.8254 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9459 - recall: 0.9763 - precision: 0.7479\n",
            "Epoch 155: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.3414 - accuracy: 0.8254 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9459 - recall: 0.9763 - precision: 0.7479 - val_loss: 0.6316 - val_accuracy: 0.6203 - val_sensitivity_at_specificity: 0.8311 - val_specificity_at_sensitivity: 0.8170 - val_recall: 0.9787 - val_precision: 0.5767\n",
            "Epoch 156/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3201 - accuracy: 0.8363 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9690 - recall: 0.9693 - precision: 0.7689\n",
            "Epoch 156: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.3201 - accuracy: 0.8363 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9690 - recall: 0.9693 - precision: 0.7689 - val_loss: 0.6825 - val_accuracy: 0.6391 - val_sensitivity_at_specificity: 0.8934 - val_specificity_at_sensitivity: 0.8246 - val_recall: 0.9861 - val_precision: 0.5848\n",
            "Epoch 157/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3329 - accuracy: 0.8328 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9421 - recall: 0.9668 - precision: 0.7600\n",
            "Epoch 157: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.3329 - accuracy: 0.8328 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9421 - recall: 0.9668 - precision: 0.7600 - val_loss: 0.6562 - val_accuracy: 0.6297 - val_sensitivity_at_specificity: 0.9009 - val_specificity_at_sensitivity: 0.8385 - val_recall: 0.9827 - val_precision: 0.5744\n",
            "Epoch 158/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3268 - accuracy: 0.8316 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9509 - recall: 0.9679 - precision: 0.7601\n",
            "Epoch 158: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.3268 - accuracy: 0.8316 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9509 - recall: 0.9679 - precision: 0.7601 - val_loss: 0.6244 - val_accuracy: 0.6469 - val_sensitivity_at_specificity: 0.9028 - val_specificity_at_sensitivity: 0.8265 - val_recall: 0.9940 - val_precision: 0.5975\n",
            "Epoch 159/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3211 - accuracy: 0.8367 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9636 - recall: 0.9709 - precision: 0.7639\n",
            "Epoch 159: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.3211 - accuracy: 0.8367 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9636 - recall: 0.9709 - precision: 0.7639 - val_loss: 0.6833 - val_accuracy: 0.6172 - val_sensitivity_at_specificity: 0.8818 - val_specificity_at_sensitivity: 0.8069 - val_recall: 0.9736 - val_precision: 0.5696\n",
            "Epoch 160/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3410 - accuracy: 0.8246 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9445 - recall: 0.9422 - precision: 0.7630\n",
            "Epoch 160: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 157ms/step - loss: 0.3410 - accuracy: 0.8246 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9445 - recall: 0.9422 - precision: 0.7630 - val_loss: 0.6773 - val_accuracy: 0.6211 - val_sensitivity_at_specificity: 0.8695 - val_specificity_at_sensitivity: 0.7919 - val_recall: 0.9811 - val_precision: 0.5688\n",
            "Epoch 161/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3389 - accuracy: 0.8258 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9514 - recall: 0.9572 - precision: 0.7588\n",
            "Epoch 161: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.3389 - accuracy: 0.8258 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9514 - recall: 0.9572 - precision: 0.7588 - val_loss: 0.7630 - val_accuracy: 0.5836 - val_sensitivity_at_specificity: 0.8403 - val_specificity_at_sensitivity: 0.7712 - val_recall: 0.9968 - val_precision: 0.5379\n",
            "Epoch 162/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3255 - accuracy: 0.8316 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9545 - recall: 0.9686 - precision: 0.7644\n",
            "Epoch 162: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 157ms/step - loss: 0.3255 - accuracy: 0.8316 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9545 - recall: 0.9686 - precision: 0.7644 - val_loss: 0.6754 - val_accuracy: 0.6523 - val_sensitivity_at_specificity: 0.8865 - val_specificity_at_sensitivity: 0.8191 - val_recall: 0.9894 - val_precision: 0.5989\n",
            "Epoch 163/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3383 - accuracy: 0.8331 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9357 - recall: 0.9799 - precision: 0.7558\n",
            "Epoch 163: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 154ms/step - loss: 0.3383 - accuracy: 0.8331 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9357 - recall: 0.9799 - precision: 0.7558 - val_loss: 0.7249 - val_accuracy: 0.5984 - val_sensitivity_at_specificity: 0.8397 - val_specificity_at_sensitivity: 0.7923 - val_recall: 0.9937 - val_precision: 0.5511\n",
            "Epoch 164/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3296 - accuracy: 0.8289 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9573 - recall: 0.9677 - precision: 0.7560\n",
            "Epoch 164: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.3296 - accuracy: 0.8289 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9573 - recall: 0.9677 - precision: 0.7560 - val_loss: 0.7417 - val_accuracy: 0.6109 - val_sensitivity_at_specificity: 0.8523 - val_specificity_at_sensitivity: 0.7997 - val_recall: 0.9919 - val_precision: 0.5534\n",
            "Epoch 165/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3351 - accuracy: 0.8254 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9463 - recall: 0.9725 - precision: 0.7505\n",
            "Epoch 165: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.3351 - accuracy: 0.8254 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9463 - recall: 0.9725 - precision: 0.7505 - val_loss: 0.6547 - val_accuracy: 0.5977 - val_sensitivity_at_specificity: 0.8558 - val_specificity_at_sensitivity: 0.8293 - val_recall: 0.9968 - val_precision: 0.5480\n",
            "Epoch 166/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3259 - accuracy: 0.8301 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9631 - recall: 0.9704 - precision: 0.7585\n",
            "Epoch 166: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.3259 - accuracy: 0.8301 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9631 - recall: 0.9704 - precision: 0.7585 - val_loss: 0.7251 - val_accuracy: 0.6133 - val_sensitivity_at_specificity: 0.8841 - val_specificity_at_sensitivity: 0.8301 - val_recall: 0.9985 - val_precision: 0.5701\n",
            "Epoch 167/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3301 - accuracy: 0.8332 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9545 - recall: 0.9702 - precision: 0.7657\n",
            "Epoch 167: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 155ms/step - loss: 0.3301 - accuracy: 0.8332 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9545 - recall: 0.9702 - precision: 0.7657 - val_loss: 0.7338 - val_accuracy: 0.6016 - val_sensitivity_at_specificity: 0.8609 - val_specificity_at_sensitivity: 0.8246 - val_recall: 0.9923 - val_precision: 0.5597\n",
            "Epoch 168/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3391 - accuracy: 0.8148 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9594 - recall: 0.9772 - precision: 0.7294\n",
            "Epoch 168: val_accuracy did not improve from 0.66094\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.3391 - accuracy: 0.8148 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9594 - recall: 0.9772 - precision: 0.7294 - val_loss: 0.6118 - val_accuracy: 0.6305 - val_sensitivity_at_specificity: 0.8346 - val_specificity_at_sensitivity: 0.8246 - val_recall: 0.9709 - val_precision: 0.5827\n",
            "Epoch 169/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3333 - accuracy: 0.8281 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9547 - recall: 0.9439 - precision: 0.7647\n",
            "Epoch 169: val_accuracy improved from 0.66094 to 0.67422, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.3333 - accuracy: 0.8281 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9547 - recall: 0.9439 - precision: 0.7647 - val_loss: 0.5854 - val_accuracy: 0.6742 - val_sensitivity_at_specificity: 0.8819 - val_specificity_at_sensitivity: 0.8481 - val_recall: 0.9386 - val_precision: 0.6119\n",
            "Epoch 170/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3472 - accuracy: 0.8211 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9453 - recall: 0.9318 - precision: 0.7595\n",
            "Epoch 170: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.3472 - accuracy: 0.8211 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9453 - recall: 0.9318 - precision: 0.7595 - val_loss: 0.6136 - val_accuracy: 0.6492 - val_sensitivity_at_specificity: 0.8649 - val_specificity_at_sensitivity: 0.8187 - val_recall: 0.9300 - val_precision: 0.5909\n",
            "Epoch 171/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3242 - accuracy: 0.8230 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9693 - recall: 0.9389 - precision: 0.7468\n",
            "Epoch 171: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.3242 - accuracy: 0.8230 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9693 - recall: 0.9389 - precision: 0.7468 - val_loss: 0.8151 - val_accuracy: 0.5758 - val_sensitivity_at_specificity: 0.8059 - val_specificity_at_sensitivity: 0.7901 - val_recall: 0.9951 - val_precision: 0.5304\n",
            "Epoch 172/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3175 - accuracy: 0.8426 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9606 - recall: 0.9549 - precision: 0.7773\n",
            "Epoch 172: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.3175 - accuracy: 0.8426 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9606 - recall: 0.9549 - precision: 0.7773 - val_loss: 0.6297 - val_accuracy: 0.6680 - val_sensitivity_at_specificity: 0.8816 - val_specificity_at_sensitivity: 0.8254 - val_recall: 0.9535 - val_precision: 0.6175\n",
            "Epoch 173/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3173 - accuracy: 0.8402 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9621 - recall: 0.9398 - precision: 0.7862\n",
            "Epoch 173: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.3173 - accuracy: 0.8402 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9621 - recall: 0.9398 - precision: 0.7862 - val_loss: 0.7322 - val_accuracy: 0.6344 - val_sensitivity_at_specificity: 0.8530 - val_specificity_at_sensitivity: 0.8182 - val_recall: 0.9709 - val_precision: 0.5854\n",
            "Epoch 174/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3278 - accuracy: 0.8324 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9588 - recall: 0.9537 - precision: 0.7702\n",
            "Epoch 174: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.3278 - accuracy: 0.8324 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9588 - recall: 0.9537 - precision: 0.7702 - val_loss: 0.7332 - val_accuracy: 0.6102 - val_sensitivity_at_specificity: 0.8164 - val_specificity_at_sensitivity: 0.8085 - val_recall: 0.9861 - val_precision: 0.5660\n",
            "Epoch 175/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3327 - accuracy: 0.8252 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9586 - recall: 0.9417 - precision: 0.7630\n",
            "Epoch 175: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 154ms/step - loss: 0.3327 - accuracy: 0.8252 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9586 - recall: 0.9417 - precision: 0.7630 - val_loss: 0.6307 - val_accuracy: 0.6547 - val_sensitivity_at_specificity: 0.8827 - val_specificity_at_sensitivity: 0.8428 - val_recall: 0.9429 - val_precision: 0.5944\n",
            "Epoch 176/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3334 - accuracy: 0.8336 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9478 - recall: 0.9467 - precision: 0.7775\n",
            "Epoch 176: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.3334 - accuracy: 0.8336 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9478 - recall: 0.9467 - precision: 0.7775 - val_loss: 0.6206 - val_accuracy: 0.6281 - val_sensitivity_at_specificity: 0.8211 - val_specificity_at_sensitivity: 0.8035 - val_recall: 0.9602 - val_precision: 0.5826\n",
            "Epoch 177/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3154 - accuracy: 0.8395 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9593 - recall: 0.9633 - precision: 0.7722\n",
            "Epoch 177: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.3154 - accuracy: 0.8395 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9593 - recall: 0.9633 - precision: 0.7722 - val_loss: 0.7270 - val_accuracy: 0.6250 - val_sensitivity_at_specificity: 0.8344 - val_specificity_at_sensitivity: 0.7707 - val_recall: 0.9893 - val_precision: 0.5769\n",
            "Epoch 178/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3145 - accuracy: 0.8324 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9659 - recall: 0.9564 - precision: 0.7596\n",
            "Epoch 178: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.3145 - accuracy: 0.8324 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9659 - recall: 0.9564 - precision: 0.7596 - val_loss: 0.8353 - val_accuracy: 0.5703 - val_sensitivity_at_specificity: 0.8159 - val_specificity_at_sensitivity: 0.7681 - val_recall: 0.9884 - val_precision: 0.5233\n",
            "Epoch 179/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3384 - accuracy: 0.8199 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9620 - recall: 0.9269 - precision: 0.7522\n",
            "Epoch 179: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.3384 - accuracy: 0.8199 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9620 - recall: 0.9269 - precision: 0.7522 - val_loss: 0.7485 - val_accuracy: 0.6062 - val_sensitivity_at_specificity: 0.8431 - val_specificity_at_sensitivity: 0.8043 - val_recall: 0.9715 - val_precision: 0.5578\n",
            "Epoch 180/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3152 - accuracy: 0.8326 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9723 - recall: 0.9161 - precision: 0.7805\n",
            "Epoch 180: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.3152 - accuracy: 0.8326 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9723 - recall: 0.9161 - precision: 0.7805 - val_loss: 0.7768 - val_accuracy: 0.6289 - val_sensitivity_at_specificity: 0.8341 - val_specificity_at_sensitivity: 0.7780 - val_recall: 0.9532 - val_precision: 0.5874\n",
            "Epoch 181/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3370 - accuracy: 0.8277 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9608 - recall: 0.9174 - precision: 0.7786\n",
            "Epoch 181: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.3370 - accuracy: 0.8277 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9608 - recall: 0.9174 - precision: 0.7786 - val_loss: 0.6588 - val_accuracy: 0.6555 - val_sensitivity_at_specificity: 0.8650 - val_specificity_at_sensitivity: 0.8284 - val_recall: 0.9540 - val_precision: 0.6106\n",
            "Epoch 182/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3348 - accuracy: 0.8297 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9493 - recall: 0.9412 - precision: 0.7660\n",
            "Epoch 182: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 157ms/step - loss: 0.3348 - accuracy: 0.8297 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9493 - recall: 0.9412 - precision: 0.7660 - val_loss: 0.6990 - val_accuracy: 0.6328 - val_sensitivity_at_specificity: 0.8255 - val_specificity_at_sensitivity: 0.8106 - val_recall: 0.9591 - val_precision: 0.5787\n",
            "Epoch 183/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3123 - accuracy: 0.8402 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9667 - recall: 0.9585 - precision: 0.7783\n",
            "Epoch 183: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 177ms/step - loss: 0.3123 - accuracy: 0.8402 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9667 - recall: 0.9585 - precision: 0.7783 - val_loss: 0.6529 - val_accuracy: 0.6367 - val_sensitivity_at_specificity: 0.9050 - val_specificity_at_sensitivity: 0.8574 - val_recall: 0.9775 - val_precision: 0.5737\n",
            "Epoch 184/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3217 - accuracy: 0.8336 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9657 - recall: 0.9510 - precision: 0.7745\n",
            "Epoch 184: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 157ms/step - loss: 0.3217 - accuracy: 0.8336 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9657 - recall: 0.9510 - precision: 0.7745 - val_loss: 0.7300 - val_accuracy: 0.6422 - val_sensitivity_at_specificity: 0.8404 - val_specificity_at_sensitivity: 0.8036 - val_recall: 0.9623 - val_precision: 0.5961\n",
            "Epoch 185/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3042 - accuracy: 0.8418 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9690 - recall: 0.9193 - precision: 0.7995\n",
            "Epoch 185: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.3042 - accuracy: 0.8418 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9690 - recall: 0.9193 - precision: 0.7995 - val_loss: 0.7579 - val_accuracy: 0.6336 - val_sensitivity_at_specificity: 0.8466 - val_specificity_at_sensitivity: 0.7787 - val_recall: 0.9463 - val_precision: 0.5871\n",
            "Epoch 186/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3191 - accuracy: 0.8343 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9586 - recall: 0.9591 - precision: 0.7667\n",
            "Epoch 186: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 153ms/step - loss: 0.3191 - accuracy: 0.8343 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9586 - recall: 0.9591 - precision: 0.7667 - val_loss: 0.6912 - val_accuracy: 0.6102 - val_sensitivity_at_specificity: 0.8476 - val_specificity_at_sensitivity: 0.8145 - val_recall: 0.9887 - val_precision: 0.5535\n",
            "Epoch 187/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3165 - accuracy: 0.8293 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9690 - recall: 0.9708 - precision: 0.7548\n",
            "Epoch 187: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.3165 - accuracy: 0.8293 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9690 - recall: 0.9708 - precision: 0.7548 - val_loss: 0.6655 - val_accuracy: 0.6344 - val_sensitivity_at_specificity: 0.8729 - val_specificity_at_sensitivity: 0.8252 - val_recall: 0.9767 - val_precision: 0.5817\n",
            "Epoch 188/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3233 - accuracy: 0.8309 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9621 - recall: 0.9591 - precision: 0.7657\n",
            "Epoch 188: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.3233 - accuracy: 0.8309 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9621 - recall: 0.9591 - precision: 0.7657 - val_loss: 0.7730 - val_accuracy: 0.6148 - val_sensitivity_at_specificity: 0.8341 - val_specificity_at_sensitivity: 0.7832 - val_recall: 0.9812 - val_precision: 0.5659\n",
            "Epoch 189/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2938 - accuracy: 0.8488 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9783 - recall: 0.9470 - precision: 0.7922\n",
            "Epoch 189: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 157ms/step - loss: 0.2938 - accuracy: 0.8488 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9783 - recall: 0.9470 - precision: 0.7922 - val_loss: 0.6496 - val_accuracy: 0.6484 - val_sensitivity_at_specificity: 0.8578 - val_specificity_at_sensitivity: 0.8253 - val_recall: 0.9542 - val_precision: 0.5893\n",
            "Epoch 190/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3102 - accuracy: 0.8473 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9667 - recall: 0.9549 - precision: 0.7933\n",
            "Epoch 190: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.3102 - accuracy: 0.8473 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9667 - recall: 0.9549 - precision: 0.7933 - val_loss: 0.6563 - val_accuracy: 0.6289 - val_sensitivity_at_specificity: 0.8826 - val_specificity_at_sensitivity: 0.8450 - val_recall: 0.9791 - val_precision: 0.5686\n",
            "Epoch 191/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3210 - accuracy: 0.8383 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9628 - recall: 0.9599 - precision: 0.7747\n",
            "Epoch 191: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.3210 - accuracy: 0.8383 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9628 - recall: 0.9599 - precision: 0.7747 - val_loss: 0.8217 - val_accuracy: 0.5977 - val_sensitivity_at_specificity: 0.8576 - val_specificity_at_sensitivity: 0.7716 - val_recall: 0.9763 - val_precision: 0.5524\n",
            "Epoch 192/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3222 - accuracy: 0.8438 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9686 - recall: 0.9286 - precision: 0.7952\n",
            "Epoch 192: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.3222 - accuracy: 0.8438 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9686 - recall: 0.9286 - precision: 0.7952 - val_loss: 1.0088 - val_accuracy: 0.5688 - val_sensitivity_at_specificity: 0.8077 - val_specificity_at_sensitivity: 0.7652 - val_recall: 0.9840 - val_precision: 0.5311\n",
            "Epoch 193/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3188 - accuracy: 0.8305 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9726 - recall: 0.8949 - precision: 0.7788\n",
            "Epoch 193: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.3188 - accuracy: 0.8305 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9726 - recall: 0.8949 - precision: 0.7788 - val_loss: 0.6697 - val_accuracy: 0.6555 - val_sensitivity_at_specificity: 0.8488 - val_specificity_at_sensitivity: 0.8341 - val_recall: 0.9307 - val_precision: 0.5982\n",
            "Epoch 194/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3096 - accuracy: 0.8406 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9697 - recall: 0.9363 - precision: 0.7844\n",
            "Epoch 194: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.3096 - accuracy: 0.8406 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9697 - recall: 0.9363 - precision: 0.7844 - val_loss: 0.6896 - val_accuracy: 0.6344 - val_sensitivity_at_specificity: 0.8539 - val_specificity_at_sensitivity: 0.8090 - val_recall: 0.9711 - val_precision: 0.5869\n",
            "Epoch 195/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3203 - accuracy: 0.8355 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9621 - recall: 0.9459 - precision: 0.7680\n",
            "Epoch 195: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.3203 - accuracy: 0.8355 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9621 - recall: 0.9459 - precision: 0.7680 - val_loss: 0.7794 - val_accuracy: 0.6219 - val_sensitivity_at_specificity: 0.8525 - val_specificity_at_sensitivity: 0.7828 - val_recall: 0.9595 - val_precision: 0.5633\n",
            "Epoch 196/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3008 - accuracy: 0.8461 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9752 - recall: 0.9312 - precision: 0.8003\n",
            "Epoch 196: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.3008 - accuracy: 0.8461 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9752 - recall: 0.9312 - precision: 0.8003 - val_loss: 0.8087 - val_accuracy: 0.6187 - val_sensitivity_at_specificity: 0.8233 - val_specificity_at_sensitivity: 0.7790 - val_recall: 0.9508 - val_precision: 0.5758\n",
            "Epoch 197/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3010 - accuracy: 0.8449 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9745 - recall: 0.9256 - precision: 0.8008\n",
            "Epoch 197: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 156ms/step - loss: 0.3010 - accuracy: 0.8449 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9745 - recall: 0.9256 - precision: 0.8008 - val_loss: 0.7262 - val_accuracy: 0.6289 - val_sensitivity_at_specificity: 0.8230 - val_specificity_at_sensitivity: 0.7856 - val_recall: 0.9506 - val_precision: 0.5731\n",
            "Epoch 198/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3014 - accuracy: 0.8508 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9654 - recall: 0.9341 - precision: 0.8021\n",
            "Epoch 198: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.3014 - accuracy: 0.8508 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9654 - recall: 0.9341 - precision: 0.8021 - val_loss: 0.7193 - val_accuracy: 0.6250 - val_sensitivity_at_specificity: 0.8464 - val_specificity_at_sensitivity: 0.7711 - val_recall: 0.9789 - val_precision: 0.5824\n",
            "Epoch 199/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3093 - accuracy: 0.8418 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9752 - recall: 0.9481 - precision: 0.7866\n",
            "Epoch 199: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.3093 - accuracy: 0.8418 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9752 - recall: 0.9481 - precision: 0.7866 - val_loss: 0.8767 - val_accuracy: 0.6250 - val_sensitivity_at_specificity: 0.8250 - val_specificity_at_sensitivity: 0.7808 - val_recall: 0.9727 - val_precision: 0.5669\n",
            "Epoch 200/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3343 - accuracy: 0.8250 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9501 - recall: 0.9368 - precision: 0.7685\n",
            "Epoch 200: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 156ms/step - loss: 0.3343 - accuracy: 0.8250 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9501 - recall: 0.9368 - precision: 0.7685 - val_loss: 0.7453 - val_accuracy: 0.6141 - val_sensitivity_at_specificity: 0.8175 - val_specificity_at_sensitivity: 0.7771 - val_recall: 0.9816 - val_precision: 0.5704\n",
            "Epoch 201/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3113 - accuracy: 0.8410 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9751 - recall: 0.9576 - precision: 0.7757\n",
            "Epoch 201: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.3113 - accuracy: 0.8410 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9751 - recall: 0.9576 - precision: 0.7757 - val_loss: 0.6490 - val_accuracy: 0.6562 - val_sensitivity_at_specificity: 0.8502 - val_specificity_at_sensitivity: 0.8080 - val_recall: 0.9369 - val_precision: 0.5976\n",
            "Epoch 202/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3090 - accuracy: 0.8223 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9831 - recall: 0.9110 - precision: 0.7696\n",
            "Epoch 202: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.3090 - accuracy: 0.8223 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9831 - recall: 0.9110 - precision: 0.7696 - val_loss: 0.6650 - val_accuracy: 0.6602 - val_sensitivity_at_specificity: 0.8596 - val_specificity_at_sensitivity: 0.8101 - val_recall: 0.9213 - val_precision: 0.6086\n",
            "Epoch 203/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3054 - accuracy: 0.8430 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9741 - recall: 0.9339 - precision: 0.7910\n",
            "Epoch 203: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 157ms/step - loss: 0.3054 - accuracy: 0.8430 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9741 - recall: 0.9339 - precision: 0.7910 - val_loss: 0.7427 - val_accuracy: 0.6211 - val_sensitivity_at_specificity: 0.8059 - val_specificity_at_sensitivity: 0.7646 - val_recall: 0.9560 - val_precision: 0.5613\n",
            "Epoch 204/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3086 - accuracy: 0.8402 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9638 - recall: 0.9442 - precision: 0.7833\n",
            "Epoch 204: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.3086 - accuracy: 0.8402 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9638 - recall: 0.9442 - precision: 0.7833 - val_loss: 0.6486 - val_accuracy: 0.6344 - val_sensitivity_at_specificity: 0.8542 - val_specificity_at_sensitivity: 0.8474 - val_recall: 0.9624 - val_precision: 0.5803\n",
            "Epoch 205/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2898 - accuracy: 0.8496 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9817 - recall: 0.9554 - precision: 0.7916\n",
            "Epoch 205: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.2898 - accuracy: 0.8496 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9817 - recall: 0.9554 - precision: 0.7916 - val_loss: 0.6778 - val_accuracy: 0.6484 - val_sensitivity_at_specificity: 0.8407 - val_specificity_at_sensitivity: 0.8328 - val_recall: 0.9401 - val_precision: 0.5913\n",
            "Epoch 206/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2908 - accuracy: 0.8500 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9856 - recall: 0.9419 - precision: 0.8000\n",
            "Epoch 206: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.2908 - accuracy: 0.8500 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9856 - recall: 0.9419 - precision: 0.8000 - val_loss: 0.7838 - val_accuracy: 0.6383 - val_sensitivity_at_specificity: 0.8681 - val_specificity_at_sensitivity: 0.8056 - val_recall: 0.9686 - val_precision: 0.5821\n",
            "Epoch 207/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3118 - accuracy: 0.8441 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9677 - recall: 0.9403 - precision: 0.7902\n",
            "Epoch 207: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.3118 - accuracy: 0.8441 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9677 - recall: 0.9403 - precision: 0.7902 - val_loss: 0.6892 - val_accuracy: 0.6602 - val_sensitivity_at_specificity: 0.8661 - val_specificity_at_sensitivity: 0.8257 - val_recall: 0.9554 - val_precision: 0.6132\n",
            "Epoch 208/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3030 - accuracy: 0.8410 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9802 - recall: 0.9351 - precision: 0.7818\n",
            "Epoch 208: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.3030 - accuracy: 0.8410 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9802 - recall: 0.9351 - precision: 0.7818 - val_loss: 0.7429 - val_accuracy: 0.6375 - val_sensitivity_at_specificity: 0.8516 - val_specificity_at_sensitivity: 0.8188 - val_recall: 0.9703 - val_precision: 0.5826\n",
            "Epoch 209/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3097 - accuracy: 0.8410 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9710 - recall: 0.9519 - precision: 0.7901\n",
            "Epoch 209: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.3097 - accuracy: 0.8410 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9710 - recall: 0.9519 - precision: 0.7901 - val_loss: 0.9103 - val_accuracy: 0.5820 - val_sensitivity_at_specificity: 0.7939 - val_specificity_at_sensitivity: 0.7557 - val_recall: 0.9710 - val_precision: 0.5384\n",
            "Epoch 210/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3006 - accuracy: 0.8512 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9726 - recall: 0.9371 - precision: 0.8057\n",
            "Epoch 210: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.3006 - accuracy: 0.8512 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9726 - recall: 0.9371 - precision: 0.8057 - val_loss: 0.8324 - val_accuracy: 0.6477 - val_sensitivity_at_specificity: 0.8640 - val_specificity_at_sensitivity: 0.7915 - val_recall: 0.9799 - val_precision: 0.5914\n",
            "Epoch 211/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3009 - accuracy: 0.8375 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9816 - recall: 0.9396 - precision: 0.7849\n",
            "Epoch 211: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.3009 - accuracy: 0.8375 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9816 - recall: 0.9396 - precision: 0.7849 - val_loss: 0.7578 - val_accuracy: 0.6203 - val_sensitivity_at_specificity: 0.8226 - val_specificity_at_sensitivity: 0.7885 - val_recall: 0.9592 - val_precision: 0.5705\n",
            "Epoch 212/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2814 - accuracy: 0.8504 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9862 - recall: 0.9373 - precision: 0.7953\n",
            "Epoch 212: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.2814 - accuracy: 0.8504 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9862 - recall: 0.9373 - precision: 0.7953 - val_loss: 0.8282 - val_accuracy: 0.6289 - val_sensitivity_at_specificity: 0.8569 - val_specificity_at_sensitivity: 0.7736 - val_recall: 0.9582 - val_precision: 0.5703\n",
            "Epoch 213/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2882 - accuracy: 0.8504 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9811 - recall: 0.9318 - precision: 0.8029\n",
            "Epoch 213: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.2882 - accuracy: 0.8504 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9811 - recall: 0.9318 - precision: 0.8029 - val_loss: 0.8351 - val_accuracy: 0.6398 - val_sensitivity_at_specificity: 0.8203 - val_specificity_at_sensitivity: 0.8109 - val_recall: 0.9734 - val_precision: 0.5839\n",
            "Epoch 214/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3043 - accuracy: 0.8438 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9755 - recall: 0.9172 - precision: 0.7956\n",
            "Epoch 214: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.3043 - accuracy: 0.8438 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9755 - recall: 0.9172 - precision: 0.7956 - val_loss: 0.8762 - val_accuracy: 0.6266 - val_sensitivity_at_specificity: 0.8038 - val_specificity_at_sensitivity: 0.7824 - val_recall: 0.9525 - val_precision: 0.5733\n",
            "Epoch 215/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2946 - accuracy: 0.8469 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9804 - recall: 0.9034 - precision: 0.8123\n",
            "Epoch 215: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.2946 - accuracy: 0.8469 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9804 - recall: 0.9034 - precision: 0.8123 - val_loss: 0.6590 - val_accuracy: 0.6586 - val_sensitivity_at_specificity: 0.8402 - val_specificity_at_sensitivity: 0.8411 - val_recall: 0.8889 - val_precision: 0.6160\n",
            "Epoch 216/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3145 - accuracy: 0.8344 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9734 - recall: 0.9197 - precision: 0.7861\n",
            "Epoch 216: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.3145 - accuracy: 0.8344 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9734 - recall: 0.9197 - precision: 0.7861 - val_loss: 0.6495 - val_accuracy: 0.6516 - val_sensitivity_at_specificity: 0.8273 - val_specificity_at_sensitivity: 0.8062 - val_recall: 0.9474 - val_precision: 0.6056\n",
            "Epoch 217/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2946 - accuracy: 0.8543 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9745 - recall: 0.9647 - precision: 0.7936\n",
            "Epoch 217: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.2946 - accuracy: 0.8543 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9745 - recall: 0.9647 - precision: 0.7936 - val_loss: 0.7757 - val_accuracy: 0.6430 - val_sensitivity_at_specificity: 0.7917 - val_specificity_at_sensitivity: 0.7664 - val_recall: 0.9449 - val_precision: 0.6019\n",
            "Epoch 218/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2732 - accuracy: 0.8605 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9897 - recall: 0.9297 - precision: 0.8189\n",
            "Epoch 218: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.2732 - accuracy: 0.8605 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9897 - recall: 0.9297 - precision: 0.8189 - val_loss: 1.0639 - val_accuracy: 0.6156 - val_sensitivity_at_specificity: 0.8134 - val_specificity_at_sensitivity: 0.7692 - val_recall: 0.9565 - val_precision: 0.5700\n",
            "Epoch 219/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3021 - accuracy: 0.8480 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9737 - recall: 0.9166 - precision: 0.8106\n",
            "Epoch 219: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.3021 - accuracy: 0.8480 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9737 - recall: 0.9166 - precision: 0.8106 - val_loss: 0.9994 - val_accuracy: 0.6211 - val_sensitivity_at_specificity: 0.8025 - val_specificity_at_sensitivity: 0.7278 - val_recall: 0.9877 - val_precision: 0.5730\n",
            "Epoch 220/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3003 - accuracy: 0.8527 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9717 - recall: 0.9592 - precision: 0.7974\n",
            "Epoch 220: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.3003 - accuracy: 0.8527 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9717 - recall: 0.9592 - precision: 0.7974 - val_loss: 0.7697 - val_accuracy: 0.6344 - val_sensitivity_at_specificity: 0.8310 - val_specificity_at_sensitivity: 0.8203 - val_recall: 0.9724 - val_precision: 0.5845\n",
            "Epoch 221/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2962 - accuracy: 0.8500 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9782 - recall: 0.9418 - precision: 0.8023\n",
            "Epoch 221: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.2962 - accuracy: 0.8500 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9782 - recall: 0.9418 - precision: 0.8023 - val_loss: 1.0031 - val_accuracy: 0.6172 - val_sensitivity_at_specificity: 0.7840 - val_specificity_at_sensitivity: 0.7437 - val_recall: 0.9691 - val_precision: 0.5719\n",
            "Epoch 222/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2699 - accuracy: 0.8684 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9847 - recall: 0.9400 - precision: 0.8274\n",
            "Epoch 222: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.2699 - accuracy: 0.8684 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9847 - recall: 0.9400 - precision: 0.8274 - val_loss: 0.8665 - val_accuracy: 0.6375 - val_sensitivity_at_specificity: 0.8150 - val_specificity_at_sensitivity: 0.7477 - val_recall: 0.9483 - val_precision: 0.5840\n",
            "Epoch 223/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2893 - accuracy: 0.8484 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9865 - recall: 0.9322 - precision: 0.8013\n",
            "Epoch 223: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.2893 - accuracy: 0.8484 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9865 - recall: 0.9322 - precision: 0.8013 - val_loss: 0.8252 - val_accuracy: 0.6078 - val_sensitivity_at_specificity: 0.8119 - val_specificity_at_sensitivity: 0.7614 - val_recall: 0.9212 - val_precision: 0.5585\n",
            "Epoch 224/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2789 - accuracy: 0.8570 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9851 - recall: 0.9340 - precision: 0.8105\n",
            "Epoch 224: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.2789 - accuracy: 0.8570 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9851 - recall: 0.9340 - precision: 0.8105 - val_loss: 0.8796 - val_accuracy: 0.6234 - val_sensitivity_at_specificity: 0.8536 - val_specificity_at_sensitivity: 0.7982 - val_recall: 0.9667 - val_precision: 0.5570\n",
            "Epoch 225/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2864 - accuracy: 0.8574 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9809 - recall: 0.9331 - precision: 0.8137\n",
            "Epoch 225: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.2864 - accuracy: 0.8574 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9809 - recall: 0.9331 - precision: 0.8137 - val_loss: 0.7356 - val_accuracy: 0.6625 - val_sensitivity_at_specificity: 0.8629 - val_specificity_at_sensitivity: 0.7655 - val_recall: 0.9260 - val_precision: 0.6102\n",
            "Epoch 226/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2956 - accuracy: 0.8512 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9767 - recall: 0.9214 - precision: 0.8067\n",
            "Epoch 226: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.2956 - accuracy: 0.8512 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9767 - recall: 0.9214 - precision: 0.8067 - val_loss: 0.7249 - val_accuracy: 0.6344 - val_sensitivity_at_specificity: 0.8000 - val_specificity_at_sensitivity: 0.7984 - val_recall: 0.9178 - val_precision: 0.5879\n",
            "Epoch 227/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2751 - accuracy: 0.8625 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9866 - recall: 0.9379 - precision: 0.8162\n",
            "Epoch 227: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.2751 - accuracy: 0.8625 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9866 - recall: 0.9379 - precision: 0.8162 - val_loss: 0.6826 - val_accuracy: 0.6742 - val_sensitivity_at_specificity: 0.8547 - val_specificity_at_sensitivity: 0.7955 - val_recall: 0.8976 - val_precision: 0.6265\n",
            "Epoch 228/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2792 - accuracy: 0.8512 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9901 - recall: 0.9145 - precision: 0.8068\n",
            "Epoch 228: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.2792 - accuracy: 0.8512 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9901 - recall: 0.9145 - precision: 0.8068 - val_loss: 0.7725 - val_accuracy: 0.6406 - val_sensitivity_at_specificity: 0.8238 - val_specificity_at_sensitivity: 0.7923 - val_recall: 0.8968 - val_precision: 0.5885\n",
            "Epoch 229/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2859 - accuracy: 0.8520 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9826 - recall: 0.9090 - precision: 0.8188\n",
            "Epoch 229: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.2859 - accuracy: 0.8520 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9826 - recall: 0.9090 - precision: 0.8188 - val_loss: 0.7590 - val_accuracy: 0.6461 - val_sensitivity_at_specificity: 0.8491 - val_specificity_at_sensitivity: 0.7837 - val_recall: 0.9345 - val_precision: 0.5992\n",
            "Epoch 230/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2720 - accuracy: 0.8645 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9876 - recall: 0.9417 - precision: 0.8142\n",
            "Epoch 230: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.2720 - accuracy: 0.8645 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9876 - recall: 0.9417 - precision: 0.8142 - val_loss: 0.8365 - val_accuracy: 0.6180 - val_sensitivity_at_specificity: 0.8325 - val_specificity_at_sensitivity: 0.7790 - val_recall: 0.9463 - val_precision: 0.5683\n",
            "Epoch 231/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2759 - accuracy: 0.8703 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9816 - recall: 0.9359 - precision: 0.8318\n",
            "Epoch 231: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.2759 - accuracy: 0.8703 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9816 - recall: 0.9359 - precision: 0.8318 - val_loss: 0.9213 - val_accuracy: 0.6273 - val_sensitivity_at_specificity: 0.8294 - val_specificity_at_sensitivity: 0.7620 - val_recall: 0.8894 - val_precision: 0.5804\n",
            "Epoch 232/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2925 - accuracy: 0.8395 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9913 - recall: 0.8937 - precision: 0.8095\n",
            "Epoch 232: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.2925 - accuracy: 0.8395 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9913 - recall: 0.8937 - precision: 0.8095 - val_loss: 0.7930 - val_accuracy: 0.6469 - val_sensitivity_at_specificity: 0.8387 - val_specificity_at_sensitivity: 0.7913 - val_recall: 0.9437 - val_precision: 0.5990\n",
            "Epoch 233/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2687 - accuracy: 0.8637 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9793 - recall: 0.9260 - precision: 0.8196\n",
            "Epoch 233: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.2687 - accuracy: 0.8637 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9793 - recall: 0.9260 - precision: 0.8196 - val_loss: 0.7654 - val_accuracy: 0.6422 - val_sensitivity_at_specificity: 0.8214 - val_specificity_at_sensitivity: 0.7810 - val_recall: 0.8868 - val_precision: 0.5896\n",
            "Epoch 234/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2717 - accuracy: 0.8594 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9884 - recall: 0.9113 - precision: 0.8226\n",
            "Epoch 234: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.2717 - accuracy: 0.8594 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9884 - recall: 0.9113 - precision: 0.8226 - val_loss: 0.9047 - val_accuracy: 0.6117 - val_sensitivity_at_specificity: 0.8418 - val_specificity_at_sensitivity: 0.7901 - val_recall: 0.9636 - val_precision: 0.5623\n",
            "Epoch 235/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2876 - accuracy: 0.8488 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9854 - recall: 0.9234 - precision: 0.7984\n",
            "Epoch 235: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 155ms/step - loss: 0.2876 - accuracy: 0.8488 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9854 - recall: 0.9234 - precision: 0.7984 - val_loss: 0.7923 - val_accuracy: 0.6406 - val_sensitivity_at_specificity: 0.8216 - val_specificity_at_sensitivity: 0.7660 - val_recall: 0.9218 - val_precision: 0.5896\n",
            "Epoch 236/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2833 - accuracy: 0.8473 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9904 - recall: 0.9018 - precision: 0.8172\n",
            "Epoch 236: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.2833 - accuracy: 0.8473 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9904 - recall: 0.9018 - precision: 0.8172 - val_loss: 0.7534 - val_accuracy: 0.6609 - val_sensitivity_at_specificity: 0.8482 - val_specificity_at_sensitivity: 0.8211 - val_recall: 0.8978 - val_precision: 0.6030\n",
            "Epoch 237/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2940 - accuracy: 0.8457 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9873 - recall: 0.8966 - precision: 0.8025\n",
            "Epoch 237: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.2940 - accuracy: 0.8457 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9873 - recall: 0.8966 - precision: 0.8025 - val_loss: 0.7769 - val_accuracy: 0.6664 - val_sensitivity_at_specificity: 0.8112 - val_specificity_at_sensitivity: 0.7783 - val_recall: 0.8882 - val_precision: 0.6249\n",
            "Epoch 238/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2938 - accuracy: 0.8484 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9820 - recall: 0.9087 - precision: 0.8111\n",
            "Epoch 238: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.2938 - accuracy: 0.8484 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9820 - recall: 0.9087 - precision: 0.8111 - val_loss: 0.8083 - val_accuracy: 0.6609 - val_sensitivity_at_specificity: 0.8410 - val_specificity_at_sensitivity: 0.7776 - val_recall: 0.9525 - val_precision: 0.6146\n",
            "Epoch 239/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2645 - accuracy: 0.8660 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9860 - recall: 0.9284 - precision: 0.8240\n",
            "Epoch 239: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.2645 - accuracy: 0.8660 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9860 - recall: 0.9284 - precision: 0.8240 - val_loss: 0.8052 - val_accuracy: 0.6203 - val_sensitivity_at_specificity: 0.8183 - val_specificity_at_sensitivity: 0.7948 - val_recall: 0.9277 - val_precision: 0.5668\n",
            "Epoch 240/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2767 - accuracy: 0.8586 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9930 - recall: 0.9371 - precision: 0.8086\n",
            "Epoch 240: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.2767 - accuracy: 0.8586 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9930 - recall: 0.9371 - precision: 0.8086 - val_loss: 0.8107 - val_accuracy: 0.6672 - val_sensitivity_at_specificity: 0.8992 - val_specificity_at_sensitivity: 0.8078 - val_recall: 0.9669 - val_precision: 0.6026\n",
            "Epoch 241/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2700 - accuracy: 0.8598 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9912 - recall: 0.9296 - precision: 0.8197\n",
            "Epoch 241: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.2700 - accuracy: 0.8598 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9912 - recall: 0.9296 - precision: 0.8197 - val_loss: 0.9949 - val_accuracy: 0.6211 - val_sensitivity_at_specificity: 0.7667 - val_specificity_at_sensitivity: 0.7113 - val_recall: 0.9485 - val_precision: 0.5812\n",
            "Epoch 242/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2781 - accuracy: 0.8645 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9883 - recall: 0.9042 - precision: 0.8366\n",
            "Epoch 242: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.2781 - accuracy: 0.8645 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9883 - recall: 0.9042 - precision: 0.8366 - val_loss: 0.9325 - val_accuracy: 0.6367 - val_sensitivity_at_specificity: 0.8038 - val_specificity_at_sensitivity: 0.7701 - val_recall: 0.9209 - val_precision: 0.5838\n",
            "Epoch 243/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2692 - accuracy: 0.8617 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9909 - recall: 0.9151 - precision: 0.8216\n",
            "Epoch 243: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.2692 - accuracy: 0.8617 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9909 - recall: 0.9151 - precision: 0.8216 - val_loss: 0.9890 - val_accuracy: 0.6227 - val_sensitivity_at_specificity: 0.7857 - val_specificity_at_sensitivity: 0.7516 - val_recall: 0.9425 - val_precision: 0.5764\n",
            "Epoch 244/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2580 - accuracy: 0.8719 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9937 - recall: 0.9274 - precision: 0.8369\n",
            "Epoch 244: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.2580 - accuracy: 0.8719 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9937 - recall: 0.9274 - precision: 0.8369 - val_loss: 0.9559 - val_accuracy: 0.6062 - val_sensitivity_at_specificity: 0.8030 - val_specificity_at_sensitivity: 0.7783 - val_recall: 0.9249 - val_precision: 0.5469\n",
            "Epoch 245/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2824 - accuracy: 0.8605 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9812 - recall: 0.8911 - precision: 0.8407\n",
            "Epoch 245: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 186ms/step - loss: 0.2824 - accuracy: 0.8605 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9812 - recall: 0.8911 - precision: 0.8407 - val_loss: 0.8676 - val_accuracy: 0.6469 - val_sensitivity_at_specificity: 0.8726 - val_specificity_at_sensitivity: 0.7945 - val_recall: 0.9554 - val_precision: 0.5859\n",
            "Epoch 246/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2599 - accuracy: 0.8656 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9906 - recall: 0.9284 - precision: 0.8256\n",
            "Epoch 246: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.2599 - accuracy: 0.8656 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9906 - recall: 0.9284 - precision: 0.8256 - val_loss: 1.0218 - val_accuracy: 0.6141 - val_sensitivity_at_specificity: 0.7944 - val_specificity_at_sensitivity: 0.7455 - val_recall: 0.9161 - val_precision: 0.5570\n",
            "Epoch 247/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2617 - accuracy: 0.8633 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9916 - recall: 0.9001 - precision: 0.8335\n",
            "Epoch 247: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.2617 - accuracy: 0.8633 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9916 - recall: 0.9001 - precision: 0.8335 - val_loss: 0.9358 - val_accuracy: 0.6234 - val_sensitivity_at_specificity: 0.8079 - val_specificity_at_sensitivity: 0.7516 - val_recall: 0.9558 - val_precision: 0.5806\n",
            "Epoch 248/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2748 - accuracy: 0.8596 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9839 - recall: 0.9282 - precision: 0.8199\n",
            "Epoch 248: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.2748 - accuracy: 0.8596 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9839 - recall: 0.9282 - precision: 0.8199 - val_loss: 0.9545 - val_accuracy: 0.6492 - val_sensitivity_at_specificity: 0.8121 - val_specificity_at_sensitivity: 0.7726 - val_recall: 0.9682 - val_precision: 0.5989\n",
            "Epoch 249/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2535 - accuracy: 0.8738 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9914 - recall: 0.9134 - precision: 0.8467\n",
            "Epoch 249: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.2535 - accuracy: 0.8738 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9914 - recall: 0.9134 - precision: 0.8467 - val_loss: 1.0101 - val_accuracy: 0.6430 - val_sensitivity_at_specificity: 0.7890 - val_specificity_at_sensitivity: 0.7545 - val_recall: 0.9525 - val_precision: 0.6013\n",
            "Epoch 250/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2621 - accuracy: 0.8719 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9844 - recall: 0.9329 - precision: 0.8316\n",
            "Epoch 250: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.2621 - accuracy: 0.8719 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9844 - recall: 0.9329 - precision: 0.8316 - val_loss: 0.8752 - val_accuracy: 0.6320 - val_sensitivity_at_specificity: 0.8141 - val_specificity_at_sensitivity: 0.7969 - val_recall: 0.9078 - val_precision: 0.5851\n",
            "Epoch 251/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2731 - accuracy: 0.8613 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9851 - recall: 0.9108 - precision: 0.8303\n",
            "Epoch 251: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.2731 - accuracy: 0.8613 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9851 - recall: 0.9108 - precision: 0.8303 - val_loss: 0.7366 - val_accuracy: 0.6687 - val_sensitivity_at_specificity: 0.8673 - val_specificity_at_sensitivity: 0.8399 - val_recall: 0.8916 - val_precision: 0.6068\n",
            "Epoch 252/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2525 - accuracy: 0.8730 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9930 - recall: 0.9157 - precision: 0.8420\n",
            "Epoch 252: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.2525 - accuracy: 0.8730 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9930 - recall: 0.9157 - precision: 0.8420 - val_loss: 0.8718 - val_accuracy: 0.6492 - val_sensitivity_at_specificity: 0.8214 - val_specificity_at_sensitivity: 0.7744 - val_recall: 0.9298 - val_precision: 0.6018\n",
            "Epoch 253/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2440 - accuracy: 0.8828 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9930 - recall: 0.9441 - precision: 0.8397\n",
            "Epoch 253: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.2440 - accuracy: 0.8828 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9930 - recall: 0.9441 - precision: 0.8397 - val_loss: 0.8116 - val_accuracy: 0.6711 - val_sensitivity_at_specificity: 0.8553 - val_specificity_at_sensitivity: 0.8280 - val_recall: 0.9475 - val_precision: 0.6057\n",
            "Epoch 254/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2529 - accuracy: 0.8738 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9953 - recall: 0.9349 - precision: 0.8346\n",
            "Epoch 254: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.2529 - accuracy: 0.8738 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9953 - recall: 0.9349 - precision: 0.8346 - val_loss: 1.0523 - val_accuracy: 0.6133 - val_sensitivity_at_specificity: 0.7849 - val_specificity_at_sensitivity: 0.7123 - val_recall: 0.9101 - val_precision: 0.5636\n",
            "Epoch 255/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2588 - accuracy: 0.8766 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9911 - recall: 0.9143 - precision: 0.8558\n",
            "Epoch 255: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.2588 - accuracy: 0.8766 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9911 - recall: 0.9143 - precision: 0.8558 - val_loss: 1.0508 - val_accuracy: 0.6492 - val_sensitivity_at_specificity: 0.8388 - val_specificity_at_sensitivity: 0.7568 - val_recall: 0.9414 - val_precision: 0.5832\n",
            "Epoch 256/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2475 - accuracy: 0.8789 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9946 - recall: 0.9082 - precision: 0.8570\n",
            "Epoch 256: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.2475 - accuracy: 0.8789 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9946 - recall: 0.9082 - precision: 0.8570 - val_loss: 1.0637 - val_accuracy: 0.6406 - val_sensitivity_at_specificity: 0.8288 - val_specificity_at_sensitivity: 0.7565 - val_recall: 0.9273 - val_precision: 0.5977\n",
            "Epoch 257/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2499 - accuracy: 0.8805 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9930 - recall: 0.9235 - precision: 0.8486\n",
            "Epoch 257: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 180ms/step - loss: 0.2499 - accuracy: 0.8805 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9930 - recall: 0.9235 - precision: 0.8486 - val_loss: 1.1005 - val_accuracy: 0.6078 - val_sensitivity_at_specificity: 0.7680 - val_specificity_at_sensitivity: 0.7313 - val_recall: 0.9524 - val_precision: 0.5683\n",
            "Epoch 258/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2619 - accuracy: 0.8687 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9891 - recall: 0.9043 - precision: 0.8435\n",
            "Epoch 258: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.2619 - accuracy: 0.8687 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9891 - recall: 0.9043 - precision: 0.8435 - val_loss: 0.9801 - val_accuracy: 0.6258 - val_sensitivity_at_specificity: 0.8071 - val_specificity_at_sensitivity: 0.7642 - val_recall: 0.9290 - val_precision: 0.5816\n",
            "Epoch 259/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2515 - accuracy: 0.8754 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9931 - recall: 0.9105 - precision: 0.8480\n",
            "Epoch 259: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.2515 - accuracy: 0.8754 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9931 - recall: 0.9105 - precision: 0.8480 - val_loss: 0.9637 - val_accuracy: 0.6352 - val_sensitivity_at_specificity: 0.7786 - val_specificity_at_sensitivity: 0.7744 - val_recall: 0.9288 - val_precision: 0.5877\n",
            "Epoch 260/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2501 - accuracy: 0.8805 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9926 - recall: 0.9247 - precision: 0.8387\n",
            "Epoch 260: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.2501 - accuracy: 0.8805 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9926 - recall: 0.9247 - precision: 0.8387 - val_loss: 1.0198 - val_accuracy: 0.6352 - val_sensitivity_at_specificity: 0.8073 - val_specificity_at_sensitivity: 0.7682 - val_recall: 0.8973 - val_precision: 0.5856\n",
            "Epoch 261/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2410 - accuracy: 0.8820 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9945 - recall: 0.9047 - precision: 0.8670\n",
            "Epoch 261: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.2410 - accuracy: 0.8820 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9945 - recall: 0.9047 - precision: 0.8670 - val_loss: 1.0368 - val_accuracy: 0.6234 - val_sensitivity_at_specificity: 0.7843 - val_specificity_at_sensitivity: 0.7132 - val_recall: 0.8721 - val_precision: 0.5865\n",
            "Epoch 262/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2495 - accuracy: 0.8797 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9905 - recall: 0.9053 - precision: 0.8641\n",
            "Epoch 262: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.2495 - accuracy: 0.8797 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9905 - recall: 0.9053 - precision: 0.8641 - val_loss: 1.1569 - val_accuracy: 0.5891 - val_sensitivity_at_specificity: 0.7681 - val_specificity_at_sensitivity: 0.7314 - val_recall: 0.9533 - val_precision: 0.5436\n",
            "Epoch 263/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2491 - accuracy: 0.8742 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9930 - recall: 0.9365 - precision: 0.8321\n",
            "Epoch 263: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.2491 - accuracy: 0.8742 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9930 - recall: 0.9365 - precision: 0.8321 - val_loss: 1.1198 - val_accuracy: 0.6297 - val_sensitivity_at_specificity: 0.7864 - val_specificity_at_sensitivity: 0.7452 - val_recall: 0.9682 - val_precision: 0.5852\n",
            "Epoch 264/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2529 - accuracy: 0.8754 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9906 - recall: 0.9306 - precision: 0.8384\n",
            "Epoch 264: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.2529 - accuracy: 0.8754 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9906 - recall: 0.9306 - precision: 0.8384 - val_loss: 1.1993 - val_accuracy: 0.6281 - val_sensitivity_at_specificity: 0.7672 - val_specificity_at_sensitivity: 0.7328 - val_recall: 0.9359 - val_precision: 0.5793\n",
            "Epoch 265/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2608 - accuracy: 0.8727 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9902 - recall: 0.8811 - precision: 0.8588\n",
            "Epoch 265: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.2608 - accuracy: 0.8727 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9902 - recall: 0.8811 - precision: 0.8588 - val_loss: 0.9370 - val_accuracy: 0.6234 - val_sensitivity_at_specificity: 0.7846 - val_specificity_at_sensitivity: 0.7702 - val_recall: 0.9072 - val_precision: 0.5770\n",
            "Epoch 266/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2489 - accuracy: 0.8703 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9937 - recall: 0.9146 - precision: 0.8414\n",
            "Epoch 266: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.2489 - accuracy: 0.8703 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9937 - recall: 0.9146 - precision: 0.8414 - val_loss: 1.0351 - val_accuracy: 0.6289 - val_sensitivity_at_specificity: 0.8021 - val_specificity_at_sensitivity: 0.7818 - val_recall: 0.9586 - val_precision: 0.5825\n",
            "Epoch 267/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2427 - accuracy: 0.8750 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9961 - recall: 0.9387 - precision: 0.8338\n",
            "Epoch 267: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.2427 - accuracy: 0.8750 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9961 - recall: 0.9387 - precision: 0.8338 - val_loss: 0.9806 - val_accuracy: 0.6219 - val_sensitivity_at_specificity: 0.7687 - val_specificity_at_sensitivity: 0.7565 - val_recall: 0.8931 - val_precision: 0.5732\n",
            "Epoch 268/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2348 - accuracy: 0.8859 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9936 - recall: 0.9340 - precision: 0.8553\n",
            "Epoch 268: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.2348 - accuracy: 0.8859 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9936 - recall: 0.9340 - precision: 0.8553 - val_loss: 0.9677 - val_accuracy: 0.6008 - val_sensitivity_at_specificity: 0.7504 - val_specificity_at_sensitivity: 0.7151 - val_recall: 0.8940 - val_precision: 0.5513\n",
            "Epoch 269/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2434 - accuracy: 0.8792 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9934 - recall: 0.9322 - precision: 0.8413\n",
            "Epoch 269: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 157ms/step - loss: 0.2434 - accuracy: 0.8792 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9934 - recall: 0.9322 - precision: 0.8413 - val_loss: 1.0335 - val_accuracy: 0.6234 - val_sensitivity_at_specificity: 0.7700 - val_specificity_at_sensitivity: 0.7569 - val_recall: 0.9329 - val_precision: 0.5703\n",
            "Epoch 270/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2566 - accuracy: 0.8820 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9871 - recall: 0.9141 - precision: 0.8642\n",
            "Epoch 270: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.2566 - accuracy: 0.8820 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9871 - recall: 0.9141 - precision: 0.8642 - val_loss: 1.0149 - val_accuracy: 0.6250 - val_sensitivity_at_specificity: 0.7917 - val_specificity_at_sensitivity: 0.7470 - val_recall: 0.8990 - val_precision: 0.5736\n",
            "Epoch 271/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2391 - accuracy: 0.8852 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9902 - recall: 0.9224 - precision: 0.8521\n",
            "Epoch 271: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.2391 - accuracy: 0.8852 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9902 - recall: 0.9224 - precision: 0.8521 - val_loss: 0.9927 - val_accuracy: 0.6508 - val_sensitivity_at_specificity: 0.8393 - val_specificity_at_sensitivity: 0.7769 - val_recall: 0.9369 - val_precision: 0.6064\n",
            "Epoch 272/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2531 - accuracy: 0.8758 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9945 - recall: 0.9237 - precision: 0.8456\n",
            "Epoch 272: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.2531 - accuracy: 0.8758 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9945 - recall: 0.9237 - precision: 0.8456 - val_loss: 1.1490 - val_accuracy: 0.6211 - val_sensitivity_at_specificity: 0.7320 - val_specificity_at_sensitivity: 0.7209 - val_recall: 0.9709 - val_precision: 0.5764\n",
            "Epoch 273/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2412 - accuracy: 0.8773 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9946 - recall: 0.9346 - precision: 0.8346\n",
            "Epoch 273: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.2412 - accuracy: 0.8773 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9946 - recall: 0.9346 - precision: 0.8346 - val_loss: 1.0902 - val_accuracy: 0.6422 - val_sensitivity_at_specificity: 0.7791 - val_specificity_at_sensitivity: 0.7213 - val_recall: 0.9388 - val_precision: 0.6013\n",
            "Epoch 274/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2523 - accuracy: 0.8801 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9908 - recall: 0.9135 - precision: 0.8532\n",
            "Epoch 274: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.2523 - accuracy: 0.8801 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9908 - recall: 0.9135 - precision: 0.8532 - val_loss: 1.1620 - val_accuracy: 0.6117 - val_sensitivity_at_specificity: 0.7500 - val_specificity_at_sensitivity: 0.7288 - val_recall: 0.9596 - val_precision: 0.5770\n",
            "Epoch 275/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2342 - accuracy: 0.8887 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9922 - recall: 0.9517 - precision: 0.8456\n",
            "Epoch 275: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 213ms/step - loss: 0.2342 - accuracy: 0.8887 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9922 - recall: 0.9517 - precision: 0.8456 - val_loss: 1.0673 - val_accuracy: 0.6281 - val_sensitivity_at_specificity: 0.8309 - val_specificity_at_sensitivity: 0.7451 - val_recall: 0.9581 - val_precision: 0.5694\n",
            "Epoch 276/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2342 - accuracy: 0.8910 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9945 - recall: 0.9209 - precision: 0.8685\n",
            "Epoch 276: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.2342 - accuracy: 0.8910 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9945 - recall: 0.9209 - precision: 0.8685 - val_loss: 1.0223 - val_accuracy: 0.6531 - val_sensitivity_at_specificity: 0.8364 - val_specificity_at_sensitivity: 0.7864 - val_recall: 0.9506 - val_precision: 0.5992\n",
            "Epoch 277/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2406 - accuracy: 0.8813 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9962 - recall: 0.9088 - precision: 0.8567\n",
            "Epoch 277: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.2406 - accuracy: 0.8813 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9962 - recall: 0.9088 - precision: 0.8567 - val_loss: 1.1082 - val_accuracy: 0.6281 - val_sensitivity_at_specificity: 0.8000 - val_specificity_at_sensitivity: 0.7359 - val_recall: 0.9156 - val_precision: 0.5813\n",
            "Epoch 278/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2289 - accuracy: 0.8902 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9961 - recall: 0.9283 - precision: 0.8630\n",
            "Epoch 278: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.2289 - accuracy: 0.8902 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9961 - recall: 0.9283 - precision: 0.8630 - val_loss: 1.1412 - val_accuracy: 0.6555 - val_sensitivity_at_specificity: 0.8421 - val_specificity_at_sensitivity: 0.7508 - val_recall: 0.9427 - val_precision: 0.6012\n",
            "Epoch 279/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2361 - accuracy: 0.8844 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9930 - recall: 0.9179 - precision: 0.8601\n",
            "Epoch 279: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.2361 - accuracy: 0.8844 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9930 - recall: 0.9179 - precision: 0.8601 - val_loss: 1.1432 - val_accuracy: 0.6250 - val_sensitivity_at_specificity: 0.7885 - val_specificity_at_sensitivity: 0.7488 - val_recall: 0.9409 - val_precision: 0.5778\n",
            "Epoch 280/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2439 - accuracy: 0.8895 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9927 - recall: 0.9092 - precision: 0.8708\n",
            "Epoch 280: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.2439 - accuracy: 0.8895 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9927 - recall: 0.9092 - precision: 0.8708 - val_loss: 1.0644 - val_accuracy: 0.6234 - val_sensitivity_at_specificity: 0.7956 - val_specificity_at_sensitivity: 0.7733 - val_recall: 0.9182 - val_precision: 0.5759\n",
            "Epoch 281/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2322 - accuracy: 0.8895 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9898 - recall: 0.9364 - precision: 0.8573\n",
            "Epoch 281: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.2322 - accuracy: 0.8895 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9898 - recall: 0.9364 - precision: 0.8573 - val_loss: 0.9393 - val_accuracy: 0.6305 - val_sensitivity_at_specificity: 0.8013 - val_specificity_at_sensitivity: 0.7805 - val_recall: 0.9038 - val_precision: 0.5773\n",
            "Epoch 282/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2567 - accuracy: 0.8742 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9852 - recall: 0.9097 - precision: 0.8484\n",
            "Epoch 282: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.2567 - accuracy: 0.8742 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9852 - recall: 0.9097 - precision: 0.8484 - val_loss: 1.0463 - val_accuracy: 0.6164 - val_sensitivity_at_specificity: 0.7374 - val_specificity_at_sensitivity: 0.7127 - val_recall: 0.9544 - val_precision: 0.5678\n",
            "Epoch 283/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2429 - accuracy: 0.8887 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9945 - recall: 0.9344 - precision: 0.8582\n",
            "Epoch 283: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.2429 - accuracy: 0.8887 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9945 - recall: 0.9344 - precision: 0.8582 - val_loss: 1.1970 - val_accuracy: 0.6172 - val_sensitivity_at_specificity: 0.7425 - val_specificity_at_sensitivity: 0.7045 - val_recall: 0.9247 - val_precision: 0.5825\n",
            "Epoch 284/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2383 - accuracy: 0.8809 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9953 - recall: 0.9139 - precision: 0.8568\n",
            "Epoch 284: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.2383 - accuracy: 0.8809 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9953 - recall: 0.9139 - precision: 0.8568 - val_loss: 1.0389 - val_accuracy: 0.6500 - val_sensitivity_at_specificity: 0.8652 - val_specificity_at_sensitivity: 0.7943 - val_recall: 0.9571 - val_precision: 0.5981\n",
            "Epoch 285/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2471 - accuracy: 0.8797 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9910 - recall: 0.9148 - precision: 0.8474\n",
            "Epoch 285: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.2471 - accuracy: 0.8797 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9910 - recall: 0.9148 - precision: 0.8474 - val_loss: 0.9196 - val_accuracy: 0.6320 - val_sensitivity_at_specificity: 0.7962 - val_specificity_at_sensitivity: 0.7561 - val_recall: 0.9252 - val_precision: 0.5781\n",
            "Epoch 286/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2490 - accuracy: 0.8766 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9921 - recall: 0.9262 - precision: 0.8455\n",
            "Epoch 286: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.2490 - accuracy: 0.8766 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9921 - recall: 0.9262 - precision: 0.8455 - val_loss: 1.0372 - val_accuracy: 0.6109 - val_sensitivity_at_specificity: 0.7531 - val_specificity_at_sensitivity: 0.7469 - val_recall: 0.9245 - val_precision: 0.5665\n",
            "Epoch 287/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2302 - accuracy: 0.8844 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9976 - recall: 0.9261 - precision: 0.8556\n",
            "Epoch 287: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.2302 - accuracy: 0.8844 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9976 - recall: 0.9261 - precision: 0.8556 - val_loss: 1.1427 - val_accuracy: 0.6156 - val_sensitivity_at_specificity: 0.7805 - val_specificity_at_sensitivity: 0.7580 - val_recall: 0.9604 - val_precision: 0.5748\n",
            "Epoch 288/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2296 - accuracy: 0.8863 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9970 - recall: 0.9319 - precision: 0.8495\n",
            "Epoch 288: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.2296 - accuracy: 0.8863 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9970 - recall: 0.9319 - precision: 0.8495 - val_loss: 1.1654 - val_accuracy: 0.6398 - val_sensitivity_at_specificity: 0.8055 - val_specificity_at_sensitivity: 0.7283 - val_recall: 0.9438 - val_precision: 0.5943\n",
            "Epoch 289/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2620 - accuracy: 0.8699 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9868 - recall: 0.9062 - precision: 0.8431\n",
            "Epoch 289: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.2620 - accuracy: 0.8699 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9868 - recall: 0.9062 - precision: 0.8431 - val_loss: 1.1203 - val_accuracy: 0.6016 - val_sensitivity_at_specificity: 0.7531 - val_specificity_at_sensitivity: 0.7344 - val_recall: 0.9438 - val_precision: 0.5603\n",
            "Epoch 290/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2267 - accuracy: 0.8930 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9961 - recall: 0.9351 - precision: 0.8623\n",
            "Epoch 290: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.2267 - accuracy: 0.8930 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9961 - recall: 0.9351 - precision: 0.8623 - val_loss: 1.1988 - val_accuracy: 0.6172 - val_sensitivity_at_specificity: 0.8138 - val_specificity_at_sensitivity: 0.7613 - val_recall: 0.9640 - val_precision: 0.5688\n",
            "Epoch 291/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2420 - accuracy: 0.8898 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9929 - recall: 0.9295 - precision: 0.8627\n",
            "Epoch 291: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.2420 - accuracy: 0.8898 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9929 - recall: 0.9295 - precision: 0.8627 - val_loss: 0.9148 - val_accuracy: 0.6352 - val_sensitivity_at_specificity: 0.8130 - val_specificity_at_sensitivity: 0.7553 - val_recall: 0.8959 - val_precision: 0.5988\n",
            "Epoch 292/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2133 - accuracy: 0.9059 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9969 - recall: 0.9412 - precision: 0.8785\n",
            "Epoch 292: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.2133 - accuracy: 0.9059 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9969 - recall: 0.9412 - precision: 0.8785 - val_loss: 1.2263 - val_accuracy: 0.6297 - val_sensitivity_at_specificity: 0.7973 - val_specificity_at_sensitivity: 0.7715 - val_recall: 0.9601 - val_precision: 0.5922\n",
            "Epoch 293/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2345 - accuracy: 0.8816 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9968 - recall: 0.9151 - precision: 0.8618\n",
            "Epoch 293: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.2345 - accuracy: 0.8816 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9968 - recall: 0.9151 - precision: 0.8618 - val_loss: 1.0843 - val_accuracy: 0.6289 - val_sensitivity_at_specificity: 0.8031 - val_specificity_at_sensitivity: 0.7628 - val_recall: 0.9386 - val_precision: 0.5775\n",
            "Epoch 294/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2298 - accuracy: 0.8929 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9208 - precision: 0.8695\n",
            "Epoch 294: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.2298 - accuracy: 0.8929 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9208 - precision: 0.8695 - val_loss: 1.1014 - val_accuracy: 0.6164 - val_sensitivity_at_specificity: 0.7594 - val_specificity_at_sensitivity: 0.7360 - val_recall: 0.8852 - val_precision: 0.5739\n",
            "Epoch 295/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2219 - accuracy: 0.8910 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9977 - recall: 0.9216 - precision: 0.8679\n",
            "Epoch 295: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.2219 - accuracy: 0.8910 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9977 - recall: 0.9216 - precision: 0.8679 - val_loss: 1.3824 - val_accuracy: 0.5883 - val_sensitivity_at_specificity: 0.7828 - val_specificity_at_sensitivity: 0.7420 - val_recall: 0.9411 - val_precision: 0.5319\n",
            "Epoch 296/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2367 - accuracy: 0.8895 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9961 - recall: 0.9186 - precision: 0.8694\n",
            "Epoch 296: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.2367 - accuracy: 0.8895 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9961 - recall: 0.9186 - precision: 0.8694 - val_loss: 1.1260 - val_accuracy: 0.6406 - val_sensitivity_at_specificity: 0.8031 - val_specificity_at_sensitivity: 0.7504 - val_recall: 0.9603 - val_precision: 0.5917\n",
            "Epoch 297/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2142 - accuracy: 0.9023 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9976 - recall: 0.9402 - precision: 0.8791\n",
            "Epoch 297: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.2142 - accuracy: 0.9023 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9976 - recall: 0.9402 - precision: 0.8791 - val_loss: 1.2166 - val_accuracy: 0.6266 - val_sensitivity_at_specificity: 0.7979 - val_specificity_at_sensitivity: 0.7578 - val_recall: 0.9584 - val_precision: 0.5890\n",
            "Epoch 298/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2133 - accuracy: 0.8962 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9201 - precision: 0.8813\n",
            "Epoch 298: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.2133 - accuracy: 0.8962 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9201 - precision: 0.8813 - val_loss: 1.3645 - val_accuracy: 0.6141 - val_sensitivity_at_specificity: 0.7586 - val_specificity_at_sensitivity: 0.7406 - val_recall: 0.9329 - val_precision: 0.5823\n",
            "Epoch 299/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2279 - accuracy: 0.8918 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9211 - precision: 0.8701\n",
            "Epoch 299: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.2279 - accuracy: 0.8918 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9211 - precision: 0.8701 - val_loss: 1.4563 - val_accuracy: 0.5875 - val_sensitivity_at_specificity: 0.7480 - val_specificity_at_sensitivity: 0.6707 - val_recall: 0.9431 - val_precision: 0.5405\n",
            "Epoch 300/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2129 - accuracy: 0.8965 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9256 - precision: 0.8760\n",
            "Epoch 300: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.2129 - accuracy: 0.8965 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9256 - precision: 0.8760 - val_loss: 1.0924 - val_accuracy: 0.6453 - val_sensitivity_at_specificity: 0.8454 - val_specificity_at_sensitivity: 0.7804 - val_recall: 0.9227 - val_precision: 0.5964\n",
            "Epoch 301/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2463 - accuracy: 0.8850 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9942 - recall: 0.9103 - precision: 0.8664\n",
            "Epoch 301: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 153ms/step - loss: 0.2463 - accuracy: 0.8850 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9942 - recall: 0.9103 - precision: 0.8664 - val_loss: 1.1616 - val_accuracy: 0.6328 - val_sensitivity_at_specificity: 0.7848 - val_specificity_at_sensitivity: 0.7177 - val_recall: 0.9350 - val_precision: 0.5853\n",
            "Epoch 302/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2269 - accuracy: 0.8883 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9914 - recall: 0.9101 - precision: 0.8719\n",
            "Epoch 302: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.2269 - accuracy: 0.8883 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9914 - recall: 0.9101 - precision: 0.8719 - val_loss: 1.2562 - val_accuracy: 0.6164 - val_sensitivity_at_specificity: 0.7591 - val_specificity_at_sensitivity: 0.7411 - val_recall: 0.9271 - val_precision: 0.5680\n",
            "Epoch 303/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2030 - accuracy: 0.9078 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9257 - precision: 0.8901\n",
            "Epoch 303: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.2030 - accuracy: 0.9078 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9257 - precision: 0.8901 - val_loss: 1.1749 - val_accuracy: 0.6492 - val_sensitivity_at_specificity: 0.8431 - val_specificity_at_sensitivity: 0.7797 - val_recall: 0.9509 - val_precision: 0.5894\n",
            "Epoch 304/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2290 - accuracy: 0.8891 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9969 - recall: 0.9165 - precision: 0.8691\n",
            "Epoch 304: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.2290 - accuracy: 0.8891 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9969 - recall: 0.9165 - precision: 0.8691 - val_loss: 1.2486 - val_accuracy: 0.6023 - val_sensitivity_at_specificity: 0.7504 - val_specificity_at_sensitivity: 0.7049 - val_recall: 0.9311 - val_precision: 0.5672\n",
            "Epoch 305/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2352 - accuracy: 0.8883 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9210 - precision: 0.8677\n",
            "Epoch 305: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.2352 - accuracy: 0.8883 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9210 - precision: 0.8677 - val_loss: 1.2855 - val_accuracy: 0.6250 - val_sensitivity_at_specificity: 0.7473 - val_specificity_at_sensitivity: 0.7027 - val_recall: 0.9251 - val_precision: 0.5785\n",
            "Epoch 306/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2180 - accuracy: 0.9047 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9960 - recall: 0.9325 - precision: 0.8881\n",
            "Epoch 306: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.2180 - accuracy: 0.9047 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9960 - recall: 0.9325 - precision: 0.8881 - val_loss: 1.4400 - val_accuracy: 0.6008 - val_sensitivity_at_specificity: 0.7347 - val_specificity_at_sensitivity: 0.6921 - val_recall: 0.9592 - val_precision: 0.5575\n",
            "Epoch 307/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2402 - accuracy: 0.8808 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9941 - recall: 0.9044 - precision: 0.8669\n",
            "Epoch 307: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.2402 - accuracy: 0.8808 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9941 - recall: 0.9044 - precision: 0.8669 - val_loss: 1.1130 - val_accuracy: 0.6414 - val_sensitivity_at_specificity: 0.7346 - val_specificity_at_sensitivity: 0.6867 - val_recall: 0.9090 - val_precision: 0.5956\n",
            "Epoch 308/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2301 - accuracy: 0.8957 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9953 - recall: 0.9261 - precision: 0.8719\n",
            "Epoch 308: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.2301 - accuracy: 0.8957 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9953 - recall: 0.9261 - precision: 0.8719 - val_loss: 1.0614 - val_accuracy: 0.6320 - val_sensitivity_at_specificity: 0.8124 - val_specificity_at_sensitivity: 0.7556 - val_recall: 0.9135 - val_precision: 0.5726\n",
            "Epoch 309/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2182 - accuracy: 0.8953 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9554 - precision: 0.8555\n",
            "Epoch 309: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.2182 - accuracy: 0.8953 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9554 - precision: 0.8555 - val_loss: 1.0662 - val_accuracy: 0.6266 - val_sensitivity_at_specificity: 0.7373 - val_specificity_at_sensitivity: 0.7107 - val_recall: 0.8771 - val_precision: 0.5893\n",
            "Epoch 310/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2082 - accuracy: 0.9055 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9984 - recall: 0.9240 - precision: 0.8906\n",
            "Epoch 310: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.2082 - accuracy: 0.9055 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9984 - recall: 0.9240 - precision: 0.8906 - val_loss: 1.3295 - val_accuracy: 0.6219 - val_sensitivity_at_specificity: 0.7703 - val_specificity_at_sensitivity: 0.7134 - val_recall: 0.9369 - val_precision: 0.5854\n",
            "Epoch 311/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2000 - accuracy: 0.9066 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9363 - precision: 0.8864\n",
            "Epoch 311: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 154ms/step - loss: 0.2000 - accuracy: 0.9066 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9363 - precision: 0.8864 - val_loss: 1.2649 - val_accuracy: 0.6242 - val_sensitivity_at_specificity: 0.8222 - val_specificity_at_sensitivity: 0.7480 - val_recall: 0.9407 - val_precision: 0.5765\n",
            "Epoch 312/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2006 - accuracy: 0.9043 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9971 - recall: 0.9162 - precision: 0.8830\n",
            "Epoch 312: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.2006 - accuracy: 0.9043 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9971 - recall: 0.9162 - precision: 0.8830 - val_loss: 1.2895 - val_accuracy: 0.6125 - val_sensitivity_at_specificity: 0.7849 - val_specificity_at_sensitivity: 0.7641 - val_recall: 0.9567 - val_precision: 0.5596\n",
            "Epoch 313/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2051 - accuracy: 0.9066 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9970 - recall: 0.9293 - precision: 0.8846\n",
            "Epoch 313: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.2051 - accuracy: 0.9066 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9970 - recall: 0.9293 - precision: 0.8846 - val_loss: 1.2717 - val_accuracy: 0.6383 - val_sensitivity_at_specificity: 0.7889 - val_specificity_at_sensitivity: 0.7206 - val_recall: 0.9341 - val_precision: 0.5983\n",
            "Epoch 314/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2168 - accuracy: 0.8961 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9969 - recall: 0.9212 - precision: 0.8757\n",
            "Epoch 314: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.2168 - accuracy: 0.8961 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9969 - recall: 0.9212 - precision: 0.8757 - val_loss: 1.2624 - val_accuracy: 0.6070 - val_sensitivity_at_specificity: 0.7152 - val_specificity_at_sensitivity: 0.7222 - val_recall: 0.8956 - val_precision: 0.5643\n",
            "Epoch 315/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2062 - accuracy: 0.9035 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9243 - precision: 0.8893\n",
            "Epoch 315: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.2062 - accuracy: 0.9035 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9243 - precision: 0.8893 - val_loss: 1.5322 - val_accuracy: 0.6156 - val_sensitivity_at_specificity: 0.7524 - val_specificity_at_sensitivity: 0.7188 - val_recall: 0.9212 - val_precision: 0.5640\n",
            "Epoch 316/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2139 - accuracy: 0.9047 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9955 - recall: 0.9151 - precision: 0.8890\n",
            "Epoch 316: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 181ms/step - loss: 0.2139 - accuracy: 0.9047 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9955 - recall: 0.9151 - precision: 0.8890 - val_loss: 1.2236 - val_accuracy: 0.6367 - val_sensitivity_at_specificity: 0.8104 - val_specificity_at_sensitivity: 0.7450 - val_recall: 0.9573 - val_precision: 0.5805\n",
            "Epoch 317/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2087 - accuracy: 0.9059 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9977 - recall: 0.9275 - precision: 0.8894\n",
            "Epoch 317: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.2087 - accuracy: 0.9059 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9977 - recall: 0.9275 - precision: 0.8894 - val_loss: 1.2161 - val_accuracy: 0.6273 - val_sensitivity_at_specificity: 0.8024 - val_specificity_at_sensitivity: 0.7331 - val_recall: 0.9271 - val_precision: 0.5871\n",
            "Epoch 318/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2055 - accuracy: 0.9078 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9288 - precision: 0.8911\n",
            "Epoch 318: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 181ms/step - loss: 0.2055 - accuracy: 0.9078 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9288 - precision: 0.8911 - val_loss: 1.3736 - val_accuracy: 0.6078 - val_sensitivity_at_specificity: 0.7480 - val_specificity_at_sensitivity: 0.7458 - val_recall: 0.9370 - val_precision: 0.5561\n",
            "Epoch 319/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2073 - accuracy: 0.9055 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9968 - recall: 0.9286 - precision: 0.8920\n",
            "Epoch 319: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.2073 - accuracy: 0.9055 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9968 - recall: 0.9286 - precision: 0.8920 - val_loss: 1.2285 - val_accuracy: 0.6297 - val_sensitivity_at_specificity: 0.7729 - val_specificity_at_sensitivity: 0.7468 - val_recall: 0.9405 - val_precision: 0.5865\n",
            "Epoch 320/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1924 - accuracy: 0.9113 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9380 - precision: 0.8953\n",
            "Epoch 320: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.1924 - accuracy: 0.9113 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9380 - precision: 0.8953 - val_loss: 1.2642 - val_accuracy: 0.6203 - val_sensitivity_at_specificity: 0.8197 - val_specificity_at_sensitivity: 0.7866 - val_recall: 0.9483 - val_precision: 0.5718\n",
            "Epoch 321/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2039 - accuracy: 0.9016 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9969 - recall: 0.9340 - precision: 0.8743\n",
            "Epoch 321: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.2039 - accuracy: 0.9016 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9969 - recall: 0.9340 - precision: 0.8743 - val_loss: 1.1680 - val_accuracy: 0.6367 - val_sensitivity_at_specificity: 0.7784 - val_specificity_at_sensitivity: 0.7430 - val_recall: 0.9350 - val_precision: 0.6006\n",
            "Epoch 322/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1957 - accuracy: 0.9098 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9969 - recall: 0.9321 - precision: 0.8906\n",
            "Epoch 322: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.1957 - accuracy: 0.9098 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9969 - recall: 0.9321 - precision: 0.8906 - val_loss: 1.1134 - val_accuracy: 0.6398 - val_sensitivity_at_specificity: 0.8083 - val_specificity_at_sensitivity: 0.7741 - val_recall: 0.9042 - val_precision: 0.5945\n",
            "Epoch 323/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1890 - accuracy: 0.9141 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9969 - recall: 0.9324 - precision: 0.9002\n",
            "Epoch 323: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.1890 - accuracy: 0.9141 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9969 - recall: 0.9324 - precision: 0.9002 - val_loss: 1.3737 - val_accuracy: 0.6320 - val_sensitivity_at_specificity: 0.8067 - val_specificity_at_sensitivity: 0.7436 - val_recall: 0.9494 - val_precision: 0.5856\n",
            "Epoch 324/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1966 - accuracy: 0.9125 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9939 - recall: 0.9268 - precision: 0.8981\n",
            "Epoch 324: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.1966 - accuracy: 0.9125 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9939 - recall: 0.9268 - precision: 0.8981 - val_loss: 1.5613 - val_accuracy: 0.5867 - val_sensitivity_at_specificity: 0.7404 - val_specificity_at_sensitivity: 0.6921 - val_recall: 0.9311 - val_precision: 0.5445\n",
            "Epoch 325/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2003 - accuracy: 0.9047 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9179 - precision: 0.8941\n",
            "Epoch 325: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.2003 - accuracy: 0.9047 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9179 - precision: 0.8941 - val_loss: 1.2821 - val_accuracy: 0.6172 - val_sensitivity_at_specificity: 0.7957 - val_specificity_at_sensitivity: 0.7393 - val_recall: 0.9171 - val_precision: 0.5779\n",
            "Epoch 326/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2003 - accuracy: 0.9008 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9977 - recall: 0.9194 - precision: 0.8845\n",
            "Epoch 326: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.2003 - accuracy: 0.9008 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9977 - recall: 0.9194 - precision: 0.8845 - val_loss: 1.3334 - val_accuracy: 0.6141 - val_sensitivity_at_specificity: 0.7812 - val_specificity_at_sensitivity: 0.7294 - val_recall: 0.9585 - val_precision: 0.5618\n",
            "Epoch 327/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1888 - accuracy: 0.9129 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9404 - precision: 0.8888\n",
            "Epoch 327: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.1888 - accuracy: 0.9129 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9404 - precision: 0.8888 - val_loss: 1.2473 - val_accuracy: 0.6250 - val_sensitivity_at_specificity: 0.7727 - val_specificity_at_sensitivity: 0.7186 - val_recall: 0.9171 - val_precision: 0.5836\n",
            "Epoch 328/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1927 - accuracy: 0.9113 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9288 - precision: 0.8989\n",
            "Epoch 328: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.1927 - accuracy: 0.9113 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9288 - precision: 0.8989 - val_loss: 1.0709 - val_accuracy: 0.6328 - val_sensitivity_at_specificity: 0.7945 - val_specificity_at_sensitivity: 0.7705 - val_recall: 0.8858 - val_precision: 0.5957\n",
            "Epoch 329/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1927 - accuracy: 0.9109 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9392 - precision: 0.8892\n",
            "Epoch 329: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.1927 - accuracy: 0.9109 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9392 - precision: 0.8892 - val_loss: 1.2268 - val_accuracy: 0.6117 - val_sensitivity_at_specificity: 0.7290 - val_specificity_at_sensitivity: 0.7163 - val_recall: 0.8769 - val_precision: 0.5739\n",
            "Epoch 330/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2021 - accuracy: 0.9066 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9334 - precision: 0.8891\n",
            "Epoch 330: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.2021 - accuracy: 0.9066 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9334 - precision: 0.8891 - val_loss: 1.2710 - val_accuracy: 0.6148 - val_sensitivity_at_specificity: 0.7368 - val_specificity_at_sensitivity: 0.6968 - val_recall: 0.8756 - val_precision: 0.5695\n",
            "Epoch 331/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1968 - accuracy: 0.9086 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9967 - recall: 0.9278 - precision: 0.9010\n",
            "Epoch 331: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 220ms/step - loss: 0.1968 - accuracy: 0.9086 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9967 - recall: 0.9278 - precision: 0.9010 - val_loss: 1.2646 - val_accuracy: 0.6328 - val_sensitivity_at_specificity: 0.7441 - val_specificity_at_sensitivity: 0.7481 - val_recall: 0.9011 - val_precision: 0.5851\n",
            "Epoch 332/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2006 - accuracy: 0.9047 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9266 - precision: 0.8842\n",
            "Epoch 332: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.2006 - accuracy: 0.9047 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9266 - precision: 0.8842 - val_loss: 1.2925 - val_accuracy: 0.6195 - val_sensitivity_at_specificity: 0.7542 - val_specificity_at_sensitivity: 0.7107 - val_recall: 0.9140 - val_precision: 0.5799\n",
            "Epoch 333/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1897 - accuracy: 0.9090 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9205 - precision: 0.8986\n",
            "Epoch 333: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.1897 - accuracy: 0.9090 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9205 - precision: 0.8986 - val_loss: 1.5349 - val_accuracy: 0.6133 - val_sensitivity_at_specificity: 0.7754 - val_specificity_at_sensitivity: 0.7134 - val_recall: 0.9499 - val_precision: 0.5754\n",
            "Epoch 334/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1771 - accuracy: 0.9187 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9329 - precision: 0.9074\n",
            "Epoch 334: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.1771 - accuracy: 0.9187 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9329 - precision: 0.9074 - val_loss: 1.3486 - val_accuracy: 0.6469 - val_sensitivity_at_specificity: 0.8144 - val_specificity_at_sensitivity: 0.7590 - val_recall: 0.9345 - val_precision: 0.5937\n",
            "Epoch 335/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1873 - accuracy: 0.9102 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9251 - precision: 0.9017\n",
            "Epoch 335: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.1873 - accuracy: 0.9102 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9251 - precision: 0.9017 - val_loss: 1.2510 - val_accuracy: 0.6047 - val_sensitivity_at_specificity: 0.6646 - val_specificity_at_sensitivity: 0.6872 - val_recall: 0.8934 - val_precision: 0.5695\n",
            "Epoch 336/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1913 - accuracy: 0.9164 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9414 - precision: 0.9003\n",
            "Epoch 336: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.1913 - accuracy: 0.9164 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9414 - precision: 0.9003 - val_loss: 1.1899 - val_accuracy: 0.6172 - val_sensitivity_at_specificity: 0.7734 - val_specificity_at_sensitivity: 0.7781 - val_recall: 0.9271 - val_precision: 0.5685\n",
            "Epoch 337/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2063 - accuracy: 0.9041 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9975 - recall: 0.9192 - precision: 0.8917\n",
            "Epoch 337: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.2063 - accuracy: 0.9041 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9975 - recall: 0.9192 - precision: 0.8917 - val_loss: 1.2664 - val_accuracy: 0.6414 - val_sensitivity_at_specificity: 0.7773 - val_specificity_at_sensitivity: 0.7757 - val_recall: 0.9322 - val_precision: 0.6048\n",
            "Epoch 338/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2036 - accuracy: 0.9066 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9241 - precision: 0.8944\n",
            "Epoch 338: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.2036 - accuracy: 0.9066 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9241 - precision: 0.8944 - val_loss: 1.3299 - val_accuracy: 0.6172 - val_sensitivity_at_specificity: 0.7621 - val_specificity_at_sensitivity: 0.7504 - val_recall: 0.9171 - val_precision: 0.5728\n",
            "Epoch 339/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1991 - accuracy: 0.9094 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9954 - recall: 0.9220 - precision: 0.8946\n",
            "Epoch 339: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.1991 - accuracy: 0.9094 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9954 - recall: 0.9220 - precision: 0.8946 - val_loss: 1.3201 - val_accuracy: 0.6484 - val_sensitivity_at_specificity: 0.7964 - val_specificity_at_sensitivity: 0.7533 - val_recall: 0.9461 - val_precision: 0.6042\n",
            "Epoch 340/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1921 - accuracy: 0.9148 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9962 - recall: 0.9243 - precision: 0.9025\n",
            "Epoch 340: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.1921 - accuracy: 0.9148 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9962 - recall: 0.9243 - precision: 0.9025 - val_loss: 1.4040 - val_accuracy: 0.5945 - val_sensitivity_at_specificity: 0.7567 - val_specificity_at_sensitivity: 0.7418 - val_recall: 0.9137 - val_precision: 0.5564\n",
            "Epoch 341/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1774 - accuracy: 0.9172 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9423 - precision: 0.8956\n",
            "Epoch 341: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.1774 - accuracy: 0.9172 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9423 - precision: 0.8956 - val_loss: 1.3901 - val_accuracy: 0.6133 - val_sensitivity_at_specificity: 0.7556 - val_specificity_at_sensitivity: 0.7568 - val_recall: 0.9228 - val_precision: 0.5622\n",
            "Epoch 342/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1972 - accuracy: 0.9105 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9969 - recall: 0.9358 - precision: 0.8905\n",
            "Epoch 342: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.1972 - accuracy: 0.9105 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9969 - recall: 0.9358 - precision: 0.8905 - val_loss: 1.3542 - val_accuracy: 0.6258 - val_sensitivity_at_specificity: 0.7573 - val_specificity_at_sensitivity: 0.7376 - val_recall: 0.9160 - val_precision: 0.5859\n",
            "Epoch 343/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1825 - accuracy: 0.9141 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9968 - recall: 0.9238 - precision: 0.9099\n",
            "Epoch 343: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.1825 - accuracy: 0.9141 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9968 - recall: 0.9238 - precision: 0.9099 - val_loss: 1.3992 - val_accuracy: 0.6125 - val_sensitivity_at_specificity: 0.7752 - val_specificity_at_sensitivity: 0.7428 - val_recall: 0.9450 - val_precision: 0.5733\n",
            "Epoch 344/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1954 - accuracy: 0.9039 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9252 - precision: 0.8861\n",
            "Epoch 344: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.1954 - accuracy: 0.9039 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9252 - precision: 0.8861 - val_loss: 1.5292 - val_accuracy: 0.6336 - val_sensitivity_at_specificity: 0.7274 - val_specificity_at_sensitivity: 0.7081 - val_recall: 0.9387 - val_precision: 0.5883\n",
            "Epoch 345/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1762 - accuracy: 0.9242 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9423 - precision: 0.9115\n",
            "Epoch 345: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.1762 - accuracy: 0.9242 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9423 - precision: 0.9115 - val_loss: 1.3775 - val_accuracy: 0.6289 - val_sensitivity_at_specificity: 0.7489 - val_specificity_at_sensitivity: 0.7382 - val_recall: 0.9383 - val_precision: 0.5898\n",
            "Epoch 346/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1997 - accuracy: 0.9078 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9280 - precision: 0.8900\n",
            "Epoch 346: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.1997 - accuracy: 0.9078 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9280 - precision: 0.8900 - val_loss: 1.3360 - val_accuracy: 0.6141 - val_sensitivity_at_specificity: 0.7791 - val_specificity_at_sensitivity: 0.7419 - val_recall: 0.9252 - val_precision: 0.5537\n",
            "Epoch 347/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1747 - accuracy: 0.9246 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9969 - recall: 0.9422 - precision: 0.9103\n",
            "Epoch 347: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.1747 - accuracy: 0.9246 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9969 - recall: 0.9422 - precision: 0.9103 - val_loss: 1.2423 - val_accuracy: 0.6359 - val_sensitivity_at_specificity: 0.8258 - val_specificity_at_sensitivity: 0.7975 - val_recall: 0.9362 - val_precision: 0.5862\n",
            "Epoch 348/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1987 - accuracy: 0.9094 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9969 - recall: 0.9267 - precision: 0.8926\n",
            "Epoch 348: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.1987 - accuracy: 0.9094 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9969 - recall: 0.9267 - precision: 0.8926 - val_loss: 1.1893 - val_accuracy: 0.6430 - val_sensitivity_at_specificity: 0.7925 - val_specificity_at_sensitivity: 0.7328 - val_recall: 0.8896 - val_precision: 0.6088\n",
            "Epoch 349/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1814 - accuracy: 0.9180 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9977 - recall: 0.9320 - precision: 0.9065\n",
            "Epoch 349: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.1814 - accuracy: 0.9180 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9977 - recall: 0.9320 - precision: 0.9065 - val_loss: 1.3551 - val_accuracy: 0.6180 - val_sensitivity_at_specificity: 0.7407 - val_specificity_at_sensitivity: 0.7136 - val_recall: 0.9151 - val_precision: 0.5774\n",
            "Epoch 350/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1836 - accuracy: 0.9184 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9984 - recall: 0.9453 - precision: 0.8969\n",
            "Epoch 350: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.1836 - accuracy: 0.9184 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9984 - recall: 0.9453 - precision: 0.8969 - val_loss: 1.3747 - val_accuracy: 0.6477 - val_sensitivity_at_specificity: 0.7848 - val_specificity_at_sensitivity: 0.7221 - val_recall: 0.9440 - val_precision: 0.6150\n",
            "Epoch 351/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1717 - accuracy: 0.9254 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9321 - precision: 0.9199\n",
            "Epoch 351: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.1717 - accuracy: 0.9254 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9321 - precision: 0.9199 - val_loss: 1.4788 - val_accuracy: 0.6367 - val_sensitivity_at_specificity: 0.7904 - val_specificity_at_sensitivity: 0.7296 - val_recall: 0.9627 - val_precision: 0.5844\n",
            "Epoch 352/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1742 - accuracy: 0.9227 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9379 - precision: 0.9111\n",
            "Epoch 352: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.1742 - accuracy: 0.9227 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9379 - precision: 0.9111 - val_loss: 1.4921 - val_accuracy: 0.6102 - val_sensitivity_at_specificity: 0.7488 - val_specificity_at_sensitivity: 0.7247 - val_recall: 0.9309 - val_precision: 0.5658\n",
            "Epoch 353/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1846 - accuracy: 0.9160 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9252 - precision: 0.9057\n",
            "Epoch 353: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.1846 - accuracy: 0.9160 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9252 - precision: 0.9057 - val_loss: 1.7067 - val_accuracy: 0.5930 - val_sensitivity_at_specificity: 0.7164 - val_specificity_at_sensitivity: 0.7134 - val_recall: 0.9238 - val_precision: 0.5460\n",
            "Epoch 354/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1755 - accuracy: 0.9273 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9977 - recall: 0.9308 - precision: 0.9220\n",
            "Epoch 354: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.1755 - accuracy: 0.9273 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9977 - recall: 0.9308 - precision: 0.9220 - val_loss: 1.6066 - val_accuracy: 0.5898 - val_sensitivity_at_specificity: 0.7352 - val_specificity_at_sensitivity: 0.7090 - val_recall: 0.9378 - val_precision: 0.5475\n",
            "Epoch 355/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1793 - accuracy: 0.9184 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9461 - precision: 0.9003\n",
            "Epoch 355: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.1793 - accuracy: 0.9184 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9461 - precision: 0.9003 - val_loss: 1.4370 - val_accuracy: 0.6250 - val_sensitivity_at_specificity: 0.7879 - val_specificity_at_sensitivity: 0.7458 - val_recall: 0.9522 - val_precision: 0.5702\n",
            "Epoch 356/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1837 - accuracy: 0.9117 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9342 - precision: 0.8936\n",
            "Epoch 356: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.1837 - accuracy: 0.9117 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9342 - precision: 0.8936 - val_loss: 1.1255 - val_accuracy: 0.6250 - val_sensitivity_at_specificity: 0.7675 - val_specificity_at_sensitivity: 0.7393 - val_recall: 0.8790 - val_precision: 0.5774\n",
            "Epoch 357/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1896 - accuracy: 0.9113 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9985 - recall: 0.9330 - precision: 0.8929\n",
            "Epoch 357: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.1896 - accuracy: 0.9113 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9985 - recall: 0.9330 - precision: 0.8929 - val_loss: 1.3744 - val_accuracy: 0.5953 - val_sensitivity_at_specificity: 0.7265 - val_specificity_at_sensitivity: 0.7024 - val_recall: 0.9369 - val_precision: 0.5473\n",
            "Epoch 358/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1763 - accuracy: 0.9238 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9977 - recall: 0.9351 - precision: 0.9144\n",
            "Epoch 358: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.1763 - accuracy: 0.9238 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9977 - recall: 0.9351 - precision: 0.9144 - val_loss: 1.5646 - val_accuracy: 0.6141 - val_sensitivity_at_specificity: 0.7592 - val_specificity_at_sensitivity: 0.7228 - val_recall: 0.9394 - val_precision: 0.5636\n",
            "Epoch 359/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1886 - accuracy: 0.9176 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9970 - recall: 0.9188 - precision: 0.9106\n",
            "Epoch 359: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.1886 - accuracy: 0.9176 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9970 - recall: 0.9188 - precision: 0.9106 - val_loss: 1.6782 - val_accuracy: 0.5992 - val_sensitivity_at_specificity: 0.7652 - val_specificity_at_sensitivity: 0.7410 - val_recall: 0.9331 - val_precision: 0.5607\n",
            "Epoch 360/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1674 - accuracy: 0.9246 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9414 - precision: 0.9107\n",
            "Epoch 360: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.1674 - accuracy: 0.9246 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9414 - precision: 0.9107 - val_loss: 1.8053 - val_accuracy: 0.5797 - val_sensitivity_at_specificity: 0.6844 - val_specificity_at_sensitivity: 0.6813 - val_recall: 0.9291 - val_precision: 0.5387\n",
            "Epoch 361/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1653 - accuracy: 0.9234 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9323 - precision: 0.9167\n",
            "Epoch 361: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.1653 - accuracy: 0.9234 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9323 - precision: 0.9167 - val_loss: 1.8737 - val_accuracy: 0.5945 - val_sensitivity_at_specificity: 0.7516 - val_specificity_at_sensitivity: 0.7238 - val_recall: 0.9272 - val_precision: 0.5534\n",
            "Epoch 362/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1824 - accuracy: 0.9211 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9985 - recall: 0.9325 - precision: 0.9094\n",
            "Epoch 362: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.1824 - accuracy: 0.9211 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9985 - recall: 0.9325 - precision: 0.9094 - val_loss: 1.4260 - val_accuracy: 0.6406 - val_sensitivity_at_specificity: 0.7896 - val_specificity_at_sensitivity: 0.7440 - val_recall: 0.9555 - val_precision: 0.5907\n",
            "Epoch 363/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1810 - accuracy: 0.9203 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9953 - recall: 0.9340 - precision: 0.9099\n",
            "Epoch 363: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.1810 - accuracy: 0.9203 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9953 - recall: 0.9340 - precision: 0.9099 - val_loss: 1.4685 - val_accuracy: 0.6289 - val_sensitivity_at_specificity: 0.7586 - val_specificity_at_sensitivity: 0.7571 - val_recall: 0.9330 - val_precision: 0.5810\n",
            "Epoch 364/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1647 - accuracy: 0.9277 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9985 - recall: 0.9422 - precision: 0.9122\n",
            "Epoch 364: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.1647 - accuracy: 0.9277 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9985 - recall: 0.9422 - precision: 0.9122 - val_loss: 1.3095 - val_accuracy: 0.6266 - val_sensitivity_at_specificity: 0.7424 - val_specificity_at_sensitivity: 0.7145 - val_recall: 0.9091 - val_precision: 0.5894\n",
            "Epoch 365/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1836 - accuracy: 0.9187 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9289 - precision: 0.9103\n",
            "Epoch 365: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.1836 - accuracy: 0.9187 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9289 - precision: 0.9103 - val_loss: 1.3760 - val_accuracy: 0.6078 - val_sensitivity_at_specificity: 0.7245 - val_specificity_at_sensitivity: 0.7239 - val_recall: 0.8933 - val_precision: 0.5633\n",
            "Epoch 366/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1802 - accuracy: 0.9176 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9378 - precision: 0.8985\n",
            "Epoch 366: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.1802 - accuracy: 0.9176 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9378 - precision: 0.8985 - val_loss: 1.3909 - val_accuracy: 0.6102 - val_sensitivity_at_specificity: 0.7476 - val_specificity_at_sensitivity: 0.7399 - val_recall: 0.9132 - val_precision: 0.5660\n",
            "Epoch 367/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1802 - accuracy: 0.9190 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9272 - precision: 0.9077\n",
            "Epoch 367: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.1802 - accuracy: 0.9190 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9272 - precision: 0.9077 - val_loss: 1.6230 - val_accuracy: 0.6203 - val_sensitivity_at_specificity: 0.7542 - val_specificity_at_sensitivity: 0.7295 - val_recall: 0.9439 - val_precision: 0.5808\n",
            "Epoch 368/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1806 - accuracy: 0.9191 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9977 - recall: 0.9314 - precision: 0.9078\n",
            "Epoch 368: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.1806 - accuracy: 0.9191 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9977 - recall: 0.9314 - precision: 0.9078 - val_loss: 1.5565 - val_accuracy: 0.6047 - val_sensitivity_at_specificity: 0.7390 - val_specificity_at_sensitivity: 0.7214 - val_recall: 0.9423 - val_precision: 0.5702\n",
            "Epoch 369/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1769 - accuracy: 0.9219 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9304 - precision: 0.9146\n",
            "Epoch 369: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.1769 - accuracy: 0.9219 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9304 - precision: 0.9146 - val_loss: 1.4476 - val_accuracy: 0.6289 - val_sensitivity_at_specificity: 0.8016 - val_specificity_at_sensitivity: 0.7638 - val_recall: 0.9411 - val_precision: 0.5814\n",
            "Epoch 370/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1706 - accuracy: 0.9273 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9346 - precision: 0.9202\n",
            "Epoch 370: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.1706 - accuracy: 0.9273 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9346 - precision: 0.9202 - val_loss: 1.5934 - val_accuracy: 0.6047 - val_sensitivity_at_specificity: 0.7088 - val_specificity_at_sensitivity: 0.6763 - val_recall: 0.9376 - val_precision: 0.5565\n",
            "Epoch 371/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1625 - accuracy: 0.9285 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9415 - precision: 0.9195\n",
            "Epoch 371: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.1625 - accuracy: 0.9285 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9415 - precision: 0.9195 - val_loss: 1.5738 - val_accuracy: 0.6156 - val_sensitivity_at_specificity: 0.7702 - val_specificity_at_sensitivity: 0.7217 - val_recall: 0.9348 - val_precision: 0.5722\n",
            "Epoch 372/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1589 - accuracy: 0.9293 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9410 - precision: 0.9169\n",
            "Epoch 372: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.1589 - accuracy: 0.9293 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9410 - precision: 0.9169 - val_loss: 1.6674 - val_accuracy: 0.6102 - val_sensitivity_at_specificity: 0.7220 - val_specificity_at_sensitivity: 0.6909 - val_recall: 0.9226 - val_precision: 0.5648\n",
            "Epoch 373/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1688 - accuracy: 0.9234 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9977 - recall: 0.9332 - precision: 0.9145\n",
            "Epoch 373: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.1688 - accuracy: 0.9234 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9977 - recall: 0.9332 - precision: 0.9145 - val_loss: 1.4364 - val_accuracy: 0.6164 - val_sensitivity_at_specificity: 0.7799 - val_specificity_at_sensitivity: 0.7504 - val_recall: 0.9171 - val_precision: 0.5671\n",
            "Epoch 374/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1567 - accuracy: 0.9281 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9384 - precision: 0.9164\n",
            "Epoch 374: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.1567 - accuracy: 0.9281 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9384 - precision: 0.9164 - val_loss: 1.6639 - val_accuracy: 0.6125 - val_sensitivity_at_specificity: 0.7532 - val_specificity_at_sensitivity: 0.7392 - val_recall: 0.9525 - val_precision: 0.5637\n",
            "Epoch 375/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1663 - accuracy: 0.9309 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9389 - precision: 0.9254\n",
            "Epoch 375: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.1663 - accuracy: 0.9309 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9389 - precision: 0.9254 - val_loss: 1.3679 - val_accuracy: 0.6156 - val_sensitivity_at_specificity: 0.7424 - val_specificity_at_sensitivity: 0.7132 - val_recall: 0.8937 - val_precision: 0.5657\n",
            "Epoch 376/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1635 - accuracy: 0.9297 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9425 - precision: 0.9162\n",
            "Epoch 376: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 210ms/step - loss: 0.1635 - accuracy: 0.9297 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9425 - precision: 0.9162 - val_loss: 1.5853 - val_accuracy: 0.6148 - val_sensitivity_at_specificity: 0.7058 - val_specificity_at_sensitivity: 0.7036 - val_recall: 0.9373 - val_precision: 0.5622\n",
            "Epoch 377/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1600 - accuracy: 0.9306 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9419 - precision: 0.9231\n",
            "Epoch 377: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.1600 - accuracy: 0.9306 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9419 - precision: 0.9231 - val_loss: 1.2780 - val_accuracy: 0.6609 - val_sensitivity_at_specificity: 0.7977 - val_specificity_at_sensitivity: 0.7408 - val_recall: 0.9135 - val_precision: 0.6242\n",
            "Epoch 378/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1550 - accuracy: 0.9336 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9441 - precision: 0.9276\n",
            "Epoch 378: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.1550 - accuracy: 0.9336 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9441 - precision: 0.9276 - val_loss: 1.4261 - val_accuracy: 0.6109 - val_sensitivity_at_specificity: 0.7199 - val_specificity_at_sensitivity: 0.7207 - val_recall: 0.8920 - val_precision: 0.5706\n",
            "Epoch 379/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1737 - accuracy: 0.9184 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9186 - precision: 0.9207\n",
            "Epoch 379: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.1737 - accuracy: 0.9184 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9186 - precision: 0.9207 - val_loss: 1.6887 - val_accuracy: 0.6172 - val_sensitivity_at_specificity: 0.7232 - val_specificity_at_sensitivity: 0.7002 - val_recall: 0.9471 - val_precision: 0.5718\n",
            "Epoch 380/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1656 - accuracy: 0.9289 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9334 - precision: 0.9247\n",
            "Epoch 380: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.1656 - accuracy: 0.9289 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9334 - precision: 0.9247 - val_loss: 1.8134 - val_accuracy: 0.6047 - val_sensitivity_at_specificity: 0.7368 - val_specificity_at_sensitivity: 0.6703 - val_recall: 0.9613 - val_precision: 0.5635\n",
            "Epoch 381/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1753 - accuracy: 0.9215 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9977 - recall: 0.9231 - precision: 0.9149\n",
            "Epoch 381: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.1753 - accuracy: 0.9215 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9977 - recall: 0.9231 - precision: 0.9149 - val_loss: 1.6700 - val_accuracy: 0.6297 - val_sensitivity_at_specificity: 0.7538 - val_specificity_at_sensitivity: 0.7413 - val_recall: 0.9477 - val_precision: 0.5833\n",
            "Epoch 382/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1664 - accuracy: 0.9266 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9992 - recall: 0.9325 - precision: 0.9177\n",
            "Epoch 382: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.1664 - accuracy: 0.9266 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9992 - recall: 0.9325 - precision: 0.9177 - val_loss: 1.8183 - val_accuracy: 0.6078 - val_sensitivity_at_specificity: 0.7079 - val_specificity_at_sensitivity: 0.6777 - val_recall: 0.9474 - val_precision: 0.5671\n",
            "Epoch 383/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1533 - accuracy: 0.9301 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9410 - precision: 0.9201\n",
            "Epoch 383: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.1533 - accuracy: 0.9301 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9410 - precision: 0.9201 - val_loss: 1.4277 - val_accuracy: 0.6328 - val_sensitivity_at_specificity: 0.8239 - val_specificity_at_sensitivity: 0.7717 - val_recall: 0.9324 - val_precision: 0.5814\n",
            "Epoch 384/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1561 - accuracy: 0.9324 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9351 - precision: 0.9285\n",
            "Epoch 384: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.1561 - accuracy: 0.9324 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9351 - precision: 0.9285 - val_loss: 1.5212 - val_accuracy: 0.6367 - val_sensitivity_at_specificity: 0.7936 - val_specificity_at_sensitivity: 0.7556 - val_recall: 0.9205 - val_precision: 0.5931\n",
            "Epoch 385/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1492 - accuracy: 0.9344 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9401 - precision: 0.9299\n",
            "Epoch 385: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.1492 - accuracy: 0.9344 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9401 - precision: 0.9299 - val_loss: 1.5731 - val_accuracy: 0.6258 - val_sensitivity_at_specificity: 0.7734 - val_specificity_at_sensitivity: 0.7321 - val_recall: 0.9418 - val_precision: 0.5824\n",
            "Epoch 386/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1487 - accuracy: 0.9344 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9450 - precision: 0.9279\n",
            "Epoch 386: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.1487 - accuracy: 0.9344 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9450 - precision: 0.9279 - val_loss: 1.5632 - val_accuracy: 0.6023 - val_sensitivity_at_specificity: 0.7830 - val_specificity_at_sensitivity: 0.7031 - val_recall: 0.9364 - val_precision: 0.5498\n",
            "Epoch 387/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1518 - accuracy: 0.9312 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9453 - precision: 0.9194\n",
            "Epoch 387: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.1518 - accuracy: 0.9312 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9453 - precision: 0.9194 - val_loss: 1.4440 - val_accuracy: 0.6406 - val_sensitivity_at_specificity: 0.7784 - val_specificity_at_sensitivity: 0.7745 - val_recall: 0.9306 - val_precision: 0.6040\n",
            "Epoch 388/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1563 - accuracy: 0.9289 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9351 - precision: 0.9236\n",
            "Epoch 388: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.1563 - accuracy: 0.9289 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9351 - precision: 0.9236 - val_loss: 1.9335 - val_accuracy: 0.5977 - val_sensitivity_at_specificity: 0.7724 - val_specificity_at_sensitivity: 0.7076 - val_recall: 0.9655 - val_precision: 0.5551\n",
            "Epoch 389/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1501 - accuracy: 0.9406 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9992 - recall: 0.9412 - precision: 0.9397\n",
            "Epoch 389: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.1501 - accuracy: 0.9406 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9992 - recall: 0.9412 - precision: 0.9397 - val_loss: 1.7763 - val_accuracy: 0.6016 - val_sensitivity_at_specificity: 0.7210 - val_specificity_at_sensitivity: 0.6760 - val_recall: 0.9279 - val_precision: 0.5606\n",
            "Epoch 390/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1571 - accuracy: 0.9332 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9387 - precision: 0.9293\n",
            "Epoch 390: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.1571 - accuracy: 0.9332 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9387 - precision: 0.9293 - val_loss: 1.6728 - val_accuracy: 0.6266 - val_sensitivity_at_specificity: 0.7666 - val_specificity_at_sensitivity: 0.7520 - val_recall: 0.9552 - val_precision: 0.5792\n",
            "Epoch 391/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1626 - accuracy: 0.9285 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9312 - precision: 0.9246\n",
            "Epoch 391: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.1626 - accuracy: 0.9285 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9312 - precision: 0.9246 - val_loss: 1.6510 - val_accuracy: 0.6164 - val_sensitivity_at_specificity: 0.7577 - val_specificity_at_sensitivity: 0.7389 - val_recall: 0.9494 - val_precision: 0.5747\n",
            "Epoch 392/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1481 - accuracy: 0.9395 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9525 - precision: 0.9303\n",
            "Epoch 392: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.1481 - accuracy: 0.9395 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9525 - precision: 0.9303 - val_loss: 1.5771 - val_accuracy: 0.6281 - val_sensitivity_at_specificity: 0.8095 - val_specificity_at_sensitivity: 0.7170 - val_recall: 0.9386 - val_precision: 0.5836\n",
            "Epoch 393/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1608 - accuracy: 0.9285 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9435 - precision: 0.9172\n",
            "Epoch 393: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.1608 - accuracy: 0.9285 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9435 - precision: 0.9172 - val_loss: 1.6877 - val_accuracy: 0.5992 - val_sensitivity_at_specificity: 0.7214 - val_specificity_at_sensitivity: 0.6656 - val_recall: 0.9056 - val_precision: 0.5641\n",
            "Epoch 394/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1385 - accuracy: 0.9431 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9451 - precision: 0.9396\n",
            "Epoch 394: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.1385 - accuracy: 0.9431 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9451 - precision: 0.9396 - val_loss: 1.8094 - val_accuracy: 0.5961 - val_sensitivity_at_specificity: 0.7276 - val_specificity_at_sensitivity: 0.7256 - val_recall: 0.9276 - val_precision: 0.5557\n",
            "Epoch 395/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1439 - accuracy: 0.9355 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9472 - precision: 0.9263\n",
            "Epoch 395: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.1439 - accuracy: 0.9355 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9472 - precision: 0.9263 - val_loss: 1.7263 - val_accuracy: 0.6266 - val_sensitivity_at_specificity: 0.7755 - val_specificity_at_sensitivity: 0.7098 - val_recall: 0.9582 - val_precision: 0.5785\n",
            "Epoch 396/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1618 - accuracy: 0.9328 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9506 - precision: 0.9175\n",
            "Epoch 396: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.1618 - accuracy: 0.9328 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9506 - precision: 0.9175 - val_loss: 1.9126 - val_accuracy: 0.6023 - val_sensitivity_at_specificity: 0.7508 - val_specificity_at_sensitivity: 0.7036 - val_recall: 0.9534 - val_precision: 0.5527\n",
            "Epoch 397/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1414 - accuracy: 0.9387 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9486 - precision: 0.9305\n",
            "Epoch 397: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 184ms/step - loss: 0.1414 - accuracy: 0.9387 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9486 - precision: 0.9305 - val_loss: 1.9027 - val_accuracy: 0.6227 - val_sensitivity_at_specificity: 0.7785 - val_specificity_at_sensitivity: 0.7058 - val_recall: 0.9470 - val_precision: 0.5748\n",
            "Epoch 398/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1544 - accuracy: 0.9348 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9977 - recall: 0.9477 - precision: 0.9239\n",
            "Epoch 398: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.1544 - accuracy: 0.9348 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9977 - recall: 0.9477 - precision: 0.9239 - val_loss: 1.8824 - val_accuracy: 0.5945 - val_sensitivity_at_specificity: 0.7138 - val_specificity_at_sensitivity: 0.6972 - val_recall: 0.9371 - val_precision: 0.5544\n",
            "Epoch 399/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1540 - accuracy: 0.9320 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9480 - precision: 0.9176\n",
            "Epoch 399: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.1540 - accuracy: 0.9320 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9480 - precision: 0.9176 - val_loss: 1.7385 - val_accuracy: 0.6031 - val_sensitivity_at_specificity: 0.7346 - val_specificity_at_sensitivity: 0.7073 - val_recall: 0.9213 - val_precision: 0.5664\n",
            "Epoch 400/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1502 - accuracy: 0.9332 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9392 - precision: 0.9299\n",
            "Epoch 400: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.1502 - accuracy: 0.9332 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9392 - precision: 0.9299 - val_loss: 1.7161 - val_accuracy: 0.6156 - val_sensitivity_at_specificity: 0.7864 - val_specificity_at_sensitivity: 0.7524 - val_recall: 0.9613 - val_precision: 0.5708\n",
            "Epoch 401/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1600 - accuracy: 0.9348 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9969 - recall: 0.9354 - precision: 0.9332\n",
            "Epoch 401: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.1600 - accuracy: 0.9348 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9969 - recall: 0.9354 - precision: 0.9332 - val_loss: 2.0170 - val_accuracy: 0.5711 - val_sensitivity_at_specificity: 0.7143 - val_specificity_at_sensitivity: 0.6807 - val_recall: 0.9464 - val_precision: 0.5305\n",
            "Epoch 402/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1346 - accuracy: 0.9445 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9587 - precision: 0.9344\n",
            "Epoch 402: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.1346 - accuracy: 0.9445 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9587 - precision: 0.9344 - val_loss: 1.8355 - val_accuracy: 0.6070 - val_sensitivity_at_specificity: 0.7637 - val_specificity_at_sensitivity: 0.7161 - val_recall: 0.9468 - val_precision: 0.5633\n",
            "Epoch 403/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1341 - accuracy: 0.9461 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9455 - precision: 0.9440\n",
            "Epoch 403: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 185ms/step - loss: 0.1341 - accuracy: 0.9461 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9455 - precision: 0.9440 - val_loss: 1.9303 - val_accuracy: 0.6055 - val_sensitivity_at_specificity: 0.7576 - val_specificity_at_sensitivity: 0.6922 - val_recall: 0.9250 - val_precision: 0.5588\n",
            "Epoch 404/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1407 - accuracy: 0.9375 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9456 - precision: 0.9311\n",
            "Epoch 404: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 184ms/step - loss: 0.1407 - accuracy: 0.9375 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9456 - precision: 0.9311 - val_loss: 1.8294 - val_accuracy: 0.6109 - val_sensitivity_at_specificity: 0.8022 - val_specificity_at_sensitivity: 0.7917 - val_recall: 0.9522 - val_precision: 0.5606\n",
            "Epoch 405/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1332 - accuracy: 0.9402 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9502 - precision: 0.9338\n",
            "Epoch 405: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.1332 - accuracy: 0.9402 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9502 - precision: 0.9338 - val_loss: 1.7266 - val_accuracy: 0.6180 - val_sensitivity_at_specificity: 0.7841 - val_specificity_at_sensitivity: 0.7400 - val_recall: 0.9317 - val_precision: 0.5682\n",
            "Epoch 406/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1425 - accuracy: 0.9379 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9354 - precision: 0.9405\n",
            "Epoch 406: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.1425 - accuracy: 0.9379 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9354 - precision: 0.9405 - val_loss: 1.6624 - val_accuracy: 0.6172 - val_sensitivity_at_specificity: 0.7425 - val_specificity_at_sensitivity: 0.7295 - val_recall: 0.9463 - val_precision: 0.5678\n",
            "Epoch 407/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1358 - accuracy: 0.9418 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9407 - precision: 0.9414\n",
            "Epoch 407: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.1358 - accuracy: 0.9418 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9407 - precision: 0.9414 - val_loss: 2.0827 - val_accuracy: 0.6125 - val_sensitivity_at_specificity: 0.7624 - val_specificity_at_sensitivity: 0.7047 - val_recall: 0.9518 - val_precision: 0.5600\n",
            "Epoch 408/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1434 - accuracy: 0.9402 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9514 - precision: 0.9285\n",
            "Epoch 408: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.1434 - accuracy: 0.9402 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9514 - precision: 0.9285 - val_loss: 1.6277 - val_accuracy: 0.6336 - val_sensitivity_at_specificity: 0.7328 - val_specificity_at_sensitivity: 0.7076 - val_recall: 0.9241 - val_precision: 0.6029\n",
            "Epoch 409/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1402 - accuracy: 0.9355 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9487 - precision: 0.9250\n",
            "Epoch 409: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.1402 - accuracy: 0.9355 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9487 - precision: 0.9250 - val_loss: 1.8749 - val_accuracy: 0.6117 - val_sensitivity_at_specificity: 0.7107 - val_specificity_at_sensitivity: 0.6876 - val_recall: 0.9518 - val_precision: 0.5677\n",
            "Epoch 410/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1502 - accuracy: 0.9324 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9313 - precision: 0.9321\n",
            "Epoch 410: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.1502 - accuracy: 0.9324 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9313 - precision: 0.9321 - val_loss: 2.3724 - val_accuracy: 0.5953 - val_sensitivity_at_specificity: 0.7516 - val_specificity_at_sensitivity: 0.6803 - val_recall: 0.9790 - val_precision: 0.5459\n",
            "Epoch 411/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1390 - accuracy: 0.9441 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9485 - precision: 0.9372\n",
            "Epoch 411: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.1390 - accuracy: 0.9441 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9485 - precision: 0.9372 - val_loss: 2.0224 - val_accuracy: 0.5945 - val_sensitivity_at_specificity: 0.7384 - val_specificity_at_sensitivity: 0.6891 - val_recall: 0.9394 - val_precision: 0.5505\n",
            "Epoch 412/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1386 - accuracy: 0.9387 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9491 - precision: 0.9295\n",
            "Epoch 412: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.1386 - accuracy: 0.9387 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9491 - precision: 0.9295 - val_loss: 1.7323 - val_accuracy: 0.6234 - val_sensitivity_at_specificity: 0.7651 - val_specificity_at_sensitivity: 0.7156 - val_recall: 0.9397 - val_precision: 0.5785\n",
            "Epoch 413/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1565 - accuracy: 0.9316 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9313 - precision: 0.9305\n",
            "Epoch 413: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.1565 - accuracy: 0.9316 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9313 - precision: 0.9305 - val_loss: 1.7168 - val_accuracy: 0.6117 - val_sensitivity_at_specificity: 0.7481 - val_specificity_at_sensitivity: 0.7235 - val_recall: 0.9289 - val_precision: 0.5713\n",
            "Epoch 414/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1394 - accuracy: 0.9395 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9474 - precision: 0.9337\n",
            "Epoch 414: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.1394 - accuracy: 0.9395 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9474 - precision: 0.9337 - val_loss: 1.7355 - val_accuracy: 0.6242 - val_sensitivity_at_specificity: 0.8300 - val_specificity_at_sensitivity: 0.7371 - val_recall: 0.9516 - val_precision: 0.5755\n",
            "Epoch 415/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1332 - accuracy: 0.9391 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9431 - precision: 0.9358\n",
            "Epoch 415: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.1332 - accuracy: 0.9391 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9431 - precision: 0.9358 - val_loss: 1.9285 - val_accuracy: 0.5898 - val_sensitivity_at_specificity: 0.7680 - val_specificity_at_sensitivity: 0.7231 - val_recall: 0.9412 - val_precision: 0.5408\n",
            "Epoch 416/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1295 - accuracy: 0.9445 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9534 - precision: 0.9357\n",
            "Epoch 416: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.1295 - accuracy: 0.9445 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9534 - precision: 0.9357 - val_loss: 1.9338 - val_accuracy: 0.6094 - val_sensitivity_at_specificity: 0.7508 - val_specificity_at_sensitivity: 0.7087 - val_recall: 0.9245 - val_precision: 0.5763\n",
            "Epoch 417/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1254 - accuracy: 0.9473 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9446 - precision: 0.9484\n",
            "Epoch 417: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.1254 - accuracy: 0.9473 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9446 - precision: 0.9484 - val_loss: 1.9500 - val_accuracy: 0.6313 - val_sensitivity_at_specificity: 0.8185 - val_specificity_at_sensitivity: 0.7531 - val_recall: 0.9586 - val_precision: 0.5744\n",
            "Epoch 418/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1287 - accuracy: 0.9438 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9410 - precision: 0.9440\n",
            "Epoch 418: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.1287 - accuracy: 0.9438 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9410 - precision: 0.9440 - val_loss: 1.6917 - val_accuracy: 0.6180 - val_sensitivity_at_specificity: 0.7576 - val_specificity_at_sensitivity: 0.7611 - val_recall: 0.9474 - val_precision: 0.5657\n",
            "Epoch 419/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1328 - accuracy: 0.9398 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9459 - precision: 0.9342\n",
            "Epoch 419: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.1328 - accuracy: 0.9398 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9459 - precision: 0.9342 - val_loss: 1.7721 - val_accuracy: 0.6430 - val_sensitivity_at_specificity: 0.7834 - val_specificity_at_sensitivity: 0.7418 - val_recall: 0.9341 - val_precision: 0.5891\n",
            "Epoch 420/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1274 - accuracy: 0.9402 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9468 - precision: 0.9360\n",
            "Epoch 420: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.1274 - accuracy: 0.9402 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9468 - precision: 0.9360 - val_loss: 2.0070 - val_accuracy: 0.6094 - val_sensitivity_at_specificity: 0.7387 - val_specificity_at_sensitivity: 0.6939 - val_recall: 0.9456 - val_precision: 0.5666\n",
            "Epoch 421/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1243 - accuracy: 0.9504 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9542 - precision: 0.9443\n",
            "Epoch 421: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.1243 - accuracy: 0.9504 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9542 - precision: 0.9443 - val_loss: 1.7932 - val_accuracy: 0.6234 - val_sensitivity_at_specificity: 0.7532 - val_specificity_at_sensitivity: 0.7424 - val_recall: 0.9519 - val_precision: 0.5679\n",
            "Epoch 422/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1267 - accuracy: 0.9457 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9518 - precision: 0.9392\n",
            "Epoch 422: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.1267 - accuracy: 0.9457 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9518 - precision: 0.9392 - val_loss: 2.0023 - val_accuracy: 0.5852 - val_sensitivity_at_specificity: 0.7565 - val_specificity_at_sensitivity: 0.6976 - val_recall: 0.9444 - val_precision: 0.5377\n",
            "Epoch 423/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1205 - accuracy: 0.9520 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9574 - precision: 0.9495\n",
            "Epoch 423: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 186ms/step - loss: 0.1205 - accuracy: 0.9520 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9574 - precision: 0.9495 - val_loss: 2.2691 - val_accuracy: 0.5953 - val_sensitivity_at_specificity: 0.7118 - val_specificity_at_sensitivity: 0.6912 - val_recall: 0.9377 - val_precision: 0.5574\n",
            "Epoch 424/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1256 - accuracy: 0.9449 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9537 - precision: 0.9368\n",
            "Epoch 424: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 217ms/step - loss: 0.1256 - accuracy: 0.9449 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9537 - precision: 0.9368 - val_loss: 2.0191 - val_accuracy: 0.6164 - val_sensitivity_at_specificity: 0.7669 - val_specificity_at_sensitivity: 0.7245 - val_recall: 0.9433 - val_precision: 0.5753\n",
            "Epoch 425/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1386 - accuracy: 0.9430 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9550 - precision: 0.9314\n",
            "Epoch 425: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.1386 - accuracy: 0.9430 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9550 - precision: 0.9314 - val_loss: 1.9666 - val_accuracy: 0.5953 - val_sensitivity_at_specificity: 0.7029 - val_specificity_at_sensitivity: 0.6890 - val_recall: 0.9342 - val_precision: 0.5622\n",
            "Epoch 426/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1456 - accuracy: 0.9441 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9984 - recall: 0.9431 - precision: 0.9481\n",
            "Epoch 426: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.1456 - accuracy: 0.9441 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9984 - recall: 0.9431 - precision: 0.9481 - val_loss: 2.1348 - val_accuracy: 0.6117 - val_sensitivity_at_specificity: 0.7893 - val_specificity_at_sensitivity: 0.6832 - val_recall: 0.9513 - val_precision: 0.5649\n",
            "Epoch 427/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1422 - accuracy: 0.9383 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9435 - precision: 0.9348\n",
            "Epoch 427: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.1422 - accuracy: 0.9383 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9435 - precision: 0.9348 - val_loss: 1.7996 - val_accuracy: 0.6078 - val_sensitivity_at_specificity: 0.7599 - val_specificity_at_sensitivity: 0.7233 - val_recall: 0.9463 - val_precision: 0.5614\n",
            "Epoch 428/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1316 - accuracy: 0.9449 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9544 - precision: 0.9394\n",
            "Epoch 428: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.1316 - accuracy: 0.9449 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9544 - precision: 0.9394 - val_loss: 1.7571 - val_accuracy: 0.5992 - val_sensitivity_at_specificity: 0.7581 - val_specificity_at_sensitivity: 0.7045 - val_recall: 0.9452 - val_precision: 0.5502\n",
            "Epoch 429/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1376 - accuracy: 0.9438 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9403 - precision: 0.9434\n",
            "Epoch 429: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.1376 - accuracy: 0.9438 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9403 - precision: 0.9434 - val_loss: 1.8208 - val_accuracy: 0.6133 - val_sensitivity_at_specificity: 0.7012 - val_specificity_at_sensitivity: 0.6843 - val_recall: 0.9223 - val_precision: 0.5767\n",
            "Epoch 430/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1260 - accuracy: 0.9488 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9566 - precision: 0.9409\n",
            "Epoch 430: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.1260 - accuracy: 0.9488 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9566 - precision: 0.9409 - val_loss: 1.7744 - val_accuracy: 0.6234 - val_sensitivity_at_specificity: 0.7281 - val_specificity_at_sensitivity: 0.7078 - val_recall: 0.9234 - val_precision: 0.5771\n",
            "Epoch 431/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1283 - accuracy: 0.9438 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9488 - precision: 0.9401\n",
            "Epoch 431: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.1283 - accuracy: 0.9438 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9488 - precision: 0.9401 - val_loss: 2.0453 - val_accuracy: 0.6141 - val_sensitivity_at_specificity: 0.7451 - val_specificity_at_sensitivity: 0.6931 - val_recall: 0.9493 - val_precision: 0.5565\n",
            "Epoch 432/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1238 - accuracy: 0.9469 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 0.9992 - recall: 0.9486 - precision: 0.9471\n",
            "Epoch 432: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.1238 - accuracy: 0.9469 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 0.9992 - recall: 0.9486 - precision: 0.9471 - val_loss: 2.0957 - val_accuracy: 0.5914 - val_sensitivity_at_specificity: 0.6921 - val_specificity_at_sensitivity: 0.6813 - val_recall: 0.9471 - val_precision: 0.5546\n",
            "Epoch 433/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1362 - accuracy: 0.9457 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9435 - precision: 0.9514\n",
            "Epoch 433: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.1362 - accuracy: 0.9457 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9435 - precision: 0.9514 - val_loss: 2.2813 - val_accuracy: 0.6023 - val_sensitivity_at_specificity: 0.7163 - val_specificity_at_sensitivity: 0.6772 - val_recall: 0.9767 - val_precision: 0.5605\n",
            "Epoch 434/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1304 - accuracy: 0.9434 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9510 - precision: 0.9388\n",
            "Epoch 434: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.1304 - accuracy: 0.9434 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9510 - precision: 0.9388 - val_loss: 1.9092 - val_accuracy: 0.5969 - val_sensitivity_at_specificity: 0.7476 - val_specificity_at_sensitivity: 0.7158 - val_recall: 0.9389 - val_precision: 0.5499\n",
            "Epoch 435/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1215 - accuracy: 0.9516 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9574 - precision: 0.9455\n",
            "Epoch 435: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.1215 - accuracy: 0.9516 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9574 - precision: 0.9455 - val_loss: 1.7720 - val_accuracy: 0.6336 - val_sensitivity_at_specificity: 0.7915 - val_specificity_at_sensitivity: 0.7327 - val_recall: 0.9300 - val_precision: 0.5727\n",
            "Epoch 436/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1323 - accuracy: 0.9469 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9466 - precision: 0.9466\n",
            "Epoch 436: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.1323 - accuracy: 0.9469 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9466 - precision: 0.9466 - val_loss: 2.0620 - val_accuracy: 0.6070 - val_sensitivity_at_specificity: 0.7456 - val_specificity_at_sensitivity: 0.6977 - val_recall: 0.9600 - val_precision: 0.5566\n",
            "Epoch 437/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1297 - accuracy: 0.9461 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9475 - precision: 0.9445\n",
            "Epoch 437: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.1297 - accuracy: 0.9461 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9475 - precision: 0.9445 - val_loss: 1.8509 - val_accuracy: 0.6109 - val_sensitivity_at_specificity: 0.7331 - val_specificity_at_sensitivity: 0.7015 - val_recall: 0.9340 - val_precision: 0.5785\n",
            "Epoch 438/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1320 - accuracy: 0.9465 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9976 - recall: 0.9509 - precision: 0.9429\n",
            "Epoch 438: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 185ms/step - loss: 0.1320 - accuracy: 0.9465 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9976 - recall: 0.9509 - precision: 0.9429 - val_loss: 1.7551 - val_accuracy: 0.6211 - val_sensitivity_at_specificity: 0.7880 - val_specificity_at_sensitivity: 0.7222 - val_recall: 0.9509 - val_precision: 0.5697\n",
            "Epoch 439/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1188 - accuracy: 0.9500 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9601 - precision: 0.9427\n",
            "Epoch 439: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 212ms/step - loss: 0.1188 - accuracy: 0.9500 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9601 - precision: 0.9427 - val_loss: 1.9318 - val_accuracy: 0.5977 - val_sensitivity_at_specificity: 0.7539 - val_specificity_at_sensitivity: 0.6959 - val_recall: 0.9283 - val_precision: 0.5596\n",
            "Epoch 440/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1237 - accuracy: 0.9504 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9519 - precision: 0.9482\n",
            "Epoch 440: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 182ms/step - loss: 0.1237 - accuracy: 0.9504 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9519 - precision: 0.9482 - val_loss: 2.1986 - val_accuracy: 0.6219 - val_sensitivity_at_specificity: 0.7536 - val_specificity_at_sensitivity: 0.6851 - val_recall: 0.9523 - val_precision: 0.5689\n",
            "Epoch 441/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1321 - accuracy: 0.9488 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9969 - recall: 0.9603 - precision: 0.9392\n",
            "Epoch 441: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.1321 - accuracy: 0.9488 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9969 - recall: 0.9603 - precision: 0.9392 - val_loss: 1.7508 - val_accuracy: 0.6102 - val_sensitivity_at_specificity: 0.7607 - val_specificity_at_sensitivity: 0.7134 - val_recall: 0.9095 - val_precision: 0.5741\n",
            "Epoch 442/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1311 - accuracy: 0.9457 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9501 - precision: 0.9436\n",
            "Epoch 442: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.1311 - accuracy: 0.9457 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9501 - precision: 0.9436 - val_loss: 1.8038 - val_accuracy: 0.6328 - val_sensitivity_at_specificity: 0.7896 - val_specificity_at_sensitivity: 0.7232 - val_recall: 0.9294 - val_precision: 0.5821\n",
            "Epoch 443/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1295 - accuracy: 0.9480 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9530 - precision: 0.9466\n",
            "Epoch 443: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.1295 - accuracy: 0.9480 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9530 - precision: 0.9466 - val_loss: 1.9724 - val_accuracy: 0.6016 - val_sensitivity_at_specificity: 0.7299 - val_specificity_at_sensitivity: 0.7371 - val_recall: 0.9630 - val_precision: 0.5516\n",
            "Epoch 444/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1162 - accuracy: 0.9492 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9541 - precision: 0.9453\n",
            "Epoch 444: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.1162 - accuracy: 0.9492 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9541 - precision: 0.9453 - val_loss: 1.9838 - val_accuracy: 0.6008 - val_sensitivity_at_specificity: 0.7496 - val_specificity_at_sensitivity: 0.6872 - val_recall: 0.9413 - val_precision: 0.5628\n",
            "Epoch 445/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1116 - accuracy: 0.9539 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9580 - precision: 0.9473\n",
            "Epoch 445: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.1116 - accuracy: 0.9539 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9580 - precision: 0.9473 - val_loss: 2.0365 - val_accuracy: 0.5969 - val_sensitivity_at_specificity: 0.7361 - val_specificity_at_sensitivity: 0.7373 - val_recall: 0.9459 - val_precision: 0.5525\n",
            "Epoch 446/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1189 - accuracy: 0.9516 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9511 - precision: 0.9496\n",
            "Epoch 446: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 174ms/step - loss: 0.1189 - accuracy: 0.9516 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9511 - precision: 0.9496 - val_loss: 2.0519 - val_accuracy: 0.6109 - val_sensitivity_at_specificity: 0.7346 - val_specificity_at_sensitivity: 0.7041 - val_recall: 0.9475 - val_precision: 0.5696\n",
            "Epoch 447/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1149 - accuracy: 0.9500 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9514 - precision: 0.9500\n",
            "Epoch 447: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.1149 - accuracy: 0.9500 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9514 - precision: 0.9500 - val_loss: 2.2365 - val_accuracy: 0.6047 - val_sensitivity_at_specificity: 0.7209 - val_specificity_at_sensitivity: 0.6803 - val_recall: 0.9597 - val_precision: 0.5632\n",
            "Epoch 448/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1220 - accuracy: 0.9488 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9564 - precision: 0.9441\n",
            "Epoch 448: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.1220 - accuracy: 0.9488 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9564 - precision: 0.9441 - val_loss: 2.1173 - val_accuracy: 0.6062 - val_sensitivity_at_specificity: 0.6908 - val_specificity_at_sensitivity: 0.6840 - val_recall: 0.9186 - val_precision: 0.5751\n",
            "Epoch 449/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1083 - accuracy: 0.9527 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9523 - precision: 0.9545\n",
            "Epoch 449: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.1083 - accuracy: 0.9527 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9523 - precision: 0.9545 - val_loss: 1.9024 - val_accuracy: 0.6344 - val_sensitivity_at_specificity: 0.7798 - val_specificity_at_sensitivity: 0.7386 - val_recall: 0.9581 - val_precision: 0.5836\n",
            "Epoch 450/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1080 - accuracy: 0.9586 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9650 - precision: 0.9531\n",
            "Epoch 450: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.1080 - accuracy: 0.9586 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9650 - precision: 0.9531 - val_loss: 2.3227 - val_accuracy: 0.5625 - val_sensitivity_at_specificity: 0.7354 - val_specificity_at_sensitivity: 0.7010 - val_recall: 0.9551 - val_precision: 0.5185\n",
            "Epoch 451/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1425 - accuracy: 0.9445 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9976 - recall: 0.9372 - precision: 0.9519\n",
            "Epoch 451: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.1425 - accuracy: 0.9445 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9976 - recall: 0.9372 - precision: 0.9519 - val_loss: 1.9494 - val_accuracy: 0.6234 - val_sensitivity_at_specificity: 0.7807 - val_specificity_at_sensitivity: 0.7394 - val_recall: 0.9518 - val_precision: 0.5757\n",
            "Epoch 452/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1121 - accuracy: 0.9555 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9671 - precision: 0.9429\n",
            "Epoch 452: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.1121 - accuracy: 0.9555 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9671 - precision: 0.9429 - val_loss: 1.9160 - val_accuracy: 0.6141 - val_sensitivity_at_specificity: 0.7449 - val_specificity_at_sensitivity: 0.7054 - val_recall: 0.9465 - val_precision: 0.5664\n",
            "Epoch 453/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1423 - accuracy: 0.9496 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9961 - recall: 0.9479 - precision: 0.9502\n",
            "Epoch 453: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.1423 - accuracy: 0.9496 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9961 - recall: 0.9479 - precision: 0.9502 - val_loss: 2.0127 - val_accuracy: 0.6055 - val_sensitivity_at_specificity: 0.7763 - val_specificity_at_sensitivity: 0.6875 - val_recall: 0.9523 - val_precision: 0.5488\n",
            "Epoch 454/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1231 - accuracy: 0.9477 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9991 - recall: 0.9449 - precision: 0.9540\n",
            "Epoch 454: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.1231 - accuracy: 0.9477 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9991 - recall: 0.9449 - precision: 0.9540 - val_loss: 2.2446 - val_accuracy: 0.5766 - val_sensitivity_at_specificity: 0.7089 - val_specificity_at_sensitivity: 0.7009 - val_recall: 0.9720 - val_precision: 0.5296\n",
            "Epoch 455/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1177 - accuracy: 0.9488 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9588 - precision: 0.9405\n",
            "Epoch 455: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.1177 - accuracy: 0.9488 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9588 - precision: 0.9405 - val_loss: 1.6755 - val_accuracy: 0.6266 - val_sensitivity_at_specificity: 0.7934 - val_specificity_at_sensitivity: 0.7426 - val_recall: 0.9405 - val_precision: 0.5773\n",
            "Epoch 456/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1206 - accuracy: 0.9535 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9565 - precision: 0.9497\n",
            "Epoch 456: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.1206 - accuracy: 0.9535 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9565 - precision: 0.9497 - val_loss: 2.0964 - val_accuracy: 0.6242 - val_sensitivity_at_specificity: 0.7821 - val_specificity_at_sensitivity: 0.6951 - val_recall: 0.9629 - val_precision: 0.5769\n",
            "Epoch 457/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1025 - accuracy: 0.9555 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9606 - precision: 0.9518\n",
            "Epoch 457: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.1025 - accuracy: 0.9555 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9606 - precision: 0.9518 - val_loss: 2.0910 - val_accuracy: 0.6102 - val_sensitivity_at_specificity: 0.7637 - val_specificity_at_sensitivity: 0.7098 - val_recall: 0.9233 - val_precision: 0.5673\n",
            "Epoch 458/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1121 - accuracy: 0.9508 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9513 - precision: 0.9498\n",
            "Epoch 458: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.1121 - accuracy: 0.9508 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9513 - precision: 0.9498 - val_loss: 2.0515 - val_accuracy: 0.6352 - val_sensitivity_at_specificity: 0.7793 - val_specificity_at_sensitivity: 0.7095 - val_recall: 0.9346 - val_precision: 0.5915\n",
            "Epoch 459/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1094 - accuracy: 0.9566 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9571 - precision: 0.9578\n",
            "Epoch 459: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.1094 - accuracy: 0.9566 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9571 - precision: 0.9578 - val_loss: 2.3912 - val_accuracy: 0.5922 - val_sensitivity_at_specificity: 0.7357 - val_specificity_at_sensitivity: 0.6610 - val_recall: 0.9459 - val_precision: 0.5490\n",
            "Epoch 460/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1232 - accuracy: 0.9516 - sensitivity_at_specificity: 0.9976 - specificity_at_sensitivity: 1.0000 - recall: 0.9550 - precision: 0.9459\n",
            "Epoch 460: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 180ms/step - loss: 0.1232 - accuracy: 0.9516 - sensitivity_at_specificity: 0.9976 - specificity_at_sensitivity: 1.0000 - recall: 0.9550 - precision: 0.9459 - val_loss: 2.0137 - val_accuracy: 0.5891 - val_sensitivity_at_specificity: 0.7074 - val_specificity_at_sensitivity: 0.6726 - val_recall: 0.9306 - val_precision: 0.5624\n",
            "Epoch 461/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1346 - accuracy: 0.9445 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9480 - precision: 0.9421\n",
            "Epoch 461: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.1346 - accuracy: 0.9445 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9480 - precision: 0.9421 - val_loss: 1.8820 - val_accuracy: 0.6125 - val_sensitivity_at_specificity: 0.7088 - val_specificity_at_sensitivity: 0.6971 - val_recall: 0.9421 - val_precision: 0.5743\n",
            "Epoch 462/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1222 - accuracy: 0.9492 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9639 - precision: 0.9359\n",
            "Epoch 462: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.1222 - accuracy: 0.9492 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9639 - precision: 0.9359 - val_loss: 2.0754 - val_accuracy: 0.5852 - val_sensitivity_at_specificity: 0.7333 - val_specificity_at_sensitivity: 0.6902 - val_recall: 0.9415 - val_precision: 0.5391\n",
            "Epoch 463/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1065 - accuracy: 0.9551 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9521 - precision: 0.9573\n",
            "Epoch 463: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.1065 - accuracy: 0.9551 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9521 - precision: 0.9573 - val_loss: 1.7481 - val_accuracy: 0.6242 - val_sensitivity_at_specificity: 0.7676 - val_specificity_at_sensitivity: 0.7316 - val_recall: 0.9174 - val_precision: 0.5842\n",
            "Epoch 464/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1005 - accuracy: 0.9535 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9603 - precision: 0.9461\n",
            "Epoch 464: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.1005 - accuracy: 0.9535 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9603 - precision: 0.9461 - val_loss: 2.0698 - val_accuracy: 0.5961 - val_sensitivity_at_specificity: 0.7579 - val_specificity_at_sensitivity: 0.6928 - val_recall: 0.9187 - val_precision: 0.5421\n",
            "Epoch 465/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1166 - accuracy: 0.9477 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9445 - precision: 0.9493\n",
            "Epoch 465: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.1166 - accuracy: 0.9477 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9445 - precision: 0.9493 - val_loss: 2.5453 - val_accuracy: 0.5813 - val_sensitivity_at_specificity: 0.7063 - val_specificity_at_sensitivity: 0.6375 - val_recall: 0.9469 - val_precision: 0.5469\n",
            "Epoch 466/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1055 - accuracy: 0.9547 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9530 - precision: 0.9545\n",
            "Epoch 466: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.1055 - accuracy: 0.9547 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9530 - precision: 0.9545 - val_loss: 2.1895 - val_accuracy: 0.6391 - val_sensitivity_at_specificity: 0.7728 - val_specificity_at_sensitivity: 0.6825 - val_recall: 0.9614 - val_precision: 0.5873\n",
            "Epoch 467/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1112 - accuracy: 0.9578 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9662 - precision: 0.9533\n",
            "Epoch 467: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.1112 - accuracy: 0.9578 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9662 - precision: 0.9533 - val_loss: 2.5508 - val_accuracy: 0.5906 - val_sensitivity_at_specificity: 0.7147 - val_specificity_at_sensitivity: 0.6546 - val_recall: 0.9579 - val_precision: 0.5427\n",
            "Epoch 468/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1088 - accuracy: 0.9559 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9582 - precision: 0.9545\n",
            "Epoch 468: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.1088 - accuracy: 0.9559 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9582 - precision: 0.9545 - val_loss: 2.1712 - val_accuracy: 0.6141 - val_sensitivity_at_specificity: 0.7732 - val_specificity_at_sensitivity: 0.7095 - val_recall: 0.9569 - val_precision: 0.5619\n",
            "Epoch 469/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1034 - accuracy: 0.9555 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9570 - precision: 0.9525\n",
            "Epoch 469: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.1034 - accuracy: 0.9555 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9570 - precision: 0.9525 - val_loss: 2.5548 - val_accuracy: 0.5781 - val_sensitivity_at_specificity: 0.7358 - val_specificity_at_sensitivity: 0.6546 - val_recall: 0.9514 - val_precision: 0.5351\n",
            "Epoch 470/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1316 - accuracy: 0.9488 - sensitivity_at_specificity: 0.9976 - specificity_at_sensitivity: 0.9992 - recall: 0.9447 - precision: 0.9500\n",
            "Epoch 470: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.1316 - accuracy: 0.9488 - sensitivity_at_specificity: 0.9976 - specificity_at_sensitivity: 0.9992 - recall: 0.9447 - precision: 0.9500 - val_loss: 1.7852 - val_accuracy: 0.6289 - val_sensitivity_at_specificity: 0.8057 - val_specificity_at_sensitivity: 0.7651 - val_recall: 0.9368 - val_precision: 0.5768\n",
            "Epoch 471/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1077 - accuracy: 0.9508 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9608 - precision: 0.9434\n",
            "Epoch 471: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.1077 - accuracy: 0.9508 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9608 - precision: 0.9434 - val_loss: 1.9458 - val_accuracy: 0.6117 - val_sensitivity_at_specificity: 0.7165 - val_specificity_at_sensitivity: 0.7385 - val_recall: 0.9492 - val_precision: 0.5704\n",
            "Epoch 472/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0833 - accuracy: 0.9684 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9750 - precision: 0.9622\n",
            "Epoch 472: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.0833 - accuracy: 0.9684 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9750 - precision: 0.9622 - val_loss: 1.8551 - val_accuracy: 0.6328 - val_sensitivity_at_specificity: 0.7769 - val_specificity_at_sensitivity: 0.7520 - val_recall: 0.9393 - val_precision: 0.5901\n",
            "Epoch 473/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1140 - accuracy: 0.9547 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9633 - precision: 0.9505\n",
            "Epoch 473: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.1140 - accuracy: 0.9547 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9633 - precision: 0.9505 - val_loss: 1.9129 - val_accuracy: 0.6172 - val_sensitivity_at_specificity: 0.8006 - val_specificity_at_sensitivity: 0.7523 - val_recall: 0.9550 - val_precision: 0.5625\n",
            "Epoch 474/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1176 - accuracy: 0.9504 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9537 - precision: 0.9470\n",
            "Epoch 474: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.1176 - accuracy: 0.9504 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9537 - precision: 0.9470 - val_loss: 1.7290 - val_accuracy: 0.6211 - val_sensitivity_at_specificity: 0.7416 - val_specificity_at_sensitivity: 0.6986 - val_recall: 0.9390 - val_precision: 0.5669\n",
            "Epoch 475/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1127 - accuracy: 0.9563 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9592 - precision: 0.9548\n",
            "Epoch 475: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.1127 - accuracy: 0.9563 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9592 - precision: 0.9548 - val_loss: 1.5405 - val_accuracy: 0.6617 - val_sensitivity_at_specificity: 0.8024 - val_specificity_at_sensitivity: 0.7363 - val_recall: 0.9240 - val_precision: 0.6135\n",
            "Epoch 476/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1055 - accuracy: 0.9563 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9605 - precision: 0.9531\n",
            "Epoch 476: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.1055 - accuracy: 0.9563 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9605 - precision: 0.9531 - val_loss: 2.3905 - val_accuracy: 0.6000 - val_sensitivity_at_specificity: 0.6816 - val_specificity_at_sensitivity: 0.6556 - val_recall: 0.9691 - val_precision: 0.5603\n",
            "Epoch 477/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0974 - accuracy: 0.9625 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9637 - precision: 0.9607\n",
            "Epoch 477: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.0974 - accuracy: 0.9625 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9637 - precision: 0.9607 - val_loss: 2.3789 - val_accuracy: 0.6031 - val_sensitivity_at_specificity: 0.7666 - val_specificity_at_sensitivity: 0.6888 - val_recall: 0.9583 - val_precision: 0.5631\n",
            "Epoch 478/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1095 - accuracy: 0.9527 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9533 - precision: 0.9525\n",
            "Epoch 478: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.1095 - accuracy: 0.9527 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9533 - precision: 0.9525 - val_loss: 2.2331 - val_accuracy: 0.6055 - val_sensitivity_at_specificity: 0.6780 - val_specificity_at_sensitivity: 0.6551 - val_recall: 0.9258 - val_precision: 0.5783\n",
            "Epoch 479/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1192 - accuracy: 0.9461 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9449 - precision: 0.9464\n",
            "Epoch 479: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.1192 - accuracy: 0.9461 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9449 - precision: 0.9464 - val_loss: 2.2929 - val_accuracy: 0.5969 - val_sensitivity_at_specificity: 0.7188 - val_specificity_at_sensitivity: 0.6859 - val_recall: 0.9500 - val_precision: 0.5568\n",
            "Epoch 480/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1198 - accuracy: 0.9504 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9530 - precision: 0.9493\n",
            "Epoch 480: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.1198 - accuracy: 0.9504 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9530 - precision: 0.9493 - val_loss: 2.0859 - val_accuracy: 0.6187 - val_sensitivity_at_specificity: 0.7446 - val_specificity_at_sensitivity: 0.7161 - val_recall: 0.9613 - val_precision: 0.5729\n",
            "Epoch 481/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1038 - accuracy: 0.9574 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9623 - precision: 0.9526\n",
            "Epoch 481: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.1038 - accuracy: 0.9574 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9623 - precision: 0.9526 - val_loss: 2.0681 - val_accuracy: 0.6055 - val_sensitivity_at_specificity: 0.7884 - val_specificity_at_sensitivity: 0.7422 - val_recall: 0.9504 - val_precision: 0.5476\n",
            "Epoch 482/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0978 - accuracy: 0.9602 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9655 - precision: 0.9550\n",
            "Epoch 482: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.0978 - accuracy: 0.9602 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9655 - precision: 0.9550 - val_loss: 1.9734 - val_accuracy: 0.6250 - val_sensitivity_at_specificity: 0.7538 - val_specificity_at_sensitivity: 0.6698 - val_recall: 0.9246 - val_precision: 0.5824\n",
            "Epoch 483/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1029 - accuracy: 0.9547 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9643 - precision: 0.9485\n",
            "Epoch 483: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.1029 - accuracy: 0.9547 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9643 - precision: 0.9485 - val_loss: 2.2937 - val_accuracy: 0.5953 - val_sensitivity_at_specificity: 0.7425 - val_specificity_at_sensitivity: 0.6878 - val_recall: 0.9415 - val_precision: 0.5534\n",
            "Epoch 484/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1052 - accuracy: 0.9578 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9601 - precision: 0.9571\n",
            "Epoch 484: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.1052 - accuracy: 0.9578 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9601 - precision: 0.9571 - val_loss: 2.2593 - val_accuracy: 0.6141 - val_sensitivity_at_specificity: 0.7814 - val_specificity_at_sensitivity: 0.6786 - val_recall: 0.9544 - val_precision: 0.5662\n",
            "Epoch 485/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1155 - accuracy: 0.9508 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9546 - precision: 0.9472\n",
            "Epoch 485: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.1155 - accuracy: 0.9508 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9546 - precision: 0.9472 - val_loss: 2.5139 - val_accuracy: 0.6055 - val_sensitivity_at_specificity: 0.7259 - val_specificity_at_sensitivity: 0.6539 - val_recall: 0.9479 - val_precision: 0.5679\n",
            "Epoch 486/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1182 - accuracy: 0.9516 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9489 - precision: 0.9534\n",
            "Epoch 486: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 218ms/step - loss: 0.1182 - accuracy: 0.9516 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9489 - precision: 0.9534 - val_loss: 2.4580 - val_accuracy: 0.5945 - val_sensitivity_at_specificity: 0.7449 - val_specificity_at_sensitivity: 0.6884 - val_recall: 0.9543 - val_precision: 0.5529\n",
            "Epoch 487/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1052 - accuracy: 0.9563 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9544 - precision: 0.9574\n",
            "Epoch 487: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.1052 - accuracy: 0.9563 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9544 - precision: 0.9574 - val_loss: 2.3300 - val_accuracy: 0.6070 - val_sensitivity_at_specificity: 0.7381 - val_specificity_at_sensitivity: 0.6688 - val_recall: 0.9522 - val_precision: 0.5670\n",
            "Epoch 488/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1057 - accuracy: 0.9535 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9556 - precision: 0.9534\n",
            "Epoch 488: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.1057 - accuracy: 0.9535 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9556 - precision: 0.9534 - val_loss: 2.2585 - val_accuracy: 0.6195 - val_sensitivity_at_specificity: 0.7404 - val_specificity_at_sensitivity: 0.6916 - val_recall: 0.9293 - val_precision: 0.5784\n",
            "Epoch 489/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.1097 - accuracy: 0.9501 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9503 - precision: 0.9478\n",
            "Epoch 489: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.1100 - accuracy: 0.9502 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9490 - precision: 0.9490 - val_loss: 2.5360 - val_accuracy: 0.5828 - val_sensitivity_at_specificity: 0.7047 - val_specificity_at_sensitivity: 0.6545 - val_recall: 0.9454 - val_precision: 0.5409\n",
            "Epoch 490/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1029 - accuracy: 0.9576 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9983 - recall: 0.9627 - precision: 0.9533\n",
            "Epoch 490: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.1029 - accuracy: 0.9576 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9983 - recall: 0.9627 - precision: 0.9533 - val_loss: 2.1632 - val_accuracy: 0.5977 - val_sensitivity_at_specificity: 0.6898 - val_specificity_at_sensitivity: 0.6820 - val_recall: 0.9244 - val_precision: 0.5624\n",
            "Epoch 491/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1242 - accuracy: 0.9469 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9526 - precision: 0.9440\n",
            "Epoch 491: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.1242 - accuracy: 0.9469 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9526 - precision: 0.9440 - val_loss: 2.0397 - val_accuracy: 0.6094 - val_sensitivity_at_specificity: 0.7701 - val_specificity_at_sensitivity: 0.7492 - val_recall: 0.9502 - val_precision: 0.5575\n",
            "Epoch 492/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0996 - accuracy: 0.9602 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9608 - precision: 0.9608\n",
            "Epoch 492: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.0996 - accuracy: 0.9602 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9608 - precision: 0.9608 - val_loss: 2.0405 - val_accuracy: 0.6195 - val_sensitivity_at_specificity: 0.7377 - val_specificity_at_sensitivity: 0.7481 - val_recall: 0.9571 - val_precision: 0.5669\n",
            "Epoch 493/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1079 - accuracy: 0.9590 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9680 - precision: 0.9509\n",
            "Epoch 493: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.1079 - accuracy: 0.9590 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9680 - precision: 0.9509 - val_loss: 2.0846 - val_accuracy: 0.5891 - val_sensitivity_at_specificity: 0.7917 - val_specificity_at_sensitivity: 0.7500 - val_recall: 0.9283 - val_precision: 0.5356\n",
            "Epoch 494/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0994 - accuracy: 0.9629 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9619 - precision: 0.9627\n",
            "Epoch 494: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.0994 - accuracy: 0.9629 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9619 - precision: 0.9627 - val_loss: 2.2268 - val_accuracy: 0.6141 - val_sensitivity_at_specificity: 0.7783 - val_specificity_at_sensitivity: 0.6739 - val_recall: 0.9638 - val_precision: 0.5655\n",
            "Epoch 495/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1044 - accuracy: 0.9551 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9620 - precision: 0.9495\n",
            "Epoch 495: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.1044 - accuracy: 0.9551 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9620 - precision: 0.9495 - val_loss: 2.2186 - val_accuracy: 0.5992 - val_sensitivity_at_specificity: 0.7566 - val_specificity_at_sensitivity: 0.6964 - val_recall: 0.9391 - val_precision: 0.5454\n",
            "Epoch 496/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1116 - accuracy: 0.9563 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9556 - precision: 0.9571\n",
            "Epoch 496: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.1116 - accuracy: 0.9563 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9556 - precision: 0.9571 - val_loss: 1.9222 - val_accuracy: 0.6320 - val_sensitivity_at_specificity: 0.7624 - val_specificity_at_sensitivity: 0.7138 - val_recall: 0.9173 - val_precision: 0.5945\n",
            "Epoch 497/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0975 - accuracy: 0.9594 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9571 - precision: 0.9616\n",
            "Epoch 497: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.0975 - accuracy: 0.9594 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9571 - precision: 0.9616 - val_loss: 2.6241 - val_accuracy: 0.5781 - val_sensitivity_at_specificity: 0.7008 - val_specificity_at_sensitivity: 0.6412 - val_recall: 0.9584 - val_precision: 0.5382\n",
            "Epoch 498/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1077 - accuracy: 0.9582 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9582 - precision: 0.9575\n",
            "Epoch 498: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.1077 - accuracy: 0.9582 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9582 - precision: 0.9575 - val_loss: 2.4608 - val_accuracy: 0.6023 - val_sensitivity_at_specificity: 0.6945 - val_specificity_at_sensitivity: 0.6822 - val_recall: 0.9496 - val_precision: 0.5583\n",
            "Epoch 499/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0975 - accuracy: 0.9605 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9705 - precision: 0.9520\n",
            "Epoch 499: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.0975 - accuracy: 0.9605 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9705 - precision: 0.9520 - val_loss: 2.3144 - val_accuracy: 0.5977 - val_sensitivity_at_specificity: 0.7283 - val_specificity_at_sensitivity: 0.6934 - val_recall: 0.9286 - val_precision: 0.5604\n",
            "Epoch 500/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1055 - accuracy: 0.9578 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9627 - precision: 0.9555\n",
            "Epoch 500: val_accuracy did not improve from 0.67422\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.1055 - accuracy: 0.9578 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9627 - precision: 0.9555 - val_loss: 2.3281 - val_accuracy: 0.5914 - val_sensitivity_at_specificity: 0.7778 - val_specificity_at_sensitivity: 0.6920 - val_recall: 0.9533 - val_precision: 0.5451\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Performance Metrics**"
      ],
      "metadata": {
        "id": "I-JNNAiCJYCE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Training_Accuracy=history.history['accuracy']\n",
        "Validation_Accuracy=history.history['val_accuracy']\n",
        "Validation_Specificity=history.history['val_specificity_at_sensitivity']\n",
        "Validation_Sensitivity=history.history['val_sensitivity_at_specificity']\n",
        "Validation_Recall=history.history['val_recall']\n",
        "Validation_Precision=history.history['val_precision']\n",
        "Validation_Loss=history.history['val_loss']\n",
        "\n",
        "print(\"Training Accuracy: \",max(Training_Accuracy))\n",
        "print(\"Validation Accuracy: \",max(Validation_Accuracy))\n",
        "print(\"Validation Specificity: \",max(Validation_Specificity))\n",
        "print(\"Validation Sensitivity: \",max(Validation_Sensitivity))\n",
        "print(\"Validation Recall: \",max(Validation_Recall))\n",
        "print(\"Validation Precision: \",max(Validation_Precision))\n",
        "print(\"Validation Loss: \",min(Validation_Loss))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCdS_0U65A0-",
        "outputId": "2cc1523f-3ee8-4dfe-b03c-15d9fed393b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy:  0.9683593511581421\n",
            "Validation Accuracy:  0.6742187738418579\n",
            "Validation Specificity:  0.881538450717926\n",
            "Validation Sensitivity:  0.9226973652839661\n",
            "Validation Recall:  1.0\n",
            "Validation Precision:  0.6264674663543701\n",
            "Validation Loss:  0.5551823973655701\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Accuracy Graph**"
      ],
      "metadata": {
        "id": "bXjlmqJoJbLs"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLqjG2X-vdLj",
        "outputId": "cc4278cf-b4a3-4cd2-9c46-fd86d488f6a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        }
      },
      "source": [
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loss Graph**"
      ],
      "metadata": {
        "id": "GUorO_ZaJc7E"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBSAyVfivvHX",
        "outputId": "6adc0c62-0ee4-4e32-e402-f6fba40e76a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        }
      },
      "source": [
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}