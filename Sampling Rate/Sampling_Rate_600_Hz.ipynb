{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "7e88OLey6Bgd"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7e88OLey6Bgd"
      },
      "source": [
        "# **Image Classification with Convolutional Neural Networks (CNNs)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsTzc3oi726u"
      },
      "source": [
        "# **Building a Convolutional Neural Network with Keras**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import Libraries**"
      ],
      "metadata": {
        "id": "xpK9LnMBFPgS"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCglDGFy8AhT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "4b188218-7304-43a2-e63b-0dd036e8a0ab"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "tf.__version__\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import matplotlib.image as mpimg\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "import imageio\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.8.2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qf7eW3HC9XVL"
      },
      "source": [
        "**Data Acquisition and ImageDataGenerator**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0BfyGlJbx0l"
      },
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255) #Normalize the pixel values\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hsimgs7aqt6G"
      },
      "source": [
        "#File path to the folder containin images\n",
        "train_dir = os.path.join('/content/spectrograms-600/Train')\n",
        "validation_dir = os.path.join('/content/spectrograms-600/Validation')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NyvlF41oqxEP",
        "outputId": "75fbe57d-60be-4dd4-b8b3-2a70f32af63f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(64,64),\n",
        "    batch_size=256,\n",
        "    shuffle=True,\n",
        "    class_mode='binary')\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    validation_dir,\n",
        "    target_size=(64,64),\n",
        "    batch_size=256,\n",
        "    shuffle=True,\n",
        "    class_mode='binary')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 33128 images belonging to 2 classes.\n",
            "Found 6780 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3yhwpN_-BaS"
      },
      "source": [
        "**Building the Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSzxq4KDtKN6"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "                                    \n",
        "    # First convolution layer \n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(64, 64, 3),use_bias=True),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "\n",
        "    # Second convolution layer \n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu',use_bias=True),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    \n",
        "\n",
        "    # Third convolution layer  \n",
        "    tf.keras.layers.Conv2D(256, (3,3), activation='relu',use_bias=True),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "\n",
        "  # Fourth convolution layer  \n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu',use_bias=True),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "\n",
        "\n",
        "    # Flatten the pooled feature maps\n",
        "    tf.keras.layers.Flatten(),\n",
        "\n",
        "    # Fully connected hidden layer\n",
        "    tf.keras.layers.Dense(8, activation='relu',use_bias=True),\n",
        "\n",
        "\n",
        "    # Output layer\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid',activity_regularizer=regularizers.L1(0.001))   \n",
        "\n",
        "])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDXufVt4-LFY"
      },
      "source": [
        "**Model Summary**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HU0RFGLtNJb",
        "outputId": "08c30a3c-9036-4547-f6ec-6ffdd88b7e8f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 62, 62, 64)        1792      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 31, 31, 64)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 31, 31, 64)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 29, 29, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 14, 14, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 12, 12, 256)       295168    \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 6, 6, 256)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 6, 6, 256)         0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 4, 4, 64)          147520    \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 2, 2, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 2, 2, 64)          0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 8)                 2056      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 520,401\n",
            "Trainable params: 520,401\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THk8lK3G-cdk"
      },
      "source": [
        "**Optimizer Implementation and model training/validation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBN3GBMItPMH"
      },
      "source": [
        "#from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import SensitivityAtSpecificity,SpecificityAtSensitivity,Recall,Precision\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=Adam(learning_rate=0.001),\n",
        "              metrics=['accuracy',SensitivityAtSpecificity(0.5),SpecificityAtSensitivity(0.5),Recall(0.5),Precision(0.5)])  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Q0MPMwh3EgY"
      },
      "source": [
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('val_accuracy')>0.99): \n",
        "      print(\"\\nReached 99% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "callbacks = myCallback()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7f6gDG3dx9sJ",
        "outputId": "312ae4ff-f159-42c6-d0c6-639c8a61ac0f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "checkpoint = ModelCheckpoint(\"ECG_Spectrogram_Model.h5\", monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
        "\n",
        "history = model.fit(\n",
        "      train_generator,\n",
        "      steps_per_epoch=10,  \n",
        "      epochs=500,\n",
        "      verbose=1,\n",
        "      validation_data = validation_generator,\n",
        "      validation_steps=5, \n",
        "      callbacks = [callbacks,checkpoint]\n",
        ") "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.7016 - accuracy: 0.4953 - sensitivity_at_specificity: 0.2454 - specificity_at_sensitivity: 0.3054 - recall: 0.3958 - precision: 0.5020\n",
            "Epoch 1: val_accuracy improved from -inf to 0.53047, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 17s 230ms/step - loss: 0.7016 - accuracy: 0.4953 - sensitivity_at_specificity: 0.2454 - specificity_at_sensitivity: 0.3054 - recall: 0.3958 - precision: 0.5020 - val_loss: 0.6936 - val_accuracy: 0.5305 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.0000e+00 - val_recall: 1.0000 - val_precision: 0.5305\n",
            "Epoch 2/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6942 - accuracy: 0.4703 - sensitivity_at_specificity: 0.0676 - specificity_at_sensitivity: 7.5075e-04 - recall: 0.8738 - precision: 0.4719\n",
            "Epoch 2: val_accuracy did not improve from 0.53047\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.6942 - accuracy: 0.4703 - sensitivity_at_specificity: 0.0676 - specificity_at_sensitivity: 7.5075e-04 - recall: 0.8738 - precision: 0.4719 - val_loss: 0.6936 - val_accuracy: 0.4945 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.0000e+00 - val_recall: 1.0000 - val_precision: 0.4945\n",
            "Epoch 3/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6937 - accuracy: 0.4988 - sensitivity_at_specificity: 0.0156 - specificity_at_sensitivity: 0.0016 - recall: 0.0976 - precision: 0.4960\n",
            "Epoch 3: val_accuracy did not improve from 0.53047\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.6937 - accuracy: 0.4988 - sensitivity_at_specificity: 0.0156 - specificity_at_sensitivity: 0.0016 - recall: 0.0976 - precision: 0.4960 - val_loss: 0.6937 - val_accuracy: 0.4875 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
            "Epoch 4/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6937 - accuracy: 0.5047 - sensitivity_at_specificity: 0.0055 - specificity_at_sensitivity: 0.0000e+00 - recall: 0.0111 - precision: 0.4516\n",
            "Epoch 4: val_accuracy did not improve from 0.53047\n",
            "10/10 [==============================] - 2s 156ms/step - loss: 0.6937 - accuracy: 0.5047 - sensitivity_at_specificity: 0.0055 - specificity_at_sensitivity: 0.0000e+00 - recall: 0.0111 - precision: 0.4516 - val_loss: 0.6937 - val_accuracy: 0.4719 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
            "Epoch 5/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6937 - accuracy: 0.4945 - sensitivity_at_specificity: 0.0062 - specificity_at_sensitivity: 0.0000e+00 - recall: 0.0070 - precision: 0.3600\n",
            "Epoch 5: val_accuracy did not improve from 0.53047\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.6937 - accuracy: 0.4945 - sensitivity_at_specificity: 0.0062 - specificity_at_sensitivity: 0.0000e+00 - recall: 0.0070 - precision: 0.3600 - val_loss: 0.6936 - val_accuracy: 0.5156 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
            "Epoch 6/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6936 - accuracy: 0.5059 - sensitivity_at_specificity: 0.0039 - specificity_at_sensitivity: 0.0000e+00 - recall: 0.0055 - precision: 0.5385\n",
            "Epoch 6: val_accuracy did not improve from 0.53047\n",
            "10/10 [==============================] - 2s 219ms/step - loss: 0.6936 - accuracy: 0.5059 - sensitivity_at_specificity: 0.0039 - specificity_at_sensitivity: 0.0000e+00 - recall: 0.0055 - precision: 0.5385 - val_loss: 0.6936 - val_accuracy: 0.5125 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
            "Epoch 7/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6937 - accuracy: 0.4863 - sensitivity_at_specificity: 0.0046 - specificity_at_sensitivity: 0.0024 - recall: 0.0061 - precision: 0.5000\n",
            "Epoch 7: val_accuracy did not improve from 0.53047\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.6937 - accuracy: 0.4863 - sensitivity_at_specificity: 0.0046 - specificity_at_sensitivity: 0.0024 - recall: 0.0061 - precision: 0.5000 - val_loss: 0.6937 - val_accuracy: 0.4922 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
            "Epoch 8/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6935 - accuracy: 0.4906 - sensitivity_at_specificity: 7.6687e-04 - specificity_at_sensitivity: 0.0844 - recall: 7.6687e-04 - precision: 0.5000\n",
            "Epoch 8: val_accuracy did not improve from 0.53047\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.6935 - accuracy: 0.4906 - sensitivity_at_specificity: 7.6687e-04 - specificity_at_sensitivity: 0.0844 - recall: 7.6687e-04 - precision: 0.5000 - val_loss: 0.6936 - val_accuracy: 0.5000 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.0031 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
            "Epoch 9/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6757 - accuracy: 0.5156 - sensitivity_at_specificity: 0.0016 - specificity_at_sensitivity: 0.4806 - recall: 0.1187 - precision: 0.5593\n",
            "Epoch 9: val_accuracy did not improve from 0.53047\n",
            "10/10 [==============================] - 2s 157ms/step - loss: 0.6757 - accuracy: 0.5156 - sensitivity_at_specificity: 0.0016 - specificity_at_sensitivity: 0.4806 - recall: 0.1187 - precision: 0.5593 - val_loss: 0.6778 - val_accuracy: 0.5266 - val_sensitivity_at_specificity: 0.6187 - val_specificity_at_sensitivity: 0.5766 - val_recall: 0.2625 - val_precision: 0.5563\n",
            "Epoch 10/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5603 - accuracy: 0.6855 - sensitivity_at_specificity: 0.9740 - specificity_at_sensitivity: 0.6610 - recall: 0.6956 - precision: 0.6779\n",
            "Epoch 10: val_accuracy improved from 0.53047 to 0.59062, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.5603 - accuracy: 0.6855 - sensitivity_at_specificity: 0.9740 - specificity_at_sensitivity: 0.6610 - recall: 0.6956 - precision: 0.6779 - val_loss: 0.6336 - val_accuracy: 0.5906 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.2272 - val_recall: 0.9885 - val_precision: 0.5388\n",
            "Epoch 11/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4936 - accuracy: 0.7574 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.5482 - recall: 0.9838 - precision: 0.6685\n",
            "Epoch 11: val_accuracy improved from 0.59062 to 0.61406, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.4936 - accuracy: 0.7574 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.5482 - recall: 0.9838 - precision: 0.6685 - val_loss: 0.6320 - val_accuracy: 0.6141 - val_sensitivity_at_specificity: 0.2704 - val_specificity_at_sensitivity: 0.2830 - val_recall: 0.9969 - val_precision: 0.5688\n",
            "Epoch 12/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4806 - accuracy: 0.7695 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.7809 - recall: 0.9894 - precision: 0.6944\n",
            "Epoch 12: val_accuracy did not improve from 0.61406\n",
            "10/10 [==============================] - 2s 157ms/step - loss: 0.4806 - accuracy: 0.7695 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.7809 - recall: 0.9894 - precision: 0.6944 - val_loss: 0.6243 - val_accuracy: 0.6016 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4953 - val_recall: 0.9984 - val_precision: 0.5582\n",
            "Epoch 13/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4632 - accuracy: 0.7715 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.7672 - recall: 0.9922 - precision: 0.6890\n",
            "Epoch 13: val_accuracy improved from 0.61406 to 0.62422, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.4632 - accuracy: 0.7715 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.7672 - recall: 0.9922 - precision: 0.6890 - val_loss: 0.6273 - val_accuracy: 0.6242 - val_sensitivity_at_specificity: 0.0988 - val_specificity_at_sensitivity: 0.2159 - val_recall: 1.0000 - val_precision: 0.5850\n",
            "Epoch 14/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4565 - accuracy: 0.7703 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7738 - recall: 0.9968 - precision: 0.6826\n",
            "Epoch 14: val_accuracy did not improve from 0.62422\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.4565 - accuracy: 0.7703 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7738 - recall: 0.9968 - precision: 0.6826 - val_loss: 0.6259 - val_accuracy: 0.6070 - val_sensitivity_at_specificity: 0.0344 - val_specificity_at_sensitivity: 0.2434 - val_recall: 0.9844 - val_precision: 0.5606\n",
            "Epoch 15/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4618 - accuracy: 0.7633 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7511 - recall: 0.9903 - precision: 0.6743\n",
            "Epoch 15: val_accuracy did not improve from 0.62422\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.4618 - accuracy: 0.7633 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7511 - recall: 0.9903 - precision: 0.6743 - val_loss: 0.6450 - val_accuracy: 0.5672 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.3628 - val_recall: 1.0000 - val_precision: 0.5208\n",
            "Epoch 16/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4523 - accuracy: 0.7805 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7829 - recall: 0.9977 - precision: 0.6962\n",
            "Epoch 16: val_accuracy did not improve from 0.62422\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.4523 - accuracy: 0.7805 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7829 - recall: 0.9977 - precision: 0.6962 - val_loss: 0.6339 - val_accuracy: 0.5992 - val_sensitivity_at_specificity: 0.0081 - val_specificity_at_sensitivity: 0.2564 - val_recall: 0.9839 - val_precision: 0.5485\n",
            "Epoch 17/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4606 - accuracy: 0.7719 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7591 - recall: 0.9881 - precision: 0.6872\n",
            "Epoch 17: val_accuracy did not improve from 0.62422\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.4606 - accuracy: 0.7719 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7591 - recall: 0.9881 - precision: 0.6872 - val_loss: 0.6376 - val_accuracy: 0.5969 - val_sensitivity_at_specificity: 0.0093 - val_specificity_at_sensitivity: 0.2088 - val_recall: 1.0000 - val_precision: 0.5548\n",
            "Epoch 18/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4573 - accuracy: 0.7785 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7735 - recall: 0.9826 - precision: 0.7051\n",
            "Epoch 18: val_accuracy did not improve from 0.62422\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.4573 - accuracy: 0.7785 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7735 - recall: 0.9826 - precision: 0.7051 - val_loss: 0.7044 - val_accuracy: 0.5734 - val_sensitivity_at_specificity: 0.0125 - val_specificity_at_sensitivity: 0.1661 - val_recall: 1.0000 - val_precision: 0.5404\n",
            "Epoch 19/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4766 - accuracy: 0.7600 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7496 - recall: 0.9933 - precision: 0.6761\n",
            "Epoch 19: val_accuracy did not improve from 0.62422\n",
            "10/10 [==============================] - 2s 193ms/step - loss: 0.4766 - accuracy: 0.7600 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7496 - recall: 0.9933 - precision: 0.6761 - val_loss: 0.6255 - val_accuracy: 0.6047 - val_sensitivity_at_specificity: 0.0047 - val_specificity_at_sensitivity: 0.2316 - val_recall: 0.9891 - val_precision: 0.5596\n",
            "Epoch 20/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4738 - accuracy: 0.7590 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7317 - recall: 0.9952 - precision: 0.6729\n",
            "Epoch 20: val_accuracy did not improve from 0.62422\n",
            "10/10 [==============================] - 2s 154ms/step - loss: 0.4738 - accuracy: 0.7590 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7317 - recall: 0.9952 - precision: 0.6729 - val_loss: 0.6357 - val_accuracy: 0.5945 - val_sensitivity_at_specificity: 0.0222 - val_specificity_at_sensitivity: 0.2145 - val_recall: 0.9968 - val_precision: 0.5493\n",
            "Epoch 21/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4623 - accuracy: 0.7672 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7139 - recall: 0.9930 - precision: 0.6847\n",
            "Epoch 21: val_accuracy did not improve from 0.62422\n",
            "10/10 [==============================] - 2s 156ms/step - loss: 0.4623 - accuracy: 0.7672 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7139 - recall: 0.9930 - precision: 0.6847 - val_loss: 0.6552 - val_accuracy: 0.5867 - val_sensitivity_at_specificity: 0.0111 - val_specificity_at_sensitivity: 0.2046 - val_recall: 1.0000 - val_precision: 0.5436\n",
            "Epoch 22/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4344 - accuracy: 0.7914 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7617 - recall: 0.9937 - precision: 0.7075\n",
            "Epoch 22: val_accuracy did not improve from 0.62422\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.4344 - accuracy: 0.7914 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7617 - recall: 0.9937 - precision: 0.7075 - val_loss: 0.6475 - val_accuracy: 0.5984 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.2126 - val_recall: 0.9984 - val_precision: 0.5566\n",
            "Epoch 23/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4479 - accuracy: 0.7801 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7728 - recall: 0.9961 - precision: 0.6954\n",
            "Epoch 23: val_accuracy did not improve from 0.62422\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.4479 - accuracy: 0.7801 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7728 - recall: 0.9961 - precision: 0.6954 - val_loss: 0.6267 - val_accuracy: 0.6219 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.2456 - val_recall: 0.9878 - val_precision: 0.5769\n",
            "Epoch 24/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4633 - accuracy: 0.7660 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7135 - recall: 0.9945 - precision: 0.6812\n",
            "Epoch 24: val_accuracy did not improve from 0.62422\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.4633 - accuracy: 0.7660 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7135 - recall: 0.9945 - precision: 0.6812 - val_loss: 0.6444 - val_accuracy: 0.5953 - val_sensitivity_at_specificity: 0.0124 - val_specificity_at_sensitivity: 0.1984 - val_recall: 0.9984 - val_precision: 0.5547\n",
            "Epoch 25/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4532 - accuracy: 0.7766 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.7846 - recall: 0.9921 - precision: 0.6907\n",
            "Epoch 25: val_accuracy did not improve from 0.62422\n",
            "10/10 [==============================] - 2s 157ms/step - loss: 0.4532 - accuracy: 0.7766 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.7846 - recall: 0.9921 - precision: 0.6907 - val_loss: 0.6567 - val_accuracy: 0.5875 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.2726 - val_recall: 0.9968 - val_precision: 0.5386\n",
            "Epoch 26/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4590 - accuracy: 0.7660 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.7644 - recall: 0.9919 - precision: 0.6755\n",
            "Epoch 26: val_accuracy did not improve from 0.62422\n",
            "10/10 [==============================] - 2s 156ms/step - loss: 0.4590 - accuracy: 0.7660 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.7644 - recall: 0.9919 - precision: 0.6755 - val_loss: 0.6358 - val_accuracy: 0.6047 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.2224 - val_recall: 1.0000 - val_precision: 0.5608\n",
            "Epoch 27/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4493 - accuracy: 0.7809 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.7728 - recall: 0.9897 - precision: 0.6957\n",
            "Epoch 27: val_accuracy did not improve from 0.62422\n",
            "10/10 [==============================] - 2s 156ms/step - loss: 0.4493 - accuracy: 0.7809 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.7728 - recall: 0.9897 - precision: 0.6957 - val_loss: 0.6327 - val_accuracy: 0.6086 - val_sensitivity_at_specificity: 0.0709 - val_specificity_at_sensitivity: 0.2792 - val_recall: 0.9968 - val_precision: 0.5537\n",
            "Epoch 28/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4388 - accuracy: 0.7852 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7857 - recall: 0.9867 - precision: 0.7027\n",
            "Epoch 28: val_accuracy did not improve from 0.62422\n",
            "10/10 [==============================] - 2s 155ms/step - loss: 0.4388 - accuracy: 0.7852 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7857 - recall: 0.9867 - precision: 0.7027 - val_loss: 0.6401 - val_accuracy: 0.6008 - val_sensitivity_at_specificity: 0.0144 - val_specificity_at_sensitivity: 0.4572 - val_recall: 0.9617 - val_precision: 0.5528\n",
            "Epoch 29/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4579 - accuracy: 0.7707 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.7508 - recall: 0.9769 - precision: 0.6874\n",
            "Epoch 29: val_accuracy did not improve from 0.62422\n",
            "10/10 [==============================] - 2s 157ms/step - loss: 0.4579 - accuracy: 0.7707 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.7508 - recall: 0.9769 - precision: 0.6874 - val_loss: 0.6406 - val_accuracy: 0.6102 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.2533 - val_recall: 1.0000 - val_precision: 0.5724\n",
            "Epoch 30/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4484 - accuracy: 0.7801 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.7742 - recall: 0.9890 - precision: 0.6960\n",
            "Epoch 30: val_accuracy improved from 0.62422 to 0.63437, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.4484 - accuracy: 0.7801 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.7742 - recall: 0.9890 - precision: 0.6960 - val_loss: 0.6269 - val_accuracy: 0.6344 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.3228 - val_recall: 0.9970 - val_precision: 0.5912\n",
            "Epoch 31/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4436 - accuracy: 0.7848 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7924 - recall: 0.9977 - precision: 0.7035\n",
            "Epoch 31: val_accuracy did not improve from 0.63437\n",
            "10/10 [==============================] - 2s 156ms/step - loss: 0.4436 - accuracy: 0.7848 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7924 - recall: 0.9977 - precision: 0.7035 - val_loss: 0.6363 - val_accuracy: 0.6172 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.3221 - val_recall: 0.9939 - val_precision: 0.5741\n",
            "Epoch 32/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4719 - accuracy: 0.7613 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7236 - recall: 0.9899 - precision: 0.6799\n",
            "Epoch 32: val_accuracy did not improve from 0.63437\n",
            "10/10 [==============================] - 2s 155ms/step - loss: 0.4719 - accuracy: 0.7613 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7236 - recall: 0.9899 - precision: 0.6799 - val_loss: 0.6496 - val_accuracy: 0.5891 - val_sensitivity_at_specificity: 0.0079 - val_specificity_at_sensitivity: 0.2229 - val_recall: 0.9905 - val_precision: 0.5470\n",
            "Epoch 33/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4388 - accuracy: 0.7875 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.7954 - recall: 0.9953 - precision: 0.7046\n",
            "Epoch 33: val_accuracy did not improve from 0.63437\n",
            "10/10 [==============================] - 2s 157ms/step - loss: 0.4388 - accuracy: 0.7875 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.7954 - recall: 0.9953 - precision: 0.7046 - val_loss: 0.6676 - val_accuracy: 0.5953 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.2385 - val_recall: 0.9969 - val_precision: 0.5571\n",
            "Epoch 34/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4526 - accuracy: 0.7756 - sensitivity_at_specificity: 0.9991 - specificity_at_sensitivity: 0.7621 - recall: 0.9904 - precision: 0.6920\n",
            "Epoch 34: val_accuracy did not improve from 0.63437\n",
            "10/10 [==============================] - 2s 151ms/step - loss: 0.4519 - accuracy: 0.7762 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.7670 - recall: 0.9900 - precision: 0.6931 - val_loss: 0.6468 - val_accuracy: 0.5984 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.2515 - val_recall: 0.9920 - val_precision: 0.5504\n",
            "Epoch 35/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4356 - accuracy: 0.7902 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.7891 - recall: 0.9945 - precision: 0.7060\n",
            "Epoch 35: val_accuracy did not improve from 0.63437\n",
            "10/10 [==============================] - 2s 157ms/step - loss: 0.4356 - accuracy: 0.7902 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.7891 - recall: 0.9945 - precision: 0.7060 - val_loss: 0.6606 - val_accuracy: 0.5867 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4813 - val_recall: 0.9951 - val_precision: 0.5370\n",
            "Epoch 36/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4586 - accuracy: 0.7691 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7571 - recall: 0.9892 - precision: 0.6889\n",
            "Epoch 36: val_accuracy did not improve from 0.63437\n",
            "10/10 [==============================] - 2s 156ms/step - loss: 0.4586 - accuracy: 0.7691 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7571 - recall: 0.9892 - precision: 0.6889 - val_loss: 0.6290 - val_accuracy: 0.6227 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.3060 - val_recall: 0.9833 - val_precision: 0.5786\n",
            "Epoch 37/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4527 - accuracy: 0.7734 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7683 - recall: 0.9913 - precision: 0.6879\n",
            "Epoch 37: val_accuracy did not improve from 0.63437\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.4527 - accuracy: 0.7734 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7683 - recall: 0.9913 - precision: 0.6879 - val_loss: 0.6380 - val_accuracy: 0.5992 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.2336 - val_recall: 0.9984 - val_precision: 0.5493\n",
            "Epoch 38/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4442 - accuracy: 0.7887 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7727 - recall: 0.9917 - precision: 0.7124\n",
            "Epoch 38: val_accuracy improved from 0.63437 to 0.63672, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.4442 - accuracy: 0.7887 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7727 - recall: 0.9917 - precision: 0.7124 - val_loss: 0.6275 - val_accuracy: 0.6367 - val_sensitivity_at_specificity: 0.2288 - val_specificity_at_sensitivity: 0.2806 - val_recall: 0.9955 - val_precision: 0.5871\n",
            "Epoch 39/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4396 - accuracy: 0.7848 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.7664 - recall: 0.9928 - precision: 0.6953\n",
            "Epoch 39: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 157ms/step - loss: 0.4396 - accuracy: 0.7848 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.7664 - recall: 0.9928 - precision: 0.6953 - val_loss: 0.6358 - val_accuracy: 0.6141 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.2595 - val_recall: 0.9969 - val_precision: 0.5677\n",
            "Epoch 40/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4568 - accuracy: 0.7691 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7271 - recall: 0.9984 - precision: 0.6816\n",
            "Epoch 40: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.4568 - accuracy: 0.7691 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7271 - recall: 0.9984 - precision: 0.6816 - val_loss: 0.6357 - val_accuracy: 0.6156 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.2279 - val_recall: 0.9985 - val_precision: 0.5719\n",
            "Epoch 41/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4324 - accuracy: 0.7949 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7626 - recall: 0.9885 - precision: 0.7173\n",
            "Epoch 41: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.4324 - accuracy: 0.7949 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7626 - recall: 0.9885 - precision: 0.7173 - val_loss: 0.6590 - val_accuracy: 0.6125 - val_sensitivity_at_specificity: 0.0119 - val_specificity_at_sensitivity: 0.2069 - val_recall: 0.9985 - val_precision: 0.5751\n",
            "Epoch 42/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4480 - accuracy: 0.7812 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.7642 - recall: 0.9890 - precision: 0.6978\n",
            "Epoch 42: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.4480 - accuracy: 0.7812 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.7642 - recall: 0.9890 - precision: 0.6978 - val_loss: 0.6473 - val_accuracy: 0.6062 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.2428 - val_recall: 0.9939 - val_precision: 0.5652\n",
            "Epoch 43/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4346 - accuracy: 0.7930 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7849 - recall: 0.9915 - precision: 0.7129\n",
            "Epoch 43: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.4346 - accuracy: 0.7930 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7849 - recall: 0.9915 - precision: 0.7129 - val_loss: 0.6548 - val_accuracy: 0.6023 - val_sensitivity_at_specificity: 0.0269 - val_specificity_at_sensitivity: 0.2793 - val_recall: 0.9921 - val_precision: 0.5544\n",
            "Epoch 44/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4339 - accuracy: 0.7957 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7671 - recall: 0.9901 - precision: 0.7192\n",
            "Epoch 44: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.4339 - accuracy: 0.7957 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7671 - recall: 0.9901 - precision: 0.7192 - val_loss: 0.6633 - val_accuracy: 0.6055 - val_sensitivity_at_specificity: 0.0932 - val_specificity_at_sensitivity: 0.2581 - val_recall: 0.9984 - val_precision: 0.5563\n",
            "Epoch 45/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4497 - accuracy: 0.7773 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7718 - recall: 0.9905 - precision: 0.6922\n",
            "Epoch 45: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.4497 - accuracy: 0.7773 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7718 - recall: 0.9905 - precision: 0.6922 - val_loss: 0.6490 - val_accuracy: 0.5898 - val_sensitivity_at_specificity: 0.0016 - val_specificity_at_sensitivity: 0.2599 - val_recall: 0.9904 - val_precision: 0.5427\n",
            "Epoch 46/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4474 - accuracy: 0.7836 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7358 - recall: 0.9953 - precision: 0.7005\n",
            "Epoch 46: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 157ms/step - loss: 0.4474 - accuracy: 0.7836 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7358 - recall: 0.9953 - precision: 0.7005 - val_loss: 0.6347 - val_accuracy: 0.6195 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.2915 - val_recall: 0.9879 - val_precision: 0.5761\n",
            "Epoch 47/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4315 - accuracy: 0.7937 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7716 - recall: 0.9924 - precision: 0.7154\n",
            "Epoch 47: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 176ms/step - loss: 0.4315 - accuracy: 0.7937 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7716 - recall: 0.9924 - precision: 0.7154 - val_loss: 0.6600 - val_accuracy: 0.6047 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.3071 - val_recall: 0.9968 - val_precision: 0.5556\n",
            "Epoch 48/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4432 - accuracy: 0.7879 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.7805 - recall: 0.9946 - precision: 0.7066\n",
            "Epoch 48: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 175ms/step - loss: 0.4432 - accuracy: 0.7879 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.7805 - recall: 0.9946 - precision: 0.7066 - val_loss: 0.6503 - val_accuracy: 0.6164 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.2259 - val_recall: 0.9910 - val_precision: 0.5775\n",
            "Epoch 49/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4472 - accuracy: 0.7781 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7243 - recall: 0.9945 - precision: 0.6916\n",
            "Epoch 49: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.4472 - accuracy: 0.7781 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7243 - recall: 0.9945 - precision: 0.6916 - val_loss: 0.6463 - val_accuracy: 0.6047 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.2311 - val_recall: 0.9953 - val_precision: 0.5603\n",
            "Epoch 50/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4524 - accuracy: 0.7758 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7419 - recall: 0.9834 - precision: 0.6924\n",
            "Epoch 50: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 156ms/step - loss: 0.4524 - accuracy: 0.7758 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7419 - recall: 0.9834 - precision: 0.6924 - val_loss: 0.6436 - val_accuracy: 0.6016 - val_sensitivity_at_specificity: 0.0286 - val_specificity_at_sensitivity: 0.2289 - val_recall: 0.9984 - val_precision: 0.5523\n",
            "Epoch 51/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4548 - accuracy: 0.7672 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7666 - recall: 0.9928 - precision: 0.6794\n",
            "Epoch 51: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.4548 - accuracy: 0.7672 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7666 - recall: 0.9928 - precision: 0.6794 - val_loss: 0.6469 - val_accuracy: 0.6008 - val_sensitivity_at_specificity: 0.0061 - val_specificity_at_sensitivity: 0.2572 - val_recall: 0.9681 - val_precision: 0.5652\n",
            "Epoch 52/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4498 - accuracy: 0.7773 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7796 - recall: 0.9886 - precision: 0.7003\n",
            "Epoch 52: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.4498 - accuracy: 0.7773 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7796 - recall: 0.9886 - precision: 0.7003 - val_loss: 0.6666 - val_accuracy: 0.5945 - val_sensitivity_at_specificity: 0.0016 - val_specificity_at_sensitivity: 0.2019 - val_recall: 1.0000 - val_precision: 0.5526\n",
            "Epoch 53/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4568 - accuracy: 0.7785 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7484 - recall: 0.9917 - precision: 0.7019\n",
            "Epoch 53: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.4568 - accuracy: 0.7785 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7484 - recall: 0.9917 - precision: 0.7019 - val_loss: 0.6738 - val_accuracy: 0.5813 - val_sensitivity_at_specificity: 0.0224 - val_specificity_at_sensitivity: 0.1911 - val_recall: 1.0000 - val_precision: 0.5387\n",
            "Epoch 54/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4423 - accuracy: 0.7867 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.7634 - recall: 0.9985 - precision: 0.7040\n",
            "Epoch 54: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.4423 - accuracy: 0.7867 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.7634 - recall: 0.9985 - precision: 0.7040 - val_loss: 0.6581 - val_accuracy: 0.5945 - val_sensitivity_at_specificity: 0.0032 - val_specificity_at_sensitivity: 0.2102 - val_recall: 1.0000 - val_precision: 0.5495\n",
            "Epoch 55/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4647 - accuracy: 0.7656 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7111 - recall: 0.9866 - precision: 0.6823\n",
            "Epoch 55: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.4647 - accuracy: 0.7656 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7111 - recall: 0.9866 - precision: 0.6823 - val_loss: 0.6391 - val_accuracy: 0.6078 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.2350 - val_recall: 0.9969 - val_precision: 0.5629\n",
            "Epoch 56/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4421 - accuracy: 0.7882 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7549 - recall: 0.9959 - precision: 0.7072\n",
            "Epoch 56: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 1s 149ms/step - loss: 0.4421 - accuracy: 0.7882 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7549 - recall: 0.9959 - precision: 0.7072 - val_loss: 0.6614 - val_accuracy: 0.5922 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.2167 - val_recall: 0.9953 - val_precision: 0.5487\n",
            "Epoch 57/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4399 - accuracy: 0.7824 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7540 - recall: 0.9873 - precision: 0.6967\n",
            "Epoch 57: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.4399 - accuracy: 0.7824 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7540 - recall: 0.9873 - precision: 0.6967 - val_loss: 0.6686 - val_accuracy: 0.5867 - val_sensitivity_at_specificity: 0.0367 - val_specificity_at_sensitivity: 0.3165 - val_recall: 0.9521 - val_precision: 0.5443\n",
            "Epoch 58/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4510 - accuracy: 0.7805 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7698 - recall: 0.9931 - precision: 0.7001\n",
            "Epoch 58: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.4510 - accuracy: 0.7805 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7698 - recall: 0.9931 - precision: 0.7001 - val_loss: 0.6714 - val_accuracy: 0.5781 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.2240 - val_recall: 1.0000 - val_precision: 0.5288\n",
            "Epoch 59/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4579 - accuracy: 0.7708 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7719 - recall: 0.9868 - precision: 0.6904\n",
            "Epoch 59: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.4579 - accuracy: 0.7708 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7719 - recall: 0.9868 - precision: 0.6904 - val_loss: 0.6376 - val_accuracy: 0.6070 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.2725 - val_recall: 0.9936 - val_precision: 0.5537\n",
            "Epoch 60/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4626 - accuracy: 0.7742 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7475 - recall: 0.9963 - precision: 0.6997\n",
            "Epoch 60: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 155ms/step - loss: 0.4626 - accuracy: 0.7742 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7475 - recall: 0.9963 - precision: 0.6997 - val_loss: 0.6607 - val_accuracy: 0.5930 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.2220 - val_recall: 1.0000 - val_precision: 0.5497\n",
            "Epoch 61/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4540 - accuracy: 0.7742 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.7388 - recall: 0.9860 - precision: 0.6935\n",
            "Epoch 61: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.4540 - accuracy: 0.7742 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.7388 - recall: 0.9860 - precision: 0.6935 - val_loss: 0.6705 - val_accuracy: 0.5875 - val_sensitivity_at_specificity: 0.1837 - val_specificity_at_sensitivity: 0.2462 - val_recall: 0.9888 - val_precision: 0.5430\n",
            "Epoch 62/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4548 - accuracy: 0.7773 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7436 - recall: 0.9924 - precision: 0.6986\n",
            "Epoch 62: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.4548 - accuracy: 0.7773 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7436 - recall: 0.9924 - precision: 0.6986 - val_loss: 0.6529 - val_accuracy: 0.5984 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.3282 - val_recall: 0.9731 - val_precision: 0.5527\n",
            "Epoch 63/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4596 - accuracy: 0.7656 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.7223 - recall: 0.9816 - precision: 0.6807\n",
            "Epoch 63: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 156ms/step - loss: 0.4596 - accuracy: 0.7656 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.7223 - recall: 0.9816 - precision: 0.6807 - val_loss: 0.6400 - val_accuracy: 0.6102 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.2271 - val_recall: 1.0000 - val_precision: 0.5691\n",
            "Epoch 64/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4313 - accuracy: 0.7961 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7648 - recall: 0.9992 - precision: 0.7120\n",
            "Epoch 64: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.4313 - accuracy: 0.7961 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7648 - recall: 0.9992 - precision: 0.7120 - val_loss: 0.6410 - val_accuracy: 0.6148 - val_sensitivity_at_specificity: 0.0139 - val_specificity_at_sensitivity: 0.2484 - val_recall: 0.9892 - val_precision: 0.5688\n",
            "Epoch 65/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4465 - accuracy: 0.7832 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.7490 - recall: 0.9818 - precision: 0.7089\n",
            "Epoch 65: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.4465 - accuracy: 0.7832 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.7490 - recall: 0.9818 - precision: 0.7089 - val_loss: 0.6542 - val_accuracy: 0.6125 - val_sensitivity_at_specificity: 0.1115 - val_specificity_at_sensitivity: 0.2634 - val_recall: 0.9985 - val_precision: 0.5658\n",
            "Epoch 66/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4441 - accuracy: 0.7773 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7664 - recall: 0.9951 - precision: 0.6858\n",
            "Epoch 66: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 193ms/step - loss: 0.4441 - accuracy: 0.7773 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7664 - recall: 0.9951 - precision: 0.6858 - val_loss: 0.6576 - val_accuracy: 0.5961 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.3655 - val_recall: 0.9686 - val_precision: 0.5539\n",
            "Epoch 67/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4503 - accuracy: 0.7793 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7537 - recall: 0.9954 - precision: 0.6972\n",
            "Epoch 67: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 195ms/step - loss: 0.4503 - accuracy: 0.7793 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7537 - recall: 0.9954 - precision: 0.6972 - val_loss: 0.6529 - val_accuracy: 0.6016 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.2254 - val_recall: 1.0000 - val_precision: 0.5569\n",
            "Epoch 68/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4369 - accuracy: 0.7914 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7930 - recall: 0.9908 - precision: 0.7130\n",
            "Epoch 68: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 156ms/step - loss: 0.4369 - accuracy: 0.7914 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7930 - recall: 0.9908 - precision: 0.7130 - val_loss: 0.6659 - val_accuracy: 0.5945 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.2208 - val_recall: 0.9984 - val_precision: 0.5511\n",
            "Epoch 69/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4414 - accuracy: 0.7848 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7356 - recall: 0.9969 - precision: 0.6990\n",
            "Epoch 69: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.4414 - accuracy: 0.7848 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7356 - recall: 0.9969 - precision: 0.6990 - val_loss: 0.6325 - val_accuracy: 0.6203 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.3364 - val_recall: 0.9872 - val_precision: 0.5627\n",
            "Epoch 70/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4423 - accuracy: 0.7840 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7652 - recall: 0.9825 - precision: 0.7086\n",
            "Epoch 70: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 157ms/step - loss: 0.4423 - accuracy: 0.7840 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7652 - recall: 0.9825 - precision: 0.7086 - val_loss: 0.6856 - val_accuracy: 0.5820 - val_sensitivity_at_specificity: 0.0016 - val_specificity_at_sensitivity: 0.1957 - val_recall: 0.9984 - val_precision: 0.5432\n",
            "Epoch 71/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4502 - accuracy: 0.7734 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7863 - recall: 0.9976 - precision: 0.6837\n",
            "Epoch 71: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.4502 - accuracy: 0.7734 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7863 - recall: 0.9976 - precision: 0.6837 - val_loss: 0.6314 - val_accuracy: 0.6227 - val_sensitivity_at_specificity: 0.0213 - val_specificity_at_sensitivity: 0.2665 - val_recall: 0.9939 - val_precision: 0.5769\n",
            "Epoch 72/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4564 - accuracy: 0.7741 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7111 - recall: 0.9909 - precision: 0.6930\n",
            "Epoch 72: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 154ms/step - loss: 0.4564 - accuracy: 0.7741 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7111 - recall: 0.9909 - precision: 0.6930 - val_loss: 0.6466 - val_accuracy: 0.5898 - val_sensitivity_at_specificity: 0.2270 - val_specificity_at_sensitivity: 0.2366 - val_recall: 0.9984 - val_precision: 0.5367\n",
            "Epoch 73/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4665 - accuracy: 0.7621 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.6975 - recall: 0.9937 - precision: 0.6781\n",
            "Epoch 73: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.4665 - accuracy: 0.7621 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.6975 - recall: 0.9937 - precision: 0.6781 - val_loss: 0.6264 - val_accuracy: 0.6266 - val_sensitivity_at_specificity: 0.3825 - val_specificity_at_sensitivity: 0.2639 - val_recall: 0.9939 - val_precision: 0.5772\n",
            "Epoch 74/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4500 - accuracy: 0.7824 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.7736 - recall: 0.9909 - precision: 0.7064\n",
            "Epoch 74: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.4500 - accuracy: 0.7824 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.7736 - recall: 0.9909 - precision: 0.7064 - val_loss: 0.6651 - val_accuracy: 0.6016 - val_sensitivity_at_specificity: 0.0248 - val_specificity_at_sensitivity: 0.2334 - val_recall: 0.9969 - val_precision: 0.5590\n",
            "Epoch 75/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4449 - accuracy: 0.7766 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7549 - recall: 0.9895 - precision: 0.6867\n",
            "Epoch 75: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.4449 - accuracy: 0.7766 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7549 - recall: 0.9895 - precision: 0.6867 - val_loss: 0.6437 - val_accuracy: 0.6062 - val_sensitivity_at_specificity: 0.0169 - val_specificity_at_sensitivity: 0.3170 - val_recall: 0.9707 - val_precision: 0.5650\n",
            "Epoch 76/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4449 - accuracy: 0.7797 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7625 - recall: 0.9852 - precision: 0.6989\n",
            "Epoch 76: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.4449 - accuracy: 0.7797 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7625 - recall: 0.9852 - precision: 0.6989 - val_loss: 0.6607 - val_accuracy: 0.5914 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.4369 - val_recall: 1.0000 - val_precision: 0.5464\n",
            "Epoch 77/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4371 - accuracy: 0.7871 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7607 - recall: 0.9977 - precision: 0.7015\n",
            "Epoch 77: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.4371 - accuracy: 0.7871 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7607 - recall: 0.9977 - precision: 0.7015 - val_loss: 0.6519 - val_accuracy: 0.6102 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.2624 - val_recall: 0.9921 - val_precision: 0.5609\n",
            "Epoch 78/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4434 - accuracy: 0.7816 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.8070 - recall: 0.9882 - precision: 0.6976\n",
            "Epoch 78: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.4434 - accuracy: 0.7816 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.8070 - recall: 0.9882 - precision: 0.6976 - val_loss: 0.6643 - val_accuracy: 0.5922 - val_sensitivity_at_specificity: 0.0304 - val_specificity_at_sensitivity: 0.2195 - val_recall: 0.9968 - val_precision: 0.5447\n",
            "Epoch 79/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4589 - accuracy: 0.7699 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.7389 - recall: 0.9914 - precision: 0.6872\n",
            "Epoch 79: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.4589 - accuracy: 0.7699 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.7389 - recall: 0.9914 - precision: 0.6872 - val_loss: 0.6357 - val_accuracy: 0.6117 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.2771 - val_recall: 0.9921 - val_precision: 0.5611\n",
            "Epoch 80/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4559 - accuracy: 0.7691 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7411 - recall: 0.9936 - precision: 0.6800\n",
            "Epoch 80: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.4559 - accuracy: 0.7691 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7411 - recall: 0.9936 - precision: 0.6800 - val_loss: 0.6466 - val_accuracy: 0.6008 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.2368 - val_recall: 0.9969 - val_precision: 0.5555\n",
            "Epoch 81/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4376 - accuracy: 0.7918 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.7447 - recall: 0.9923 - precision: 0.7107\n",
            "Epoch 81: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.4376 - accuracy: 0.7918 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.7447 - recall: 0.9923 - precision: 0.7107 - val_loss: 0.6589 - val_accuracy: 0.5992 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.2458 - val_recall: 0.9921 - val_precision: 0.5512\n",
            "Epoch 82/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4474 - accuracy: 0.7793 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7823 - recall: 0.9906 - precision: 0.6968\n",
            "Epoch 82: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.4474 - accuracy: 0.7793 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7823 - recall: 0.9906 - precision: 0.6968 - val_loss: 0.6367 - val_accuracy: 0.6242 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.2580 - val_recall: 0.9985 - val_precision: 0.5756\n",
            "Epoch 83/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4398 - accuracy: 0.7848 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7734 - recall: 0.9969 - precision: 0.6993\n",
            "Epoch 83: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.4398 - accuracy: 0.7848 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7734 - recall: 0.9969 - precision: 0.6993 - val_loss: 0.6585 - val_accuracy: 0.5977 - val_sensitivity_at_specificity: 0.2114 - val_specificity_at_sensitivity: 0.2366 - val_recall: 0.9936 - val_precision: 0.5502\n",
            "Epoch 84/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4405 - accuracy: 0.7882 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7617 - recall: 0.9893 - precision: 0.7076\n",
            "Epoch 84: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 153ms/step - loss: 0.4405 - accuracy: 0.7882 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7617 - recall: 0.9893 - precision: 0.7076 - val_loss: 0.6366 - val_accuracy: 0.6258 - val_sensitivity_at_specificity: 0.0619 - val_specificity_at_sensitivity: 0.2573 - val_recall: 0.9940 - val_precision: 0.5808\n",
            "Epoch 85/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4351 - accuracy: 0.7918 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7687 - recall: 0.9800 - precision: 0.7156\n",
            "Epoch 85: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 154ms/step - loss: 0.4351 - accuracy: 0.7918 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7687 - recall: 0.9800 - precision: 0.7156 - val_loss: 0.6596 - val_accuracy: 0.6102 - val_sensitivity_at_specificity: 0.1254 - val_specificity_at_sensitivity: 0.2334 - val_recall: 0.9969 - val_precision: 0.5644\n",
            "Epoch 86/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4576 - accuracy: 0.7723 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7457 - recall: 0.9953 - precision: 0.6886\n",
            "Epoch 86: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.4576 - accuracy: 0.7723 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7457 - recall: 0.9953 - precision: 0.6886 - val_loss: 0.6463 - val_accuracy: 0.6109 - val_sensitivity_at_specificity: 0.0093 - val_specificity_at_sensitivity: 0.2642 - val_recall: 0.9876 - val_precision: 0.5648\n",
            "Epoch 87/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4550 - accuracy: 0.7711 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7506 - recall: 0.9913 - precision: 0.6849\n",
            "Epoch 87: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.4550 - accuracy: 0.7711 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7506 - recall: 0.9913 - precision: 0.6849 - val_loss: 0.6466 - val_accuracy: 0.6000 - val_sensitivity_at_specificity: 0.0079 - val_specificity_at_sensitivity: 0.2496 - val_recall: 0.9905 - val_precision: 0.5526\n",
            "Epoch 88/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4541 - accuracy: 0.7727 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7793 - recall: 0.9922 - precision: 0.6891\n",
            "Epoch 88: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.4541 - accuracy: 0.7727 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7793 - recall: 0.9922 - precision: 0.6891 - val_loss: 0.6395 - val_accuracy: 0.6133 - val_sensitivity_at_specificity: 0.0170 - val_specificity_at_sensitivity: 0.3060 - val_recall: 0.9845 - val_precision: 0.5674\n",
            "Epoch 89/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4569 - accuracy: 0.7676 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7684 - recall: 0.9929 - precision: 0.6826\n",
            "Epoch 89: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.4569 - accuracy: 0.7676 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7684 - recall: 0.9929 - precision: 0.6826 - val_loss: 0.6476 - val_accuracy: 0.6109 - val_sensitivity_at_specificity: 0.0137 - val_specificity_at_sensitivity: 0.2324 - val_recall: 1.0000 - val_precision: 0.5685\n",
            "Epoch 90/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4494 - accuracy: 0.7811 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7159 - recall: 0.9935 - precision: 0.7017\n",
            "Epoch 90: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 152ms/step - loss: 0.4494 - accuracy: 0.7811 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7159 - recall: 0.9935 - precision: 0.7017 - val_loss: 0.6658 - val_accuracy: 0.5867 - val_sensitivity_at_specificity: 0.1194 - val_specificity_at_sensitivity: 0.2545 - val_recall: 0.9855 - val_precision: 0.5402\n",
            "Epoch 91/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4619 - accuracy: 0.7656 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7581 - recall: 0.9913 - precision: 0.6806\n",
            "Epoch 91: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.4619 - accuracy: 0.7656 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7581 - recall: 0.9913 - precision: 0.6806 - val_loss: 0.6319 - val_accuracy: 0.6234 - val_sensitivity_at_specificity: 0.0921 - val_specificity_at_sensitivity: 0.2427 - val_recall: 0.9955 - val_precision: 0.5791\n",
            "Epoch 92/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4407 - accuracy: 0.7820 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7374 - recall: 0.9968 - precision: 0.6954\n",
            "Epoch 92: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.4407 - accuracy: 0.7820 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7374 - recall: 0.9968 - precision: 0.6954 - val_loss: 0.6285 - val_accuracy: 0.6313 - val_sensitivity_at_specificity: 0.0590 - val_specificity_at_sensitivity: 0.2674 - val_recall: 0.9882 - val_precision: 0.5908\n",
            "Epoch 93/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4496 - accuracy: 0.7777 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7358 - recall: 0.9899 - precision: 0.6970\n",
            "Epoch 93: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 177ms/step - loss: 0.4496 - accuracy: 0.7777 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7358 - recall: 0.9899 - precision: 0.6970 - val_loss: 0.6650 - val_accuracy: 0.5945 - val_sensitivity_at_specificity: 0.1661 - val_specificity_at_sensitivity: 0.2222 - val_recall: 0.9984 - val_precision: 0.5492\n",
            "Epoch 94/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4594 - accuracy: 0.7641 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7663 - recall: 0.9951 - precision: 0.6716\n",
            "Epoch 94: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.4594 - accuracy: 0.7641 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7663 - recall: 0.9951 - precision: 0.6716 - val_loss: 0.6459 - val_accuracy: 0.5961 - val_sensitivity_at_specificity: 0.0585 - val_specificity_at_sensitivity: 0.3617 - val_recall: 0.9763 - val_precision: 0.5518\n",
            "Epoch 95/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4459 - accuracy: 0.7785 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7169 - recall: 0.9904 - precision: 0.6910\n",
            "Epoch 95: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 155ms/step - loss: 0.4459 - accuracy: 0.7785 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7169 - recall: 0.9904 - precision: 0.6910 - val_loss: 0.6398 - val_accuracy: 0.6141 - val_sensitivity_at_specificity: 0.0382 - val_specificity_at_sensitivity: 0.2320 - val_recall: 0.9969 - val_precision: 0.5703\n",
            "Epoch 96/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4483 - accuracy: 0.7707 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7818 - recall: 0.9844 - precision: 0.6784\n",
            "Epoch 96: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.4483 - accuracy: 0.7707 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7818 - recall: 0.9844 - precision: 0.6784 - val_loss: 0.6536 - val_accuracy: 0.6039 - val_sensitivity_at_specificity: 0.0980 - val_specificity_at_sensitivity: 0.2281 - val_recall: 0.9908 - val_precision: 0.5636\n",
            "Epoch 97/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4490 - accuracy: 0.7852 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7327 - recall: 0.9940 - precision: 0.7091\n",
            "Epoch 97: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.4490 - accuracy: 0.7852 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7327 - recall: 0.9940 - precision: 0.7091 - val_loss: 0.6520 - val_accuracy: 0.6094 - val_sensitivity_at_specificity: 0.1265 - val_specificity_at_sensitivity: 0.2864 - val_recall: 1.0000 - val_precision: 0.5645\n",
            "Epoch 98/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4357 - accuracy: 0.7875 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.7940 - recall: 0.9905 - precision: 0.7026\n",
            "Epoch 98: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 157ms/step - loss: 0.4357 - accuracy: 0.7875 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.7940 - recall: 0.9905 - precision: 0.7026 - val_loss: 0.6552 - val_accuracy: 0.6086 - val_sensitivity_at_specificity: 0.1630 - val_specificity_at_sensitivity: 0.3019 - val_recall: 0.9907 - val_precision: 0.5631\n",
            "Epoch 99/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4271 - accuracy: 0.7977 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7661 - recall: 0.9900 - precision: 0.7180\n",
            "Epoch 99: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 157ms/step - loss: 0.4271 - accuracy: 0.7977 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7661 - recall: 0.9900 - precision: 0.7180 - val_loss: 0.6440 - val_accuracy: 0.6320 - val_sensitivity_at_specificity: 0.4785 - val_specificity_at_sensitivity: 0.2636 - val_recall: 0.9985 - val_precision: 0.5884\n",
            "Epoch 100/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4448 - accuracy: 0.7820 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7585 - recall: 0.9977 - precision: 0.7005\n",
            "Epoch 100: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.4448 - accuracy: 0.7820 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7585 - recall: 0.9977 - precision: 0.7005 - val_loss: 0.6377 - val_accuracy: 0.6133 - val_sensitivity_at_specificity: 0.1152 - val_specificity_at_sensitivity: 0.3008 - val_recall: 0.9952 - val_precision: 0.5583\n",
            "Epoch 101/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4425 - accuracy: 0.7852 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7819 - recall: 0.9899 - precision: 0.7040\n",
            "Epoch 101: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.4425 - accuracy: 0.7852 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7819 - recall: 0.9899 - precision: 0.7040 - val_loss: 0.6461 - val_accuracy: 0.6148 - val_sensitivity_at_specificity: 0.0397 - val_specificity_at_sensitivity: 0.4192 - val_recall: 0.9954 - val_precision: 0.5709\n",
            "Epoch 102/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4398 - accuracy: 0.7828 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7813 - recall: 0.9928 - precision: 0.6953\n",
            "Epoch 102: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.4398 - accuracy: 0.7828 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7813 - recall: 0.9928 - precision: 0.6953 - val_loss: 0.6465 - val_accuracy: 0.6094 - val_sensitivity_at_specificity: 0.1398 - val_specificity_at_sensitivity: 0.2767 - val_recall: 0.9752 - val_precision: 0.5647\n",
            "Epoch 103/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4578 - accuracy: 0.7691 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7606 - recall: 0.9874 - precision: 0.6848\n",
            "Epoch 103: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.4578 - accuracy: 0.7691 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7606 - recall: 0.9874 - precision: 0.6848 - val_loss: 0.6720 - val_accuracy: 0.5758 - val_sensitivity_at_specificity: 0.1407 - val_specificity_at_sensitivity: 0.2130 - val_recall: 0.9983 - val_precision: 0.5266\n",
            "Epoch 104/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4327 - accuracy: 0.7922 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7488 - recall: 0.9969 - precision: 0.7063\n",
            "Epoch 104: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.4327 - accuracy: 0.7922 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7488 - recall: 0.9969 - precision: 0.7063 - val_loss: 0.6497 - val_accuracy: 0.6109 - val_sensitivity_at_specificity: 0.2391 - val_specificity_at_sensitivity: 0.2610 - val_recall: 0.9845 - val_precision: 0.5651\n",
            "Epoch 105/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4456 - accuracy: 0.7832 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7524 - recall: 0.9878 - precision: 0.7056\n",
            "Epoch 105: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.4456 - accuracy: 0.7832 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7524 - recall: 0.9878 - precision: 0.7056 - val_loss: 0.6722 - val_accuracy: 0.6031 - val_sensitivity_at_specificity: 0.2123 - val_specificity_at_sensitivity: 0.2127 - val_recall: 0.9969 - val_precision: 0.5615\n",
            "Epoch 106/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4423 - accuracy: 0.7832 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.7566 - recall: 0.9929 - precision: 0.6972\n",
            "Epoch 106: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.4423 - accuracy: 0.7832 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.7566 - recall: 0.9929 - precision: 0.6972 - val_loss: 0.6274 - val_accuracy: 0.6281 - val_sensitivity_at_specificity: 0.0747 - val_specificity_at_sensitivity: 0.3061 - val_recall: 0.9939 - val_precision: 0.5801\n",
            "Epoch 107/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4501 - accuracy: 0.7836 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7376 - recall: 0.9932 - precision: 0.7078\n",
            "Epoch 107: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.4501 - accuracy: 0.7836 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7376 - recall: 0.9932 - precision: 0.7078 - val_loss: 0.6563 - val_accuracy: 0.6070 - val_sensitivity_at_specificity: 0.1794 - val_specificity_at_sensitivity: 0.2457 - val_recall: 0.9969 - val_precision: 0.5605\n",
            "Epoch 108/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4355 - accuracy: 0.7852 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.7715 - recall: 0.9896 - precision: 0.6968\n",
            "Epoch 108: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.4355 - accuracy: 0.7852 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.7715 - recall: 0.9896 - precision: 0.6968 - val_loss: 0.6588 - val_accuracy: 0.6070 - val_sensitivity_at_specificity: 0.1700 - val_specificity_at_sensitivity: 0.2385 - val_recall: 0.9969 - val_precision: 0.5628\n",
            "Epoch 109/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4505 - accuracy: 0.7766 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7825 - recall: 0.9922 - precision: 0.6936\n",
            "Epoch 109: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.4505 - accuracy: 0.7766 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7825 - recall: 0.9922 - precision: 0.6936 - val_loss: 0.6641 - val_accuracy: 0.5961 - val_sensitivity_at_specificity: 0.1966 - val_specificity_at_sensitivity: 0.2098 - val_recall: 1.0000 - val_precision: 0.5555\n",
            "Epoch 110/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4484 - accuracy: 0.7824 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7607 - recall: 0.9915 - precision: 0.7021\n",
            "Epoch 110: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.4484 - accuracy: 0.7824 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7607 - recall: 0.9915 - precision: 0.7021 - val_loss: 0.6656 - val_accuracy: 0.5859 - val_sensitivity_at_specificity: 0.2681 - val_specificity_at_sensitivity: 0.2192 - val_recall: 0.9968 - val_precision: 0.5405\n",
            "Epoch 111/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4398 - accuracy: 0.7840 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7506 - recall: 0.9953 - precision: 0.6978\n",
            "Epoch 111: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.4398 - accuracy: 0.7840 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7506 - recall: 0.9953 - precision: 0.6978 - val_loss: 0.6486 - val_accuracy: 0.6102 - val_sensitivity_at_specificity: 0.2898 - val_specificity_at_sensitivity: 0.2496 - val_recall: 0.9969 - val_precision: 0.5602\n",
            "Epoch 112/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4582 - accuracy: 0.7711 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7219 - recall: 0.9922 - precision: 0.6892\n",
            "Epoch 112: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.4582 - accuracy: 0.7711 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7219 - recall: 0.9922 - precision: 0.6892 - val_loss: 0.6612 - val_accuracy: 0.5977 - val_sensitivity_at_specificity: 0.3750 - val_specificity_at_sensitivity: 0.2073 - val_recall: 0.9985 - val_precision: 0.5573\n",
            "Epoch 113/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4324 - accuracy: 0.7953 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7837 - recall: 0.9932 - precision: 0.7181\n",
            "Epoch 113: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.4324 - accuracy: 0.7953 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7837 - recall: 0.9932 - precision: 0.7181 - val_loss: 0.6578 - val_accuracy: 0.6086 - val_sensitivity_at_specificity: 0.3764 - val_specificity_at_sensitivity: 0.2589 - val_recall: 0.9874 - val_precision: 0.5598\n",
            "Epoch 114/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4394 - accuracy: 0.7863 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7436 - recall: 0.9937 - precision: 0.7012\n",
            "Epoch 114: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.4394 - accuracy: 0.7863 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7436 - recall: 0.9937 - precision: 0.7012 - val_loss: 0.6643 - val_accuracy: 0.6008 - val_sensitivity_at_specificity: 0.2949 - val_specificity_at_sensitivity: 0.2207 - val_recall: 0.9938 - val_precision: 0.5568\n",
            "Epoch 115/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4390 - accuracy: 0.7841 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7471 - recall: 0.9933 - precision: 0.6970\n",
            "Epoch 115: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.4390 - accuracy: 0.7841 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7471 - recall: 0.9933 - precision: 0.6970 - val_loss: 0.6477 - val_accuracy: 0.6039 - val_sensitivity_at_specificity: 0.2797 - val_specificity_at_sensitivity: 0.3489 - val_recall: 0.9837 - val_precision: 0.5490\n",
            "Epoch 116/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4444 - accuracy: 0.7773 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7921 - recall: 0.9874 - precision: 0.6929\n",
            "Epoch 116: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.4444 - accuracy: 0.7773 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7921 - recall: 0.9874 - precision: 0.6929 - val_loss: 0.6420 - val_accuracy: 0.6148 - val_sensitivity_at_specificity: 0.3841 - val_specificity_at_sensitivity: 0.2480 - val_recall: 0.9984 - val_precision: 0.5661\n",
            "Epoch 117/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4705 - accuracy: 0.7574 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7037 - recall: 0.9899 - precision: 0.6759\n",
            "Epoch 117: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.4705 - accuracy: 0.7574 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7037 - recall: 0.9899 - precision: 0.6759 - val_loss: 0.6355 - val_accuracy: 0.6250 - val_sensitivity_at_specificity: 0.4619 - val_specificity_at_sensitivity: 0.2455 - val_recall: 0.9910 - val_precision: 0.5831\n",
            "Epoch 118/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4462 - accuracy: 0.7793 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.7510 - recall: 0.9952 - precision: 0.6915\n",
            "Epoch 118: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.4462 - accuracy: 0.7793 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.7510 - recall: 0.9952 - precision: 0.6915 - val_loss: 0.6453 - val_accuracy: 0.6062 - val_sensitivity_at_specificity: 0.2402 - val_specificity_at_sensitivity: 0.2457 - val_recall: 0.9984 - val_precision: 0.5584\n",
            "Epoch 119/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4504 - accuracy: 0.7762 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7236 - recall: 0.9843 - precision: 0.6956\n",
            "Epoch 119: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 157ms/step - loss: 0.4504 - accuracy: 0.7762 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7236 - recall: 0.9843 - precision: 0.6956 - val_loss: 0.6690 - val_accuracy: 0.5914 - val_sensitivity_at_specificity: 0.3738 - val_specificity_at_sensitivity: 0.2132 - val_recall: 0.9953 - val_precision: 0.5513\n",
            "Epoch 120/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4440 - accuracy: 0.7832 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.7527 - recall: 0.9976 - precision: 0.6972\n",
            "Epoch 120: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.4440 - accuracy: 0.7832 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.7527 - recall: 0.9976 - precision: 0.6972 - val_loss: 0.6712 - val_accuracy: 0.5836 - val_sensitivity_at_specificity: 0.5859 - val_specificity_at_sensitivity: 0.5205 - val_recall: 0.9888 - val_precision: 0.5394\n",
            "Epoch 121/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4491 - accuracy: 0.7754 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.7873 - recall: 0.9880 - precision: 0.6877\n",
            "Epoch 121: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.4491 - accuracy: 0.7754 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.7873 - recall: 0.9880 - precision: 0.6877 - val_loss: 0.6765 - val_accuracy: 0.5813 - val_sensitivity_at_specificity: 0.5570 - val_specificity_at_sensitivity: 0.5540 - val_recall: 0.9984 - val_precision: 0.5376\n",
            "Epoch 122/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4606 - accuracy: 0.7664 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7862 - recall: 0.9922 - precision: 0.6825\n",
            "Epoch 122: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.4606 - accuracy: 0.7664 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7862 - recall: 0.9922 - precision: 0.6825 - val_loss: 0.6542 - val_accuracy: 0.5953 - val_sensitivity_at_specificity: 0.4047 - val_specificity_at_sensitivity: 0.2264 - val_recall: 0.9984 - val_precision: 0.5508\n",
            "Epoch 123/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4372 - accuracy: 0.7871 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7725 - recall: 0.9961 - precision: 0.7033\n",
            "Epoch 123: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.4372 - accuracy: 0.7871 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7725 - recall: 0.9961 - precision: 0.7033 - val_loss: 0.6673 - val_accuracy: 0.5859 - val_sensitivity_at_specificity: 0.1886 - val_specificity_at_sensitivity: 0.2331 - val_recall: 0.9902 - val_precision: 0.5375\n",
            "Epoch 124/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4467 - accuracy: 0.7762 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7513 - recall: 0.9929 - precision: 0.6894\n",
            "Epoch 124: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.4467 - accuracy: 0.7762 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7513 - recall: 0.9929 - precision: 0.6894 - val_loss: 0.6553 - val_accuracy: 0.6070 - val_sensitivity_at_specificity: 0.3488 - val_specificity_at_sensitivity: 0.2378 - val_recall: 0.9907 - val_precision: 0.5625\n",
            "Epoch 125/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4301 - accuracy: 0.7973 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.7701 - recall: 0.9927 - precision: 0.7174\n",
            "Epoch 125: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 155ms/step - loss: 0.4301 - accuracy: 0.7973 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.7701 - recall: 0.9927 - precision: 0.7174 - val_loss: 0.6861 - val_accuracy: 0.5875 - val_sensitivity_at_specificity: 0.2960 - val_specificity_at_sensitivity: 0.1850 - val_recall: 0.9969 - val_precision: 0.5489\n",
            "Epoch 126/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4437 - accuracy: 0.7828 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7946 - recall: 0.9914 - precision: 0.6987\n",
            "Epoch 126: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.4437 - accuracy: 0.7828 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7946 - recall: 0.9914 - precision: 0.6987 - val_loss: 0.6502 - val_accuracy: 0.5992 - val_sensitivity_at_specificity: 0.2857 - val_specificity_at_sensitivity: 0.2907 - val_recall: 0.9839 - val_precision: 0.5493\n",
            "Epoch 127/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4377 - accuracy: 0.7867 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7592 - recall: 0.9945 - precision: 0.7020\n",
            "Epoch 127: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.4377 - accuracy: 0.7867 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7592 - recall: 0.9945 - precision: 0.7020 - val_loss: 0.6683 - val_accuracy: 0.5969 - val_sensitivity_at_specificity: 0.1954 - val_specificity_at_sensitivity: 0.2095 - val_recall: 0.9954 - val_precision: 0.5578\n",
            "Epoch 128/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4540 - accuracy: 0.7707 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.7202 - recall: 0.9850 - precision: 0.6871\n",
            "Epoch 128: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 194ms/step - loss: 0.4540 - accuracy: 0.7707 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.7202 - recall: 0.9850 - precision: 0.6871 - val_loss: 0.6440 - val_accuracy: 0.6070 - val_sensitivity_at_specificity: 0.2918 - val_specificity_at_sensitivity: 0.2461 - val_recall: 0.9984 - val_precision: 0.5577\n",
            "Epoch 129/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4457 - accuracy: 0.7805 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7308 - recall: 0.9977 - precision: 0.6965\n",
            "Epoch 129: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.4457 - accuracy: 0.7805 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7308 - recall: 0.9977 - precision: 0.6965 - val_loss: 0.6465 - val_accuracy: 0.6086 - val_sensitivity_at_specificity: 0.2635 - val_specificity_at_sensitivity: 0.2330 - val_recall: 0.9954 - val_precision: 0.5647\n",
            "Epoch 130/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4548 - accuracy: 0.7730 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7616 - recall: 0.9923 - precision: 0.6920\n",
            "Epoch 130: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.4548 - accuracy: 0.7730 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7616 - recall: 0.9923 - precision: 0.6920 - val_loss: 0.6485 - val_accuracy: 0.6125 - val_sensitivity_at_specificity: 0.3960 - val_specificity_at_sensitivity: 0.2406 - val_recall: 1.0000 - val_precision: 0.5649\n",
            "Epoch 131/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4291 - accuracy: 0.7926 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7510 - recall: 0.9944 - precision: 0.7050\n",
            "Epoch 131: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.4291 - accuracy: 0.7926 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7510 - recall: 0.9944 - precision: 0.7050 - val_loss: 0.6379 - val_accuracy: 0.6297 - val_sensitivity_at_specificity: 0.6035 - val_specificity_at_sensitivity: 0.5320 - val_recall: 0.9898 - val_precision: 0.5925\n",
            "Epoch 132/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4454 - accuracy: 0.7770 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7651 - recall: 0.9936 - precision: 0.6886\n",
            "Epoch 132: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.4454 - accuracy: 0.7770 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7651 - recall: 0.9936 - precision: 0.6886 - val_loss: 0.6556 - val_accuracy: 0.6078 - val_sensitivity_at_specificity: 0.3922 - val_specificity_at_sensitivity: 0.2299 - val_recall: 0.9984 - val_precision: 0.5624\n",
            "Epoch 133/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4416 - accuracy: 0.7863 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7789 - recall: 0.9916 - precision: 0.7089\n",
            "Epoch 133: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.4416 - accuracy: 0.7863 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7789 - recall: 0.9916 - precision: 0.7089 - val_loss: 0.6521 - val_accuracy: 0.6086 - val_sensitivity_at_specificity: 0.2759 - val_specificity_at_sensitivity: 0.2179 - val_recall: 0.9985 - val_precision: 0.5671\n",
            "Epoch 134/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4426 - accuracy: 0.7777 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7851 - recall: 0.9905 - precision: 0.6918\n",
            "Epoch 134: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 183ms/step - loss: 0.4426 - accuracy: 0.7777 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7851 - recall: 0.9905 - precision: 0.6918 - val_loss: 0.6555 - val_accuracy: 0.6102 - val_sensitivity_at_specificity: 0.4322 - val_specificity_at_sensitivity: 0.4809 - val_recall: 0.9936 - val_precision: 0.5572\n",
            "Epoch 135/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4461 - accuracy: 0.7797 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.8023 - recall: 0.9929 - precision: 0.6952\n",
            "Epoch 135: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.4461 - accuracy: 0.7797 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.8023 - recall: 0.9929 - precision: 0.6952 - val_loss: 0.6832 - val_accuracy: 0.5711 - val_sensitivity_at_specificity: 0.2512 - val_specificity_at_sensitivity: 0.1777 - val_recall: 1.0000 - val_precision: 0.5355\n",
            "Epoch 136/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4412 - accuracy: 0.7875 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7733 - recall: 0.9924 - precision: 0.7098\n",
            "Epoch 136: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.4412 - accuracy: 0.7875 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7733 - recall: 0.9924 - precision: 0.7098 - val_loss: 0.6622 - val_accuracy: 0.5953 - val_sensitivity_at_specificity: 0.3328 - val_specificity_at_sensitivity: 0.2590 - val_recall: 0.9805 - val_precision: 0.5441\n",
            "Epoch 137/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4565 - accuracy: 0.7746 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.7534 - recall: 0.9908 - precision: 0.6949\n",
            "Epoch 137: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.4565 - accuracy: 0.7746 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.7534 - recall: 0.9908 - precision: 0.6949 - val_loss: 0.6813 - val_accuracy: 0.5828 - val_sensitivity_at_specificity: 0.3295 - val_specificity_at_sensitivity: 0.2294 - val_recall: 0.9967 - val_precision: 0.5346\n",
            "Epoch 138/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4361 - accuracy: 0.7867 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7806 - recall: 0.9841 - precision: 0.7023\n",
            "Epoch 138: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.4361 - accuracy: 0.7867 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7806 - recall: 0.9841 - precision: 0.7023 - val_loss: 0.6864 - val_accuracy: 0.5797 - val_sensitivity_at_specificity: 0.3291 - val_specificity_at_sensitivity: 0.1975 - val_recall: 0.9968 - val_precision: 0.5403\n",
            "Epoch 139/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4435 - accuracy: 0.7820 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7838 - recall: 0.9976 - precision: 0.6946\n",
            "Epoch 139: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.4435 - accuracy: 0.7820 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7838 - recall: 0.9976 - precision: 0.6946 - val_loss: 0.6454 - val_accuracy: 0.6039 - val_sensitivity_at_specificity: 0.3233 - val_specificity_at_sensitivity: 0.2755 - val_recall: 0.9779 - val_precision: 0.5571\n",
            "Epoch 140/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4306 - accuracy: 0.7871 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7790 - recall: 0.9903 - precision: 0.6978\n",
            "Epoch 140: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.4306 - accuracy: 0.7871 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7790 - recall: 0.9903 - precision: 0.6978 - val_loss: 0.6624 - val_accuracy: 0.6000 - val_sensitivity_at_specificity: 0.4139 - val_specificity_at_sensitivity: 0.2457 - val_recall: 0.9889 - val_precision: 0.5535\n",
            "Epoch 141/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4470 - accuracy: 0.7840 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7543 - recall: 0.9940 - precision: 0.7089\n",
            "Epoch 141: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.4470 - accuracy: 0.7840 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7543 - recall: 0.9940 - precision: 0.7089 - val_loss: 0.6754 - val_accuracy: 0.6055 - val_sensitivity_at_specificity: 0.5023 - val_specificity_at_sensitivity: 0.5591 - val_recall: 0.9984 - val_precision: 0.5610\n",
            "Epoch 142/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4340 - accuracy: 0.7902 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7923 - recall: 0.9922 - precision: 0.7082\n",
            "Epoch 142: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.4340 - accuracy: 0.7902 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7923 - recall: 0.9922 - precision: 0.7082 - val_loss: 0.6777 - val_accuracy: 0.5852 - val_sensitivity_at_specificity: 0.3456 - val_specificity_at_sensitivity: 0.2595 - val_recall: 0.9776 - val_precision: 0.5417\n",
            "Epoch 143/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4513 - accuracy: 0.7730 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7319 - recall: 0.9911 - precision: 0.6825\n",
            "Epoch 143: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.4513 - accuracy: 0.7730 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7319 - recall: 0.9911 - precision: 0.6825 - val_loss: 0.6588 - val_accuracy: 0.6008 - val_sensitivity_at_specificity: 0.2550 - val_specificity_at_sensitivity: 0.2130 - val_recall: 1.0000 - val_precision: 0.5602\n",
            "Epoch 144/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4407 - accuracy: 0.7873 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7739 - recall: 0.9914 - precision: 0.7061\n",
            "Epoch 144: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.4382 - accuracy: 0.7903 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7732 - recall: 0.9918 - precision: 0.7100 - val_loss: 0.6589 - val_accuracy: 0.6039 - val_sensitivity_at_specificity: 0.2875 - val_specificity_at_sensitivity: 0.4755 - val_recall: 0.9923 - val_precision: 0.5612\n",
            "Epoch 145/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4316 - accuracy: 0.7871 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8192 - recall: 0.9937 - precision: 0.7017\n",
            "Epoch 145: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.4316 - accuracy: 0.7871 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8192 - recall: 0.9937 - precision: 0.7017 - val_loss: 0.6968 - val_accuracy: 0.5906 - val_sensitivity_at_specificity: 0.5113 - val_specificity_at_sensitivity: 0.5773 - val_recall: 0.9839 - val_precision: 0.5427\n",
            "Epoch 146/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4528 - accuracy: 0.7699 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7596 - recall: 0.9936 - precision: 0.6820\n",
            "Epoch 146: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.4528 - accuracy: 0.7699 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7596 - recall: 0.9936 - precision: 0.6820 - val_loss: 0.6488 - val_accuracy: 0.6039 - val_sensitivity_at_specificity: 0.2449 - val_specificity_at_sensitivity: 0.2363 - val_recall: 0.9906 - val_precision: 0.5590\n",
            "Epoch 147/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4369 - accuracy: 0.7922 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7554 - recall: 0.9901 - precision: 0.7140\n",
            "Epoch 147: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.4369 - accuracy: 0.7922 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7554 - recall: 0.9901 - precision: 0.7140 - val_loss: 0.6779 - val_accuracy: 0.5867 - val_sensitivity_at_specificity: 0.1764 - val_specificity_at_sensitivity: 0.1736 - val_recall: 1.0000 - val_precision: 0.5521\n",
            "Epoch 148/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4469 - accuracy: 0.7730 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7523 - recall: 0.9911 - precision: 0.6832\n",
            "Epoch 148: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.4469 - accuracy: 0.7730 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7523 - recall: 0.9911 - precision: 0.6832 - val_loss: 0.6906 - val_accuracy: 0.5828 - val_sensitivity_at_specificity: 0.3054 - val_specificity_at_sensitivity: 0.1921 - val_recall: 1.0000 - val_precision: 0.5471\n",
            "Epoch 149/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4436 - accuracy: 0.7793 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7527 - recall: 0.9938 - precision: 0.6958\n",
            "Epoch 149: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.4436 - accuracy: 0.7793 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7527 - recall: 0.9938 - precision: 0.6958 - val_loss: 0.6763 - val_accuracy: 0.5938 - val_sensitivity_at_specificity: 0.4861 - val_specificity_at_sensitivity: 0.2208 - val_recall: 0.9907 - val_precision: 0.5546\n",
            "Epoch 150/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4422 - accuracy: 0.7816 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.7849 - recall: 0.9952 - precision: 0.6936\n",
            "Epoch 150: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.4422 - accuracy: 0.7816 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.7849 - recall: 0.9952 - precision: 0.6936 - val_loss: 0.6547 - val_accuracy: 0.6039 - val_sensitivity_at_specificity: 0.3719 - val_specificity_at_sensitivity: 0.2278 - val_recall: 0.9938 - val_precision: 0.5615\n",
            "Epoch 151/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4527 - accuracy: 0.7668 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7372 - recall: 0.9911 - precision: 0.6757\n",
            "Epoch 151: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.4527 - accuracy: 0.7668 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7372 - recall: 0.9911 - precision: 0.6757 - val_loss: 0.6883 - val_accuracy: 0.5789 - val_sensitivity_at_specificity: 0.3370 - val_specificity_at_sensitivity: 0.1969 - val_recall: 0.9969 - val_precision: 0.5410\n",
            "Epoch 152/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4376 - accuracy: 0.7832 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7965 - recall: 0.9837 - precision: 0.7033\n",
            "Epoch 152: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.4376 - accuracy: 0.7832 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7965 - recall: 0.9837 - precision: 0.7033 - val_loss: 0.6713 - val_accuracy: 0.6023 - val_sensitivity_at_specificity: 0.3857 - val_specificity_at_sensitivity: 0.2340 - val_recall: 0.9878 - val_precision: 0.5640\n",
            "Epoch 153/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4331 - accuracy: 0.7922 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7934 - recall: 0.9947 - precision: 0.7137\n",
            "Epoch 153: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.4331 - accuracy: 0.7922 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7934 - recall: 0.9947 - precision: 0.7137 - val_loss: 0.6902 - val_accuracy: 0.5867 - val_sensitivity_at_specificity: 0.4541 - val_specificity_at_sensitivity: 0.2500 - val_recall: 0.9794 - val_precision: 0.5454\n",
            "Epoch 154/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4285 - accuracy: 0.8012 - sensitivity_at_specificity: 0.9993 - specificity_at_sensitivity: 0.7997 - recall: 0.9874 - precision: 0.7300\n",
            "Epoch 154: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.4285 - accuracy: 0.8012 - sensitivity_at_specificity: 0.9993 - specificity_at_sensitivity: 0.7997 - recall: 0.9874 - precision: 0.7300 - val_loss: 0.6911 - val_accuracy: 0.5969 - val_sensitivity_at_specificity: 0.2120 - val_specificity_at_sensitivity: 0.2423 - val_recall: 0.9984 - val_precision: 0.5506\n",
            "Epoch 155/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4430 - accuracy: 0.7797 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7584 - recall: 0.9891 - precision: 0.6980\n",
            "Epoch 155: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.4430 - accuracy: 0.7797 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7584 - recall: 0.9891 - precision: 0.6980 - val_loss: 0.6720 - val_accuracy: 0.5945 - val_sensitivity_at_specificity: 0.2371 - val_specificity_at_sensitivity: 0.2332 - val_recall: 0.9984 - val_precision: 0.5527\n",
            "Epoch 156/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4489 - accuracy: 0.7785 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7876 - recall: 0.9882 - precision: 0.6945\n",
            "Epoch 156: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.4489 - accuracy: 0.7785 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7876 - recall: 0.9882 - precision: 0.6945 - val_loss: 0.6683 - val_accuracy: 0.6039 - val_sensitivity_at_specificity: 0.3575 - val_specificity_at_sensitivity: 0.3054 - val_recall: 0.9874 - val_precision: 0.5568\n",
            "Epoch 157/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4462 - accuracy: 0.7758 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7788 - recall: 0.9953 - precision: 0.6910\n",
            "Epoch 157: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.4462 - accuracy: 0.7758 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7788 - recall: 0.9953 - precision: 0.6910 - val_loss: 0.6634 - val_accuracy: 0.6016 - val_sensitivity_at_specificity: 0.6295 - val_specificity_at_sensitivity: 0.5008 - val_recall: 0.9969 - val_precision: 0.5556\n",
            "Epoch 158/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4389 - accuracy: 0.7867 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7376 - recall: 0.9939 - precision: 0.7076\n",
            "Epoch 158: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.4389 - accuracy: 0.7867 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7376 - recall: 0.9939 - precision: 0.7076 - val_loss: 0.6586 - val_accuracy: 0.6062 - val_sensitivity_at_specificity: 0.3108 - val_specificity_at_sensitivity: 0.4540 - val_recall: 0.9923 - val_precision: 0.5638\n",
            "Epoch 159/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4467 - accuracy: 0.7762 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7579 - recall: 0.9921 - precision: 0.6900\n",
            "Epoch 159: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.4467 - accuracy: 0.7762 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7579 - recall: 0.9921 - precision: 0.6900 - val_loss: 0.6869 - val_accuracy: 0.5781 - val_sensitivity_at_specificity: 0.3532 - val_specificity_at_sensitivity: 0.2682 - val_recall: 0.9855 - val_precision: 0.5350\n",
            "Epoch 160/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4544 - accuracy: 0.7695 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7784 - recall: 0.9897 - precision: 0.6845\n",
            "Epoch 160: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.4544 - accuracy: 0.7695 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7784 - recall: 0.9897 - precision: 0.6845 - val_loss: 0.6757 - val_accuracy: 0.5852 - val_sensitivity_at_specificity: 0.1466 - val_specificity_at_sensitivity: 0.1987 - val_recall: 0.9984 - val_precision: 0.5470\n",
            "Epoch 161/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4303 - accuracy: 0.7953 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7612 - recall: 0.9938 - precision: 0.7125\n",
            "Epoch 161: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.4303 - accuracy: 0.7953 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7612 - recall: 0.9938 - precision: 0.7125 - val_loss: 0.6714 - val_accuracy: 0.5867 - val_sensitivity_at_specificity: 0.3003 - val_specificity_at_sensitivity: 0.3294 - val_recall: 0.9785 - val_precision: 0.5347\n",
            "Epoch 162/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4359 - accuracy: 0.7895 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7422 - recall: 0.9869 - precision: 0.7112\n",
            "Epoch 162: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.4359 - accuracy: 0.7895 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7422 - recall: 0.9869 - precision: 0.7112 - val_loss: 0.7099 - val_accuracy: 0.5867 - val_sensitivity_at_specificity: 0.3529 - val_specificity_at_sensitivity: 0.3871 - val_recall: 0.9968 - val_precision: 0.5433\n",
            "Epoch 163/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4319 - accuracy: 0.7871 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7964 - recall: 0.9897 - precision: 0.7023\n",
            "Epoch 163: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.4319 - accuracy: 0.7871 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7964 - recall: 0.9897 - precision: 0.7023 - val_loss: 0.6593 - val_accuracy: 0.6133 - val_sensitivity_at_specificity: 0.4840 - val_specificity_at_sensitivity: 0.2400 - val_recall: 0.9939 - val_precision: 0.5701\n",
            "Epoch 164/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4426 - accuracy: 0.7766 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7638 - recall: 0.9912 - precision: 0.6887\n",
            "Epoch 164: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.4426 - accuracy: 0.7766 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7638 - recall: 0.9912 - precision: 0.6887 - val_loss: 0.6550 - val_accuracy: 0.6047 - val_sensitivity_at_specificity: 0.3525 - val_specificity_at_sensitivity: 0.2862 - val_recall: 0.9767 - val_precision: 0.5616\n",
            "Epoch 165/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4277 - accuracy: 0.7895 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7900 - recall: 0.9889 - precision: 0.7044\n",
            "Epoch 165: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.4277 - accuracy: 0.7895 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7900 - recall: 0.9889 - precision: 0.7044 - val_loss: 0.6753 - val_accuracy: 0.6008 - val_sensitivity_at_specificity: 0.5710 - val_specificity_at_sensitivity: 0.5102 - val_recall: 0.9953 - val_precision: 0.5567\n",
            "Epoch 166/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4442 - accuracy: 0.7812 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7762 - recall: 0.9938 - precision: 0.6992\n",
            "Epoch 166: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.4442 - accuracy: 0.7812 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7762 - recall: 0.9938 - precision: 0.6992 - val_loss: 0.6888 - val_accuracy: 0.5781 - val_sensitivity_at_specificity: 0.3583 - val_specificity_at_sensitivity: 0.2147 - val_recall: 0.9935 - val_precision: 0.5323\n",
            "Epoch 167/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4516 - accuracy: 0.7719 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.7658 - recall: 0.9872 - precision: 0.6846\n",
            "Epoch 167: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.4516 - accuracy: 0.7719 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.7658 - recall: 0.9872 - precision: 0.6846 - val_loss: 0.6855 - val_accuracy: 0.5758 - val_sensitivity_at_specificity: 0.3039 - val_specificity_at_sensitivity: 0.2620 - val_recall: 0.9918 - val_precision: 0.5301\n",
            "Epoch 168/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4387 - accuracy: 0.7805 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7711 - recall: 0.9913 - precision: 0.6957\n",
            "Epoch 168: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.4387 - accuracy: 0.7805 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7711 - recall: 0.9913 - precision: 0.6957 - val_loss: 0.6592 - val_accuracy: 0.6078 - val_sensitivity_at_specificity: 0.4277 - val_specificity_at_sensitivity: 0.3241 - val_recall: 0.9809 - val_precision: 0.5574\n",
            "Epoch 169/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4343 - accuracy: 0.7852 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7827 - recall: 0.9907 - precision: 0.7037\n",
            "Epoch 169: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.4343 - accuracy: 0.7852 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7827 - recall: 0.9907 - precision: 0.7037 - val_loss: 0.6769 - val_accuracy: 0.6008 - val_sensitivity_at_specificity: 0.5261 - val_specificity_at_sensitivity: 0.5732 - val_recall: 0.9862 - val_precision: 0.5616\n",
            "Epoch 170/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4498 - accuracy: 0.7762 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7378 - recall: 0.9930 - precision: 0.6936\n",
            "Epoch 170: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.4498 - accuracy: 0.7762 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7378 - recall: 0.9930 - precision: 0.6936 - val_loss: 0.6652 - val_accuracy: 0.6078 - val_sensitivity_at_specificity: 0.2942 - val_specificity_at_sensitivity: 0.2212 - val_recall: 0.9878 - val_precision: 0.5674\n",
            "Epoch 171/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4295 - accuracy: 0.7922 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7857 - recall: 0.9921 - precision: 0.7059\n",
            "Epoch 171: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.4295 - accuracy: 0.7922 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7857 - recall: 0.9921 - precision: 0.7059 - val_loss: 0.7006 - val_accuracy: 0.5852 - val_sensitivity_at_specificity: 0.4215 - val_specificity_at_sensitivity: 0.2058 - val_recall: 0.9968 - val_precision: 0.5404\n",
            "Epoch 172/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4265 - accuracy: 0.7937 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7953 - recall: 0.9844 - precision: 0.7135\n",
            "Epoch 172: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 183ms/step - loss: 0.4265 - accuracy: 0.7937 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7953 - recall: 0.9844 - precision: 0.7135 - val_loss: 0.6798 - val_accuracy: 0.5930 - val_sensitivity_at_specificity: 0.3259 - val_specificity_at_sensitivity: 0.2423 - val_recall: 0.9889 - val_precision: 0.5487\n",
            "Epoch 173/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4326 - accuracy: 0.7914 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7913 - recall: 0.9923 - precision: 0.7103\n",
            "Epoch 173: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.4326 - accuracy: 0.7914 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7913 - recall: 0.9923 - precision: 0.7103 - val_loss: 0.6655 - val_accuracy: 0.6094 - val_sensitivity_at_specificity: 0.3421 - val_specificity_at_sensitivity: 0.2904 - val_recall: 0.9751 - val_precision: 0.5644\n",
            "Epoch 174/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4470 - accuracy: 0.7738 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7762 - recall: 0.9968 - precision: 0.6844\n",
            "Epoch 174: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.4470 - accuracy: 0.7738 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7762 - recall: 0.9968 - precision: 0.6844 - val_loss: 0.6729 - val_accuracy: 0.5961 - val_sensitivity_at_specificity: 0.2198 - val_specificity_at_sensitivity: 0.2350 - val_recall: 0.9830 - val_precision: 0.5565\n",
            "Epoch 175/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4373 - accuracy: 0.7852 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7995 - recall: 0.9874 - precision: 0.7018\n",
            "Epoch 175: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.4373 - accuracy: 0.7852 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7995 - recall: 0.9874 - precision: 0.7018 - val_loss: 0.6609 - val_accuracy: 0.6078 - val_sensitivity_at_specificity: 0.2102 - val_specificity_at_sensitivity: 0.2280 - val_recall: 0.9925 - val_precision: 0.5708\n",
            "Epoch 176/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4315 - accuracy: 0.7867 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7889 - recall: 0.9904 - precision: 0.6983\n",
            "Epoch 176: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.4315 - accuracy: 0.7867 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7889 - recall: 0.9904 - precision: 0.6983 - val_loss: 0.6605 - val_accuracy: 0.6031 - val_sensitivity_at_specificity: 0.2615 - val_specificity_at_sensitivity: 0.2571 - val_recall: 0.9954 - val_precision: 0.5616\n",
            "Epoch 177/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4260 - accuracy: 0.7898 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7824 - recall: 0.9920 - precision: 0.7022\n",
            "Epoch 177: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.4260 - accuracy: 0.7898 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7824 - recall: 0.9920 - precision: 0.7022 - val_loss: 0.7214 - val_accuracy: 0.5773 - val_sensitivity_at_specificity: 0.3495 - val_specificity_at_sensitivity: 0.4940 - val_recall: 0.9968 - val_precision: 0.5333\n",
            "Epoch 178/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4232 - accuracy: 0.7945 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7645 - recall: 0.9953 - precision: 0.7084\n",
            "Epoch 178: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.4232 - accuracy: 0.7945 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7645 - recall: 0.9953 - precision: 0.7084 - val_loss: 0.6687 - val_accuracy: 0.5953 - val_sensitivity_at_specificity: 0.3301 - val_specificity_at_sensitivity: 0.2940 - val_recall: 0.9825 - val_precision: 0.5485\n",
            "Epoch 179/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4384 - accuracy: 0.7820 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7804 - recall: 0.9858 - precision: 0.6988\n",
            "Epoch 179: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.4384 - accuracy: 0.7820 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7804 - recall: 0.9858 - precision: 0.6988 - val_loss: 0.6759 - val_accuracy: 0.6031 - val_sensitivity_at_specificity: 0.2368 - val_specificity_at_sensitivity: 0.2241 - val_recall: 0.9984 - val_precision: 0.5584\n",
            "Epoch 180/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4492 - accuracy: 0.7758 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7553 - recall: 0.9914 - precision: 0.6922\n",
            "Epoch 180: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.4492 - accuracy: 0.7758 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7553 - recall: 0.9914 - precision: 0.6922 - val_loss: 0.6581 - val_accuracy: 0.5961 - val_sensitivity_at_specificity: 0.2540 - val_specificity_at_sensitivity: 0.2662 - val_recall: 0.9810 - val_precision: 0.5503\n",
            "Epoch 181/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4476 - accuracy: 0.7754 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.8011 - recall: 0.9858 - precision: 0.6918\n",
            "Epoch 181: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.4476 - accuracy: 0.7754 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.8011 - recall: 0.9858 - precision: 0.6918 - val_loss: 0.6630 - val_accuracy: 0.6086 - val_sensitivity_at_specificity: 0.3695 - val_specificity_at_sensitivity: 0.2545 - val_recall: 0.9910 - val_precision: 0.5703\n",
            "Epoch 182/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4519 - accuracy: 0.7688 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7887 - recall: 0.9944 - precision: 0.6798\n",
            "Epoch 182: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.4519 - accuracy: 0.7688 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7887 - recall: 0.9944 - precision: 0.6798 - val_loss: 0.7064 - val_accuracy: 0.5797 - val_sensitivity_at_specificity: 0.5016 - val_specificity_at_sensitivity: 0.5520 - val_recall: 0.9856 - val_precision: 0.5384\n",
            "Epoch 183/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4407 - accuracy: 0.7816 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7857 - recall: 0.9875 - precision: 0.6990\n",
            "Epoch 183: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.4407 - accuracy: 0.7816 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7857 - recall: 0.9875 - precision: 0.6990 - val_loss: 0.6762 - val_accuracy: 0.5945 - val_sensitivity_at_specificity: 0.5476 - val_specificity_at_sensitivity: 0.5587 - val_recall: 0.9828 - val_precision: 0.5536\n",
            "Epoch 184/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4223 - accuracy: 0.7906 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8467 - recall: 0.9936 - precision: 0.7003\n",
            "Epoch 184: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 180ms/step - loss: 0.4223 - accuracy: 0.7906 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8467 - recall: 0.9936 - precision: 0.7003 - val_loss: 0.6835 - val_accuracy: 0.5953 - val_sensitivity_at_specificity: 0.4141 - val_specificity_at_sensitivity: 0.4125 - val_recall: 0.9906 - val_precision: 0.5532\n",
            "Epoch 185/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4490 - accuracy: 0.7766 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7506 - recall: 0.9915 - precision: 0.6956\n",
            "Epoch 185: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.4490 - accuracy: 0.7766 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7506 - recall: 0.9915 - precision: 0.6956 - val_loss: 0.6613 - val_accuracy: 0.6023 - val_sensitivity_at_specificity: 0.2422 - val_specificity_at_sensitivity: 0.2266 - val_recall: 0.9953 - val_precision: 0.5573\n",
            "Epoch 186/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4264 - accuracy: 0.7887 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7663 - recall: 0.9886 - precision: 0.6975\n",
            "Epoch 186: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.4264 - accuracy: 0.7887 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7663 - recall: 0.9886 - precision: 0.6975 - val_loss: 0.6595 - val_accuracy: 0.6156 - val_sensitivity_at_specificity: 0.2959 - val_specificity_at_sensitivity: 0.4235 - val_recall: 0.9939 - val_precision: 0.5731\n",
            "Epoch 187/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4287 - accuracy: 0.7930 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.7772 - recall: 0.9954 - precision: 0.7130\n",
            "Epoch 187: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 188ms/step - loss: 0.4287 - accuracy: 0.7930 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.7772 - recall: 0.9954 - precision: 0.7130 - val_loss: 0.7075 - val_accuracy: 0.6109 - val_sensitivity_at_specificity: 0.5303 - val_specificity_at_sensitivity: 0.5840 - val_recall: 0.9876 - val_precision: 0.5644\n",
            "Epoch 188/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4387 - accuracy: 0.7890 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7985 - recall: 0.9910 - precision: 0.7090\n",
            "Epoch 188: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.4387 - accuracy: 0.7890 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7985 - recall: 0.9910 - precision: 0.7090 - val_loss: 0.6655 - val_accuracy: 0.6039 - val_sensitivity_at_specificity: 0.3338 - val_specificity_at_sensitivity: 0.2891 - val_recall: 0.9907 - val_precision: 0.5613\n",
            "Epoch 189/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4321 - accuracy: 0.7910 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8047 - recall: 0.9930 - precision: 0.7081\n",
            "Epoch 189: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.4321 - accuracy: 0.7910 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8047 - recall: 0.9930 - precision: 0.7081 - val_loss: 0.6957 - val_accuracy: 0.5859 - val_sensitivity_at_specificity: 0.4054 - val_specificity_at_sensitivity: 0.2393 - val_recall: 0.9968 - val_precision: 0.5409\n",
            "Epoch 190/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4231 - accuracy: 0.7973 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7886 - recall: 0.9861 - precision: 0.7177\n",
            "Epoch 190: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.4231 - accuracy: 0.7973 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7886 - recall: 0.9861 - precision: 0.7177 - val_loss: 0.7213 - val_accuracy: 0.5711 - val_sensitivity_at_specificity: 0.5199 - val_specificity_at_sensitivity: 0.5487 - val_recall: 0.9917 - val_precision: 0.5232\n",
            "Epoch 191/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4345 - accuracy: 0.7840 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7754 - recall: 0.9929 - precision: 0.6991\n",
            "Epoch 191: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.4345 - accuracy: 0.7840 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7754 - recall: 0.9929 - precision: 0.6991 - val_loss: 0.6727 - val_accuracy: 0.6031 - val_sensitivity_at_specificity: 0.3693 - val_specificity_at_sensitivity: 0.2808 - val_recall: 0.9906 - val_precision: 0.5577\n",
            "Epoch 192/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4301 - accuracy: 0.7887 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8003 - recall: 0.9921 - precision: 0.7024\n",
            "Epoch 192: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 181ms/step - loss: 0.4301 - accuracy: 0.7887 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8003 - recall: 0.9921 - precision: 0.7024 - val_loss: 0.7046 - val_accuracy: 0.5789 - val_sensitivity_at_specificity: 0.4463 - val_specificity_at_sensitivity: 0.2162 - val_recall: 0.9951 - val_precision: 0.5327\n",
            "Epoch 193/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4381 - accuracy: 0.7863 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8094 - recall: 0.9899 - precision: 0.7043\n",
            "Epoch 193: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 183ms/step - loss: 0.4381 - accuracy: 0.7863 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8094 - recall: 0.9899 - precision: 0.7043 - val_loss: 0.6808 - val_accuracy: 0.5969 - val_sensitivity_at_specificity: 0.4718 - val_specificity_at_sensitivity: 0.2819 - val_recall: 0.9859 - val_precision: 0.5537\n",
            "Epoch 194/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4334 - accuracy: 0.7848 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7848 - recall: 0.9835 - precision: 0.7026\n",
            "Epoch 194: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.4334 - accuracy: 0.7848 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7848 - recall: 0.9835 - precision: 0.7026 - val_loss: 0.6728 - val_accuracy: 0.5992 - val_sensitivity_at_specificity: 0.4060 - val_specificity_at_sensitivity: 0.2679 - val_recall: 0.9828 - val_precision: 0.5554\n",
            "Epoch 195/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4540 - accuracy: 0.7707 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7559 - recall: 0.9872 - precision: 0.6842\n",
            "Epoch 195: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.4540 - accuracy: 0.7707 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7559 - recall: 0.9872 - precision: 0.6842 - val_loss: 0.6778 - val_accuracy: 0.5844 - val_sensitivity_at_specificity: 0.4064 - val_specificity_at_sensitivity: 0.2321 - val_recall: 0.9904 - val_precision: 0.5406\n",
            "Epoch 196/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4383 - accuracy: 0.7844 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7991 - recall: 0.9905 - precision: 0.6990\n",
            "Epoch 196: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.4383 - accuracy: 0.7844 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7991 - recall: 0.9905 - precision: 0.6990 - val_loss: 0.6793 - val_accuracy: 0.6070 - val_sensitivity_at_specificity: 0.4318 - val_specificity_at_sensitivity: 0.2708 - val_recall: 0.9895 - val_precision: 0.5709\n",
            "Epoch 197/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4438 - accuracy: 0.7758 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7785 - recall: 0.9825 - precision: 0.6916\n",
            "Epoch 197: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.4438 - accuracy: 0.7758 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7785 - recall: 0.9825 - precision: 0.6916 - val_loss: 0.6727 - val_accuracy: 0.5891 - val_sensitivity_at_specificity: 0.3354 - val_specificity_at_sensitivity: 0.3565 - val_recall: 0.9842 - val_precision: 0.5466\n",
            "Epoch 198/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4345 - accuracy: 0.7882 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7670 - recall: 0.9846 - precision: 0.7119\n",
            "Epoch 198: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.4345 - accuracy: 0.7882 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7670 - recall: 0.9846 - precision: 0.7119 - val_loss: 0.6975 - val_accuracy: 0.5922 - val_sensitivity_at_specificity: 0.4771 - val_specificity_at_sensitivity: 0.2581 - val_recall: 0.9937 - val_precision: 0.5484\n",
            "Epoch 199/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4339 - accuracy: 0.7926 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7644 - recall: 0.9939 - precision: 0.7137\n",
            "Epoch 199: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.4339 - accuracy: 0.7926 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7644 - recall: 0.9939 - precision: 0.7137 - val_loss: 0.6717 - val_accuracy: 0.6062 - val_sensitivity_at_specificity: 0.5469 - val_specificity_at_sensitivity: 0.5596 - val_recall: 0.9846 - val_precision: 0.5648\n",
            "Epoch 200/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4365 - accuracy: 0.7870 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7785 - recall: 0.9892 - precision: 0.7048\n",
            "Epoch 200: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.4365 - accuracy: 0.7870 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7785 - recall: 0.9892 - precision: 0.7048 - val_loss: 0.6412 - val_accuracy: 0.6281 - val_sensitivity_at_specificity: 0.2915 - val_specificity_at_sensitivity: 0.3074 - val_recall: 0.9955 - val_precision: 0.5822\n",
            "Epoch 201/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4286 - accuracy: 0.7891 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7911 - recall: 0.9897 - precision: 0.7078\n",
            "Epoch 201: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 157ms/step - loss: 0.4280 - accuracy: 0.7903 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7886 - recall: 0.9901 - precision: 0.7095 - val_loss: 0.6825 - val_accuracy: 0.6016 - val_sensitivity_at_specificity: 0.4353 - val_specificity_at_sensitivity: 0.3083 - val_recall: 0.9828 - val_precision: 0.5580\n",
            "Epoch 202/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4306 - accuracy: 0.7949 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8051 - recall: 0.9916 - precision: 0.7162\n",
            "Epoch 202: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.4306 - accuracy: 0.7949 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8051 - recall: 0.9916 - precision: 0.7162 - val_loss: 0.6853 - val_accuracy: 0.6117 - val_sensitivity_at_specificity: 0.4658 - val_specificity_at_sensitivity: 0.4751 - val_recall: 0.9924 - val_precision: 0.5699\n",
            "Epoch 203/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4242 - accuracy: 0.7953 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8291 - recall: 0.9870 - precision: 0.7180\n",
            "Epoch 203: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.4242 - accuracy: 0.7953 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8291 - recall: 0.9870 - precision: 0.7180 - val_loss: 0.6636 - val_accuracy: 0.6203 - val_sensitivity_at_specificity: 0.6254 - val_specificity_at_sensitivity: 0.5919 - val_recall: 0.9953 - val_precision: 0.5680\n",
            "Epoch 204/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4188 - accuracy: 0.8051 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7779 - recall: 0.9963 - precision: 0.7299\n",
            "Epoch 204: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.4188 - accuracy: 0.8051 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7779 - recall: 0.9963 - precision: 0.7299 - val_loss: 0.6891 - val_accuracy: 0.6062 - val_sensitivity_at_specificity: 0.4914 - val_specificity_at_sensitivity: 0.2512 - val_recall: 0.9953 - val_precision: 0.5609\n",
            "Epoch 205/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4499 - accuracy: 0.7789 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.7753 - recall: 0.9859 - precision: 0.6962\n",
            "Epoch 205: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.4499 - accuracy: 0.7789 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.7753 - recall: 0.9859 - precision: 0.6962 - val_loss: 0.6723 - val_accuracy: 0.5828 - val_sensitivity_at_specificity: 0.2398 - val_specificity_at_sensitivity: 0.3463 - val_recall: 0.9869 - val_precision: 0.5349\n",
            "Epoch 206/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4472 - accuracy: 0.7777 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7776 - recall: 0.9922 - precision: 0.6949\n",
            "Epoch 206: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.4472 - accuracy: 0.7777 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7776 - recall: 0.9922 - precision: 0.6949 - val_loss: 0.6737 - val_accuracy: 0.5930 - val_sensitivity_at_specificity: 0.3987 - val_specificity_at_sensitivity: 0.2639 - val_recall: 0.9810 - val_precision: 0.5492\n",
            "Epoch 207/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4333 - accuracy: 0.7844 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7976 - recall: 0.9912 - precision: 0.6954\n",
            "Epoch 207: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 180ms/step - loss: 0.4333 - accuracy: 0.7844 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7976 - recall: 0.9912 - precision: 0.6954 - val_loss: 0.7257 - val_accuracy: 0.5633 - val_sensitivity_at_specificity: 0.4142 - val_specificity_at_sensitivity: 0.4911 - val_recall: 0.9934 - val_precision: 0.5203\n",
            "Epoch 208/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4186 - accuracy: 0.7996 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8041 - recall: 0.9876 - precision: 0.7200\n",
            "Epoch 208: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.4186 - accuracy: 0.7996 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8041 - recall: 0.9876 - precision: 0.7200 - val_loss: 0.6949 - val_accuracy: 0.5922 - val_sensitivity_at_specificity: 0.5766 - val_specificity_at_sensitivity: 0.5765 - val_recall: 0.9937 - val_precision: 0.5484\n",
            "Epoch 209/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4447 - accuracy: 0.7781 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7657 - recall: 0.9945 - precision: 0.6926\n",
            "Epoch 209: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.4447 - accuracy: 0.7781 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7657 - recall: 0.9945 - precision: 0.6926 - val_loss: 0.6538 - val_accuracy: 0.6242 - val_sensitivity_at_specificity: 0.2633 - val_specificity_at_sensitivity: 0.4350 - val_recall: 0.9909 - val_precision: 0.5782\n",
            "Epoch 210/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4421 - accuracy: 0.7781 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7606 - recall: 0.9889 - precision: 0.6924\n",
            "Epoch 210: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.4421 - accuracy: 0.7781 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7606 - recall: 0.9889 - precision: 0.6924 - val_loss: 0.7035 - val_accuracy: 0.5961 - val_sensitivity_at_specificity: 0.4321 - val_specificity_at_sensitivity: 0.2595 - val_recall: 0.9954 - val_precision: 0.5565\n",
            "Epoch 211/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4262 - accuracy: 0.7984 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7873 - recall: 0.9932 - precision: 0.7223\n",
            "Epoch 211: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.4262 - accuracy: 0.7984 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7873 - recall: 0.9932 - precision: 0.7223 - val_loss: 0.7147 - val_accuracy: 0.5844 - val_sensitivity_at_specificity: 0.5276 - val_specificity_at_sensitivity: 0.5595 - val_recall: 0.9921 - val_precision: 0.5437\n",
            "Epoch 212/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4245 - accuracy: 0.7949 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7689 - recall: 0.9953 - precision: 0.7118\n",
            "Epoch 212: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.4245 - accuracy: 0.7949 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7689 - recall: 0.9953 - precision: 0.7118 - val_loss: 0.6694 - val_accuracy: 0.6070 - val_sensitivity_at_specificity: 0.4839 - val_specificity_at_sensitivity: 0.2679 - val_recall: 0.9908 - val_precision: 0.5656\n",
            "Epoch 213/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4523 - accuracy: 0.7719 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.7496 - recall: 0.9827 - precision: 0.6902\n",
            "Epoch 213: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.4523 - accuracy: 0.7719 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.7496 - recall: 0.9827 - precision: 0.6902 - val_loss: 0.6680 - val_accuracy: 0.6078 - val_sensitivity_at_specificity: 0.2392 - val_specificity_at_sensitivity: 0.3687 - val_recall: 0.9923 - val_precision: 0.5640\n",
            "Epoch 214/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4294 - accuracy: 0.7903 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7964 - recall: 0.9907 - precision: 0.7038\n",
            "Epoch 214: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 156ms/step - loss: 0.4294 - accuracy: 0.7903 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7964 - recall: 0.9907 - precision: 0.7038 - val_loss: 0.6857 - val_accuracy: 0.5859 - val_sensitivity_at_specificity: 0.5491 - val_specificity_at_sensitivity: 0.5978 - val_recall: 0.9906 - val_precision: 0.5479\n",
            "Epoch 215/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4514 - accuracy: 0.7719 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7574 - recall: 0.9899 - precision: 0.6897\n",
            "Epoch 215: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.4514 - accuracy: 0.7719 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7574 - recall: 0.9899 - precision: 0.6897 - val_loss: 0.6735 - val_accuracy: 0.6023 - val_sensitivity_at_specificity: 0.2802 - val_specificity_at_sensitivity: 0.2539 - val_recall: 0.9985 - val_precision: 0.5594\n",
            "Epoch 216/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4306 - accuracy: 0.7875 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7548 - recall: 0.9929 - precision: 0.7023\n",
            "Epoch 216: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.4306 - accuracy: 0.7875 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7548 - recall: 0.9929 - precision: 0.7023 - val_loss: 0.6976 - val_accuracy: 0.5828 - val_sensitivity_at_specificity: 0.2801 - val_specificity_at_sensitivity: 0.2315 - val_recall: 0.9953 - val_precision: 0.5422\n",
            "Epoch 217/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4311 - accuracy: 0.7867 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7741 - recall: 0.9929 - precision: 0.7023\n",
            "Epoch 217: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.4311 - accuracy: 0.7867 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7741 - recall: 0.9929 - precision: 0.7023 - val_loss: 0.6579 - val_accuracy: 0.6219 - val_sensitivity_at_specificity: 0.4526 - val_specificity_at_sensitivity: 0.4715 - val_recall: 0.9820 - val_precision: 0.5804\n",
            "Epoch 218/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4383 - accuracy: 0.7805 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7609 - recall: 0.9864 - precision: 0.6936\n",
            "Epoch 218: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.4383 - accuracy: 0.7805 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7609 - recall: 0.9864 - precision: 0.6936 - val_loss: 0.6971 - val_accuracy: 0.5828 - val_sensitivity_at_specificity: 0.3873 - val_specificity_at_sensitivity: 0.3338 - val_recall: 0.9857 - val_precision: 0.5419\n",
            "Epoch 219/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4347 - accuracy: 0.7852 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7775 - recall: 0.9913 - precision: 0.7002\n",
            "Epoch 219: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.4347 - accuracy: 0.7852 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7775 - recall: 0.9913 - precision: 0.7002 - val_loss: 0.6799 - val_accuracy: 0.5883 - val_sensitivity_at_specificity: 0.3215 - val_specificity_at_sensitivity: 0.3146 - val_recall: 0.9839 - val_precision: 0.5421\n",
            "Epoch 220/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4372 - accuracy: 0.7840 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7841 - recall: 0.9937 - precision: 0.6981\n",
            "Epoch 220: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.4372 - accuracy: 0.7840 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7841 - recall: 0.9937 - precision: 0.6981 - val_loss: 0.6796 - val_accuracy: 0.6000 - val_sensitivity_at_specificity: 0.3500 - val_specificity_at_sensitivity: 0.2672 - val_recall: 0.9937 - val_precision: 0.5559\n",
            "Epoch 221/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4190 - accuracy: 0.7992 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.8029 - recall: 0.9898 - precision: 0.7152\n",
            "Epoch 221: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.4190 - accuracy: 0.7992 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.8029 - recall: 0.9898 - precision: 0.7152 - val_loss: 0.6675 - val_accuracy: 0.6219 - val_sensitivity_at_specificity: 0.4411 - val_specificity_at_sensitivity: 0.2896 - val_recall: 0.9879 - val_precision: 0.5788\n",
            "Epoch 222/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4585 - accuracy: 0.7699 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7313 - recall: 0.9946 - precision: 0.6881\n",
            "Epoch 222: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.4585 - accuracy: 0.7699 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7313 - recall: 0.9946 - precision: 0.6881 - val_loss: 0.6832 - val_accuracy: 0.5883 - val_sensitivity_at_specificity: 0.3805 - val_specificity_at_sensitivity: 0.2422 - val_recall: 0.9969 - val_precision: 0.5470\n",
            "Epoch 223/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4396 - accuracy: 0.7797 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7878 - recall: 0.9835 - precision: 0.6968\n",
            "Epoch 223: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.4396 - accuracy: 0.7797 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7878 - recall: 0.9835 - precision: 0.6968 - val_loss: 0.6454 - val_accuracy: 0.6289 - val_sensitivity_at_specificity: 0.3457 - val_specificity_at_sensitivity: 0.4620 - val_recall: 0.9896 - val_precision: 0.5877\n",
            "Epoch 224/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4418 - accuracy: 0.7809 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8052 - recall: 0.9900 - precision: 0.7009\n",
            "Epoch 224: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 183ms/step - loss: 0.4418 - accuracy: 0.7809 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8052 - recall: 0.9900 - precision: 0.7009 - val_loss: 0.6782 - val_accuracy: 0.5992 - val_sensitivity_at_specificity: 0.4297 - val_specificity_at_sensitivity: 0.2488 - val_recall: 1.0000 - val_precision: 0.5524\n",
            "Epoch 225/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4316 - accuracy: 0.7883 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7983 - recall: 0.9960 - precision: 0.7005\n",
            "Epoch 225: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.4316 - accuracy: 0.7883 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7983 - recall: 0.9960 - precision: 0.7005 - val_loss: 0.6764 - val_accuracy: 0.6070 - val_sensitivity_at_specificity: 0.3636 - val_specificity_at_sensitivity: 0.2629 - val_recall: 0.9970 - val_precision: 0.5677\n",
            "Epoch 226/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4309 - accuracy: 0.7867 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7655 - recall: 0.9913 - precision: 0.7015\n",
            "Epoch 226: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.4309 - accuracy: 0.7867 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7655 - recall: 0.9913 - precision: 0.7015 - val_loss: 0.6783 - val_accuracy: 0.6133 - val_sensitivity_at_specificity: 0.5586 - val_specificity_at_sensitivity: 0.5650 - val_recall: 0.9954 - val_precision: 0.5707\n",
            "Epoch 227/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4465 - accuracy: 0.7703 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7887 - recall: 0.9880 - precision: 0.6838\n",
            "Epoch 227: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.4465 - accuracy: 0.7703 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7887 - recall: 0.9880 - precision: 0.6838 - val_loss: 0.6917 - val_accuracy: 0.5875 - val_sensitivity_at_specificity: 0.3529 - val_specificity_at_sensitivity: 0.3675 - val_recall: 0.9845 - val_precision: 0.5511\n",
            "Epoch 228/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4333 - accuracy: 0.7871 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7430 - recall: 0.9937 - precision: 0.7018\n",
            "Epoch 228: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.4333 - accuracy: 0.7871 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7430 - recall: 0.9937 - precision: 0.7018 - val_loss: 0.6871 - val_accuracy: 0.5750 - val_sensitivity_at_specificity: 0.4188 - val_specificity_at_sensitivity: 0.3298 - val_recall: 0.9789 - val_precision: 0.5317\n",
            "Epoch 229/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4298 - accuracy: 0.7859 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8106 - recall: 0.9928 - precision: 0.6982\n",
            "Epoch 229: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.4298 - accuracy: 0.7859 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8106 - recall: 0.9928 - precision: 0.6982 - val_loss: 0.6829 - val_accuracy: 0.5984 - val_sensitivity_at_specificity: 0.4858 - val_specificity_at_sensitivity: 0.3323 - val_recall: 0.9953 - val_precision: 0.5533\n",
            "Epoch 230/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4412 - accuracy: 0.7793 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7798 - recall: 0.9905 - precision: 0.6940\n",
            "Epoch 230: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.4412 - accuracy: 0.7793 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7798 - recall: 0.9905 - precision: 0.6940 - val_loss: 0.6756 - val_accuracy: 0.5914 - val_sensitivity_at_specificity: 0.4601 - val_specificity_at_sensitivity: 0.3354 - val_recall: 0.9953 - val_precision: 0.5502\n",
            "Epoch 231/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4380 - accuracy: 0.7832 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7908 - recall: 0.9952 - precision: 0.6947\n",
            "Epoch 231: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.4380 - accuracy: 0.7832 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7908 - recall: 0.9952 - precision: 0.6947 - val_loss: 0.6786 - val_accuracy: 0.5836 - val_sensitivity_at_specificity: 0.3536 - val_specificity_at_sensitivity: 0.3359 - val_recall: 0.9920 - val_precision: 0.5401\n",
            "Epoch 232/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4413 - accuracy: 0.7793 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7525 - recall: 0.9883 - precision: 0.6968\n",
            "Epoch 232: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.4413 - accuracy: 0.7793 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7525 - recall: 0.9883 - precision: 0.6968 - val_loss: 0.6887 - val_accuracy: 0.5875 - val_sensitivity_at_specificity: 0.5397 - val_specificity_at_sensitivity: 0.5732 - val_recall: 0.9903 - val_precision: 0.5393\n",
            "Epoch 233/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4446 - accuracy: 0.7797 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7396 - recall: 0.9924 - precision: 0.7009\n",
            "Epoch 233: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.4446 - accuracy: 0.7797 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7396 - recall: 0.9924 - precision: 0.7009 - val_loss: 0.7282 - val_accuracy: 0.5750 - val_sensitivity_at_specificity: 0.5997 - val_specificity_at_sensitivity: 0.5105 - val_recall: 0.9886 - val_precision: 0.5298\n",
            "Epoch 234/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4287 - accuracy: 0.7922 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7895 - recall: 0.9871 - precision: 0.7167\n",
            "Epoch 234: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.4287 - accuracy: 0.7922 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7895 - recall: 0.9871 - precision: 0.7167 - val_loss: 0.7028 - val_accuracy: 0.5750 - val_sensitivity_at_specificity: 0.3620 - val_specificity_at_sensitivity: 0.2801 - val_recall: 0.9935 - val_precision: 0.5312\n",
            "Epoch 235/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4281 - accuracy: 0.7910 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8056 - recall: 0.9929 - precision: 0.7063\n",
            "Epoch 235: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.4281 - accuracy: 0.7910 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8056 - recall: 0.9929 - precision: 0.7063 - val_loss: 0.6971 - val_accuracy: 0.6047 - val_sensitivity_at_specificity: 0.5306 - val_specificity_at_sensitivity: 0.5739 - val_recall: 0.9890 - val_precision: 0.5580\n",
            "Epoch 236/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4354 - accuracy: 0.7859 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8175 - recall: 0.9906 - precision: 0.7034\n",
            "Epoch 236: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.4354 - accuracy: 0.7859 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8175 - recall: 0.9906 - precision: 0.7034 - val_loss: 0.6748 - val_accuracy: 0.6125 - val_sensitivity_at_specificity: 0.2496 - val_specificity_at_sensitivity: 0.4764 - val_recall: 0.9910 - val_precision: 0.5735\n",
            "Epoch 237/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4459 - accuracy: 0.7691 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8137 - recall: 0.9896 - precision: 0.6807\n",
            "Epoch 237: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.4459 - accuracy: 0.7691 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8137 - recall: 0.9896 - precision: 0.6807 - val_loss: 0.6750 - val_accuracy: 0.5922 - val_sensitivity_at_specificity: 0.4189 - val_specificity_at_sensitivity: 0.4775 - val_recall: 0.9591 - val_precision: 0.5511\n",
            "Epoch 238/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4369 - accuracy: 0.7849 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7904 - recall: 0.9882 - precision: 0.6986\n",
            "Epoch 238: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.4369 - accuracy: 0.7849 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7904 - recall: 0.9882 - precision: 0.6986 - val_loss: 0.6957 - val_accuracy: 0.5906 - val_sensitivity_at_specificity: 0.5147 - val_specificity_at_sensitivity: 0.5717 - val_recall: 0.9969 - val_precision: 0.5519\n",
            "Epoch 239/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4382 - accuracy: 0.7855 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.7844 - recall: 0.9960 - precision: 0.6978\n",
            "Epoch 239: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.4382 - accuracy: 0.7855 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.7844 - recall: 0.9960 - precision: 0.6978 - val_loss: 0.6700 - val_accuracy: 0.5977 - val_sensitivity_at_specificity: 0.4582 - val_specificity_at_sensitivity: 0.3404 - val_recall: 0.9887 - val_precision: 0.5476\n",
            "Epoch 240/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4391 - accuracy: 0.7844 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.7738 - recall: 0.9868 - precision: 0.7036\n",
            "Epoch 240: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.4391 - accuracy: 0.7844 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.7738 - recall: 0.9868 - precision: 0.7036 - val_loss: 0.7259 - val_accuracy: 0.5750 - val_sensitivity_at_specificity: 0.5260 - val_specificity_at_sensitivity: 0.5535 - val_recall: 0.9969 - val_precision: 0.5387\n",
            "Epoch 241/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4358 - accuracy: 0.7832 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8282 - recall: 0.9850 - precision: 0.7005\n",
            "Epoch 241: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.4358 - accuracy: 0.7832 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8282 - recall: 0.9850 - precision: 0.7005 - val_loss: 0.6966 - val_accuracy: 0.5922 - val_sensitivity_at_specificity: 0.5976 - val_specificity_at_sensitivity: 0.5137 - val_recall: 0.9743 - val_precision: 0.5605\n",
            "Epoch 242/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4389 - accuracy: 0.7820 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7590 - recall: 0.9941 - precision: 0.6937\n",
            "Epoch 242: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.4389 - accuracy: 0.7820 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7590 - recall: 0.9941 - precision: 0.6937 - val_loss: 0.6841 - val_accuracy: 0.5914 - val_sensitivity_at_specificity: 0.4793 - val_specificity_at_sensitivity: 0.4006 - val_recall: 0.9877 - val_precision: 0.5553\n",
            "Epoch 243/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4290 - accuracy: 0.7848 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8048 - recall: 0.9855 - precision: 0.6959\n",
            "Epoch 243: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.4290 - accuracy: 0.7848 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8048 - recall: 0.9855 - precision: 0.6959 - val_loss: 0.6682 - val_accuracy: 0.5984 - val_sensitivity_at_specificity: 0.4302 - val_specificity_at_sensitivity: 0.3831 - val_recall: 0.9857 - val_precision: 0.5515\n",
            "Epoch 244/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4384 - accuracy: 0.7824 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7959 - recall: 0.9942 - precision: 0.6982\n",
            "Epoch 244: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.4384 - accuracy: 0.7824 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7959 - recall: 0.9942 - precision: 0.6982 - val_loss: 0.6709 - val_accuracy: 0.6070 - val_sensitivity_at_specificity: 0.6430 - val_specificity_at_sensitivity: 0.5324 - val_recall: 0.9892 - val_precision: 0.5634\n",
            "Epoch 245/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4481 - accuracy: 0.7695 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7725 - recall: 0.9872 - precision: 0.6818\n",
            "Epoch 245: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 185ms/step - loss: 0.4481 - accuracy: 0.7695 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7725 - recall: 0.9872 - precision: 0.6818 - val_loss: 0.7317 - val_accuracy: 0.5695 - val_sensitivity_at_specificity: 0.4416 - val_specificity_at_sensitivity: 0.3142 - val_recall: 0.9874 - val_precision: 0.5355\n",
            "Epoch 246/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4338 - accuracy: 0.7871 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7800 - recall: 0.9864 - precision: 0.7117\n",
            "Epoch 246: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.4338 - accuracy: 0.7871 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7800 - recall: 0.9864 - precision: 0.7117 - val_loss: 0.6794 - val_accuracy: 0.6055 - val_sensitivity_at_specificity: 0.4420 - val_specificity_at_sensitivity: 0.3302 - val_recall: 0.9922 - val_precision: 0.5587\n",
            "Epoch 247/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4378 - accuracy: 0.7789 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7813 - recall: 0.9897 - precision: 0.6923\n",
            "Epoch 247: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.4378 - accuracy: 0.7789 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7813 - recall: 0.9897 - precision: 0.6923 - val_loss: 0.6479 - val_accuracy: 0.6102 - val_sensitivity_at_specificity: 0.6569 - val_specificity_at_sensitivity: 0.6079 - val_recall: 0.9569 - val_precision: 0.5691\n",
            "Epoch 248/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4345 - accuracy: 0.7809 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8116 - recall: 0.9862 - precision: 0.6900\n",
            "Epoch 248: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 211ms/step - loss: 0.4345 - accuracy: 0.7809 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8116 - recall: 0.9862 - precision: 0.6900 - val_loss: 0.6913 - val_accuracy: 0.5938 - val_sensitivity_at_specificity: 0.6699 - val_specificity_at_sensitivity: 0.5257 - val_recall: 1.0000 - val_precision: 0.5431\n",
            "Epoch 249/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4433 - accuracy: 0.7828 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7750 - recall: 0.9893 - precision: 0.7025\n",
            "Epoch 249: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 195ms/step - loss: 0.4433 - accuracy: 0.7828 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7750 - recall: 0.9893 - precision: 0.7025 - val_loss: 0.6588 - val_accuracy: 0.6062 - val_sensitivity_at_specificity: 0.7296 - val_specificity_at_sensitivity: 0.5140 - val_recall: 0.9953 - val_precision: 0.5582\n",
            "Epoch 250/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4281 - accuracy: 0.7977 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7954 - recall: 0.9933 - precision: 0.7231\n",
            "Epoch 250: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.4281 - accuracy: 0.7977 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7954 - recall: 0.9933 - precision: 0.7231 - val_loss: 0.6923 - val_accuracy: 0.6156 - val_sensitivity_at_specificity: 0.7027 - val_specificity_at_sensitivity: 0.6138 - val_recall: 0.9924 - val_precision: 0.5721\n",
            "Epoch 251/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4197 - accuracy: 0.7992 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8224 - recall: 0.9902 - precision: 0.7231\n",
            "Epoch 251: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.4197 - accuracy: 0.7992 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8224 - recall: 0.9902 - precision: 0.7231 - val_loss: 0.7123 - val_accuracy: 0.5859 - val_sensitivity_at_specificity: 0.5874 - val_specificity_at_sensitivity: 0.6140 - val_recall: 0.9827 - val_precision: 0.5459\n",
            "Epoch 252/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4377 - accuracy: 0.7797 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.8287 - recall: 0.9830 - precision: 0.7010\n",
            "Epoch 252: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.4377 - accuracy: 0.7797 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.8287 - recall: 0.9830 - precision: 0.7010 - val_loss: 0.6865 - val_accuracy: 0.5969 - val_sensitivity_at_specificity: 0.7081 - val_specificity_at_sensitivity: 0.6156 - val_recall: 0.9809 - val_precision: 0.5496\n",
            "Epoch 253/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4365 - accuracy: 0.7801 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7758 - recall: 0.9898 - precision: 0.6958\n",
            "Epoch 253: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.4365 - accuracy: 0.7801 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7758 - recall: 0.9898 - precision: 0.6958 - val_loss: 0.6678 - val_accuracy: 0.5914 - val_sensitivity_at_specificity: 0.5886 - val_specificity_at_sensitivity: 0.5926 - val_recall: 0.9684 - val_precision: 0.5489\n",
            "Epoch 254/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4357 - accuracy: 0.7766 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8305 - recall: 0.9779 - precision: 0.6866\n",
            "Epoch 254: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.4357 - accuracy: 0.7766 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8305 - recall: 0.9779 - precision: 0.6866 - val_loss: 0.6983 - val_accuracy: 0.5945 - val_sensitivity_at_specificity: 0.5337 - val_specificity_at_sensitivity: 0.5915 - val_recall: 0.9968 - val_precision: 0.5461\n",
            "Epoch 255/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4390 - accuracy: 0.7809 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8050 - recall: 0.9890 - precision: 0.6971\n",
            "Epoch 255: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.4390 - accuracy: 0.7809 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8050 - recall: 0.9890 - precision: 0.6971 - val_loss: 0.6941 - val_accuracy: 0.5930 - val_sensitivity_at_specificity: 0.6161 - val_specificity_at_sensitivity: 0.6491 - val_recall: 0.9905 - val_precision: 0.5490\n",
            "Epoch 256/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4383 - accuracy: 0.7809 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8189 - recall: 0.9905 - precision: 0.6958\n",
            "Epoch 256: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.4383 - accuracy: 0.7809 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8189 - recall: 0.9905 - precision: 0.6958 - val_loss: 0.6789 - val_accuracy: 0.6008 - val_sensitivity_at_specificity: 0.6572 - val_specificity_at_sensitivity: 0.6321 - val_recall: 0.9921 - val_precision: 0.5538\n",
            "Epoch 257/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4304 - accuracy: 0.7805 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8384 - recall: 0.9864 - precision: 0.6942\n",
            "Epoch 257: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.4304 - accuracy: 0.7805 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8384 - recall: 0.9864 - precision: 0.6942 - val_loss: 0.7351 - val_accuracy: 0.5984 - val_sensitivity_at_specificity: 0.5809 - val_specificity_at_sensitivity: 0.5347 - val_recall: 0.9849 - val_precision: 0.5636\n",
            "Epoch 258/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4124 - accuracy: 0.7957 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.8413 - recall: 0.9874 - precision: 0.7118\n",
            "Epoch 258: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.4124 - accuracy: 0.7957 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.8413 - recall: 0.9874 - precision: 0.7118 - val_loss: 0.6944 - val_accuracy: 0.5992 - val_sensitivity_at_specificity: 0.6609 - val_specificity_at_sensitivity: 0.6344 - val_recall: 0.9828 - val_precision: 0.5561\n",
            "Epoch 259/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4245 - accuracy: 0.7949 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8316 - recall: 0.9930 - precision: 0.7127\n",
            "Epoch 259: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.4245 - accuracy: 0.7949 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8316 - recall: 0.9930 - precision: 0.7127 - val_loss: 0.6852 - val_accuracy: 0.6031 - val_sensitivity_at_specificity: 0.4177 - val_specificity_at_sensitivity: 0.3931 - val_recall: 0.9922 - val_precision: 0.5595\n",
            "Epoch 260/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4358 - accuracy: 0.7855 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.7606 - recall: 0.9922 - precision: 0.7030\n",
            "Epoch 260: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.4358 - accuracy: 0.7855 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.7606 - recall: 0.9922 - precision: 0.7030 - val_loss: 0.6832 - val_accuracy: 0.5992 - val_sensitivity_at_specificity: 0.3627 - val_specificity_at_sensitivity: 0.4415 - val_recall: 0.9861 - val_precision: 0.5591\n",
            "Epoch 261/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4421 - accuracy: 0.7812 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8069 - recall: 0.9924 - precision: 0.7046\n",
            "Epoch 261: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.4421 - accuracy: 0.7812 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8069 - recall: 0.9924 - precision: 0.7046 - val_loss: 0.6851 - val_accuracy: 0.6195 - val_sensitivity_at_specificity: 0.5340 - val_specificity_at_sensitivity: 0.6171 - val_recall: 0.9923 - val_precision: 0.5716\n",
            "Epoch 262/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4217 - accuracy: 0.7957 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8345 - recall: 0.9939 - precision: 0.7155\n",
            "Epoch 262: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.4217 - accuracy: 0.7957 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8345 - recall: 0.9939 - precision: 0.7155 - val_loss: 0.7188 - val_accuracy: 0.5883 - val_sensitivity_at_specificity: 0.6447 - val_specificity_at_sensitivity: 0.6003 - val_recall: 0.9887 - val_precision: 0.5419\n",
            "Epoch 263/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4227 - accuracy: 0.7969 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8449 - recall: 0.9897 - precision: 0.7259\n",
            "Epoch 263: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.4227 - accuracy: 0.7969 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8449 - recall: 0.9897 - precision: 0.7259 - val_loss: 0.7154 - val_accuracy: 0.6039 - val_sensitivity_at_specificity: 0.6293 - val_specificity_at_sensitivity: 0.5614 - val_recall: 0.9985 - val_precision: 0.5690\n",
            "Epoch 264/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4136 - accuracy: 0.7949 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8500 - recall: 0.9911 - precision: 0.7051\n",
            "Epoch 264: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.4136 - accuracy: 0.7949 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8500 - recall: 0.9911 - precision: 0.7051 - val_loss: 0.6929 - val_accuracy: 0.6016 - val_sensitivity_at_specificity: 0.6636 - val_specificity_at_sensitivity: 0.6223 - val_recall: 0.9735 - val_precision: 0.5590\n",
            "Epoch 265/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4201 - accuracy: 0.7887 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8622 - recall: 0.9790 - precision: 0.7096\n",
            "Epoch 265: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.4201 - accuracy: 0.7887 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8622 - recall: 0.9790 - precision: 0.7096 - val_loss: 0.6967 - val_accuracy: 0.5766 - val_sensitivity_at_specificity: 0.6419 - val_specificity_at_sensitivity: 0.6273 - val_recall: 0.9758 - val_precision: 0.5345\n",
            "Epoch 266/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4296 - accuracy: 0.7890 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8399 - recall: 0.9741 - precision: 0.7095\n",
            "Epoch 266: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 157ms/step - loss: 0.4296 - accuracy: 0.7890 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8399 - recall: 0.9741 - precision: 0.7095 - val_loss: 0.7053 - val_accuracy: 0.6023 - val_sensitivity_at_specificity: 0.7014 - val_specificity_at_sensitivity: 0.6641 - val_recall: 0.9813 - val_precision: 0.5594\n",
            "Epoch 267/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4133 - accuracy: 0.7961 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8355 - recall: 0.9849 - precision: 0.7114\n",
            "Epoch 267: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.4133 - accuracy: 0.7961 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8355 - recall: 0.9849 - precision: 0.7114 - val_loss: 0.7328 - val_accuracy: 0.5914 - val_sensitivity_at_specificity: 0.6740 - val_specificity_at_sensitivity: 0.6264 - val_recall: 0.9906 - val_precision: 0.5489\n",
            "Epoch 268/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4167 - accuracy: 0.7930 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8505 - recall: 0.9869 - precision: 0.7137\n",
            "Epoch 268: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.4167 - accuracy: 0.7930 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8505 - recall: 0.9869 - precision: 0.7137 - val_loss: 0.6783 - val_accuracy: 0.6047 - val_sensitivity_at_specificity: 0.6641 - val_specificity_at_sensitivity: 0.6032 - val_recall: 0.9863 - val_precision: 0.5652\n",
            "Epoch 269/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4157 - accuracy: 0.7902 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8648 - recall: 0.9876 - precision: 0.7094\n",
            "Epoch 269: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.4157 - accuracy: 0.7902 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8648 - recall: 0.9876 - precision: 0.7094 - val_loss: 0.6862 - val_accuracy: 0.5852 - val_sensitivity_at_specificity: 0.6516 - val_specificity_at_sensitivity: 0.6106 - val_recall: 0.9710 - val_precision: 0.5399\n",
            "Epoch 270/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4374 - accuracy: 0.7719 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8482 - recall: 0.9806 - precision: 0.6934\n",
            "Epoch 270: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.4374 - accuracy: 0.7719 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8482 - recall: 0.9806 - precision: 0.6934 - val_loss: 0.7058 - val_accuracy: 0.6094 - val_sensitivity_at_specificity: 0.6636 - val_specificity_at_sensitivity: 0.6323 - val_recall: 0.9879 - val_precision: 0.5699\n",
            "Epoch 271/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4370 - accuracy: 0.7820 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8340 - recall: 0.9676 - precision: 0.7030\n",
            "Epoch 271: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.4370 - accuracy: 0.7820 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8340 - recall: 0.9676 - precision: 0.7030 - val_loss: 0.6848 - val_accuracy: 0.5961 - val_sensitivity_at_specificity: 0.6923 - val_specificity_at_sensitivity: 0.6508 - val_recall: 0.9892 - val_precision: 0.5577\n",
            "Epoch 272/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4279 - accuracy: 0.7841 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8508 - recall: 0.9907 - precision: 0.6981\n",
            "Epoch 272: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 157ms/step - loss: 0.4279 - accuracy: 0.7841 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8508 - recall: 0.9907 - precision: 0.6981 - val_loss: 0.6452 - val_accuracy: 0.6102 - val_sensitivity_at_specificity: 0.7439 - val_specificity_at_sensitivity: 0.6987 - val_recall: 0.9756 - val_precision: 0.5699\n",
            "Epoch 273/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4170 - accuracy: 0.7941 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8577 - recall: 0.9846 - precision: 0.7155\n",
            "Epoch 273: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.4170 - accuracy: 0.7941 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8577 - recall: 0.9846 - precision: 0.7155 - val_loss: 0.7264 - val_accuracy: 0.5742 - val_sensitivity_at_specificity: 0.6786 - val_specificity_at_sensitivity: 0.6342 - val_recall: 0.9886 - val_precision: 0.5297\n",
            "Epoch 274/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4220 - accuracy: 0.7855 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8671 - recall: 0.9874 - precision: 0.7011\n",
            "Epoch 274: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.4220 - accuracy: 0.7855 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8671 - recall: 0.9874 - precision: 0.7011 - val_loss: 0.7472 - val_accuracy: 0.6023 - val_sensitivity_at_specificity: 0.6898 - val_specificity_at_sensitivity: 0.5876 - val_recall: 0.9906 - val_precision: 0.5557\n",
            "Epoch 275/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4296 - accuracy: 0.7828 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8351 - recall: 0.9864 - precision: 0.6958\n",
            "Epoch 275: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.4296 - accuracy: 0.7828 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8351 - recall: 0.9864 - precision: 0.6958 - val_loss: 0.6618 - val_accuracy: 0.6055 - val_sensitivity_at_specificity: 0.6947 - val_specificity_at_sensitivity: 0.6724 - val_recall: 0.9922 - val_precision: 0.5602\n",
            "Epoch 276/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4270 - accuracy: 0.7875 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8618 - recall: 0.9930 - precision: 0.7060\n",
            "Epoch 276: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.4270 - accuracy: 0.7875 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8618 - recall: 0.9930 - precision: 0.7060 - val_loss: 0.7401 - val_accuracy: 0.5813 - val_sensitivity_at_specificity: 0.6640 - val_specificity_at_sensitivity: 0.6146 - val_recall: 0.9921 - val_precision: 0.5422\n",
            "Epoch 277/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4268 - accuracy: 0.7871 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8489 - recall: 0.9760 - precision: 0.7099\n",
            "Epoch 277: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.4268 - accuracy: 0.7871 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8489 - recall: 0.9760 - precision: 0.7099 - val_loss: 0.6848 - val_accuracy: 0.5914 - val_sensitivity_at_specificity: 0.7284 - val_specificity_at_sensitivity: 0.6713 - val_recall: 0.9904 - val_precision: 0.5453\n",
            "Epoch 278/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4316 - accuracy: 0.7844 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8518 - recall: 0.9954 - precision: 0.7029\n",
            "Epoch 278: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.4316 - accuracy: 0.7844 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8518 - recall: 0.9954 - precision: 0.7029 - val_loss: 0.6640 - val_accuracy: 0.6141 - val_sensitivity_at_specificity: 0.7556 - val_specificity_at_sensitivity: 0.6793 - val_recall: 0.9867 - val_precision: 0.5786\n",
            "Epoch 279/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4391 - accuracy: 0.7746 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8483 - recall: 0.9826 - precision: 0.6918\n",
            "Epoch 279: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.4391 - accuracy: 0.7746 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8483 - recall: 0.9826 - precision: 0.6918 - val_loss: 0.7474 - val_accuracy: 0.5680 - val_sensitivity_at_specificity: 0.5924 - val_specificity_at_sensitivity: 0.5690 - val_recall: 0.9793 - val_precision: 0.5325\n",
            "Epoch 280/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4504 - accuracy: 0.7688 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7889 - recall: 0.9807 - precision: 0.6821\n",
            "Epoch 280: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.4504 - accuracy: 0.7688 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7889 - recall: 0.9807 - precision: 0.6821 - val_loss: 0.6631 - val_accuracy: 0.6039 - val_sensitivity_at_specificity: 0.7356 - val_specificity_at_sensitivity: 0.6562 - val_recall: 0.9813 - val_precision: 0.5604\n",
            "Epoch 281/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4300 - accuracy: 0.7836 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8253 - recall: 0.9850 - precision: 0.6998\n",
            "Epoch 281: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.4300 - accuracy: 0.7836 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8253 - recall: 0.9850 - precision: 0.6998 - val_loss: 0.7439 - val_accuracy: 0.5656 - val_sensitivity_at_specificity: 0.6872 - val_specificity_at_sensitivity: 0.6124 - val_recall: 0.9870 - val_precision: 0.5264\n",
            "Epoch 282/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4368 - accuracy: 0.7812 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8283 - recall: 0.9954 - precision: 0.7025\n",
            "Epoch 282: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.4368 - accuracy: 0.7812 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8283 - recall: 0.9954 - precision: 0.7025 - val_loss: 0.6644 - val_accuracy: 0.6086 - val_sensitivity_at_specificity: 0.6804 - val_specificity_at_sensitivity: 0.6709 - val_recall: 0.9802 - val_precision: 0.5689\n",
            "Epoch 283/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4225 - accuracy: 0.7809 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8638 - recall: 0.9753 - precision: 0.6975\n",
            "Epoch 283: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.4225 - accuracy: 0.7809 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8638 - recall: 0.9753 - precision: 0.6975 - val_loss: 0.7329 - val_accuracy: 0.6055 - val_sensitivity_at_specificity: 0.6048 - val_specificity_at_sensitivity: 0.5833 - val_recall: 0.9775 - val_precision: 0.5713\n",
            "Epoch 284/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4362 - accuracy: 0.7891 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8093 - recall: 0.9864 - precision: 0.7151\n",
            "Epoch 284: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.4362 - accuracy: 0.7891 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8093 - recall: 0.9864 - precision: 0.7151 - val_loss: 0.7010 - val_accuracy: 0.6039 - val_sensitivity_at_specificity: 0.5963 - val_specificity_at_sensitivity: 0.5723 - val_recall: 0.9876 - val_precision: 0.5604\n",
            "Epoch 285/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4254 - accuracy: 0.7911 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7927 - recall: 0.9908 - precision: 0.7068\n",
            "Epoch 285: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.4254 - accuracy: 0.7911 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7927 - recall: 0.9908 - precision: 0.7068 - val_loss: 0.7450 - val_accuracy: 0.5711 - val_sensitivity_at_specificity: 0.3780 - val_specificity_at_sensitivity: 0.4312 - val_recall: 0.9952 - val_precision: 0.5301\n",
            "Epoch 286/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4190 - accuracy: 0.8020 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7886 - recall: 0.9933 - precision: 0.7270\n",
            "Epoch 286: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.4190 - accuracy: 0.8020 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7886 - recall: 0.9933 - precision: 0.7270 - val_loss: 0.7266 - val_accuracy: 0.5859 - val_sensitivity_at_specificity: 0.4913 - val_specificity_at_sensitivity: 0.4465 - val_recall: 0.9795 - val_precision: 0.5461\n",
            "Epoch 287/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4178 - accuracy: 0.7969 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8172 - recall: 0.9937 - precision: 0.7112\n",
            "Epoch 287: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.4178 - accuracy: 0.7969 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8172 - recall: 0.9937 - precision: 0.7112 - val_loss: 0.6814 - val_accuracy: 0.5883 - val_sensitivity_at_specificity: 0.7122 - val_specificity_at_sensitivity: 0.6298 - val_recall: 0.9746 - val_precision: 0.5454\n",
            "Epoch 288/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4113 - accuracy: 0.7996 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8356 - recall: 0.9844 - precision: 0.7192\n",
            "Epoch 288: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 181ms/step - loss: 0.4113 - accuracy: 0.7996 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8356 - recall: 0.9844 - precision: 0.7192 - val_loss: 0.7602 - val_accuracy: 0.5703 - val_sensitivity_at_specificity: 0.6286 - val_specificity_at_sensitivity: 0.6123 - val_recall: 0.9873 - val_precision: 0.5344\n",
            "Epoch 289/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4324 - accuracy: 0.7855 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.8140 - recall: 0.9873 - precision: 0.6999\n",
            "Epoch 289: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.4324 - accuracy: 0.7855 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.8140 - recall: 0.9873 - precision: 0.6999 - val_loss: 0.6778 - val_accuracy: 0.6117 - val_sensitivity_at_specificity: 0.4259 - val_specificity_at_sensitivity: 0.4992 - val_recall: 0.9750 - val_precision: 0.5651\n",
            "Epoch 290/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4371 - accuracy: 0.7848 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8125 - recall: 0.9898 - precision: 0.7001\n",
            "Epoch 290: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.4371 - accuracy: 0.7848 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8125 - recall: 0.9898 - precision: 0.7001 - val_loss: 0.6989 - val_accuracy: 0.5797 - val_sensitivity_at_specificity: 0.2672 - val_specificity_at_sensitivity: 0.4688 - val_recall: 0.9719 - val_precision: 0.5447\n",
            "Epoch 291/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4295 - accuracy: 0.7890 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8159 - recall: 0.9925 - precision: 0.7042\n",
            "Epoch 291: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.4295 - accuracy: 0.7890 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8159 - recall: 0.9925 - precision: 0.7042 - val_loss: 0.7063 - val_accuracy: 0.5859 - val_sensitivity_at_specificity: 0.4137 - val_specificity_at_sensitivity: 0.4190 - val_recall: 0.9936 - val_precision: 0.5418\n",
            "Epoch 292/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4339 - accuracy: 0.7777 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8195 - recall: 0.9895 - precision: 0.6875\n",
            "Epoch 292: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.4339 - accuracy: 0.7777 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8195 - recall: 0.9895 - precision: 0.6875 - val_loss: 0.6543 - val_accuracy: 0.5969 - val_sensitivity_at_specificity: 0.6740 - val_specificity_at_sensitivity: 0.6434 - val_recall: 0.9906 - val_precision: 0.5522\n",
            "Epoch 293/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4285 - accuracy: 0.7871 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.8412 - recall: 0.9875 - precision: 0.7053\n",
            "Epoch 293: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.4285 - accuracy: 0.7871 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.8412 - recall: 0.9875 - precision: 0.7053 - val_loss: 0.7367 - val_accuracy: 0.5828 - val_sensitivity_at_specificity: 0.6192 - val_specificity_at_sensitivity: 0.5435 - val_recall: 0.9968 - val_precision: 0.5394\n",
            "Epoch 294/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4206 - accuracy: 0.7965 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8186 - recall: 0.9930 - precision: 0.7130\n",
            "Epoch 294: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.4206 - accuracy: 0.7965 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8186 - recall: 0.9930 - precision: 0.7130 - val_loss: 0.7195 - val_accuracy: 0.5781 - val_sensitivity_at_specificity: 0.2572 - val_specificity_at_sensitivity: 0.4786 - val_recall: 0.9696 - val_precision: 0.5381\n",
            "Epoch 295/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4290 - accuracy: 0.7879 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7817 - recall: 0.9897 - precision: 0.7016\n",
            "Epoch 295: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.4290 - accuracy: 0.7879 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.7817 - recall: 0.9897 - precision: 0.7016 - val_loss: 0.7407 - val_accuracy: 0.5703 - val_sensitivity_at_specificity: 0.2757 - val_specificity_at_sensitivity: 0.4322 - val_recall: 0.9954 - val_precision: 0.5430\n",
            "Epoch 296/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4201 - accuracy: 0.7914 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8299 - recall: 0.9834 - precision: 0.7084\n",
            "Epoch 296: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.4201 - accuracy: 0.7914 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8299 - recall: 0.9834 - precision: 0.7084 - val_loss: 0.6840 - val_accuracy: 0.5938 - val_sensitivity_at_specificity: 0.6746 - val_specificity_at_sensitivity: 0.6337 - val_recall: 0.9779 - val_precision: 0.5502\n",
            "Epoch 297/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4413 - accuracy: 0.7773 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8168 - recall: 0.9787 - precision: 0.6953\n",
            "Epoch 297: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.4413 - accuracy: 0.7773 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8168 - recall: 0.9787 - precision: 0.6953 - val_loss: 0.6756 - val_accuracy: 0.6109 - val_sensitivity_at_specificity: 0.7484 - val_specificity_at_sensitivity: 0.6431 - val_recall: 0.9798 - val_precision: 0.5654\n",
            "Epoch 298/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4124 - accuracy: 0.7957 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8528 - recall: 0.9832 - precision: 0.7200\n",
            "Epoch 298: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.4124 - accuracy: 0.7957 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8528 - recall: 0.9832 - precision: 0.7200 - val_loss: 0.6503 - val_accuracy: 0.6117 - val_sensitivity_at_specificity: 0.7047 - val_specificity_at_sensitivity: 0.6734 - val_recall: 0.9844 - val_precision: 0.5640\n",
            "Epoch 299/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4186 - accuracy: 0.7887 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8649 - recall: 0.9803 - precision: 0.7073\n",
            "Epoch 299: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.4186 - accuracy: 0.7887 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8649 - recall: 0.9803 - precision: 0.7073 - val_loss: 0.6847 - val_accuracy: 0.5906 - val_sensitivity_at_specificity: 0.7346 - val_specificity_at_sensitivity: 0.6798 - val_recall: 0.9968 - val_precision: 0.5413\n",
            "Epoch 300/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4359 - accuracy: 0.7699 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8676 - recall: 0.9799 - precision: 0.6840\n",
            "Epoch 300: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.4359 - accuracy: 0.7699 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8676 - recall: 0.9799 - precision: 0.6840 - val_loss: 0.6707 - val_accuracy: 0.5938 - val_sensitivity_at_specificity: 0.7426 - val_specificity_at_sensitivity: 0.6731 - val_recall: 0.9918 - val_precision: 0.5402\n",
            "Epoch 301/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4177 - accuracy: 0.7891 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8616 - recall: 0.9841 - precision: 0.7044\n",
            "Epoch 301: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.4177 - accuracy: 0.7891 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8616 - recall: 0.9841 - precision: 0.7044 - val_loss: 0.6549 - val_accuracy: 0.6008 - val_sensitivity_at_specificity: 0.6796 - val_specificity_at_sensitivity: 0.6893 - val_recall: 0.9907 - val_precision: 0.5590\n",
            "Epoch 302/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4149 - accuracy: 0.7871 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8769 - recall: 0.9903 - precision: 0.6966\n",
            "Epoch 302: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.4149 - accuracy: 0.7871 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8769 - recall: 0.9903 - precision: 0.6966 - val_loss: 0.7013 - val_accuracy: 0.5961 - val_sensitivity_at_specificity: 0.7280 - val_specificity_at_sensitivity: 0.6656 - val_recall: 0.9872 - val_precision: 0.5480\n",
            "Epoch 303/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3991 - accuracy: 0.8031 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8733 - recall: 0.9834 - precision: 0.7205\n",
            "Epoch 303: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.3991 - accuracy: 0.8031 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8733 - recall: 0.9834 - precision: 0.7205 - val_loss: 0.7296 - val_accuracy: 0.5969 - val_sensitivity_at_specificity: 0.7014 - val_specificity_at_sensitivity: 0.6300 - val_recall: 0.9832 - val_precision: 0.5597\n",
            "Epoch 304/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4171 - accuracy: 0.7891 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8662 - recall: 0.9814 - precision: 0.7103\n",
            "Epoch 304: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.4171 - accuracy: 0.7891 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8662 - recall: 0.9814 - precision: 0.7103 - val_loss: 0.6933 - val_accuracy: 0.6141 - val_sensitivity_at_specificity: 0.6662 - val_specificity_at_sensitivity: 0.6377 - val_recall: 0.9605 - val_precision: 0.5749\n",
            "Epoch 305/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4180 - accuracy: 0.7895 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.8613 - recall: 0.9778 - precision: 0.7072\n",
            "Epoch 305: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.4180 - accuracy: 0.7895 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.8613 - recall: 0.9778 - precision: 0.7072 - val_loss: 0.7000 - val_accuracy: 0.6031 - val_sensitivity_at_specificity: 0.6949 - val_specificity_at_sensitivity: 0.6359 - val_recall: 0.9653 - val_precision: 0.5685\n",
            "Epoch 306/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4332 - accuracy: 0.7914 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.8471 - recall: 0.9792 - precision: 0.7148\n",
            "Epoch 306: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.4332 - accuracy: 0.7914 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.8471 - recall: 0.9792 - precision: 0.7148 - val_loss: 0.6803 - val_accuracy: 0.6062 - val_sensitivity_at_specificity: 0.6865 - val_specificity_at_sensitivity: 0.6480 - val_recall: 0.9436 - val_precision: 0.5626\n",
            "Epoch 307/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4087 - accuracy: 0.7961 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8631 - recall: 0.9609 - precision: 0.7178\n",
            "Epoch 307: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.4087 - accuracy: 0.7961 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8631 - recall: 0.9609 - precision: 0.7178 - val_loss: 0.6692 - val_accuracy: 0.6039 - val_sensitivity_at_specificity: 0.7718 - val_specificity_at_sensitivity: 0.7039 - val_recall: 0.9676 - val_precision: 0.5512\n",
            "Epoch 308/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4035 - accuracy: 0.8023 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8726 - recall: 0.9657 - precision: 0.7332\n",
            "Epoch 308: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.4035 - accuracy: 0.8023 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8726 - recall: 0.9657 - precision: 0.7332 - val_loss: 0.7156 - val_accuracy: 0.6070 - val_sensitivity_at_specificity: 0.7435 - val_specificity_at_sensitivity: 0.6909 - val_recall: 0.9774 - val_precision: 0.5534\n",
            "Epoch 309/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4396 - accuracy: 0.7770 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8394 - recall: 0.9537 - precision: 0.6995\n",
            "Epoch 309: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.4396 - accuracy: 0.7770 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8394 - recall: 0.9537 - precision: 0.6995 - val_loss: 0.7055 - val_accuracy: 0.5891 - val_sensitivity_at_specificity: 0.6793 - val_specificity_at_sensitivity: 0.6125 - val_recall: 0.9650 - val_precision: 0.5580\n",
            "Epoch 310/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4274 - accuracy: 0.7863 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8419 - recall: 0.9837 - precision: 0.7068\n",
            "Epoch 310: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.4274 - accuracy: 0.7863 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8419 - recall: 0.9837 - precision: 0.7068 - val_loss: 0.7294 - val_accuracy: 0.5875 - val_sensitivity_at_specificity: 0.6548 - val_specificity_at_sensitivity: 0.6483 - val_recall: 0.9861 - val_precision: 0.5510\n",
            "Epoch 311/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4260 - accuracy: 0.7742 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8712 - recall: 0.9404 - precision: 0.6952\n",
            "Epoch 311: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 200ms/step - loss: 0.4260 - accuracy: 0.7742 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8712 - recall: 0.9404 - precision: 0.6952 - val_loss: 0.7260 - val_accuracy: 0.5750 - val_sensitivity_at_specificity: 0.7184 - val_specificity_at_sensitivity: 0.6571 - val_recall: 0.9693 - val_precision: 0.5329\n",
            "Epoch 312/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4011 - accuracy: 0.8043 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8684 - recall: 0.9826 - precision: 0.7212\n",
            "Epoch 312: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 198ms/step - loss: 0.4011 - accuracy: 0.8043 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8684 - recall: 0.9826 - precision: 0.7212 - val_loss: 0.6455 - val_accuracy: 0.6258 - val_sensitivity_at_specificity: 0.7558 - val_specificity_at_sensitivity: 0.7154 - val_recall: 0.9631 - val_precision: 0.5795\n",
            "Epoch 313/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4044 - accuracy: 0.7953 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8743 - recall: 0.9535 - precision: 0.7184\n",
            "Epoch 313: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.4044 - accuracy: 0.7953 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8743 - recall: 0.9535 - precision: 0.7184 - val_loss: 0.7313 - val_accuracy: 0.5867 - val_sensitivity_at_specificity: 0.7573 - val_specificity_at_sensitivity: 0.6742 - val_recall: 0.9772 - val_precision: 0.5381\n",
            "Epoch 314/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4134 - accuracy: 0.7934 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8921 - recall: 0.9672 - precision: 0.7178\n",
            "Epoch 314: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.4134 - accuracy: 0.7934 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8921 - recall: 0.9672 - precision: 0.7178 - val_loss: 0.6704 - val_accuracy: 0.5969 - val_sensitivity_at_specificity: 0.7605 - val_specificity_at_sensitivity: 0.6903 - val_recall: 0.9757 - val_precision: 0.5462\n",
            "Epoch 315/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4152 - accuracy: 0.7984 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8577 - recall: 0.9896 - precision: 0.7260\n",
            "Epoch 315: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 187ms/step - loss: 0.4152 - accuracy: 0.7984 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8577 - recall: 0.9896 - precision: 0.7260 - val_loss: 0.6795 - val_accuracy: 0.6070 - val_sensitivity_at_specificity: 0.7682 - val_specificity_at_sensitivity: 0.6619 - val_recall: 0.9861 - val_precision: 0.5636\n",
            "Epoch 316/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4086 - accuracy: 0.8047 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8684 - recall: 0.9846 - precision: 0.7271\n",
            "Epoch 316: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.4086 - accuracy: 0.8047 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8684 - recall: 0.9846 - precision: 0.7271 - val_loss: 0.6520 - val_accuracy: 0.6180 - val_sensitivity_at_specificity: 0.7368 - val_specificity_at_sensitivity: 0.6947 - val_recall: 0.9743 - val_precision: 0.5771\n",
            "Epoch 317/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4019 - accuracy: 0.8020 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8897 - recall: 0.9733 - precision: 0.7297\n",
            "Epoch 317: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.4019 - accuracy: 0.8020 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8897 - recall: 0.9733 - precision: 0.7297 - val_loss: 0.7183 - val_accuracy: 0.6133 - val_sensitivity_at_specificity: 0.7595 - val_specificity_at_sensitivity: 0.6613 - val_recall: 0.9650 - val_precision: 0.5732\n",
            "Epoch 318/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3959 - accuracy: 0.8020 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8851 - recall: 0.9533 - precision: 0.7288\n",
            "Epoch 318: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.3959 - accuracy: 0.8020 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8851 - recall: 0.9533 - precision: 0.7288 - val_loss: 0.8023 - val_accuracy: 0.5633 - val_sensitivity_at_specificity: 0.6443 - val_specificity_at_sensitivity: 0.6096 - val_recall: 0.9664 - val_precision: 0.5166\n",
            "Epoch 319/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4408 - accuracy: 0.7680 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8486 - recall: 0.9278 - precision: 0.6964\n",
            "Epoch 319: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.4408 - accuracy: 0.7680 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8486 - recall: 0.9278 - precision: 0.6964 - val_loss: 0.6466 - val_accuracy: 0.6070 - val_sensitivity_at_specificity: 0.7326 - val_specificity_at_sensitivity: 0.6873 - val_recall: 0.8522 - val_precision: 0.5534\n",
            "Epoch 320/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4167 - accuracy: 0.7953 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8657 - recall: 0.9762 - precision: 0.7205\n",
            "Epoch 320: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.4167 - accuracy: 0.7953 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8657 - recall: 0.9762 - precision: 0.7205 - val_loss: 0.6638 - val_accuracy: 0.5891 - val_sensitivity_at_specificity: 0.7009 - val_specificity_at_sensitivity: 0.6740 - val_recall: 0.9486 - val_precision: 0.5526\n",
            "Epoch 321/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3965 - accuracy: 0.8082 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8903 - recall: 0.9714 - precision: 0.7345\n",
            "Epoch 321: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.3965 - accuracy: 0.8082 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8903 - recall: 0.9714 - precision: 0.7345 - val_loss: 0.8167 - val_accuracy: 0.5875 - val_sensitivity_at_specificity: 0.7508 - val_specificity_at_sensitivity: 0.6661 - val_recall: 0.9875 - val_precision: 0.5494\n",
            "Epoch 322/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4030 - accuracy: 0.8059 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8851 - recall: 0.9638 - precision: 0.7354\n",
            "Epoch 322: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.4030 - accuracy: 0.8059 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8851 - recall: 0.9638 - precision: 0.7354 - val_loss: 0.6712 - val_accuracy: 0.6055 - val_sensitivity_at_specificity: 0.7070 - val_specificity_at_sensitivity: 0.6887 - val_recall: 0.9029 - val_precision: 0.5608\n",
            "Epoch 323/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4230 - accuracy: 0.7878 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8686 - recall: 0.9469 - precision: 0.7258\n",
            "Epoch 323: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.4230 - accuracy: 0.7878 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8686 - recall: 0.9469 - precision: 0.7258 - val_loss: 0.7158 - val_accuracy: 0.5992 - val_sensitivity_at_specificity: 0.6739 - val_specificity_at_sensitivity: 0.6291 - val_recall: 0.9735 - val_precision: 0.5571\n",
            "Epoch 324/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4040 - accuracy: 0.8012 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8761 - recall: 0.9864 - precision: 0.7153\n",
            "Epoch 324: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.4040 - accuracy: 0.8012 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8761 - recall: 0.9864 - precision: 0.7153 - val_loss: 0.6784 - val_accuracy: 0.5891 - val_sensitivity_at_specificity: 0.6825 - val_specificity_at_sensitivity: 0.6368 - val_recall: 0.9763 - val_precision: 0.5474\n",
            "Epoch 325/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4250 - accuracy: 0.7836 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8703 - recall: 0.9722 - precision: 0.7087\n",
            "Epoch 325: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.4250 - accuracy: 0.7836 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8703 - recall: 0.9722 - precision: 0.7087 - val_loss: 0.7109 - val_accuracy: 0.5867 - val_sensitivity_at_specificity: 0.7276 - val_specificity_at_sensitivity: 0.6905 - val_recall: 0.9792 - val_precision: 0.5421\n",
            "Epoch 326/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4360 - accuracy: 0.7805 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8421 - recall: 0.9813 - precision: 0.7003\n",
            "Epoch 326: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.4360 - accuracy: 0.7805 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8421 - recall: 0.9813 - precision: 0.7003 - val_loss: 0.6767 - val_accuracy: 0.6094 - val_sensitivity_at_specificity: 0.6197 - val_specificity_at_sensitivity: 0.6210 - val_recall: 0.9879 - val_precision: 0.5699\n",
            "Epoch 327/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4114 - accuracy: 0.7973 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8496 - recall: 0.9693 - precision: 0.7250\n",
            "Epoch 327: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.4114 - accuracy: 0.7973 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8496 - recall: 0.9693 - precision: 0.7250 - val_loss: 0.6939 - val_accuracy: 0.6156 - val_sensitivity_at_specificity: 0.6942 - val_specificity_at_sensitivity: 0.6629 - val_recall: 0.9709 - val_precision: 0.5731\n",
            "Epoch 328/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4130 - accuracy: 0.7930 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8601 - recall: 0.9635 - precision: 0.7148\n",
            "Epoch 328: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.4130 - accuracy: 0.7930 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8601 - recall: 0.9635 - precision: 0.7148 - val_loss: 0.6721 - val_accuracy: 0.6133 - val_sensitivity_at_specificity: 0.7037 - val_specificity_at_sensitivity: 0.6535 - val_recall: 0.8765 - val_precision: 0.5778\n",
            "Epoch 329/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4047 - accuracy: 0.7953 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8891 - recall: 0.9449 - precision: 0.7222\n",
            "Epoch 329: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.4047 - accuracy: 0.7953 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8891 - recall: 0.9449 - precision: 0.7222 - val_loss: 0.6878 - val_accuracy: 0.6109 - val_sensitivity_at_specificity: 0.7610 - val_specificity_at_sensitivity: 0.6972 - val_recall: 0.9670 - val_precision: 0.5632\n",
            "Epoch 330/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3876 - accuracy: 0.8109 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8986 - recall: 0.9575 - precision: 0.7466\n",
            "Epoch 330: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.3876 - accuracy: 0.8109 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8986 - recall: 0.9575 - precision: 0.7466 - val_loss: 0.7728 - val_accuracy: 0.5813 - val_sensitivity_at_specificity: 0.7097 - val_specificity_at_sensitivity: 0.6409 - val_recall: 0.9613 - val_precision: 0.5379\n",
            "Epoch 331/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3869 - accuracy: 0.8203 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8893 - recall: 0.9580 - precision: 0.7521\n",
            "Epoch 331: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.3869 - accuracy: 0.8203 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8893 - recall: 0.9580 - precision: 0.7521 - val_loss: 0.6815 - val_accuracy: 0.5969 - val_sensitivity_at_specificity: 0.7423 - val_specificity_at_sensitivity: 0.7166 - val_recall: 0.9201 - val_precision: 0.5470\n",
            "Epoch 332/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3995 - accuracy: 0.7992 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8942 - recall: 0.9435 - precision: 0.7311\n",
            "Epoch 332: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.3995 - accuracy: 0.7992 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8942 - recall: 0.9435 - precision: 0.7311 - val_loss: 0.6945 - val_accuracy: 0.6000 - val_sensitivity_at_specificity: 0.7250 - val_specificity_at_sensitivity: 0.6805 - val_recall: 0.9603 - val_precision: 0.5536\n",
            "Epoch 333/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3912 - accuracy: 0.8047 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9032 - recall: 0.9567 - precision: 0.7318\n",
            "Epoch 333: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.3912 - accuracy: 0.8047 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9032 - recall: 0.9567 - precision: 0.7318 - val_loss: 0.6794 - val_accuracy: 0.6148 - val_sensitivity_at_specificity: 0.7677 - val_specificity_at_sensitivity: 0.7190 - val_recall: 0.9662 - val_precision: 0.5714\n",
            "Epoch 334/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4203 - accuracy: 0.7899 - sensitivity_at_specificity: 0.9983 - specificity_at_sensitivity: 0.8774 - recall: 0.9241 - precision: 0.7247\n",
            "Epoch 334: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.4203 - accuracy: 0.7899 - sensitivity_at_specificity: 0.9983 - specificity_at_sensitivity: 0.8774 - recall: 0.9241 - precision: 0.7247 - val_loss: 0.7117 - val_accuracy: 0.6148 - val_sensitivity_at_specificity: 0.6614 - val_specificity_at_sensitivity: 0.6231 - val_recall: 0.9545 - val_precision: 0.5676\n",
            "Epoch 335/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4215 - accuracy: 0.7910 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8593 - recall: 0.9727 - precision: 0.7136\n",
            "Epoch 335: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.4215 - accuracy: 0.7910 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8593 - recall: 0.9727 - precision: 0.7136 - val_loss: 0.6764 - val_accuracy: 0.6148 - val_sensitivity_at_specificity: 0.7477 - val_specificity_at_sensitivity: 0.6877 - val_recall: 0.9350 - val_precision: 0.5725\n",
            "Epoch 336/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4138 - accuracy: 0.7937 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8614 - recall: 0.9550 - precision: 0.7239\n",
            "Epoch 336: val_accuracy did not improve from 0.63672\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.4138 - accuracy: 0.7937 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8614 - recall: 0.9550 - precision: 0.7239 - val_loss: 0.7257 - val_accuracy: 0.5992 - val_sensitivity_at_specificity: 0.7773 - val_specificity_at_sensitivity: 0.6971 - val_recall: 0.9858 - val_precision: 0.5532\n",
            "Epoch 337/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3923 - accuracy: 0.8004 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8965 - recall: 0.9652 - precision: 0.7283\n",
            "Epoch 337: val_accuracy improved from 0.63672 to 0.64453, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.3923 - accuracy: 0.8004 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8965 - recall: 0.9652 - precision: 0.7283 - val_loss: 0.6355 - val_accuracy: 0.6445 - val_sensitivity_at_specificity: 0.8075 - val_specificity_at_sensitivity: 0.7311 - val_recall: 0.9522 - val_precision: 0.6013\n",
            "Epoch 338/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4088 - accuracy: 0.7969 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8892 - recall: 0.9488 - precision: 0.7291\n",
            "Epoch 338: val_accuracy did not improve from 0.64453\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.4088 - accuracy: 0.7969 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8892 - recall: 0.9488 - precision: 0.7291 - val_loss: 0.6921 - val_accuracy: 0.6016 - val_sensitivity_at_specificity: 0.7464 - val_specificity_at_sensitivity: 0.7014 - val_recall: 0.9537 - val_precision: 0.5542\n",
            "Epoch 339/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3881 - accuracy: 0.8078 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8935 - recall: 0.9621 - precision: 0.7372\n",
            "Epoch 339: val_accuracy did not improve from 0.64453\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.3881 - accuracy: 0.8078 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8935 - recall: 0.9621 - precision: 0.7372 - val_loss: 0.6619 - val_accuracy: 0.6445 - val_sensitivity_at_specificity: 0.7159 - val_specificity_at_sensitivity: 0.6785 - val_recall: 0.9206 - val_precision: 0.5888\n",
            "Epoch 340/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3961 - accuracy: 0.8102 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8824 - recall: 0.9498 - precision: 0.7417\n",
            "Epoch 340: val_accuracy did not improve from 0.64453\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.3961 - accuracy: 0.8102 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8824 - recall: 0.9498 - precision: 0.7417 - val_loss: 0.7543 - val_accuracy: 0.6023 - val_sensitivity_at_specificity: 0.7110 - val_specificity_at_sensitivity: 0.6430 - val_recall: 0.9607 - val_precision: 0.5680\n",
            "Epoch 341/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3865 - accuracy: 0.8160 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8884 - recall: 0.9745 - precision: 0.7425\n",
            "Epoch 341: val_accuracy did not improve from 0.64453\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.3865 - accuracy: 0.8160 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8884 - recall: 0.9745 - precision: 0.7425 - val_loss: 0.7058 - val_accuracy: 0.6109 - val_sensitivity_at_specificity: 0.7866 - val_specificity_at_sensitivity: 0.7025 - val_recall: 0.9650 - val_precision: 0.5601\n",
            "Epoch 342/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4161 - accuracy: 0.7883 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8707 - recall: 0.9239 - precision: 0.7232\n",
            "Epoch 342: val_accuracy did not improve from 0.64453\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.4161 - accuracy: 0.7883 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8707 - recall: 0.9239 - precision: 0.7232 - val_loss: 0.7136 - val_accuracy: 0.6117 - val_sensitivity_at_specificity: 0.6985 - val_specificity_at_sensitivity: 0.6323 - val_recall: 0.9333 - val_precision: 0.5762\n",
            "Epoch 343/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4143 - accuracy: 0.7910 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8775 - recall: 0.9699 - precision: 0.7169\n",
            "Epoch 343: val_accuracy did not improve from 0.64453\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.4143 - accuracy: 0.7910 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8775 - recall: 0.9699 - precision: 0.7169 - val_loss: 0.6847 - val_accuracy: 0.6187 - val_sensitivity_at_specificity: 0.7686 - val_specificity_at_sensitivity: 0.7159 - val_recall: 0.9467 - val_precision: 0.5786\n",
            "Epoch 344/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3948 - accuracy: 0.8086 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8936 - recall: 0.9470 - precision: 0.7421\n",
            "Epoch 344: val_accuracy did not improve from 0.64453\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.3948 - accuracy: 0.8086 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8936 - recall: 0.9470 - precision: 0.7421 - val_loss: 0.7232 - val_accuracy: 0.5922 - val_sensitivity_at_specificity: 0.7091 - val_specificity_at_sensitivity: 0.6528 - val_recall: 0.9110 - val_precision: 0.5515\n",
            "Epoch 345/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3992 - accuracy: 0.8043 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8885 - recall: 0.9272 - precision: 0.7437\n",
            "Epoch 345: val_accuracy did not improve from 0.64453\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.3992 - accuracy: 0.8043 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8885 - recall: 0.9272 - precision: 0.7437 - val_loss: 0.7087 - val_accuracy: 0.6125 - val_sensitivity_at_specificity: 0.7641 - val_specificity_at_sensitivity: 0.6734 - val_recall: 0.9469 - val_precision: 0.5674\n",
            "Epoch 346/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4075 - accuracy: 0.7980 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8863 - recall: 0.9598 - precision: 0.7319\n",
            "Epoch 346: val_accuracy did not improve from 0.64453\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.4075 - accuracy: 0.7980 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8863 - recall: 0.9598 - precision: 0.7319 - val_loss: 0.7500 - val_accuracy: 0.6055 - val_sensitivity_at_specificity: 0.6553 - val_specificity_at_sensitivity: 0.6274 - val_recall: 0.9410 - val_precision: 0.5648\n",
            "Epoch 347/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3985 - accuracy: 0.7961 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8920 - recall: 0.9130 - precision: 0.7369\n",
            "Epoch 347: val_accuracy did not improve from 0.64453\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.3985 - accuracy: 0.7961 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8920 - recall: 0.9130 - precision: 0.7369 - val_loss: 0.7522 - val_accuracy: 0.6102 - val_sensitivity_at_specificity: 0.7143 - val_specificity_at_sensitivity: 0.6563 - val_recall: 0.9435 - val_precision: 0.5648\n",
            "Epoch 348/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4023 - accuracy: 0.8051 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8813 - recall: 0.9522 - precision: 0.7385\n",
            "Epoch 348: val_accuracy did not improve from 0.64453\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.4023 - accuracy: 0.8051 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8813 - recall: 0.9522 - precision: 0.7385 - val_loss: 0.7042 - val_accuracy: 0.6258 - val_sensitivity_at_specificity: 0.7434 - val_specificity_at_sensitivity: 0.6746 - val_recall: 0.9258 - val_precision: 0.5816\n",
            "Epoch 349/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4167 - accuracy: 0.7824 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.8891 - recall: 0.9205 - precision: 0.7196\n",
            "Epoch 349: val_accuracy did not improve from 0.64453\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.4167 - accuracy: 0.7824 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.8891 - recall: 0.9205 - precision: 0.7196 - val_loss: 0.6827 - val_accuracy: 0.6258 - val_sensitivity_at_specificity: 0.7515 - val_specificity_at_sensitivity: 0.6907 - val_recall: 0.9314 - val_precision: 0.5847\n",
            "Epoch 350/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3953 - accuracy: 0.8027 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9038 - recall: 0.9383 - precision: 0.7383\n",
            "Epoch 350: val_accuracy did not improve from 0.64453\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.3953 - accuracy: 0.8027 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9038 - recall: 0.9383 - precision: 0.7383 - val_loss: 0.6870 - val_accuracy: 0.6266 - val_sensitivity_at_specificity: 0.7480 - val_specificity_at_sensitivity: 0.7270 - val_recall: 0.9311 - val_precision: 0.5782\n",
            "Epoch 351/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4064 - accuracy: 0.7949 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.8931 - recall: 0.9441 - precision: 0.7252\n",
            "Epoch 351: val_accuracy did not improve from 0.64453\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.4064 - accuracy: 0.7949 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.8931 - recall: 0.9441 - precision: 0.7252 - val_loss: 0.6525 - val_accuracy: 0.6336 - val_sensitivity_at_specificity: 0.7790 - val_specificity_at_sensitivity: 0.7523 - val_recall: 0.9467 - val_precision: 0.5813\n",
            "Epoch 352/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4008 - accuracy: 0.7996 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8916 - recall: 0.9409 - precision: 0.7348\n",
            "Epoch 352: val_accuracy did not improve from 0.64453\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.4008 - accuracy: 0.7996 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8916 - recall: 0.9409 - precision: 0.7348 - val_loss: 0.7528 - val_accuracy: 0.6008 - val_sensitivity_at_specificity: 0.6579 - val_specificity_at_sensitivity: 0.6577 - val_recall: 0.9164 - val_precision: 0.5643\n",
            "Epoch 353/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3888 - accuracy: 0.8094 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9029 - recall: 0.9324 - precision: 0.7414\n",
            "Epoch 353: val_accuracy did not improve from 0.64453\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.3888 - accuracy: 0.8094 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9029 - recall: 0.9324 - precision: 0.7414 - val_loss: 0.6992 - val_accuracy: 0.6117 - val_sensitivity_at_specificity: 0.7650 - val_specificity_at_sensitivity: 0.7307 - val_recall: 0.9495 - val_precision: 0.5642\n",
            "Epoch 354/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3934 - accuracy: 0.8008 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8826 - recall: 0.9682 - precision: 0.7214\n",
            "Epoch 354: val_accuracy did not improve from 0.64453\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.3934 - accuracy: 0.8008 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8826 - recall: 0.9682 - precision: 0.7214 - val_loss: 0.7085 - val_accuracy: 0.6227 - val_sensitivity_at_specificity: 0.7407 - val_specificity_at_sensitivity: 0.6804 - val_recall: 0.9213 - val_precision: 0.5802\n",
            "Epoch 355/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3817 - accuracy: 0.8129 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9016 - recall: 0.9187 - precision: 0.7581\n",
            "Epoch 355: val_accuracy did not improve from 0.64453\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.3817 - accuracy: 0.8129 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9016 - recall: 0.9187 - precision: 0.7581 - val_loss: 0.8750 - val_accuracy: 0.5875 - val_sensitivity_at_specificity: 0.7384 - val_specificity_at_sensitivity: 0.6423 - val_recall: 0.9759 - val_precision: 0.5424\n",
            "Epoch 356/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3980 - accuracy: 0.7961 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8870 - recall: 0.9384 - precision: 0.7250\n",
            "Epoch 356: val_accuracy did not improve from 0.64453\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.3980 - accuracy: 0.7961 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8870 - recall: 0.9384 - precision: 0.7250 - val_loss: 0.6894 - val_accuracy: 0.6039 - val_sensitivity_at_specificity: 0.7434 - val_specificity_at_sensitivity: 0.6726 - val_recall: 0.8586 - val_precision: 0.5536\n",
            "Epoch 357/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3849 - accuracy: 0.8191 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8894 - recall: 0.9657 - precision: 0.7519\n",
            "Epoch 357: val_accuracy did not improve from 0.64453\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.3849 - accuracy: 0.8191 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8894 - recall: 0.9657 - precision: 0.7519 - val_loss: 0.7254 - val_accuracy: 0.6055 - val_sensitivity_at_specificity: 0.7372 - val_specificity_at_sensitivity: 0.7096 - val_recall: 0.8992 - val_precision: 0.5506\n",
            "Epoch 358/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3834 - accuracy: 0.8078 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9163 - recall: 0.9386 - precision: 0.7422\n",
            "Epoch 358: val_accuracy did not improve from 0.64453\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.3834 - accuracy: 0.8078 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9163 - recall: 0.9386 - precision: 0.7422 - val_loss: 0.7455 - val_accuracy: 0.6203 - val_sensitivity_at_specificity: 0.7219 - val_specificity_at_sensitivity: 0.6578 - val_recall: 0.9516 - val_precision: 0.5724\n",
            "Epoch 359/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4022 - accuracy: 0.7871 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8946 - recall: 0.8984 - precision: 0.7328\n",
            "Epoch 359: val_accuracy did not improve from 0.64453\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.4022 - accuracy: 0.7871 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8946 - recall: 0.8984 - precision: 0.7328 - val_loss: 0.8004 - val_accuracy: 0.5922 - val_sensitivity_at_specificity: 0.6641 - val_specificity_at_sensitivity: 0.6115 - val_recall: 0.9279 - val_precision: 0.5602\n",
            "Epoch 360/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4056 - accuracy: 0.7887 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8930 - recall: 0.9057 - precision: 0.7281\n",
            "Epoch 360: val_accuracy did not improve from 0.64453\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.4056 - accuracy: 0.7887 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8930 - recall: 0.9057 - precision: 0.7281 - val_loss: 0.6658 - val_accuracy: 0.6367 - val_sensitivity_at_specificity: 0.7808 - val_specificity_at_sensitivity: 0.6758 - val_recall: 0.9193 - val_precision: 0.5945\n",
            "Epoch 361/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4038 - accuracy: 0.8031 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8859 - recall: 0.9415 - precision: 0.7466\n",
            "Epoch 361: val_accuracy did not improve from 0.64453\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.4038 - accuracy: 0.8031 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8859 - recall: 0.9415 - precision: 0.7466 - val_loss: 0.7519 - val_accuracy: 0.6008 - val_sensitivity_at_specificity: 0.7096 - val_specificity_at_sensitivity: 0.6730 - val_recall: 0.9612 - val_precision: 0.5602\n",
            "Epoch 362/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3964 - accuracy: 0.8027 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9002 - recall: 0.9452 - precision: 0.7351\n",
            "Epoch 362: val_accuracy did not improve from 0.64453\n",
            "10/10 [==============================] - 2s 177ms/step - loss: 0.3964 - accuracy: 0.8027 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9002 - recall: 0.9452 - precision: 0.7351 - val_loss: 0.6802 - val_accuracy: 0.6313 - val_sensitivity_at_specificity: 0.7365 - val_specificity_at_sensitivity: 0.6650 - val_recall: 0.9386 - val_precision: 0.5926\n",
            "Epoch 363/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4046 - accuracy: 0.8031 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8557 - recall: 0.9612 - precision: 0.7359\n",
            "Epoch 363: val_accuracy did not improve from 0.64453\n",
            "10/10 [==============================] - 2s 185ms/step - loss: 0.4046 - accuracy: 0.8031 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8557 - recall: 0.9612 - precision: 0.7359 - val_loss: 0.7031 - val_accuracy: 0.6203 - val_sensitivity_at_specificity: 0.7722 - val_specificity_at_sensitivity: 0.6757 - val_recall: 0.9465 - val_precision: 0.5785\n",
            "Epoch 364/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3856 - accuracy: 0.8055 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9050 - recall: 0.9248 - precision: 0.7459\n",
            "Epoch 364: val_accuracy did not improve from 0.64453\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.3856 - accuracy: 0.8055 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9050 - recall: 0.9248 - precision: 0.7459 - val_loss: 0.7001 - val_accuracy: 0.6297 - val_sensitivity_at_specificity: 0.7713 - val_specificity_at_sensitivity: 0.6889 - val_recall: 0.9259 - val_precision: 0.5733\n",
            "Epoch 365/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3893 - accuracy: 0.8055 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8988 - recall: 0.9263 - precision: 0.7451\n",
            "Epoch 365: val_accuracy did not improve from 0.64453\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.3893 - accuracy: 0.8055 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8988 - recall: 0.9263 - precision: 0.7451 - val_loss: 0.7680 - val_accuracy: 0.5977 - val_sensitivity_at_specificity: 0.6667 - val_specificity_at_sensitivity: 0.6285 - val_recall: 0.9221 - val_precision: 0.5601\n",
            "Epoch 366/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3959 - accuracy: 0.7973 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9135 - recall: 0.9279 - precision: 0.7374\n",
            "Epoch 366: val_accuracy did not improve from 0.64453\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.3959 - accuracy: 0.7973 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9135 - recall: 0.9279 - precision: 0.7374 - val_loss: 0.7318 - val_accuracy: 0.6070 - val_sensitivity_at_specificity: 0.7276 - val_specificity_at_sensitivity: 0.6738 - val_recall: 0.9407 - val_precision: 0.5575\n",
            "Epoch 367/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3789 - accuracy: 0.8121 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9136 - recall: 0.9435 - precision: 0.7463\n",
            "Epoch 367: val_accuracy did not improve from 0.64453\n",
            "10/10 [==============================] - 2s 186ms/step - loss: 0.3789 - accuracy: 0.8121 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9136 - recall: 0.9435 - precision: 0.7463 - val_loss: 0.6975 - val_accuracy: 0.6297 - val_sensitivity_at_specificity: 0.7697 - val_specificity_at_sensitivity: 0.6888 - val_recall: 0.9614 - val_precision: 0.5808\n",
            "Epoch 368/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3782 - accuracy: 0.8105 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9058 - recall: 0.9411 - precision: 0.7509\n",
            "Epoch 368: val_accuracy did not improve from 0.64453\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.3782 - accuracy: 0.8105 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9058 - recall: 0.9411 - precision: 0.7509 - val_loss: 0.7444 - val_accuracy: 0.6242 - val_sensitivity_at_specificity: 0.7459 - val_specificity_at_sensitivity: 0.6943 - val_recall: 0.9444 - val_precision: 0.5858\n",
            "Epoch 369/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3995 - accuracy: 0.7994 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8946 - recall: 0.9173 - precision: 0.7458\n",
            "Epoch 369: val_accuracy did not improve from 0.64453\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.3995 - accuracy: 0.7994 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8946 - recall: 0.9173 - precision: 0.7458 - val_loss: 0.7360 - val_accuracy: 0.5867 - val_sensitivity_at_specificity: 0.7080 - val_specificity_at_sensitivity: 0.6972 - val_recall: 0.8809 - val_precision: 0.5422\n",
            "Epoch 370/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3682 - accuracy: 0.8164 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9254 - recall: 0.9387 - precision: 0.7530\n",
            "Epoch 370: val_accuracy did not improve from 0.64453\n",
            "10/10 [==============================] - 2s 186ms/step - loss: 0.3682 - accuracy: 0.8164 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9254 - recall: 0.9387 - precision: 0.7530 - val_loss: 0.7072 - val_accuracy: 0.6336 - val_sensitivity_at_specificity: 0.7631 - val_specificity_at_sensitivity: 0.6974 - val_recall: 0.9332 - val_precision: 0.5789\n",
            "Epoch 371/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4093 - accuracy: 0.7883 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8926 - recall: 0.9111 - precision: 0.7341\n",
            "Epoch 371: val_accuracy did not improve from 0.64453\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.4093 - accuracy: 0.7883 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8926 - recall: 0.9111 - precision: 0.7341 - val_loss: 0.7270 - val_accuracy: 0.6008 - val_sensitivity_at_specificity: 0.7778 - val_specificity_at_sensitivity: 0.7530 - val_recall: 0.9395 - val_precision: 0.5481\n",
            "Epoch 372/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3913 - accuracy: 0.8066 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9169 - recall: 0.9167 - precision: 0.7476\n",
            "Epoch 372: val_accuracy did not improve from 0.64453\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.3913 - accuracy: 0.8066 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9169 - recall: 0.9167 - precision: 0.7476 - val_loss: 0.7252 - val_accuracy: 0.6180 - val_sensitivity_at_specificity: 0.7423 - val_specificity_at_sensitivity: 0.6630 - val_recall: 0.9414 - val_precision: 0.5749\n",
            "Epoch 373/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3655 - accuracy: 0.8277 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9163 - recall: 0.9701 - precision: 0.7661\n",
            "Epoch 373: val_accuracy did not improve from 0.64453\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.3655 - accuracy: 0.8277 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9163 - recall: 0.9701 - precision: 0.7661 - val_loss: 0.7739 - val_accuracy: 0.6000 - val_sensitivity_at_specificity: 0.7480 - val_specificity_at_sensitivity: 0.6853 - val_recall: 0.9654 - val_precision: 0.5558\n",
            "Epoch 374/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4034 - accuracy: 0.7977 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9049 - recall: 0.9077 - precision: 0.7415\n",
            "Epoch 374: val_accuracy did not improve from 0.64453\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.4034 - accuracy: 0.7977 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9049 - recall: 0.9077 - precision: 0.7415 - val_loss: 0.7151 - val_accuracy: 0.6211 - val_sensitivity_at_specificity: 0.7393 - val_specificity_at_sensitivity: 0.6866 - val_recall: 0.9444 - val_precision: 0.5690\n",
            "Epoch 375/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3853 - accuracy: 0.8117 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9048 - recall: 0.9376 - precision: 0.7523\n",
            "Epoch 375: val_accuracy did not improve from 0.64453\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.3853 - accuracy: 0.8117 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9048 - recall: 0.9376 - precision: 0.7523 - val_loss: 0.7432 - val_accuracy: 0.5914 - val_sensitivity_at_specificity: 0.7631 - val_specificity_at_sensitivity: 0.6952 - val_recall: 0.9289 - val_precision: 0.5330\n",
            "Epoch 376/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3837 - accuracy: 0.8110 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9119 - recall: 0.9229 - precision: 0.7520\n",
            "Epoch 376: val_accuracy did not improve from 0.64453\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.3837 - accuracy: 0.8110 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9119 - recall: 0.9229 - precision: 0.7520 - val_loss: 0.7796 - val_accuracy: 0.6148 - val_sensitivity_at_specificity: 0.7096 - val_specificity_at_sensitivity: 0.6887 - val_recall: 0.9472 - val_precision: 0.5706\n",
            "Epoch 377/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3837 - accuracy: 0.8074 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9221 - recall: 0.9170 - precision: 0.7538\n",
            "Epoch 377: val_accuracy did not improve from 0.64453\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.3837 - accuracy: 0.8074 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9221 - recall: 0.9170 - precision: 0.7538 - val_loss: 0.7927 - val_accuracy: 0.5945 - val_sensitivity_at_specificity: 0.7013 - val_specificity_at_sensitivity: 0.6529 - val_recall: 0.9010 - val_precision: 0.5524\n",
            "Epoch 378/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3873 - accuracy: 0.8039 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9185 - recall: 0.9247 - precision: 0.7363\n",
            "Epoch 378: val_accuracy did not improve from 0.64453\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.3873 - accuracy: 0.8039 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9185 - recall: 0.9247 - precision: 0.7363 - val_loss: 0.6894 - val_accuracy: 0.6047 - val_sensitivity_at_specificity: 0.7835 - val_specificity_at_sensitivity: 0.7307 - val_recall: 0.9160 - val_precision: 0.5553\n",
            "Epoch 379/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3913 - accuracy: 0.8156 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9003 - recall: 0.9401 - precision: 0.7537\n",
            "Epoch 379: val_accuracy did not improve from 0.64453\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.3913 - accuracy: 0.8156 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9003 - recall: 0.9401 - precision: 0.7537 - val_loss: 0.7273 - val_accuracy: 0.6016 - val_sensitivity_at_specificity: 0.7090 - val_specificity_at_sensitivity: 0.6767 - val_recall: 0.9443 - val_precision: 0.5627\n",
            "Epoch 380/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3948 - accuracy: 0.8020 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9079 - recall: 0.8999 - precision: 0.7523\n",
            "Epoch 380: val_accuracy did not improve from 0.64453\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.3948 - accuracy: 0.8020 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9079 - recall: 0.8999 - precision: 0.7523 - val_loss: 0.7895 - val_accuracy: 0.6086 - val_sensitivity_at_specificity: 0.7154 - val_specificity_at_sensitivity: 0.6593 - val_recall: 0.9689 - val_precision: 0.5643\n",
            "Epoch 381/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3761 - accuracy: 0.8195 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9036 - recall: 0.9560 - precision: 0.7535\n",
            "Epoch 381: val_accuracy did not improve from 0.64453\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.3761 - accuracy: 0.8195 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9036 - recall: 0.9560 - precision: 0.7535 - val_loss: 0.6893 - val_accuracy: 0.6219 - val_sensitivity_at_specificity: 0.7864 - val_specificity_at_sensitivity: 0.7083 - val_recall: 0.9367 - val_precision: 0.5714\n",
            "Epoch 382/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3961 - accuracy: 0.8004 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8973 - recall: 0.9533 - precision: 0.7309\n",
            "Epoch 382: val_accuracy did not improve from 0.64453\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.3961 - accuracy: 0.8004 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.8973 - recall: 0.9533 - precision: 0.7309 - val_loss: 0.7483 - val_accuracy: 0.6086 - val_sensitivity_at_specificity: 0.7063 - val_specificity_at_sensitivity: 0.6641 - val_recall: 0.9234 - val_precision: 0.5666\n",
            "Epoch 383/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3617 - accuracy: 0.8152 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9488 - recall: 0.9134 - precision: 0.7617\n",
            "Epoch 383: val_accuracy did not improve from 0.64453\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.3617 - accuracy: 0.8152 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9488 - recall: 0.9134 - precision: 0.7617 - val_loss: 0.8442 - val_accuracy: 0.6023 - val_sensitivity_at_specificity: 0.7340 - val_specificity_at_sensitivity: 0.6802 - val_recall: 0.9218 - val_precision: 0.5620\n",
            "Epoch 384/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3796 - accuracy: 0.8133 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9054 - recall: 0.9345 - precision: 0.7579\n",
            "Epoch 384: val_accuracy did not improve from 0.64453\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.3796 - accuracy: 0.8133 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9054 - recall: 0.9345 - precision: 0.7579 - val_loss: 0.7061 - val_accuracy: 0.6250 - val_sensitivity_at_specificity: 0.7954 - val_specificity_at_sensitivity: 0.7159 - val_recall: 0.9308 - val_precision: 0.5817\n",
            "Epoch 385/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3954 - accuracy: 0.7949 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9102 - recall: 0.8872 - precision: 0.7465\n",
            "Epoch 385: val_accuracy did not improve from 0.64453\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.3954 - accuracy: 0.7949 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9102 - recall: 0.8872 - precision: 0.7465 - val_loss: 0.7783 - val_accuracy: 0.6047 - val_sensitivity_at_specificity: 0.7221 - val_specificity_at_sensitivity: 0.6656 - val_recall: 0.9451 - val_precision: 0.5610\n",
            "Epoch 386/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3709 - accuracy: 0.8141 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9290 - recall: 0.9357 - precision: 0.7571\n",
            "Epoch 386: val_accuracy did not improve from 0.64453\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.3709 - accuracy: 0.8141 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9290 - recall: 0.9357 - precision: 0.7571 - val_loss: 0.7426 - val_accuracy: 0.6398 - val_sensitivity_at_specificity: 0.7785 - val_specificity_at_sensitivity: 0.7121 - val_recall: 0.9220 - val_precision: 0.5898\n",
            "Epoch 387/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3743 - accuracy: 0.8070 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9275 - recall: 0.8923 - precision: 0.7589\n",
            "Epoch 387: val_accuracy did not improve from 0.64453\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.3743 - accuracy: 0.8070 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9275 - recall: 0.8923 - precision: 0.7589 - val_loss: 0.7297 - val_accuracy: 0.6430 - val_sensitivity_at_specificity: 0.7682 - val_specificity_at_sensitivity: 0.6839 - val_recall: 0.9121 - val_precision: 0.6014\n",
            "Epoch 388/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3690 - accuracy: 0.8227 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9214 - recall: 0.9216 - precision: 0.7730\n",
            "Epoch 388: val_accuracy did not improve from 0.64453\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.3690 - accuracy: 0.8227 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9214 - recall: 0.9216 - precision: 0.7730 - val_loss: 0.7610 - val_accuracy: 0.6070 - val_sensitivity_at_specificity: 0.7571 - val_specificity_at_sensitivity: 0.6935 - val_recall: 0.9322 - val_precision: 0.5623\n",
            "Epoch 389/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3715 - accuracy: 0.8129 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9154 - recall: 0.9167 - precision: 0.7485\n",
            "Epoch 389: val_accuracy did not improve from 0.64453\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.3715 - accuracy: 0.8129 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9154 - recall: 0.9167 - precision: 0.7485 - val_loss: 0.7728 - val_accuracy: 0.6070 - val_sensitivity_at_specificity: 0.7709 - val_specificity_at_sensitivity: 0.6955 - val_recall: 0.9115 - val_precision: 0.5635\n",
            "Epoch 390/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3836 - accuracy: 0.8062 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9174 - recall: 0.9169 - precision: 0.7500\n",
            "Epoch 390: val_accuracy did not improve from 0.64453\n",
            "10/10 [==============================] - 2s 190ms/step - loss: 0.3836 - accuracy: 0.8062 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9174 - recall: 0.9169 - precision: 0.7500 - val_loss: 0.7680 - val_accuracy: 0.6094 - val_sensitivity_at_specificity: 0.7310 - val_specificity_at_sensitivity: 0.6836 - val_recall: 0.9082 - val_precision: 0.5650\n",
            "Epoch 391/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.3813 - accuracy: 0.8108 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9140 - recall: 0.9097 - precision: 0.7548\n",
            "Epoch 391: val_accuracy did not improve from 0.64453\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.3835 - accuracy: 0.8086 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9142 - recall: 0.9105 - precision: 0.7523 - val_loss: 0.7275 - val_accuracy: 0.6258 - val_sensitivity_at_specificity: 0.7763 - val_specificity_at_sensitivity: 0.7014 - val_recall: 0.9498 - val_precision: 0.5667\n",
            "Epoch 392/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3900 - accuracy: 0.8023 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9153 - recall: 0.9128 - precision: 0.7500\n",
            "Epoch 392: val_accuracy did not improve from 0.64453\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.3900 - accuracy: 0.8023 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9153 - recall: 0.9128 - precision: 0.7500 - val_loss: 0.7855 - val_accuracy: 0.5844 - val_sensitivity_at_specificity: 0.6814 - val_specificity_at_sensitivity: 0.6095 - val_recall: 0.9228 - val_precision: 0.5368\n",
            "Epoch 393/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3784 - accuracy: 0.8094 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9179 - recall: 0.9002 - precision: 0.7643\n",
            "Epoch 393: val_accuracy improved from 0.64453 to 0.65000, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.3784 - accuracy: 0.8094 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9179 - recall: 0.9002 - precision: 0.7643 - val_loss: 0.7095 - val_accuracy: 0.6500 - val_sensitivity_at_specificity: 0.8033 - val_specificity_at_sensitivity: 0.7028 - val_recall: 0.9031 - val_precision: 0.6127\n",
            "Epoch 394/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3677 - accuracy: 0.8215 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9262 - recall: 0.9270 - precision: 0.7667\n",
            "Epoch 394: val_accuracy did not improve from 0.65000\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.3677 - accuracy: 0.8215 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9262 - recall: 0.9270 - precision: 0.7667 - val_loss: 0.7884 - val_accuracy: 0.6000 - val_sensitivity_at_specificity: 0.7492 - val_specificity_at_sensitivity: 0.6757 - val_recall: 0.9358 - val_precision: 0.5656\n",
            "Epoch 395/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3672 - accuracy: 0.8223 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9223 - recall: 0.9367 - precision: 0.7675\n",
            "Epoch 395: val_accuracy did not improve from 0.65000\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.3672 - accuracy: 0.8223 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9223 - recall: 0.9367 - precision: 0.7675 - val_loss: 0.8141 - val_accuracy: 0.6062 - val_sensitivity_at_specificity: 0.7571 - val_specificity_at_sensitivity: 0.6542 - val_recall: 0.9498 - val_precision: 0.5622\n",
            "Epoch 396/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3822 - accuracy: 0.8008 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9291 - recall: 0.9000 - precision: 0.7529\n",
            "Epoch 396: val_accuracy did not improve from 0.65000\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.3822 - accuracy: 0.8008 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9291 - recall: 0.9000 - precision: 0.7529 - val_loss: 0.7743 - val_accuracy: 0.6133 - val_sensitivity_at_specificity: 0.7339 - val_specificity_at_sensitivity: 0.6821 - val_recall: 0.8899 - val_precision: 0.5791\n",
            "Epoch 397/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3897 - accuracy: 0.8023 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9127 - recall: 0.9099 - precision: 0.7482\n",
            "Epoch 397: val_accuracy did not improve from 0.65000\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.3897 - accuracy: 0.8023 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9127 - recall: 0.9099 - precision: 0.7482 - val_loss: 0.7028 - val_accuracy: 0.6086 - val_sensitivity_at_specificity: 0.7434 - val_specificity_at_sensitivity: 0.7098 - val_recall: 0.8454 - val_precision: 0.5581\n",
            "Epoch 398/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3637 - accuracy: 0.8223 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9181 - recall: 0.9344 - precision: 0.7608\n",
            "Epoch 398: val_accuracy did not improve from 0.65000\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.3637 - accuracy: 0.8223 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9181 - recall: 0.9344 - precision: 0.7608 - val_loss: 0.7542 - val_accuracy: 0.6172 - val_sensitivity_at_specificity: 0.7629 - val_specificity_at_sensitivity: 0.7058 - val_recall: 0.9158 - val_precision: 0.5738\n",
            "Epoch 399/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3769 - accuracy: 0.8055 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9320 - recall: 0.9055 - precision: 0.7546\n",
            "Epoch 399: val_accuracy did not improve from 0.65000\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.3769 - accuracy: 0.8055 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9320 - recall: 0.9055 - precision: 0.7546 - val_loss: 0.7584 - val_accuracy: 0.6141 - val_sensitivity_at_specificity: 0.7280 - val_specificity_at_sensitivity: 0.6626 - val_recall: 0.9136 - val_precision: 0.5648\n",
            "Epoch 400/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3689 - accuracy: 0.8206 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9271 - recall: 0.9201 - precision: 0.7693\n",
            "Epoch 400: val_accuracy did not improve from 0.65000\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.3689 - accuracy: 0.8206 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9271 - recall: 0.9201 - precision: 0.7693 - val_loss: 0.7631 - val_accuracy: 0.6062 - val_sensitivity_at_specificity: 0.7748 - val_specificity_at_sensitivity: 0.7201 - val_recall: 0.9550 - val_precision: 0.5642\n",
            "Epoch 401/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3865 - accuracy: 0.8105 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9021 - recall: 0.9348 - precision: 0.7529\n",
            "Epoch 401: val_accuracy did not improve from 0.65000\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.3865 - accuracy: 0.8105 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9021 - recall: 0.9348 - precision: 0.7529 - val_loss: 0.6943 - val_accuracy: 0.6336 - val_sensitivity_at_specificity: 0.7966 - val_specificity_at_sensitivity: 0.6989 - val_recall: 0.9230 - val_precision: 0.5884\n",
            "Epoch 402/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3742 - accuracy: 0.8133 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9310 - recall: 0.9291 - precision: 0.7500\n",
            "Epoch 402: val_accuracy did not improve from 0.65000\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.3742 - accuracy: 0.8133 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9310 - recall: 0.9291 - precision: 0.7500 - val_loss: 0.7408 - val_accuracy: 0.6109 - val_sensitivity_at_specificity: 0.7492 - val_specificity_at_sensitivity: 0.6888 - val_recall: 0.9175 - val_precision: 0.5592\n",
            "Epoch 403/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3730 - accuracy: 0.8082 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9385 - recall: 0.8905 - precision: 0.7570\n",
            "Epoch 403: val_accuracy did not improve from 0.65000\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.3730 - accuracy: 0.8082 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9385 - recall: 0.8905 - precision: 0.7570 - val_loss: 0.7126 - val_accuracy: 0.6344 - val_sensitivity_at_specificity: 0.7539 - val_specificity_at_sensitivity: 0.6682 - val_recall: 0.9107 - val_precision: 0.5857\n",
            "Epoch 404/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3700 - accuracy: 0.8113 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9414 - recall: 0.9192 - precision: 0.7529\n",
            "Epoch 404: val_accuracy did not improve from 0.65000\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.3700 - accuracy: 0.8113 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9414 - recall: 0.9192 - precision: 0.7529 - val_loss: 0.7524 - val_accuracy: 0.6133 - val_sensitivity_at_specificity: 0.7686 - val_specificity_at_sensitivity: 0.6949 - val_recall: 0.9477 - val_precision: 0.5642\n",
            "Epoch 405/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3816 - accuracy: 0.8121 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9207 - recall: 0.9089 - precision: 0.7603\n",
            "Epoch 405: val_accuracy did not improve from 0.65000\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.3816 - accuracy: 0.8121 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9207 - recall: 0.9089 - precision: 0.7603 - val_loss: 0.7609 - val_accuracy: 0.6047 - val_sensitivity_at_specificity: 0.7268 - val_specificity_at_sensitivity: 0.6834 - val_recall: 0.9123 - val_precision: 0.5488\n",
            "Epoch 406/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3957 - accuracy: 0.7937 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9264 - recall: 0.8910 - precision: 0.7354\n",
            "Epoch 406: val_accuracy improved from 0.65000 to 0.65469, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 174ms/step - loss: 0.3957 - accuracy: 0.7937 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9264 - recall: 0.8910 - precision: 0.7354 - val_loss: 0.6793 - val_accuracy: 0.6547 - val_sensitivity_at_specificity: 0.7951 - val_specificity_at_sensitivity: 0.7359 - val_recall: 0.8589 - val_precision: 0.6186\n",
            "Epoch 407/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3580 - accuracy: 0.8207 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9343 - recall: 0.9098 - precision: 0.7753\n",
            "Epoch 407: val_accuracy did not improve from 0.65469\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.3580 - accuracy: 0.8207 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9343 - recall: 0.9098 - precision: 0.7753 - val_loss: 0.7352 - val_accuracy: 0.6148 - val_sensitivity_at_specificity: 0.7429 - val_specificity_at_sensitivity: 0.7074 - val_recall: 0.9164 - val_precision: 0.5690\n",
            "Epoch 408/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3755 - accuracy: 0.8113 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9314 - recall: 0.9181 - precision: 0.7614\n",
            "Epoch 408: val_accuracy did not improve from 0.65469\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.3755 - accuracy: 0.8113 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9314 - recall: 0.9181 - precision: 0.7614 - val_loss: 0.7549 - val_accuracy: 0.6195 - val_sensitivity_at_specificity: 0.7315 - val_specificity_at_sensitivity: 0.7041 - val_recall: 0.9074 - val_precision: 0.5793\n",
            "Epoch 409/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3671 - accuracy: 0.8121 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9405 - recall: 0.9022 - precision: 0.7680\n",
            "Epoch 409: val_accuracy did not improve from 0.65469\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.3671 - accuracy: 0.8121 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9405 - recall: 0.9022 - precision: 0.7680 - val_loss: 0.7954 - val_accuracy: 0.6031 - val_sensitivity_at_specificity: 0.7284 - val_specificity_at_sensitivity: 0.6713 - val_recall: 0.9169 - val_precision: 0.5573\n",
            "Epoch 410/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3592 - accuracy: 0.8234 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9368 - recall: 0.9238 - precision: 0.7633\n",
            "Epoch 410: val_accuracy did not improve from 0.65469\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.3592 - accuracy: 0.8234 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9368 - recall: 0.9238 - precision: 0.7633 - val_loss: 0.7762 - val_accuracy: 0.6328 - val_sensitivity_at_specificity: 0.7735 - val_specificity_at_sensitivity: 0.6878 - val_recall: 0.9307 - val_precision: 0.5870\n",
            "Epoch 411/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3886 - accuracy: 0.7980 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9200 - recall: 0.8902 - precision: 0.7451\n",
            "Epoch 411: val_accuracy did not improve from 0.65469\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.3886 - accuracy: 0.7980 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9200 - recall: 0.8902 - precision: 0.7451 - val_loss: 0.7057 - val_accuracy: 0.6406 - val_sensitivity_at_specificity: 0.7607 - val_specificity_at_sensitivity: 0.7463 - val_recall: 0.8863 - val_precision: 0.6104\n",
            "Epoch 412/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3597 - accuracy: 0.8160 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9443 - recall: 0.9132 - precision: 0.7623\n",
            "Epoch 412: val_accuracy did not improve from 0.65469\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.3597 - accuracy: 0.8160 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9443 - recall: 0.9132 - precision: 0.7623 - val_loss: 0.7318 - val_accuracy: 0.6445 - val_sensitivity_at_specificity: 0.7743 - val_specificity_at_sensitivity: 0.7093 - val_recall: 0.9335 - val_precision: 0.5945\n",
            "Epoch 413/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3883 - accuracy: 0.8020 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9252 - recall: 0.9023 - precision: 0.7534\n",
            "Epoch 413: val_accuracy did not improve from 0.65469\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.3883 - accuracy: 0.8020 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9252 - recall: 0.9023 - precision: 0.7534 - val_loss: 0.7267 - val_accuracy: 0.6406 - val_sensitivity_at_specificity: 0.7786 - val_specificity_at_sensitivity: 0.7240 - val_recall: 0.9071 - val_precision: 0.5943\n",
            "Epoch 414/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3646 - accuracy: 0.8199 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9327 - recall: 0.9186 - precision: 0.7623\n",
            "Epoch 414: val_accuracy did not improve from 0.65469\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.3646 - accuracy: 0.8199 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9327 - recall: 0.9186 - precision: 0.7623 - val_loss: 0.7056 - val_accuracy: 0.6391 - val_sensitivity_at_specificity: 0.7455 - val_specificity_at_sensitivity: 0.6879 - val_recall: 0.8862 - val_precision: 0.6053\n",
            "Epoch 415/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3822 - accuracy: 0.8043 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9184 - recall: 0.8806 - precision: 0.7626\n",
            "Epoch 415: val_accuracy did not improve from 0.65469\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.3822 - accuracy: 0.8043 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9184 - recall: 0.8806 - precision: 0.7626 - val_loss: 0.7454 - val_accuracy: 0.6352 - val_sensitivity_at_specificity: 0.7515 - val_specificity_at_sensitivity: 0.7141 - val_recall: 0.9072 - val_precision: 0.5994\n",
            "Epoch 416/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3829 - accuracy: 0.8074 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9094 - recall: 0.9279 - precision: 0.7495\n",
            "Epoch 416: val_accuracy did not improve from 0.65469\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.3829 - accuracy: 0.8074 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9094 - recall: 0.9279 - precision: 0.7495 - val_loss: 0.7699 - val_accuracy: 0.6500 - val_sensitivity_at_specificity: 0.7763 - val_specificity_at_sensitivity: 0.6934 - val_recall: 0.9635 - val_precision: 0.5989\n",
            "Epoch 417/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3661 - accuracy: 0.8164 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9329 - recall: 0.9163 - precision: 0.7634\n",
            "Epoch 417: val_accuracy did not improve from 0.65469\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.3661 - accuracy: 0.8164 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9329 - recall: 0.9163 - precision: 0.7634 - val_loss: 0.8371 - val_accuracy: 0.6039 - val_sensitivity_at_specificity: 0.6808 - val_specificity_at_sensitivity: 0.6862 - val_recall: 0.8893 - val_precision: 0.5543\n",
            "Epoch 418/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3641 - accuracy: 0.8219 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9387 - recall: 0.9001 - precision: 0.7859\n",
            "Epoch 418: val_accuracy did not improve from 0.65469\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.3641 - accuracy: 0.8219 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9387 - recall: 0.9001 - precision: 0.7859 - val_loss: 0.8147 - val_accuracy: 0.6117 - val_sensitivity_at_specificity: 0.7508 - val_specificity_at_sensitivity: 0.6796 - val_recall: 0.9558 - val_precision: 0.5637\n",
            "Epoch 419/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3885 - accuracy: 0.8035 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9194 - recall: 0.9330 - precision: 0.7391\n",
            "Epoch 419: val_accuracy did not improve from 0.65469\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.3885 - accuracy: 0.8035 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9194 - recall: 0.9330 - precision: 0.7391 - val_loss: 0.7362 - val_accuracy: 0.6289 - val_sensitivity_at_specificity: 0.7461 - val_specificity_at_sensitivity: 0.6610 - val_recall: 0.9401 - val_precision: 0.5770\n",
            "Epoch 420/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3832 - accuracy: 0.8070 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9181 - recall: 0.9053 - precision: 0.7562\n",
            "Epoch 420: val_accuracy did not improve from 0.65469\n",
            "10/10 [==============================] - 2s 175ms/step - loss: 0.3832 - accuracy: 0.8070 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9181 - recall: 0.9053 - precision: 0.7562 - val_loss: 0.7991 - val_accuracy: 0.6219 - val_sensitivity_at_specificity: 0.7188 - val_specificity_at_sensitivity: 0.6687 - val_recall: 0.9375 - val_precision: 0.5747\n",
            "Epoch 421/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3775 - accuracy: 0.8004 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9201 - recall: 0.8668 - precision: 0.7579\n",
            "Epoch 421: val_accuracy did not improve from 0.65469\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.3775 - accuracy: 0.8004 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9201 - recall: 0.8668 - precision: 0.7579 - val_loss: 0.7871 - val_accuracy: 0.6070 - val_sensitivity_at_specificity: 0.7055 - val_specificity_at_sensitivity: 0.7115 - val_recall: 0.9142 - val_precision: 0.5567\n",
            "Epoch 422/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3683 - accuracy: 0.8141 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9216 - recall: 0.9182 - precision: 0.7583\n",
            "Epoch 422: val_accuracy did not improve from 0.65469\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.3683 - accuracy: 0.8141 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9216 - recall: 0.9182 - precision: 0.7583 - val_loss: 0.6998 - val_accuracy: 0.6281 - val_sensitivity_at_specificity: 0.7560 - val_specificity_at_sensitivity: 0.6986 - val_recall: 0.9262 - val_precision: 0.5730\n",
            "Epoch 423/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3743 - accuracy: 0.8160 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9274 - recall: 0.9319 - precision: 0.7587\n",
            "Epoch 423: val_accuracy did not improve from 0.65469\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.3743 - accuracy: 0.8160 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9274 - recall: 0.9319 - precision: 0.7587 - val_loss: 0.7429 - val_accuracy: 0.6430 - val_sensitivity_at_specificity: 0.7615 - val_specificity_at_sensitivity: 0.7093 - val_recall: 0.9190 - val_precision: 0.5980\n",
            "Epoch 424/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3545 - accuracy: 0.8277 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9367 - recall: 0.9234 - precision: 0.7751\n",
            "Epoch 424: val_accuracy did not improve from 0.65469\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.3545 - accuracy: 0.8277 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9367 - recall: 0.9234 - precision: 0.7751 - val_loss: 0.8456 - val_accuracy: 0.6094 - val_sensitivity_at_specificity: 0.6770 - val_specificity_at_sensitivity: 0.6509 - val_recall: 0.9425 - val_precision: 0.5673\n",
            "Epoch 425/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3684 - accuracy: 0.8172 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9367 - recall: 0.9138 - precision: 0.7629\n",
            "Epoch 425: val_accuracy did not improve from 0.65469\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.3684 - accuracy: 0.8172 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9367 - recall: 0.9138 - precision: 0.7629 - val_loss: 0.7394 - val_accuracy: 0.6359 - val_sensitivity_at_specificity: 0.7412 - val_specificity_at_sensitivity: 0.6699 - val_recall: 0.8729 - val_precision: 0.5981\n",
            "Epoch 426/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3485 - accuracy: 0.8234 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9477 - recall: 0.9101 - precision: 0.7755\n",
            "Epoch 426: val_accuracy did not improve from 0.65469\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.3485 - accuracy: 0.8234 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9477 - recall: 0.9101 - precision: 0.7755 - val_loss: 0.8152 - val_accuracy: 0.6297 - val_sensitivity_at_specificity: 0.7534 - val_specificity_at_sensitivity: 0.6874 - val_recall: 0.9791 - val_precision: 0.5874\n",
            "Epoch 427/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3519 - accuracy: 0.8207 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9414 - recall: 0.9227 - precision: 0.7664\n",
            "Epoch 427: val_accuracy did not improve from 0.65469\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.3519 - accuracy: 0.8207 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9414 - recall: 0.9227 - precision: 0.7664 - val_loss: 0.7698 - val_accuracy: 0.6344 - val_sensitivity_at_specificity: 0.7872 - val_specificity_at_sensitivity: 0.7161 - val_recall: 0.8889 - val_precision: 0.5886\n",
            "Epoch 428/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3551 - accuracy: 0.8309 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9344 - recall: 0.9050 - precision: 0.7908\n",
            "Epoch 428: val_accuracy did not improve from 0.65469\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.3551 - accuracy: 0.8309 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9344 - recall: 0.9050 - precision: 0.7908 - val_loss: 0.8181 - val_accuracy: 0.5906 - val_sensitivity_at_specificity: 0.7045 - val_specificity_at_sensitivity: 0.6735 - val_recall: 0.9565 - val_precision: 0.5536\n",
            "Epoch 429/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3592 - accuracy: 0.8148 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9513 - recall: 0.9207 - precision: 0.7611\n",
            "Epoch 429: val_accuracy did not improve from 0.65469\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.3592 - accuracy: 0.8148 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9513 - recall: 0.9207 - precision: 0.7611 - val_loss: 0.7626 - val_accuracy: 0.6250 - val_sensitivity_at_specificity: 0.7769 - val_specificity_at_sensitivity: 0.6933 - val_recall: 0.9360 - val_precision: 0.5775\n",
            "Epoch 430/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3775 - accuracy: 0.8145 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9273 - recall: 0.9165 - precision: 0.7613\n",
            "Epoch 430: val_accuracy did not improve from 0.65469\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.3775 - accuracy: 0.8145 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9273 - recall: 0.9165 - precision: 0.7613 - val_loss: 0.8030 - val_accuracy: 0.6000 - val_sensitivity_at_specificity: 0.7204 - val_specificity_at_sensitivity: 0.6785 - val_recall: 0.9384 - val_precision: 0.5567\n",
            "Epoch 431/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3764 - accuracy: 0.8051 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9257 - recall: 0.9022 - precision: 0.7531\n",
            "Epoch 431: val_accuracy did not improve from 0.65469\n",
            "10/10 [==============================] - 2s 231ms/step - loss: 0.3764 - accuracy: 0.8051 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9257 - recall: 0.9022 - precision: 0.7531 - val_loss: 0.8251 - val_accuracy: 0.6219 - val_sensitivity_at_specificity: 0.7235 - val_specificity_at_sensitivity: 0.6645 - val_recall: 0.9017 - val_precision: 0.5829\n",
            "Epoch 432/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3628 - accuracy: 0.8160 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9492 - recall: 0.9000 - precision: 0.7667\n",
            "Epoch 432: val_accuracy did not improve from 0.65469\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.3628 - accuracy: 0.8160 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9492 - recall: 0.9000 - precision: 0.7667 - val_loss: 0.7407 - val_accuracy: 0.6383 - val_sensitivity_at_specificity: 0.7730 - val_specificity_at_sensitivity: 0.6954 - val_recall: 0.8619 - val_precision: 0.5909\n",
            "Epoch 433/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3501 - accuracy: 0.8254 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9484 - recall: 0.8938 - precision: 0.7863\n",
            "Epoch 433: val_accuracy did not improve from 0.65469\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.3501 - accuracy: 0.8254 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9484 - recall: 0.8938 - precision: 0.7863 - val_loss: 0.7463 - val_accuracy: 0.6484 - val_sensitivity_at_specificity: 0.7953 - val_specificity_at_sensitivity: 0.6992 - val_recall: 0.9302 - val_precision: 0.5970\n",
            "Epoch 434/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3714 - accuracy: 0.8160 - sensitivity_at_specificity: 0.9983 - specificity_at_sensitivity: 0.9376 - recall: 0.9055 - precision: 0.7685\n",
            "Epoch 434: val_accuracy did not improve from 0.65469\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.3714 - accuracy: 0.8160 - sensitivity_at_specificity: 0.9983 - specificity_at_sensitivity: 0.9376 - recall: 0.9055 - precision: 0.7685 - val_loss: 0.7298 - val_accuracy: 0.6195 - val_sensitivity_at_specificity: 0.7456 - val_specificity_at_sensitivity: 0.6855 - val_recall: 0.8800 - val_precision: 0.5717\n",
            "Epoch 435/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3676 - accuracy: 0.8121 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9366 - recall: 0.8760 - precision: 0.7706\n",
            "Epoch 435: val_accuracy did not improve from 0.65469\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.3676 - accuracy: 0.8121 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9366 - recall: 0.8760 - precision: 0.7706 - val_loss: 0.9390 - val_accuracy: 0.5867 - val_sensitivity_at_specificity: 0.7357 - val_specificity_at_sensitivity: 0.6764 - val_recall: 0.9586 - val_precision: 0.5448\n",
            "Epoch 436/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.3390 - accuracy: 0.8286 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9508 - recall: 0.9254 - precision: 0.7779\n",
            "Epoch 436: val_accuracy did not improve from 0.65469\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.3434 - accuracy: 0.8277 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9478 - recall: 0.9262 - precision: 0.7766 - val_loss: 0.8086 - val_accuracy: 0.6070 - val_sensitivity_at_specificity: 0.7404 - val_specificity_at_sensitivity: 0.7195 - val_recall: 0.9391 - val_precision: 0.5576\n",
            "Epoch 437/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3540 - accuracy: 0.8266 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9462 - recall: 0.9331 - precision: 0.7751\n",
            "Epoch 437: val_accuracy did not improve from 0.65469\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.3540 - accuracy: 0.8266 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9462 - recall: 0.9331 - precision: 0.7751 - val_loss: 0.7539 - val_accuracy: 0.6367 - val_sensitivity_at_specificity: 0.7496 - val_specificity_at_sensitivity: 0.7046 - val_recall: 0.9629 - val_precision: 0.5855\n",
            "Epoch 438/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3747 - accuracy: 0.8129 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9297 - recall: 0.8894 - precision: 0.7686\n",
            "Epoch 438: val_accuracy did not improve from 0.65469\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.3747 - accuracy: 0.8129 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9297 - recall: 0.8894 - precision: 0.7686 - val_loss: 0.7154 - val_accuracy: 0.6531 - val_sensitivity_at_specificity: 0.7925 - val_specificity_at_sensitivity: 0.7449 - val_recall: 0.9173 - val_precision: 0.6006\n",
            "Epoch 439/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3583 - accuracy: 0.8301 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9377 - recall: 0.9095 - precision: 0.7812\n",
            "Epoch 439: val_accuracy did not improve from 0.65469\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.3583 - accuracy: 0.8301 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9377 - recall: 0.9095 - precision: 0.7812 - val_loss: 0.7104 - val_accuracy: 0.6406 - val_sensitivity_at_specificity: 0.7448 - val_specificity_at_sensitivity: 0.6881 - val_recall: 0.8724 - val_precision: 0.6112\n",
            "Epoch 440/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3648 - accuracy: 0.8211 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9387 - recall: 0.8973 - precision: 0.7740\n",
            "Epoch 440: val_accuracy did not improve from 0.65469\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.3648 - accuracy: 0.8211 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9387 - recall: 0.8973 - precision: 0.7740 - val_loss: 0.7721 - val_accuracy: 0.6313 - val_sensitivity_at_specificity: 0.7901 - val_specificity_at_sensitivity: 0.7158 - val_recall: 0.9682 - val_precision: 0.5740\n",
            "Epoch 441/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3532 - accuracy: 0.8238 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9499 - recall: 0.8914 - precision: 0.7781\n",
            "Epoch 441: val_accuracy did not improve from 0.65469\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.3532 - accuracy: 0.8238 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9499 - recall: 0.8914 - precision: 0.7781 - val_loss: 0.7711 - val_accuracy: 0.6266 - val_sensitivity_at_specificity: 0.7297 - val_specificity_at_sensitivity: 0.6672 - val_recall: 0.9375 - val_precision: 0.5780\n",
            "Epoch 442/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3476 - accuracy: 0.8359 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9406 - recall: 0.9323 - precision: 0.7874\n",
            "Epoch 442: val_accuracy did not improve from 0.65469\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.3476 - accuracy: 0.8359 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9406 - recall: 0.9323 - precision: 0.7874 - val_loss: 0.7516 - val_accuracy: 0.6453 - val_sensitivity_at_specificity: 0.7789 - val_specificity_at_sensitivity: 0.7041 - val_recall: 0.9429 - val_precision: 0.6012\n",
            "Epoch 443/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3477 - accuracy: 0.8262 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9547 - recall: 0.9001 - precision: 0.7844\n",
            "Epoch 443: val_accuracy did not improve from 0.65469\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.3477 - accuracy: 0.8262 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9547 - recall: 0.9001 - precision: 0.7844 - val_loss: 0.7807 - val_accuracy: 0.6336 - val_sensitivity_at_specificity: 0.7928 - val_specificity_at_sensitivity: 0.7210 - val_recall: 0.9206 - val_precision: 0.5857\n",
            "Epoch 444/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3375 - accuracy: 0.8301 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9536 - recall: 0.9138 - precision: 0.7841\n",
            "Epoch 444: val_accuracy did not improve from 0.65469\n",
            "10/10 [==============================] - 2s 189ms/step - loss: 0.3375 - accuracy: 0.8301 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9536 - recall: 0.9138 - precision: 0.7841 - val_loss: 0.7984 - val_accuracy: 0.6320 - val_sensitivity_at_specificity: 0.7604 - val_specificity_at_sensitivity: 0.6761 - val_recall: 0.9474 - val_precision: 0.5838\n",
            "Epoch 445/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3402 - accuracy: 0.8372 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9465 - recall: 0.9271 - precision: 0.7937\n",
            "Epoch 445: val_accuracy did not improve from 0.65469\n",
            "10/10 [==============================] - 2s 181ms/step - loss: 0.3402 - accuracy: 0.8372 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9465 - recall: 0.9271 - precision: 0.7937 - val_loss: 0.8618 - val_accuracy: 0.6102 - val_sensitivity_at_specificity: 0.7455 - val_specificity_at_sensitivity: 0.7240 - val_recall: 0.9400 - val_precision: 0.5566\n",
            "Epoch 446/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3490 - accuracy: 0.8324 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9470 - recall: 0.9006 - precision: 0.7883\n",
            "Epoch 446: val_accuracy did not improve from 0.65469\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.3490 - accuracy: 0.8324 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9470 - recall: 0.9006 - precision: 0.7883 - val_loss: 0.7176 - val_accuracy: 0.6391 - val_sensitivity_at_specificity: 0.7892 - val_specificity_at_sensitivity: 0.7222 - val_recall: 0.8846 - val_precision: 0.5977\n",
            "Epoch 447/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3527 - accuracy: 0.8256 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9484 - recall: 0.8781 - precision: 0.7950\n",
            "Epoch 447: val_accuracy did not improve from 0.65469\n",
            "10/10 [==============================] - 3s 262ms/step - loss: 0.3527 - accuracy: 0.8256 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9484 - recall: 0.8781 - precision: 0.7950 - val_loss: 0.9092 - val_accuracy: 0.5891 - val_sensitivity_at_specificity: 0.7296 - val_specificity_at_sensitivity: 0.6809 - val_recall: 0.9488 - val_precision: 0.5455\n",
            "Epoch 448/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3543 - accuracy: 0.8203 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9416 - recall: 0.8776 - precision: 0.7864\n",
            "Epoch 448: val_accuracy did not improve from 0.65469\n",
            "10/10 [==============================] - 3s 313ms/step - loss: 0.3543 - accuracy: 0.8203 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9416 - recall: 0.8776 - precision: 0.7864 - val_loss: 0.8900 - val_accuracy: 0.6062 - val_sensitivity_at_specificity: 0.7626 - val_specificity_at_sensitivity: 0.6755 - val_recall: 0.9701 - val_precision: 0.5599\n",
            "Epoch 449/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3536 - accuracy: 0.8238 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9444 - recall: 0.9265 - precision: 0.7755\n",
            "Epoch 449: val_accuracy did not improve from 0.65469\n",
            "10/10 [==============================] - 2s 250ms/step - loss: 0.3536 - accuracy: 0.8238 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9444 - recall: 0.9265 - precision: 0.7755 - val_loss: 0.6983 - val_accuracy: 0.6383 - val_sensitivity_at_specificity: 0.7711 - val_specificity_at_sensitivity: 0.6995 - val_recall: 0.8909 - val_precision: 0.5967\n",
            "Epoch 450/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3419 - accuracy: 0.8305 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9529 - recall: 0.9082 - precision: 0.7908\n",
            "Epoch 450: val_accuracy did not improve from 0.65469\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.3419 - accuracy: 0.8305 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9529 - recall: 0.9082 - precision: 0.7908 - val_loss: 0.8287 - val_accuracy: 0.6414 - val_sensitivity_at_specificity: 0.7355 - val_specificity_at_sensitivity: 0.6709 - val_recall: 0.9495 - val_precision: 0.5931\n",
            "Epoch 451/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3469 - accuracy: 0.8264 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9499 - recall: 0.8884 - precision: 0.7916\n",
            "Epoch 451: val_accuracy did not improve from 0.65469\n",
            "10/10 [==============================] - 3s 283ms/step - loss: 0.3469 - accuracy: 0.8264 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9499 - recall: 0.8884 - precision: 0.7916 - val_loss: 0.7916 - val_accuracy: 0.6141 - val_sensitivity_at_specificity: 0.8013 - val_specificity_at_sensitivity: 0.7005 - val_recall: 0.9491 - val_precision: 0.5637\n",
            "Epoch 452/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3471 - accuracy: 0.8203 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9515 - recall: 0.8994 - precision: 0.7732\n",
            "Epoch 452: val_accuracy did not improve from 0.65469\n",
            "10/10 [==============================] - 3s 324ms/step - loss: 0.3471 - accuracy: 0.8203 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9515 - recall: 0.8994 - precision: 0.7732 - val_loss: 0.8565 - val_accuracy: 0.6109 - val_sensitivity_at_specificity: 0.7307 - val_specificity_at_sensitivity: 0.6713 - val_recall: 0.9606 - val_precision: 0.5633\n",
            "Epoch 453/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3453 - accuracy: 0.8306 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9471 - recall: 0.9107 - precision: 0.7838\n",
            "Epoch 453: val_accuracy improved from 0.65469 to 0.66328, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.3453 - accuracy: 0.8306 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9471 - recall: 0.9107 - precision: 0.7838 - val_loss: 0.7480 - val_accuracy: 0.6633 - val_sensitivity_at_specificity: 0.8398 - val_specificity_at_sensitivity: 0.7464 - val_recall: 0.9137 - val_precision: 0.6126\n",
            "Epoch 454/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3497 - accuracy: 0.8320 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9425 - recall: 0.8878 - precision: 0.7976\n",
            "Epoch 454: val_accuracy did not improve from 0.66328\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.3497 - accuracy: 0.8320 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9425 - recall: 0.8878 - precision: 0.7976 - val_loss: 0.8039 - val_accuracy: 0.6141 - val_sensitivity_at_specificity: 0.7673 - val_specificity_at_sensitivity: 0.6925 - val_recall: 0.9497 - val_precision: 0.5666\n",
            "Epoch 455/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3526 - accuracy: 0.8301 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9430 - recall: 0.9140 - precision: 0.7814\n",
            "Epoch 455: val_accuracy did not improve from 0.66328\n",
            "10/10 [==============================] - 2s 194ms/step - loss: 0.3526 - accuracy: 0.8301 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9430 - recall: 0.9140 - precision: 0.7814 - val_loss: 0.7721 - val_accuracy: 0.6203 - val_sensitivity_at_specificity: 0.7621 - val_specificity_at_sensitivity: 0.7161 - val_recall: 0.8998 - val_precision: 0.5767\n",
            "Epoch 456/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3466 - accuracy: 0.8223 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9587 - recall: 0.9039 - precision: 0.7809\n",
            "Epoch 456: val_accuracy did not improve from 0.66328\n",
            "10/10 [==============================] - 2s 254ms/step - loss: 0.3466 - accuracy: 0.8223 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9587 - recall: 0.9039 - precision: 0.7809 - val_loss: 0.7942 - val_accuracy: 0.6258 - val_sensitivity_at_specificity: 0.7904 - val_specificity_at_sensitivity: 0.7237 - val_recall: 0.9168 - val_precision: 0.5730\n",
            "Epoch 457/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3425 - accuracy: 0.8289 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9485 - recall: 0.9084 - precision: 0.7872\n",
            "Epoch 457: val_accuracy did not improve from 0.66328\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.3425 - accuracy: 0.8289 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9485 - recall: 0.9084 - precision: 0.7872 - val_loss: 0.8122 - val_accuracy: 0.6117 - val_sensitivity_at_specificity: 0.7344 - val_specificity_at_sensitivity: 0.6947 - val_recall: 0.9248 - val_precision: 0.5623\n",
            "Epoch 458/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3532 - accuracy: 0.8268 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9382 - recall: 0.8860 - precision: 0.7936\n",
            "Epoch 458: val_accuracy did not improve from 0.66328\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.3532 - accuracy: 0.8268 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9382 - recall: 0.8860 - precision: 0.7936 - val_loss: 0.8508 - val_accuracy: 0.6180 - val_sensitivity_at_specificity: 0.7785 - val_specificity_at_sensitivity: 0.6901 - val_recall: 0.9610 - val_precision: 0.5704\n",
            "Epoch 459/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3513 - accuracy: 0.8285 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9451 - recall: 0.8928 - precision: 0.7817\n",
            "Epoch 459: val_accuracy did not improve from 0.66328\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.3513 - accuracy: 0.8285 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9451 - recall: 0.8928 - precision: 0.7817 - val_loss: 0.8019 - val_accuracy: 0.6227 - val_sensitivity_at_specificity: 0.7441 - val_specificity_at_sensitivity: 0.6832 - val_recall: 0.8736 - val_precision: 0.5785\n",
            "Epoch 460/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3504 - accuracy: 0.8254 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9530 - recall: 0.9025 - precision: 0.7785\n",
            "Epoch 460: val_accuracy did not improve from 0.66328\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.3504 - accuracy: 0.8254 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9530 - recall: 0.9025 - precision: 0.7785 - val_loss: 0.7997 - val_accuracy: 0.6211 - val_sensitivity_at_specificity: 0.7905 - val_specificity_at_sensitivity: 0.6892 - val_recall: 0.9492 - val_precision: 0.5690\n",
            "Epoch 461/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3279 - accuracy: 0.8379 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9471 - recall: 0.9134 - precision: 0.7960\n",
            "Epoch 461: val_accuracy did not improve from 0.66328\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.3279 - accuracy: 0.8379 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9471 - recall: 0.9134 - precision: 0.7960 - val_loss: 0.8436 - val_accuracy: 0.6242 - val_sensitivity_at_specificity: 0.7929 - val_specificity_at_sensitivity: 0.7213 - val_recall: 0.9433 - val_precision: 0.5807\n",
            "Epoch 462/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3585 - accuracy: 0.8238 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9423 - recall: 0.9034 - precision: 0.7722\n",
            "Epoch 462: val_accuracy did not improve from 0.66328\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.3585 - accuracy: 0.8238 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9423 - recall: 0.9034 - precision: 0.7722 - val_loss: 0.7878 - val_accuracy: 0.6172 - val_sensitivity_at_specificity: 0.7236 - val_specificity_at_sensitivity: 0.6887 - val_recall: 0.8960 - val_precision: 0.5770\n",
            "Epoch 463/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3348 - accuracy: 0.8395 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9508 - recall: 0.9250 - precision: 0.7965\n",
            "Epoch 463: val_accuracy did not improve from 0.66328\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.3348 - accuracy: 0.8395 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9508 - recall: 0.9250 - precision: 0.7965 - val_loss: 0.8147 - val_accuracy: 0.6227 - val_sensitivity_at_specificity: 0.7560 - val_specificity_at_sensitivity: 0.6998 - val_recall: 0.9585 - val_precision: 0.5681\n",
            "Epoch 464/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3550 - accuracy: 0.8215 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9436 - recall: 0.9190 - precision: 0.7697\n",
            "Epoch 464: val_accuracy did not improve from 0.66328\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.3550 - accuracy: 0.8215 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9436 - recall: 0.9190 - precision: 0.7697 - val_loss: 0.7420 - val_accuracy: 0.6297 - val_sensitivity_at_specificity: 0.7668 - val_specificity_at_sensitivity: 0.6907 - val_recall: 0.9192 - val_precision: 0.5889\n",
            "Epoch 465/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3523 - accuracy: 0.8238 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9419 - recall: 0.9079 - precision: 0.7754\n",
            "Epoch 465: val_accuracy did not improve from 0.66328\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.3523 - accuracy: 0.8238 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9419 - recall: 0.9079 - precision: 0.7754 - val_loss: 0.8332 - val_accuracy: 0.6508 - val_sensitivity_at_specificity: 0.8130 - val_specificity_at_sensitivity: 0.7109 - val_recall: 0.9444 - val_precision: 0.5978\n",
            "Epoch 466/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3492 - accuracy: 0.8211 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9457 - recall: 0.8928 - precision: 0.7892\n",
            "Epoch 466: val_accuracy did not improve from 0.66328\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.3492 - accuracy: 0.8211 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9457 - recall: 0.8928 - precision: 0.7892 - val_loss: 0.8493 - val_accuracy: 0.6086 - val_sensitivity_at_specificity: 0.7325 - val_specificity_at_sensitivity: 0.6641 - val_recall: 0.9409 - val_precision: 0.5665\n",
            "Epoch 467/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3399 - accuracy: 0.8322 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9583 - recall: 0.9140 - precision: 0.7865\n",
            "Epoch 467: val_accuracy did not improve from 0.66328\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.3399 - accuracy: 0.8322 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9583 - recall: 0.9140 - precision: 0.7865 - val_loss: 0.8137 - val_accuracy: 0.6094 - val_sensitivity_at_specificity: 0.7528 - val_specificity_at_sensitivity: 0.7136 - val_recall: 0.9442 - val_precision: 0.5601\n",
            "Epoch 468/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3259 - accuracy: 0.8410 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9679 - recall: 0.9158 - precision: 0.7972\n",
            "Epoch 468: val_accuracy did not improve from 0.66328\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.3259 - accuracy: 0.8410 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9679 - recall: 0.9158 - precision: 0.7972 - val_loss: 0.9786 - val_accuracy: 0.6078 - val_sensitivity_at_specificity: 0.6892 - val_specificity_at_sensitivity: 0.6619 - val_recall: 0.9185 - val_precision: 0.5707\n",
            "Epoch 469/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.3475 - accuracy: 0.8333 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9436 - recall: 0.9003 - precision: 0.8042\n",
            "Epoch 469: val_accuracy did not improve from 0.66328\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.3462 - accuracy: 0.8360 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9445 - recall: 0.9036 - precision: 0.8054 - val_loss: 0.8198 - val_accuracy: 0.6250 - val_sensitivity_at_specificity: 0.7589 - val_specificity_at_sensitivity: 0.6967 - val_recall: 0.9134 - val_precision: 0.5823\n",
            "Epoch 470/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3181 - accuracy: 0.8523 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9628 - recall: 0.9128 - precision: 0.8170\n",
            "Epoch 470: val_accuracy did not improve from 0.66328\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.3181 - accuracy: 0.8523 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9628 - recall: 0.9128 - precision: 0.8170 - val_loss: 0.8631 - val_accuracy: 0.6109 - val_sensitivity_at_specificity: 0.7433 - val_specificity_at_sensitivity: 0.7036 - val_recall: 0.9311 - val_precision: 0.5672\n",
            "Epoch 471/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3357 - accuracy: 0.8348 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9603 - recall: 0.8985 - precision: 0.8005\n",
            "Epoch 471: val_accuracy did not improve from 0.66328\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.3357 - accuracy: 0.8348 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9603 - recall: 0.8985 - precision: 0.8005 - val_loss: 0.8195 - val_accuracy: 0.6187 - val_sensitivity_at_specificity: 0.7981 - val_specificity_at_sensitivity: 0.7270 - val_recall: 0.9296 - val_precision: 0.5728\n",
            "Epoch 472/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3385 - accuracy: 0.8445 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9465 - recall: 0.9048 - precision: 0.8059\n",
            "Epoch 472: val_accuracy did not improve from 0.66328\n",
            "10/10 [==============================] - 2s 176ms/step - loss: 0.3385 - accuracy: 0.8445 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9465 - recall: 0.9048 - precision: 0.8059 - val_loss: 0.9249 - val_accuracy: 0.6313 - val_sensitivity_at_specificity: 0.7427 - val_specificity_at_sensitivity: 0.6672 - val_recall: 0.9630 - val_precision: 0.5825\n",
            "Epoch 473/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3301 - accuracy: 0.8445 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9543 - recall: 0.9071 - precision: 0.8083\n",
            "Epoch 473: val_accuracy did not improve from 0.66328\n",
            "10/10 [==============================] - 2s 189ms/step - loss: 0.3301 - accuracy: 0.8445 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9543 - recall: 0.9071 - precision: 0.8083 - val_loss: 0.7731 - val_accuracy: 0.6477 - val_sensitivity_at_specificity: 0.8036 - val_specificity_at_sensitivity: 0.7129 - val_recall: 0.9475 - val_precision: 0.6031\n",
            "Epoch 474/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3251 - accuracy: 0.8367 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9624 - recall: 0.9345 - precision: 0.7820\n",
            "Epoch 474: val_accuracy did not improve from 0.66328\n",
            "10/10 [==============================] - 2s 221ms/step - loss: 0.3251 - accuracy: 0.8367 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9624 - recall: 0.9345 - precision: 0.7820 - val_loss: 0.7873 - val_accuracy: 0.6266 - val_sensitivity_at_specificity: 0.7411 - val_specificity_at_sensitivity: 0.7322 - val_recall: 0.9045 - val_precision: 0.5852\n",
            "Epoch 475/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3167 - accuracy: 0.8484 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9640 - recall: 0.9099 - precision: 0.8153\n",
            "Epoch 475: val_accuracy did not improve from 0.66328\n",
            "10/10 [==============================] - 2s 186ms/step - loss: 0.3167 - accuracy: 0.8484 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9640 - recall: 0.9099 - precision: 0.8153 - val_loss: 0.8536 - val_accuracy: 0.6109 - val_sensitivity_at_specificity: 0.7727 - val_specificity_at_sensitivity: 0.7035 - val_recall: 0.9555 - val_precision: 0.5612\n",
            "Epoch 476/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3347 - accuracy: 0.8397 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9500 - recall: 0.9215 - precision: 0.7999\n",
            "Epoch 476: val_accuracy did not improve from 0.66328\n",
            "10/10 [==============================] - 2s 181ms/step - loss: 0.3347 - accuracy: 0.8397 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9500 - recall: 0.9215 - precision: 0.7999 - val_loss: 0.8642 - val_accuracy: 0.6102 - val_sensitivity_at_specificity: 0.7488 - val_specificity_at_sensitivity: 0.7079 - val_recall: 0.8878 - val_precision: 0.5677\n",
            "Epoch 477/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3361 - accuracy: 0.8414 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9523 - recall: 0.8884 - precision: 0.8123\n",
            "Epoch 477: val_accuracy did not improve from 0.66328\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.3361 - accuracy: 0.8414 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9523 - recall: 0.8884 - precision: 0.8123 - val_loss: 0.8577 - val_accuracy: 0.5977 - val_sensitivity_at_specificity: 0.7449 - val_specificity_at_sensitivity: 0.7054 - val_recall: 0.9591 - val_precision: 0.5546\n",
            "Epoch 478/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3745 - accuracy: 0.8113 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9364 - recall: 0.8796 - precision: 0.7753\n",
            "Epoch 478: val_accuracy did not improve from 0.66328\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.3745 - accuracy: 0.8113 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9364 - recall: 0.8796 - precision: 0.7753 - val_loss: 0.8745 - val_accuracy: 0.5914 - val_sensitivity_at_specificity: 0.7320 - val_specificity_at_sensitivity: 0.6501 - val_recall: 0.9514 - val_precision: 0.5348\n",
            "Epoch 479/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3247 - accuracy: 0.8445 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9574 - recall: 0.9273 - precision: 0.7977\n",
            "Epoch 479: val_accuracy did not improve from 0.66328\n",
            "10/10 [==============================] - 2s 207ms/step - loss: 0.3247 - accuracy: 0.8445 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9574 - recall: 0.9273 - precision: 0.7977 - val_loss: 0.8233 - val_accuracy: 0.6187 - val_sensitivity_at_specificity: 0.8006 - val_specificity_at_sensitivity: 0.7099 - val_recall: 0.9351 - val_precision: 0.5694\n",
            "Epoch 480/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3198 - accuracy: 0.8430 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9723 - recall: 0.9183 - precision: 0.8009\n",
            "Epoch 480: val_accuracy did not improve from 0.66328\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.3198 - accuracy: 0.8430 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9723 - recall: 0.9183 - precision: 0.8009 - val_loss: 0.8205 - val_accuracy: 0.6297 - val_sensitivity_at_specificity: 0.8050 - val_specificity_at_sensitivity: 0.7224 - val_recall: 0.9505 - val_precision: 0.5814\n",
            "Epoch 481/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3293 - accuracy: 0.8398 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9594 - recall: 0.9067 - precision: 0.7951\n",
            "Epoch 481: val_accuracy did not improve from 0.66328\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.3293 - accuracy: 0.8398 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9594 - recall: 0.9067 - precision: 0.7951 - val_loss: 0.8318 - val_accuracy: 0.6234 - val_sensitivity_at_specificity: 0.7851 - val_specificity_at_sensitivity: 0.6929 - val_recall: 0.9386 - val_precision: 0.5668\n",
            "Epoch 482/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3295 - accuracy: 0.8438 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9618 - recall: 0.9118 - precision: 0.8066\n",
            "Epoch 482: val_accuracy did not improve from 0.66328\n",
            "10/10 [==============================] - 2s 176ms/step - loss: 0.3295 - accuracy: 0.8438 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9618 - recall: 0.9118 - precision: 0.8066 - val_loss: 0.8521 - val_accuracy: 0.6430 - val_sensitivity_at_specificity: 0.8346 - val_specificity_at_sensitivity: 0.7308 - val_recall: 0.9438 - val_precision: 0.5897\n",
            "Epoch 483/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3331 - accuracy: 0.8367 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9593 - recall: 0.8975 - precision: 0.7963\n",
            "Epoch 483: val_accuracy did not improve from 0.66328\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.3331 - accuracy: 0.8367 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9593 - recall: 0.8975 - precision: 0.7963 - val_loss: 0.8847 - val_accuracy: 0.6008 - val_sensitivity_at_specificity: 0.7225 - val_specificity_at_sensitivity: 0.7182 - val_recall: 0.9490 - val_precision: 0.5540\n",
            "Epoch 484/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3250 - accuracy: 0.8430 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9618 - recall: 0.9050 - precision: 0.8005\n",
            "Epoch 484: val_accuracy did not improve from 0.66328\n",
            "10/10 [==============================] - 2s 240ms/step - loss: 0.3250 - accuracy: 0.8430 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9618 - recall: 0.9050 - precision: 0.8005 - val_loss: 0.8674 - val_accuracy: 0.6156 - val_sensitivity_at_specificity: 0.7637 - val_specificity_at_sensitivity: 0.6731 - val_recall: 0.9451 - val_precision: 0.5762\n",
            "Epoch 485/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3275 - accuracy: 0.8430 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9576 - recall: 0.9236 - precision: 0.8001\n",
            "Epoch 485: val_accuracy did not improve from 0.66328\n",
            "10/10 [==============================] - 2s 177ms/step - loss: 0.3275 - accuracy: 0.8430 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9576 - recall: 0.9236 - precision: 0.8001 - val_loss: 0.9077 - val_accuracy: 0.6148 - val_sensitivity_at_specificity: 0.7186 - val_specificity_at_sensitivity: 0.6475 - val_recall: 0.9528 - val_precision: 0.5669\n",
            "Epoch 486/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3293 - accuracy: 0.8422 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9563 - recall: 0.9179 - precision: 0.7997\n",
            "Epoch 486: val_accuracy did not improve from 0.66328\n",
            "10/10 [==============================] - 2s 229ms/step - loss: 0.3293 - accuracy: 0.8422 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9563 - recall: 0.9179 - precision: 0.7997 - val_loss: 0.8765 - val_accuracy: 0.6086 - val_sensitivity_at_specificity: 0.7662 - val_specificity_at_sensitivity: 0.6937 - val_recall: 0.9477 - val_precision: 0.5688\n",
            "Epoch 487/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3262 - accuracy: 0.8402 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9559 - recall: 0.9024 - precision: 0.8046\n",
            "Epoch 487: val_accuracy did not improve from 0.66328\n",
            "10/10 [==============================] - 2s 181ms/step - loss: 0.3262 - accuracy: 0.8402 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9559 - recall: 0.9024 - precision: 0.8046 - val_loss: 0.9847 - val_accuracy: 0.6086 - val_sensitivity_at_specificity: 0.7480 - val_specificity_at_sensitivity: 0.6575 - val_recall: 0.9583 - val_precision: 0.5569\n",
            "Epoch 488/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3281 - accuracy: 0.8398 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9650 - recall: 0.9055 - precision: 0.8042\n",
            "Epoch 488: val_accuracy did not improve from 0.66328\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.3281 - accuracy: 0.8398 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9650 - recall: 0.9055 - precision: 0.8042 - val_loss: 0.7950 - val_accuracy: 0.6313 - val_sensitivity_at_specificity: 0.7788 - val_specificity_at_sensitivity: 0.7079 - val_recall: 0.8926 - val_precision: 0.5831\n",
            "Epoch 489/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3176 - accuracy: 0.8508 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9620 - recall: 0.9291 - precision: 0.8061\n",
            "Epoch 489: val_accuracy did not improve from 0.66328\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.3176 - accuracy: 0.8508 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9620 - recall: 0.9291 - precision: 0.8061 - val_loss: 0.7896 - val_accuracy: 0.6453 - val_sensitivity_at_specificity: 0.7648 - val_specificity_at_sensitivity: 0.6818 - val_recall: 0.9237 - val_precision: 0.5942\n",
            "Epoch 490/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3382 - accuracy: 0.8340 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9544 - recall: 0.8688 - precision: 0.8138\n",
            "Epoch 490: val_accuracy did not improve from 0.66328\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.3382 - accuracy: 0.8340 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9544 - recall: 0.8688 - precision: 0.8138 - val_loss: 0.8322 - val_accuracy: 0.6344 - val_sensitivity_at_specificity: 0.7652 - val_specificity_at_sensitivity: 0.6919 - val_recall: 0.9152 - val_precision: 0.5945\n",
            "Epoch 491/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3098 - accuracy: 0.8480 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9677 - recall: 0.9205 - precision: 0.8088\n",
            "Epoch 491: val_accuracy did not improve from 0.66328\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.3098 - accuracy: 0.8480 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9677 - recall: 0.9205 - precision: 0.8088 - val_loss: 0.8579 - val_accuracy: 0.6383 - val_sensitivity_at_specificity: 0.7854 - val_specificity_at_sensitivity: 0.7111 - val_recall: 0.9471 - val_precision: 0.5867\n",
            "Epoch 492/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3274 - accuracy: 0.8441 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9561 - recall: 0.9023 - precision: 0.8007\n",
            "Epoch 492: val_accuracy did not improve from 0.66328\n",
            "10/10 [==============================] - 2s 189ms/step - loss: 0.3274 - accuracy: 0.8441 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9561 - recall: 0.9023 - precision: 0.8007 - val_loss: 0.9235 - val_accuracy: 0.5906 - val_sensitivity_at_specificity: 0.6911 - val_specificity_at_sensitivity: 0.6436 - val_recall: 0.9593 - val_precision: 0.5418\n",
            "Epoch 493/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3430 - accuracy: 0.8336 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9597 - recall: 0.9041 - precision: 0.7947\n",
            "Epoch 493: val_accuracy did not improve from 0.66328\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.3430 - accuracy: 0.8336 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9597 - recall: 0.9041 - precision: 0.7947 - val_loss: 0.8433 - val_accuracy: 0.6328 - val_sensitivity_at_specificity: 0.7883 - val_specificity_at_sensitivity: 0.7022 - val_recall: 0.9601 - val_precision: 0.5850\n",
            "Epoch 494/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3328 - accuracy: 0.8406 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9588 - recall: 0.9135 - precision: 0.7832\n",
            "Epoch 494: val_accuracy did not improve from 0.66328\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.3328 - accuracy: 0.8406 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9588 - recall: 0.9135 - precision: 0.7832 - val_loss: 0.7888 - val_accuracy: 0.6211 - val_sensitivity_at_specificity: 0.7363 - val_specificity_at_sensitivity: 0.6394 - val_recall: 0.9192 - val_precision: 0.5826\n",
            "Epoch 495/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3296 - accuracy: 0.8418 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9659 - recall: 0.9024 - precision: 0.8032\n",
            "Epoch 495: val_accuracy did not improve from 0.66328\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.3296 - accuracy: 0.8418 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9659 - recall: 0.9024 - precision: 0.8032 - val_loss: 0.9216 - val_accuracy: 0.6062 - val_sensitivity_at_specificity: 0.7228 - val_specificity_at_sensitivity: 0.6651 - val_recall: 0.9575 - val_precision: 0.5604\n",
            "Epoch 496/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3262 - accuracy: 0.8336 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9600 - recall: 0.8961 - precision: 0.7930\n",
            "Epoch 496: val_accuracy did not improve from 0.66328\n",
            "10/10 [==============================] - 2s 210ms/step - loss: 0.3262 - accuracy: 0.8336 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9600 - recall: 0.8961 - precision: 0.7930 - val_loss: 0.8307 - val_accuracy: 0.6109 - val_sensitivity_at_specificity: 0.7425 - val_specificity_at_sensitivity: 0.6847 - val_recall: 0.8815 - val_precision: 0.5688\n",
            "Epoch 497/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3309 - accuracy: 0.8367 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9579 - recall: 0.8932 - precision: 0.8065\n",
            "Epoch 497: val_accuracy did not improve from 0.66328\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.3309 - accuracy: 0.8367 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9579 - recall: 0.8932 - precision: 0.8065 - val_loss: 0.9078 - val_accuracy: 0.5977 - val_sensitivity_at_specificity: 0.7088 - val_specificity_at_sensitivity: 0.6522 - val_recall: 0.9527 - val_precision: 0.5636\n",
            "Epoch 498/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3361 - accuracy: 0.8352 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9650 - recall: 0.9060 - precision: 0.8023\n",
            "Epoch 498: val_accuracy did not improve from 0.66328\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.3361 - accuracy: 0.8352 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9650 - recall: 0.9060 - precision: 0.8023 - val_loss: 0.8377 - val_accuracy: 0.6156 - val_sensitivity_at_specificity: 0.7683 - val_specificity_at_sensitivity: 0.7067 - val_recall: 0.9512 - val_precision: 0.5756\n",
            "Epoch 499/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3198 - accuracy: 0.8477 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9665 - recall: 0.9201 - precision: 0.8030\n",
            "Epoch 499: val_accuracy did not improve from 0.66328\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.3198 - accuracy: 0.8477 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9665 - recall: 0.9201 - precision: 0.8030 - val_loss: 0.8416 - val_accuracy: 0.6164 - val_sensitivity_at_specificity: 0.7433 - val_specificity_at_sensitivity: 0.6755 - val_recall: 0.9045 - val_precision: 0.5734\n",
            "Epoch 500/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3166 - accuracy: 0.8484 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9602 - recall: 0.9110 - precision: 0.8137\n",
            "Epoch 500: val_accuracy did not improve from 0.66328\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.3166 - accuracy: 0.8484 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9602 - recall: 0.9110 - precision: 0.8137 - val_loss: 0.9010 - val_accuracy: 0.6250 - val_sensitivity_at_specificity: 0.7981 - val_specificity_at_sensitivity: 0.7020 - val_recall: 0.9332 - val_precision: 0.5727\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Performance Metrics**"
      ],
      "metadata": {
        "id": "_94Ihob_GMaS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Training_Accuracy=history.history['accuracy']\n",
        "Validation_Accuracy=history.history['val_accuracy']\n",
        "Validation_Specificity=history.history['val_specificity_at_sensitivity']\n",
        "Validation_Sensitivity=history.history['val_sensitivity_at_specificity']\n",
        "Validation_Recall=history.history['val_recall']\n",
        "Validation_Precision=history.history['val_precision']\n",
        "Validation_Loss=history.history['val_loss']\n",
        "\n",
        "print(\"Training Accuracy: \",max(Training_Accuracy))\n",
        "print(\"Validation Accuracy: \",max(Validation_Accuracy))\n",
        "print(\"Validation Specificity: \",max(Validation_Specificity))\n",
        "print(\"Validation Sensitivity: \",max(Validation_Sensitivity))\n",
        "print(\"Validation Recall: \",max(Validation_Recall))\n",
        "print(\"Validation Precision: \",max(Validation_Precision))\n",
        "print(\"Validation Loss: \",min(Validation_Loss))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCdS_0U65A0-",
        "outputId": "a4fbe644-576f-46d0-ba93-4495b97efb14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy:  0.852343738079071\n",
            "Validation Accuracy:  0.663281261920929\n",
            "Validation Specificity:  0.7529940009117126\n",
            "Validation Sensitivity:  0.8397534489631653\n",
            "Validation Recall:  1.0\n",
            "Validation Precision:  0.6185792088508606\n",
            "Validation Loss:  0.6242520213127136\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Accuracy Graph**"
      ],
      "metadata": {
        "id": "MHwE0fRxGOBi"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLqjG2X-vdLj",
        "outputId": "1a56850e-2eac-4a52-d86a-f85eb67cd854",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        }
      },
      "source": [
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loss Graph**"
      ],
      "metadata": {
        "id": "KJWZEi8pGQFS"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBSAyVfivvHX",
        "outputId": "4b5b8ed6-c354-4360-9b28-23e85afa526c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        }
      },
      "source": [
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmEAAAGDCAYAAABjkcdfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOydeZwcVbn+n9PLdM8+yUz2CUkIa9gCRBBQAREFBOWqeEFRcUFRlp9XEUWuiqjXDTe8LhcVkUUQQQQEZJNVtgQISwghkHWyTiaZfXo/vz/eevucqq7u6Z7pnunJvN/Ph093V1dXneoJU88873Peo7TWEARBEARBEMaWwHgPQBAEQRAEYTIiIkwQBEEQBGEcEBEmCIIgCIIwDogIEwRBEARBGAdEhAmCIAiCIIwDIsIEQRAEQRDGARFhgiDstiil5iultFIqVMS+5yilnhiLcQmCIAAiwgRBqBKUUuuUUgmlVJtn+wuOkJo/PiMrTcwJgiAUi4gwQRCqibUAzuIXSqmDANSN33AEQRAqh4gwQRCqiesBfNx6/QkA19k7KKWalVLXKaU6lVLrlVL/rZQKOO8FlVJXKqV2KKXWAHivz2f/oJTaopTapJT6rlIqOJoBK6VmK6XuVErtVEq9oZQ613rvCKXUMqVUr1Jqm1Lqp872qFLqBqVUl1KqWym1VCk1YzTjEARh4iEiTBCEauJpAE1Kqf0dcXQmgBs8+/wSQDOAPQEcCxJtn3TeOxfAqQAOBbAEwIc8n70WQArAXs4+7wbwmVGO+WYAHQBmO+f7H6XUO533fgHgF1rrJgALAdzibP+Ecw1zAbQCOA/A0CjHIQjCBENEmCAI1Qa7YScCWAlgE79hCbNLtdZ9Wut1AH4C4GPOLh8G8HOt9Uat9U4A37c+OwPAKQC+qLUe0FpvB/Az53gjQik1F8AxAL6qtY5prZcD+D2Mm5cEsJdSqk1r3a+1ftra3gpgL611Wmv9nNa6d6TjEARhYiIiTBCEauN6AB8BcA48pUgAbQDCANZb29YDmOM8nw1go+c9Zp7z2S1OCbAbwP8BmD6Ksc4GsFNr3ZdnPJ8GsA+A15yS46nO9usB3AfgZqXUZqXUj5RS4VGMQxCECYiIMEEQqgqt9XpQQP8UAH/zvL0D5CLNs7btAeOWbQGV+Oz3mI0A4gDatNYtzn9NWusDRjHczQCmKqUa/cajtV6ttT4LJPR+COBWpVS91jqptf621noRgKNBJdSPQxCESYWIMEEQqpFPA3in1nrA3qi1ToNyVd9TSjUqpeYB+BJMbuwWABcppdqVUlMAfM367BYA9wP4iVKqSSkVUEotVEodW8K4Ik6oPqqUioLE1pMAvu9sO9gZ+w0AoJQ6Wyk1TWudAdDtHCOjlDpeKXWQU17tBQnLTAnjEARhN0BEmCAIVYfW+k2t9bI8b18IYADAGgBPAPgzgGuc934HKvO9COB55DppHwdQA+BVALsA3ApgVglD6wcF6Pm/d4JaaswHuWK3A/iW1vpBZ/+TAKxQSvWDQvpnaq2HAMx0zt0Lyr09CipRCoIwiVBa6/EegyAIgiAIwqRDnDBBEARBEIRxQESYIAiCIAjCOCAiTBAEQRAEYRwQESYIgiAIgjAOiAgTBEEQBEEYB0LjPYBSaWtr0/Pnzx/vYQiCIAiCIAzLc889t0NrPc3vvQknwubPn49ly/K1DxIEQRAEQagelFLr870n5UhBEARBEIRxQESYIAiCIAjCOFAxEaaUukYptV0p9Uqe95VS6iql1BtKqZeUUodVaiyCIAiCIAjVRiUzYdcC+F8A1+V5/2QAezv/HQngN85jySSTSXR0dCAWi43k4xOKaDSK9vZ2hMPh8R6KIAiCIAijoGIiTGv9mFJqfoFd3g/gOk2LVz6tlGpRSs3SWm8p9VwdHR1obGzE/PnzoZQa4YirH601urq60NHRgQULFoz3cARBEARBGAXjmQmbA2Cj9brD2VYysVgMra2tu7UAAwClFFpbWyeF4ycIgiAIuzsTIpivlPqsUmqZUmpZZ2dnvn3GeFTjw2S5TkEQBEHY3RlPEbYJwFzrdbuzLQet9dVa6yVa6yXTpvn2OxtXurq6sHjxYixevBgzZ87EnDlzsq8TiUTBzy5btgwXXXTRGI1UEARBEIRqYTybtd4J4AKl1M2gQH7PSPJg1UBrayuWL18OALj88svR0NCAiy++OPt+KpVCKOT/VS9ZsgRLliwZk3EKgiAIglA9VLJFxU0AngKwr1KqQyn1aaXUeUqp85xd7gGwBsAbAH4H4AuVGst4cM455+C8887DkUceiUsuuQTPPvssjjrqKBx66KE4+uijsWrVKgDAI488glNPPRUACbhPfepTOO6447DnnnviqquuGs9LEARBEAShglRyduRZw7yvAZxf7vN++64VeHVzb1mPuWh2E7512gElf66jowNPPvkkgsEgent78fjjjyMUCuHBBx/E17/+ddx22205n3nttdfw8MMPo6+vD/vuuy8+//nPSzsKQRAEQdgNmXBrR04kzjjjDASDQQBAT08PPvGJT2D16tVQSiGZTPp+5r3vfS8ikQgikQimT5+Obdu2ob29fSyHLQiCIAgTi85VwLR9x3sUJbPbibCROFaVor6+Pvv8G9/4Bo4//njcfvvtWLduHY477jjfz0QikezzYDCIVCpV6WEKgiAIwsRl8wvA1ccBn3scmHXweI+mJCZEi4rdgZ6eHsyZQ23Qrr322vEdjCAIgiDsLgx00ePQrvEdxwgQETZGXHLJJbj00ktx6KGHirslCIIgTG62rQBeuqU8x8o48R6dLs/xxhBF+fiJw5IlS/SyZctc21auXIn9999/nEY09ky26xUEQRB2M+75Comwr60f/bFevRO45WPAR28D9n7X6I9XZpRSz2mtfXtRiRMmCIIgCMLYkk4CmTJVhdJOU/RyHW8MEREmCIIgCMLYotNApkzlQxZfE7AcKSJMEARBEISxJZOugBMmIkwQBEEQBKEwZRVhEzeYLyJMEARBEISxJZMCoIFMZvTHYhEmTpggCIIgCMIwlDPHlW1RUQZBN8bsdh3zx4Ouri6ccMIJAICtW7ciGAxi2rRpAIBnn30WNTU1BT//yCOPoKamBkcffXTFxyoIgiAI4w6Lr0wKCI5yfeQJnAkTEVYGWltbsXz5cgDA5ZdfjoaGBlx88cVFf/6RRx5BQ0ODiDBBEARhcpCxRNhoScvsSMHDc889h2OPPRaHH3443vOe92DLli0AgKuuugqLFi3CwQcfjDPPPBPr1q3Db3/7W/zsZz/D4sWL8fjjj4/zyAVBEAShwpRVhE3cPmG7nxN279eArS+X95gzDwJO/kHRu2utceGFF+KOO+7AtGnT8Je//AWXXXYZrrnmGvzgBz/A2rVrEYlE0N3djZaWFpx33nklu2eCIAiCMGFhwVSOYH5m4gbzdz8RVgXE43G88sorOPHEEwEA6XQas2bNAgAcfPDB+OhHP4rTTz8dp59++ngOUxAEQRDGh6wIK4cTJsH86qEEx6pSaK1xwAEH4Kmnnsp57+6778Zjjz2Gu+66C9/73vfw8stldu0EQRAEodphwVROETYBnTDJhFWASCSCzs7OrAhLJpNYsWIFMpkMNm7ciOOPPx4//OEP0dPTg/7+fjQ2NqKvr2+cRy0IgiAIY0RZnTAnEybBfAEAAoEAbr31Vnz1q1/FIYccgsWLF+PJJ59EOp3G2WefjYMOOgiHHnooLrroIrS0tOC0007D7bffLsF8QRAEYXLArlVZ+oSxoJt4Imz3K0eOM5dffnn2+WOPPZbz/hNPPJGzbZ999sFLL71UyWEJgiAIQvVQTuEkyxYJgiAIgjAh6N1SnlmJo0FXokWFiDBBEARBEKqVwZ3ALw4GXr93fMdRzj5hE7gcKSJMEARBECYLsR5yjvq3j+84ylqOlGD+uKO1Hu8hjAmT5ToFQRCEClDO1hCjIeuElTETJk7Y+BCNRtHV1bXbCxStNbq6uhCNRsd7KIIgCMJEpGpEWCWatU48EbZbzI5sb29HR0cHOjs7x3soFScajaK9vX28hyEIgiBMRNgtYuEyXpQzmC/LFo0v4XAYCxYsGO9hCIIgCEJ1U07xMxrK2ScsmwmbeMsW7RblSEEQBEEQiqCcsxJHNQ5POfKVvwG/O2Fkx0rnCfmvfmD8Hb9hEBEmCIIgCJOFanPC+HHry8CmZSPrX+Y3O7LzdeDGDwGr7we0Bp65mtpzVBkiwgRBEARhssAiZ7wdIq8TNpo2E9lMmCUsYz30GO8DejYC934FeO3ukY21gogIEwRBEITJQnZ25HgH83kcHmduJA6dX4uK1JDzGAdSjsBLx0s/doURESYIgiAIkwVdxv5coyGfEzYaEWa7aMmYOS4fk8VYFSEiTBAEQRAmC9XSoiJHhPmUFIslK+CsPFnWCYsZ1y8tIkwQBEEQhPFiJMH8dKr8C357g/mj6XrP1+LnhKXiuW5bFSEiTBAEQRAmC1nxU4IT9p1W4JaPlW8MWhvBxI8jKUemk8BLfyWhBfhnwtIJS+glgFfvMKH9KqCiIkwpdZJSapVS6g2l1Nd83p+nlHpIKfWSUuoRpZS0ghcEQRCESuENxBfLa/8o/xgAqyw5gnLkmw8Df/uMCdz7OmEx47L1bgZu+Tjwym0jG3cFqJgIU0oFAfwKwMkAFgE4Sym1yLPblQCu01ofDOAKAN+v1HgEQRAEYdKjq6BFhS20RpMJG9rlOa7f7EgrmM/7JwaKP0eFqaQTdgSAN7TWa7TWCQA3A3i/Z59FAP7lPH/Y531BEARBEMpFNXTMt8VSxluOLMGhi/fmP67thLHLFu8z72XSwENXAOufLP58FaCSImwOgI3W6w5nm82LAD7gPP8PAI1KqdYKjkkQBEEQJi+j6Zgf6x1+n2JwOWHeYH4J4/Jmu/QwmTDePxUDkoPA4z8BNj1X/PkqwHgH8y8GcKxS6gUAxwLYBCBHBiulPquUWqaUWtbZ2TnWYxQEQRCE3YPROGE9G4ffp6gxFCpHluKE9XmOm2d2ZNrjhKViQNIRaeHa4s9XASopwjYBmGu9bne2ZdFab9Zaf0BrfSiAy5xt3d4Daa2v1lov0VovmTZtWgWHLAiCIAi7MXoUfcJ6Oso0hjIF873lSD8nLBUzx3SJsEF6Hq4r/nwVoJIibCmAvZVSC5RSNQDOBHCnvYNSqk0pxWO4FMA1FRyPIAiCIExusrMjixQ7Wpvn3RvKMwb73KNpUeEtj/o5YemEfyZsd3fCtNYpABcAuA/ASgC3aK1XKKWuUEq9z9ntOACrlFKvA5gB4HuVGo8gCIIgTHoyJYowW9iUrRzpF8wfSTnS64T5dcyPW+dwWllUkRMWquTBtdb3ALjHs+2b1vNbAdxayTEIgiAIguBQajnSLvEN5aSFRka5WlSUmgljqigTVlERJgiCIAhCFVFqMN8WNrrEBq95jzlKEZZJAxuezi1HujJhXI6M5x7TJcJ2YydMEARBEIQqItuiYgRO2EjWdfQ9ph3M94ynGBH2+n3AzWflbrc/m7TLkZ5rTdrlyN00EyYIgiAIQpXhXTh72P19enqNegx+TlgJzVr7tuQ5ro8TZmfC7PeqpBwpIkwQBEEQJgulLluUsVyrspUjCwXzi3DCvMsVMa61I+1mrX7lyOoI5osIEwRBEITJQsktKipQjhxtJiyfCLMFY8pnAW/7PXHCBEEQBKEEVt4FXLkvlZiEkVEVwXyfY3I50nuODU8D15zk/pnbszRP+BZwyEeAhe/0d8JSPk5YUpwwQRAEQSiNnWuA/q1AYmC8RzJxKXXtSJcTlsm/30jGwOPIZPKP67ZzgQ1PuRvF2k7YlHnAf/wGiDb7Z8IKzY4MhIBgePTXMwpEhAmCIAgTA77J6jKJgcmIN4NV7P5AhVpUpN2zF70lz/5t9GiPd2inec5Olgqa8WltOWEFypHj7IIBIsIEQRCEiUKpM/uEXEblhFUimJ8ypUi/cXGXey4fAm4njF3RQNAz01ID4Xrns0PuY3IwPxQd8SWUC+kTJgiCIEwMsk6HiLARU2owvyKzIz1OmO1U8XuJQWDbCrM90W+eD+0C9j0FqG+jR4CcMB4ri67aFiA54P4snyPeN+6hfEBEmCAIgjBR4Bu0OGEjp5S1I3etA+I91mfL1azVOs6qe4GYfQ5nXM/+H/Dg5WZ7wnHCtCYR1rY3cOIV5v1AwByX82DRZqB3k9tFY4Z2VUU5UkSYIAiCMDHIirAS1hcU3JSyduQvDjElPaB8WTzXGo8DwBsP5L634Wn3Z7jsmBykcmPtFPf7Kmg+y05YtNn9WZuhXVXhhEkmTBAEQZgYSDB/9GSskq7W+ffj95KWgCmX+C10nEyKzt2xzL2dS4qcB6ud6n4/EPJ3wuzP2lSJEyYiTBAEQZgYSDB/9HjbQ+TDDstn97c+e8f5wBM/G9kY+DjBGp/3UlQGHdwBzD3SbOeS4qAzM9LrhAUsJyzeR491rfQoTpggCIIgjBIJ5o8eW0gVKkn65ajs733dE7luVdFjcMRfMOI/Pj7ue38CfGMHPWchlXXCfMqR7JD2b6fH5rnOZ32uJdYjIkwQBEEQikaC+aPHLuUWcsKSMffrQMiT5Yr5f37rK8CWl4obQyiPE9bjNGZt3YuaqQZrLBFWhBM2wCKsnR5tJyxgNWeVcqQgCIIgFElGnLBRU6wIS3l6awVr3N97asi/ZHnfpcC9l+Q/7iu3Af+81DlmHicsGQOgTB+vmnojpHq30GPjLPfnVMBcT38nPWZFmJUJq20xz8UJEwRBEIQikdmR+RncOfw+QG6j1Hx4G5wGw+6eYUmfTvQAMLjL3XLCy62fMk5VyE+EpUjghaKAUrQtXG/Ko72b6L06bzDf6pg/sJ2cspoGem07YRzWB8QJEwRBEISiyTYaHcPZkS/fCuxcO3bnGwkdy4AfL6RA+3DoYjNhnnKk7YRlMtTJ3u/zsR7jPA10Ab2b85/Dr2N9JkXnDlvv1dSbY/Z0AE1zjEBj7BYV/duA+ulG5KWtxb+j4oQJgiAIQumwczOW5cjbPwe8cP3YnW8k9G4mgcqB9EIU64T5lSP5s/xexkeExXuM8/TPrwJ/Pcf/3AAQ9GlVmnXCLIFUU2fC9b2bgOY5uZ8LBAFoam/R3wk0TPcXeS4nTESYIAiCIBTHWAfzM+nctQ2rER5fMeMstkWFXzmSP8sumfd8mQy1h2AR1rcVGOg07/d0eMbtc37OhLmcsAZzzJ5NZtajTSBkPj+wHaif5hZZypE7tgjz5srGARFhgiAIwsRgrIP5WXFTBRm0eD+w5hH/97gsWEwX/KJnRxbhhHm/l0Q/HT8Vo/fife72EDvf9IzbrxdZij5vO2HhOjp2OgX0b6VypBcWWTptnDA788Wd/20RdtCHco8zxogIEwRBECYGYx3MZ5FQDRMB7rkYuO79QNebue9lShBhdp6u0P4pn0xYZhgnLN5rnvPC2Xa/sZ1r3Pv7nT+TIgHozYQlB4G+LSTy8pYjQY5Zoo+csBpLhPHzpjnAotOBc+7xnxgwxsjakYIgCMLEYKyD+SwSqkGE7VpPj72bgNaF7veyYrEYJ6zYcqSnwaldjsyXCYtZIiwxQE6YfZwurwgr5IR5g/kDdO0A0NSe+znliLA+p4VFNhOmAGjjitXUAR/+U+7nxwlxwgRBEISJwVgH81Nx93nHE25Oyh3jbbLlyCIyYUW3qPA6YREfJ8wrwqzWFIkBKqFmUkDKGddglxFLgHvWIuB0vU+TE5YjwgaBbqeJayEnrG8rPdZPoxmUNfXmGID/UknjiDhhgiAIwsRgrNeOrKZyJIswvxmQpWTXinXCcmZHOk7Yv39hhI5XhNnlyFivWfw7OUDd8dMJcqjYrfJ+PlxLP9tUzB2q5xYVW14kMdi6V+54WdyxSOXsF+fJmuYADTPc61FWASLCBEEQhInBWDth1VSOZCeHBYzNcLMjh7pNp3hdZCbMG8wPOU7YA9/M/3m7HNm/zX2s2ik0vtqp5hpSHicsXGsyYbYTFq6jn/mGp4GZB5Eg9MJOGLtxkUZ6rKkDBpzHM67Nf73jhJQjBUEQhIlBNhM2CYP5XLrr9RNhPGHBR1RtfgH44Txgxe3OPrYTVoIIC9a4BZzf52Pd5rktFnmGZDrhXi/S+3kWYal4bosKANi0DJhzmP94eXYkj4FFGM+KDPgItypARJggCIIwMRjrPmFZh6mIwHul4RxWQSfMZ5zrnqDHDc/Qo6tFRYHvMWd2ZDh3/0LlSC5ZAqYsmYr7rxfJhFiEeZq1Ns02z2fnEWHcJ2yIRVgTPXJZM1CdhT8RYYIgCMLEIFuOHKvZkeyEVcGC4aliRJhVjmSBNNhFj7zWon0tBcuR3tmRNbll4EySOtQzdjnSHie7aumkfymRCdX4N2vd71RgzuH0vP0t/p/NliMdEcbuGbem8OvOXwVU56gEQRCE6mH1g8CsQ4CGaeM7jskczC8owjx9wrreBH51JHDe42Zhbw726zSV5jLJEmdH1vh/75mUEVaxHnNsOxPG3e7TcaBmitl+3hO07mXrXsBr/wA2PkvX4HXCAgHgk/dSML/NJ5QPWMH8bsqTcdkzW46sTrkjTpggCIKQn0wa+POHgeeroLfSmAfzRyDCeja5S3Hlgt2kWI+7Cz1gslV9W4CbPkI5sEySFvRmJyybp0ubJqWFMmF+5Ui/79123+K9ZikgWyyueRhY8Xfa124RMfMgYMkngQVvB07+IblZ7MCFPes+hiLA3CPyj9d2wjgPBhgnrEozYdUpDQVBEITqIJOim6/3pjwejHkwfwSzI/92LhBtAc76c3nHYn//Qzvd3eBZCG18Ftj8PNA4g14nBowTxjMRdYYETaK/sKPoW470KQPbJc1YL5U9+7cCfZYT9uQv6bFtXzpOUzvQ61lHEiC3Kt5Hz0MlLq7NwfyhXW4Rxk1aq9QJq85RCYIgCNXBWC8VVIjxCuaXcu271gONFRCs9mxFb2sHFkIsYFgAJQdJsAFmdqVOm/YPBTNhPuVIP+xjDO4gEVZTT4to5+zrOGGff8KIQ5tAyJQuvU7YcLATNtRj2nEAVpPW6pQ7Uo4UBEEQ8lNVIowX8B6jYH6qRBGmNYkPO6BetrHE/Z8DRiwm+umx3ymHJgaBgU7nM3wtGSOoCrao8Fm2yA/7GLvWAy17mFC8F25RUTsld+klgIQUX0OoRBGm7HJkk9le5U5YRUWYUuokpdQqpdQbSqmv+by/h1LqYaXUC0qpl5RSp1RyPIIgCEKJjHUYvhDV7oTFeugz7EiVk9SQ6QLvXe4n64Q5AoYzabFukwmznTAWSV4x5zqfz7JFfvB3FO8j161lnnGf7CWKeN9CywYFQuYaShVh7ITFe/3LkfYsziqiYiJMKRUE8CsAJwNYBOAspdQiz27/DeAWrfWhAM4E8OtKjUcQBEEogVgvuSZV6YSNdZ+wIq+dlxSKV8AJS8aMCMtXjsw6YU45cudas0/KarcRcUQYl/58z+ezbJEfD14OPP0bs8D4lHlG5NW2uB2oVKJwn7BAyPQUC5eYCbPPY4swniVZzLqa40AlnbAjALyhtV6jtU4AuBnA+z37aADsGzYD2FzB8QiCIAjFkIwBPzsQeOXW6hJh2uPKpZPApucrd75Sg/mcg0oOlr/BaypGgX8gfzkSjtvD4921ztrHcsLCtRRk95YcbfyWLfJjxd+B1+42i2u3zDciSGeMEwWQwCrUJ8wWUiMtRwJuEcairxoa7vpQSRE2B8BG63WHs83mcgBnK6U6ANwD4MIKjkcQBEEohngfEO+hNgPVJMK8Y3ngW8Dvjgc6X6/M+UotR9qLa5e7JJm0ypGdq4DbzzPh+XwCw24TwU6YzpBgCdfltrqw8ZYj87Z40DQjsdtywt76BWfMMbcIy6TyiznAlBSBEThhlpxxiTBn3N4SbpUw3sH8swBcq7VuB3AKgOuVUjljUkp9Vim1TCm1rLOzc8wHKQiCMKngG1YmVWWZME85cuPT9GivWVhOst9DkS7KgHV/4oWkiyWTMUIp5700jYFF2ENXAC/eBLx6hzPOPJ+zG6ZmryVNYidcZ0p/XtJJU9oEACi3QPIyuJPKkeF6oK4V2OfdwKcfAM6+1d1KAxg+E8aUywkLTV4nbBOAudbrdmebzacB3AIAWuunAEQBtHkPpLW+Wmu9RGu9ZNq0ce7YLAiCsLuTsm7YWRFWTU6YMzuSxUehEtdoyJYjixSgLiesxFzY078CfvUW/wA5u1Jcjqx3bpM7HAcwnwjjz9U0uvuEqSCJI2/JkenpoP1a5tHrQDBXhNmCaWgnOWFT5gFK0ba5RwDz3+Z2woDiRdioMmHW7Mjg5M2ELQWwt1JqgVKqBhS8v9OzzwYAJwCAUmp/kAgTq0sQBGE8sctw1VSO5NYU7ISxczTabujxfsrArXnEvb3UcqTdG6vUNhU7VlOGy8/V47Ij979iYcEibLjx1be518EMBMi1yhfM5yxZq7NEkArmznS0hU4qRuNvnoscRirCSnXCZh5kjc2vHDnJRJjWOgXgAgD3AVgJmgW5Qil1hVLqfc5uXwZwrlLqRQA3AThH6yqdRyoIgjBZcDlhVSTCvC0qyrW248angZ6NwGNX0usVt1PD05IzYZ2mc3upThjv3+PTST7lOFZcjmShtmM1PRYUGIoaqKasYH7WCcuTCeN8F/fy8nPC5hzmfr3zTaBpVu6xvI5WqIAIs9NIpTph0SZgj6Ppud1HjkVfvlLvOFPR7mVa63tAgXt72zet568COKaSYxAEQRBKxM8JK7ZNQyXxlkZLLRfmY8cb9Ni6F5Xo/noOcMK3chfGHo6BTnKDuteX7oRxkL97o9vVAYwTxuXIIRZhr9N4C4mwSCMtAWQ7YSpAIidfMH/XOnKlWvag114n7MPXA83twBsPmm06AzTOzj0W9wxjKuWEAcD7fgnceg6VQZkpC+hxzuGlH28MqM4WsoIgCML4kfIL5leDCPMs4G1PIBgNXNZrmm2ESSrudgQL8dSvyQVKDtIxuteX7oSxaOvZmPseO2FcjrTbTXRvLCwSI43kPvHxdcYJ5tfTrEY/dq0nMVH7ItsAACAASURBVMntHQIBtxMWCPnn8PycsEPPJtH32j/o9XB9wgAqL3vFWzG07QWc94R724xFwPlLTWm1yhARJgiCILhJV2E5UmurT5gnmF/s7MV82NkqLtGlE8X3CVv6e2DafiTaODRfshPm7M/9tmxYDNo5LCYdH0aENZHwSfuUIws5YVPmG+EVCLlLhcGwv6Pl54Tt916aMZkVYUX0CWvbu/BszFKZtk/5jlVmxrtFhSAIglBtpKowmG/nfLTVrBUY3di0Bra/6hwvYWYUphPFZ8KSQ/S5VJxETyhKfdZKgcuRfk4Yz2KsqctdAzGVKFyOjDaRE2avHZltUZFndiTPdORzKU8mLBD0X4vRzwkD3L3BiukTNm3f/PvsZogIEwRBENzYrom3S/14YQshbzB/NHm1wZ3W+opJywlLup225X8Gtq/0P0ZywBFtcXKIIo2lN2tl56zbrxzpCMNQbW5WKp8TxhmuSKOPExagcp9fn7BUnL6PpnarPOjJhAXyOWH5RJg15kKZMP4Zt4kIEwRBECYr1eiE2SLQO6bRjI0FGOCIMNsJs8TNXV8Elv7B/xi2ExaKkhtWSjkykwYS7IT5zI5kxyoczRUxqbi/E8Zl0YjXCbOatfqVIwd3Op9v9ThhlvPllwkLRYHaKf7XZ7tfhUQYt8YQJ0wQBEGYtKRH0Kw1MVjZNgD2+b0LeJcqwjJp4MFvU0sJuy9XOuFxwqylbtJx976xXkcApUwZMxUnwRNtKi2Yz93pQ7VuUcj4OWGhWjNmv0xc/XR6jPplwgIkwjLJXBdtcAc91rUCQXbCPMF8v0xY40zTqNVLyGo3UUiEdTmzVEWECYIgCJMW1+zIIt2m608HHry8cmOyhVcm436v1GD+jteBJ34KrL7fvbxQJumfCWOGLBH20/2BP55sZi6m4iR0QlGgpqHwuoxe2DVrmEbX6S2v8pjCUdNni2dKehuuctkw64Q1khPlXTuSlxNKDND3ecMHgdvONb3H6jxOmCqQCatp9A/lM65MWAERts9J9Dh1Yf59djNkdqQgCILgxrdj/jCZsJ4OckMqhX3+HCfMZ2xa53dmWLikhtwizJUJS+S6RLzvQBe5V5ueAzY9T9s4AxasIdHBZb1i4M/WT6fZkakhIGh1fU/6OGHRZlqg27XGI0g8DWwHGmbQ60gz7ZN1N61gPkDXq5Tp+bVluXOcNnO9gaB7gWxvJuyk75ueYn4Umwk78Qrg2EtIbE4SxAkTBEEQ3IykY35qmFYJo8WVCRumHLntVeC7M4Cda/2PxcIlOWRKjJFmpxwZM8f0OmG8LwsVAHjyl857jpsVitJ/qTiKhkuXDU4J0fvZwS4AyiktOiKGu+fHPSJs4fHAOy4B9jrBuS7HCUsnTJsPFTR9uJJD7lmS3K6joBPmyYQdcDqw57H5r8+VCRtmdiRf1yRBRJggCILgxuWEFZkJSydKEx6l4podmXKX7Lzib9dacn663vQ/VtwSYVxirG/zccK8IsxxhliENc+l5XoAM9MwFHFEWKz4a2MBxyVE72f7tzkZrbDbCQOMqxeuN9vfeZkJydvCLZ2w1o60ypF+rSpqp1h9woK5mbBA0PQO864P6SUQNOt7Vmqx9QmKiDBBEATBzYidsDEM5tvtFbxjY1Hhtxg2YIRLcpCEVShKjlHakwnzTjRgwbblRWpm2twO9G117+Mnwu67DPjHl/JfW9YJc0qISa8Is8qL7CrxEkbs6nHGi99nYRRpMttSceOE8dqMyUHzfbFYq51CofxCThjglCUjxTVWzU4oKOCETUJEhAmCIFQrW14Clv1x7M9bqhOmtb9zVE60pxxpuzfesbEAyivC7HJkD7lHwRqnHOkc1+4TxqTjJJC2vgzMOoQEjncR7GDECcI7Y9j+GvDUr4D1T7r3e+CbwPUfoOcswnhGo58TxqXKrAhjJ4xFWL05P0DrTx7wAWDukWZb1gmzypG2E9bmdJava6XHQJ7Zkbw9WGPE33DwuAtlwiYhIsIEQRCqleU3Avd9fezPW+rsyEwKgK6wE2YH8zPuWYH5nLChIp2waDOVydJJS4Q5wfyAp3wW6yb3q3kulfq8hCLkMvF3+PD3AGgzi5L59y+ANx9yjmnNjgR8RNh2M+nBW47k0iqXI7PvNwFn/JGO6XLCMqZFBX8HPLa2vemxzimL5nPCuKQYDJnzDgc7byLCXIgIEwRBqFa499RYY/eUKkaE8Rgr2ifM64RZDlSOE+aMZ9hypBPMj7Y4IizhEWGJXKenfxudu3YKlTC9hCwnbPNyYOWdJOTsn2PPJvdn4n0kjGqnOuO3RJjWQP9W44Rlg/mOAPQ6YX7lvqwIiwHQ7mB+YrAIJyzkmR1pOWFhqwdYIcQJ80VEmCAIQrXCGZ7RLMszovNa3dWLKUdmlw8qQoT981Lg5o/6v5fJ5Pa9GuoGOp7LzYTZfbi8wfzUcE6YI1wSg+5yZCZpPsvlSK/TwzMu66b6L6jNmbBMCvj3z0ngHfhBd/l0zcOea9xFY2BBY4uwWDeNI5sJc5yucB2Ju5xMmE97BxY+fFxXi4oBI2hb2QlzxGDeZYusTFjR5cioeywCABFhgiAI1Qu7J+kxdsNSVpuGYvqElTLOHa8Dna/lbo/3Ab84BPjN0e7tz/0R+ONJ7mNnUu5gfscy4KeLTG8uDrbH8iyi7VuOrPEpRyZynZ6da+ixdqq/E8aZMADY8QZlxxqmu52wDU+Z51oDvZtorUb+nB3M799Oj1kR5oiYcC3t750dWcgJ42tTASDSQM/j/eZ8XI6s9ylHepctApxyZAmZMK+jJogIEwRBqFqyZb4xFmG+zVoLOWEsworoE5aK57pdAPDYlUDPBrN+IBPvo/HYC2J7g/nbXiYh07vZOUcJwfyhbhJhgZB/OdIrMliE1U3172kVipplega7qOwXipLDprWz3WrkmklRo9vmdvM52wnr30aP2WB+1DwGa0wmrFA5koP57HgFgtTVXwVIhPL2hunAKVcCi8929iuwbBHglCNLcMIK9QibpIgIEwRBqDQ3fxS4+2L3tvsuA/722cKfy4qbCmat/Cg1mM/ly2LEYjrpL8J6N7n3yT53jm0viK0z7nIkP8+KVkfEDBvMHyARUtuSOzsyFadrrvGUI1kk1uYrR9YYIcQijDvA+11LKg70bHREmBWgZ7JOmBPM53JeuM5xwvK0qPCOCQAe/RE9qiB1yY84a1xml0WqBY44F2jbi14P16KicRaNuxhCEekR5oOIMEEQhErz2j+Apb9zb9v2CrD1FWD7SmC9VZ761/eAXy6h5+PuhGWKzISV4ISlEyQc2BVibGFiL8XDx7QXxM6kgYTljLGTw3mupOWExfuAO84HBnbkHn+gi/Jl2XJkynLRnPN5S462E+YbzI8atyodd8SS85oFXtwqkw7uICHY3G72s2dSZp2waeb4AAm7oJUJ886OtGEHat3j9MhNVqNNdJ38/XldLVezVuczLOAA4Mw/Ayf/MPd8foSi0iPMBxFhgiAIlcS72DSTStBN+pEfAP/4L7P9sR8BXasdQVAFThj359KZwtcCFJcJSyfoWN4u7Xa50XbK+Nr5/UCYxtS7hcREqNYSYY6AYhET66E1EV+4Abj7y7nHZ4GTbVGRyBV0XqHFjl3tVP8WFcEa99qHNQ1GGCUG6LuyBSd39W9uN5+zRXesB4CiZZUAdzPWYMQqRxbhhDEsrqLNTjlyiM7hDc37OWF2NizSUMLsyKiE8n0QESYIglBJBjrN82f+D3jmanqejtMNOTmY2/AToMWZs6LCZwmcJ38JXN7sLsuVi7RPORLIXTjbuz+vT1jw2I6o8pYkhxNh2bUZIyZH1TjLLTq8zmGs1/T5spul8vH5enhJILscydgibOqe9BiuI8E0nBMGkDhioXL3l4EbPkDXWuME49lZa56b65jxNUQajRPF18vOUsZxCnmZIr/cldfhYkEVaSaHMTlE+3gXPLdnR7JwG2lJcf9TgcUfGdlnd2NEhAmCIFQSO+v0ym3AK7fSc3bC8vUC695gBIjdfysxSCVMzvfkmwE4GlI+wXx+7bu/Nf7hSpK8b8Kz8HS8xyzFEy9QjgzWUDmytwNomuN2ZlisZkWMJjELAAPbrXN7BGBdm3PcVK4Is92u2YfRI/fzGi4TBjjBfOf1thX0s4v3mhmI7IS1zHWcIuX+PuO9brGXLUfWup2lOUuAlnlGKNpM2xc4+zaaqQkYQWc7YWGfMmbWCQtYTlgRSxT5ceAHgePHofFwlSMiTBAEIR9aA0/+b25zzVKwRVgqZpyrdJxutizGGHZIutdb6xha7991EfDrtxpR4u3EXg6yTli6OBFml0uHK52yqPJzwppmO+/ZIozLkZYTpjNmRqHtzCR9nMOejeZ5x1JzLpv6tgJOmCO0QlFaCgiwMlVOidAOrXudsHC9NVtyB/2XSQH1Tsar6w0SOw0zyInyrjsZ63GLvWgzAEWPttibdTDwxZeAplnwZa93AVMXesbPmbAh/1mOfgt4e1cQEEaFiDBBECYXfjPz8jHYBdx/GTlYw/HiX4DNL+Ru57YJ4Xqn/Oicnxe8TsVo+5pHgeeuNW5Q9wb/WYdbXvRcTwXKkXxenXb3B8vncrmcsOFEGJcjLaGlNYmBxlm572WdMEc4BcNOOXITiTA/J8wlwiwRzD+LxIBbONW3kbgoVI4MRYAZB9Jzdtf4vdoWs38w4ilHWk6YXXbmdSL7tlA5lEVOKGL6l/F1227covcDn/onLWPEAjQQ8g/ke5kyjx55kkKkiRzI1JB/tssvEyYzHMuKiDBBECYP21YA358L7Fhd3P4s2LzOiR/3fAVY+vvc7eyERRpIHNh9qGwhdt37gLv+n3GhujdYTpglbNgtYryiwaanI/97LJzifcBvjqEldph8mbB8DVtLcsJ8RFhyiAQfuziFMmHBCAXq03FHhFliiq8pGTMlQ9uJHNhBAjOTdDckjbaY0l6iz+322E7YjAPoOeewgmFyuTiPFQhTqS9fJsyGzz+0y+1ChWvp39EP9qDZm/FetxMWigB7vNV8FwCJQW+ey48WR4Rxm41oM32vicE8syotkcclTFv0CqNGRJggCBOXXetM0L2o/dfTzb57Q3H7s3Nht0fwIxUnR8HPlWInhpt/2j2ttLMGoh145zyUKxNmOTuNXhGWxwlb9wTwswNN5simewPw3enA078hd2jbK8DWl6zrGUUmbLh2Gn7BfBa5jX7lSE8mLBQh4QI4IswSTPbsSF7wuqeDhJIKkLPJx+ZyYF0rCRgWHDrjbsJqO2F8zD2Pd7/PIiwbmrczYQ3+AiefCLM/u/R3JJL8ZmHa+/pNEPBj3jH0OPcIeow2AdA0ecS3HOmzbJGIsLIiIkwQhPKz5hH/m3+5eekW4N6vuDuQM7Ee4Klfu2frcX6q2JIkC6bYMCJssIse/QRRtou743hxOdLbesE7RjsTZgfzva5KPhHW9SYA7e+Gdb5Oj//8GglTwO2o5XXC8mXCCgTzNz1nyrRa+4fjWWCxyPEN5nM50gqj5wvmp+JmmZ/ezY5QmkpO6I8W0HZepLquLfe4viKslsTaV94EzrrJvD/FCsNn20dYPyO7T5gNi8DkoHv9RXvfZ6+mXmd+EwDsMdcUKcKm7QN8dR1w2CfoNR+3b6t/MJ+Fl71skYiwsiIiTBCE8nP7ecATP638eTg3Y7eBYFb9E7jvUmD7q2YbC418wsVLsU4Yn99P3PEYOYifSRlBBuQXeANdRvSkCzhN+a5l0Mn9+C3dw/2xAGDto85xnO/GFkqZtLs3WF4nzC5HesZ332XAA98yx4Mjivm76t4IrH2MnjcWUY60naKm2bR+YXYc1uxIPpZOUym4vs00KwWAKfPpsd4RY3bWiQUaYJUjnfPWt7lF1kdvBU52ZqoG/Zywen+BwyIM8Dhh1r6DXfRfuZwwgFw7Ll2y2OzflscJC5CDaC9bJJmwsiIiTBB2V/q3A/++avi+TTaZDJX3Sgmv+xHrdXcorxQscHhpFxsuO7FLBRihUez1FS3Cdrj3t7EXw86ev99aDsgn7N44271AtSv47hE5+YL5A851+7Ww6N9qnvO18dgyKWSFUs7syGH6hAG5mTCefed9j52tX78VuPtL9Ly2hcRAodmRtgioneJxwqxli+qmmvdqGsjx4uOeczdwwOn0POuEWcflUiFgBFC+4HttixEzdg8vhteO9DKcCLO35XXCnDGXIsJs+Np0Ov/1BUKeZq0jbFEh+CIiTBB2V1beCTzwDfcU/eHY8gKV91bfP/LzZjIkIPxKhOWGb8y2s8OwILLFIG8rWYR5Soav32/KjPY5/ASRLTw4+5VvYWnG22bAPkaOE5YnmJ91wnxEWJ/1fbHDlLSyagBlrYrOhNlOmEdUJvqtZq7W2PlnYAuuSCOJFr9MGG9jtylcTyLEW47Umr6TUNTMNK1pIFEGkJiY+1azzE+9TznSFmF2Jiwf3FqC9wl6+4QNI8JqfDJh3NMLKCDCRuCE2dhl13wLcQdC0qKigogIE4TdlVJdH8DcnO1MTqlwpmloDEQYCwi/ciRfv8sJ43JVkeVIv0xYJg38+Qzgp/sbgTBYyAnzCapzsDwfjR4RZgfz0wm6MXKuJ5nn5zuQR4RpTU4Yl9xYYHrdqnBdrghL9Pu7YYXKpYkB8z3ZAs3v32VWhPmUIxkWSywgAp4+YekkAE0lQG4dweVIwJQwuaTolwljgaQCRpwM1wIiFDECKhAwAslXhCl3ydMub3KpcNZis23YcmRD4bHlI2KLsDzLDwVr6D+lACjJhJUZEWGCsLuSFWEl9JEacMp6oylH8mdt8fPCjcAbD438mPnIOmF+5UgehyUGR+yEWSLMFjXL/kiPLALziTDvjatkEWY7YTHq3H7qz51z5nPCnO9/yHLdOlcB324BXr0DaNmDtrEIyy5+zWsmNgDQbuH0+xNo6SUvhfqEJQb8FyIf3EHnZkcKIMenprGwCON1EFlguVpUxMx1hGo9Tpgjeprb6ZHFFWfC7J8RC7NwnSn5+eW6XOOKuh2wbFnRR4RFGt3Hs78D/nlM388Iw+GC+fneHw6XE5bn+t7/K+Atn6HngaBkwsqMiDBB2F1hQZDPKfGjnwPmo3DC+AY61E2uidbAHV+gNfPKTayACOPrLyYTlkkDj//ELVjsY9jlSFtAcVuHguXIeG65yHseLzxL0D4Gk0qQAxLwLF7tZdAnE2ZPUsiKME8mjF037tzvXbey643cc/n1Cdu51ul1NmQ5YdZ+L/+VemF5ZyLW1Lu/b295k4UOf84WBam4cTvDUbNPTb0RVizCpi4A3vZfwH6nOsfxccLCtUacleKE8etghFw32xmLNJNocpUsrVIgX3vDDNMTLp8TlhVhIyxH1rcBM5xVAPJd3/6nAq3caT8ombAyIyJMEKqZzS8Ar90zss/yzWisnbCsKNAkAHiB4krAAmKgWBE26H5kNi8HHroCWOX5rm1hwm6ULaD6nIC7Hcy3J0LwTMMcETaME+ZtyOoN5vPNvqauQDDfpxxpd4lvagegcsuRLicMuU5UvBe47nTg+evyjM/Z/2+fBf7+BTNmIFdQ6Yxb8AfDw5cj2Qljl8uVCRsyojFklyMbc52wQBB41+VG8LpEmLOvS4QVyIQBTqd8a59w1L/1xBHn0n+ufa39+A+L+mnUggPI73SFRinClALeeh497y4iOxoISiaszIgIE4Rq5t+/oF5OI6FYJyyTAZb/GUinjKNUDicMoFLgpufpuX2TKxeFnDAWJ4NWMJ9v0F6RyZMXvMfxaygacwRU7VQjwrLn0O7yIM809N5ES3bC7HJkwgqn1/mXIxMDpixnTwKwr6dhGgmDrAjjYP4wTtjQLuoDt/HZ/OMD6LvZudb9vndmJ5A76SHS4B/MZ7xOmHd2pC3C7HJkvUeEeQn6dMkP15FQUcHhnbAp801Hej5/jZXV4nLf4o8Ab/ui0yC2xpyH4e+jfloRThiL8RFmwgDg4DOBIz4HHH3h8Pva/cKEslDRb1MpdRKAXwAIAvi91voHnvd/BoBbD9cBmK61bsHuQCpB/1MXs5SEIORjqHvkgsiv9LZtBXDjh4Fz/wU0Os0sO5YCf/88lT/6LSesdwuJgVL/DdvnG9oJbHZEGP9VXy7SSSM0fMuRfsH8POVIbmjqDfjbAifeQzdyFlDTFwGdr+V+LjkILLuGbsp7HkvbSnXC/IL5T/yM2ofU1BsHJFznL7LtGaG2E2b/W4r10nGysyOtHluAJcI8wql7IwDtvgbOvWVSRnAN7bKEHYswv7UnNXDkecABHzDnzeeENc42Dl2tnxNmLQsVrjX71NQDrXuRizPTmnVoY4uwbA6s1rweToSddRMA6/+VUMTntTOW7HkidH12KJ6/M1uE5XXCRjk7EqBy6Sk/Km7fQEAyYWWmYk6YUioI4FcATgawCMBZSqlF9j5a6//SWi/WWi8G8EsAf6vUeEohlc4Mv1Mh0ingZ4uAl/5SngEJk5d478gXaM6G0K3Pb1sB9HYAO1432/gmHes2Zb0dq4GfHwi8fl/p53U5YV2mW7rXURktLB7C9SSCvP3QkgWC+d5yJIswr5iz9+PzsfiYvj85YIM7aWki7tCeGKBGtc//yYgP702yUIuKUNQsg8OkEsCDlwN9m8kpyTphtf5OGDtz9dPcIoxdllmLgcPPcY6j3deadcIcsZCKu13MbqfDvn1cO/eWjpPYSvSZlhxpTzD/8E+6WzDMOBDY40jnvA1ud8zuozb/bTRjEfB3wgZ2AI9fSc9DEbNPpIEycJd2AHPfAl/sa8w6VM53cNov6PsqRDDsbhwbiroFV6jWXF92G3e8t/b75L3AW79Apcx9TiZxGs3jTYw2mF8q4oSVnUqWI48A8IbWeo3WOgHgZgDvL7D/WQBuKvD+mPDQym047DsPYFN3gUVxhyPRTzcFXiRVEEZKrIfcnnxNMgEK0/vNPMx2D/cpqdntIxJ95j0O5neuIlfDFmvFYguXwZ1mAeXRtL3wI+6IgFkH043aXvsQcDthLNDyOWG97IQVEGHZ746dsP3pccXf6Pz7nGTON9hFfcRYfHhFWKEeapHG3PKS3ettaKf75u0n0rlR69SF9G+Ie5ol+knEfPYRWm7HdnfyZcJSMfd+/O/K5YQlzNI56WSu05dJUdmbXa2DP0x5LMYutzVMoz8+kkP0GbtFxvxjzPWy8LCdmZ6NwMq76Ll3diRQeIajfZyAxwk75Eygbe/8n/VjxgHAzAPN63AUgBq+Meu8o4CTvm+en/FHs3h2zphHmQkrlUBIRFiZqaQImwPATvp1ONtyUErNA7AAwL8qOJ6iWNBWj95YCg+s2Dr8zvmw1y8ThNHA7kuhoPyyPwA3fij3ZuzXooKFhF2i42MPdBphw49+TVC1LtyF3y55De10N+W0P5dO5ilPFQl/N4d+jG64y67xjMNydrIO2DDlSBahK/5Ox08MGuclbjlh4XqT/1l+E91MF76TXu9YbY7JvwtyMmF5ypELTwAOOctxRpxSlgoC6/9t9kknPE6Yjwhjl2rKPHr/p/sDHcvoumsaTYk5ZLk/+WZHphP+oXQ712Y7Yam4//WlE+bnHYyY2YqA+/vhsnXv5tzVBPY42vwb5vPlEwV1rVY5sojMVKBAOXIknPYL4H2/NK/ZGbMFlV8mrBT4+uzmspVEWlSUnWoJ5p8J4Fatte+f+0qpzyqllimllnV2+jRlLCN7TmvAXtMbcP+rPjefYsn+MhMRNqm57zJg1b2jO0a8CBE2sINmmfVtcW/364lVSIRxiNqmz/PHSCoOXLk38Mpt+ceT8DhhiQFHyGj3WP72WfrvH18CbvpI/uPlg7+blrnAgR8EXvqr06wzBWx71e0AZmcv5lk7ssdywnatB/76CeCak2i/+unO+TiY303lQg7Pb1oG7HGU6cjOObFYtxEqxZYjF38EePd3SCSxcPBzOUJ2MN9HhLG7aYfQu94gN9KbSWJy+oSxqIr556Hsa0gl3LMp84ow53diMOxuVmq3qeA8XO9m45wd9gnghG+RG5XwijBPy4RQFDh/KfXZ4hKxfa58+JYjRyiO/PAG9QH3LNeRsPe7gU/db1pIVJqZBxkHWCgLlfQVNwGYa71ud7b5cSaA8/MdSGt9NYCrAWDJkiUlLIQ3AnauxVdbH8fjq3fg0Rv+hZpQAIFAAEGloBQQjtZj/xM/iXCkwF9I/Jek30wgYfKw9A9049735JF93p7pVajDO98Mezrcv4yTPuXI7HqK1k2Sy4Rdb9JjTaO50XmdsL4t5JhtfQk46EP+4+Gx1k4lUZOKUaCa80x8s972Ct2YvGXEYmEnLNJEWaHlN1Dps2MZ8PfzSJhOWQDsWkv/TZnn7w4mY3RNwRoSp3zN21fQTbN1IXWYtzNhtS3u8PxBZ5j8kF3C3bXWjNEmnxNmOy+RBvo5RJtyRdtwIox/prb46NtKx7O7q9sOV94+YXF/EZPoB169E5i2L/2uYyH12I/pZ+slnTCiKliTX4SxE9a3BUgfQM9nHAAc+Tnn2rwizOPMNM4Cpu1Dz+ceCZx9G7DHW3PH44UdnkDYEmGjcMK8hKK5ne1He55A0GTpxoKP/nXszjVJqKQIWwpgb6XUApD4OhNAzp+7Sqn9AEwB8FQFx1I821bgxLU/xokhAD49CQFgebgei9/zifzH8P4yEyYfqTg5C8PNbOxcRbkVnqloYy+VU+g4XHqy1zIE/IP5vk6Yc2zOME6ZZ26iXieMg+v9BRzpRL9TbmqlGZYAXV/fZvd19G9zB9CTsfyZnc5VwNaX3cKPnbBok1lrsW8LOT7amVwz9wgSQltfAfY8zvpOnNLouifMDLQZB9JMTi4n8n5N7eQScqPTIccJY+cLoBLijlVmrAz3SPO2GMgnwmxRlHXCeHHoqPmdMlwwnx3HqZYo7+lwNAIs7gAAIABJREFUnLB8ImzQrLsIWMH8PE4YQI7hwWc6DWSjJGBSMWDF7bn7vnA9rbkJUBk07DhDiX6PCGMnbJMl2iyhxQKTx8flyECYypd2ew+lgL3e5T92L7YgypYjy+iEHXSGe+F0wN1VX5iUVEyEaa1TSqkLANwHalFxjdZ6hVLqCgDLtNZ3OrueCeBmrQuFTMaQvU8ELib1NZBIIZlKI5XRSGc0+vv7sfDPRyG57bXCx8gu0ZEovJ+w++LNcl1zEjDvGOCEb5h9/vl14OlfUUnB7y9Me6kcPk6sl2a+Td3TvMclLw6XM36lN99gvnNsvkE0zzUizDtbkF0iv+aoG56htgyJQSqvRBpNibRhpvv8ySESj3bz0O4NxsHw8sTPgBdvojYDs5019bJOWLNVwtpiJgLwtTTOIgEHGBGj0+SY/elU4Liv07aZjgjrXOk+d6SRyo3rHqfXQ7uAtr3oBn/OPU7rA2uNwa7VdF06DexcZ47BhGpN6c9LyOOEAUbAte1trmO4YH6in27s+7wHuGg58JePkQhLDLjdGG/vtlTMyrE5++lM/kalOuOIJWcGpTfDZbP0D2aCAZ+3rpXGajuFkUZ63bvF7ZzZ18b7AUYwRZvoj4sR56OcW1C4tjJO2MFn5G4bbTlSmPBUdJqD1voeAPd4tn3T8/rySo6hZEIRmp0DwPu3yQwA2zAVoV3DdABPiRM2Iclk8s9CykfvFvql7w2r2lmueD+w4Snjztz4YRJRr/2DXm9b4f5s5+tUQtRWqxQWSvdcTK1Pzl9qBAuXqnKcMC69We5TISeM4eVsAAroJ4fMzYhFmFecaQ3c8EHKNCUGSABEm4AtTjmOnT4+Fx/HFpq71uUXYfwdPXQF8DGnk83AdsqaRZvM99+3xeS7ALq5zTiQRKXWJEi53MqtFlh0tTnnZidrxkHAtpfp2mceCKy+j37esW4z627+Mda5rN8YMw8EtrxonDBbhNVOAfryiDDbCWTHim/UrZYI8wbztXb3c+Oyr1K0PE9zu/O9aKDO01DUJjlE//Gizfn2s+nbQn94DtdR3g7y8/jrWunfQsgjBptmAxuezP4udo3lXd8G7ryQxC9gMmERR4R523sUS10r/bFwyo/pfLMWUwaqklQieyZMKKolmD9h2BpqR8PghsI7cRbHu9zGRCbWC/zxvcCOPDXaic7214DvTneXooZj5xrgp/tRV3svLIzifaaM1bmKbpbbXgHWP2Ecm4FOEoDMr94CXH2cpxzpiLCNz9DjnReY94byiLBUsbMjLRGmArlL5tglSRZf2QWrY8Ad5wOv3U3Cpms1CciaehIeXHbLOmH9NGHhri/Sa7v9QL6WLpk0fXd1bcCbDwFrH6PtHcsoKxQMOwsi15MgsL+HcB3dSDtfo2vXGdM5na+LhdK0/ehx+0pysuYcRq9r6ilzBtB6h4M7/W/09o20bV/KxGVFmOX0FBIJttjhz3D5rc0SqHYmDJr+4Iv3AS/dQv/GEp6yY3M7uVDxPk/vKo/4STrL/oRq3bMOvQJLWbeO3s30XfJ6i/ngnCFgRHN9m7sUybB7+a/vuvcHgH3eDVy8yvxhwONkEVprlYlLIRSh4y56H/0x9rlHgQNOH9mxSjknICJsEiMirER66/bA9MQwa2ztjk7YzjdJOGx6brxHUhl2rKJSit/ixDbpJHDLJ+gG8fRvaZvf2oh2OZLdi1g3iZihXZRR0hlqWJlO+Jf3dlmzFRMDdHPlQH3HUtM7jDNhPVYZLp00AscuR9r5ryv3oRuoPWOxdoopf/Ff6XY4P1uOdITjPV8GXrgBePh/nO9irVWOtGe8WU7Yq3cAax7Of70v3myOx8dMx4HjL6WA/0PfoRmQHcuAuU7gWinKEvVudpcjw3XkSmVS5EwBJhDOpVKeFTrD6enUs5G+B+4LlYoDMw8G5hwOPPAN+ney4Njc8dsCat7RlE3iEq/thDVYYoUdIS7LukRYA71mwWz3qfJ2Sh/sAh78NvC3c6mdhbfs2Nzu/Pvb5ilHesQVO2HhqLtU7HXCmqxZl4l++vmU0keLxz/3SP/QvHemb6ElrziYz39s1OZpbFqNcFf94VxEYbdFRFiJxJsXoFn3ITNQYNkRdsJ2p0wY/4Ibbh3CiQrf6Owu4H50bwBe/TvNCnvhBtrm14OIj5Pod88U2/qyI4qc/Mk8x2HxWzx3zaPmeWKABEa8hxwRnXGWhRkys3Bt8eESXj4tKgC6Ia993N1Eta7VXA87L3xDTCeNE5ZJUTaNv4M+x33q2UjXXtPgER6OEza0yz1Om03P0fdw++eAR39otrOTOPswWt+u41lg5R30b3GuNTOscRY5Xva119RTGQ8wPwfuT8XXEu8FoICG6aYdRd1UypMB9L0HgsDH7wSOuoBm2+3tE/a2S9l7n5ibcwLIQbLXF2RXit+3M0i1U+h97n5vixwWT+1L6HHdE6a0u3NNbgCfW1WkYp5gvkdc9Wygf1OhqLv1g1ckTF2AHLg8aBPxcbkAI6recTHw4ety3z/uUvfrQotGsxPG/85HWo4cD4IR+hnL8naTFhFhJRJso180uzpW5t9pd3TCsg03R7iETrXDHcyHW1iZ+01teMoIUlvYvPkw3dyzImyAXK8pzk1r49Pu4807mh57fErcax4xz5MDVCYDjAvTv92Mt2UPCttng+/Ovz0VyA3me0POtkirazXCYM7htG/HMuDxnwDfnQGssiKe3NICMGXHTIpcxXCdR4Q5Ttj2le6sGxOMUKn1pjPNtnVP0HnXPwlAUblw0fvovYeuoMc9fESYTbjWTGLY6ogwLpvZbku0mURHy1zzPbDQyGaOGoD3fM80ZS1Ec7t7RmS4jpylYMTdu4tFEO9ri6KjLwQ+fL3VeHW+5Zg5P8OZh5CofOMhIy67N1DpzxZbtmhyTRLwOEzX/wfw8i30vdnlSNsxUwEaC+D+tzR1IfDZR2kiAFObR4R5e3t5OeB04D9vtM5fQITxUkFHfIYei50NWQ3Utoy8fCrsFogIK5H6mTTle9eWN/PvtDtmwlhwFOpXNZHY/ALw+xONeODH4ZwwdiXssiw7EE/9Grj+dOCR71vB/H5yJha8g5yRDR4RtsdR9MhOmC2IYt0AFN30EgPGEVrwDnp87MeUSQOAdmc9PO5R5erV1Qk88gMq4cX73DfXvq3uTFjtVCPCmtspC7XsjyR6uJcy93Ha6fw/oDy/RmI9dAzvUjRQuZMQmP+8Hjjy8+YaAeCxK+m8z/yGZvnV1NGYZh9K5dQF7zBuFWBaG9iE60g8Nc4y/ch4v25L+HIJiycl1E6lEuSpPwfe+1P/Mftx1AXA6b+h57YTFoqY/+zMXagGgNWY1RZhze0U/H/bf9HraLP52bAoCgSAhccDb/7L/D/auYqcMLvsyKVWwL9Za8gzCzAUyZ8JO+aL1G4h0gTMcZy4cD2VX2cvJsF30QvAl1bSBAbvsYvFLisWLEc645z/NuDyHrfIrXbe8RXpvTXJERFWIi1T6K/Nwd4Cjkm1OWHbVwIPfKvwUjPDwQ5Yoc7tE4nrTqey1mbnr3Z2wgotrAxYgXTn+2ie6yyyPUB5IQDo22bEnM6QcGuYTu6B3Zi0YSaFxKPNZuo+O23Zm7GmG1xigARW/XRqjgm4XSnORm19hW7CPDOS80+PfN9Z+kYDb/k09bUK1eb27qqbagRB7RRqn5EcoLG+4xLazjMDOT/HgXabGo8TVtNA/7EIC9a43ZW6VrqJ2i4ZC9ljv0aOEHPYx6nE+ME/uMs49qxOLoNx4HnqQnNuFkF2WZRLWHyMuql07CWfdGe4huM936MZooBbhAZryM0JRYyIBeg7YHEG+M9CfNflJC4AI6BsB2ve0fRvjJ2+zlXO8kSefmDsAPr1CfOG43OC+da43vUtYMHbgQ9cDZzyI9rWutD9s5i6J33P7/gK8I4v515TMURLFGHefNtEoL6NOvsLkxYRYSUSitIvMFWoeWa1ZcKe+Dnw75+7FwHe8QZw/3+TO6K1u7TkR3btvXF2wp6/nmbWPf0b4LpC68EXYOcaI7ZY9HDfrOGcMN4foNJQ294Uwt/+mgnC927KPU5dK92U7O1c+mrZw7RFYKft3d81+9XUk1Dq6aDP8M3UFvmzF1Nu5v5vAL85xggMe8Yan2PqnsB//JZ++fduoRs2i5C6VhKMUDSufU6i6zz6AuDg/6R95h5Bj/xvhkWhfa693uV2gmoayJlJDtA43/IZ4ID/MO9Hmmghbptd6+g4x1/qFh1LPgVcuMwZp8UhH6ES1uceA6bOp218g25daDl5jlNiz8zk62dnra4MJSKXExY1gssWYaEaR4RFSWgM1yKFRaUtihodUckze3e+Sf+evVnFNufn5Jod6QgXb5g9HC08OxKglSBmHkSuoV8eDKDy8X6n5b+eQtjZrkLlSB6nhNuFCYgsh14iAeev20CygAjLLuBdBU5YKmHWL+x6w8kO7QL+93Datvhs+qV980eAC5bln+FULZmw1/9JWamF7wQ2Li398/3bKffCcC6Ig/lD3SSopu3rH5a1Wzs0zaEbxa71tMQNQHmtba/kukN1be4y1P6nmVLk/u8HHv4usPpB4wTNOgQ48TsUnl91L33vvZvouNEWuvHYIqKulX52XM7jsqc93m3OLE0WB42zSEilYiTMhnaR+GjZA7hgKd1YlQIueh5o3oMEwvlLSQg+/yczm5Fv7g0zgDP+RN/JjEV0PQCJrlCNEQV1rcBJ3ydB+tLNtC3aRJ+PthiBXGrPp5o6YP9T6fmMg2g2JOeF7ExU214kiOxlxbJO2DwzxtHicsIcFyzoKUcGnW3BmuLKdt5yJGDEKC+6zv8uvEvkTNuHZjjbf0iww1Q/zZ2nC9V6FpoOk5N7zBdzx/SBq91lYS/e3FmxlFqOLLSPIFQp4oSVSLimBkO6BsFiRNhI1478x5eofFgO1j5mfjmzc7H0D+b9WDeFyQET/PbSu9lywspYjhzqLl3U9W8jV2iH048q4wl5D1dyXXUvOSyf+AeJgo3PAH96n3ER1v8b+PWRFLz3g8uRAImVSBOVzbatoLLhgreTeODZgkzdVONYAMBpVwFHOculHnMRldfuu9Qcv66Vtr/neyQu2AlrbqebI4ewmWiLu48UizDbbeJyFYuhxlmmpMhLvbD4aNvbiNAp880Nedo+FNpm8QkYJ6xhOmWYZiyi11yOZOFw2Mfokd+vaQTgnCPSROfzNscc6Uy3U35MgnDWIfSaj3vs10hwep0uLn2xWKv3uGwjgcVuMELXFqzJXT/QzooV4+T4lSNtR9B2pLxO2HFfB/Y71b30EztqU+YB5z9LzieQ64QFQsD/e5HKs172PrFwSW2k4sjunVXoGOySiRMmTECKEmFKqXqlKH2rlNpHKfU+pVQBf3j3JRxQ6EcUgUJiJFuOHKEIe/0+CtoWQyZDJcV8bHyGgtPhenPDXXmXmWU1tMvcsLmDuM26J4Cf7g8sv4les2hKxakcuPkFs+/Lt+auNViIGz9EwgOghqe2OMwHtxXgv9q5LNy7Gfjt24GfH2z6Z/VvN+NmeHxzjyTh8drdwNpHjfvCj369vwDHRXCEQ8tcEhrxPhJhMxYBLfPpPRY8TF2rFRxX7gxOKEIltx2vk8MEuJdeqWmgHmDJQRM69uaUos3AdBY/TUZE7vdeyhPNOsS0aGBx1DTLlOjYAeJZjMNRO9Vkttj18woXdoJYDBzz/4AvPA2873/pdSBAYwmETGuGd10OHP/f1nlGKMJq6tyNNheeAFz4PH3PPH7X9TjnadsbOPOm8jTp5J8xC51QJNcVCtYYAZZv3UwbFia2E2aXgeccbp57nbCGacCZN7r/bbFwCUZITPOxvJmwwCiKJiPNatlOdKFyZLQZOf9PCcIEoVgn7DEAUaXUHAD3A/gYgGsrNahqJhQMoF/XIpTsy7+THcwvNQyfSlDZydv9PB//uoK6q+ejp4McmNaFJMK6NwBblhtXonuDuTn7dSx/4yHnOM5MMnbEejqoLMguWs8m4LZPU7PIYtCahAqfc/lNwPIbC34EgOVEOd8ri7B/Xkqh954NlH0b6AL+dBrw9/Pc32X/VhJEoRpnvcE8Px+7QanN4A7jNjTPJaGRilHAf8YBJuc1tNPtVtVb5Uhuh2Cz6HRyaDY+Q+U7V56q3iwOzXkivlme/lsSNcEQcORngY/dDux5rBFXLG5a5pnZuizCGq3ZhPPfRuKjmPYLgLtcN2UeiRpv7yivEwYA0/cHmq1MVKTJuGAA9b06+MPm/XL1fFKK/h/Ijt8RYSwu7PPsd0p51gzknyELL3bCAJoo0DiLvptwHa0rWsx37+eEhSLGyXP1IPPpX+eFHSYWYyzQvLMjR1PqKySgynGMfU6m7vbelR4EYQJQ7J83Sms9qJT6NIBfa61/pJRaPuyndkNCQYUB1KIpVaCMlrSyYOlkaZmIno0ANN3s/34+3eRP+n7u8dMJem/F3ymbE++jzt8bnwGOONd9vOZ2+gW1+XkjmhZ/FHjuWmD1A3S+QMhfhHkba2YXknZKnLvWAr97p2maabd6CNebTM66f1P5jkVK/3YSq/b+g1ZWxY94f+7EgHg/tXdYeRet9bZlOXDvVyk7xuxcY35B920zjUMbPS0NAmGzALF3bURmYAflvqbMozIMO4GJPspG2TP0mueYa6prNeVIv47egSC1IrjzQroR2i5AuM4IKHbC2HXa6wRTjqqdQjfyTc/R98GfBUxfp4aZpnw4xRJNNQ3Avif5X7MfLGJUkM5x3uO57hKLkEKLE0cazb8Rxs5SVarxJh+3aQ45wJXosh61ypEAlYtZ3F2wFICidSsTA2ayw3BkRZjHNWuYTi5ubQu9523Kmg8+jp0NA+j3lv2HQkuBzNew57CcsGhz/hB/IQqWI0Om7CwIE4xinTCllDoKwEcB3O1sG6bb3u5JOBDAAKIIFipHshMG+IfzYz35Z07aJcHlNwBP/zp3n/u+Dlz7XhIXHI7e8Tr1qLrnYtNuATAirHUvcr12vknlyVmLASgjIuYsMRkfgGb8Pfm/uTkxbn3AImzt43TTf8ZZwqdxFv0Cv+ow2van04AXbgRuPovaJGSv03HWuNlorIdcrqT13Xnxc6diPfR9AMB7nKVubAEGmGVpAHLCeAkdb18pW0D5lVW1JhHWNIu6ps89wt2GYeoCEjl8Y2NXIlxPN18+Xz5hcfCZJAq8a/DZmR92wloX0n5+6/Ut+TRw/GXUdZyzXnxDPvSj5qY472jqzeW99mJgERZpJMHY3J4rtmoa4OqB5Ue0ye36AcWvszga7PIjYIR5OfE6YR/8HfC+q+h5IEjl2BkHFC/AACuY7xElXEaOtpjn3nKkHyGPE8bubaLPvWzRFI/LWQr2WM+5Gzi3yKiF6xiTMv0iTAKKdcK+COBSALdrrVcopfYE4LP42+5PKKjQp2sRThXRogIgB+PlWymrMXUB3ch/+3YKx57wzdzP7vLJZXnpXEWlt1fvdG/j0ufGZ2j6eCZDZcJFp5MTojPU/bx+Ov3yjTaRU6MCVAZ69mr6TCAA3HsJ8OJNuefOdol38kAsAnlWXzpBIffBHeS8rX2M/vqN9biX72GxGesm0cbH7ekwN8YNT1P2bE+nQ7wdimcev5JE17u/S24czxoMRYE9jwdev9ed7+rbZmbzeZ0w212wnbBUgr6PxR8hp8wuM9qCYcoC+u4+fge5c7MXAyvvNKW7SBMJknzCIlQD/OcNuU1+j/gssPT39JwF2dEXAYef4z+Ds24qcOwl7m2HfYwmDLzd6tmkFHDyD4ATryh9Bhu7XtGm/Ptw5ssuR3o55Kzc6w0EzYSHSokwFpF7HEXf5fy3l/8cfl3wR0u2RYUnZ8VivLaFhHf3emSzi4Vgl45FDjuCiQF3OZKd1JEQCJKg0+mRL1QtMx+F3ZSiRJjW+lEAjwKAE9DfobW+qJIDq1ZCASpHhtMFSme2ExbroaxUqBb4763UEqF7PbDtVf/P2l2888GLAj/9a+p5NLCdRFhzO2WR1v+bRNjAdhINze3G6dj0vJnJVDuFxlc/nQRiOkHj69/mL8AAE8znBaq9DHSZBas3PU+P3BC1cxWF5gNBU/qM9ZiSJF//6/fRMbh9ATeqZGHEv9ABEmqNs2mJF4Cuc+caCoEf/3Vy5FiEZTJ0beyE8bT6066ijvIHfgD41wr3dwzQWJ77I/0HeMLPlhM2xXG+9ngr/cdiPFu6c5beKXRDm3NY7rZp+1KH8p1rTIkoHC0uyM00zTaNNb2MpIVA1gkrIML4/UJOmN9sO/5cJUVYrTV+FvnlJjs7sowCor7N9ByzsUvSbzmX/hArpoRoB/MB87OK97tF2Gj7pgVr6PeiiDBBcFHs7Mg/K6WalFL1AF4B8KpS6iuVHVp1opTCIGoRThcxOxIwpbDUEAmQLU7H9HyLGHevz52h5i1d9jlluf5tFCJu3YsEDpcI1zsz43o66LF5rvmFnBoyDhCHeRtnmvX1ulabJXk+cguVv8KWk8GZrLglwuzFdQd3mK7w7JJxk9hUzHwftti0n/dsBB7+HyPAABJ2fL2AyTQB5KTZs724bMLLtEzd04iwoZ0kSrn0tM9JwFl/oQ7sX15pzS5sdjth3evM8yWfAuYdZV671gf0WfpFBd3j+9jfTNm0FD7wO+AzD5X+uUqRdfcaC+93yo+MQC4FnulWaSdsuPGPBj52OVsnLPkU8On7c3N0LMKiLcDBZwDf2FGce5Xt1O88cvm6be/RzYjMOY8jogrlA/049Gx6HG6tSUGYoBSbCVukte4FcDqAewEsAM2QnJQMqjpEComw1JD5y43bQgBAx1LjEuWb/bhrnWnIydhOUbyf8hrMvidT4HfHKlOu2/w8zTxk8dPcTmKK1/hr9GSTGmcZ0bLtVWr4GWmmJWu+9Kp7keTkIDlKduf3GQdQRurwT1LJy16axws3NbWzb/aEgB2r6ftb9H7glCud63FyawOdABS5RfZf1PZMPZ6hN/NA83rXOirVcs6LnbBgiMLoXNKbuoC+o71OMH25Hvux+Zl96n7g5B+7r6eQE6ScPJQ9vmjzyGbeKeVfehwvaosUMfu9l8qypcIiLFqBwDxgjb+I3NRICQSpF1o5RVik0T+EPn0R/bHEucNiM1TZcqTz+6p1IfDJe4GTf1Re4cPHL9UJO+0q4Otbht9PECYoxYqwsNMX7HQAd2qtk/j/7J13fFv19f6fj7YtyfLe207iJM7eg5AQAgkrbAijtFBGgZZSfpTRltLSQgtll7LafstICykzlJAQCEkgey+P2HG8l2zZ1rL2/f3xufdKsmUn8cjivF+vvGJLV9KV4liPnnPOc/qc7T/76VZEQR1w953P5XP33q8H8LgHSaA428IdM4CLG3M5d3pCl9B2hzTaS26QQsV/wefM5cdbqrhAmvNz/gb2xS+Du/JMmfyXsiS+5AZxyQlL4Z+k9Un8Ni0lPPNKetPv6UZ88KOgMAH4J+7C87nr5Pf0XlIdyoof8InOtgoxrBPhIuzIOt5fNmapuCaHcWeufidQtooLmoW/BX74v+BtQp2mUUuAURcF87oSRnDXzlIVLDH21YSdPBr4ZRUXnwDw/Fhg3R/4Yu7oRC5GezoQxyrHTb89PDD1bCG0z2040Jn4ffd8vYeKhELuUg6m1+l40MWcnJ2GIxcDD1aeuHPY0wkD+MCGJjoowoaip02p5Y75iTbYK5Qn7p4RxBnE8Yqw1wFUA9AD2MgYywHQR1PQ2Y+Lib8UQh0pjwN4vpgnsnu7g5/k2ysBMP7G31nDxYtk8/dMVe+q4w5M8hjeQD31Vn55qBMmrdlZ8jRw43+5zR9anksq4o3WNZu4i1OwMCi2pB6oSE4YwB2tlgN8IlIqzYUeJ5UdSz4JXx4tp4yLYsjvCe+bAnhP3Lhr+Rvrqv/Hy7FFF/HrJFcsJiO4didpNH8DSxzJnb0vf82F1MQbuGBMnxyc3gp1mgrPB5b9J5jwPvpSftzut4LlWWM/k3BRcb13Evrdfb9ZS+XIoksiX7/wN1wYnm0MdzkvJj38g8hQkzQSeLimd0L/UGNIHp74i54wNjCxok/k7m+kDQEaAy8lD2SasSdK9cD7wQjiLOa4RJggCC8JgpAhCMJFAqcGwIJhPrfTFpdCLCe5QyYkLVVcRJV/wXufZBF2hPd4SWWxjuqgQJFKkm477xeTBEjyGN4kPvkW/n1o5IRUUsuZE+xNSgwRYYYkYNLNwMy7ubha+tfgdbE9RJjk1kk9aCnFfN+euyu4Wib0uJ5xCHG5PHRSmiwLnRrsKUqMqXxEf/7DwbLpuGv435ITNu224PFSllDObD5hWbcdmHkXcMET/HLGgqWknit8QolJ42Jvz7s8/T8q/tjuR9oEIHM6cMtnwecRlxP5WJWWJ7FfdRxp/2cTx1uOHCjn/xa46aPhuW+J4ewHk7j6n3wH6OlKTDrws728BN8TxvjUccrYwT+OSjs0AbgEcZZxvI35JsbYc4yxneKfZ8Fdse8lLoX41D0hIqxT7L9q2B0uwrpqufiJyRB7mwQuLAAeH7Hyp8BTGeHlw+TR/G/JbYhUjjSGNO8nFAb7vQwp/Jfn4qeA+w+Fp0hLTph0WS8nrDh4bOa04NfScfoeYseQypc7S7/AezpSAF/8DATdp9GX8r8TRwKp4/nXkgib9IPg7aVG3vHX8jKr4O+dKC6VM481uTX5Ft6rdvBDHklwrN4qfSLw47VA3jwe3QH0L9wSCk5sUvFsICqO//uH7qscSnSm3jluZyLx+af/84jLGf5+Q6WGyooEEYHjbbj4J/hUpLRP5GYA/wfgyuE4qdMdj0L8ZeIOKUdKTfAtYq9U6B4zKbFeykPKng3geaBhJ7D7bX5Z7TaxFyw7WOKS3IbP7uMC7pLneTlSqQ1vWFbruEiwVIWXFXo21mbN4II3G+PjAAAgAElEQVRLiquICpmOBLhjNPtnwMgLw5t/ZREWYV9hKPoQESY9RsZkLkSlx4jN5hNPaRODj99Zy0u0+kTgspfDp7KyZvLbONq5OxWK5IT1FIc9yV/Az91h5tERJ0KGKMJi+3DCvq8oVVzk09QacTwoNVSOJIgIHK8IKxAE4aqQ73/3fV1bBAAupeiEhYqwnvleBecBh8RyiikzvL8lZQwXNtJy6REX8j2MXmd4GVCjD4aP7l/Be7K2v86FWs9PromjuKPUnyAZtRgYVRb8vnARDwKV+r90pmC5L5Q+RViPpmypLGhM5/cVl8fLps37geSQksbSV4Jfq6P589aZ+HOa/IPw+1QogMV/5plnPfOspHJSqAMXCaUKKL6KJ/hLLuTxkjObl2SGYqHz2cZwNc0TZx8qbdCtJwhC5nh/i3YzxuYKgvAdADDG5gDoZ7/M2Y1TKb7571/B+6FUGu6ERSfwslf2bF7KkkgdH+yHUIhTilN+BHz3HC8ljlkKVKzhK4WkXByAi5KAOIHpsQM7/8EdpHMf6n1SoxbzDKwTcSZi0oCLnjn2cZJj1bPs12vdjAG4/FX+mjAG3Cfq9Ek39j0hposVRVg/zctSA39PNMfREyYx5z5+XPqkYx8bikI5sJwrgiCCzL0/uFWDIAiZ4xVhdwF4mzEm1Z86ANwyPKd0+tOizsbqmKuxeP97PLZg6q3cCUubwOMTkkeHTzRmTQ8218dm8zf2BY/yMNO8ecEEewDIndv3Awd8vOE+kiiZ8kP+ZzhIKuLiT+oTU2r5xGCklTUTb+h9WX9ra4ypfEp0IGPwcmP+MZwwgJeDz/1e5gsTxKlnxKJTfQYEcVpyvGuL9gGYwBiLEb+3MsZ+DqCfVM6zF5VKgeXRt2OxchefhsydB7RX8ZKVFEwZmrsTm8MjGoDglJ1SDVzzL/61NGWpju7bqZFctp7N6SeD6Hjgzg38a52J56C9t2xoMqIWPAosv5ovID9RNEYAbPhS1QmCIAhiGDmhpg4xNV/iFwBeGNrTOTNQKxTwBgSe/7TtdaBCjJwI3dUWWn5jjPdTKbXBtTqhaA388vi83mGGd6znobDbX+fTlIak3rc/mRQu5DliQP/Lm4+XEYv4Gp/QKc7jJS5HfM2oN4kgCII48xjMu9dptEPl5KJWMbi9AZ5SvfVvQMo4Hso4cnHwIJWO93+d9yv+vUIBXP9vHhIZievejZxbJDljaeNPn56KxFHAgl8DRZcOzf3Numdgt5v7C16eJQiCIIgzkMGIsO/t2iKVQgF7wM/7txb9nifB98wCUiiAx9rCLxtxft93mlrc93XA0O6fGywKxenRX6XS9J6YJAiCIIgzhH5FGGPMhshiiwH43sYfq5UMXl+AN9jPue9Unw5BEARBEGcg/YowQRBOwl6PMw+VQgFf4DQpDRIEQRAEcUZC6XkDQKVk8Pm/t9VYgiAIgiCGABJhA0CtVMBLThhBEARBEIOARNgAUCnICSMIgiAIYnCQCBsAapUCXhJhBEEQBEEMgmEVYYyxxYyxcsZYJWPs4T6OuZYxVsIYO8QY+/dwns9QoVYwaswnCIIgCGJQDFvUOGNMCeAVAIsA1APYwRhbKQhCScgxIwA8AmCOIAgdjLHk4TqfoUSlVFA5kiAIgiCIQTGcTth0AJWCIFQJguAB8B6ApT2OuR3AK4IgdACAIAitw3g+Q4ZKyeDxkxNGEARBEMTAGU4RlgGgLuT7evGyUEYCGMkY28QY28oYW4wIMMbuYIztZIztNJvNw3S6x49aoYCPRBhBEARBEIPgVDfmqwCMADAfwDIAbzLGYnseJAjCG4IgTBUEYWpS0ileYA3uhAUEIBCgkiRBEARBEANjOEVYA4CskO8zxctCqQewUhAEryAIRwEcBhdlpzVqJX/ZKCuMIAiCIIiBMpwibAeAEYyxPMaYBsD1AFb2OOYTcBcMjLFE8PJk1TCe05CgVjIAoOZ8giAIgiAGzLCJMEEQfADuBbAGQCmAFYIgHGKM/Z4xdpl42BoA7YyxEgDfAHhQEIT24TqnoUKl4C8biTCCIAiCIAbKsEVUAIAgCKsArOpx2WMhXwsAfiH+OWOQnDAqRxIEQRAEMVBOdWP+GYlKSU4YQRAEQRCDg0TYAFApRCeMYioIgiAIghggJMIGgDwdSSKMIAiCIIgBQiJsAEgizEc5YQRBEARBDBASYQNApaRyJEEQBEEQg4NE2ACgnDCCIAiCIAYLibABIOeEUUQFQRAEQRADhETYAAiWI8kJIwiCIAhiYJAIGwA0HUkQBEEQxGAhETYApJww6gkjCIIgCGKgkAgbAOSEEQRBEAQxWEiEDQDKCSMIgiAIYrCQCBsAGhV/2Tw+csIIgiAIghgYJMIGgE7NXzaX13+Kz4QgCIIgiDMVEmEDQKdSAiARRhAEQRDEwCERNgB0alGEUTmSIAiCIIgBQiJsAGhVVI4kCIIgCGJwkAgbAAoFg0apgMtLThhBEARBEAODRNgA0aoV5IQRBEEQBDFgSIQNEJ1aCbePRBhBEARBEAODRNgA0akVcFM5kiAIgiCIAUIibIDoVEq4yAkjCIIgCGKAkAgbIDq1khrzCYIgCIIYMCTCBoiOGvMJgiAIghgEJMIGCHfCSIQRBEEQBDEwSIQNEK2KcsIIgiAIghg4JMIGiFZNjfkEQRAEQQwcEmEDRKdSUkQFQRAEQRADhkTYAKHGfIIgCIIgBgOJsAFCjfkEQRAEQQwGEmEDRKdWwO2jciRBEARBEAODRNgA0amU8AUE+PwkxAiCIAiCOHFIhA0QnVoJAHCRG0YQBEEQxAAgETZAtGr+0lFfGEEQBEEQA4FE2ADRqUQnjEQYQRAEQRADYFhFGGNsMWOsnDFWyRh7OML1P2SMmRlje8U/Px7O8xlKgk4YlSMJgiAIgjhxVMN1x4wxJYBXACwCUA9gB2NspSAIJT0OfV8QhHuH6zyGC7knjJwwgiAIgiAGwHA6YdMBVAqCUCUIggfAewCWDuPjnVQkEeam1UUEQRAEQQyA4RRhGQDqQr6vFy/ryVWMsf2MsQ8YY1mR7ogxdgdjbCdjbKfZbB6Ocz1hdCoqRxIEQRAEMXBOdWP+ZwByBUEYD2AtgLciHSQIwhuCIEwVBGFqUlLSST3BvqByJEEQBEEQg2E4RVgDgFBnK1O8TEYQhHZBENzit38HMGUYz2dICZYjyQkjCIIgCOLEGU4RtgPACMZYHmNMA+B6ACtDD2CMpYV8exmA0mE8nyElLloNADDb3Mc4kiAIgiAIojfDNh0pCIKPMXYvgDUAlAD+KQjCIcbY7wHsFARhJYCfMcYuA+ADYAHww+E6n6EmyaiFKUqNsmbbqT4VgiAIgiDOQIZNhAGAIAirAKzqcdljIV8/AuCR4TyH4YIxhqJUI8qbraf6VAiCIAiCOAM51Y35ZzRchNkQCAin+lQIgiAIgjjDIBE2CIrSYuDw+NHQ2X2qT4UgCIIgiDMMEmGDYFSqEQBQ2kQlSYIgCIIgTgwSYYOgIMkAAKhud0S8nsqUBEEQBEH0BYmwQWCKUsMUpUatxdnrOp8/gNl/WodffXzgFJwZQRAEQRCnOyTCBkl2fDRqLb17wlpsbjRbXVi+rRZrDjWfgjMjCIIgCOJ0hkTYIMmOj0ZdBCesoSMozE5EhP1ixV48teqMyaw9Y3D7/NhRbTnVp0EQBEEQMiTCBklWfDTqO5zw9+j/aujkwiwvUY8D9V3HfX87qi3YU9c5pOdIAJ/ubcQ1r21BUxdNshIEQRCnByTCBkl2fDS8fgHNVlfY5ZITdsHYFFSa7XC4fcd1fxa7B11O75Cf51DiDwh45ZvKM2plU6MYI9LY6TrGkQRBEARxciARNkiy46MBALXt4SXJhk4XEvQazMiLhyAAhxp5jIXF4YHb5494Xy6vHw6PH53dnmE51311nbjtXzvgGeTS8b11nXhmTTk+3dtw7INPE9rsXDCeScKRIAiCOLshETZIchK4CCtvtuKtzdVotbogCAIaOruREReF4gwTAGB/fScEQcAlL32LZ788HPG+LA4uvjqHyQnbcNiMr8taUd8RFIy7aztw0Yvfot1+/OJkVw3vrYo0FXqifHmo+aT0arXb+WtrtpETRhAEQZwekAgbJJlxUShI0uOldZX47cpDeG1DFWY+9TU2HjYjIzYKyUYdjFoV6ju60e7woLHLhW8r2lDZauslfCQR5vYF4PL6xa/96PZEds5OlBaxZNpiDT7un78oQ0mTFd+Um2F1efHKN5XHdMp2VncAAKrbe4uwwy02+dyPh199chAvfV0BgAvC/fXD0w8XyQnbX9+Jib//kvrETjP8AWHQbi1BEMSZAImwQcIYw6UT0mUB9e/tNbLI0aj4y5tg0KDd4cHRNh7qWtZsxeWvbMYfxSnIP/yvBO9srUG7I1iGlNyw617figm//1K+vLnLhcpW+wmdY7fHj921HfJ5tYpu0K4aC7Yd5S7Upso2/PTfe/DMmnJsP9q3MyUIAnbXchFW0yOk1unx4YLnN2LR8xsiBtW+/HUFVh1okl+DkkYrzDa3LA4fWLEPj316qN/nsnJfI/68uqzfY9YcasalL38Hnz/4Rt4mOmGtISJs42EzOp1eHG45sddTornLFfYYxNDw1KpS3Pj3raf6NAiCIIYdEmFDwGUT0qFgQLxeA5c3AJ1agem58bhiUgYAfrnF4UaVmb/ZCwJgd/tksfPfXfV4d0sNLI6gQJD6wvbWdcLjC6BE7Cn7/f8O4Z7lu4/rvOosTqw60ISX11Xg6lc3o6yZ34ckej7c3YAotRLnj07Bx3sasOGwGQBgdfVdDj3cYkeb3YMkoxb1Hd3whogQSWTWWbrxwe76sNsJgoBn1x7G3ct349kvy3HZy5uw7E3+RtvU5UJzlwtH2xyoaOl/IfonexqwfGtNv897y5F2HGjokoUxENkJO9DAp1Zbrb1LlA63D4Ig4NO9DRGdPavLi/l/+Qb/3VXf67qhoM3uDisbn2pcXj8E4eRsgKhqc+BAQ9dJezyCIIhTBYmwISA/yYAv7z8XT105DgAwMz8BK+6ahfmjkgEA8Xot2u0eVLU5oFYyKBi/XX1HN6rMdnR1e1HeYkOVOegsNXR0h01Uvr+jFgBwpNUhT/r1R32HE9e+vgV3L9+Nd7bWICDwxwN4OdLnD2DNwWYsHJ2MC8emhN021JHryUd76qFUMNw6Jw/+gBCWhyaJMICLx1BsIc/l5XWV8PgD6OrmYs/m8mFdWSsAHHMhep3FCavL1+dwg/TcAcAsCi+X1w+byxd2GQA5OqS1R7N+ldmO8b/7Er/+5CDue28v/rnpaK/HqGy1w+UNoOIYLtqnextwsCE8omR9eSv2HSOG5IEV+3DXu7siXicIwoAFiiAIEXPt+qOr24spT6wdktDhylb7MR/f5vLC5Q30+3NIEARxNkAibIgoTDZgZl4CjFoVLipOC7suQa+BxeFBldmB3AQ9frm4CA9eOAoAL69JhL7J3fbWTtwd4nitPtSMQEBArcUJm9sX1ifm9Ph6CZc/ry6HtdsLo04lCxCJZqsL249a0O7w4OJxabhiUgb+cctUbH90IQAekwEAXn8Ay7fVyE6QPyDgkz0NmD8yCVNz4wAANSFvqEdFEVmYbJAFn4TkNr14/UR8es8cvHbTlLDrPwmZtDzcYkMkBEGQ77dNbrR3Y1eNBVVmO/7+bRW8/gDqLOHHSG/mSgVDebMN/7fpKFptLjR2ucLOTeJgoxX+gIDl27jwjdSfJD3XSP1kN/9jGz7cVQ9BEPDoRwfw+saqsOfwwIp9eGZNecTnCHARsvlIm/w8evK39Uew6PmNEAQBLq//hETVqxuO4JynvzmhpfM17Q44PH7srj12v15pkxUd/YinB1bsxeMrD+FXHx/A4ysjl56ln9eeP0NnIzurLfhG/ABCEMT3DxJhQ4gpWo1tv1qIa6Zmhl0eb5BEmB35SXrcdW4Bbj8nH1qVAiv3BkVYz96kLUfaAQDTcuPQYnVjS1U7ukVBtPVoO7ZW8ev//EUZ5vxpHTaK5cSGzm6sOtCEG2fm4Edz8hClVsr9aQAXHVuPWqBgwDkjk6BSKrBwdAqSY3Qw6lRyWXTl3kb86uODWFvSAoAHybZY3bhicgYKkgxgLHiOAHfC0kw6jEwxoL7DiVabS3asmrv4fabE6DAhKxaLxqQgyahFXLQaALD9qAXTRGH3x89Lsei5Db32brbZPfLzl8qKT64qxY1/34YXvqrAHz4vxb3/3i07YW3iMdIARGGSAW5fAL/7rATPrw1OqPZ0wmrawnvdXN7eIqyqjf9bSUJOoqvbi28r2vBlSTNsbh8cHj+q2xyye1Vn4QMaUmla4pk1ZXjko/3wBwR8W9EGr19AV7e3l+MnCAJW7KxDZasdrTY33txYhYte/PaYvWk7qi0Y//gaPL2ai79dNR2o73Bi8QsbjzmY0CQ+x6NtkRfVh7LkxW8x6Ym1fZa0m7pcaOjsxuYj7WE/O6FIIqxhGESY2+fHW5urw8rop5KnvijD7z7rvw+SIIizFxJhQ0y0RgXGWNhlCXoNfAEBVW0O5CcZAPCm/QlZsagS39jGiVEW8XqNfDuP+EZx1WQu6t4N6YV66IP9uGf5bgiCgO3itOL97++FIAh4bf0RAMAPZ+fivoUjsOGX81EoPq5Bq0KL1Y399Z0oTDbAoFX1OteSJiuufX0LXtvA70dypr4pa4VayTB/VDLi9RosHpuKf2+rQWUr7+Piz0+PrLho1Hd0Y9FzG/H8Wj75KPWhpcboAHBX6p3bpuOVGyfLj33+aF4WrWpzoKLVjk9FgSoIAne4Qnqk9td3YnNlG74pb4XLG8CuGv4arDnUAofoEkp9YNLfKSadfPv/bK9DslGLqTlx2H7UgsUvbESzJDZ6DBy02d3YVtUOjzi1+vTqMnxTxgWvVBoOBASc95f1eGYNHxoob7bJ91fd5sC1r2/Bz9/fiz11/Dwbu1xwerjYaLe78cbGKvxnex2eW1uOr0uDzkjPXLPyFhtqxKnU0iYrSpqssLl9cpn18/1NmPHkV73Cgb8qbYE1xBE9UN+FA/VdKGu2Yf8xNjo0ic/xWCIsVNi89BX/d/cHgqVTQRDQ4fSg2cp7APsSf5KAk7ZOAMAXB5rwyw/29fv4AP+3+temo332Fa460ITfrjyE7yrbjnlfw43PH8Chxi40dbmo/40gvqeQCDsJSMJKEIBRKUb58ik53PnRKBV47NIxABDWTC4xISsWBUl6fHEwWK5stbnR7vCgze5BpzNYdttypB3Lt9XgphnZSI+NglLBkGzUoTCZi7DijBi0WF3YX9+FCZmxEc91R3UHth+1oEKcwixv5iJsXVkrpufFy8Ltjnn5sLp8OP+5jVi+vRZVZjvyEvXIjIuCx8d7vlYdaIIgCGgRJzKTY7TyYxWlxmBydpz8/cz8BPx4bh4uHp+GR5YUwe72wWxz47FPD+HC5zdityi0AOCxTw/hhr9vk6dIGzq75ddTQhJfkpNz29w8LJ2YjivFgYkfzslFZlwU2h0elDXbsPlIG1746jAONViRmxAtC8ad1RZc98ZW3PXuLrz0dQX+tv4ISsRyXpvdjf/urMPe+k5UtTnw4S5eVq2xOGW3y+b2YUd1Bz7d24gHVgSFhCRqPt7TAK9fwKTsWLy9pQbflLciQfyZkUSYFNuw9lCLfPuy5mAfobQJYEtVG1qsbnmCVWJfXSfGZ5qw77ELMG9kEvbVd6JN/FmLNJgQSlOImHxu7WFU9yHGQvPtDjZyYbfsza248tXN8PkDsLp88PoFdDq96Pb6YXX5eonFQECA3d3bCfvf/ias2Fnfy2F7a3M1zvvLelkALt9ai8c/K5GHLnoiDcNUtkhDMgK+ONB0SpyxCrGv0O0LRPx/TxDE2Q+JsJNAgiEoPEakGOSvp4qiIS1Wh2m58bhwbIrcKxZKSowOl03IiHjf++o60dTlkgXIHz4vhValxP2LRoYdN0IUYROz4uRf+uOzIomw4Lkum56N2QUJ2FffiYc+2I+KVjsWiMMGADApOw5v3zodOQnReHNjFawuH0alxiBT3CIA8EDX7yp5f5NRp0K0Jtx506mVSNBrYNCqMDY9Br++ZAxeuWGyHHJ7uMWG/aLAeTLCYnOlIug6LhydjIzYKPl7qSfs490NyI6PxjmFiXjx+kn46cIRuHh8Gm6ckYPkmKA79tqGI3jhqwqUt9gwMz8BWx9diAWjkuQ8tHVlrfjb+iNhbqUgAA9+sB+/E/ubpHKpIAAbK8LdFo1KAV9AQJRaCQA4IgqoVQeaMCHThHvmF8Lm8sHi8OCqKdz9lEqlT68uw+WvbEJJkxX5iXqkmXQoabTKrp3kyEnxJTtCYkb8AQEH6rswMSsWpmg1JmSaUNFqR73YSxaaGxcJqeTqCwh46esKvNPHdKr0YSBKrURlKz+v7Uct2FPbiZfWVUYMBG7qUc51eHyQTKG3ttTgZTFDThKsh5ttqLM48ckePvDwh89LUNXmkIODJadxcx+lTimSpaKVf7D4tqINP1m+Wy65HwuvP4Clf/0Oqw8OfkghdKdsz9fhRGi3u/HO1pphcdMONXYNWU4hQRC9IRF2EpBcDQUDCpKCIkxygSTh8PrNU3HPgsKw26qVDHHRavxwTq58WYjuwJcl/M3gvCIujkqarBiXaUJstCb0bnDjzBy8eP1E3DQzW75sQqapz3PNjo/GU1eOw4y8BLRY3Xh/Zx1umJGNG2Zkhx0/b2QSFhenotbihErBcFFxKrLi+PNJFMXnzf/Yjv9sr0VKiOAJpSDZgDmFCVApgz+OI0XHsKzZhlqLE+MzTVApFUg0aGCK4n1kF45NwWs3TZEfJz/RgLmFieLXeqwvb8Wt/9qBnTUduGV2LhTiC5eXqMcrN0yGKUotP18gvCcvJ0Ef9hwA3pt3//kj8dlP5yIzLgq3zc2Tr9sX8oYq/ftsKDfLl2mUCux9bBGeuXo83rp1OhjjU5iCIKCixY7xmbGYOyIR0RollAqGa3qIsA2HzShpsqKs2YbcRD1Gp8VgXVmrPDQglfZk8ROyhaCy1Q6Hx4+JouguzjDBHxBkodIibnlYfbC3I9Rud6Opsxs6dfDfpq9erg7RCZuWF482ezD/DQC2HmmP6PY0dXWj0+mRBVrPIZJn1x6G0+MLydiz4Yn/leDn7+/FD/65XS79V7c5EAgI2CMOD2wSS9UvfV0Bs42LlBarS3YOJbG6SSxL9pxy9fkDeHNjFdYcag4TNxvKzdhX34U/fdH7A8GJsr8hOOhwPBPPffHxngb85pOD/U4Vh2J1efHjt3Yc8zG7PX5c8cpmLN/WfyQMQRADR3XsQ4jBIjknuYl66EQXBADi9BpMz4vvVUabkBULrVKB8hYbDFreY2aKUuOvN0xCp9OLF8U3FgDyJ/K5hYl4fu1h+AKC3F/W8xyWTuRu2sYHF2BDhTnycQZ+rvlJXIQUJAfFyJNXjIv4/BYWpeD1DVWYPyoZCQYt9GK5cmFRMoozTfhsXyO2H7VAq4qs+d+8eSqUyvA+uiSjFgl6DXbXdKDD6cUd89LwyJLRMNvdeOnrCnR1e3HRuDQsGpOCf3xXhTa7G4XJeoxKLcDYjBhsPGzGV6UOfFthxqgUY69hCYm+ktnj9VzoJRq5CIuNVuO/d82Wr//uofNQ2WrDP77rHV8xNt2EI2Y7Gjq7Ea/XwNrtRXFGDKI1KlwzNQsAkG6KQlmTDWabGza3D4XJBujUSlwzJRMdTi/yEvVgjEdyNHR2y315R9scmD8qCbFRGjnWA+DlyC6nF212N6LUSuyp7YTL64dOrZRLc+PF8nOuKDClCckWmxvfVbbhrnd346krx2HZdC606yxOnPfsenj9AuaPSsJ6UVSWNlvR6fRgT10nJmfHyaK4Q3TCpuXEYeNhszw4AvA+O8mZDKWpy4XXNhxBdZsTN83MQYX4PK+anCn3vK0taZEdxsMtNllsWBwevLxsEn76nz042uZAbqIDXd1eJOg1+K6yTe77ek4cwpCy9sZlmLC7thPnPL1OnkCtarOjw+HB5X/bhCnZcYiJUuNfm6sBAH+4vBg3zcwBwCNaAP5/uT8eX3kIJU1W3DkvHwtHp0Q8ZnNlO8akxaCkySqHGM/IS4DN7UVmXHTYsduq2rGurBUPLynq1XMquWgWhwcZsVEw291INkb+wAMA68vN+Kq0FWplCV7tMaUcitXlhccf6HNKtdXqglGnRpRGGfF6giCODTlhJwFJhIX2g0msuHMWHrggvAT56T1zsOKuWcgTy04Sl4xPx00zc5AsCoPCZIPcbF2QbJCXiRdnxPR7PtkJ0bh5Zk6vX+ZA0AnLT+SO3az8BEzPjce7P57e5/1Nzo7FNVMyce953MXTqZV48fqJuGdBIW6emYPfLx0LINij1RNTtLrXgAAAjEo1ygGy2fHRmFWQgMsmpCNRFIqj0/jzHJFshErBkB2vR16iHj+YlYsYHRcGV0zKwJr758nf92TZjGxcNTkTi8bwN8pzRiTiD5cX43Kxb0xywiRnLJSM2PA3ymjxzSg3UY8FojOZEqPDtdOyZGEjccHYFKwtbcHXopCSevZ+t7QYLy2bBJVSgQS9Fm9srMKcP61DaJ95boIeN8/Kkb+Pi1ajqasblWYuYG6YkQ23L4AvDvI39iNmO9RKhlxxz2mG6FT6xDtt6XLJ5cuVexvh8wfw13UVWLGzDl6/IL7GBnz1i3Pxn9tnQhCA+97bix/93w488b8S+TykcuTU3HgAwNYqfp9Tc+JgtkUOnz3Y0IUtR9rR0NmNP68uw0d7eE/d0onpWP7jGQCAD8RAXLWS4WBDFypa7Fg2PRsf3z0bl05IhylKjaNtDuwSB1R+fcloTM+Lx7PXTAh73T/cVY9ojRJLJ6YDQFgEyNE2B0qbrahpd+KjPQ341+ZqXIwlaAYAACAASURBVDohHYXJBvl1dHn9+Eocmmg9Rgn3/R112H7UIq/k6kllqx1VbQ5cNy0LGqUCn+xtxKMfH8QfV5Xg2te2hLlv/oCAX31yEK9vrMKhRmuvCJfmEBH2dWkrZj+1rl+XS/owdKwIEKk3L9LS+0BAwPQnv8adfWTZEQRxfJAIOwno1EpMz42X35iPl6euHIcnLi/udXmSUQu9RombxU/neYl6GLQq+dN5JIfreJEEo+SEJRi0WHHXLBSl9i3sVEoFnrlmglzuAoClEzOQLb7pF6XG4JElRXh52eS+7iIi03Lj5TeCrPhgr1eSUQeNUoE88fneNb8Ab/xgSlgMh9QjtLg4td/HSDRo8ey1E1Cczl+zsekm3DQzB1qVUryevx55CdG9bhulUWL7owvxrx9NA8AHC1JitBifYcJlE/gbfZXZjievGCc7YBI/mV8AtZLhyc95WSu0TC3hD4S7dJJmzkmIRrxeg58tHIERyQaMy4xFU5dLLqndPDMHeYl6vLu1Vj6H7Phoudxr0KrkaBAAaLG5sFMceth6tB2fH2jCX748jJfXVcqPGRutQWGyAZNzYjEuwySL49BhCakcWZwRA51agW2iEyaJMmmCValgiI1WI9GgwdtbeJCwVH6VMOpUiNNrUJCkx7dib905I5Kwu7YTHn8AcwoTMEks5+cm6nG0zYGvSluQGqPD0gkZWHHnLFw1JRO/u2ws3rtjJkanxcDjD2BKTpzsCF4/LQsFSXrMKUxAldmBelGUrbyX59j9+apxWFiUjG1VFthcXpQ2WeHxBZBo0PQb6+Hy+tHt9UOpYDjQ0BUxrkPqQVs0JkWegm6zu7Gpsh2NYoyHxOqDzXL59KZ/bMNFL34bdr10LhaHByVNVvgCQq/VZjXtDtH5c8IqhiQfayODox8RVi32IkqxOARBDAwSYSeJFXfNwrU93oiPxei0GNntCeWi4jTcMCMbt8zOxf7HL8And88BABSnxyBBr0FeYu839OMlzcTFTlFqb9duMNx5bgGm58Wf0G3mjkiUv84Oafa/floWHrxwFNSiqMiIjcJ5ReElnwcvHIXzRydjbmHScT1WjiiyRqWGv3ZJ/ThhAJAco8NYUcDlJeqx4cEFuG1uHuaP4o97wdjIIjDZqMMPZuXC5vbBoFUhJWRqVEISNeMyTBiZEnQ6pXP5xaKRWPuLc5ERq0NjpwtflbYiyahFVnw0bpyRjV01HShtsqLKHIxGkcgKeT07nV5sO2rB7IIECALC3Jsfzc7D8h/PwK1zeP+bVqXEynvn4Jv/Nx+PLClCVZsDF7/0Lb4ubUGH0wONUgGDVoWCJIMcvyINoOys6YBRq0JqjA6pMTq5ZJabEI2nrx6Pv1wzQX5co+hcnjMi+O/3wAXBYZPxGUHBn5+oR2mTFRsrzLhwbIrc+wfwYYiZ+QlyBt303HhMz4vHxgcX4E9XjcfXD8zHBWNSYXf7sLu2AwrG/98tLk5FtEaF84qS4QsI+K6iDQfFcuaiManocHrDGtb31XXKU6ZSL9zlEzMQEIJDElVmu9y79vGeeozPNCE9ZJAEgCyu9oQE424+0oYYnQpFqUZ0Or3wBQS8Kzbi292+MCdM+vDR0+XadtSCOks3DjVaZfe8w+ntdypU+gAk7ZoNZV89Pz+jjjpaCGIwkAg7A7l2WhZ+dTGPtIjRqWESXY27FxRi9c/nhU0Mnigz8+Px4U9m9epTOxVMzIqFQauCUauS+44AYE5hIm6fl9/vbWfkJ+Dvt0wLc8f6Y6ZYdp1dkBh2uVS6GxmhlCyRZNTi1xePxrLp2dCplVAoGLQqJXb9+nw8c/X4Pm9357x8RGuUKEg2RCwNv7xsEn6xaCQ+vWcOvrhvHgqSDFAqWNgEKMBdtDa7G+vKWnDl5AwoFQxXT8mEVqXA21uqUd3u6OW0ZYrPSxJ2/oCA66dnI9moxRGzAzq1ArPyE3D1lEzMKUwM6/thjCEvUS+v5TrUaMVL6yrR6fAiNloNxphcXgWCUSxmmxvxBg1GphgwKtWI+84fgTvm5ePNH0wFY0we6ACCb+4PLynC89dNwOs3T8HYdBPuWzgCRanGMGc0P1GPDidfdXRhH87nzPwEAMDsQv53doizKbm+Gw6bkWaKksU9wCeAFYz3zx2s70JctFoWlZID5fEFsOzNrXhezEaTRNGS4lRoVApsOdIOQRBw8UvfYf5f1uP5rw7jcItdFra/uWQM5o0M/7AQuvarucuFjLhoLJ2YAVOUGrPyE/De9lq8u60W0//4lTy9anF4UNsuibBwl0saSDDb3bITBgTjZyJhd/XthO2r432Gof8vCYI4cehjzFmETq0Ma/wfCIwxTMk5McdquFArFVhQlIxWqyuiSBlKUk06rLhrVq/LcxL0+N9P52JMBEcylB+f01sUhkaTRCLBoMVfb5iEKHXk/4aXiiVNiYvGpSEuWtNLWN40Mwcf7W5ASZNVLuvFRmtwyfh0/Gd7HYCg0JCQGr+LM2JQa3EizaTDBWNSsK60BZ/sbcT8kcl47ea+m7YBYGSKAbfMykFjlwtrS1rgdPvkcnZoOHCcXoM0kw5NXS4oFQyv3jQFjHFX7cIQpzA02kQSYTq1EldMCpYq7180slf8yrIZ2bB7fLC5fJieG/lnd/HYVHx09+ywXDqJsekmMMYb3Gf0cGs1KgVSY3So7+hGWbMNxRkmpMVyB6+py4X8JAMONHTC6fHLuXDNohOWkxCNiZmx2FnTgSNmhzxc8PK6SuQmROOS8Xy92W1z8/Cj2bkY89vVcHkDMOpU2BOS89bU5UKaSYc75+XjB7NysKmyDXe8swsvrD0MZ4gb1+EMOmF1PZww6dzMtqAI06gUuOkf27DynrlholTCIYYJOzx+ONw+eeAGCIpEyjcjiMFBIow4rXnm6vEInOI08eJB9Ngdi55l1P64ekomrp7Se8pTp1birVuno7TJisLkoGP3k/n5+HA3b2ov6CXCuJN00bg0zBuRhEsnpEOnVmJ2YSI+2duIcRHiS3rCGMPvlhaj1erC16UtqGi1Y2Y+FzFSHp7UU/fz80fgoQ8PoCjV2OcHhdSQCJOoE/gwkWjQ4pElo/s9RqFgEQUYwPsgi9NNONDQFVamlciMj8YRsx2HW2y4fVQ+0sWS/YqddRiTFiMPIEh9UpITlmLSYWJ2LP61qVqeflz983PQbvcgN1EfFsmiUHD38GCDFVdPycTbW2rQZncj0aBFs9WFSdmxUCgY9FoV5hQmQqNS9Fpw3tjpkgVgLydMLA2bbS64fQFkxEbhxesn4urXtmBrVXtEEWZ3BwWe2eaGXqvC6oNNKM4woayZl2adEQQaQRDHD/3PIU5rBuvsfV9IMmqRZAwvaRUmG/GPW6bi1fVHeg1WSOXV/EQDxqQHr1swKhmj02KwcPTxD5Ekx+hwXlEyvipthV4M45XKkZIbeN20bF7W7OffM7SMPtzOZ0/OGZHIRVhcbzGSFReNj/bUQxB4f16qOLH86d5GxOjUsvvUYnXD6fGh2eqCXqOEUavCxKxYePwB/HPTUYxJi+l3wGVCZix8fgHXT8vG/22qxmf7GrFsejYsDk/YlLReq8LM/ISwpvgYnUqOItFrlGGTnz5/ADXtkgjjpUVTlFr+cGHuY2o5dJtBq82N9Ngo3L18Ny6fmAGXN4BxGVy4SgKtJ5WtNvx5dTkmZJpw73kj+nzeBPF9hnrCCOIsZuHoFHzwk9m93iRn5MXj6wfODRNgABdzX9x3Tr9iIRI/nM37m8rF+IScBD1UCiY7YQAvgR6rRHuqkHqyciI4QlnxUXKKf3G6SY5gAYD1h1uxo9qCJDE2ptbiRIvVhRSTDowxeWK40+nFsun9D+b85pIxeP/OWRiVasSYtBi8s6VGDpNNNYX3AV45KQNpJh2uFfPvijNMcmlwuhiW6xLLn9XtTjlqhJcjfYiJUkGnVsKoU0Xs+QJ6ijAXWqwuBIRgELDklrb2cfuHPjyAtSUteOGrimMumCeI7yskwgjiewhjLGIsxkCZU5iAKydl4LeX8kw4tVKBa6ZmypscjpfXbpqM34p7VE8mM/Li8dpNk7FkXO/Gfskdi9Gp5IGApRMz8MiSItRZuuH0+HH7OVyE3vXOLqw60IxEcf1XmkmHZKMWiQZNr5iSnujUSrnR/YELRsJsc+O2t3bK9xPK5ZMysOWRhXjqyvH49pcL5J4/lYLhfDHzbs2hZtS2O3HVq5uhYNzFM9vcsLq8cm5eklEb5oSFTkvaXD45oqTV6pYnN6XJy/GSk9aHCGvq7IZeo4QvIMgRKKEcbXPIIrMn26ra8eyX5X29VARx1kAijCCIQcMYw3PXTZRDbwHgqSvH47pp2f3cqjeLi9Pwozl5xz5wiGGMYXFxmpwPF0qWHIJsCiuTzirgk5bJRi2um8qfp7RndHSaUb7fxy8bi79cM+GESusLR6fglRuDuXqppsgJ+EoFQ1Z8tCyq5o9KxtVTMjE5OxYPf3gAn+1vRFe3F//84TTMHZEIs92NTqdXFnuJBq0sot7bXovi367B//Y3AuBOWIqYyddic/XKRpOcsMbO7ohOl8XpwWUTM6BWsrDtDhKPfXoQN/59G55eXdbruvd31OGv31T2udGCIM4WSIQRBEH0g+R+9QxBHptuEkuCWXJMjEGrws5fn49HLgoOClw0Lk2O8zgR5hQG41JS+9i7KiFNSS4pToVWpcQjF41Gt9eP1QeboWD8vpIMWnj9ApqtLsREBZ2wNpsbR9scePijA3D7AnhXXNDu8Phg0KmQJubQNXYG88KUCib3Ff5xVSn+9EVZj/PxweUNICs+CpOy4uSg3lCkcud7O+p6XVdptkMQImeUEcTZBIkwgiCIfkiN0eHBC0f1Wl6vVDB88//my5EZmx4+D9seXYhEg3ZIBkqUCoYrJ2eAMRxz+vCucwvwi0Uj5ZVM+eI2iYONXXL2mdS3BgTzvZIMvBz5XQVv8r9qcia2VlnQ0NkNu9sPvVbF40U6u8NS+lOMWqiVCjkE94Pd9WGrlqT+tAS9BplxUWjucqHN7pYDbQHIobEWhycs+FYQBBwRE/+lSdOhQhAErNhRJ/fLEcSphkQYQRBEPzDGcM+CwohbE3RqpTzVmREbNeRRDX+5egIq/rDkmMelmnT42cIRcuxFvF4Do04FQQg6eemxQTctRsxhSzJqYXP5sK6sFRmxUbhvIZ9iXLm3EQ63DwatEumxUWjs7EZTZzdU4nOVyqP/vWs2nrxiHDqdXhwxB1cldTh4FllctAYpJh1arC48sGIffvbenpBjPPLO2IbObqwvb8XLX1egqcsFhyjKai3OIXXDvq1owy8/3N/LuSOIU8WwijDG2GLGWDljrJIx9nA/x13FGBMYY1OH83wIgiDOJBQKFpYndrwwxmQ3TBosmJgVzEmTyqeSO/ZNuRmzCxKQnRCNKTlx+HhPPewuvlIr3RSFFpsbdR3dcqxFWsi05ryRvGy64XCwyd4iLnNPMPCgXl9AwPajFhwV88oCAQEdTg/GitO5jZ3d+Ns3R/D8V4exOySo9slVZVjwzHp09BMKu7myDZe/sgnbj1rg8QXw+f6mMFcuFL94eX+bAgjiZDJsIowxpgTwCoAlAMYAWMYY6zX2xBgzArgPwLbhOheCIIjvG7mSCBMHC5QKhh/NyRW/5r/6k0IiQ6SYjssnZeBwix1VbXbotSqkx0bBLy4Fn5BpQoxOFRblkRkXjaz4qLBl7hYHb/aPi9YgRexn6/b60Wpzw+sPwOryIiAEg5APt9iwu7YDAQFYLi6eVyoY2uxuODx+rNjZu28MALqcXty/Yi/21nXixr9vxb3/3o17/r0bW8Tl8T3xio3+nd189+d1r2/Bocau431JCWLIGU4nbDqASkEQqgRB8AB4D8DSCMc9AeDPAKgDkyAIYojITZBEWNC1enhJEZ5YOhYXiFOskhOmVjJcNI6vUbpkXBrUSgavX4BBq5LXNAHA2AwTPrlnDn4yvyDssfISDaixcJfL4fbJTfzx4soqCUHgC86lnrHRaTFQMOCDXfXwBbhLtaWqHWkmnbzXFADe3VYT0d1adbAJLVY3Xrx+Irx+AV+WtAAA2u29nbMup1deSt7l9KCuw4ltRy34tiJyTAZBnAyGU4RlAAj9+FIvXibDGJsMIEsQhM/7uyPG2B2MsZ2MsZ1ms7m/QwmCIAgE94WGihmtSombZ+XKgwNFqUbct3AEvv3leXJvW5xeI09z6sVypMTi4lTkJxlg1IUv7s6Jj5aXh9/0j214Zk05lAqGGJ2612Rnc5cLHWK5MsmoRWqMDmXNNug1Snnt1UOLi2TxNi7DhDpLt5xP1mZ34/0dtRAEAbUWJ1QKhkvGp8ulTQBhQwQAcMRsx6QnvsR3ouDqcHrlHZp1lvAVTwRxMjlljfmMMQWA5wA8cKxjBUF4QxCEqYIgTE1KSjrW4QRBEN97Fhen4umrxmNSVuSdmQCgUipw/6KRvXLIrpjEPy8btKoeDf3h4ksiJyEaVpcPrVYX9td3ybdVKBgSDFq5oR8A3vy2Ci99XQkAiI/WyIvNr52WhbvnF+KucwuwdGK6fE7SVOqhRr6v8v0ddXjowwOotTjR0NGNtFgdlAqGC8YEg3YbOrphc3nx7Jfl6Pb4UdFiQ0AA9ournbq9ftmN67nsHOBuniAIePnrCrlcua+uE+19rHgaKFVmOzYcJmPh+8xw7o5sABAaEZ0pXiZhBFAMYL0YgJgKYCVj7DJBEHYO43kRBEGc9WhVSlw7rf+U/r44rygZ545MwrTceBh1ajx2yRi5ZywSUt/ZV6Wt8ItlxS7RaVIqGJKNWrQ7PHD7AlhzqEW+XZxejYIkA3bWdODeBYVIMGjlxylKNSLRoMWlE9Lxq48PYH15K9w+v9zcX9ZsQ32HE5mx/LFvmJENp8eHr0pb0NDZjae+KMO/t9WiIMmATtF5C11sLjXn91x2XtvuxEUvfYufLSzEs2sPw+72oSg1Bsve3Iobpmfj15cM3UaH857dAACo/tPFQ3afxJnFcIqwHQBGMMbywMXX9QBukK4UBKELgJxGyBhbD+D/kQAjCII4tejUSrx163T5+1vn9r/FQGrUX32oOeL16bFRSDRqZZdMIl6vwas3TUGn09Nrr+itc/KwbHo2DFoVCpMNeG9HHd7bUSeXV8uabGjo7MY5I7hoSzJq8chFo3HE7ECtxYHD4h5Ti8ODFjHmwuUNJvBLzlp9RzcCAQEKBYMgCPjtyoOwu334qpSn/Hd1e9HYyddTNQ1xbpmEIAgnfWk9cXowbOVIQRB8AO4FsAZAKYAVgiAcYoz9njF22XA9LkEQBHFykWIwNh42Q6dW4JwRibjr3GDz/uOXjcUfLx/X63ZRaiWSjFqMENP3Q1EpFXLvmUYVfKuqFXu4DjR0odXmRmZc+HLzzLgoHG6xyz1ktRZnWOirpHWkZfMeX0Den7nmUAu+KTeDMWBvXScALsKq27n71teezFv+uR1PrSoNu+ypVaV44avDEY8HELbqqTskPNbi8GBntQUurz9iv5rb54+4gYA4MxnWnjBBEFYJgjBSEIQCQRD+KF72mCAIKyMcO59cMIIgiDMPvVYlT1qOTDHindtm4OElRfL1xRkmjMs0IUGvCbvd8bo/d84rQHyP264vb4Ug8JDcUEK/TzRoUGtxhjlYeeLUaKjAqbM4YXf78PvPDqEo1YiFRcny3squbi+qxRKoOUJP2BGxr2ttSbDM6vL68frGKrzwVYV82eEWW5h4Cu1Fs3b75K//b9NR3PDmNryzpQYXvrARbl94uv9n+5pw1aubSYidJVBiPkEQBDFoHr90LGblJ+CaKZl9HvPl/fOw7dGFuHxiOuYUJhz3fV86IR27f7MIhckGAEBBkl6OtMiMiw47NkVs6L/9nDxMyYlDTbsDLSHrkpJjtIhSK+XbAzwi47FPD6LJ6sIfrxgXth2hq9uLqrbITlirzYW3NlcDAKraHHIf3OYjvWMvnlxVip/9J7gxQCqXAoDN5Q3ep9UNjz+AAw1dcHr8vR6zQRRvb2+p7vUYxJkHiTCCIAhi0Fw8Pg3/uWMmbp6V2+cxCQYtUmJ0eOH6SVj+45kn/BjSEvWfieuVAIQFxwLA4rGp+NuNk/HQ4iLkJOhRZ+lGU8jycaNOjUQjd9XyE/W4aWY23ttRh492N+DWOVy4hZY4O51BJ8zu9sHpCbpW17+xFW9vqZF3cR4Upy/XlrTKxwREsVfb7kRDZ7c8JFDZGlzzZA0RYZYe1++q6cDtb+/E1a9uhtvnh9nOn8uqA0204PwsgEQYQRAEcUYwuyABMToVzh+dgr2PLcJ/75qF9B7lSI1KgYvGpUGlVCA7PhoefwCekP4ro1aFRHEIICZKjT9cPg6rf34OPrlnDn598WgA4e6atduLo20OSCkbbTYukrqcXlSZHbh6SiZW3DkLALCvnveR7aqxyLfvcHrgDwhyj1pJEx8IKAtZnRRajpRWNEm7OF9dfwRrS1qws6YDNe1OtFrdiI1Ww+sX8N72yJsEiDMHEmEEQRDEGcHVUzKx7dHzodeqEButwbTc+H6Pl/ZnAsFeMYMuKMKM4iLzotQYTMyKlXvUQvvKbG4f6ju6MUYMg5Xcp0NN3PW6bEI6RqUakZMQjf11XfAHBFS3OeX7qGy1o7TJKgvBEnEq82BDl1xeDXPCRBHmFnvSykPKljXtTpjtboxNj8G8kUlYvq0G3hCB2RN/QMA7W6ppV+ZpDIkwgiAI4oyAMYYojfK4j5+Rn4A/XzUOy6Zn4+LxfC2TURfuhEUiU1z1FC0+li8gYEo2D71t7HJBEARZTEnibHxmLPbVd6K+wwmPP4AZYvr/He/swiUvfyffd0mjFVYXd9fmFPC+uA2Hzfj7t1UAguVICUEARqZwsVbT7oDZ5kayUYcbpmehxerGrpqOsBJpKLtqOvCbTw/hwhc2Yk9t5Eb+yla7PIRwOhIICGgb4pDc0wkSYQRBEMRZiVLBcN20bDx15Tg5X8ygVSPJwHvCYnSRozJjdGr86cpxuHNeMGZjcg4XYT/7zx78aXUZShqtSInRyoJuQqYJTV0ubKvipcgZeVyESc36AFCYbMCXJS343coSAMDsQh6V+dHuBvzh81K0WF1hx0uMz4yFUadCrcUJs82NJKMWswoSwRjw8If7MeaxNagRYzRCCZ0AjbTUvMvpxZIXN+L9HbURX4fTgS8ONmPOn9ZFfF3OBkiEEQRBEGc9cdFceBl1KiSKcRp9rWECgOunZ6M4I7iPckJmrPz1W5ursbWqHWPSgtePF6//eA9fDDM9r/f056s3TsaY9Bh8uLseADAlJy4sA23l3kZE2FOO7Pho5CRE42BDF9y+AJKNWpii1BibHoNqcWdnRYu91+3qOpxgjAfZljXZ4PT4cP0bW7Cj2iJf7/ULYSXP041aixNuX0DulTvbIBFGEARBnPXERXPBdTzlSIlY8TZKBUNmXBQunZCOW2blwOUNoNnqws2zcuRjizNioGDccYqLViMnPjpsZyYAjEgx4u1bp0OtZIhSK5Fo0IYJwY/2NCAS2fHRyInXY3ctb/yXMtlm5QeFXo3Fibc2V4eFwNZ3dCPFqMO4DBPKm2043GLH1ioLrnltCzy+gJyfVtN++i4xl/rlHH2UXM90hnNtEUEQBEGcFuQnGWDU8RVIDjcPQDX2UY6UkKIn0kw6qJQKvLxsEgAg1RSFvMRonFeUIh8brVFhdFoMDjVakZ9kEJeXa9BidePBC0dBKzpeOrUSu3+zCDYXFxXS5YwBpeLkpESyUYtWmxtZohMmkSSKyMXFafh0byNabW68tbkatRYnRqQYMLuAlznrLE5kxUdhVKoRGw+bw/ZkrjnULMdlSPs4T0ekDDWnx3+MI89MSIQRBEEQZz2pJh0OPH4hAKCpqxtKBeuVtt8TySnL6hEI+5P5BZEOx+s3T8H6cjPGZ/I8s0SDFl6/gLvnF4RtBzDq1PJKJqvY63TeqGR8XcbzxVJitGixulGUFoNWmxlZ8VHiJOgRADxwFuDlzO2/Oh/nPL1OXufUEJLEX9/Rjel58ShKNcIXELCpMtgXVituCZCOu/D5jfjFBSNx4djUfl+Tk40kVh1ucsIIgiAI4ownzRSFDQ/OP6YIk5ywrPj+j5PIjIvGTTODJcppufFwuH39rmeyieLihhnZ+Ka8FQGBN/C3WN24bW4eZuTFI8mgxYKiZPzlmgn4cFd9ry0BaaYo1Fm4+JJKjF5/AE1d3ciM404YAGwob4VayaBVKWG2uWUnDOBRGGtLWk47ESaJVHLCCIIgCOIsoaeQiYRWpcSS4lScPzrlmMdG4vHLxh73seMyTZiQFYs9tZ0oSDJgU2U7pubE4dyRSfIxV0/JxNUR1kKFisnGTi7GmrtcCAjcxctPNEClYGjsciEzLgoalQJmmxttdjd0agVcXt5HJiX+DyUurx9ef0B2/k4UcsIIgiAI4nvKqzdNGdb7j1Ir0e31I8mgxbVTswDwANiAIMg5ZcciPVYnf90girDPDzQBAIrSjNCoFChIMqC8xYY0kw4KxtBqc6HF6sa03Hh8W8F3XVa02uHy+qFTH38W27H43WeHUNFixwc/mT2g21upJ4wgCIIgiOFg1X3n4GibHYwxLJuejWXTswEAU4+xDSAUaXWTWsnQ1OVCm92NV9ZVYmFRshydMSrViPIWG1JNURAEAfvru9Dc5cKS4lTcu6AQjV3duP/9fShpsmKyGEwbSkmjFSolw4hkQ7/l1Z4cbXOg0mzHpso2lDZZcdvcvBO6veyE0XQkQRAEQRBDSV6iHnkh65UGwviMWGhVCpwzIgmbKtvw0Af74fYH8MhFo+VjRqUagX1AaowW/gBQa+FOWXpsFGbkJ8gO2v66zl4i7MlVpXhjI0/0f3hJEe46N3wwYfXBZhh1KswpTMSbG6tQ3e7AHXRktwAAD7hJREFUry8egyiNEh0OLzqdXjzy0QHUWpwQBOD2efnH/dyknrDus9QJo5wwgiAIgjiDGZdpQtkTizEzPx7dXj++LmvFI0uK5N2UAFAkNuenmqLknDEAKM7gk5zpJh1GJBvw8d7GsPv+urQFb2yswvXTslCcEYPVB5vDrv+mrBU/Wb4LD6zYB39AwB9XlWL5tlqc/9wGfLS7Hh1i87+UeP/UF6XYftSC48EfEOAQxZcUK3K2QSKMIAiCIM5wGAtGbpw7Mgk/nJ0bdv3ErFhkxEZhcnYskkNE2Fhx9yVjDDfOyMa+uk78dV0FWq18R+YT/yvBiGQDfr+0GDPyElDaZIXT48MRsx2dTg9++eF+xOjUaLa68MGuOgDAwqJkqJQMr3xTiU4nF19d3V4snZiOnAQ9HvpwP4RIqwF6YHcFS5B97cc80yERRhAEQRBnAbMKEnDDjGw8c834Xn1XCQYtNj18HiZlx4U5YaFN+FdOyYQpSo2/fHkYr3xTiSNmO6rbnbh1bh40KgXGZZjg9gVw/rMbsPDZDZj11DqYbW68euNkxOs1eOjDAwCAe84rxIJRyaizdMMTkuA/ItmAW+fk4mibA/Ud3dhc2YanV5f1+XykpnwAsiN2tkEijCAIgiDOAmKjNXjyinFINur6PS5BXGAurW+SiNGp8d1DCzA9Lx47azrkcNe54qJxqXTZ2OXCbXPzYNSpsGhMCmYXJoY5b2PSYpASowsTYADvP5sprlraUtWOj/c04PWNVQgEIrtioSLMOcCIih3VlrBVTqcbJMIIgiAI4ntEboIecdFqPHXluF7XGXVqzMyLR2mTFV+WNCMrPgpZ8TxTLT9RD71Giez4aDx60Whsevg8/O3GyQCA28/hzfYGrQo6tRIpMdpe951mikJhsgEJeg22VrWjsasb/oAg94v1xNodFF4DmY6saLHhmte2yEvVT0doOpIgCIIgvkfotSrseeyCPq+fnBOHgABsqmyXIzMAQKFgeOLyYmTERkGpYFAiWPKM0iix8cEFkKqgqTG93bj0WB0YY5iRH4//3979B1lZ3Xccf3+4sAu7rAu7wEJZlgVZS1BQCQOI1Co1DtGMppomajJFY8ZJRh3bpE207aSTTBzbZGpSq5OMSW1txtSkSUyMphaCjiapkR+CIBEREEQEFlhQ+VF+fvvHc3a9uy7+YPbuc939vGbu3Oec59nnnnu/w+V7z3Oec57e2Naxbubu/Yc5FsG67W8wJ/W6wZvrRo4YWvme5gl7eXe2Zua6HfsAWPJSG3+W5mArN+4JMzMzsw5nF01RceO8SZ32XT69kVnpkmJXTfVVHb1mo4qSsPZJZ0fXZnVnjK1l696DbEkLim/de5Bzbl/M1d97mrb9by6l1D5H2Ojaync9Y/66HW9w3jceZ8lLbby0K0vClm/e0+mYVa/sLZspL5yEmZmZWYfaIYO44+Nnsugvz3vH9TVPpD3hAmhpqGHE0EoqB2bJWMuobLqMI8eysWD/tPCFju3frM9m71+34w3+4dG1VKXLn+82adrQmiVem9sOsHHXfgA27trP7n2HgGxppkvv+i0PLH35pN5XT3MSZmZmZp1cPr2Rloaak/77oZUDqa4oIMEN55/KTUU9ai1F85cBrN76GmOHDaF2yCB+vW4nAA+v2saufYd44PrZjKoZ3OnuyMfXtjLztl91rJNZ7NW0gHnb/sO8tGs/NZXZqKsnX8zO++0nNgCwPiVreXMSZmZmZj2uoXYwpwwexEWnj2ZB0d2T4+qqOsaDAURA84gq5k4awZMv7uT48eCVtgOMOWUw0xqHUVVR4MDhoxw6eoyHnn2VW366itY3DrFwzXYOHz3OUxt2d9xhuS0lZu1J2MVTxzB5dA23PbKWZ17ew3+nNTU37z7Qex/E2/DAfDMzM+txDTWD6W5O1sIAcerIofx+2+tIWRI2bngVcyaN4JHV21i8tpUtew7QmMaXVVUUOHIs+OHSLXz552uorihQV13BT57Zyi9WbWP55j386dljadt/uGPs2IbWfew9cISWhqFcc24zl931W67+7u8YWBjAjPHD2bR7f29+FCfknjAzMzPrcZ+aPZ5rz23udl9Lw1AGFcS44VmiNa6uiovPGE3j8CF854kNbGk72LGvqiLrL1r8fCsjaypZ8rcXcumZf8Dqra+xfPMeZk6o48EVW3li3U6WpUH4K7bsBbLpOD4w5hS+cNFp/N+R41wxvZEZzXW8uvcgh47mPzjfPWFmZmbW4y6ZNuaE+z4zdyKzJtTzX8u38HLbAZrqqhhYGMA1c5r52iPPAzCuLrspoH1y2ac27Oai0xuorhzI5dPH8uhz27n98qnMmljHz1a8yld+sYZDR7OJWdvvshxfnyVyn/mjiYwYWsmFH2jgsRd2cDxgS9vBTutr5sE9YWZmZtarpjbWcvWsJuqrswSrfWqLeZNHdRzT3hN20ZTR1FdXcPjY8Y7pMaY1DuOpW+dxweRRVFUM5OpZTZx32si3vE5jOkdhgLjig43UVg1ifH01AJvL4JKkkzAzMzPLRV1KwppSEjZhRHXHtBjtidmQigKfnjsBgHOK5ijruj7m2U3DAKhO85KNrKlkSEWBriaOyJKwx9a29tj7OFlOwszMzCwXU8acwvj6KoZXDQKyxOq807JZ89svRwJ89o9P5eGb5r7t5cP2dSk/2FyX/f3w7uc4G1ZVwTVzmrn/6ZdZuGZ7j7yPk+UxYWZmZpaLa86dwII5zZ16tT597gSGV1V0WvqoMEAdC4ifyPSm4fzq8+exdNMenly3s6N3rTu3XjyZ9a37KAzQCY/pDU7CzMzMLDddLyu2NNTwxfmTT+pck0bVsGFnNtbr7ZKwyoEFvn/dzLe8dm/z5UgzMzPrM9oH+ze+TRIGb03+8uAkzMzMzPqMM8bWctXMcVzwh6Pe+eCclTQJkzRf0guS1ku6pZv9n5W0WtJKSb+RNKWU7TEzM7O+bfCgArdfPo2RNZV5N+UdlSwJk1QA7gY+DEwBruomyfpBREyNiLOArwN3lKo9ZmZmZuWklD1hM4H1EbExIg4DDwCXFR8QEa8XFauBblaZMjMzM+t7Snl35FhgS1H5FWBW14Mk3QB8HqgA5nV3IknXA9cDNDU19XhDzczMzHpb7gPzI+LuiDgV+BLwdyc45p6ImBERM0aOfOuyBGZmZmbvN6VMwrYC44rKjanuRB4APlrC9piZmZmVjVImYUuBFkkTJFUAVwIPFR8gqaWoeAnwYgnbY2ZmZlY2SjYmLCKOSroR+B+gANwbEWskfRVYFhEPATdKuhA4AuwBFpSqPWZmZmblpKTLFkXEL4Ffdqn7ctH2zaV8fTMzM7NylfvAfDMzM7P+yEmYmZmZWQ6chJmZmZnlwEmYmZmZWQ6chJmZmZnlQBHvr+UaJe0ENpf4ZUYAu0r8GvbeOS7lyXEpP45JeXJcylOp4zI+Irpd7ud9l4T1BknLImJG3u2wzhyX8uS4lB/HpDw5LuUpz7j4cqSZmZlZDpyEmZmZmeXASVj37sm7AdYtx6U8OS7lxzEpT45LecotLh4TZmZmZpYD94SZmZmZ5cBJWBeS5kt6QdJ6Sbfk3Z7+RNK9klolPVdUVydpkaQX0/PwVC9Jd6Y4rZI0Pb+W912Sxkl6XNLvJa2RdHOqd1xyJGmwpCWSnk1x+UqqnyDp6fT5/1BSRaqvTOX1aX9znu3vyyQVJK2Q9HAqOyY5k7RJ0mpJKyUtS3Vl8R3mJKyIpAJwN/BhYApwlaQp+baqX/l3YH6XuluAxRHRAixOZchi1JIe1wPf7qU29jdHgS9ExBRgNnBD+jfhuOTrEDAvIs4EzgLmS5oN/CPwzYiYBOwBrkvHXwfsSfXfTMdZadwMPF9UdkzKwwURcVbRVBRl8R3mJKyzmcD6iNgYEYeBB4DLcm5TvxERTwJtXaovA+5L2/cBHy2q/4/I/A4YJmlM77S0/4iIbRHxTNp+g+w/l7E4LrlKn+++VByUHgHMA36c6rvGpT1ePwb+RJJ6qbn9hqRG4BLge6ksHJNyVRbfYU7COhsLbCkqv5LqLD8NEbEtbW8HGtK2Y9XL0uWSs4GncVxyly57rQRagUXABmBvRBxNhxR/9h1xSftfA+p7t8X9wreALwLHU7kex6QcBLBQ0nJJ16e6svgOG1iqE5v1tIgISb6dNweShgI/Af4iIl4v/sHuuOQjIo4BZ0kaBjwITM65Sf2apI8ArRGxXNL5ebfHOpkbEVsljQIWSVpbvDPP7zD3hHW2FRhXVG5MdZafHe1dwem5NdU7Vr1E0iCyBOz+iPhpqnZcykRE7AUeB84hu3TS/uO6+LPviEvaXwvs7uWm9nXnApdK2kQ2lGUe8M84JrmLiK3puZXsB8tMyuQ7zElYZ0uBlnQ3SwVwJfBQzm3q7x4CFqTtBcDPi+r/PN3JMht4rahr2XpIGqPyr8DzEXFH0S7HJUeSRqYeMCQNAT5ENl7vceBj6bCucWmP18eAx8KTRPaoiLg1Ihojopns/47HIuKTOCa5klQtqaZ9G7gIeI4y+Q7zZK1dSLqY7Lp+Abg3Im7LuUn9hqT/BM4nW9F+B/D3wM+AHwFNwGbg4xHRlpKDu8jupjwAXBsRy/Jod18maS7wa2A1b45z+RuycWGOS04kTSMbTFwg+zH9o4j4qqSJZL0wdcAK4FMRcUjSYOD7ZGP62oArI2JjPq3v+9LlyL+KiI84JvlKn/+DqTgQ+EFE3CapnjL4DnMSZmZmZpYDX440MzMzy4GTMDMzM7McOAkzMzMzy4GTMDMzM7McOAkzMzMzy4GTMDPrUyQdk7Sy6HHLO//Vuz53s6Tneup8Zta/edkiM+trDkbEWXk3wszsnbgnzMz6BUmbJH1d0mpJSyRNSvXNkh6TtErSYklNqb5B0oOSnk2POelUBUnflbRG0sI0Y72Z2XvmJMzM+pohXS5HfqJo32sRMZVsRuxvpbp/Ae6LiGnA/cCdqf5O4ImIOBOYDqxJ9S3A3RFxOrAXuKLE78fM+ijPmG9mfYqkfRExtJv6TcC8iNiYFiXfHhH1knYBYyLiSKrfFhEjJO0EGiPiUNE5moFFEdGSyl8CBkXE10r/zsysr3FPmJn1J3GC7ffiUNH2MTy21sxOkpMwM+tPPlH0/FTa/l/gyrT9SbIFywEWA58DkFSQVNtbjTSz/sG/4MysrxkiaWVR+dGIaJ+mYrikVWS9WVelupuAf5P018BO4NpUfzNwj6TryHq8PgdsK3nrzazf8JgwM+sX0piwGRGxK++2mJmBL0eamZmZ5cI9YWZmZmY5cE+YmZmZWQ6chJmZmZnlwEmYmZmZWQ6chJmZmZnlwEmYmZmZWQ6chJmZmZnl4P8BZz5AB/1Q6NAAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}