{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "7e88OLey6Bgd"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7e88OLey6Bgd"
      },
      "source": [
        "# **Image Classification with Convolutional Neural Networks (CNNs)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsTzc3oi726u"
      },
      "source": [
        "# **Building a Convolutional Neural Network with Keras**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import Libraries**"
      ],
      "metadata": {
        "id": "RPPhrQ6HGq_Z"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCglDGFy8AhT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "ebd8e8a1-250e-44d5-bd08-8a165139a39a"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "tf.__version__\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import matplotlib.image as mpimg\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "import imageio\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.8.2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qf7eW3HC9XVL"
      },
      "source": [
        "**Data Acquisition and ImageDataGenerator**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0BfyGlJbx0l"
      },
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255) #Normalize the pixel values\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hsimgs7aqt6G"
      },
      "source": [
        "#File path to the folder containin images\n",
        "train_dir = os.path.join('/content/spectrograms-400/Train')\n",
        "validation_dir = os.path.join('/content/spectrograms-400/Validation')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NyvlF41oqxEP",
        "outputId": "927e0903-f6a3-4e9b-eeff-892636e26989",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(64,64),\n",
        "    batch_size=256,\n",
        "    shuffle=True,\n",
        "    class_mode='binary')\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    validation_dir,\n",
        "    target_size=(64,64),\n",
        "    batch_size=256,\n",
        "    shuffle=True,\n",
        "    class_mode='binary')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 33128 images belonging to 2 classes.\n",
            "Found 6780 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3yhwpN_-BaS"
      },
      "source": [
        "**Building the Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSzxq4KDtKN6"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "                                    \n",
        "    # First convolution layer \n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(64, 64, 3),use_bias=True),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "\n",
        "    # Second convolution layer \n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu',use_bias=True),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    \n",
        "\n",
        "    # Third convolution layer  \n",
        "    tf.keras.layers.Conv2D(256, (3,3), activation='relu',use_bias=True),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "\n",
        "  # Fourth convolution layer  \n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu',use_bias=True),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "\n",
        "\n",
        "    # Flatten the pooled feature maps\n",
        "    tf.keras.layers.Flatten(),\n",
        "\n",
        "    # Fully connected hidden layer\n",
        "    tf.keras.layers.Dense(8, activation='relu',use_bias=True),\n",
        "\n",
        "\n",
        "    # Output layer\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid',activity_regularizer=regularizers.L1(0.001))   \n",
        "\n",
        "])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDXufVt4-LFY"
      },
      "source": [
        "**Model Summary**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HU0RFGLtNJb",
        "outputId": "08c30a3c-9036-4547-f6ec-6ffdd88b7e8f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 62, 62, 64)        1792      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 31, 31, 64)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 31, 31, 64)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 29, 29, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 14, 14, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 12, 12, 256)       295168    \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 6, 6, 256)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 6, 6, 256)         0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 4, 4, 64)          147520    \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 2, 2, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 2, 2, 64)          0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 8)                 2056      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 520,401\n",
            "Trainable params: 520,401\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THk8lK3G-cdk"
      },
      "source": [
        "**Optimizer Implementation and model training/validation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBN3GBMItPMH"
      },
      "source": [
        "#from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import SensitivityAtSpecificity,SpecificityAtSensitivity,Recall,Precision\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=Adam(learning_rate=0.001),\n",
        "              metrics=['accuracy',SensitivityAtSpecificity(0.5),SpecificityAtSensitivity(0.5),Recall(0.5),Precision(0.5)]) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Q0MPMwh3EgY"
      },
      "source": [
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('val_accuracy')>0.99): \n",
        "      print(\"\\nReached 99% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "callbacks = myCallback()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7f6gDG3dx9sJ",
        "outputId": "b72033dd-564c-4ee6-9f39-0f9c7e745eaf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "checkpoint = ModelCheckpoint(\"ECG_Spectrogram_Model.h5\", monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
        "\n",
        "history = model.fit(\n",
        "      train_generator,\n",
        "      steps_per_epoch=10,  \n",
        "      epochs=500,\n",
        "      verbose=1,\n",
        "      validation_data = validation_generator,\n",
        "      validation_steps=5, \n",
        "      callbacks = [callbacks,checkpoint]\n",
        ") "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.7142 - accuracy: 0.4930 - sensitivity_at_specificity: 0.4588 - specificity_at_sensitivity: 0.4623 - recall: 0.3971 - precision: 0.5068\n",
            "Epoch 1: val_accuracy improved from -inf to 0.50234, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 17s 231ms/step - loss: 0.7142 - accuracy: 0.4930 - sensitivity_at_specificity: 0.4588 - specificity_at_sensitivity: 0.4623 - recall: 0.3971 - precision: 0.5068 - val_loss: 0.6936 - val_accuracy: 0.5023 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
            "Epoch 2/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6940 - accuracy: 0.5035 - sensitivity_at_specificity: 0.1698 - specificity_at_sensitivity: 0.3364 - recall: 0.2005 - precision: 0.4679\n",
            "Epoch 2: val_accuracy improved from 0.50234 to 0.50547, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.6940 - accuracy: 0.5035 - sensitivity_at_specificity: 0.1698 - specificity_at_sensitivity: 0.3364 - recall: 0.2005 - precision: 0.4679 - val_loss: 0.6936 - val_accuracy: 0.5055 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
            "Epoch 3/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6935 - accuracy: 0.4992 - sensitivity_at_specificity: 0.0642 - specificity_at_sensitivity: 0.3533 - recall: 0.0766 - precision: 0.5266\n",
            "Epoch 3: val_accuracy did not improve from 0.50547\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.6935 - accuracy: 0.4992 - sensitivity_at_specificity: 0.0642 - specificity_at_sensitivity: 0.3533 - recall: 0.0766 - precision: 0.5266 - val_loss: 0.6936 - val_accuracy: 0.4992 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
            "Epoch 4/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6934 - accuracy: 0.5043 - sensitivity_at_specificity: 0.1922 - specificity_at_sensitivity: 0.2446 - recall: 0.2145 - precision: 0.5304\n",
            "Epoch 4: val_accuracy did not improve from 0.50547\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.6934 - accuracy: 0.5043 - sensitivity_at_specificity: 0.1922 - specificity_at_sensitivity: 0.2446 - recall: 0.2145 - precision: 0.5304 - val_loss: 0.6937 - val_accuracy: 0.4797 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
            "Epoch 5/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6943 - accuracy: 0.4984 - sensitivity_at_specificity: 0.3157 - specificity_at_sensitivity: 0.2716 - recall: 0.3394 - precision: 0.4886\n",
            "Epoch 5: val_accuracy did not improve from 0.50547\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.6943 - accuracy: 0.4984 - sensitivity_at_specificity: 0.3157 - specificity_at_sensitivity: 0.2716 - recall: 0.3394 - precision: 0.4886 - val_loss: 0.6938 - val_accuracy: 0.5031 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
            "Epoch 6/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6943 - accuracy: 0.4867 - sensitivity_at_specificity: 0.1033 - specificity_at_sensitivity: 0.3223 - recall: 0.1330 - precision: 0.5029\n",
            "Epoch 6: val_accuracy did not improve from 0.50547\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.6943 - accuracy: 0.4867 - sensitivity_at_specificity: 0.1033 - specificity_at_sensitivity: 0.3223 - recall: 0.1330 - precision: 0.5029 - val_loss: 0.6936 - val_accuracy: 0.5023 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.0000e+00 - val_recall: 1.0000 - val_precision: 0.5023\n",
            "Epoch 7/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6936 - accuracy: 0.5004 - sensitivity_at_specificity: 0.0473 - specificity_at_sensitivity: 0.1773 - recall: 0.6925 - precision: 0.5034\n",
            "Epoch 7: val_accuracy did not improve from 0.50547\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.6936 - accuracy: 0.5004 - sensitivity_at_specificity: 0.0473 - specificity_at_sensitivity: 0.1773 - recall: 0.6925 - precision: 0.5034 - val_loss: 0.6936 - val_accuracy: 0.5055 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.0000e+00 - val_recall: 1.0000 - val_precision: 0.5055\n",
            "Epoch 8/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6937 - accuracy: 0.5070 - sensitivity_at_specificity: 0.0064 - specificity_at_sensitivity: 0.2935 - recall: 0.6351 - precision: 0.4978\n",
            "Epoch 8: val_accuracy improved from 0.50547 to 0.50703, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.6937 - accuracy: 0.5070 - sensitivity_at_specificity: 0.0064 - specificity_at_sensitivity: 0.2935 - recall: 0.6351 - precision: 0.4978 - val_loss: 0.6930 - val_accuracy: 0.5070 - val_sensitivity_at_specificity: 0.6101 - val_specificity_at_sensitivity: 0.7350 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
            "Epoch 9/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6937 - accuracy: 0.5133 - sensitivity_at_specificity: 0.0015 - specificity_at_sensitivity: 0.3488 - recall: 0.5731 - precision: 0.5212    \n",
            "Epoch 9: val_accuracy improved from 0.50703 to 0.59453, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 179ms/step - loss: 0.6937 - accuracy: 0.5133 - sensitivity_at_specificity: 0.0015 - specificity_at_sensitivity: 0.3488 - recall: 0.5731 - precision: 0.5212 - val_loss: 0.6928 - val_accuracy: 0.5945 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.0896 - val_recall: 0.3344 - val_precision: 0.7252\n",
            "Epoch 10/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6935 - accuracy: 0.4984 - sensitivity_at_specificity: 0.0064 - specificity_at_sensitivity: 0.3570 - recall: 0.5260 - precision: 0.4870\n",
            "Epoch 10: val_accuracy did not improve from 0.59453\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.6935 - accuracy: 0.4984 - sensitivity_at_specificity: 0.0064 - specificity_at_sensitivity: 0.3570 - recall: 0.5260 - precision: 0.4870 - val_loss: 0.6901 - val_accuracy: 0.4883 - val_sensitivity_at_specificity: 0.9649 - val_specificity_at_sensitivity: 0.5376 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
            "Epoch 11/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6925 - accuracy: 0.5082 - sensitivity_at_specificity: 0.4833 - specificity_at_sensitivity: 0.3802 - recall: 0.2107 - precision: 0.4726\n",
            "Epoch 11: val_accuracy did not improve from 0.59453\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.6925 - accuracy: 0.5082 - sensitivity_at_specificity: 0.4833 - specificity_at_sensitivity: 0.3802 - recall: 0.2107 - precision: 0.4726 - val_loss: 0.6769 - val_accuracy: 0.5109 - val_sensitivity_at_specificity: 0.9617 - val_specificity_at_sensitivity: 0.7554 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
            "Epoch 12/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6882 - accuracy: 0.5074 - sensitivity_at_specificity: 0.5102 - specificity_at_sensitivity: 0.5802 - recall: 0.0431 - precision: 0.5789\n",
            "Epoch 12: val_accuracy improved from 0.59453 to 0.66328, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.6882 - accuracy: 0.5074 - sensitivity_at_specificity: 0.5102 - specificity_at_sensitivity: 0.5802 - recall: 0.0431 - precision: 0.5789 - val_loss: 0.6426 - val_accuracy: 0.6633 - val_sensitivity_at_specificity: 0.9858 - val_specificity_at_sensitivity: 0.7280 - val_recall: 0.5340 - val_precision: 0.7131\n",
            "Epoch 13/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6748 - accuracy: 0.5387 - sensitivity_at_specificity: 0.1712 - specificity_at_sensitivity: 0.4618 - recall: 0.5283 - precision: 0.5439\n",
            "Epoch 13: val_accuracy improved from 0.66328 to 0.76797, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.6748 - accuracy: 0.5387 - sensitivity_at_specificity: 0.1712 - specificity_at_sensitivity: 0.4618 - recall: 0.5283 - precision: 0.5439 - val_loss: 0.5486 - val_accuracy: 0.7680 - val_sensitivity_at_specificity: 0.9954 - val_specificity_at_sensitivity: 0.6228 - val_recall: 0.9168 - val_precision: 0.7100\n",
            "Epoch 14/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6413 - accuracy: 0.5793 - sensitivity_at_specificity: 0.5407 - specificity_at_sensitivity: 0.5687 - recall: 0.9053 - precision: 0.5455\n",
            "Epoch 14: val_accuracy did not improve from 0.76797\n",
            "10/10 [==============================] - 2s 193ms/step - loss: 0.6413 - accuracy: 0.5793 - sensitivity_at_specificity: 0.5407 - specificity_at_sensitivity: 0.5687 - recall: 0.9053 - precision: 0.5455 - val_loss: 0.4947 - val_accuracy: 0.7625 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5455 - val_recall: 0.9937 - val_precision: 0.6764\n",
            "Epoch 15/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6333 - accuracy: 0.5973 - sensitivity_at_specificity: 0.5428 - specificity_at_sensitivity: 0.5487 - recall: 0.9846 - precision: 0.5581\n",
            "Epoch 15: val_accuracy improved from 0.76797 to 0.78203, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.6333 - accuracy: 0.5973 - sensitivity_at_specificity: 0.5428 - specificity_at_sensitivity: 0.5487 - recall: 0.9846 - precision: 0.5581 - val_loss: 0.4724 - val_accuracy: 0.7820 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5859 - val_recall: 0.9889 - val_precision: 0.6954\n",
            "Epoch 16/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6452 - accuracy: 0.5535 - sensitivity_at_specificity: 0.5930 - specificity_at_sensitivity: 0.5068 - recall: 0.8366 - precision: 0.5235\n",
            "Epoch 16: val_accuracy did not improve from 0.78203\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.6452 - accuracy: 0.5535 - sensitivity_at_specificity: 0.5930 - specificity_at_sensitivity: 0.5068 - recall: 0.8366 - precision: 0.5235 - val_loss: 0.5093 - val_accuracy: 0.7484 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.6034 - val_recall: 0.9011 - val_precision: 0.6848\n",
            "Epoch 17/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6423 - accuracy: 0.5918 - sensitivity_at_specificity: 0.5678 - specificity_at_sensitivity: 0.5455 - recall: 0.9704 - precision: 0.5530\n",
            "Epoch 17: val_accuracy improved from 0.78203 to 0.78750, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 186ms/step - loss: 0.6423 - accuracy: 0.5918 - sensitivity_at_specificity: 0.5678 - specificity_at_sensitivity: 0.5455 - recall: 0.9704 - precision: 0.5530 - val_loss: 0.4939 - val_accuracy: 0.7875 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 0.5864 - val_recall: 0.9846 - val_precision: 0.7092\n",
            "Epoch 18/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6285 - accuracy: 0.6074 - sensitivity_at_specificity: 0.5274 - specificity_at_sensitivity: 0.5691 - recall: 0.9787 - precision: 0.5687\n",
            "Epoch 18: val_accuracy improved from 0.78750 to 0.79531, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 178ms/step - loss: 0.6285 - accuracy: 0.6074 - sensitivity_at_specificity: 0.5274 - specificity_at_sensitivity: 0.5691 - recall: 0.9787 - precision: 0.5687 - val_loss: 0.4608 - val_accuracy: 0.7953 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.6009 - val_recall: 0.9953 - val_precision: 0.7096\n",
            "Epoch 19/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6486 - accuracy: 0.5914 - sensitivity_at_specificity: 0.4376 - specificity_at_sensitivity: 0.4904 - recall: 0.9802 - precision: 0.5581\n",
            "Epoch 19: val_accuracy improved from 0.79531 to 0.79609, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.6486 - accuracy: 0.5914 - sensitivity_at_specificity: 0.4376 - specificity_at_sensitivity: 0.4904 - recall: 0.9802 - precision: 0.5581 - val_loss: 0.4939 - val_accuracy: 0.7961 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5760 - val_recall: 0.9912 - val_precision: 0.7258\n",
            "Epoch 20/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6459 - accuracy: 0.5930 - sensitivity_at_specificity: 0.4873 - specificity_at_sensitivity: 0.4185 - recall: 0.9823 - precision: 0.5568\n",
            "Epoch 20: val_accuracy did not improve from 0.79609\n",
            "10/10 [==============================] - 2s 156ms/step - loss: 0.6459 - accuracy: 0.5930 - sensitivity_at_specificity: 0.4873 - specificity_at_sensitivity: 0.4185 - recall: 0.9823 - precision: 0.5568 - val_loss: 0.4983 - val_accuracy: 0.7703 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.5848 - val_recall: 0.9655 - val_precision: 0.6933\n",
            "Epoch 21/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6360 - accuracy: 0.5746 - sensitivity_at_specificity: 0.5676 - specificity_at_sensitivity: 0.5395 - recall: 0.9614 - precision: 0.5342\n",
            "Epoch 21: val_accuracy did not improve from 0.79609\n",
            "10/10 [==============================] - 2s 154ms/step - loss: 0.6360 - accuracy: 0.5746 - sensitivity_at_specificity: 0.5676 - specificity_at_sensitivity: 0.5395 - recall: 0.9614 - precision: 0.5342 - val_loss: 0.4933 - val_accuracy: 0.7789 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5728 - val_recall: 0.9875 - val_precision: 0.6971\n",
            "Epoch 22/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6441 - accuracy: 0.5742 - sensitivity_at_specificity: 0.5614 - specificity_at_sensitivity: 0.5345 - recall: 0.9769 - precision: 0.5359\n",
            "Epoch 22: val_accuracy improved from 0.79609 to 0.80625, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.6441 - accuracy: 0.5742 - sensitivity_at_specificity: 0.5614 - specificity_at_sensitivity: 0.5345 - recall: 0.9769 - precision: 0.5359 - val_loss: 0.4843 - val_accuracy: 0.8062 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 0.6292 - val_recall: 0.9802 - val_precision: 0.7327\n",
            "Epoch 23/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6379 - accuracy: 0.5973 - sensitivity_at_specificity: 0.5949 - specificity_at_sensitivity: 0.5201 - recall: 0.9794 - precision: 0.5519\n",
            "Epoch 23: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 2s 175ms/step - loss: 0.6379 - accuracy: 0.5973 - sensitivity_at_specificity: 0.5949 - specificity_at_sensitivity: 0.5201 - recall: 0.9794 - precision: 0.5519 - val_loss: 0.4973 - val_accuracy: 0.7648 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5939 - val_recall: 0.9356 - val_precision: 0.7020\n",
            "Epoch 24/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6334 - accuracy: 0.5926 - sensitivity_at_specificity: 0.4727 - specificity_at_sensitivity: 0.4555 - recall: 0.9648 - precision: 0.5531\n",
            "Epoch 24: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 2s 154ms/step - loss: 0.6334 - accuracy: 0.5926 - sensitivity_at_specificity: 0.4727 - specificity_at_sensitivity: 0.4555 - recall: 0.9648 - precision: 0.5531 - val_loss: 0.4860 - val_accuracy: 0.7797 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 0.5800 - val_recall: 0.9815 - val_precision: 0.7023\n",
            "Epoch 25/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6346 - accuracy: 0.5883 - sensitivity_at_specificity: 0.5079 - specificity_at_sensitivity: 0.5922 - recall: 0.9698 - precision: 0.5456\n",
            "Epoch 25: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.6346 - accuracy: 0.5883 - sensitivity_at_specificity: 0.5079 - specificity_at_sensitivity: 0.5922 - recall: 0.9698 - precision: 0.5456 - val_loss: 0.4822 - val_accuracy: 0.7898 - val_sensitivity_at_specificity: 0.9968 - val_specificity_at_sensitivity: 0.7569 - val_recall: 0.9968 - val_precision: 0.7003\n",
            "Epoch 26/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6385 - accuracy: 0.5977 - sensitivity_at_specificity: 0.4217 - specificity_at_sensitivity: 0.4229 - recall: 0.9735 - precision: 0.5638\n",
            "Epoch 26: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 2s 156ms/step - loss: 0.6385 - accuracy: 0.5977 - sensitivity_at_specificity: 0.4217 - specificity_at_sensitivity: 0.4229 - recall: 0.9735 - precision: 0.5638 - val_loss: 0.4738 - val_accuracy: 0.7992 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.6250 - val_recall: 0.9741 - val_precision: 0.7270\n",
            "Epoch 27/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6282 - accuracy: 0.5965 - sensitivity_at_specificity: 0.5063 - specificity_at_sensitivity: 0.5924 - recall: 0.9764 - precision: 0.5532\n",
            "Epoch 27: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.6282 - accuracy: 0.5965 - sensitivity_at_specificity: 0.5063 - specificity_at_sensitivity: 0.5924 - recall: 0.9764 - precision: 0.5532 - val_loss: 0.4774 - val_accuracy: 0.7797 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.5886 - val_recall: 0.9902 - val_precision: 0.6878\n",
            "Epoch 28/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6251 - accuracy: 0.5969 - sensitivity_at_specificity: 0.6560 - specificity_at_sensitivity: 0.5822 - recall: 0.9497 - precision: 0.5512\n",
            "Epoch 28: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 2s 157ms/step - loss: 0.6251 - accuracy: 0.5969 - sensitivity_at_specificity: 0.6560 - specificity_at_sensitivity: 0.5822 - recall: 0.9497 - precision: 0.5512 - val_loss: 0.5134 - val_accuracy: 0.7391 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.7312 - val_recall: 0.8766 - val_precision: 0.6875\n",
            "Epoch 29/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6481 - accuracy: 0.5895 - sensitivity_at_specificity: 0.5039 - specificity_at_sensitivity: 0.5992 - recall: 0.9605 - precision: 0.5534\n",
            "Epoch 29: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 2s 155ms/step - loss: 0.6481 - accuracy: 0.5895 - sensitivity_at_specificity: 0.5039 - specificity_at_sensitivity: 0.5992 - recall: 0.9605 - precision: 0.5534 - val_loss: 0.5060 - val_accuracy: 0.7641 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5248 - val_recall: 0.9939 - val_precision: 0.6860\n",
            "Epoch 30/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6356 - accuracy: 0.5867 - sensitivity_at_specificity: 0.4589 - specificity_at_sensitivity: 0.4864 - recall: 0.9366 - precision: 0.5504\n",
            "Epoch 30: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.6356 - accuracy: 0.5867 - sensitivity_at_specificity: 0.4589 - specificity_at_sensitivity: 0.4864 - recall: 0.9366 - precision: 0.5504 - val_loss: 0.4842 - val_accuracy: 0.7727 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.6019 - val_recall: 0.9778 - val_precision: 0.6905\n",
            "Epoch 31/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6310 - accuracy: 0.6042 - sensitivity_at_specificity: 0.4701 - specificity_at_sensitivity: 0.4693 - recall: 0.9770 - precision: 0.5629\n",
            "Epoch 31: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 2s 153ms/step - loss: 0.6310 - accuracy: 0.6042 - sensitivity_at_specificity: 0.4701 - specificity_at_sensitivity: 0.4693 - recall: 0.9770 - precision: 0.5629 - val_loss: 0.4741 - val_accuracy: 0.7812 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5891 - val_recall: 0.9828 - val_precision: 0.7004\n",
            "Epoch 32/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6233 - accuracy: 0.6086 - sensitivity_at_specificity: 0.5494 - specificity_at_sensitivity: 0.5584 - recall: 0.9890 - precision: 0.5609\n",
            "Epoch 32: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.6233 - accuracy: 0.6086 - sensitivity_at_specificity: 0.5494 - specificity_at_sensitivity: 0.5584 - recall: 0.9890 - precision: 0.5609 - val_loss: 0.5062 - val_accuracy: 0.7656 - val_sensitivity_at_specificity: 0.9952 - val_specificity_at_sensitivity: 0.5994 - val_recall: 0.9485 - val_precision: 0.6873\n",
            "Epoch 33/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6300 - accuracy: 0.5922 - sensitivity_at_specificity: 0.6609 - specificity_at_sensitivity: 0.5139 - recall: 0.9707 - precision: 0.5488\n",
            "Epoch 33: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 2s 154ms/step - loss: 0.6300 - accuracy: 0.5922 - sensitivity_at_specificity: 0.6609 - specificity_at_sensitivity: 0.5139 - recall: 0.9707 - precision: 0.5488 - val_loss: 0.4814 - val_accuracy: 0.7789 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.5728 - val_recall: 0.9953 - val_precision: 0.6926\n",
            "Epoch 34/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6351 - accuracy: 0.5887 - sensitivity_at_specificity: 0.4225 - specificity_at_sensitivity: 0.4670 - recall: 0.9748 - precision: 0.5482\n",
            "Epoch 34: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.6351 - accuracy: 0.5887 - sensitivity_at_specificity: 0.4225 - specificity_at_sensitivity: 0.4670 - recall: 0.9748 - precision: 0.5482 - val_loss: 0.4868 - val_accuracy: 0.7852 - val_sensitivity_at_specificity: 0.9968 - val_specificity_at_sensitivity: 0.6028 - val_recall: 0.9779 - val_precision: 0.7034\n",
            "Epoch 35/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6515 - accuracy: 0.5715 - sensitivity_at_specificity: 0.5533 - specificity_at_sensitivity: 0.5469 - recall: 0.9873 - precision: 0.5347\n",
            "Epoch 35: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.6515 - accuracy: 0.5715 - sensitivity_at_specificity: 0.5533 - specificity_at_sensitivity: 0.5469 - recall: 0.9873 - precision: 0.5347 - val_loss: 0.4877 - val_accuracy: 0.7891 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5762 - val_recall: 0.9985 - val_precision: 0.7070\n",
            "Epoch 36/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6380 - accuracy: 0.5879 - sensitivity_at_specificity: 0.4047 - specificity_at_sensitivity: 0.3784 - recall: 0.9549 - precision: 0.5476\n",
            "Epoch 36: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.6380 - accuracy: 0.5879 - sensitivity_at_specificity: 0.4047 - specificity_at_sensitivity: 0.3784 - recall: 0.9549 - precision: 0.5476 - val_loss: 0.4994 - val_accuracy: 0.7641 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.5669 - val_recall: 0.9674 - val_precision: 0.6895\n",
            "Epoch 37/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6266 - accuracy: 0.6000 - sensitivity_at_specificity: 0.4712 - specificity_at_sensitivity: 0.4129 - recall: 0.9779 - precision: 0.5548\n",
            "Epoch 37: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.6266 - accuracy: 0.6000 - sensitivity_at_specificity: 0.4712 - specificity_at_sensitivity: 0.4129 - recall: 0.9779 - precision: 0.5548 - val_loss: 0.4915 - val_accuracy: 0.7828 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5742 - val_recall: 0.9833 - val_precision: 0.7085\n",
            "Epoch 38/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6418 - accuracy: 0.5867 - sensitivity_at_specificity: 0.4969 - specificity_at_sensitivity: 0.3866 - recall: 0.9772 - precision: 0.5471\n",
            "Epoch 38: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.6418 - accuracy: 0.5867 - sensitivity_at_specificity: 0.4969 - specificity_at_sensitivity: 0.3866 - recall: 0.9772 - precision: 0.5471 - val_loss: 0.4750 - val_accuracy: 0.7937 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5892 - val_recall: 0.9923 - val_precision: 0.7141\n",
            "Epoch 39/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6297 - accuracy: 0.6008 - sensitivity_at_specificity: 0.4385 - specificity_at_sensitivity: 0.4342 - recall: 0.9813 - precision: 0.5580\n",
            "Epoch 39: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.6297 - accuracy: 0.6008 - sensitivity_at_specificity: 0.4385 - specificity_at_sensitivity: 0.4342 - recall: 0.9813 - precision: 0.5580 - val_loss: 0.4900 - val_accuracy: 0.7617 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.6221 - val_recall: 0.9316 - val_precision: 0.6910\n",
            "Epoch 40/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6385 - accuracy: 0.5902 - sensitivity_at_specificity: 0.4687 - specificity_at_sensitivity: 0.3972 - recall: 0.9624 - precision: 0.5509\n",
            "Epoch 40: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.6385 - accuracy: 0.5902 - sensitivity_at_specificity: 0.4687 - specificity_at_sensitivity: 0.3972 - recall: 0.9624 - precision: 0.5509 - val_loss: 0.4795 - val_accuracy: 0.7953 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 0.7624 - val_recall: 0.9756 - val_precision: 0.7227\n",
            "Epoch 41/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6349 - accuracy: 0.5895 - sensitivity_at_specificity: 0.3405 - specificity_at_sensitivity: 0.4900 - recall: 0.9641 - precision: 0.5458\n",
            "Epoch 41: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.6349 - accuracy: 0.5895 - sensitivity_at_specificity: 0.3405 - specificity_at_sensitivity: 0.4900 - recall: 0.9641 - precision: 0.5458 - val_loss: 0.4875 - val_accuracy: 0.7656 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7060 - val_recall: 0.9177 - val_precision: 0.7053\n",
            "Epoch 42/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6341 - accuracy: 0.5816 - sensitivity_at_specificity: 0.4612 - specificity_at_sensitivity: 0.4427 - recall: 0.9159 - precision: 0.5368\n",
            "Epoch 42: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.6341 - accuracy: 0.5816 - sensitivity_at_specificity: 0.4612 - specificity_at_sensitivity: 0.4427 - recall: 0.9159 - precision: 0.5368 - val_loss: 0.4822 - val_accuracy: 0.7648 - val_sensitivity_at_specificity: 0.9967 - val_specificity_at_sensitivity: 0.6552 - val_recall: 0.9311 - val_precision: 0.6868\n",
            "Epoch 43/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6288 - accuracy: 0.6016 - sensitivity_at_specificity: 0.5341 - specificity_at_sensitivity: 0.5643 - recall: 0.9327 - precision: 0.5605\n",
            "Epoch 43: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.6288 - accuracy: 0.6016 - sensitivity_at_specificity: 0.5341 - specificity_at_sensitivity: 0.5643 - recall: 0.9327 - precision: 0.5605 - val_loss: 0.4821 - val_accuracy: 0.7805 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.6486 - val_recall: 0.9493 - val_precision: 0.7136\n",
            "Epoch 44/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6257 - accuracy: 0.6047 - sensitivity_at_specificity: 0.6514 - specificity_at_sensitivity: 0.5033 - recall: 0.9468 - precision: 0.5617\n",
            "Epoch 44: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 2s 174ms/step - loss: 0.6257 - accuracy: 0.6047 - sensitivity_at_specificity: 0.6514 - specificity_at_sensitivity: 0.5033 - recall: 0.9468 - precision: 0.5617 - val_loss: 0.4643 - val_accuracy: 0.7898 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7027 - val_recall: 0.9438 - val_precision: 0.7220\n",
            "Epoch 45/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6224 - accuracy: 0.5980 - sensitivity_at_specificity: 0.6258 - specificity_at_sensitivity: 0.5239 - recall: 0.9415 - precision: 0.5548\n",
            "Epoch 45: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.6224 - accuracy: 0.5980 - sensitivity_at_specificity: 0.6258 - specificity_at_sensitivity: 0.5239 - recall: 0.9415 - precision: 0.5548 - val_loss: 0.4967 - val_accuracy: 0.7320 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.7865 - val_recall: 0.7885 - val_precision: 0.7101\n",
            "Epoch 46/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6432 - accuracy: 0.5816 - sensitivity_at_specificity: 0.5162 - specificity_at_sensitivity: 0.5677 - recall: 0.9440 - precision: 0.5446\n",
            "Epoch 46: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.6432 - accuracy: 0.5816 - sensitivity_at_specificity: 0.5162 - specificity_at_sensitivity: 0.5677 - recall: 0.9440 - precision: 0.5446 - val_loss: 0.4771 - val_accuracy: 0.7898 - val_sensitivity_at_specificity: 0.9968 - val_specificity_at_sensitivity: 0.6009 - val_recall: 0.9936 - val_precision: 0.6995\n",
            "Epoch 47/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6410 - accuracy: 0.5742 - sensitivity_at_specificity: 0.4767 - specificity_at_sensitivity: 0.4132 - recall: 0.9342 - precision: 0.5359\n",
            "Epoch 47: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.6410 - accuracy: 0.5742 - sensitivity_at_specificity: 0.4767 - specificity_at_sensitivity: 0.4132 - recall: 0.9342 - precision: 0.5359 - val_loss: 0.4823 - val_accuracy: 0.7695 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5920 - val_recall: 0.9650 - val_precision: 0.6894\n",
            "Epoch 48/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6313 - accuracy: 0.5973 - sensitivity_at_specificity: 0.4808 - specificity_at_sensitivity: 0.3333 - recall: 0.9789 - precision: 0.5550\n",
            "Epoch 48: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.6313 - accuracy: 0.5973 - sensitivity_at_specificity: 0.4808 - specificity_at_sensitivity: 0.3333 - recall: 0.9789 - precision: 0.5550 - val_loss: 0.4711 - val_accuracy: 0.7844 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.6036 - val_recall: 0.9902 - val_precision: 0.6925\n",
            "Epoch 49/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6240 - accuracy: 0.6102 - sensitivity_at_specificity: 0.3553 - specificity_at_sensitivity: 0.4854 - recall: 0.9503 - precision: 0.5674\n",
            "Epoch 49: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.6240 - accuracy: 0.6102 - sensitivity_at_specificity: 0.3553 - specificity_at_sensitivity: 0.4854 - recall: 0.9503 - precision: 0.5674 - val_loss: 0.4682 - val_accuracy: 0.7797 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.6703 - val_recall: 0.9359 - val_precision: 0.7131\n",
            "Epoch 50/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6317 - accuracy: 0.6098 - sensitivity_at_specificity: 0.4300 - specificity_at_sensitivity: 0.4933 - recall: 0.9358 - precision: 0.5691\n",
            "Epoch 50: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.6317 - accuracy: 0.6098 - sensitivity_at_specificity: 0.4300 - specificity_at_sensitivity: 0.4933 - recall: 0.9358 - precision: 0.5691 - val_loss: 0.4768 - val_accuracy: 0.7773 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5871 - val_recall: 0.9813 - val_precision: 0.6980\n",
            "Epoch 51/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6257 - accuracy: 0.6059 - sensitivity_at_specificity: 0.5692 - specificity_at_sensitivity: 0.5437 - recall: 0.9608 - precision: 0.5659\n",
            "Epoch 51: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.6257 - accuracy: 0.6059 - sensitivity_at_specificity: 0.5692 - specificity_at_sensitivity: 0.5437 - recall: 0.9608 - precision: 0.5659 - val_loss: 0.4759 - val_accuracy: 0.7828 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.6041 - val_recall: 0.9770 - val_precision: 0.7075\n",
            "Epoch 52/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6215 - accuracy: 0.6023 - sensitivity_at_specificity: 0.6074 - specificity_at_sensitivity: 0.5368 - recall: 0.9308 - precision: 0.5539\n",
            "Epoch 52: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.6215 - accuracy: 0.6023 - sensitivity_at_specificity: 0.6074 - specificity_at_sensitivity: 0.5368 - recall: 0.9308 - precision: 0.5539 - val_loss: 0.4709 - val_accuracy: 0.7773 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.6140 - val_recall: 0.9775 - val_precision: 0.6917\n",
            "Epoch 53/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6277 - accuracy: 0.5831 - sensitivity_at_specificity: 0.5307 - specificity_at_sensitivity: 0.5810 - recall: 0.8675 - precision: 0.5407\n",
            "Epoch 53: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 2s 156ms/step - loss: 0.6277 - accuracy: 0.5831 - sensitivity_at_specificity: 0.5307 - specificity_at_sensitivity: 0.5810 - recall: 0.8675 - precision: 0.5407 - val_loss: 0.4789 - val_accuracy: 0.7828 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.5967 - val_recall: 0.9904 - val_precision: 0.6940\n",
            "Epoch 54/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6349 - accuracy: 0.5926 - sensitivity_at_specificity: 0.5911 - specificity_at_sensitivity: 0.5179 - recall: 0.9733 - precision: 0.5514\n",
            "Epoch 54: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 2s 155ms/step - loss: 0.6349 - accuracy: 0.5926 - sensitivity_at_specificity: 0.5911 - specificity_at_sensitivity: 0.5179 - recall: 0.9733 - precision: 0.5514 - val_loss: 0.4852 - val_accuracy: 0.7758 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 0.6736 - val_recall: 0.9387 - val_precision: 0.7125\n",
            "Epoch 55/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6270 - accuracy: 0.6141 - sensitivity_at_specificity: 0.5872 - specificity_at_sensitivity: 0.5630 - recall: 0.9284 - precision: 0.5769\n",
            "Epoch 55: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.6270 - accuracy: 0.6141 - sensitivity_at_specificity: 0.5872 - specificity_at_sensitivity: 0.5630 - recall: 0.9284 - precision: 0.5769 - val_loss: 0.4726 - val_accuracy: 0.7852 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.6891 - val_recall: 0.9466 - val_precision: 0.7213\n",
            "Epoch 56/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6336 - accuracy: 0.5957 - sensitivity_at_specificity: 0.5933 - specificity_at_sensitivity: 0.5343 - recall: 0.9078 - precision: 0.5613\n",
            "Epoch 56: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.6336 - accuracy: 0.5957 - sensitivity_at_specificity: 0.5933 - specificity_at_sensitivity: 0.5343 - recall: 0.9078 - precision: 0.5613 - val_loss: 0.4651 - val_accuracy: 0.7945 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.6181 - val_recall: 0.9984 - val_precision: 0.7053\n",
            "Epoch 57/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6358 - accuracy: 0.5977 - sensitivity_at_specificity: 0.5505 - specificity_at_sensitivity: 0.5495 - recall: 0.9673 - precision: 0.5573\n",
            "Epoch 57: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 2s 156ms/step - loss: 0.6358 - accuracy: 0.5977 - sensitivity_at_specificity: 0.5505 - specificity_at_sensitivity: 0.5495 - recall: 0.9673 - precision: 0.5573 - val_loss: 0.4517 - val_accuracy: 0.8008 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.6495 - val_recall: 0.9790 - val_precision: 0.7143\n",
            "Epoch 58/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6255 - accuracy: 0.6016 - sensitivity_at_specificity: 0.2934 - specificity_at_sensitivity: 0.4954 - recall: 0.9866 - precision: 0.5550\n",
            "Epoch 58: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.6255 - accuracy: 0.6016 - sensitivity_at_specificity: 0.2934 - specificity_at_sensitivity: 0.4954 - recall: 0.9866 - precision: 0.5550 - val_loss: 0.4756 - val_accuracy: 0.7656 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.6548 - val_recall: 0.9306 - val_precision: 0.6974\n",
            "Epoch 59/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6247 - accuracy: 0.6051 - sensitivity_at_specificity: 0.5997 - specificity_at_sensitivity: 0.5282 - recall: 0.9431 - precision: 0.5635\n",
            "Epoch 59: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.6247 - accuracy: 0.6051 - sensitivity_at_specificity: 0.5997 - specificity_at_sensitivity: 0.5282 - recall: 0.9431 - precision: 0.5635 - val_loss: 0.4680 - val_accuracy: 0.7922 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.6577 - val_recall: 0.9507 - val_precision: 0.7250\n",
            "Epoch 60/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6330 - accuracy: 0.5957 - sensitivity_at_specificity: 0.5839 - specificity_at_sensitivity: 0.5293 - recall: 0.9742 - precision: 0.5547\n",
            "Epoch 60: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.6330 - accuracy: 0.5957 - sensitivity_at_specificity: 0.5839 - specificity_at_sensitivity: 0.5293 - recall: 0.9742 - precision: 0.5547 - val_loss: 0.4682 - val_accuracy: 0.7805 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5773 - val_recall: 0.9984 - val_precision: 0.6885\n",
            "Epoch 61/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6320 - accuracy: 0.6070 - sensitivity_at_specificity: 0.4492 - specificity_at_sensitivity: 0.4097 - recall: 0.9598 - precision: 0.5707\n",
            "Epoch 61: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.6320 - accuracy: 0.6070 - sensitivity_at_specificity: 0.4492 - specificity_at_sensitivity: 0.4097 - recall: 0.9598 - precision: 0.5707 - val_loss: 0.4717 - val_accuracy: 0.7820 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5797 - val_recall: 0.9953 - val_precision: 0.6977\n",
            "Epoch 62/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6284 - accuracy: 0.6035 - sensitivity_at_specificity: 0.5112 - specificity_at_sensitivity: 0.6273 - recall: 0.9915 - precision: 0.5620\n",
            "Epoch 62: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.6284 - accuracy: 0.6035 - sensitivity_at_specificity: 0.5112 - specificity_at_sensitivity: 0.6273 - recall: 0.9915 - precision: 0.5620 - val_loss: 0.4688 - val_accuracy: 0.7719 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7792 - val_recall: 0.8838 - val_precision: 0.7209\n",
            "Epoch 63/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6279 - accuracy: 0.6062 - sensitivity_at_specificity: 0.5807 - specificity_at_sensitivity: 0.5573 - recall: 0.9050 - precision: 0.5698\n",
            "Epoch 63: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.6279 - accuracy: 0.6062 - sensitivity_at_specificity: 0.5807 - specificity_at_sensitivity: 0.5573 - recall: 0.9050 - precision: 0.5698 - val_loss: 0.4617 - val_accuracy: 0.7883 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.6708 - val_recall: 0.9889 - val_precision: 0.7024\n",
            "Epoch 64/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6234 - accuracy: 0.6098 - sensitivity_at_specificity: 0.5317 - specificity_at_sensitivity: 0.5735 - recall: 0.9722 - precision: 0.5664\n",
            "Epoch 64: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.6234 - accuracy: 0.6098 - sensitivity_at_specificity: 0.5317 - specificity_at_sensitivity: 0.5735 - recall: 0.9722 - precision: 0.5664 - val_loss: 0.4792 - val_accuracy: 0.7883 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 0.6346 - val_recall: 0.9512 - val_precision: 0.7231\n",
            "Epoch 65/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6171 - accuracy: 0.6250 - sensitivity_at_specificity: 0.4488 - specificity_at_sensitivity: 0.4940 - recall: 0.9800 - precision: 0.5825\n",
            "Epoch 65: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.6171 - accuracy: 0.6250 - sensitivity_at_specificity: 0.4488 - specificity_at_sensitivity: 0.4940 - recall: 0.9800 - precision: 0.5825 - val_loss: 0.4604 - val_accuracy: 0.7922 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.6013 - val_recall: 0.9815 - val_precision: 0.7146\n",
            "Epoch 66/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6378 - accuracy: 0.5926 - sensitivity_at_specificity: 0.4926 - specificity_at_sensitivity: 0.4227 - recall: 0.9782 - precision: 0.5533\n",
            "Epoch 66: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.6378 - accuracy: 0.5926 - sensitivity_at_specificity: 0.4926 - specificity_at_sensitivity: 0.4227 - recall: 0.9782 - precision: 0.5533 - val_loss: 0.4737 - val_accuracy: 0.7836 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 0.5946 - val_recall: 0.9846 - val_precision: 0.7059\n",
            "Epoch 67/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6193 - accuracy: 0.6008 - sensitivity_at_specificity: 0.4774 - specificity_at_sensitivity: 0.4058 - recall: 0.9738 - precision: 0.5535\n",
            "Epoch 67: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.6193 - accuracy: 0.6008 - sensitivity_at_specificity: 0.4774 - specificity_at_sensitivity: 0.4058 - recall: 0.9738 - precision: 0.5535 - val_loss: 0.4824 - val_accuracy: 0.7617 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5751 - val_recall: 0.9710 - val_precision: 0.6775\n",
            "Epoch 68/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6204 - accuracy: 0.5996 - sensitivity_at_specificity: 0.2720 - specificity_at_sensitivity: 0.4633 - recall: 0.9798 - precision: 0.5483\n",
            "Epoch 68: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.6204 - accuracy: 0.5996 - sensitivity_at_specificity: 0.2720 - specificity_at_sensitivity: 0.4633 - recall: 0.9798 - precision: 0.5483 - val_loss: 0.4712 - val_accuracy: 0.8023 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.6232 - val_recall: 0.9775 - val_precision: 0.7326\n",
            "Epoch 69/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6214 - accuracy: 0.6203 - sensitivity_at_specificity: 0.5623 - specificity_at_sensitivity: 0.5691 - recall: 0.9681 - precision: 0.5780\n",
            "Epoch 69: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.6214 - accuracy: 0.6203 - sensitivity_at_specificity: 0.5623 - specificity_at_sensitivity: 0.5691 - recall: 0.9681 - precision: 0.5780 - val_loss: 0.4622 - val_accuracy: 0.7797 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5932 - val_recall: 0.9967 - val_precision: 0.6807\n",
            "Epoch 70/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6292 - accuracy: 0.6082 - sensitivity_at_specificity: 0.5685 - specificity_at_sensitivity: 0.5563 - recall: 0.9472 - precision: 0.5700\n",
            "Epoch 70: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 2s 157ms/step - loss: 0.6292 - accuracy: 0.6082 - sensitivity_at_specificity: 0.5685 - specificity_at_sensitivity: 0.5563 - recall: 0.9472 - precision: 0.5700 - val_loss: 0.4673 - val_accuracy: 0.8031 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5954 - val_recall: 1.0000 - val_precision: 0.7273\n",
            "Epoch 71/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6287 - accuracy: 0.5926 - sensitivity_at_specificity: 0.4135 - specificity_at_sensitivity: 0.4934 - recall: 0.9593 - precision: 0.5528\n",
            "Epoch 71: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 2s 157ms/step - loss: 0.6287 - accuracy: 0.5926 - sensitivity_at_specificity: 0.4135 - specificity_at_sensitivity: 0.4934 - recall: 0.9593 - precision: 0.5528 - val_loss: 0.4707 - val_accuracy: 0.7750 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.6972 - val_recall: 0.9355 - val_precision: 0.7067\n",
            "Epoch 72/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6291 - accuracy: 0.5938 - sensitivity_at_specificity: 0.4988 - specificity_at_sensitivity: 0.3951 - recall: 0.9754 - precision: 0.5489\n",
            "Epoch 72: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.6291 - accuracy: 0.5938 - sensitivity_at_specificity: 0.4988 - specificity_at_sensitivity: 0.3951 - recall: 0.9754 - precision: 0.5489 - val_loss: 0.4800 - val_accuracy: 0.7750 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5910 - val_recall: 0.9890 - val_precision: 0.6915\n",
            "Epoch 73/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6266 - accuracy: 0.5832 - sensitivity_at_specificity: 0.3217 - specificity_at_sensitivity: 0.4815 - recall: 0.9515 - precision: 0.5389\n",
            "Epoch 73: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.6266 - accuracy: 0.5832 - sensitivity_at_specificity: 0.3217 - specificity_at_sensitivity: 0.4815 - recall: 0.9515 - precision: 0.5389 - val_loss: 0.4764 - val_accuracy: 0.7836 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5750 - val_recall: 0.9969 - val_precision: 0.6988\n",
            "Epoch 74/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6257 - accuracy: 0.6004 - sensitivity_at_specificity: 0.5970 - specificity_at_sensitivity: 0.5175 - recall: 0.9654 - precision: 0.5566\n",
            "Epoch 74: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.6257 - accuracy: 0.6004 - sensitivity_at_specificity: 0.5970 - specificity_at_sensitivity: 0.5175 - recall: 0.9654 - precision: 0.5566 - val_loss: 0.4665 - val_accuracy: 0.7797 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5967 - val_recall: 0.9759 - val_precision: 0.6949\n",
            "Epoch 75/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6222 - accuracy: 0.5992 - sensitivity_at_specificity: 0.6040 - specificity_at_sensitivity: 0.5730 - recall: 0.9866 - precision: 0.5529\n",
            "Epoch 75: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.6222 - accuracy: 0.5992 - sensitivity_at_specificity: 0.6040 - specificity_at_sensitivity: 0.5730 - recall: 0.9866 - precision: 0.5529 - val_loss: 0.4983 - val_accuracy: 0.7594 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5447 - val_recall: 0.9798 - val_precision: 0.6811\n",
            "Epoch 76/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6236 - accuracy: 0.6043 - sensitivity_at_specificity: 0.2795 - specificity_at_sensitivity: 0.4505 - recall: 0.9697 - precision: 0.5619\n",
            "Epoch 76: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.6236 - accuracy: 0.6043 - sensitivity_at_specificity: 0.2795 - specificity_at_sensitivity: 0.4505 - recall: 0.9697 - precision: 0.5619 - val_loss: 0.4699 - val_accuracy: 0.7852 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5938 - val_recall: 0.9890 - val_precision: 0.7009\n",
            "Epoch 77/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6258 - accuracy: 0.6031 - sensitivity_at_specificity: 0.2929 - specificity_at_sensitivity: 0.4784 - recall: 0.9814 - precision: 0.5601\n",
            "Epoch 77: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 2s 157ms/step - loss: 0.6258 - accuracy: 0.6031 - sensitivity_at_specificity: 0.2929 - specificity_at_sensitivity: 0.4784 - recall: 0.9814 - precision: 0.5601 - val_loss: 0.4735 - val_accuracy: 0.7734 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5805 - val_recall: 0.9887 - val_precision: 0.6849\n",
            "Epoch 78/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6207 - accuracy: 0.5934 - sensitivity_at_specificity: 0.5782 - specificity_at_sensitivity: 0.5197 - recall: 0.9750 - precision: 0.5448\n",
            "Epoch 78: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.6207 - accuracy: 0.5934 - sensitivity_at_specificity: 0.5782 - specificity_at_sensitivity: 0.5197 - recall: 0.9750 - precision: 0.5448 - val_loss: 0.4523 - val_accuracy: 0.7922 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.6123 - val_recall: 0.9902 - val_precision: 0.6998\n",
            "Epoch 79/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6230 - accuracy: 0.5961 - sensitivity_at_specificity: 0.6161 - specificity_at_sensitivity: 0.5247 - recall: 0.9743 - precision: 0.5476\n",
            "Epoch 79: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 2s 157ms/step - loss: 0.6230 - accuracy: 0.5961 - sensitivity_at_specificity: 0.6161 - specificity_at_sensitivity: 0.5247 - recall: 0.9743 - precision: 0.5476 - val_loss: 0.4584 - val_accuracy: 0.7906 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.6211 - val_recall: 0.9870 - val_precision: 0.7001\n",
            "Epoch 80/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6228 - accuracy: 0.6098 - sensitivity_at_specificity: 0.3477 - specificity_at_sensitivity: 0.4127 - recall: 0.9762 - precision: 0.5673\n",
            "Epoch 80: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.6228 - accuracy: 0.6098 - sensitivity_at_specificity: 0.3477 - specificity_at_sensitivity: 0.4127 - recall: 0.9762 - precision: 0.5673 - val_loss: 0.4693 - val_accuracy: 0.7688 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.6057 - val_recall: 0.9657 - val_precision: 0.6828\n",
            "Epoch 81/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6177 - accuracy: 0.6184 - sensitivity_at_specificity: 0.4271 - specificity_at_sensitivity: 0.4252 - recall: 0.9757 - precision: 0.5760\n",
            "Epoch 81: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.6177 - accuracy: 0.6184 - sensitivity_at_specificity: 0.4271 - specificity_at_sensitivity: 0.4252 - recall: 0.9757 - precision: 0.5760 - val_loss: 0.4667 - val_accuracy: 0.7844 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5814 - val_recall: 0.9921 - val_precision: 0.6992\n",
            "Epoch 82/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6215 - accuracy: 0.6187 - sensitivity_at_specificity: 0.5757 - specificity_at_sensitivity: 0.5580 - recall: 0.9812 - precision: 0.5779\n",
            "Epoch 82: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 2s 157ms/step - loss: 0.6215 - accuracy: 0.6187 - sensitivity_at_specificity: 0.5757 - specificity_at_sensitivity: 0.5580 - recall: 0.9812 - precision: 0.5779 - val_loss: 0.4625 - val_accuracy: 0.7930 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5910 - val_recall: 0.9984 - val_precision: 0.7067\n",
            "Epoch 83/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6244 - accuracy: 0.6004 - sensitivity_at_specificity: 0.5719 - specificity_at_sensitivity: 0.5437 - recall: 0.9914 - precision: 0.5563\n",
            "Epoch 83: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.6244 - accuracy: 0.6004 - sensitivity_at_specificity: 0.5719 - specificity_at_sensitivity: 0.5437 - recall: 0.9914 - precision: 0.5563 - val_loss: 0.4664 - val_accuracy: 0.7773 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.6157 - val_recall: 0.9652 - val_precision: 0.6987\n",
            "Epoch 84/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6266 - accuracy: 0.5957 - sensitivity_at_specificity: 0.3675 - specificity_at_sensitivity: 0.4692 - recall: 0.9825 - precision: 0.5500\n",
            "Epoch 84: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.6266 - accuracy: 0.5957 - sensitivity_at_specificity: 0.3675 - specificity_at_sensitivity: 0.4692 - recall: 0.9825 - precision: 0.5500 - val_loss: 0.4774 - val_accuracy: 0.7719 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5692 - val_recall: 0.9921 - val_precision: 0.6853\n",
            "Epoch 85/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6219 - accuracy: 0.6031 - sensitivity_at_specificity: 0.4842 - specificity_at_sensitivity: 0.4125 - recall: 0.9661 - precision: 0.5631\n",
            "Epoch 85: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.6219 - accuracy: 0.6031 - sensitivity_at_specificity: 0.4842 - specificity_at_sensitivity: 0.4125 - recall: 0.9661 - precision: 0.5631 - val_loss: 0.4614 - val_accuracy: 0.7984 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.6103 - val_recall: 0.9938 - val_precision: 0.7149\n",
            "Epoch 86/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6208 - accuracy: 0.5875 - sensitivity_at_specificity: 0.3257 - specificity_at_sensitivity: 0.4692 - recall: 0.9870 - precision: 0.5382\n",
            "Epoch 86: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.6208 - accuracy: 0.5875 - sensitivity_at_specificity: 0.3257 - specificity_at_sensitivity: 0.4692 - recall: 0.9870 - precision: 0.5382 - val_loss: 0.4664 - val_accuracy: 0.8023 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.6252 - val_recall: 0.9773 - val_precision: 0.7308\n",
            "Epoch 87/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6111 - accuracy: 0.6203 - sensitivity_at_specificity: 0.5384 - specificity_at_sensitivity: 0.5922 - recall: 0.9793 - precision: 0.5743\n",
            "Epoch 87: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.6111 - accuracy: 0.6203 - sensitivity_at_specificity: 0.5384 - specificity_at_sensitivity: 0.5922 - recall: 0.9793 - precision: 0.5743 - val_loss: 0.4650 - val_accuracy: 0.7969 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5994 - val_recall: 0.9954 - val_precision: 0.7144\n",
            "Epoch 88/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6178 - accuracy: 0.6227 - sensitivity_at_specificity: 0.5716 - specificity_at_sensitivity: 0.5418 - recall: 0.9873 - precision: 0.5823\n",
            "Epoch 88: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.6178 - accuracy: 0.6227 - sensitivity_at_specificity: 0.5716 - specificity_at_sensitivity: 0.5418 - recall: 0.9873 - precision: 0.5823 - val_loss: 0.4718 - val_accuracy: 0.7914 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 0.6246 - val_recall: 0.9694 - val_precision: 0.7196\n",
            "Epoch 89/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6265 - accuracy: 0.5879 - sensitivity_at_specificity: 0.5556 - specificity_at_sensitivity: 0.5805 - recall: 0.9912 - precision: 0.5425\n",
            "Epoch 89: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.6265 - accuracy: 0.5879 - sensitivity_at_specificity: 0.5556 - specificity_at_sensitivity: 0.5805 - recall: 0.9912 - precision: 0.5425 - val_loss: 0.4700 - val_accuracy: 0.7812 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5890 - val_recall: 0.9857 - val_precision: 0.6955\n",
            "Epoch 90/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6253 - accuracy: 0.6016 - sensitivity_at_specificity: 0.5737 - specificity_at_sensitivity: 0.5325 - recall: 0.9891 - precision: 0.5578\n",
            "Epoch 90: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.6253 - accuracy: 0.6016 - sensitivity_at_specificity: 0.5737 - specificity_at_sensitivity: 0.5325 - recall: 0.9891 - precision: 0.5578 - val_loss: 0.4694 - val_accuracy: 0.7906 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5918 - val_recall: 0.9907 - val_precision: 0.7086\n",
            "Epoch 91/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6176 - accuracy: 0.6070 - sensitivity_at_specificity: 0.6378 - specificity_at_sensitivity: 0.5285 - recall: 0.9719 - precision: 0.5621\n",
            "Epoch 91: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.6176 - accuracy: 0.6070 - sensitivity_at_specificity: 0.6378 - specificity_at_sensitivity: 0.5285 - recall: 0.9719 - precision: 0.5621 - val_loss: 0.4685 - val_accuracy: 0.7789 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5957 - val_recall: 0.9839 - val_precision: 0.6915\n",
            "Epoch 92/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6149 - accuracy: 0.6059 - sensitivity_at_specificity: 0.3005 - specificity_at_sensitivity: 0.4977 - recall: 0.9803 - precision: 0.5581\n",
            "Epoch 92: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.6149 - accuracy: 0.6059 - sensitivity_at_specificity: 0.3005 - specificity_at_sensitivity: 0.4977 - recall: 0.9803 - precision: 0.5581 - val_loss: 0.4715 - val_accuracy: 0.7937 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5939 - val_recall: 0.9908 - val_precision: 0.7146\n",
            "Epoch 93/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6162 - accuracy: 0.6125 - sensitivity_at_specificity: 0.5977 - specificity_at_sensitivity: 0.5480 - recall: 0.9868 - precision: 0.5663\n",
            "Epoch 93: val_accuracy did not improve from 0.80625\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.6162 - accuracy: 0.6125 - sensitivity_at_specificity: 0.5977 - specificity_at_sensitivity: 0.5480 - recall: 0.9868 - precision: 0.5663 - val_loss: 0.4593 - val_accuracy: 0.7859 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5879 - val_recall: 0.9984 - val_precision: 0.6939\n",
            "Epoch 94/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6199 - accuracy: 0.6098 - sensitivity_at_specificity: 0.4178 - specificity_at_sensitivity: 0.3731 - recall: 0.9846 - precision: 0.5657\n",
            "Epoch 94: val_accuracy improved from 0.80625 to 0.82344, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.6199 - accuracy: 0.6098 - sensitivity_at_specificity: 0.4178 - specificity_at_sensitivity: 0.3731 - recall: 0.9846 - precision: 0.5657 - val_loss: 0.4440 - val_accuracy: 0.8234 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.6564 - val_recall: 0.9850 - val_precision: 0.7523\n",
            "Epoch 95/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6160 - accuracy: 0.6109 - sensitivity_at_specificity: 0.6050 - specificity_at_sensitivity: 0.5309 - recall: 0.9906 - precision: 0.5632\n",
            "Epoch 95: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.6160 - accuracy: 0.6109 - sensitivity_at_specificity: 0.6050 - specificity_at_sensitivity: 0.5309 - recall: 0.9906 - precision: 0.5632 - val_loss: 0.4645 - val_accuracy: 0.7773 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.6258 - val_recall: 0.9565 - val_precision: 0.6968\n",
            "Epoch 96/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6213 - accuracy: 0.6105 - sensitivity_at_specificity: 0.5658 - specificity_at_sensitivity: 0.5773 - recall: 0.9707 - precision: 0.5680\n",
            "Epoch 96: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.6213 - accuracy: 0.6105 - sensitivity_at_specificity: 0.5658 - specificity_at_sensitivity: 0.5773 - recall: 0.9707 - precision: 0.5680 - val_loss: 0.4563 - val_accuracy: 0.7969 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.6109 - val_recall: 1.0000 - val_precision: 0.7052\n",
            "Epoch 97/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6128 - accuracy: 0.6242 - sensitivity_at_specificity: 0.6692 - specificity_at_sensitivity: 0.5012 - recall: 0.9690 - precision: 0.5816\n",
            "Epoch 97: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.6128 - accuracy: 0.6242 - sensitivity_at_specificity: 0.6692 - specificity_at_sensitivity: 0.5012 - recall: 0.9690 - precision: 0.5816 - val_loss: 0.4617 - val_accuracy: 0.7914 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.6472 - val_recall: 0.9860 - val_precision: 0.7114\n",
            "Epoch 98/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6120 - accuracy: 0.6152 - sensitivity_at_specificity: 0.5511 - specificity_at_sensitivity: 0.5732 - recall: 0.9766 - precision: 0.5675\n",
            "Epoch 98: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.6120 - accuracy: 0.6152 - sensitivity_at_specificity: 0.5511 - specificity_at_sensitivity: 0.5732 - recall: 0.9766 - precision: 0.5675 - val_loss: 0.4521 - val_accuracy: 0.7906 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.6030 - val_recall: 0.9984 - val_precision: 0.6986\n",
            "Epoch 99/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6178 - accuracy: 0.6074 - sensitivity_at_specificity: 0.5757 - specificity_at_sensitivity: 0.5440 - recall: 0.9945 - precision: 0.5596\n",
            "Epoch 99: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.6178 - accuracy: 0.6074 - sensitivity_at_specificity: 0.5757 - specificity_at_sensitivity: 0.5440 - recall: 0.9945 - precision: 0.5596 - val_loss: 0.4680 - val_accuracy: 0.7828 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5904 - val_recall: 0.9858 - val_precision: 0.6988\n",
            "Epoch 100/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6214 - accuracy: 0.6023 - sensitivity_at_specificity: 0.4202 - specificity_at_sensitivity: 0.4289 - recall: 0.9834 - precision: 0.5553\n",
            "Epoch 100: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.6214 - accuracy: 0.6023 - sensitivity_at_specificity: 0.4202 - specificity_at_sensitivity: 0.4289 - recall: 0.9834 - precision: 0.5553 - val_loss: 0.4741 - val_accuracy: 0.7883 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5694 - val_recall: 0.9985 - val_precision: 0.7072\n",
            "Epoch 101/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6177 - accuracy: 0.6125 - sensitivity_at_specificity: 0.5501 - specificity_at_sensitivity: 0.5848 - recall: 0.9938 - precision: 0.5673\n",
            "Epoch 101: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.6177 - accuracy: 0.6125 - sensitivity_at_specificity: 0.5501 - specificity_at_sensitivity: 0.5848 - recall: 0.9938 - precision: 0.5673 - val_loss: 0.4636 - val_accuracy: 0.7984 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.6476 - val_recall: 0.9523 - val_precision: 0.7317\n",
            "Epoch 102/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6302 - accuracy: 0.6004 - sensitivity_at_specificity: 0.5832 - specificity_at_sensitivity: 0.5141 - recall: 0.9930 - precision: 0.5574\n",
            "Epoch 102: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 187ms/step - loss: 0.6302 - accuracy: 0.6004 - sensitivity_at_specificity: 0.5832 - specificity_at_sensitivity: 0.5141 - recall: 0.9930 - precision: 0.5574 - val_loss: 0.4607 - val_accuracy: 0.7969 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.6006 - val_recall: 0.9969 - val_precision: 0.7117\n",
            "Epoch 103/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6220 - accuracy: 0.6105 - sensitivity_at_specificity: 0.4221 - specificity_at_sensitivity: 0.3800 - recall: 0.9802 - precision: 0.5694\n",
            "Epoch 103: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.6220 - accuracy: 0.6105 - sensitivity_at_specificity: 0.4221 - specificity_at_sensitivity: 0.3800 - recall: 0.9802 - precision: 0.5694 - val_loss: 0.4620 - val_accuracy: 0.8016 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.6044 - val_recall: 0.9984 - val_precision: 0.7173\n",
            "Epoch 104/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6193 - accuracy: 0.6016 - sensitivity_at_specificity: 0.4443 - specificity_at_sensitivity: 0.3761 - recall: 0.9881 - precision: 0.5543\n",
            "Epoch 104: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.6193 - accuracy: 0.6016 - sensitivity_at_specificity: 0.4443 - specificity_at_sensitivity: 0.3761 - recall: 0.9881 - precision: 0.5543 - val_loss: 0.4710 - val_accuracy: 0.7664 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.6370 - val_recall: 0.9610 - val_precision: 0.6828\n",
            "Epoch 105/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6218 - accuracy: 0.5914 - sensitivity_at_specificity: 0.3430 - specificity_at_sensitivity: 0.4228 - recall: 0.9767 - precision: 0.5446\n",
            "Epoch 105: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.6218 - accuracy: 0.5914 - sensitivity_at_specificity: 0.3430 - specificity_at_sensitivity: 0.4228 - recall: 0.9767 - precision: 0.5446 - val_loss: 0.4783 - val_accuracy: 0.7812 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5800 - val_recall: 0.9968 - val_precision: 0.6932\n",
            "Epoch 106/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6195 - accuracy: 0.6055 - sensitivity_at_specificity: 0.5452 - specificity_at_sensitivity: 0.5540 - recall: 0.9711 - precision: 0.5613\n",
            "Epoch 106: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.6195 - accuracy: 0.6055 - sensitivity_at_specificity: 0.5452 - specificity_at_sensitivity: 0.5540 - recall: 0.9711 - precision: 0.5613 - val_loss: 0.4610 - val_accuracy: 0.7953 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.6028 - val_recall: 1.0000 - val_precision: 0.7056\n",
            "Epoch 107/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6255 - accuracy: 0.5973 - sensitivity_at_specificity: 0.4704 - specificity_at_sensitivity: 0.3582 - recall: 0.9938 - precision: 0.5550\n",
            "Epoch 107: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.6255 - accuracy: 0.5973 - sensitivity_at_specificity: 0.4704 - specificity_at_sensitivity: 0.3582 - recall: 0.9938 - precision: 0.5550 - val_loss: 0.4713 - val_accuracy: 0.7766 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5939 - val_recall: 0.9728 - val_precision: 0.6933\n",
            "Epoch 108/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6197 - accuracy: 0.5961 - sensitivity_at_specificity: 0.2302 - specificity_at_sensitivity: 0.4874 - recall: 0.9848 - precision: 0.5483\n",
            "Epoch 108: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.6197 - accuracy: 0.5961 - sensitivity_at_specificity: 0.2302 - specificity_at_sensitivity: 0.4874 - recall: 0.9848 - precision: 0.5483 - val_loss: 0.4637 - val_accuracy: 0.7969 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5975 - val_recall: 0.9969 - val_precision: 0.7117\n",
            "Epoch 109/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6204 - accuracy: 0.6090 - sensitivity_at_specificity: 0.4206 - specificity_at_sensitivity: 0.3761 - recall: 0.9668 - precision: 0.5605\n",
            "Epoch 109: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.6204 - accuracy: 0.6090 - sensitivity_at_specificity: 0.4206 - specificity_at_sensitivity: 0.3761 - recall: 0.9668 - precision: 0.5605 - val_loss: 0.4732 - val_accuracy: 0.7898 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5759 - val_recall: 1.0000 - val_precision: 0.7067\n",
            "Epoch 110/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6241 - accuracy: 0.6141 - sensitivity_at_specificity: 0.2261 - specificity_at_sensitivity: 0.4734 - recall: 0.9985 - precision: 0.5717\n",
            "Epoch 110: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.6241 - accuracy: 0.6141 - sensitivity_at_specificity: 0.2261 - specificity_at_sensitivity: 0.4734 - recall: 0.9985 - precision: 0.5717 - val_loss: 0.4582 - val_accuracy: 0.8133 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.6276 - val_recall: 1.0000 - val_precision: 0.7333\n",
            "Epoch 111/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6198 - accuracy: 0.6145 - sensitivity_at_specificity: 0.4770 - specificity_at_sensitivity: 0.3768 - recall: 0.9708 - precision: 0.5712\n",
            "Epoch 111: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.6198 - accuracy: 0.6145 - sensitivity_at_specificity: 0.4770 - specificity_at_sensitivity: 0.3768 - recall: 0.9708 - precision: 0.5712 - val_loss: 0.4580 - val_accuracy: 0.7914 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5929 - val_recall: 0.9968 - val_precision: 0.7046\n",
            "Epoch 112/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6178 - accuracy: 0.6094 - sensitivity_at_specificity: 0.4444 - specificity_at_sensitivity: 0.4179 - recall: 0.9900 - precision: 0.5648\n",
            "Epoch 112: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.6178 - accuracy: 0.6094 - sensitivity_at_specificity: 0.4444 - specificity_at_sensitivity: 0.4179 - recall: 0.9900 - precision: 0.5648 - val_loss: 0.4769 - val_accuracy: 0.7781 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7855 - val_recall: 0.9924 - val_precision: 0.7013\n",
            "Epoch 113/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6256 - accuracy: 0.5930 - sensitivity_at_specificity: 0.4549 - specificity_at_sensitivity: 0.4713 - recall: 0.9792 - precision: 0.5470\n",
            "Epoch 113: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.6256 - accuracy: 0.5930 - sensitivity_at_specificity: 0.4549 - specificity_at_sensitivity: 0.4713 - recall: 0.9792 - precision: 0.5470 - val_loss: 0.4605 - val_accuracy: 0.7992 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8246 - val_recall: 0.9892 - val_precision: 0.7191\n",
            "Epoch 114/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6184 - accuracy: 0.6026 - sensitivity_at_specificity: 0.6288 - specificity_at_sensitivity: 0.5239 - recall: 0.9490 - precision: 0.5588\n",
            "Epoch 114: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.6184 - accuracy: 0.6026 - sensitivity_at_specificity: 0.6288 - specificity_at_sensitivity: 0.5239 - recall: 0.9490 - precision: 0.5588 - val_loss: 0.4683 - val_accuracy: 0.7844 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7966 - val_recall: 0.9874 - val_precision: 0.7009\n",
            "Epoch 115/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6139 - accuracy: 0.6023 - sensitivity_at_specificity: 0.4512 - specificity_at_sensitivity: 0.4405 - recall: 0.9800 - precision: 0.5523\n",
            "Epoch 115: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.6139 - accuracy: 0.6023 - sensitivity_at_specificity: 0.4512 - specificity_at_sensitivity: 0.4405 - recall: 0.9800 - precision: 0.5523 - val_loss: 0.4555 - val_accuracy: 0.8016 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7543 - val_recall: 0.9984 - val_precision: 0.7167\n",
            "Epoch 116/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6208 - accuracy: 0.6070 - sensitivity_at_specificity: 0.4790 - specificity_at_sensitivity: 0.4324 - recall: 0.9798 - precision: 0.5629\n",
            "Epoch 116: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.6208 - accuracy: 0.6070 - sensitivity_at_specificity: 0.4790 - specificity_at_sensitivity: 0.4324 - recall: 0.9798 - precision: 0.5629 - val_loss: 0.4680 - val_accuracy: 0.8031 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8010 - val_recall: 0.9940 - val_precision: 0.7263\n",
            "Epoch 117/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6135 - accuracy: 0.6215 - sensitivity_at_specificity: 0.6458 - specificity_at_sensitivity: 0.6145 - recall: 0.9694 - precision: 0.5770\n",
            "Epoch 117: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.6135 - accuracy: 0.6215 - sensitivity_at_specificity: 0.6458 - specificity_at_sensitivity: 0.6145 - recall: 0.9694 - precision: 0.5770 - val_loss: 0.4624 - val_accuracy: 0.7852 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8071 - val_recall: 0.9652 - val_precision: 0.7068\n",
            "Epoch 118/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6246 - accuracy: 0.6047 - sensitivity_at_specificity: 0.5376 - specificity_at_sensitivity: 0.5688 - recall: 0.9825 - precision: 0.5668\n",
            "Epoch 118: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.6246 - accuracy: 0.6047 - sensitivity_at_specificity: 0.5376 - specificity_at_sensitivity: 0.5688 - recall: 0.9825 - precision: 0.5668 - val_loss: 0.4645 - val_accuracy: 0.8016 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.6848 - val_recall: 0.9777 - val_precision: 0.7339\n",
            "Epoch 119/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6173 - accuracy: 0.6031 - sensitivity_at_specificity: 0.6331 - specificity_at_sensitivity: 0.5155 - recall: 0.9709 - precision: 0.5574\n",
            "Epoch 119: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.6173 - accuracy: 0.6031 - sensitivity_at_specificity: 0.6331 - specificity_at_sensitivity: 0.5155 - recall: 0.9709 - precision: 0.5574 - val_loss: 0.4595 - val_accuracy: 0.7945 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8031 - val_recall: 0.9829 - val_precision: 0.7156\n",
            "Epoch 120/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6174 - accuracy: 0.6152 - sensitivity_at_specificity: 0.6366 - specificity_at_sensitivity: 0.5305 - recall: 0.9892 - precision: 0.5696\n",
            "Epoch 120: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.6174 - accuracy: 0.6152 - sensitivity_at_specificity: 0.6366 - specificity_at_sensitivity: 0.5305 - recall: 0.9892 - precision: 0.5696 - val_loss: 0.4535 - val_accuracy: 0.7937 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.6620 - val_recall: 0.9874 - val_precision: 0.7101\n",
            "Epoch 121/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6196 - accuracy: 0.6082 - sensitivity_at_specificity: 0.5660 - specificity_at_sensitivity: 0.5653 - recall: 0.9899 - precision: 0.5629\n",
            "Epoch 121: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.6196 - accuracy: 0.6082 - sensitivity_at_specificity: 0.5660 - specificity_at_sensitivity: 0.5653 - recall: 0.9899 - precision: 0.5629 - val_loss: 0.4696 - val_accuracy: 0.7805 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5858 - val_recall: 0.9921 - val_precision: 0.6947\n",
            "Epoch 122/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6162 - accuracy: 0.5930 - sensitivity_at_specificity: 0.3385 - specificity_at_sensitivity: 0.4596 - recall: 0.9919 - precision: 0.5428\n",
            "Epoch 122: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.6162 - accuracy: 0.5930 - sensitivity_at_specificity: 0.3385 - specificity_at_sensitivity: 0.4596 - recall: 0.9919 - precision: 0.5428 - val_loss: 0.4701 - val_accuracy: 0.7805 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5844 - val_recall: 0.9936 - val_precision: 0.6926\n",
            "Epoch 123/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.6200 - accuracy: 0.5929 - sensitivity_at_specificity: 0.3806 - specificity_at_sensitivity: 0.4217 - recall: 0.9850 - precision: 0.5483\n",
            "Epoch 123: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 155ms/step - loss: 0.6206 - accuracy: 0.5943 - sensitivity_at_specificity: 0.3815 - specificity_at_sensitivity: 0.4228 - recall: 0.9840 - precision: 0.5500 - val_loss: 0.4549 - val_accuracy: 0.8062 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.6374 - val_recall: 0.9938 - val_precision: 0.7237\n",
            "Epoch 124/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6226 - accuracy: 0.5969 - sensitivity_at_specificity: 0.4980 - specificity_at_sensitivity: 0.4427 - recall: 0.9883 - precision: 0.5538\n",
            "Epoch 124: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 178ms/step - loss: 0.6226 - accuracy: 0.5969 - sensitivity_at_specificity: 0.4980 - specificity_at_sensitivity: 0.4427 - recall: 0.9883 - precision: 0.5538 - val_loss: 0.4837 - val_accuracy: 0.7812 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8084 - val_recall: 0.9081 - val_precision: 0.7336\n",
            "Epoch 125/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6154 - accuracy: 0.6105 - sensitivity_at_specificity: 0.6519 - specificity_at_sensitivity: 0.6168 - recall: 0.9525 - precision: 0.5665\n",
            "Epoch 125: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.6154 - accuracy: 0.6105 - sensitivity_at_specificity: 0.6519 - specificity_at_sensitivity: 0.6168 - recall: 0.9525 - precision: 0.5665 - val_loss: 0.4741 - val_accuracy: 0.7898 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.6079 - val_recall: 0.9953 - val_precision: 0.7070\n",
            "Epoch 126/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6153 - accuracy: 0.6078 - sensitivity_at_specificity: 0.5339 - specificity_at_sensitivity: 0.5959 - recall: 0.9805 - precision: 0.5624\n",
            "Epoch 126: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.6153 - accuracy: 0.6078 - sensitivity_at_specificity: 0.5339 - specificity_at_sensitivity: 0.5959 - recall: 0.9805 - precision: 0.5624 - val_loss: 0.4857 - val_accuracy: 0.7820 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5574 - val_recall: 0.9985 - val_precision: 0.7036\n",
            "Epoch 127/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6168 - accuracy: 0.6082 - sensitivity_at_specificity: 0.6345 - specificity_at_sensitivity: 0.5400 - recall: 0.9838 - precision: 0.5651\n",
            "Epoch 127: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.6168 - accuracy: 0.6082 - sensitivity_at_specificity: 0.6345 - specificity_at_sensitivity: 0.5400 - recall: 0.9838 - precision: 0.5651 - val_loss: 0.4715 - val_accuracy: 0.7719 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8018 - val_recall: 0.9650 - val_precision: 0.6921\n",
            "Epoch 128/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6139 - accuracy: 0.6125 - sensitivity_at_specificity: 0.5995 - specificity_at_sensitivity: 0.5765 - recall: 0.9748 - precision: 0.5713\n",
            "Epoch 128: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.6139 - accuracy: 0.6125 - sensitivity_at_specificity: 0.5995 - specificity_at_sensitivity: 0.5765 - recall: 0.9748 - precision: 0.5713 - val_loss: 0.4467 - val_accuracy: 0.7922 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7805 - val_recall: 0.9919 - val_precision: 0.7003\n",
            "Epoch 129/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6139 - accuracy: 0.6094 - sensitivity_at_specificity: 0.6456 - specificity_at_sensitivity: 0.6099 - recall: 0.8993 - precision: 0.5695\n",
            "Epoch 129: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.6139 - accuracy: 0.6094 - sensitivity_at_specificity: 0.6456 - specificity_at_sensitivity: 0.6099 - recall: 0.8993 - precision: 0.5695 - val_loss: 0.4645 - val_accuracy: 0.7867 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8300 - val_recall: 0.9793 - val_precision: 0.7025\n",
            "Epoch 130/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6106 - accuracy: 0.6066 - sensitivity_at_specificity: 0.6068 - specificity_at_sensitivity: 0.5486 - recall: 0.9834 - precision: 0.5576\n",
            "Epoch 130: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.6106 - accuracy: 0.6066 - sensitivity_at_specificity: 0.6068 - specificity_at_sensitivity: 0.5486 - recall: 0.9834 - precision: 0.5576 - val_loss: 0.4569 - val_accuracy: 0.7953 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.6206 - val_recall: 0.9921 - val_precision: 0.7083\n",
            "Epoch 131/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6111 - accuracy: 0.6145 - sensitivity_at_specificity: 0.5265 - specificity_at_sensitivity: 0.6276 - recall: 0.9818 - precision: 0.5626\n",
            "Epoch 131: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.6111 - accuracy: 0.6145 - sensitivity_at_specificity: 0.5265 - specificity_at_sensitivity: 0.6276 - recall: 0.9818 - precision: 0.5626 - val_loss: 0.4740 - val_accuracy: 0.7945 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.6240 - val_recall: 0.9985 - val_precision: 0.7213\n",
            "Epoch 132/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6156 - accuracy: 0.5898 - sensitivity_at_specificity: 0.5622 - specificity_at_sensitivity: 0.5650 - recall: 0.9184 - precision: 0.5395\n",
            "Epoch 132: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.6156 - accuracy: 0.5898 - sensitivity_at_specificity: 0.5622 - specificity_at_sensitivity: 0.5650 - recall: 0.9184 - precision: 0.5395 - val_loss: 0.4936 - val_accuracy: 0.7523 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7785 - val_recall: 0.8311 - val_precision: 0.7261\n",
            "Epoch 133/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6101 - accuracy: 0.6090 - sensitivity_at_specificity: 0.6482 - specificity_at_sensitivity: 0.5429 - recall: 0.9194 - precision: 0.5640\n",
            "Epoch 133: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.6101 - accuracy: 0.6090 - sensitivity_at_specificity: 0.6482 - specificity_at_sensitivity: 0.5429 - recall: 0.9194 - precision: 0.5640 - val_loss: 0.4528 - val_accuracy: 0.8008 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7423 - val_recall: 0.9968 - val_precision: 0.7122\n",
            "Epoch 134/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6159 - accuracy: 0.6078 - sensitivity_at_specificity: 0.5292 - specificity_at_sensitivity: 0.5890 - recall: 0.9767 - precision: 0.5630\n",
            "Epoch 134: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.6159 - accuracy: 0.6078 - sensitivity_at_specificity: 0.5292 - specificity_at_sensitivity: 0.5890 - recall: 0.9767 - precision: 0.5630 - val_loss: 0.4604 - val_accuracy: 0.7937 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5854 - val_recall: 0.9985 - val_precision: 0.7110\n",
            "Epoch 135/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6171 - accuracy: 0.6152 - sensitivity_at_specificity: 0.5936 - specificity_at_sensitivity: 0.5263 - recall: 0.9916 - precision: 0.5704\n",
            "Epoch 135: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.6171 - accuracy: 0.6152 - sensitivity_at_specificity: 0.5936 - specificity_at_sensitivity: 0.5263 - recall: 0.9916 - precision: 0.5704 - val_loss: 0.4554 - val_accuracy: 0.8117 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.6238 - val_recall: 0.9939 - val_precision: 0.7340\n",
            "Epoch 136/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6098 - accuracy: 0.6180 - sensitivity_at_specificity: 0.5004 - specificity_at_sensitivity: 0.6571 - recall: 0.9939 - precision: 0.5729\n",
            "Epoch 136: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.6098 - accuracy: 0.6180 - sensitivity_at_specificity: 0.5004 - specificity_at_sensitivity: 0.6571 - recall: 0.9939 - precision: 0.5729 - val_loss: 0.4644 - val_accuracy: 0.7773 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7734 - val_recall: 0.9952 - val_precision: 0.6887\n",
            "Epoch 137/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6061 - accuracy: 0.6152 - sensitivity_at_specificity: 0.6240 - specificity_at_sensitivity: 0.5533 - recall: 0.9874 - precision: 0.5633\n",
            "Epoch 137: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 157ms/step - loss: 0.6061 - accuracy: 0.6152 - sensitivity_at_specificity: 0.6240 - specificity_at_sensitivity: 0.5533 - recall: 0.9874 - precision: 0.5633 - val_loss: 0.4796 - val_accuracy: 0.7844 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.6503 - val_recall: 0.9985 - val_precision: 0.7081\n",
            "Epoch 138/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6199 - accuracy: 0.6051 - sensitivity_at_specificity: 0.3751 - specificity_at_sensitivity: 0.4714 - recall: 0.9852 - precision: 0.5607\n",
            "Epoch 138: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.6199 - accuracy: 0.6051 - sensitivity_at_specificity: 0.3751 - specificity_at_sensitivity: 0.4714 - recall: 0.9852 - precision: 0.5607 - val_loss: 0.4701 - val_accuracy: 0.7883 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.6060 - val_recall: 0.9844 - val_precision: 0.7081\n",
            "Epoch 139/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6123 - accuracy: 0.6184 - sensitivity_at_specificity: 0.6182 - specificity_at_sensitivity: 0.5443 - recall: 0.9901 - precision: 0.5731\n",
            "Epoch 139: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.6123 - accuracy: 0.6184 - sensitivity_at_specificity: 0.6182 - specificity_at_sensitivity: 0.5443 - recall: 0.9901 - precision: 0.5731 - val_loss: 0.4553 - val_accuracy: 0.7922 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.6082 - val_recall: 0.9952 - val_precision: 0.7025\n",
            "Epoch 140/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6070 - accuracy: 0.6086 - sensitivity_at_specificity: 0.3317 - specificity_at_sensitivity: 0.4742 - recall: 0.9881 - precision: 0.5584\n",
            "Epoch 140: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 156ms/step - loss: 0.6070 - accuracy: 0.6086 - sensitivity_at_specificity: 0.3317 - specificity_at_sensitivity: 0.4742 - recall: 0.9881 - precision: 0.5584 - val_loss: 0.4627 - val_accuracy: 0.7805 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5846 - val_recall: 0.9968 - val_precision: 0.6883\n",
            "Epoch 141/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6130 - accuracy: 0.6113 - sensitivity_at_specificity: 0.3926 - specificity_at_sensitivity: 0.4336 - recall: 0.9876 - precision: 0.5662\n",
            "Epoch 141: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.6130 - accuracy: 0.6113 - sensitivity_at_specificity: 0.3926 - specificity_at_sensitivity: 0.4336 - recall: 0.9876 - precision: 0.5662 - val_loss: 0.4509 - val_accuracy: 0.8008 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.6192 - val_recall: 0.9858 - val_precision: 0.7176\n",
            "Epoch 142/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6125 - accuracy: 0.6125 - sensitivity_at_specificity: 0.5911 - specificity_at_sensitivity: 0.5853 - recall: 0.9969 - precision: 0.5686\n",
            "Epoch 142: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.6125 - accuracy: 0.6125 - sensitivity_at_specificity: 0.5911 - specificity_at_sensitivity: 0.5853 - recall: 0.9969 - precision: 0.5686 - val_loss: 0.4541 - val_accuracy: 0.7898 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.6194 - val_recall: 0.9873 - val_precision: 0.7048\n",
            "Epoch 143/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6182 - accuracy: 0.5953 - sensitivity_at_specificity: 0.6271 - specificity_at_sensitivity: 0.5287 - recall: 0.9801 - precision: 0.5489\n",
            "Epoch 143: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.6182 - accuracy: 0.5953 - sensitivity_at_specificity: 0.6271 - specificity_at_sensitivity: 0.5287 - recall: 0.9801 - precision: 0.5489 - val_loss: 0.4847 - val_accuracy: 0.7727 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7804 - val_recall: 0.9660 - val_precision: 0.6991\n",
            "Epoch 144/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6073 - accuracy: 0.6067 - sensitivity_at_specificity: 0.6339 - specificity_at_sensitivity: 0.5406 - recall: 0.9676 - precision: 0.5616\n",
            "Epoch 144: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 155ms/step - loss: 0.6073 - accuracy: 0.6067 - sensitivity_at_specificity: 0.6339 - specificity_at_sensitivity: 0.5406 - recall: 0.9676 - precision: 0.5616 - val_loss: 0.4683 - val_accuracy: 0.7727 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5853 - val_recall: 0.9968 - val_precision: 0.6845\n",
            "Epoch 145/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6286 - accuracy: 0.5949 - sensitivity_at_specificity: 0.4424 - specificity_at_sensitivity: 0.4731 - recall: 0.9789 - precision: 0.5531\n",
            "Epoch 145: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.6286 - accuracy: 0.5949 - sensitivity_at_specificity: 0.4424 - specificity_at_sensitivity: 0.4731 - recall: 0.9789 - precision: 0.5531 - val_loss: 0.4681 - val_accuracy: 0.8008 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.6950 - val_recall: 1.0000 - val_precision: 0.7204\n",
            "Epoch 146/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6243 - accuracy: 0.5945 - sensitivity_at_specificity: 0.5641 - specificity_at_sensitivity: 0.5789 - recall: 0.9664 - precision: 0.5542\n",
            "Epoch 146: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.6243 - accuracy: 0.5945 - sensitivity_at_specificity: 0.5641 - specificity_at_sensitivity: 0.5789 - recall: 0.9664 - precision: 0.5542 - val_loss: 0.4766 - val_accuracy: 0.8039 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7496 - val_recall: 0.9882 - val_precision: 0.7336\n",
            "Epoch 147/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6156 - accuracy: 0.6094 - sensitivity_at_specificity: 0.4096 - specificity_at_sensitivity: 0.4705 - recall: 0.9756 - precision: 0.5615\n",
            "Epoch 147: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.6156 - accuracy: 0.6094 - sensitivity_at_specificity: 0.4096 - specificity_at_sensitivity: 0.4705 - recall: 0.9756 - precision: 0.5615 - val_loss: 0.4702 - val_accuracy: 0.7703 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5889 - val_recall: 0.9951 - val_precision: 0.6763\n",
            "Epoch 148/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6257 - accuracy: 0.6012 - sensitivity_at_specificity: 0.3043 - specificity_at_sensitivity: 0.4937 - recall: 0.9961 - precision: 0.5600\n",
            "Epoch 148: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.6257 - accuracy: 0.6012 - sensitivity_at_specificity: 0.3043 - specificity_at_sensitivity: 0.4937 - recall: 0.9961 - precision: 0.5600 - val_loss: 0.4619 - val_accuracy: 0.7891 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.6019 - val_recall: 0.9953 - val_precision: 0.7037\n",
            "Epoch 149/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6191 - accuracy: 0.5996 - sensitivity_at_specificity: 0.5145 - specificity_at_sensitivity: 0.6212 - recall: 0.9836 - precision: 0.5558\n",
            "Epoch 149: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.6191 - accuracy: 0.5996 - sensitivity_at_specificity: 0.5145 - specificity_at_sensitivity: 0.6212 - recall: 0.9836 - precision: 0.5558 - val_loss: 0.4717 - val_accuracy: 0.7750 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.6019 - val_recall: 0.9938 - val_precision: 0.6920\n",
            "Epoch 150/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6188 - accuracy: 0.5930 - sensitivity_at_specificity: 0.6233 - specificity_at_sensitivity: 0.5289 - recall: 0.9715 - precision: 0.5491\n",
            "Epoch 150: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.6188 - accuracy: 0.5930 - sensitivity_at_specificity: 0.6233 - specificity_at_sensitivity: 0.5289 - recall: 0.9715 - precision: 0.5491 - val_loss: 0.4676 - val_accuracy: 0.7875 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7920 - val_recall: 0.9984 - val_precision: 0.6992\n",
            "Epoch 151/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6136 - accuracy: 0.6016 - sensitivity_at_specificity: 0.5796 - specificity_at_sensitivity: 0.5960 - recall: 0.9675 - precision: 0.5552\n",
            "Epoch 151: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.6136 - accuracy: 0.6016 - sensitivity_at_specificity: 0.5796 - specificity_at_sensitivity: 0.5960 - recall: 0.9675 - precision: 0.5552 - val_loss: 0.4619 - val_accuracy: 0.7758 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.6088 - val_recall: 0.9984 - val_precision: 0.6833\n",
            "Epoch 152/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6219 - accuracy: 0.5938 - sensitivity_at_specificity: 0.5139 - specificity_at_sensitivity: 0.5902 - recall: 0.9602 - precision: 0.5494\n",
            "Epoch 152: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.6219 - accuracy: 0.5938 - sensitivity_at_specificity: 0.5139 - specificity_at_sensitivity: 0.5902 - recall: 0.9602 - precision: 0.5494 - val_loss: 0.4683 - val_accuracy: 0.7906 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7308 - val_recall: 0.9873 - val_precision: 0.7052\n",
            "Epoch 153/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6172 - accuracy: 0.5996 - sensitivity_at_specificity: 0.5683 - specificity_at_sensitivity: 0.5770 - recall: 0.9929 - precision: 0.5532\n",
            "Epoch 153: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.6172 - accuracy: 0.5996 - sensitivity_at_specificity: 0.5683 - specificity_at_sensitivity: 0.5770 - recall: 0.9929 - precision: 0.5532 - val_loss: 0.4715 - val_accuracy: 0.7703 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.6135 - val_recall: 1.0000 - val_precision: 0.6766\n",
            "Epoch 154/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6158 - accuracy: 0.5887 - sensitivity_at_specificity: 0.4893 - specificity_at_sensitivity: 0.4903 - recall: 0.9901 - precision: 0.5363\n",
            "Epoch 154: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.6158 - accuracy: 0.5887 - sensitivity_at_specificity: 0.4893 - specificity_at_sensitivity: 0.4903 - recall: 0.9901 - precision: 0.5363 - val_loss: 0.4651 - val_accuracy: 0.7797 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7708 - val_recall: 0.9889 - val_precision: 0.6938\n",
            "Epoch 155/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6216 - accuracy: 0.6023 - sensitivity_at_specificity: 0.5860 - specificity_at_sensitivity: 0.5501 - recall: 0.8806 - precision: 0.5642\n",
            "Epoch 155: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.6216 - accuracy: 0.6023 - sensitivity_at_specificity: 0.5860 - specificity_at_sensitivity: 0.5501 - recall: 0.8806 - precision: 0.5642 - val_loss: 0.4601 - val_accuracy: 0.7961 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8423 - val_recall: 0.9319 - val_precision: 0.7350\n",
            "Epoch 156/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6090 - accuracy: 0.6172 - sensitivity_at_specificity: 0.6197 - specificity_at_sensitivity: 0.6258 - recall: 0.9505 - precision: 0.5768\n",
            "Epoch 156: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.6090 - accuracy: 0.6172 - sensitivity_at_specificity: 0.6197 - specificity_at_sensitivity: 0.6258 - recall: 0.9505 - precision: 0.5768 - val_loss: 0.4623 - val_accuracy: 0.7914 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8156 - val_recall: 0.9906 - val_precision: 0.7084\n",
            "Epoch 157/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6129 - accuracy: 0.6043 - sensitivity_at_specificity: 0.5866 - specificity_at_sensitivity: 0.5698 - recall: 0.9780 - precision: 0.5577\n",
            "Epoch 157: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.6129 - accuracy: 0.6043 - sensitivity_at_specificity: 0.5866 - specificity_at_sensitivity: 0.5698 - recall: 0.9780 - precision: 0.5577 - val_loss: 0.4450 - val_accuracy: 0.8086 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7885 - val_recall: 0.9922 - val_precision: 0.7248\n",
            "Epoch 158/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6185 - accuracy: 0.5977 - sensitivity_at_specificity: 0.6128 - specificity_at_sensitivity: 0.6130 - recall: 0.8794 - precision: 0.5656\n",
            "Epoch 158: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.6185 - accuracy: 0.5977 - sensitivity_at_specificity: 0.6128 - specificity_at_sensitivity: 0.6130 - recall: 0.8794 - precision: 0.5656 - val_loss: 0.4721 - val_accuracy: 0.7711 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8103 - val_recall: 0.9184 - val_precision: 0.7082\n",
            "Epoch 159/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6091 - accuracy: 0.6160 - sensitivity_at_specificity: 0.6815 - specificity_at_sensitivity: 0.6435 - recall: 0.9180 - precision: 0.5725\n",
            "Epoch 159: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.6091 - accuracy: 0.6160 - sensitivity_at_specificity: 0.6815 - specificity_at_sensitivity: 0.6435 - recall: 0.9180 - precision: 0.5725 - val_loss: 0.4720 - val_accuracy: 0.7805 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7806 - val_recall: 0.9564 - val_precision: 0.7082\n",
            "Epoch 160/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6035 - accuracy: 0.6035 - sensitivity_at_specificity: 0.6626 - specificity_at_sensitivity: 0.6540 - recall: 0.9291 - precision: 0.5545\n",
            "Epoch 160: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 203ms/step - loss: 0.6035 - accuracy: 0.6035 - sensitivity_at_specificity: 0.6626 - specificity_at_sensitivity: 0.6540 - recall: 0.9291 - precision: 0.5545 - val_loss: 0.4664 - val_accuracy: 0.7758 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8361 - val_recall: 0.9920 - val_precision: 0.6881\n",
            "Epoch 161/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6141 - accuracy: 0.6022 - sensitivity_at_specificity: 0.6481 - specificity_at_sensitivity: 0.6140 - recall: 0.9295 - precision: 0.5651\n",
            "Epoch 161: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.6141 - accuracy: 0.6022 - sensitivity_at_specificity: 0.6481 - specificity_at_sensitivity: 0.6140 - recall: 0.9295 - precision: 0.5651 - val_loss: 0.4607 - val_accuracy: 0.7828 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8214 - val_recall: 0.9424 - val_precision: 0.7088\n",
            "Epoch 162/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6112 - accuracy: 0.6062 - sensitivity_at_specificity: 0.5964 - specificity_at_sensitivity: 0.5631 - recall: 0.9412 - precision: 0.5628\n",
            "Epoch 162: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.6112 - accuracy: 0.6062 - sensitivity_at_specificity: 0.5964 - specificity_at_sensitivity: 0.5631 - recall: 0.9412 - precision: 0.5628 - val_loss: 0.4639 - val_accuracy: 0.8078 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7348 - val_recall: 0.9941 - val_precision: 0.7344\n",
            "Epoch 163/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6165 - accuracy: 0.6141 - sensitivity_at_specificity: 0.6315 - specificity_at_sensitivity: 0.5222 - recall: 0.9746 - precision: 0.5702\n",
            "Epoch 163: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.6165 - accuracy: 0.6141 - sensitivity_at_specificity: 0.6315 - specificity_at_sensitivity: 0.5222 - recall: 0.9746 - precision: 0.5702 - val_loss: 0.4691 - val_accuracy: 0.7703 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7393 - val_recall: 0.9570 - val_precision: 0.6924\n",
            "Epoch 164/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6132 - accuracy: 0.6066 - sensitivity_at_specificity: 0.6819 - specificity_at_sensitivity: 0.5059 - recall: 0.9876 - precision: 0.5634\n",
            "Epoch 164: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.6132 - accuracy: 0.6066 - sensitivity_at_specificity: 0.6819 - specificity_at_sensitivity: 0.5059 - recall: 0.9876 - precision: 0.5634 - val_loss: 0.4641 - val_accuracy: 0.7742 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7733 - val_recall: 0.9739 - val_precision: 0.6866\n",
            "Epoch 165/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6144 - accuracy: 0.5863 - sensitivity_at_specificity: 0.6527 - specificity_at_sensitivity: 0.6315 - recall: 0.9574 - precision: 0.5421\n",
            "Epoch 165: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.6144 - accuracy: 0.5863 - sensitivity_at_specificity: 0.6527 - specificity_at_sensitivity: 0.6315 - recall: 0.9574 - precision: 0.5421 - val_loss: 0.4742 - val_accuracy: 0.7789 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8018 - val_recall: 0.9618 - val_precision: 0.7002\n",
            "Epoch 166/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6211 - accuracy: 0.6027 - sensitivity_at_specificity: 0.6114 - specificity_at_sensitivity: 0.6020 - recall: 0.9502 - precision: 0.5577\n",
            "Epoch 166: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.6211 - accuracy: 0.6027 - sensitivity_at_specificity: 0.6114 - specificity_at_sensitivity: 0.6020 - recall: 0.9502 - precision: 0.5577 - val_loss: 0.4784 - val_accuracy: 0.7820 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7649 - val_recall: 0.9439 - val_precision: 0.7138\n",
            "Epoch 167/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6110 - accuracy: 0.5992 - sensitivity_at_specificity: 0.6619 - specificity_at_sensitivity: 0.6154 - recall: 0.9667 - precision: 0.5531\n",
            "Epoch 167: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.6110 - accuracy: 0.5992 - sensitivity_at_specificity: 0.6619 - specificity_at_sensitivity: 0.6154 - recall: 0.9667 - precision: 0.5531 - val_loss: 0.4770 - val_accuracy: 0.7922 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8000 - val_recall: 0.9750 - val_precision: 0.7270\n",
            "Epoch 168/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5980 - accuracy: 0.6199 - sensitivity_at_specificity: 0.6609 - specificity_at_sensitivity: 0.6524 - recall: 0.9554 - precision: 0.5712\n",
            "Epoch 168: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.5980 - accuracy: 0.6199 - sensitivity_at_specificity: 0.6609 - specificity_at_sensitivity: 0.6524 - recall: 0.9554 - precision: 0.5712 - val_loss: 0.4514 - val_accuracy: 0.8000 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8084 - val_recall: 0.9843 - val_precision: 0.7185\n",
            "Epoch 169/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.6026 - accuracy: 0.6076 - sensitivity_at_specificity: 0.6088 - specificity_at_sensitivity: 0.6340 - recall: 0.9789 - precision: 0.5591\n",
            "Epoch 169: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 157ms/step - loss: 0.6038 - accuracy: 0.6092 - sensitivity_at_specificity: 0.6803 - specificity_at_sensitivity: 0.6371 - recall: 0.9784 - precision: 0.5622 - val_loss: 0.4828 - val_accuracy: 0.7711 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7421 - val_recall: 0.9814 - val_precision: 0.6922\n",
            "Epoch 170/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6147 - accuracy: 0.6063 - sensitivity_at_specificity: 0.6825 - specificity_at_sensitivity: 0.6349 - recall: 0.9525 - precision: 0.5619\n",
            "Epoch 170: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.6147 - accuracy: 0.6063 - sensitivity_at_specificity: 0.6825 - specificity_at_sensitivity: 0.6349 - recall: 0.9525 - precision: 0.5619 - val_loss: 0.4637 - val_accuracy: 0.7922 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7931 - val_recall: 0.9798 - val_precision: 0.7132\n",
            "Epoch 171/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6154 - accuracy: 0.6020 - sensitivity_at_specificity: 0.6016 - specificity_at_sensitivity: 0.6235 - recall: 0.9440 - precision: 0.5616\n",
            "Epoch 171: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.6154 - accuracy: 0.6020 - sensitivity_at_specificity: 0.6016 - specificity_at_sensitivity: 0.6235 - recall: 0.9440 - precision: 0.5616 - val_loss: 0.4824 - val_accuracy: 0.7773 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7648 - val_recall: 0.9969 - val_precision: 0.6976\n",
            "Epoch 172/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6113 - accuracy: 0.6070 - sensitivity_at_specificity: 0.6630 - specificity_at_sensitivity: 0.6077 - recall: 0.9441 - precision: 0.5656\n",
            "Epoch 172: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.6113 - accuracy: 0.6070 - sensitivity_at_specificity: 0.6630 - specificity_at_sensitivity: 0.6077 - recall: 0.9441 - precision: 0.5656 - val_loss: 0.4671 - val_accuracy: 0.7750 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7610 - val_recall: 1.0000 - val_precision: 0.6839\n",
            "Epoch 173/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6029 - accuracy: 0.6203 - sensitivity_at_specificity: 0.6202 - specificity_at_sensitivity: 0.5537 - recall: 0.9907 - precision: 0.5701\n",
            "Epoch 173: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.6029 - accuracy: 0.6203 - sensitivity_at_specificity: 0.6202 - specificity_at_sensitivity: 0.5537 - recall: 0.9907 - precision: 0.5701 - val_loss: 0.4542 - val_accuracy: 0.7891 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8092 - val_recall: 0.9873 - val_precision: 0.7036\n",
            "Epoch 174/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6139 - accuracy: 0.6078 - sensitivity_at_specificity: 0.6810 - specificity_at_sensitivity: 0.5780 - recall: 0.9624 - precision: 0.5679\n",
            "Epoch 174: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.6139 - accuracy: 0.6078 - sensitivity_at_specificity: 0.6810 - specificity_at_sensitivity: 0.5780 - recall: 0.9624 - precision: 0.5679 - val_loss: 0.4593 - val_accuracy: 0.7781 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8336 - val_recall: 0.9919 - val_precision: 0.6876\n",
            "Epoch 175/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6071 - accuracy: 0.6199 - sensitivity_at_specificity: 0.7154 - specificity_at_sensitivity: 0.6703 - recall: 0.8980 - precision: 0.5737\n",
            "Epoch 175: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.6071 - accuracy: 0.6199 - sensitivity_at_specificity: 0.7154 - specificity_at_sensitivity: 0.6703 - recall: 0.8980 - precision: 0.5737 - val_loss: 0.4726 - val_accuracy: 0.7781 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8310 - val_recall: 0.8471 - val_precision: 0.7449\n",
            "Epoch 176/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6110 - accuracy: 0.6008 - sensitivity_at_specificity: 0.7018 - specificity_at_sensitivity: 0.6493 - recall: 0.8675 - precision: 0.5682\n",
            "Epoch 176: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.6110 - accuracy: 0.6008 - sensitivity_at_specificity: 0.7018 - specificity_at_sensitivity: 0.6493 - recall: 0.8675 - precision: 0.5682 - val_loss: 0.4635 - val_accuracy: 0.7961 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8489 - val_recall: 0.9422 - val_precision: 0.7355\n",
            "Epoch 177/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6044 - accuracy: 0.6316 - sensitivity_at_specificity: 0.7302 - specificity_at_sensitivity: 0.6777 - recall: 0.8693 - precision: 0.5974\n",
            "Epoch 177: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.6044 - accuracy: 0.6316 - sensitivity_at_specificity: 0.7302 - specificity_at_sensitivity: 0.6777 - recall: 0.8693 - precision: 0.5974 - val_loss: 0.4479 - val_accuracy: 0.7977 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8207 - val_recall: 0.9924 - val_precision: 0.7209\n",
            "Epoch 178/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6073 - accuracy: 0.6152 - sensitivity_at_specificity: 0.7199 - specificity_at_sensitivity: 0.6664 - recall: 0.9245 - precision: 0.5693\n",
            "Epoch 178: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.6073 - accuracy: 0.6152 - sensitivity_at_specificity: 0.7199 - specificity_at_sensitivity: 0.6664 - recall: 0.9245 - precision: 0.5693 - val_loss: 0.4666 - val_accuracy: 0.7773 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8620 - val_recall: 0.9283 - val_precision: 0.7084\n",
            "Epoch 179/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6040 - accuracy: 0.6145 - sensitivity_at_specificity: 0.7239 - specificity_at_sensitivity: 0.7107 - recall: 0.7335 - precision: 0.5858\n",
            "Epoch 179: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.6040 - accuracy: 0.6145 - sensitivity_at_specificity: 0.7239 - specificity_at_sensitivity: 0.7107 - recall: 0.7335 - precision: 0.5858 - val_loss: 0.4653 - val_accuracy: 0.7617 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8607 - val_recall: 0.7488 - val_precision: 0.7475\n",
            "Epoch 180/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6059 - accuracy: 0.6176 - sensitivity_at_specificity: 0.7235 - specificity_at_sensitivity: 0.6763 - recall: 0.8201 - precision: 0.5847\n",
            "Epoch 180: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.6059 - accuracy: 0.6176 - sensitivity_at_specificity: 0.7235 - specificity_at_sensitivity: 0.6763 - recall: 0.8201 - precision: 0.5847 - val_loss: 0.4419 - val_accuracy: 0.7977 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8758 - val_recall: 0.9612 - val_precision: 0.7257\n",
            "Epoch 181/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6011 - accuracy: 0.6258 - sensitivity_at_specificity: 0.7334 - specificity_at_sensitivity: 0.6834 - recall: 0.8352 - precision: 0.5857\n",
            "Epoch 181: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.6011 - accuracy: 0.6258 - sensitivity_at_specificity: 0.7334 - specificity_at_sensitivity: 0.6834 - recall: 0.8352 - precision: 0.5857 - val_loss: 0.4651 - val_accuracy: 0.7773 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8487 - val_recall: 0.9108 - val_precision: 0.7185\n",
            "Epoch 182/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5974 - accuracy: 0.6391 - sensitivity_at_specificity: 0.7713 - specificity_at_sensitivity: 0.7068 - recall: 0.8564 - precision: 0.5972\n",
            "Epoch 182: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.5974 - accuracy: 0.6391 - sensitivity_at_specificity: 0.7713 - specificity_at_sensitivity: 0.7068 - recall: 0.8564 - precision: 0.5972 - val_loss: 0.4515 - val_accuracy: 0.7953 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8754 - val_recall: 0.8897 - val_precision: 0.7571\n",
            "Epoch 183/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6047 - accuracy: 0.6328 - sensitivity_at_specificity: 0.7559 - specificity_at_sensitivity: 0.6770 - recall: 0.7997 - precision: 0.6055\n",
            "Epoch 183: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.6047 - accuracy: 0.6328 - sensitivity_at_specificity: 0.7559 - specificity_at_sensitivity: 0.6770 - recall: 0.7997 - precision: 0.6055 - val_loss: 0.4512 - val_accuracy: 0.7812 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8022 - val_recall: 0.9387 - val_precision: 0.7186\n",
            "Epoch 184/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6022 - accuracy: 0.6219 - sensitivity_at_specificity: 0.6881 - specificity_at_sensitivity: 0.6410 - recall: 0.9042 - precision: 0.5764\n",
            "Epoch 184: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.6022 - accuracy: 0.6219 - sensitivity_at_specificity: 0.6881 - specificity_at_sensitivity: 0.6410 - recall: 0.9042 - precision: 0.5764 - val_loss: 0.4616 - val_accuracy: 0.7898 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8609 - val_recall: 0.9266 - val_precision: 0.7276\n",
            "Epoch 185/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5974 - accuracy: 0.6383 - sensitivity_at_specificity: 0.7853 - specificity_at_sensitivity: 0.7108 - recall: 0.8169 - precision: 0.5986\n",
            "Epoch 185: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.5974 - accuracy: 0.6383 - sensitivity_at_specificity: 0.7853 - specificity_at_sensitivity: 0.7108 - recall: 0.8169 - precision: 0.5986 - val_loss: 0.4505 - val_accuracy: 0.7977 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8159 - val_recall: 0.9892 - val_precision: 0.7184\n",
            "Epoch 186/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5927 - accuracy: 0.6336 - sensitivity_at_specificity: 0.7610 - specificity_at_sensitivity: 0.7344 - recall: 0.8103 - precision: 0.5977\n",
            "Epoch 186: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.5927 - accuracy: 0.6336 - sensitivity_at_specificity: 0.7610 - specificity_at_sensitivity: 0.7344 - recall: 0.8103 - precision: 0.5977 - val_loss: 0.4491 - val_accuracy: 0.8016 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8535 - val_recall: 0.9364 - val_precision: 0.7393\n",
            "Epoch 187/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5904 - accuracy: 0.6359 - sensitivity_at_specificity: 0.7738 - specificity_at_sensitivity: 0.7444 - recall: 0.8542 - precision: 0.5920\n",
            "Epoch 187: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.5904 - accuracy: 0.6359 - sensitivity_at_specificity: 0.7738 - specificity_at_sensitivity: 0.7444 - recall: 0.8542 - precision: 0.5920 - val_loss: 0.4497 - val_accuracy: 0.7828 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8820 - val_recall: 0.7819 - val_precision: 0.7719\n",
            "Epoch 188/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5958 - accuracy: 0.6242 - sensitivity_at_specificity: 0.7458 - specificity_at_sensitivity: 0.7149 - recall: 0.7660 - precision: 0.5909\n",
            "Epoch 188: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.5958 - accuracy: 0.6242 - sensitivity_at_specificity: 0.7458 - specificity_at_sensitivity: 0.7149 - recall: 0.7660 - precision: 0.5909 - val_loss: 0.4684 - val_accuracy: 0.7867 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8498 - val_recall: 0.9173 - val_precision: 0.7277\n",
            "Epoch 189/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5863 - accuracy: 0.6527 - sensitivity_at_specificity: 0.8099 - specificity_at_sensitivity: 0.7492 - recall: 0.7989 - precision: 0.6151\n",
            "Epoch 189: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.5863 - accuracy: 0.6527 - sensitivity_at_specificity: 0.8099 - specificity_at_sensitivity: 0.7492 - recall: 0.7989 - precision: 0.6151 - val_loss: 0.4468 - val_accuracy: 0.7812 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8643 - val_recall: 0.9327 - val_precision: 0.7098\n",
            "Epoch 190/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5929 - accuracy: 0.6359 - sensitivity_at_specificity: 0.7672 - specificity_at_sensitivity: 0.7386 - recall: 0.8044 - precision: 0.5973\n",
            "Epoch 190: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.5929 - accuracy: 0.6359 - sensitivity_at_specificity: 0.7672 - specificity_at_sensitivity: 0.7386 - recall: 0.8044 - precision: 0.5973 - val_loss: 0.4396 - val_accuracy: 0.8125 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8576 - val_recall: 0.9022 - val_precision: 0.7627\n",
            "Epoch 191/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5946 - accuracy: 0.6395 - sensitivity_at_specificity: 0.7797 - specificity_at_sensitivity: 0.7227 - recall: 0.7591 - precision: 0.6075\n",
            "Epoch 191: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.5946 - accuracy: 0.6395 - sensitivity_at_specificity: 0.7797 - specificity_at_sensitivity: 0.7227 - recall: 0.7591 - precision: 0.6075 - val_loss: 0.4280 - val_accuracy: 0.8055 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8669 - val_recall: 0.9132 - val_precision: 0.7490\n",
            "Epoch 192/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5880 - accuracy: 0.6590 - sensitivity_at_specificity: 0.8025 - specificity_at_sensitivity: 0.7526 - recall: 0.7971 - precision: 0.6274\n",
            "Epoch 192: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.5880 - accuracy: 0.6590 - sensitivity_at_specificity: 0.8025 - specificity_at_sensitivity: 0.7526 - recall: 0.7971 - precision: 0.6274 - val_loss: 0.4498 - val_accuracy: 0.7898 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8742 - val_recall: 0.8662 - val_precision: 0.7462\n",
            "Epoch 193/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5842 - accuracy: 0.6541 - sensitivity_at_specificity: 0.8074 - specificity_at_sensitivity: 0.7538 - recall: 0.8397 - precision: 0.6139\n",
            "Epoch 193: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 157ms/step - loss: 0.5842 - accuracy: 0.6541 - sensitivity_at_specificity: 0.8074 - specificity_at_sensitivity: 0.7538 - recall: 0.8397 - precision: 0.6139 - val_loss: 0.4521 - val_accuracy: 0.7836 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8656 - val_recall: 0.8443 - val_precision: 0.7596\n",
            "Epoch 194/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5878 - accuracy: 0.6562 - sensitivity_at_specificity: 0.8083 - specificity_at_sensitivity: 0.7490 - recall: 0.7518 - precision: 0.6292\n",
            "Epoch 194: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.5878 - accuracy: 0.6562 - sensitivity_at_specificity: 0.8083 - specificity_at_sensitivity: 0.7490 - recall: 0.7518 - precision: 0.6292 - val_loss: 0.4409 - val_accuracy: 0.7977 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8875 - val_recall: 0.8875 - val_precision: 0.7523\n",
            "Epoch 195/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5806 - accuracy: 0.6645 - sensitivity_at_specificity: 0.8032 - specificity_at_sensitivity: 0.7712 - recall: 0.7994 - precision: 0.6349\n",
            "Epoch 195: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.5806 - accuracy: 0.6645 - sensitivity_at_specificity: 0.8032 - specificity_at_sensitivity: 0.7712 - recall: 0.7994 - precision: 0.6349 - val_loss: 0.4427 - val_accuracy: 0.7852 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8838 - val_recall: 0.8466 - val_precision: 0.7593\n",
            "Epoch 196/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5828 - accuracy: 0.6551 - sensitivity_at_specificity: 0.8163 - specificity_at_sensitivity: 0.7603 - recall: 0.7795 - precision: 0.6239\n",
            "Epoch 196: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.5828 - accuracy: 0.6551 - sensitivity_at_specificity: 0.8163 - specificity_at_sensitivity: 0.7603 - recall: 0.7795 - precision: 0.6239 - val_loss: 0.4311 - val_accuracy: 0.8234 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8846 - val_recall: 0.9179 - val_precision: 0.7864\n",
            "Epoch 197/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5984 - accuracy: 0.6449 - sensitivity_at_specificity: 0.7541 - specificity_at_sensitivity: 0.6966 - recall: 0.9100 - precision: 0.6061\n",
            "Epoch 197: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.5984 - accuracy: 0.6449 - sensitivity_at_specificity: 0.7541 - specificity_at_sensitivity: 0.6966 - recall: 0.9100 - precision: 0.6061 - val_loss: 0.4512 - val_accuracy: 0.7922 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8673 - val_recall: 0.8949 - val_precision: 0.7452\n",
            "Epoch 198/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5836 - accuracy: 0.6523 - sensitivity_at_specificity: 0.7990 - specificity_at_sensitivity: 0.7586 - recall: 0.7736 - precision: 0.6168\n",
            "Epoch 198: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.5836 - accuracy: 0.6523 - sensitivity_at_specificity: 0.7990 - specificity_at_sensitivity: 0.7586 - recall: 0.7736 - precision: 0.6168 - val_loss: 0.4528 - val_accuracy: 0.7852 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8789 - val_recall: 0.7783 - val_precision: 0.7870\n",
            "Epoch 199/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5931 - accuracy: 0.6527 - sensitivity_at_specificity: 0.8005 - specificity_at_sensitivity: 0.7424 - recall: 0.8059 - precision: 0.6177\n",
            "Epoch 199: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.5931 - accuracy: 0.6527 - sensitivity_at_specificity: 0.8005 - specificity_at_sensitivity: 0.7424 - recall: 0.8059 - precision: 0.6177 - val_loss: 0.4145 - val_accuracy: 0.8188 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8962 - val_recall: 0.9388 - val_precision: 0.7618\n",
            "Epoch 200/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5812 - accuracy: 0.6594 - sensitivity_at_specificity: 0.8124 - specificity_at_sensitivity: 0.7526 - recall: 0.7931 - precision: 0.6297\n",
            "Epoch 200: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.5812 - accuracy: 0.6594 - sensitivity_at_specificity: 0.8124 - specificity_at_sensitivity: 0.7526 - recall: 0.7931 - precision: 0.6297 - val_loss: 0.4479 - val_accuracy: 0.7789 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8515 - val_recall: 0.8346 - val_precision: 0.7542\n",
            "Epoch 201/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5769 - accuracy: 0.6711 - sensitivity_at_specificity: 0.8333 - specificity_at_sensitivity: 0.7568 - recall: 0.8502 - precision: 0.6311\n",
            "Epoch 201: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.5769 - accuracy: 0.6711 - sensitivity_at_specificity: 0.8333 - specificity_at_sensitivity: 0.7568 - recall: 0.8502 - precision: 0.6311 - val_loss: 0.4686 - val_accuracy: 0.7672 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8449 - val_recall: 0.8571 - val_precision: 0.7154\n",
            "Epoch 202/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5791 - accuracy: 0.6625 - sensitivity_at_specificity: 0.8103 - specificity_at_sensitivity: 0.7736 - recall: 0.7957 - precision: 0.6327\n",
            "Epoch 202: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.5791 - accuracy: 0.6625 - sensitivity_at_specificity: 0.8103 - specificity_at_sensitivity: 0.7736 - recall: 0.7957 - precision: 0.6327 - val_loss: 0.4292 - val_accuracy: 0.7961 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8862 - val_recall: 0.9308 - val_precision: 0.7261\n",
            "Epoch 203/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5794 - accuracy: 0.6613 - sensitivity_at_specificity: 0.8011 - specificity_at_sensitivity: 0.7920 - recall: 0.7596 - precision: 0.6269\n",
            "Epoch 203: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.5794 - accuracy: 0.6613 - sensitivity_at_specificity: 0.8011 - specificity_at_sensitivity: 0.7920 - recall: 0.7596 - precision: 0.6269 - val_loss: 0.4283 - val_accuracy: 0.8039 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8866 - val_recall: 0.8639 - val_precision: 0.7772\n",
            "Epoch 204/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5783 - accuracy: 0.6590 - sensitivity_at_specificity: 0.8044 - specificity_at_sensitivity: 0.7787 - recall: 0.7506 - precision: 0.6295\n",
            "Epoch 204: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.5783 - accuracy: 0.6590 - sensitivity_at_specificity: 0.8044 - specificity_at_sensitivity: 0.7787 - recall: 0.7506 - precision: 0.6295 - val_loss: 0.4201 - val_accuracy: 0.8008 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8862 - val_recall: 0.8696 - val_precision: 0.7563\n",
            "Epoch 205/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5853 - accuracy: 0.6672 - sensitivity_at_specificity: 0.8106 - specificity_at_sensitivity: 0.7733 - recall: 0.8053 - precision: 0.6424\n",
            "Epoch 205: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.5853 - accuracy: 0.6672 - sensitivity_at_specificity: 0.8106 - specificity_at_sensitivity: 0.7733 - recall: 0.8053 - precision: 0.6424 - val_loss: 0.4343 - val_accuracy: 0.7898 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8735 - val_recall: 0.9046 - val_precision: 0.7227\n",
            "Epoch 206/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5854 - accuracy: 0.6512 - sensitivity_at_specificity: 0.8011 - specificity_at_sensitivity: 0.7786 - recall: 0.8066 - precision: 0.6158\n",
            "Epoch 206: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.5854 - accuracy: 0.6512 - sensitivity_at_specificity: 0.8011 - specificity_at_sensitivity: 0.7786 - recall: 0.8066 - precision: 0.6158 - val_loss: 0.4234 - val_accuracy: 0.8102 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9013 - val_recall: 0.9396 - val_precision: 0.7539\n",
            "Epoch 207/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5722 - accuracy: 0.6531 - sensitivity_at_specificity: 0.7900 - specificity_at_sensitivity: 0.7833 - recall: 0.7938 - precision: 0.6283\n",
            "Epoch 207: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.5722 - accuracy: 0.6531 - sensitivity_at_specificity: 0.7900 - specificity_at_sensitivity: 0.7833 - recall: 0.7938 - precision: 0.6283 - val_loss: 0.4498 - val_accuracy: 0.7734 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8578 - val_recall: 0.8029 - val_precision: 0.7474\n",
            "Epoch 208/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5752 - accuracy: 0.6586 - sensitivity_at_specificity: 0.8031 - specificity_at_sensitivity: 0.7984 - recall: 0.7710 - precision: 0.6281\n",
            "Epoch 208: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.5752 - accuracy: 0.6586 - sensitivity_at_specificity: 0.8031 - specificity_at_sensitivity: 0.7984 - recall: 0.7710 - precision: 0.6281 - val_loss: 0.4546 - val_accuracy: 0.7781 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8554 - val_recall: 0.8636 - val_precision: 0.7268\n",
            "Epoch 209/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5737 - accuracy: 0.6664 - sensitivity_at_specificity: 0.8243 - specificity_at_sensitivity: 0.7634 - recall: 0.7762 - precision: 0.6443\n",
            "Epoch 209: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.5737 - accuracy: 0.6664 - sensitivity_at_specificity: 0.8243 - specificity_at_sensitivity: 0.7634 - recall: 0.7762 - precision: 0.6443 - val_loss: 0.4655 - val_accuracy: 0.7727 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8494 - val_recall: 0.7892 - val_precision: 0.7788\n",
            "Epoch 210/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5782 - accuracy: 0.6578 - sensitivity_at_specificity: 0.8011 - specificity_at_sensitivity: 0.7693 - recall: 0.7572 - precision: 0.6308\n",
            "Epoch 210: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.5782 - accuracy: 0.6578 - sensitivity_at_specificity: 0.8011 - specificity_at_sensitivity: 0.7693 - recall: 0.7572 - precision: 0.6308 - val_loss: 0.4327 - val_accuracy: 0.7961 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8856 - val_recall: 0.8278 - val_precision: 0.7751\n",
            "Epoch 211/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5715 - accuracy: 0.6719 - sensitivity_at_specificity: 0.8252 - specificity_at_sensitivity: 0.7922 - recall: 0.7866 - precision: 0.6371\n",
            "Epoch 211: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.5715 - accuracy: 0.6719 - sensitivity_at_specificity: 0.8252 - specificity_at_sensitivity: 0.7922 - recall: 0.7866 - precision: 0.6371 - val_loss: 0.4543 - val_accuracy: 0.7906 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8667 - val_recall: 0.8376 - val_precision: 0.7768\n",
            "Epoch 212/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5733 - accuracy: 0.6668 - sensitivity_at_specificity: 0.8155 - specificity_at_sensitivity: 0.7828 - recall: 0.7449 - precision: 0.6549\n",
            "Epoch 212: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.5733 - accuracy: 0.6668 - sensitivity_at_specificity: 0.8155 - specificity_at_sensitivity: 0.7828 - recall: 0.7449 - precision: 0.6549 - val_loss: 0.4081 - val_accuracy: 0.7984 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8839 - val_recall: 0.9448 - val_precision: 0.7287\n",
            "Epoch 213/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5769 - accuracy: 0.6605 - sensitivity_at_specificity: 0.8130 - specificity_at_sensitivity: 0.7887 - recall: 0.7989 - precision: 0.6239\n",
            "Epoch 213: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.5769 - accuracy: 0.6605 - sensitivity_at_specificity: 0.8130 - specificity_at_sensitivity: 0.7887 - recall: 0.7989 - precision: 0.6239 - val_loss: 0.4481 - val_accuracy: 0.7828 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8600 - val_recall: 0.8650 - val_precision: 0.7416\n",
            "Epoch 214/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5815 - accuracy: 0.6602 - sensitivity_at_specificity: 0.8122 - specificity_at_sensitivity: 0.7799 - recall: 0.7433 - precision: 0.6262\n",
            "Epoch 214: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.5833 - accuracy: 0.6599 - sensitivity_at_specificity: 0.8052 - specificity_at_sensitivity: 0.7804 - recall: 0.7485 - precision: 0.6237 - val_loss: 0.4499 - val_accuracy: 0.7867 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8729 - val_recall: 0.8220 - val_precision: 0.7836\n",
            "Epoch 215/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5849 - accuracy: 0.6488 - sensitivity_at_specificity: 0.7917 - specificity_at_sensitivity: 0.7595 - recall: 0.7677 - precision: 0.6246\n",
            "Epoch 215: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.5849 - accuracy: 0.6488 - sensitivity_at_specificity: 0.7917 - specificity_at_sensitivity: 0.7595 - recall: 0.7677 - precision: 0.6246 - val_loss: 0.4490 - val_accuracy: 0.7563 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8656 - val_recall: 0.7248 - val_precision: 0.7639\n",
            "Epoch 216/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5726 - accuracy: 0.6777 - sensitivity_at_specificity: 0.8271 - specificity_at_sensitivity: 0.7843 - recall: 0.7768 - precision: 0.6572\n",
            "Epoch 216: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 189ms/step - loss: 0.5726 - accuracy: 0.6777 - sensitivity_at_specificity: 0.8271 - specificity_at_sensitivity: 0.7843 - recall: 0.7768 - precision: 0.6572 - val_loss: 0.4550 - val_accuracy: 0.7805 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8810 - val_recall: 0.7744 - val_precision: 0.7706\n",
            "Epoch 217/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5622 - accuracy: 0.6816 - sensitivity_at_specificity: 0.8544 - specificity_at_sensitivity: 0.7983 - recall: 0.7600 - precision: 0.6545\n",
            "Epoch 217: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.5622 - accuracy: 0.6816 - sensitivity_at_specificity: 0.8544 - specificity_at_sensitivity: 0.7983 - recall: 0.7600 - precision: 0.6545 - val_loss: 0.4259 - val_accuracy: 0.7844 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8862 - val_recall: 0.8286 - val_precision: 0.7565\n",
            "Epoch 218/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5711 - accuracy: 0.6695 - sensitivity_at_specificity: 0.8284 - specificity_at_sensitivity: 0.8133 - recall: 0.6919 - precision: 0.6534\n",
            "Epoch 218: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.5711 - accuracy: 0.6695 - sensitivity_at_specificity: 0.8284 - specificity_at_sensitivity: 0.8133 - recall: 0.6919 - precision: 0.6534 - val_loss: 0.4351 - val_accuracy: 0.7664 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8587 - val_recall: 0.7385 - val_precision: 0.7882\n",
            "Epoch 219/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5666 - accuracy: 0.6766 - sensitivity_at_specificity: 0.8323 - specificity_at_sensitivity: 0.8151 - recall: 0.7071 - precision: 0.6555\n",
            "Epoch 219: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.5666 - accuracy: 0.6766 - sensitivity_at_specificity: 0.8323 - specificity_at_sensitivity: 0.8151 - recall: 0.7071 - precision: 0.6555 - val_loss: 0.4529 - val_accuracy: 0.7820 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8698 - val_recall: 0.7890 - val_precision: 0.7755\n",
            "Epoch 220/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5632 - accuracy: 0.6773 - sensitivity_at_specificity: 0.8405 - specificity_at_sensitivity: 0.7915 - recall: 0.8002 - precision: 0.6321\n",
            "Epoch 220: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.5632 - accuracy: 0.6773 - sensitivity_at_specificity: 0.8405 - specificity_at_sensitivity: 0.7915 - recall: 0.8002 - precision: 0.6321 - val_loss: 0.4358 - val_accuracy: 0.7852 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8955 - val_recall: 0.8013 - val_precision: 0.7706\n",
            "Epoch 221/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5694 - accuracy: 0.6730 - sensitivity_at_specificity: 0.8157 - specificity_at_sensitivity: 0.8017 - recall: 0.7355 - precision: 0.6476\n",
            "Epoch 221: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.5694 - accuracy: 0.6730 - sensitivity_at_specificity: 0.8157 - specificity_at_sensitivity: 0.8017 - recall: 0.7355 - precision: 0.6476 - val_loss: 0.4324 - val_accuracy: 0.7789 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9027 - val_recall: 0.7534 - val_precision: 0.8013\n",
            "Epoch 222/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5585 - accuracy: 0.6777 - sensitivity_at_specificity: 0.8308 - specificity_at_sensitivity: 0.8085 - recall: 0.7715 - precision: 0.6455\n",
            "Epoch 222: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.5585 - accuracy: 0.6777 - sensitivity_at_specificity: 0.8308 - specificity_at_sensitivity: 0.8085 - recall: 0.7715 - precision: 0.6455 - val_loss: 0.4458 - val_accuracy: 0.7734 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8819 - val_recall: 0.7500 - val_precision: 0.7798\n",
            "Epoch 223/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5647 - accuracy: 0.6664 - sensitivity_at_specificity: 0.8093 - specificity_at_sensitivity: 0.8047 - recall: 0.7183 - precision: 0.6523\n",
            "Epoch 223: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.5647 - accuracy: 0.6664 - sensitivity_at_specificity: 0.8093 - specificity_at_sensitivity: 0.8047 - recall: 0.7183 - precision: 0.6523 - val_loss: 0.4538 - val_accuracy: 0.7617 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8782 - val_recall: 0.6898 - val_precision: 0.8223\n",
            "Epoch 224/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5596 - accuracy: 0.6754 - sensitivity_at_specificity: 0.8313 - specificity_at_sensitivity: 0.8244 - recall: 0.6642 - precision: 0.6626\n",
            "Epoch 224: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.5596 - accuracy: 0.6754 - sensitivity_at_specificity: 0.8313 - specificity_at_sensitivity: 0.8244 - recall: 0.6642 - precision: 0.6626 - val_loss: 0.4433 - val_accuracy: 0.7789 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8875 - val_recall: 0.7644 - val_precision: 0.7971\n",
            "Epoch 225/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5662 - accuracy: 0.6727 - sensitivity_at_specificity: 0.8187 - specificity_at_sensitivity: 0.8225 - recall: 0.7047 - precision: 0.6425\n",
            "Epoch 225: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.5662 - accuracy: 0.6727 - sensitivity_at_specificity: 0.8187 - specificity_at_sensitivity: 0.8225 - recall: 0.7047 - precision: 0.6425 - val_loss: 0.4316 - val_accuracy: 0.7930 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8923 - val_recall: 0.8070 - val_precision: 0.7937\n",
            "Epoch 226/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5548 - accuracy: 0.6781 - sensitivity_at_specificity: 0.8226 - specificity_at_sensitivity: 0.8195 - recall: 0.7271 - precision: 0.6707\n",
            "Epoch 226: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.5548 - accuracy: 0.6781 - sensitivity_at_specificity: 0.8226 - specificity_at_sensitivity: 0.8195 - recall: 0.7271 - precision: 0.6707 - val_loss: 0.4604 - val_accuracy: 0.7656 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8849 - val_recall: 0.7268 - val_precision: 0.7861\n",
            "Epoch 227/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5589 - accuracy: 0.6794 - sensitivity_at_specificity: 0.8216 - specificity_at_sensitivity: 0.8121 - recall: 0.7311 - precision: 0.6629\n",
            "Epoch 227: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 156ms/step - loss: 0.5589 - accuracy: 0.6794 - sensitivity_at_specificity: 0.8216 - specificity_at_sensitivity: 0.8121 - recall: 0.7311 - precision: 0.6629 - val_loss: 0.4480 - val_accuracy: 0.7750 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8585 - val_recall: 0.7857 - val_precision: 0.7639\n",
            "Epoch 228/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5624 - accuracy: 0.6773 - sensitivity_at_specificity: 0.8435 - specificity_at_sensitivity: 0.8149 - recall: 0.7339 - precision: 0.6720\n",
            "Epoch 228: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.5624 - accuracy: 0.6773 - sensitivity_at_specificity: 0.8435 - specificity_at_sensitivity: 0.8149 - recall: 0.7339 - precision: 0.6720 - val_loss: 0.4365 - val_accuracy: 0.7688 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8853 - val_recall: 0.7859 - val_precision: 0.7523\n",
            "Epoch 229/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5865 - accuracy: 0.6531 - sensitivity_at_specificity: 0.7948 - specificity_at_sensitivity: 0.7498 - recall: 0.7940 - precision: 0.6249\n",
            "Epoch 229: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.5865 - accuracy: 0.6531 - sensitivity_at_specificity: 0.7948 - specificity_at_sensitivity: 0.7498 - recall: 0.7940 - precision: 0.6249 - val_loss: 0.4586 - val_accuracy: 0.7695 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8266 - val_recall: 0.8326 - val_precision: 0.7500\n",
            "Epoch 230/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5690 - accuracy: 0.6762 - sensitivity_at_specificity: 0.8316 - specificity_at_sensitivity: 0.7825 - recall: 0.7490 - precision: 0.6477\n",
            "Epoch 230: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.5690 - accuracy: 0.6762 - sensitivity_at_specificity: 0.8316 - specificity_at_sensitivity: 0.7825 - recall: 0.7490 - precision: 0.6477 - val_loss: 0.4522 - val_accuracy: 0.7766 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8924 - val_recall: 0.7371 - val_precision: 0.7997\n",
            "Epoch 231/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5628 - accuracy: 0.6668 - sensitivity_at_specificity: 0.8108 - specificity_at_sensitivity: 0.8159 - recall: 0.7826 - precision: 0.6437\n",
            "Epoch 231: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.5628 - accuracy: 0.6668 - sensitivity_at_specificity: 0.8108 - specificity_at_sensitivity: 0.8159 - recall: 0.7826 - precision: 0.6437 - val_loss: 0.4550 - val_accuracy: 0.7500 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8541 - val_recall: 0.7350 - val_precision: 0.7422\n",
            "Epoch 232/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5555 - accuracy: 0.6801 - sensitivity_at_specificity: 0.8344 - specificity_at_sensitivity: 0.8328 - recall: 0.6896 - precision: 0.6667\n",
            "Epoch 232: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.5555 - accuracy: 0.6801 - sensitivity_at_specificity: 0.8344 - specificity_at_sensitivity: 0.8328 - recall: 0.6896 - precision: 0.6667 - val_loss: 0.4634 - val_accuracy: 0.7516 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8776 - val_recall: 0.7107 - val_precision: 0.7759\n",
            "Epoch 233/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5555 - accuracy: 0.6785 - sensitivity_at_specificity: 0.8396 - specificity_at_sensitivity: 0.8086 - recall: 0.6934 - precision: 0.6664\n",
            "Epoch 233: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.5555 - accuracy: 0.6785 - sensitivity_at_specificity: 0.8396 - specificity_at_sensitivity: 0.8086 - recall: 0.6934 - precision: 0.6664 - val_loss: 0.4524 - val_accuracy: 0.7625 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8775 - val_recall: 0.7213 - val_precision: 0.7829\n",
            "Epoch 234/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5457 - accuracy: 0.6969 - sensitivity_at_specificity: 0.8359 - specificity_at_sensitivity: 0.8524 - recall: 0.7053 - precision: 0.6755\n",
            "Epoch 234: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.5457 - accuracy: 0.6969 - sensitivity_at_specificity: 0.8359 - specificity_at_sensitivity: 0.8524 - recall: 0.7053 - precision: 0.6755 - val_loss: 0.4532 - val_accuracy: 0.7664 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8640 - val_recall: 0.7649 - val_precision: 0.7755\n",
            "Epoch 235/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5529 - accuracy: 0.6885 - sensitivity_at_specificity: 0.8405 - specificity_at_sensitivity: 0.8322 - recall: 0.7355 - precision: 0.6742\n",
            "Epoch 235: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 157ms/step - loss: 0.5529 - accuracy: 0.6885 - sensitivity_at_specificity: 0.8405 - specificity_at_sensitivity: 0.8322 - recall: 0.7355 - precision: 0.6742 - val_loss: 0.4249 - val_accuracy: 0.7922 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8752 - val_recall: 0.8162 - val_precision: 0.7744\n",
            "Epoch 236/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5538 - accuracy: 0.6823 - sensitivity_at_specificity: 0.8500 - specificity_at_sensitivity: 0.8251 - recall: 0.7258 - precision: 0.6556\n",
            "Epoch 236: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 176ms/step - loss: 0.5538 - accuracy: 0.6823 - sensitivity_at_specificity: 0.8500 - specificity_at_sensitivity: 0.8251 - recall: 0.7258 - precision: 0.6556 - val_loss: 0.4408 - val_accuracy: 0.7719 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8892 - val_recall: 0.7590 - val_precision: 0.7785\n",
            "Epoch 237/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5575 - accuracy: 0.6906 - sensitivity_at_specificity: 0.8270 - specificity_at_sensitivity: 0.8270 - recall: 0.6890 - precision: 0.6825\n",
            "Epoch 237: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.5575 - accuracy: 0.6906 - sensitivity_at_specificity: 0.8270 - specificity_at_sensitivity: 0.8270 - recall: 0.6890 - precision: 0.6825 - val_loss: 0.4377 - val_accuracy: 0.7820 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8688 - val_recall: 0.8323 - val_precision: 0.7525\n",
            "Epoch 238/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5434 - accuracy: 0.7023 - sensitivity_at_specificity: 0.8705 - specificity_at_sensitivity: 0.8470 - recall: 0.7264 - precision: 0.7007\n",
            "Epoch 238: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.5434 - accuracy: 0.7023 - sensitivity_at_specificity: 0.8705 - specificity_at_sensitivity: 0.8470 - recall: 0.7264 - precision: 0.7007 - val_loss: 0.4352 - val_accuracy: 0.7734 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8822 - val_recall: 0.7906 - val_precision: 0.7618\n",
            "Epoch 239/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5496 - accuracy: 0.6840 - sensitivity_at_specificity: 0.8375 - specificity_at_sensitivity: 0.8337 - recall: 0.7155 - precision: 0.6652\n",
            "Epoch 239: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.5496 - accuracy: 0.6840 - sensitivity_at_specificity: 0.8375 - specificity_at_sensitivity: 0.8337 - recall: 0.7155 - precision: 0.6652 - val_loss: 0.4413 - val_accuracy: 0.7727 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8984 - val_recall: 0.7909 - val_precision: 0.7733\n",
            "Epoch 240/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5609 - accuracy: 0.6699 - sensitivity_at_specificity: 0.8265 - specificity_at_sensitivity: 0.8235 - recall: 0.7033 - precision: 0.6628\n",
            "Epoch 240: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.5609 - accuracy: 0.6699 - sensitivity_at_specificity: 0.8265 - specificity_at_sensitivity: 0.8235 - recall: 0.7033 - precision: 0.6628 - val_loss: 0.4153 - val_accuracy: 0.7789 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9087 - val_recall: 0.7839 - val_precision: 0.7729\n",
            "Epoch 241/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5522 - accuracy: 0.6730 - sensitivity_at_specificity: 0.8397 - specificity_at_sensitivity: 0.8384 - recall: 0.7513 - precision: 0.6651\n",
            "Epoch 241: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.5522 - accuracy: 0.6730 - sensitivity_at_specificity: 0.8397 - specificity_at_sensitivity: 0.8384 - recall: 0.7513 - precision: 0.6651 - val_loss: 0.4305 - val_accuracy: 0.7750 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8830 - val_recall: 0.8312 - val_precision: 0.7386\n",
            "Epoch 242/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5616 - accuracy: 0.6707 - sensitivity_at_specificity: 0.8342 - specificity_at_sensitivity: 0.8143 - recall: 0.7706 - precision: 0.6403\n",
            "Epoch 242: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.5616 - accuracy: 0.6707 - sensitivity_at_specificity: 0.8342 - specificity_at_sensitivity: 0.8143 - recall: 0.7706 - precision: 0.6403 - val_loss: 0.4481 - val_accuracy: 0.7469 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8729 - val_recall: 0.6721 - val_precision: 0.7747\n",
            "Epoch 243/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5426 - accuracy: 0.6859 - sensitivity_at_specificity: 0.8389 - specificity_at_sensitivity: 0.8296 - recall: 0.7337 - precision: 0.6821\n",
            "Epoch 243: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.5426 - accuracy: 0.6859 - sensitivity_at_specificity: 0.8389 - specificity_at_sensitivity: 0.8296 - recall: 0.7337 - precision: 0.6821 - val_loss: 0.4542 - val_accuracy: 0.7695 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.8713 - val_recall: 0.7654 - val_precision: 0.7690\n",
            "Epoch 244/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5581 - accuracy: 0.6707 - sensitivity_at_specificity: 0.8332 - specificity_at_sensitivity: 0.8355 - recall: 0.6802 - precision: 0.6522\n",
            "Epoch 244: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.5581 - accuracy: 0.6707 - sensitivity_at_specificity: 0.8332 - specificity_at_sensitivity: 0.8355 - recall: 0.6802 - precision: 0.6522 - val_loss: 0.4690 - val_accuracy: 0.7414 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8752 - val_recall: 0.6491 - val_precision: 0.8015\n",
            "Epoch 245/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5514 - accuracy: 0.6894 - sensitivity_at_specificity: 0.8486 - specificity_at_sensitivity: 0.8360 - recall: 0.7151 - precision: 0.6707\n",
            "Epoch 245: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.5514 - accuracy: 0.6894 - sensitivity_at_specificity: 0.8486 - specificity_at_sensitivity: 0.8360 - recall: 0.7151 - precision: 0.6707 - val_loss: 0.4588 - val_accuracy: 0.7719 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8554 - val_recall: 0.7841 - val_precision: 0.7600\n",
            "Epoch 246/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5454 - accuracy: 0.6883 - sensitivity_at_specificity: 0.8498 - specificity_at_sensitivity: 0.8432 - recall: 0.6553 - precision: 0.6961\n",
            "Epoch 246: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.5454 - accuracy: 0.6883 - sensitivity_at_specificity: 0.8498 - specificity_at_sensitivity: 0.8432 - recall: 0.6553 - precision: 0.6961 - val_loss: 0.4628 - val_accuracy: 0.7453 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8609 - val_recall: 0.7219 - val_precision: 0.7574\n",
            "Epoch 247/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5339 - accuracy: 0.7055 - sensitivity_at_specificity: 0.8620 - specificity_at_sensitivity: 0.8403 - recall: 0.7472 - precision: 0.7049\n",
            "Epoch 247: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.5339 - accuracy: 0.7055 - sensitivity_at_specificity: 0.8620 - specificity_at_sensitivity: 0.8403 - recall: 0.7472 - precision: 0.7049 - val_loss: 0.4479 - val_accuracy: 0.7789 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8894 - val_recall: 0.7450 - val_precision: 0.8033\n",
            "Epoch 248/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5476 - accuracy: 0.7035 - sensitivity_at_specificity: 0.8426 - specificity_at_sensitivity: 0.8379 - recall: 0.7062 - precision: 0.7034\n",
            "Epoch 248: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.5476 - accuracy: 0.7035 - sensitivity_at_specificity: 0.8426 - specificity_at_sensitivity: 0.8379 - recall: 0.7062 - precision: 0.7034 - val_loss: 0.4397 - val_accuracy: 0.7711 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8789 - val_recall: 0.8251 - val_precision: 0.7582\n",
            "Epoch 249/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5359 - accuracy: 0.6926 - sensitivity_at_specificity: 0.8490 - specificity_at_sensitivity: 0.8663 - recall: 0.7277 - precision: 0.6893\n",
            "Epoch 249: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.5359 - accuracy: 0.6926 - sensitivity_at_specificity: 0.8490 - specificity_at_sensitivity: 0.8663 - recall: 0.7277 - precision: 0.6893 - val_loss: 0.4489 - val_accuracy: 0.7656 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8752 - val_recall: 0.7718 - val_precision: 0.7574\n",
            "Epoch 250/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5397 - accuracy: 0.7004 - sensitivity_at_specificity: 0.8639 - specificity_at_sensitivity: 0.8530 - recall: 0.7658 - precision: 0.6869\n",
            "Epoch 250: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.5397 - accuracy: 0.7004 - sensitivity_at_specificity: 0.8639 - specificity_at_sensitivity: 0.8530 - recall: 0.7658 - precision: 0.6869 - val_loss: 0.4636 - val_accuracy: 0.7422 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8742 - val_recall: 0.6662 - val_precision: 0.8062\n",
            "Epoch 251/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5357 - accuracy: 0.6965 - sensitivity_at_specificity: 0.8603 - specificity_at_sensitivity: 0.8402 - recall: 0.7114 - precision: 0.6958\n",
            "Epoch 251: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 186ms/step - loss: 0.5357 - accuracy: 0.6965 - sensitivity_at_specificity: 0.8603 - specificity_at_sensitivity: 0.8402 - recall: 0.7114 - precision: 0.6958 - val_loss: 0.4268 - val_accuracy: 0.7820 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8927 - val_recall: 0.7740 - val_precision: 0.7899\n",
            "Epoch 252/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5390 - accuracy: 0.6910 - sensitivity_at_specificity: 0.8575 - specificity_at_sensitivity: 0.8527 - recall: 0.6841 - precision: 0.6879\n",
            "Epoch 252: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.5390 - accuracy: 0.6910 - sensitivity_at_specificity: 0.8575 - specificity_at_sensitivity: 0.8527 - recall: 0.6841 - precision: 0.6879 - val_loss: 0.4435 - val_accuracy: 0.7789 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8684 - val_recall: 0.8202 - val_precision: 0.7547\n",
            "Epoch 253/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5309 - accuracy: 0.7027 - sensitivity_at_specificity: 0.8710 - specificity_at_sensitivity: 0.8545 - recall: 0.7527 - precision: 0.6906\n",
            "Epoch 253: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.5309 - accuracy: 0.7027 - sensitivity_at_specificity: 0.8710 - specificity_at_sensitivity: 0.8545 - recall: 0.7527 - precision: 0.6906 - val_loss: 0.4309 - val_accuracy: 0.7844 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8762 - val_recall: 0.8233 - val_precision: 0.7609\n",
            "Epoch 254/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5439 - accuracy: 0.6973 - sensitivity_at_specificity: 0.8403 - specificity_at_sensitivity: 0.8449 - recall: 0.7555 - precision: 0.6849\n",
            "Epoch 254: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.5439 - accuracy: 0.6973 - sensitivity_at_specificity: 0.8403 - specificity_at_sensitivity: 0.8449 - recall: 0.7555 - precision: 0.6849 - val_loss: 0.4606 - val_accuracy: 0.7492 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8811 - val_recall: 0.6934 - val_precision: 0.7867\n",
            "Epoch 255/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5335 - accuracy: 0.7105 - sensitivity_at_specificity: 0.8631 - specificity_at_sensitivity: 0.8634 - recall: 0.7347 - precision: 0.7092\n",
            "Epoch 255: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.5335 - accuracy: 0.7105 - sensitivity_at_specificity: 0.8631 - specificity_at_sensitivity: 0.8634 - recall: 0.7347 - precision: 0.7092 - val_loss: 0.4456 - val_accuracy: 0.7625 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8662 - val_recall: 0.7546 - val_precision: 0.7736\n",
            "Epoch 256/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5389 - accuracy: 0.6938 - sensitivity_at_specificity: 0.8528 - specificity_at_sensitivity: 0.8387 - recall: 0.7322 - precision: 0.6790\n",
            "Epoch 256: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.5389 - accuracy: 0.6938 - sensitivity_at_specificity: 0.8528 - specificity_at_sensitivity: 0.8387 - recall: 0.7322 - precision: 0.6790 - val_loss: 0.4329 - val_accuracy: 0.7648 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8927 - val_recall: 0.7221 - val_precision: 0.7877\n",
            "Epoch 257/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5287 - accuracy: 0.7109 - sensitivity_at_specificity: 0.8769 - specificity_at_sensitivity: 0.8541 - recall: 0.7042 - precision: 0.7042\n",
            "Epoch 257: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.5287 - accuracy: 0.7109 - sensitivity_at_specificity: 0.8769 - specificity_at_sensitivity: 0.8541 - recall: 0.7042 - precision: 0.7042 - val_loss: 0.4805 - val_accuracy: 0.7555 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8475 - val_recall: 0.7686 - val_precision: 0.7583\n",
            "Epoch 258/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5450 - accuracy: 0.6968 - sensitivity_at_specificity: 0.8416 - specificity_at_sensitivity: 0.8428 - recall: 0.7405 - precision: 0.6817\n",
            "Epoch 258: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.5450 - accuracy: 0.6968 - sensitivity_at_specificity: 0.8416 - specificity_at_sensitivity: 0.8428 - recall: 0.7405 - precision: 0.6817 - val_loss: 0.4649 - val_accuracy: 0.7398 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8909 - val_recall: 0.6242 - val_precision: 0.7947\n",
            "Epoch 259/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5309 - accuracy: 0.7012 - sensitivity_at_specificity: 0.8602 - specificity_at_sensitivity: 0.8709 - recall: 0.6600 - precision: 0.7115\n",
            "Epoch 259: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.5309 - accuracy: 0.7012 - sensitivity_at_specificity: 0.8602 - specificity_at_sensitivity: 0.8709 - recall: 0.6600 - precision: 0.7115 - val_loss: 0.4617 - val_accuracy: 0.7547 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8700 - val_recall: 0.7713 - val_precision: 0.7432\n",
            "Epoch 260/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5412 - accuracy: 0.6965 - sensitivity_at_specificity: 0.8534 - specificity_at_sensitivity: 0.8574 - recall: 0.6759 - precision: 0.6865\n",
            "Epoch 260: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.5412 - accuracy: 0.6965 - sensitivity_at_specificity: 0.8534 - specificity_at_sensitivity: 0.8574 - recall: 0.6759 - precision: 0.6865 - val_loss: 0.4517 - val_accuracy: 0.7531 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8717 - val_recall: 0.6919 - val_precision: 0.7835\n",
            "Epoch 261/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5184 - accuracy: 0.7160 - sensitivity_at_specificity: 0.8763 - specificity_at_sensitivity: 0.8761 - recall: 0.7463 - precision: 0.7051\n",
            "Epoch 261: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.5184 - accuracy: 0.7160 - sensitivity_at_specificity: 0.8763 - specificity_at_sensitivity: 0.8761 - recall: 0.7463 - precision: 0.7051 - val_loss: 0.4526 - val_accuracy: 0.7477 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8793 - val_recall: 0.6672 - val_precision: 0.7907\n",
            "Epoch 262/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5397 - accuracy: 0.7023 - sensitivity_at_specificity: 0.8535 - specificity_at_sensitivity: 0.8519 - recall: 0.6654 - precision: 0.7246\n",
            "Epoch 262: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.5397 - accuracy: 0.7023 - sensitivity_at_specificity: 0.8535 - specificity_at_sensitivity: 0.8519 - recall: 0.6654 - precision: 0.7246 - val_loss: 0.4321 - val_accuracy: 0.7750 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8717 - val_recall: 0.7988 - val_precision: 0.7630\n",
            "Epoch 263/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5386 - accuracy: 0.6977 - sensitivity_at_specificity: 0.8595 - specificity_at_sensitivity: 0.8616 - recall: 0.7197 - precision: 0.6918\n",
            "Epoch 263: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.5386 - accuracy: 0.6977 - sensitivity_at_specificity: 0.8595 - specificity_at_sensitivity: 0.8616 - recall: 0.7197 - precision: 0.6918 - val_loss: 0.4362 - val_accuracy: 0.7633 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8772 - val_recall: 0.7752 - val_precision: 0.7599\n",
            "Epoch 264/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5257 - accuracy: 0.6984 - sensitivity_at_specificity: 0.8615 - specificity_at_sensitivity: 0.8819 - recall: 0.7406 - precision: 0.6909\n",
            "Epoch 264: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.5257 - accuracy: 0.6984 - sensitivity_at_specificity: 0.8615 - specificity_at_sensitivity: 0.8819 - recall: 0.7406 - precision: 0.6909 - val_loss: 0.4470 - val_accuracy: 0.7508 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8783 - val_recall: 0.6948 - val_precision: 0.7817\n",
            "Epoch 265/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5322 - accuracy: 0.7047 - sensitivity_at_specificity: 0.8507 - specificity_at_sensitivity: 0.8524 - recall: 0.7136 - precision: 0.7115\n",
            "Epoch 265: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.5322 - accuracy: 0.7047 - sensitivity_at_specificity: 0.8507 - specificity_at_sensitivity: 0.8524 - recall: 0.7136 - precision: 0.7115 - val_loss: 0.4492 - val_accuracy: 0.7664 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.8861 - val_recall: 0.7340 - val_precision: 0.7843\n",
            "Epoch 266/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5447 - accuracy: 0.6883 - sensitivity_at_specificity: 0.8604 - specificity_at_sensitivity: 0.8381 - recall: 0.7349 - precision: 0.6707\n",
            "Epoch 266: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.5447 - accuracy: 0.6883 - sensitivity_at_specificity: 0.8604 - specificity_at_sensitivity: 0.8381 - recall: 0.7349 - precision: 0.6707 - val_loss: 0.4402 - val_accuracy: 0.7555 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8821 - val_recall: 0.7143 - val_precision: 0.7810\n",
            "Epoch 267/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5494 - accuracy: 0.6836 - sensitivity_at_specificity: 0.8293 - specificity_at_sensitivity: 0.8270 - recall: 0.6601 - precision: 0.6916\n",
            "Epoch 267: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.5494 - accuracy: 0.6836 - sensitivity_at_specificity: 0.8293 - specificity_at_sensitivity: 0.8270 - recall: 0.6601 - precision: 0.6916 - val_loss: 0.4206 - val_accuracy: 0.7977 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8748 - val_recall: 0.8846 - val_precision: 0.7540\n",
            "Epoch 268/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5428 - accuracy: 0.6898 - sensitivity_at_specificity: 0.8505 - specificity_at_sensitivity: 0.8479 - recall: 0.7262 - precision: 0.6742\n",
            "Epoch 268: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.5428 - accuracy: 0.6898 - sensitivity_at_specificity: 0.8505 - specificity_at_sensitivity: 0.8479 - recall: 0.7262 - precision: 0.6742 - val_loss: 0.4371 - val_accuracy: 0.7812 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8844 - val_recall: 0.7808 - val_precision: 0.7904\n",
            "Epoch 269/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5396 - accuracy: 0.7004 - sensitivity_at_specificity: 0.8503 - specificity_at_sensitivity: 0.8432 - recall: 0.7397 - precision: 0.7001\n",
            "Epoch 269: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.5396 - accuracy: 0.7004 - sensitivity_at_specificity: 0.8503 - specificity_at_sensitivity: 0.8432 - recall: 0.7397 - precision: 0.7001 - val_loss: 0.4526 - val_accuracy: 0.7633 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8659 - val_recall: 0.7227 - val_precision: 0.7808\n",
            "Epoch 270/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5236 - accuracy: 0.7000 - sensitivity_at_specificity: 0.8530 - specificity_at_sensitivity: 0.8813 - recall: 0.7758 - precision: 0.6916\n",
            "Epoch 270: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.5236 - accuracy: 0.7000 - sensitivity_at_specificity: 0.8530 - specificity_at_sensitivity: 0.8813 - recall: 0.7758 - precision: 0.6916 - val_loss: 0.4530 - val_accuracy: 0.7516 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8954 - val_recall: 0.6556 - val_precision: 0.8035\n",
            "Epoch 271/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5263 - accuracy: 0.7109 - sensitivity_at_specificity: 0.8696 - specificity_at_sensitivity: 0.8650 - recall: 0.6423 - precision: 0.7203\n",
            "Epoch 271: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 183ms/step - loss: 0.5263 - accuracy: 0.7109 - sensitivity_at_specificity: 0.8696 - specificity_at_sensitivity: 0.8650 - recall: 0.6423 - precision: 0.7203 - val_loss: 0.4512 - val_accuracy: 0.7664 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8641 - val_recall: 0.7609 - val_precision: 0.7694\n",
            "Epoch 272/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5335 - accuracy: 0.6992 - sensitivity_at_specificity: 0.8714 - specificity_at_sensitivity: 0.8583 - recall: 0.6937 - precision: 0.7024\n",
            "Epoch 272: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.5335 - accuracy: 0.6992 - sensitivity_at_specificity: 0.8714 - specificity_at_sensitivity: 0.8583 - recall: 0.6937 - precision: 0.7024 - val_loss: 0.4451 - val_accuracy: 0.7750 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8721 - val_recall: 0.7544 - val_precision: 0.7769\n",
            "Epoch 273/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5095 - accuracy: 0.7270 - sensitivity_at_specificity: 0.9004 - specificity_at_sensitivity: 0.8972 - recall: 0.7436 - precision: 0.7241\n",
            "Epoch 273: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 191ms/step - loss: 0.5095 - accuracy: 0.7270 - sensitivity_at_specificity: 0.9004 - specificity_at_sensitivity: 0.8972 - recall: 0.7436 - precision: 0.7241 - val_loss: 0.4240 - val_accuracy: 0.7758 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8746 - val_recall: 0.8162 - val_precision: 0.7561\n",
            "Epoch 274/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5427 - accuracy: 0.6961 - sensitivity_at_specificity: 0.8361 - specificity_at_sensitivity: 0.8585 - recall: 0.7119 - precision: 0.6904\n",
            "Epoch 274: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.5427 - accuracy: 0.6961 - sensitivity_at_specificity: 0.8361 - specificity_at_sensitivity: 0.8585 - recall: 0.7119 - precision: 0.6904 - val_loss: 0.4562 - val_accuracy: 0.7617 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8495 - val_recall: 0.8037 - val_precision: 0.7424\n",
            "Epoch 275/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5256 - accuracy: 0.7023 - sensitivity_at_specificity: 0.8721 - specificity_at_sensitivity: 0.8624 - recall: 0.7045 - precision: 0.6946\n",
            "Epoch 275: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.5256 - accuracy: 0.7023 - sensitivity_at_specificity: 0.8721 - specificity_at_sensitivity: 0.8624 - recall: 0.7045 - precision: 0.6946 - val_loss: 0.4358 - val_accuracy: 0.7773 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8942 - val_recall: 0.7264 - val_precision: 0.8131\n",
            "Epoch 276/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5262 - accuracy: 0.7055 - sensitivity_at_specificity: 0.8649 - specificity_at_sensitivity: 0.8648 - recall: 0.7329 - precision: 0.6972\n",
            "Epoch 276: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.5262 - accuracy: 0.7055 - sensitivity_at_specificity: 0.8649 - specificity_at_sensitivity: 0.8648 - recall: 0.7329 - precision: 0.6972 - val_loss: 0.4298 - val_accuracy: 0.7758 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8959 - val_recall: 0.7724 - val_precision: 0.7809\n",
            "Epoch 277/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5080 - accuracy: 0.7176 - sensitivity_at_specificity: 0.8766 - specificity_at_sensitivity: 0.8951 - recall: 0.7263 - precision: 0.7089\n",
            "Epoch 277: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.5080 - accuracy: 0.7176 - sensitivity_at_specificity: 0.8766 - specificity_at_sensitivity: 0.8951 - recall: 0.7263 - precision: 0.7089 - val_loss: 0.4661 - val_accuracy: 0.7664 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8659 - val_recall: 0.7864 - val_precision: 0.7593\n",
            "Epoch 278/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5228 - accuracy: 0.7008 - sensitivity_at_specificity: 0.8721 - specificity_at_sensitivity: 0.8700 - recall: 0.7213 - precision: 0.7009\n",
            "Epoch 278: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.5228 - accuracy: 0.7008 - sensitivity_at_specificity: 0.8721 - specificity_at_sensitivity: 0.8700 - recall: 0.7213 - precision: 0.7009 - val_loss: 0.4464 - val_accuracy: 0.7922 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8672 - val_recall: 0.8400 - val_precision: 0.7598\n",
            "Epoch 279/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5148 - accuracy: 0.7195 - sensitivity_at_specificity: 0.8931 - specificity_at_sensitivity: 0.8866 - recall: 0.7010 - precision: 0.7283\n",
            "Epoch 279: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.5148 - accuracy: 0.7195 - sensitivity_at_specificity: 0.8931 - specificity_at_sensitivity: 0.8866 - recall: 0.7010 - precision: 0.7283 - val_loss: 0.4366 - val_accuracy: 0.7820 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8871 - val_recall: 0.8191 - val_precision: 0.7762\n",
            "Epoch 280/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5196 - accuracy: 0.7078 - sensitivity_at_specificity: 0.8721 - specificity_at_sensitivity: 0.8826 - recall: 0.7049 - precision: 0.7071\n",
            "Epoch 280: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.5196 - accuracy: 0.7078 - sensitivity_at_specificity: 0.8721 - specificity_at_sensitivity: 0.8826 - recall: 0.7049 - precision: 0.7071 - val_loss: 0.4348 - val_accuracy: 0.7789 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8877 - val_recall: 0.8091 - val_precision: 0.7625\n",
            "Epoch 281/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5035 - accuracy: 0.7242 - sensitivity_at_specificity: 0.8896 - specificity_at_sensitivity: 0.8964 - recall: 0.7475 - precision: 0.7186\n",
            "Epoch 281: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.5035 - accuracy: 0.7242 - sensitivity_at_specificity: 0.8896 - specificity_at_sensitivity: 0.8964 - recall: 0.7475 - precision: 0.7186 - val_loss: 0.4435 - val_accuracy: 0.7758 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8744 - val_recall: 0.7745 - val_precision: 0.7781\n",
            "Epoch 282/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5106 - accuracy: 0.7211 - sensitivity_at_specificity: 0.8900 - specificity_at_sensitivity: 0.8714 - recall: 0.7018 - precision: 0.7213\n",
            "Epoch 282: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.5106 - accuracy: 0.7211 - sensitivity_at_specificity: 0.8900 - specificity_at_sensitivity: 0.8714 - recall: 0.7018 - precision: 0.7213 - val_loss: 0.4681 - val_accuracy: 0.7359 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8817 - val_recall: 0.6471 - val_precision: 0.7917\n",
            "Epoch 283/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5301 - accuracy: 0.7043 - sensitivity_at_specificity: 0.8726 - specificity_at_sensitivity: 0.8626 - recall: 0.7030 - precision: 0.6982\n",
            "Epoch 283: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.5301 - accuracy: 0.7043 - sensitivity_at_specificity: 0.8726 - specificity_at_sensitivity: 0.8626 - recall: 0.7030 - precision: 0.6982 - val_loss: 0.4456 - val_accuracy: 0.7594 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8854 - val_recall: 0.7061 - val_precision: 0.7923\n",
            "Epoch 284/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5151 - accuracy: 0.7188 - sensitivity_at_specificity: 0.8755 - specificity_at_sensitivity: 0.8959 - recall: 0.6840 - precision: 0.7257\n",
            "Epoch 284: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.5151 - accuracy: 0.7188 - sensitivity_at_specificity: 0.8755 - specificity_at_sensitivity: 0.8959 - recall: 0.6840 - precision: 0.7257 - val_loss: 0.4688 - val_accuracy: 0.7539 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8617 - val_recall: 0.7219 - val_precision: 0.7825\n",
            "Epoch 285/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5167 - accuracy: 0.7342 - sensitivity_at_specificity: 0.8839 - specificity_at_sensitivity: 0.8787 - recall: 0.7054 - precision: 0.7368\n",
            "Epoch 285: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.5167 - accuracy: 0.7342 - sensitivity_at_specificity: 0.8839 - specificity_at_sensitivity: 0.8787 - recall: 0.7054 - precision: 0.7368 - val_loss: 0.4485 - val_accuracy: 0.7453 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8834 - val_recall: 0.6651 - val_precision: 0.8026\n",
            "Epoch 286/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5213 - accuracy: 0.7129 - sensitivity_at_specificity: 0.8706 - specificity_at_sensitivity: 0.8765 - recall: 0.7038 - precision: 0.7352\n",
            "Epoch 286: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.5213 - accuracy: 0.7129 - sensitivity_at_specificity: 0.8706 - specificity_at_sensitivity: 0.8765 - recall: 0.7038 - precision: 0.7352 - val_loss: 0.4208 - val_accuracy: 0.7859 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8962 - val_recall: 0.8073 - val_precision: 0.7811\n",
            "Epoch 287/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5128 - accuracy: 0.7188 - sensitivity_at_specificity: 0.8755 - specificity_at_sensitivity: 0.8939 - recall: 0.7636 - precision: 0.6976\n",
            "Epoch 287: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.5128 - accuracy: 0.7188 - sensitivity_at_specificity: 0.8755 - specificity_at_sensitivity: 0.8939 - recall: 0.7636 - precision: 0.6976 - val_loss: 0.4683 - val_accuracy: 0.7633 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8669 - val_recall: 0.7982 - val_precision: 0.7507\n",
            "Epoch 288/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5134 - accuracy: 0.7184 - sensitivity_at_specificity: 0.8702 - specificity_at_sensitivity: 0.8947 - recall: 0.6797 - precision: 0.7360\n",
            "Epoch 288: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.5134 - accuracy: 0.7184 - sensitivity_at_specificity: 0.8702 - specificity_at_sensitivity: 0.8947 - recall: 0.6797 - precision: 0.7360 - val_loss: 0.4487 - val_accuracy: 0.7883 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8457 - val_recall: 0.8419 - val_precision: 0.7684\n",
            "Epoch 289/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5135 - accuracy: 0.7176 - sensitivity_at_specificity: 0.8753 - specificity_at_sensitivity: 0.8916 - recall: 0.6767 - precision: 0.7295\n",
            "Epoch 289: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.5135 - accuracy: 0.7176 - sensitivity_at_specificity: 0.8753 - specificity_at_sensitivity: 0.8916 - recall: 0.6767 - precision: 0.7295 - val_loss: 0.4223 - val_accuracy: 0.7922 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8920 - val_recall: 0.8146 - val_precision: 0.7933\n",
            "Epoch 290/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5207 - accuracy: 0.7078 - sensitivity_at_specificity: 0.8769 - specificity_at_sensitivity: 0.8763 - recall: 0.7537 - precision: 0.6866\n",
            "Epoch 290: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.5207 - accuracy: 0.7078 - sensitivity_at_specificity: 0.8769 - specificity_at_sensitivity: 0.8763 - recall: 0.7537 - precision: 0.6866 - val_loss: 0.4572 - val_accuracy: 0.7461 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8628 - val_recall: 0.7229 - val_precision: 0.7618\n",
            "Epoch 291/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4824 - accuracy: 0.7457 - sensitivity_at_specificity: 0.9202 - specificity_at_sensitivity: 0.9166 - recall: 0.7015 - precision: 0.7604\n",
            "Epoch 291: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.4824 - accuracy: 0.7457 - sensitivity_at_specificity: 0.9202 - specificity_at_sensitivity: 0.9166 - recall: 0.7015 - precision: 0.7604 - val_loss: 0.4424 - val_accuracy: 0.7953 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8703 - val_recall: 0.8422 - val_precision: 0.7700\n",
            "Epoch 292/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5038 - accuracy: 0.7332 - sensitivity_at_specificity: 0.8784 - specificity_at_sensitivity: 0.9029 - recall: 0.7644 - precision: 0.7317\n",
            "Epoch 292: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.5038 - accuracy: 0.7332 - sensitivity_at_specificity: 0.8784 - specificity_at_sensitivity: 0.9029 - recall: 0.7644 - precision: 0.7317 - val_loss: 0.4389 - val_accuracy: 0.7930 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8634 - val_recall: 0.8351 - val_precision: 0.7716\n",
            "Epoch 293/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5053 - accuracy: 0.7129 - sensitivity_at_specificity: 0.8711 - specificity_at_sensitivity: 0.8958 - recall: 0.7352 - precision: 0.6992\n",
            "Epoch 293: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.5053 - accuracy: 0.7129 - sensitivity_at_specificity: 0.8711 - specificity_at_sensitivity: 0.8958 - recall: 0.7352 - precision: 0.6992 - val_loss: 0.4472 - val_accuracy: 0.7602 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8770 - val_recall: 0.7508 - val_precision: 0.7732\n",
            "Epoch 294/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5013 - accuracy: 0.7328 - sensitivity_at_specificity: 0.8938 - specificity_at_sensitivity: 0.9000 - recall: 0.7185 - precision: 0.7460\n",
            "Epoch 294: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.5013 - accuracy: 0.7328 - sensitivity_at_specificity: 0.8938 - specificity_at_sensitivity: 0.9000 - recall: 0.7185 - precision: 0.7460 - val_loss: 0.4438 - val_accuracy: 0.7563 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8965 - val_recall: 0.7159 - val_precision: 0.7676\n",
            "Epoch 295/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4943 - accuracy: 0.7180 - sensitivity_at_specificity: 0.8819 - specificity_at_sensitivity: 0.9230 - recall: 0.7144 - precision: 0.7300\n",
            "Epoch 295: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.4943 - accuracy: 0.7180 - sensitivity_at_specificity: 0.8819 - specificity_at_sensitivity: 0.9230 - recall: 0.7144 - precision: 0.7300 - val_loss: 0.4417 - val_accuracy: 0.7695 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 0.8901 - val_recall: 0.7126 - val_precision: 0.8177\n",
            "Epoch 296/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4989 - accuracy: 0.7414 - sensitivity_at_specificity: 0.8911 - specificity_at_sensitivity: 0.9075 - recall: 0.7409 - precision: 0.7432\n",
            "Epoch 296: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.4989 - accuracy: 0.7414 - sensitivity_at_specificity: 0.8911 - specificity_at_sensitivity: 0.9075 - recall: 0.7409 - precision: 0.7432 - val_loss: 0.4815 - val_accuracy: 0.7477 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8583 - val_recall: 0.7299 - val_precision: 0.7684\n",
            "Epoch 297/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4951 - accuracy: 0.7453 - sensitivity_at_specificity: 0.8948 - specificity_at_sensitivity: 0.9090 - recall: 0.7097 - precision: 0.7589\n",
            "Epoch 297: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.4951 - accuracy: 0.7453 - sensitivity_at_specificity: 0.8948 - specificity_at_sensitivity: 0.9090 - recall: 0.7097 - precision: 0.7589 - val_loss: 0.4492 - val_accuracy: 0.7703 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8611 - val_recall: 0.8718 - val_precision: 0.7212\n",
            "Epoch 298/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4998 - accuracy: 0.7238 - sensitivity_at_specificity: 0.8929 - specificity_at_sensitivity: 0.9002 - recall: 0.7321 - precision: 0.7226\n",
            "Epoch 298: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.4998 - accuracy: 0.7238 - sensitivity_at_specificity: 0.8929 - specificity_at_sensitivity: 0.9002 - recall: 0.7321 - precision: 0.7226 - val_loss: 0.4881 - val_accuracy: 0.7703 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8752 - val_recall: 0.7541 - val_precision: 0.7924\n",
            "Epoch 299/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5018 - accuracy: 0.7336 - sensitivity_at_specificity: 0.8940 - specificity_at_sensitivity: 0.9126 - recall: 0.7195 - precision: 0.7324\n",
            "Epoch 299: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.5018 - accuracy: 0.7336 - sensitivity_at_specificity: 0.8940 - specificity_at_sensitivity: 0.9126 - recall: 0.7195 - precision: 0.7324 - val_loss: 0.4448 - val_accuracy: 0.7641 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8671 - val_recall: 0.7457 - val_precision: 0.7700\n",
            "Epoch 300/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4952 - accuracy: 0.7324 - sensitivity_at_specificity: 0.8944 - specificity_at_sensitivity: 0.9009 - recall: 0.7019 - precision: 0.7469\n",
            "Epoch 300: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.4952 - accuracy: 0.7324 - sensitivity_at_specificity: 0.8944 - specificity_at_sensitivity: 0.9009 - recall: 0.7019 - precision: 0.7469 - val_loss: 0.4585 - val_accuracy: 0.7641 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8691 - val_recall: 0.7879 - val_precision: 0.7552\n",
            "Epoch 301/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4899 - accuracy: 0.7445 - sensitivity_at_specificity: 0.8893 - specificity_at_sensitivity: 0.9320 - recall: 0.7439 - precision: 0.7404\n",
            "Epoch 301: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.4899 - accuracy: 0.7445 - sensitivity_at_specificity: 0.8893 - specificity_at_sensitivity: 0.9320 - recall: 0.7439 - precision: 0.7404 - val_loss: 0.4310 - val_accuracy: 0.7688 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8795 - val_recall: 0.7722 - val_precision: 0.7674\n",
            "Epoch 302/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4996 - accuracy: 0.7359 - sensitivity_at_specificity: 0.8896 - specificity_at_sensitivity: 0.9037 - recall: 0.7239 - precision: 0.7492\n",
            "Epoch 302: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.4996 - accuracy: 0.7359 - sensitivity_at_specificity: 0.8896 - specificity_at_sensitivity: 0.9037 - recall: 0.7239 - precision: 0.7492 - val_loss: 0.4715 - val_accuracy: 0.7437 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8721 - val_recall: 0.6830 - val_precision: 0.7710\n",
            "Epoch 303/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4849 - accuracy: 0.7409 - sensitivity_at_specificity: 0.9032 - specificity_at_sensitivity: 0.9180 - recall: 0.7321 - precision: 0.7469\n",
            "Epoch 303: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 176ms/step - loss: 0.4860 - accuracy: 0.7388 - sensitivity_at_specificity: 0.9046 - specificity_at_sensitivity: 0.9185 - recall: 0.7289 - precision: 0.7443 - val_loss: 0.4588 - val_accuracy: 0.7719 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8607 - val_recall: 0.7956 - val_precision: 0.7601\n",
            "Epoch 304/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4866 - accuracy: 0.7457 - sensitivity_at_specificity: 0.9026 - specificity_at_sensitivity: 0.9138 - recall: 0.7313 - precision: 0.7542\n",
            "Epoch 304: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.4866 - accuracy: 0.7457 - sensitivity_at_specificity: 0.9026 - specificity_at_sensitivity: 0.9138 - recall: 0.7313 - precision: 0.7542 - val_loss: 0.4604 - val_accuracy: 0.7617 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8608 - val_recall: 0.7835 - val_precision: 0.7393\n",
            "Epoch 305/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4872 - accuracy: 0.7317 - sensitivity_at_specificity: 0.9168 - specificity_at_sensitivity: 0.9138 - recall: 0.7421 - precision: 0.7264\n",
            "Epoch 305: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.4872 - accuracy: 0.7317 - sensitivity_at_specificity: 0.9168 - specificity_at_sensitivity: 0.9138 - recall: 0.7421 - precision: 0.7264 - val_loss: 0.4160 - val_accuracy: 0.7914 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8892 - val_recall: 0.8364 - val_precision: 0.7710\n",
            "Epoch 306/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5012 - accuracy: 0.7219 - sensitivity_at_specificity: 0.8899 - specificity_at_sensitivity: 0.9044 - recall: 0.7210 - precision: 0.7365\n",
            "Epoch 306: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.5012 - accuracy: 0.7219 - sensitivity_at_specificity: 0.8899 - specificity_at_sensitivity: 0.9044 - recall: 0.7210 - precision: 0.7365 - val_loss: 0.4805 - val_accuracy: 0.7656 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8658 - val_recall: 0.8655 - val_precision: 0.7111\n",
            "Epoch 307/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4898 - accuracy: 0.7391 - sensitivity_at_specificity: 0.9128 - specificity_at_sensitivity: 0.9238 - recall: 0.7700 - precision: 0.7198\n",
            "Epoch 307: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.4898 - accuracy: 0.7391 - sensitivity_at_specificity: 0.9128 - specificity_at_sensitivity: 0.9238 - recall: 0.7700 - precision: 0.7198 - val_loss: 0.4517 - val_accuracy: 0.7703 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8798 - val_recall: 0.7424 - val_precision: 0.7958\n",
            "Epoch 308/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4891 - accuracy: 0.7441 - sensitivity_at_specificity: 0.8863 - specificity_at_sensitivity: 0.9152 - recall: 0.7247 - precision: 0.7524\n",
            "Epoch 308: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.4891 - accuracy: 0.7441 - sensitivity_at_specificity: 0.8863 - specificity_at_sensitivity: 0.9152 - recall: 0.7247 - precision: 0.7524 - val_loss: 0.4501 - val_accuracy: 0.7656 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8766 - val_recall: 0.7688 - val_precision: 0.7640\n",
            "Epoch 309/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4788 - accuracy: 0.7457 - sensitivity_at_specificity: 0.9113 - specificity_at_sensitivity: 0.9210 - recall: 0.6940 - precision: 0.7480\n",
            "Epoch 309: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.4788 - accuracy: 0.7457 - sensitivity_at_specificity: 0.9113 - specificity_at_sensitivity: 0.9210 - recall: 0.6940 - precision: 0.7480 - val_loss: 0.4720 - val_accuracy: 0.7523 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8438 - val_recall: 0.7570 - val_precision: 0.7535\n",
            "Epoch 310/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4903 - accuracy: 0.7402 - sensitivity_at_specificity: 0.8966 - specificity_at_sensitivity: 0.9142 - recall: 0.7167 - precision: 0.7479\n",
            "Epoch 310: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.4903 - accuracy: 0.7402 - sensitivity_at_specificity: 0.8966 - specificity_at_sensitivity: 0.9142 - recall: 0.7167 - precision: 0.7479 - val_loss: 0.4669 - val_accuracy: 0.7781 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8669 - val_recall: 0.8398 - val_precision: 0.7517\n",
            "Epoch 311/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4840 - accuracy: 0.7410 - sensitivity_at_specificity: 0.9176 - specificity_at_sensitivity: 0.9176 - recall: 0.7573 - precision: 0.7420\n",
            "Epoch 311: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.4840 - accuracy: 0.7410 - sensitivity_at_specificity: 0.9176 - specificity_at_sensitivity: 0.9176 - recall: 0.7573 - precision: 0.7420 - val_loss: 0.4508 - val_accuracy: 0.7711 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8610 - val_recall: 0.7666 - val_precision: 0.7774\n",
            "Epoch 312/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4861 - accuracy: 0.7437 - sensitivity_at_specificity: 0.8973 - specificity_at_sensitivity: 0.9138 - recall: 0.7274 - precision: 0.7566\n",
            "Epoch 312: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.4861 - accuracy: 0.7437 - sensitivity_at_specificity: 0.8973 - specificity_at_sensitivity: 0.9138 - recall: 0.7274 - precision: 0.7566 - val_loss: 0.4358 - val_accuracy: 0.7641 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8820 - val_recall: 0.7657 - val_precision: 0.7609\n",
            "Epoch 313/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4800 - accuracy: 0.7531 - sensitivity_at_specificity: 0.9173 - specificity_at_sensitivity: 0.9284 - recall: 0.7348 - precision: 0.7481\n",
            "Epoch 313: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.4800 - accuracy: 0.7531 - sensitivity_at_specificity: 0.9173 - specificity_at_sensitivity: 0.9284 - recall: 0.7348 - precision: 0.7481 - val_loss: 0.4696 - val_accuracy: 0.7602 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 0.8576 - val_recall: 0.7299 - val_precision: 0.7818\n",
            "Epoch 314/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4796 - accuracy: 0.7465 - sensitivity_at_specificity: 0.8978 - specificity_at_sensitivity: 0.9247 - recall: 0.7209 - precision: 0.7572\n",
            "Epoch 314: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.4796 - accuracy: 0.7465 - sensitivity_at_specificity: 0.8978 - specificity_at_sensitivity: 0.9247 - recall: 0.7209 - precision: 0.7572 - val_loss: 0.4491 - val_accuracy: 0.7836 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8805 - val_recall: 0.8045 - val_precision: 0.7615\n",
            "Epoch 315/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4783 - accuracy: 0.7465 - sensitivity_at_specificity: 0.9065 - specificity_at_sensitivity: 0.9327 - recall: 0.7069 - precision: 0.7584\n",
            "Epoch 315: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.4783 - accuracy: 0.7465 - sensitivity_at_specificity: 0.9065 - specificity_at_sensitivity: 0.9327 - recall: 0.7069 - precision: 0.7584 - val_loss: 0.4754 - val_accuracy: 0.7641 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8612 - val_recall: 0.8204 - val_precision: 0.7402\n",
            "Epoch 316/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4850 - accuracy: 0.7473 - sensitivity_at_specificity: 0.8903 - specificity_at_sensitivity: 0.9273 - recall: 0.7008 - precision: 0.7590\n",
            "Epoch 316: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.4850 - accuracy: 0.7473 - sensitivity_at_specificity: 0.8903 - specificity_at_sensitivity: 0.9273 - recall: 0.7008 - precision: 0.7590 - val_loss: 0.4489 - val_accuracy: 0.7734 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8650 - val_recall: 0.8030 - val_precision: 0.7706\n",
            "Epoch 317/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4745 - accuracy: 0.7523 - sensitivity_at_specificity: 0.9308 - specificity_at_sensitivity: 0.9174 - recall: 0.7573 - precision: 0.7346\n",
            "Epoch 317: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.4745 - accuracy: 0.7523 - sensitivity_at_specificity: 0.9308 - specificity_at_sensitivity: 0.9174 - recall: 0.7573 - precision: 0.7346 - val_loss: 0.4580 - val_accuracy: 0.7563 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8724 - val_recall: 0.7307 - val_precision: 0.7828\n",
            "Epoch 318/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4801 - accuracy: 0.7461 - sensitivity_at_specificity: 0.9193 - specificity_at_sensitivity: 0.9174 - recall: 0.7207 - precision: 0.7621\n",
            "Epoch 318: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.4801 - accuracy: 0.7461 - sensitivity_at_specificity: 0.9193 - specificity_at_sensitivity: 0.9174 - recall: 0.7207 - precision: 0.7621 - val_loss: 0.4657 - val_accuracy: 0.7570 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8589 - val_recall: 0.7671 - val_precision: 0.7371\n",
            "Epoch 319/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4642 - accuracy: 0.7598 - sensitivity_at_specificity: 0.9262 - specificity_at_sensitivity: 0.9261 - recall: 0.7741 - precision: 0.7620\n",
            "Epoch 319: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.4642 - accuracy: 0.7598 - sensitivity_at_specificity: 0.9262 - specificity_at_sensitivity: 0.9261 - recall: 0.7741 - precision: 0.7620 - val_loss: 0.4615 - val_accuracy: 0.7633 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8688 - val_recall: 0.7650 - val_precision: 0.7492\n",
            "Epoch 320/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4670 - accuracy: 0.7551 - sensitivity_at_specificity: 0.9185 - specificity_at_sensitivity: 0.9329 - recall: 0.7601 - precision: 0.7687\n",
            "Epoch 320: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.4670 - accuracy: 0.7551 - sensitivity_at_specificity: 0.9185 - specificity_at_sensitivity: 0.9329 - recall: 0.7601 - precision: 0.7687 - val_loss: 0.4510 - val_accuracy: 0.7758 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8305 - val_recall: 0.8399 - val_precision: 0.7431\n",
            "Epoch 321/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4545 - accuracy: 0.7676 - sensitivity_at_specificity: 0.9290 - specificity_at_sensitivity: 0.9491 - recall: 0.7535 - precision: 0.7759\n",
            "Epoch 321: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.4545 - accuracy: 0.7676 - sensitivity_at_specificity: 0.9290 - specificity_at_sensitivity: 0.9491 - recall: 0.7535 - precision: 0.7759 - val_loss: 0.4236 - val_accuracy: 0.7930 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8822 - val_recall: 0.7953 - val_precision: 0.7891\n",
            "Epoch 322/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4567 - accuracy: 0.7492 - sensitivity_at_specificity: 0.9264 - specificity_at_sensitivity: 0.9496 - recall: 0.7581 - precision: 0.7592\n",
            "Epoch 322: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.4567 - accuracy: 0.7492 - sensitivity_at_specificity: 0.9264 - specificity_at_sensitivity: 0.9496 - recall: 0.7581 - precision: 0.7592 - val_loss: 0.5210 - val_accuracy: 0.7430 - val_sensitivity_at_specificity: 0.9969 - val_specificity_at_sensitivity: 0.8419 - val_recall: 0.7508 - val_precision: 0.7473\n",
            "Epoch 323/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4650 - accuracy: 0.7574 - sensitivity_at_specificity: 0.9228 - specificity_at_sensitivity: 0.9429 - recall: 0.7325 - precision: 0.7552\n",
            "Epoch 323: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.4650 - accuracy: 0.7574 - sensitivity_at_specificity: 0.9228 - specificity_at_sensitivity: 0.9429 - recall: 0.7325 - precision: 0.7552 - val_loss: 0.4820 - val_accuracy: 0.7703 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8533 - val_recall: 0.7841 - val_precision: 0.7699\n",
            "Epoch 324/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4644 - accuracy: 0.7492 - sensitivity_at_specificity: 0.9096 - specificity_at_sensitivity: 0.9530 - recall: 0.7090 - precision: 0.7648\n",
            "Epoch 324: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.4644 - accuracy: 0.7492 - sensitivity_at_specificity: 0.9096 - specificity_at_sensitivity: 0.9530 - recall: 0.7090 - precision: 0.7648 - val_loss: 0.4812 - val_accuracy: 0.7734 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8395 - val_recall: 0.8069 - val_precision: 0.7676\n",
            "Epoch 325/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4627 - accuracy: 0.7570 - sensitivity_at_specificity: 0.9186 - specificity_at_sensitivity: 0.9509 - recall: 0.7655 - precision: 0.7689\n",
            "Epoch 325: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 183ms/step - loss: 0.4627 - accuracy: 0.7570 - sensitivity_at_specificity: 0.9186 - specificity_at_sensitivity: 0.9509 - recall: 0.7655 - precision: 0.7689 - val_loss: 0.4178 - val_accuracy: 0.7797 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9019 - val_recall: 0.8040 - val_precision: 0.7757\n",
            "Epoch 326/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4571 - accuracy: 0.7656 - sensitivity_at_specificity: 0.9231 - specificity_at_sensitivity: 0.9442 - recall: 0.7430 - precision: 0.7806\n",
            "Epoch 326: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.4571 - accuracy: 0.7656 - sensitivity_at_specificity: 0.9231 - specificity_at_sensitivity: 0.9442 - recall: 0.7430 - precision: 0.7806 - val_loss: 0.4849 - val_accuracy: 0.7641 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8584 - val_recall: 0.8234 - val_precision: 0.7277\n",
            "Epoch 327/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4655 - accuracy: 0.7574 - sensitivity_at_specificity: 0.9247 - specificity_at_sensitivity: 0.9269 - recall: 0.7465 - precision: 0.7696\n",
            "Epoch 327: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.4655 - accuracy: 0.7574 - sensitivity_at_specificity: 0.9247 - specificity_at_sensitivity: 0.9269 - recall: 0.7465 - precision: 0.7696 - val_loss: 0.4300 - val_accuracy: 0.8031 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8862 - val_recall: 0.8872 - val_precision: 0.7658\n",
            "Epoch 328/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4565 - accuracy: 0.7703 - sensitivity_at_specificity: 0.9329 - specificity_at_sensitivity: 0.9413 - recall: 0.7730 - precision: 0.7694\n",
            "Epoch 328: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.4565 - accuracy: 0.7703 - sensitivity_at_specificity: 0.9329 - specificity_at_sensitivity: 0.9413 - recall: 0.7730 - precision: 0.7694 - val_loss: 0.4718 - val_accuracy: 0.7633 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8591 - val_recall: 0.7618 - val_precision: 0.7606\n",
            "Epoch 329/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4682 - accuracy: 0.7492 - sensitivity_at_specificity: 0.9211 - specificity_at_sensitivity: 0.9319 - recall: 0.7326 - precision: 0.7541\n",
            "Epoch 329: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.4682 - accuracy: 0.7492 - sensitivity_at_specificity: 0.9211 - specificity_at_sensitivity: 0.9319 - recall: 0.7326 - precision: 0.7541 - val_loss: 0.4672 - val_accuracy: 0.7766 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8674 - val_recall: 0.7952 - val_precision: 0.7812\n",
            "Epoch 330/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4557 - accuracy: 0.7688 - sensitivity_at_specificity: 0.9234 - specificity_at_sensitivity: 0.9377 - recall: 0.7624 - precision: 0.7756\n",
            "Epoch 330: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.4557 - accuracy: 0.7688 - sensitivity_at_specificity: 0.9234 - specificity_at_sensitivity: 0.9377 - recall: 0.7624 - precision: 0.7756 - val_loss: 0.4596 - val_accuracy: 0.7805 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8621 - val_recall: 0.7876 - val_precision: 0.7958\n",
            "Epoch 331/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4509 - accuracy: 0.7691 - sensitivity_at_specificity: 0.9178 - specificity_at_sensitivity: 0.9523 - recall: 0.7548 - precision: 0.7831\n",
            "Epoch 331: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.4509 - accuracy: 0.7691 - sensitivity_at_specificity: 0.9178 - specificity_at_sensitivity: 0.9523 - recall: 0.7548 - precision: 0.7831 - val_loss: 0.4387 - val_accuracy: 0.8023 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8718 - val_recall: 0.8735 - val_precision: 0.7744\n",
            "Epoch 332/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4656 - accuracy: 0.7535 - sensitivity_at_specificity: 0.9239 - specificity_at_sensitivity: 0.9387 - recall: 0.7319 - precision: 0.7671\n",
            "Epoch 332: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 0.4656 - accuracy: 0.7535 - sensitivity_at_specificity: 0.9239 - specificity_at_sensitivity: 0.9387 - recall: 0.7319 - precision: 0.7671 - val_loss: 0.4688 - val_accuracy: 0.7688 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8430 - val_recall: 0.8216 - val_precision: 0.7286\n",
            "Epoch 333/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4537 - accuracy: 0.7664 - sensitivity_at_specificity: 0.9248 - specificity_at_sensitivity: 0.9502 - recall: 0.7578 - precision: 0.7699\n",
            "Epoch 333: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.4537 - accuracy: 0.7664 - sensitivity_at_specificity: 0.9248 - specificity_at_sensitivity: 0.9502 - recall: 0.7578 - precision: 0.7699 - val_loss: 0.5182 - val_accuracy: 0.7289 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8274 - val_recall: 0.7174 - val_precision: 0.7324\n",
            "Epoch 334/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4577 - accuracy: 0.7664 - sensitivity_at_specificity: 0.9237 - specificity_at_sensitivity: 0.9454 - recall: 0.7533 - precision: 0.7785\n",
            "Epoch 334: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.4577 - accuracy: 0.7664 - sensitivity_at_specificity: 0.9237 - specificity_at_sensitivity: 0.9454 - recall: 0.7533 - precision: 0.7785 - val_loss: 0.4787 - val_accuracy: 0.7734 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8517 - val_recall: 0.7786 - val_precision: 0.7738\n",
            "Epoch 335/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4418 - accuracy: 0.7691 - sensitivity_at_specificity: 0.9326 - specificity_at_sensitivity: 0.9591 - recall: 0.7500 - precision: 0.7606\n",
            "Epoch 335: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.4418 - accuracy: 0.7691 - sensitivity_at_specificity: 0.9326 - specificity_at_sensitivity: 0.9591 - recall: 0.7500 - precision: 0.7606 - val_loss: 0.5253 - val_accuracy: 0.7437 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8562 - val_recall: 0.7156 - val_precision: 0.7583\n",
            "Epoch 336/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4658 - accuracy: 0.7530 - sensitivity_at_specificity: 0.9077 - specificity_at_sensitivity: 0.9426 - recall: 0.7089 - precision: 0.7720\n",
            "Epoch 336: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.4626 - accuracy: 0.7554 - sensitivity_at_specificity: 0.9096 - specificity_at_sensitivity: 0.9420 - recall: 0.7117 - precision: 0.7725 - val_loss: 0.4756 - val_accuracy: 0.7578 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.8578 - val_recall: 0.7883 - val_precision: 0.7393\n",
            "Epoch 337/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4659 - accuracy: 0.7547 - sensitivity_at_specificity: 0.9139 - specificity_at_sensitivity: 0.9363 - recall: 0.7308 - precision: 0.7702\n",
            "Epoch 337: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.4659 - accuracy: 0.7547 - sensitivity_at_specificity: 0.9139 - specificity_at_sensitivity: 0.9363 - recall: 0.7308 - precision: 0.7702 - val_loss: 0.4779 - val_accuracy: 0.7867 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8608 - val_recall: 0.8457 - val_precision: 0.7601\n",
            "Epoch 338/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4598 - accuracy: 0.7617 - sensitivity_at_specificity: 0.9301 - specificity_at_sensitivity: 0.9430 - recall: 0.7018 - precision: 0.7851\n",
            "Epoch 338: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.4598 - accuracy: 0.7617 - sensitivity_at_specificity: 0.9301 - specificity_at_sensitivity: 0.9430 - recall: 0.7018 - precision: 0.7851 - val_loss: 0.5419 - val_accuracy: 0.7719 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8384 - val_recall: 0.8414 - val_precision: 0.7283\n",
            "Epoch 339/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4575 - accuracy: 0.7684 - sensitivity_at_specificity: 0.9243 - specificity_at_sensitivity: 0.9464 - recall: 0.7602 - precision: 0.7657\n",
            "Epoch 339: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.4575 - accuracy: 0.7684 - sensitivity_at_specificity: 0.9243 - specificity_at_sensitivity: 0.9464 - recall: 0.7602 - precision: 0.7657 - val_loss: 0.4779 - val_accuracy: 0.7711 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8475 - val_recall: 0.8225 - val_precision: 0.7414\n",
            "Epoch 340/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4378 - accuracy: 0.7793 - sensitivity_at_specificity: 0.9373 - specificity_at_sensitivity: 0.9536 - recall: 0.7446 - precision: 0.7896\n",
            "Epoch 340: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.4378 - accuracy: 0.7793 - sensitivity_at_specificity: 0.9373 - specificity_at_sensitivity: 0.9536 - recall: 0.7446 - precision: 0.7896 - val_loss: 0.5098 - val_accuracy: 0.7664 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8545 - val_recall: 0.7776 - val_precision: 0.7573\n",
            "Epoch 341/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4461 - accuracy: 0.7719 - sensitivity_at_specificity: 0.9377 - specificity_at_sensitivity: 0.9505 - recall: 0.7849 - precision: 0.7825\n",
            "Epoch 341: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.4461 - accuracy: 0.7719 - sensitivity_at_specificity: 0.9377 - specificity_at_sensitivity: 0.9505 - recall: 0.7849 - precision: 0.7825 - val_loss: 0.5006 - val_accuracy: 0.7703 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8477 - val_recall: 0.8103 - val_precision: 0.7518\n",
            "Epoch 342/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4394 - accuracy: 0.7762 - sensitivity_at_specificity: 0.9442 - specificity_at_sensitivity: 0.9568 - recall: 0.7448 - precision: 0.8031\n",
            "Epoch 342: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.4394 - accuracy: 0.7762 - sensitivity_at_specificity: 0.9442 - specificity_at_sensitivity: 0.9568 - recall: 0.7448 - precision: 0.8031 - val_loss: 0.4724 - val_accuracy: 0.7711 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8676 - val_recall: 0.8363 - val_precision: 0.7317\n",
            "Epoch 343/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4217 - accuracy: 0.7898 - sensitivity_at_specificity: 0.9373 - specificity_at_sensitivity: 0.9603 - recall: 0.7955 - precision: 0.7856\n",
            "Epoch 343: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.4217 - accuracy: 0.7898 - sensitivity_at_specificity: 0.9373 - specificity_at_sensitivity: 0.9603 - recall: 0.7955 - precision: 0.7856 - val_loss: 0.4581 - val_accuracy: 0.7719 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 0.8627 - val_recall: 0.7655 - val_precision: 0.7869\n",
            "Epoch 344/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4562 - accuracy: 0.7586 - sensitivity_at_specificity: 0.9234 - specificity_at_sensitivity: 0.9551 - recall: 0.7332 - precision: 0.7684\n",
            "Epoch 344: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.4562 - accuracy: 0.7586 - sensitivity_at_specificity: 0.9234 - specificity_at_sensitivity: 0.9551 - recall: 0.7332 - precision: 0.7684 - val_loss: 0.5028 - val_accuracy: 0.7734 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8394 - val_recall: 0.8248 - val_precision: 0.7504\n",
            "Epoch 345/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4455 - accuracy: 0.7773 - sensitivity_at_specificity: 0.9284 - specificity_at_sensitivity: 0.9540 - recall: 0.7542 - precision: 0.7841\n",
            "Epoch 345: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.4455 - accuracy: 0.7773 - sensitivity_at_specificity: 0.9284 - specificity_at_sensitivity: 0.9540 - recall: 0.7542 - precision: 0.7841 - val_loss: 0.4907 - val_accuracy: 0.7352 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8391 - val_recall: 0.7125 - val_precision: 0.7463\n",
            "Epoch 346/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4661 - accuracy: 0.7578 - sensitivity_at_specificity: 0.9080 - specificity_at_sensitivity: 0.9315 - recall: 0.7177 - precision: 0.7742\n",
            "Epoch 346: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 184ms/step - loss: 0.4661 - accuracy: 0.7578 - sensitivity_at_specificity: 0.9080 - specificity_at_sensitivity: 0.9315 - recall: 0.7177 - precision: 0.7742 - val_loss: 0.4780 - val_accuracy: 0.7594 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8543 - val_recall: 0.7341 - val_precision: 0.7658\n",
            "Epoch 347/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4367 - accuracy: 0.7750 - sensitivity_at_specificity: 0.9428 - specificity_at_sensitivity: 0.9525 - recall: 0.7408 - precision: 0.7943\n",
            "Epoch 347: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.4367 - accuracy: 0.7750 - sensitivity_at_specificity: 0.9428 - specificity_at_sensitivity: 0.9525 - recall: 0.7408 - precision: 0.7943 - val_loss: 0.4391 - val_accuracy: 0.7828 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8698 - val_recall: 0.7811 - val_precision: 0.7811\n",
            "Epoch 348/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4397 - accuracy: 0.7676 - sensitivity_at_specificity: 0.9348 - specificity_at_sensitivity: 0.9517 - recall: 0.7454 - precision: 0.7731\n",
            "Epoch 348: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.4397 - accuracy: 0.7676 - sensitivity_at_specificity: 0.9348 - specificity_at_sensitivity: 0.9517 - recall: 0.7454 - precision: 0.7731 - val_loss: 0.4693 - val_accuracy: 0.7727 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.8793 - val_recall: 0.7997 - val_precision: 0.7556\n",
            "Epoch 349/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4278 - accuracy: 0.7812 - sensitivity_at_specificity: 0.9428 - specificity_at_sensitivity: 0.9626 - recall: 0.7531 - precision: 0.7968\n",
            "Epoch 349: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.4278 - accuracy: 0.7812 - sensitivity_at_specificity: 0.9428 - specificity_at_sensitivity: 0.9626 - recall: 0.7531 - precision: 0.7968 - val_loss: 0.4948 - val_accuracy: 0.7789 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8489 - val_recall: 0.8576 - val_precision: 0.7342\n",
            "Epoch 350/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4371 - accuracy: 0.7781 - sensitivity_at_specificity: 0.9365 - specificity_at_sensitivity: 0.9553 - recall: 0.7582 - precision: 0.7973\n",
            "Epoch 350: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.4371 - accuracy: 0.7781 - sensitivity_at_specificity: 0.9365 - specificity_at_sensitivity: 0.9553 - recall: 0.7582 - precision: 0.7973 - val_loss: 0.4865 - val_accuracy: 0.7547 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8528 - val_recall: 0.7847 - val_precision: 0.7482\n",
            "Epoch 351/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4333 - accuracy: 0.7844 - sensitivity_at_specificity: 0.9259 - specificity_at_sensitivity: 0.9667 - recall: 0.7518 - precision: 0.8010\n",
            "Epoch 351: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.4333 - accuracy: 0.7844 - sensitivity_at_specificity: 0.9259 - specificity_at_sensitivity: 0.9667 - recall: 0.7518 - precision: 0.8010 - val_loss: 0.4754 - val_accuracy: 0.7773 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8614 - val_recall: 0.7947 - val_precision: 0.7670\n",
            "Epoch 352/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4282 - accuracy: 0.7859 - sensitivity_at_specificity: 0.9371 - specificity_at_sensitivity: 0.9655 - recall: 0.7562 - precision: 0.7968\n",
            "Epoch 352: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.4282 - accuracy: 0.7859 - sensitivity_at_specificity: 0.9371 - specificity_at_sensitivity: 0.9655 - recall: 0.7562 - precision: 0.7968 - val_loss: 0.4913 - val_accuracy: 0.7555 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8527 - val_recall: 0.7354 - val_precision: 0.7834\n",
            "Epoch 353/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4468 - accuracy: 0.7666 - sensitivity_at_specificity: 0.9321 - specificity_at_sensitivity: 0.9469 - recall: 0.7430 - precision: 0.7855\n",
            "Epoch 353: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.4468 - accuracy: 0.7666 - sensitivity_at_specificity: 0.9321 - specificity_at_sensitivity: 0.9469 - recall: 0.7430 - precision: 0.7855 - val_loss: 0.5042 - val_accuracy: 0.7555 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8544 - val_recall: 0.7608 - val_precision: 0.7573\n",
            "Epoch 354/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4318 - accuracy: 0.7809 - sensitivity_at_specificity: 0.9285 - specificity_at_sensitivity: 0.9655 - recall: 0.7694 - precision: 0.7967\n",
            "Epoch 354: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.4318 - accuracy: 0.7809 - sensitivity_at_specificity: 0.9285 - specificity_at_sensitivity: 0.9655 - recall: 0.7694 - precision: 0.7967 - val_loss: 0.4954 - val_accuracy: 0.7727 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8439 - val_recall: 0.8331 - val_precision: 0.7548\n",
            "Epoch 355/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4390 - accuracy: 0.7840 - sensitivity_at_specificity: 0.9355 - specificity_at_sensitivity: 0.9534 - recall: 0.7681 - precision: 0.7911\n",
            "Epoch 355: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.4390 - accuracy: 0.7840 - sensitivity_at_specificity: 0.9355 - specificity_at_sensitivity: 0.9534 - recall: 0.7681 - precision: 0.7911 - val_loss: 0.5273 - val_accuracy: 0.7672 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8552 - val_recall: 0.8045 - val_precision: 0.7404\n",
            "Epoch 356/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4196 - accuracy: 0.7891 - sensitivity_at_specificity: 0.9437 - specificity_at_sensitivity: 0.9650 - recall: 0.7492 - precision: 0.8034\n",
            "Epoch 356: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.4196 - accuracy: 0.7891 - sensitivity_at_specificity: 0.9437 - specificity_at_sensitivity: 0.9650 - recall: 0.7492 - precision: 0.8034 - val_loss: 0.4696 - val_accuracy: 0.7719 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8517 - val_recall: 0.8034 - val_precision: 0.7588\n",
            "Epoch 357/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4189 - accuracy: 0.7934 - sensitivity_at_specificity: 0.9451 - specificity_at_sensitivity: 0.9708 - recall: 0.7613 - precision: 0.8069\n",
            "Epoch 357: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.4189 - accuracy: 0.7934 - sensitivity_at_specificity: 0.9451 - specificity_at_sensitivity: 0.9708 - recall: 0.7613 - precision: 0.8069 - val_loss: 0.5255 - val_accuracy: 0.7563 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8333 - val_recall: 0.8115 - val_precision: 0.7236\n",
            "Epoch 358/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4416 - accuracy: 0.7707 - sensitivity_at_specificity: 0.9216 - specificity_at_sensitivity: 0.9611 - recall: 0.7592 - precision: 0.7756\n",
            "Epoch 358: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.4416 - accuracy: 0.7707 - sensitivity_at_specificity: 0.9216 - specificity_at_sensitivity: 0.9611 - recall: 0.7592 - precision: 0.7756 - val_loss: 0.5239 - val_accuracy: 0.7539 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8438 - val_recall: 0.7678 - val_precision: 0.7504\n",
            "Epoch 359/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4304 - accuracy: 0.7762 - sensitivity_at_specificity: 0.9398 - specificity_at_sensitivity: 0.9610 - recall: 0.7639 - precision: 0.7829\n",
            "Epoch 359: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 176ms/step - loss: 0.4304 - accuracy: 0.7762 - sensitivity_at_specificity: 0.9398 - specificity_at_sensitivity: 0.9610 - recall: 0.7639 - precision: 0.7829 - val_loss: 0.5040 - val_accuracy: 0.7531 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.8467 - val_recall: 0.7536 - val_precision: 0.7417\n",
            "Epoch 360/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4089 - accuracy: 0.7965 - sensitivity_at_specificity: 0.9476 - specificity_at_sensitivity: 0.9704 - recall: 0.7754 - precision: 0.8090\n",
            "Epoch 360: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.4089 - accuracy: 0.7965 - sensitivity_at_specificity: 0.9476 - specificity_at_sensitivity: 0.9704 - recall: 0.7754 - precision: 0.8090 - val_loss: 0.4933 - val_accuracy: 0.7773 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8540 - val_recall: 0.8308 - val_precision: 0.7552\n",
            "Epoch 361/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4302 - accuracy: 0.7852 - sensitivity_at_specificity: 0.9396 - specificity_at_sensitivity: 0.9523 - recall: 0.7666 - precision: 0.8081\n",
            "Epoch 361: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.4302 - accuracy: 0.7852 - sensitivity_at_specificity: 0.9396 - specificity_at_sensitivity: 0.9523 - recall: 0.7666 - precision: 0.8081 - val_loss: 0.4892 - val_accuracy: 0.7734 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8549 - val_recall: 0.8404 - val_precision: 0.7407\n",
            "Epoch 362/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4240 - accuracy: 0.7949 - sensitivity_at_specificity: 0.9381 - specificity_at_sensitivity: 0.9653 - recall: 0.7848 - precision: 0.8041\n",
            "Epoch 362: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.4240 - accuracy: 0.7949 - sensitivity_at_specificity: 0.9381 - specificity_at_sensitivity: 0.9653 - recall: 0.7848 - precision: 0.8041 - val_loss: 0.5111 - val_accuracy: 0.7437 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8447 - val_recall: 0.7644 - val_precision: 0.7463\n",
            "Epoch 363/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4175 - accuracy: 0.7809 - sensitivity_at_specificity: 0.9609 - specificity_at_sensitivity: 0.9625 - recall: 0.7448 - precision: 0.7949\n",
            "Epoch 363: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.4175 - accuracy: 0.7809 - sensitivity_at_specificity: 0.9609 - specificity_at_sensitivity: 0.9625 - recall: 0.7448 - precision: 0.7949 - val_loss: 0.5298 - val_accuracy: 0.7766 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8365 - val_recall: 0.8323 - val_precision: 0.7535\n",
            "Epoch 364/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4059 - accuracy: 0.7961 - sensitivity_at_specificity: 0.9427 - specificity_at_sensitivity: 0.9739 - recall: 0.7540 - precision: 0.8164\n",
            "Epoch 364: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 176ms/step - loss: 0.4059 - accuracy: 0.7961 - sensitivity_at_specificity: 0.9427 - specificity_at_sensitivity: 0.9739 - recall: 0.7540 - precision: 0.8164 - val_loss: 0.4558 - val_accuracy: 0.7820 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8770 - val_recall: 0.8172 - val_precision: 0.7740\n",
            "Epoch 365/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4099 - accuracy: 0.8031 - sensitivity_at_specificity: 0.9508 - specificity_at_sensitivity: 0.9687 - recall: 0.7861 - precision: 0.8141\n",
            "Epoch 365: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.4099 - accuracy: 0.8031 - sensitivity_at_specificity: 0.9508 - specificity_at_sensitivity: 0.9687 - recall: 0.7861 - precision: 0.8141 - val_loss: 0.4684 - val_accuracy: 0.7805 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.8867 - val_recall: 0.7961 - val_precision: 0.7604\n",
            "Epoch 366/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4081 - accuracy: 0.7863 - sensitivity_at_specificity: 0.9514 - specificity_at_sensitivity: 0.9723 - recall: 0.7764 - precision: 0.7967\n",
            "Epoch 366: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.4081 - accuracy: 0.7863 - sensitivity_at_specificity: 0.9514 - specificity_at_sensitivity: 0.9723 - recall: 0.7764 - precision: 0.7967 - val_loss: 0.5047 - val_accuracy: 0.7688 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8473 - val_recall: 0.8176 - val_precision: 0.7374\n",
            "Epoch 367/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4092 - accuracy: 0.7961 - sensitivity_at_specificity: 0.9441 - specificity_at_sensitivity: 0.9713 - recall: 0.7687 - precision: 0.8108\n",
            "Epoch 367: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.4092 - accuracy: 0.7961 - sensitivity_at_specificity: 0.9441 - specificity_at_sensitivity: 0.9713 - recall: 0.7687 - precision: 0.8108 - val_loss: 0.5019 - val_accuracy: 0.7789 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 0.8588 - val_recall: 0.8346 - val_precision: 0.7650\n",
            "Epoch 368/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4021 - accuracy: 0.8000 - sensitivity_at_specificity: 0.9541 - specificity_at_sensitivity: 0.9749 - recall: 0.7753 - precision: 0.8172\n",
            "Epoch 368: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.4021 - accuracy: 0.8000 - sensitivity_at_specificity: 0.9541 - specificity_at_sensitivity: 0.9749 - recall: 0.7753 - precision: 0.8172 - val_loss: 0.4802 - val_accuracy: 0.7875 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8859 - val_recall: 0.8582 - val_precision: 0.7558\n",
            "Epoch 369/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4215 - accuracy: 0.7863 - sensitivity_at_specificity: 0.9517 - specificity_at_sensitivity: 0.9655 - recall: 0.7819 - precision: 0.7899\n",
            "Epoch 369: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.4215 - accuracy: 0.7863 - sensitivity_at_specificity: 0.9517 - specificity_at_sensitivity: 0.9655 - recall: 0.7819 - precision: 0.7899 - val_loss: 0.4453 - val_accuracy: 0.7898 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8833 - val_recall: 0.8516 - val_precision: 0.7489\n",
            "Epoch 370/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4237 - accuracy: 0.7922 - sensitivity_at_specificity: 0.9452 - specificity_at_sensitivity: 0.9667 - recall: 0.7710 - precision: 0.7940\n",
            "Epoch 370: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.4237 - accuracy: 0.7922 - sensitivity_at_specificity: 0.9452 - specificity_at_sensitivity: 0.9667 - recall: 0.7710 - precision: 0.7940 - val_loss: 0.4904 - val_accuracy: 0.7664 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8556 - val_recall: 0.7679 - val_precision: 0.7594\n",
            "Epoch 371/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4223 - accuracy: 0.7824 - sensitivity_at_specificity: 0.9407 - specificity_at_sensitivity: 0.9659 - recall: 0.7737 - precision: 0.7926\n",
            "Epoch 371: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.4223 - accuracy: 0.7824 - sensitivity_at_specificity: 0.9407 - specificity_at_sensitivity: 0.9659 - recall: 0.7737 - precision: 0.7926 - val_loss: 0.4819 - val_accuracy: 0.7633 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8638 - val_recall: 0.7348 - val_precision: 0.7889\n",
            "Epoch 372/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4216 - accuracy: 0.7988 - sensitivity_at_specificity: 0.9356 - specificity_at_sensitivity: 0.9658 - recall: 0.7643 - precision: 0.8106\n",
            "Epoch 372: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 174ms/step - loss: 0.4216 - accuracy: 0.7988 - sensitivity_at_specificity: 0.9356 - specificity_at_sensitivity: 0.9658 - recall: 0.7643 - precision: 0.8106 - val_loss: 0.4938 - val_accuracy: 0.7734 - val_sensitivity_at_specificity: 0.9967 - val_specificity_at_sensitivity: 0.8574 - val_recall: 0.7941 - val_precision: 0.7450\n",
            "Epoch 373/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4243 - accuracy: 0.7852 - sensitivity_at_specificity: 0.9519 - specificity_at_sensitivity: 0.9640 - recall: 0.7645 - precision: 0.7823\n",
            "Epoch 373: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.4243 - accuracy: 0.7852 - sensitivity_at_specificity: 0.9519 - specificity_at_sensitivity: 0.9640 - recall: 0.7645 - precision: 0.7823 - val_loss: 0.5165 - val_accuracy: 0.7641 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8512 - val_recall: 0.7543 - val_precision: 0.7664\n",
            "Epoch 374/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4185 - accuracy: 0.7961 - sensitivity_at_specificity: 0.9498 - specificity_at_sensitivity: 0.9585 - recall: 0.7299 - precision: 0.8249\n",
            "Epoch 374: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.4185 - accuracy: 0.7961 - sensitivity_at_specificity: 0.9498 - specificity_at_sensitivity: 0.9585 - recall: 0.7299 - precision: 0.8249 - val_loss: 0.5025 - val_accuracy: 0.7414 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.8465 - val_recall: 0.7138 - val_precision: 0.7437\n",
            "Epoch 375/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4194 - accuracy: 0.7961 - sensitivity_at_specificity: 0.9645 - specificity_at_sensitivity: 0.9613 - recall: 0.7792 - precision: 0.7959\n",
            "Epoch 375: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.4194 - accuracy: 0.7961 - sensitivity_at_specificity: 0.9645 - specificity_at_sensitivity: 0.9613 - recall: 0.7792 - precision: 0.7959 - val_loss: 0.4827 - val_accuracy: 0.7531 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8690 - val_recall: 0.7214 - val_precision: 0.7696\n",
            "Epoch 376/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4103 - accuracy: 0.7961 - sensitivity_at_specificity: 0.9516 - specificity_at_sensitivity: 0.9679 - recall: 0.7566 - precision: 0.8220\n",
            "Epoch 376: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.4103 - accuracy: 0.7961 - sensitivity_at_specificity: 0.9516 - specificity_at_sensitivity: 0.9679 - recall: 0.7566 - precision: 0.8220 - val_loss: 0.4607 - val_accuracy: 0.7734 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8891 - val_recall: 0.8034 - val_precision: 0.7343\n",
            "Epoch 377/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4071 - accuracy: 0.8035 - sensitivity_at_specificity: 0.9499 - specificity_at_sensitivity: 0.9735 - recall: 0.7989 - precision: 0.8058\n",
            "Epoch 377: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.4071 - accuracy: 0.8035 - sensitivity_at_specificity: 0.9499 - specificity_at_sensitivity: 0.9735 - recall: 0.7989 - precision: 0.8058 - val_loss: 0.4954 - val_accuracy: 0.7789 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8567 - val_recall: 0.8448 - val_precision: 0.7455\n",
            "Epoch 378/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4145 - accuracy: 0.7848 - sensitivity_at_specificity: 0.9545 - specificity_at_sensitivity: 0.9704 - recall: 0.7774 - precision: 0.7879\n",
            "Epoch 378: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.4145 - accuracy: 0.7848 - sensitivity_at_specificity: 0.9545 - specificity_at_sensitivity: 0.9704 - recall: 0.7774 - precision: 0.7879 - val_loss: 0.4882 - val_accuracy: 0.7633 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 0.8612 - val_recall: 0.7508 - val_precision: 0.7735\n",
            "Epoch 379/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4524 - accuracy: 0.7633 - sensitivity_at_specificity: 0.9289 - specificity_at_sensitivity: 0.9415 - recall: 0.7443 - precision: 0.7734\n",
            "Epoch 379: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.4524 - accuracy: 0.7633 - sensitivity_at_specificity: 0.9289 - specificity_at_sensitivity: 0.9415 - recall: 0.7443 - precision: 0.7734 - val_loss: 0.4966 - val_accuracy: 0.7492 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8388 - val_recall: 0.7525 - val_precision: 0.7297\n",
            "Epoch 380/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4326 - accuracy: 0.7797 - sensitivity_at_specificity: 0.9474 - specificity_at_sensitivity: 0.9548 - recall: 0.7522 - precision: 0.7886\n",
            "Epoch 380: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.4326 - accuracy: 0.7797 - sensitivity_at_specificity: 0.9474 - specificity_at_sensitivity: 0.9548 - recall: 0.7522 - precision: 0.7886 - val_loss: 0.5196 - val_accuracy: 0.7594 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.8144 - val_recall: 0.8153 - val_precision: 0.7273\n",
            "Epoch 381/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4070 - accuracy: 0.8055 - sensitivity_at_specificity: 0.9556 - specificity_at_sensitivity: 0.9633 - recall: 0.7956 - precision: 0.8181\n",
            "Epoch 381: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.4070 - accuracy: 0.8055 - sensitivity_at_specificity: 0.9556 - specificity_at_sensitivity: 0.9633 - recall: 0.7956 - precision: 0.8181 - val_loss: 0.4959 - val_accuracy: 0.7781 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8602 - val_recall: 0.8286 - val_precision: 0.7507\n",
            "Epoch 382/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4199 - accuracy: 0.7887 - sensitivity_at_specificity: 0.9464 - specificity_at_sensitivity: 0.9713 - recall: 0.7994 - precision: 0.7891\n",
            "Epoch 382: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.4199 - accuracy: 0.7887 - sensitivity_at_specificity: 0.9464 - specificity_at_sensitivity: 0.9713 - recall: 0.7994 - precision: 0.7891 - val_loss: 0.4449 - val_accuracy: 0.7766 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8797 - val_recall: 0.8075 - val_precision: 0.7727\n",
            "Epoch 383/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4137 - accuracy: 0.8004 - sensitivity_at_specificity: 0.9518 - specificity_at_sensitivity: 0.9592 - recall: 0.7809 - precision: 0.8144\n",
            "Epoch 383: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.4137 - accuracy: 0.8004 - sensitivity_at_specificity: 0.9518 - specificity_at_sensitivity: 0.9592 - recall: 0.7809 - precision: 0.8144 - val_loss: 0.5151 - val_accuracy: 0.7648 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8495 - val_recall: 0.7711 - val_precision: 0.7555\n",
            "Epoch 384/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4057 - accuracy: 0.8078 - sensitivity_at_specificity: 0.9502 - specificity_at_sensitivity: 0.9730 - recall: 0.7723 - precision: 0.8273\n",
            "Epoch 384: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 177ms/step - loss: 0.4057 - accuracy: 0.8078 - sensitivity_at_specificity: 0.9502 - specificity_at_sensitivity: 0.9730 - recall: 0.7723 - precision: 0.8273 - val_loss: 0.4755 - val_accuracy: 0.7727 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8701 - val_recall: 0.8034 - val_precision: 0.7574\n",
            "Epoch 385/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3944 - accuracy: 0.8059 - sensitivity_at_specificity: 0.9481 - specificity_at_sensitivity: 0.9795 - recall: 0.7837 - precision: 0.8226\n",
            "Epoch 385: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.3944 - accuracy: 0.8059 - sensitivity_at_specificity: 0.9481 - specificity_at_sensitivity: 0.9795 - recall: 0.7837 - precision: 0.8226 - val_loss: 0.5152 - val_accuracy: 0.7727 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8460 - val_recall: 0.8540 - val_precision: 0.7332\n",
            "Epoch 386/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4141 - accuracy: 0.7918 - sensitivity_at_specificity: 0.9388 - specificity_at_sensitivity: 0.9798 - recall: 0.7582 - precision: 0.8111\n",
            "Epoch 386: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.4141 - accuracy: 0.7918 - sensitivity_at_specificity: 0.9388 - specificity_at_sensitivity: 0.9798 - recall: 0.7582 - precision: 0.8111 - val_loss: 0.5226 - val_accuracy: 0.7734 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8509 - val_recall: 0.8538 - val_precision: 0.7338\n",
            "Epoch 387/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3737 - accuracy: 0.8137 - sensitivity_at_specificity: 0.9540 - specificity_at_sensitivity: 0.9906 - recall: 0.7958 - precision: 0.8261\n",
            "Epoch 387: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.3737 - accuracy: 0.8137 - sensitivity_at_specificity: 0.9540 - specificity_at_sensitivity: 0.9906 - recall: 0.7958 - precision: 0.8261 - val_loss: 0.4932 - val_accuracy: 0.7906 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.8758 - val_recall: 0.8525 - val_precision: 0.7604\n",
            "Epoch 388/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3905 - accuracy: 0.8086 - sensitivity_at_specificity: 0.9526 - specificity_at_sensitivity: 0.9822 - recall: 0.7916 - precision: 0.8161\n",
            "Epoch 388: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.3905 - accuracy: 0.8086 - sensitivity_at_specificity: 0.9526 - specificity_at_sensitivity: 0.9822 - recall: 0.7916 - precision: 0.8161 - val_loss: 0.5088 - val_accuracy: 0.7727 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8567 - val_recall: 0.8209 - val_precision: 0.7443\n",
            "Epoch 389/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3955 - accuracy: 0.8070 - sensitivity_at_specificity: 0.9555 - specificity_at_sensitivity: 0.9743 - recall: 0.7668 - precision: 0.8213\n",
            "Epoch 389: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.3955 - accuracy: 0.8070 - sensitivity_at_specificity: 0.9555 - specificity_at_sensitivity: 0.9743 - recall: 0.7668 - precision: 0.8213 - val_loss: 0.4654 - val_accuracy: 0.7891 - val_sensitivity_at_specificity: 0.9968 - val_specificity_at_sensitivity: 0.8852 - val_recall: 0.8301 - val_precision: 0.7566\n",
            "Epoch 390/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3978 - accuracy: 0.8012 - sensitivity_at_specificity: 0.9549 - specificity_at_sensitivity: 0.9753 - recall: 0.7886 - precision: 0.8045\n",
            "Epoch 390: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.3978 - accuracy: 0.8012 - sensitivity_at_specificity: 0.9549 - specificity_at_sensitivity: 0.9753 - recall: 0.7886 - precision: 0.8045 - val_loss: 0.5063 - val_accuracy: 0.7828 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8708 - val_recall: 0.8270 - val_precision: 0.7660\n",
            "Epoch 391/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3875 - accuracy: 0.8105 - sensitivity_at_specificity: 0.9607 - specificity_at_sensitivity: 0.9787 - recall: 0.7674 - precision: 0.8307\n",
            "Epoch 391: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.3875 - accuracy: 0.8105 - sensitivity_at_specificity: 0.9607 - specificity_at_sensitivity: 0.9787 - recall: 0.7674 - precision: 0.8307 - val_loss: 0.5465 - val_accuracy: 0.7492 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8489 - val_recall: 0.8010 - val_precision: 0.7143\n",
            "Epoch 392/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3868 - accuracy: 0.8055 - sensitivity_at_specificity: 0.9757 - specificity_at_sensitivity: 0.9759 - recall: 0.7892 - precision: 0.8147\n",
            "Epoch 392: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.3868 - accuracy: 0.8055 - sensitivity_at_specificity: 0.9757 - specificity_at_sensitivity: 0.9759 - recall: 0.7892 - precision: 0.8147 - val_loss: 0.5084 - val_accuracy: 0.7688 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.8534 - val_recall: 0.7896 - val_precision: 0.7538\n",
            "Epoch 393/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3781 - accuracy: 0.8254 - sensitivity_at_specificity: 0.9702 - specificity_at_sensitivity: 0.9788 - recall: 0.7953 - precision: 0.8364\n",
            "Epoch 393: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 218ms/step - loss: 0.3781 - accuracy: 0.8254 - sensitivity_at_specificity: 0.9702 - specificity_at_sensitivity: 0.9788 - recall: 0.7953 - precision: 0.8364 - val_loss: 0.5634 - val_accuracy: 0.7695 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8462 - val_recall: 0.8460 - val_precision: 0.7351\n",
            "Epoch 394/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3804 - accuracy: 0.8207 - sensitivity_at_specificity: 0.9675 - specificity_at_sensitivity: 0.9776 - recall: 0.7989 - precision: 0.8311\n",
            "Epoch 394: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 178ms/step - loss: 0.3804 - accuracy: 0.8207 - sensitivity_at_specificity: 0.9675 - specificity_at_sensitivity: 0.9776 - recall: 0.7989 - precision: 0.8311 - val_loss: 0.5597 - val_accuracy: 0.7648 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8331 - val_recall: 0.8454 - val_precision: 0.7192\n",
            "Epoch 395/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3824 - accuracy: 0.8160 - sensitivity_at_specificity: 0.9594 - specificity_at_sensitivity: 0.9797 - recall: 0.8072 - precision: 0.8219\n",
            "Epoch 395: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.3824 - accuracy: 0.8160 - sensitivity_at_specificity: 0.9594 - specificity_at_sensitivity: 0.9797 - recall: 0.8072 - precision: 0.8219 - val_loss: 0.5088 - val_accuracy: 0.7742 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8694 - val_recall: 0.8666 - val_precision: 0.7302\n",
            "Epoch 396/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3866 - accuracy: 0.8156 - sensitivity_at_specificity: 0.9642 - specificity_at_sensitivity: 0.9823 - recall: 0.7796 - precision: 0.8340\n",
            "Epoch 396: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.3866 - accuracy: 0.8156 - sensitivity_at_specificity: 0.9642 - specificity_at_sensitivity: 0.9823 - recall: 0.7796 - precision: 0.8340 - val_loss: 0.4901 - val_accuracy: 0.7836 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.8654 - val_recall: 0.8275 - val_precision: 0.7540\n",
            "Epoch 397/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3871 - accuracy: 0.8069 - sensitivity_at_specificity: 0.9546 - specificity_at_sensitivity: 0.9870 - recall: 0.7928 - precision: 0.8292\n",
            "Epoch 397: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.3871 - accuracy: 0.8069 - sensitivity_at_specificity: 0.9546 - specificity_at_sensitivity: 0.9870 - recall: 0.7928 - precision: 0.8292 - val_loss: 0.5018 - val_accuracy: 0.7656 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8509 - val_recall: 0.8286 - val_precision: 0.7340\n",
            "Epoch 398/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4051 - accuracy: 0.7994 - sensitivity_at_specificity: 0.9508 - specificity_at_sensitivity: 0.9714 - recall: 0.7984 - precision: 0.8043\n",
            "Epoch 398: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.4051 - accuracy: 0.7994 - sensitivity_at_specificity: 0.9508 - specificity_at_sensitivity: 0.9714 - recall: 0.7984 - precision: 0.8043 - val_loss: 0.5687 - val_accuracy: 0.7477 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8240 - val_recall: 0.8675 - val_precision: 0.6832\n",
            "Epoch 399/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3905 - accuracy: 0.8062 - sensitivity_at_specificity: 0.9596 - specificity_at_sensitivity: 0.9843 - recall: 0.8003 - precision: 0.8117\n",
            "Epoch 399: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.3905 - accuracy: 0.8062 - sensitivity_at_specificity: 0.9596 - specificity_at_sensitivity: 0.9843 - recall: 0.8003 - precision: 0.8117 - val_loss: 0.5081 - val_accuracy: 0.7555 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8557 - val_recall: 0.7862 - val_precision: 0.7231\n",
            "Epoch 400/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3768 - accuracy: 0.8195 - sensitivity_at_specificity: 0.9518 - specificity_at_sensitivity: 0.9856 - recall: 0.7871 - precision: 0.8482\n",
            "Epoch 400: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.3768 - accuracy: 0.8195 - sensitivity_at_specificity: 0.9518 - specificity_at_sensitivity: 0.9856 - recall: 0.7871 - precision: 0.8482 - val_loss: 0.4963 - val_accuracy: 0.7820 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8495 - val_recall: 0.8333 - val_precision: 0.7567\n",
            "Epoch 401/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3942 - accuracy: 0.8020 - sensitivity_at_specificity: 0.9630 - specificity_at_sensitivity: 0.9783 - recall: 0.7821 - precision: 0.8121\n",
            "Epoch 401: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.3942 - accuracy: 0.8020 - sensitivity_at_specificity: 0.9630 - specificity_at_sensitivity: 0.9783 - recall: 0.7821 - precision: 0.8121 - val_loss: 0.5336 - val_accuracy: 0.7648 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8346 - val_recall: 0.8626 - val_precision: 0.7184\n",
            "Epoch 402/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3734 - accuracy: 0.8305 - sensitivity_at_specificity: 0.9594 - specificity_at_sensitivity: 0.9820 - recall: 0.8331 - precision: 0.8292\n",
            "Epoch 402: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 174ms/step - loss: 0.3734 - accuracy: 0.8305 - sensitivity_at_specificity: 0.9594 - specificity_at_sensitivity: 0.9820 - recall: 0.8331 - precision: 0.8292 - val_loss: 0.4730 - val_accuracy: 0.7883 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8810 - val_recall: 0.8339 - val_precision: 0.7489\n",
            "Epoch 403/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3667 - accuracy: 0.8199 - sensitivity_at_specificity: 0.9676 - specificity_at_sensitivity: 0.9850 - recall: 0.7986 - precision: 0.8381\n",
            "Epoch 403: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.3667 - accuracy: 0.8199 - sensitivity_at_specificity: 0.9676 - specificity_at_sensitivity: 0.9850 - recall: 0.7986 - precision: 0.8381 - val_loss: 0.4953 - val_accuracy: 0.7781 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 0.8770 - val_recall: 0.8104 - val_precision: 0.7681\n",
            "Epoch 404/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3583 - accuracy: 0.8207 - sensitivity_at_specificity: 0.9724 - specificity_at_sensitivity: 0.9896 - recall: 0.8098 - precision: 0.8335\n",
            "Epoch 404: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.3583 - accuracy: 0.8207 - sensitivity_at_specificity: 0.9724 - specificity_at_sensitivity: 0.9896 - recall: 0.8098 - precision: 0.8335 - val_loss: 0.5230 - val_accuracy: 0.7656 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.8574 - val_recall: 0.8010 - val_precision: 0.7419\n",
            "Epoch 405/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3491 - accuracy: 0.8371 - sensitivity_at_specificity: 0.9694 - specificity_at_sensitivity: 0.9899 - recall: 0.8204 - precision: 0.8476\n",
            "Epoch 405: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.3491 - accuracy: 0.8371 - sensitivity_at_specificity: 0.9694 - specificity_at_sensitivity: 0.9899 - recall: 0.8204 - precision: 0.8476 - val_loss: 0.5306 - val_accuracy: 0.7703 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8732 - val_recall: 0.8752 - val_precision: 0.7273\n",
            "Epoch 406/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3903 - accuracy: 0.8086 - sensitivity_at_specificity: 0.9585 - specificity_at_sensitivity: 0.9782 - recall: 0.7864 - precision: 0.8224\n",
            "Epoch 406: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.3903 - accuracy: 0.8086 - sensitivity_at_specificity: 0.9585 - specificity_at_sensitivity: 0.9782 - recall: 0.7864 - precision: 0.8224 - val_loss: 0.4844 - val_accuracy: 0.7750 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8775 - val_recall: 0.8045 - val_precision: 0.7489\n",
            "Epoch 407/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3748 - accuracy: 0.8242 - sensitivity_at_specificity: 0.9583 - specificity_at_sensitivity: 0.9839 - recall: 0.8171 - precision: 0.8375\n",
            "Epoch 407: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.3748 - accuracy: 0.8242 - sensitivity_at_specificity: 0.9583 - specificity_at_sensitivity: 0.9839 - recall: 0.8171 - precision: 0.8375 - val_loss: 0.4959 - val_accuracy: 0.7883 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8636 - val_recall: 0.8349 - val_precision: 0.7646\n",
            "Epoch 408/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3892 - accuracy: 0.8156 - sensitivity_at_specificity: 0.9604 - specificity_at_sensitivity: 0.9701 - recall: 0.7950 - precision: 0.8312\n",
            "Epoch 408: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.3892 - accuracy: 0.8156 - sensitivity_at_specificity: 0.9604 - specificity_at_sensitivity: 0.9701 - recall: 0.7950 - precision: 0.8312 - val_loss: 0.4971 - val_accuracy: 0.7695 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8394 - val_recall: 0.8664 - val_precision: 0.7306\n",
            "Epoch 409/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3665 - accuracy: 0.8164 - sensitivity_at_specificity: 0.9677 - specificity_at_sensitivity: 0.9870 - recall: 0.7925 - precision: 0.8248\n",
            "Epoch 409: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.3665 - accuracy: 0.8164 - sensitivity_at_specificity: 0.9677 - specificity_at_sensitivity: 0.9870 - recall: 0.7925 - precision: 0.8248 - val_loss: 0.5334 - val_accuracy: 0.7789 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8576 - val_recall: 0.8502 - val_precision: 0.7445\n",
            "Epoch 410/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3713 - accuracy: 0.8260 - sensitivity_at_specificity: 0.9714 - specificity_at_sensitivity: 0.9822 - recall: 0.7984 - precision: 0.8504\n",
            "Epoch 410: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.3713 - accuracy: 0.8260 - sensitivity_at_specificity: 0.9714 - specificity_at_sensitivity: 0.9822 - recall: 0.7984 - precision: 0.8504 - val_loss: 0.5144 - val_accuracy: 0.7586 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8484 - val_recall: 0.8038 - val_precision: 0.7304\n",
            "Epoch 411/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3574 - accuracy: 0.8285 - sensitivity_at_specificity: 0.9709 - specificity_at_sensitivity: 0.9829 - recall: 0.8248 - precision: 0.8294\n",
            "Epoch 411: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.3574 - accuracy: 0.8285 - sensitivity_at_specificity: 0.9709 - specificity_at_sensitivity: 0.9829 - recall: 0.8248 - precision: 0.8294 - val_loss: 0.5069 - val_accuracy: 0.7805 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8529 - val_recall: 0.8470 - val_precision: 0.7448\n",
            "Epoch 412/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3863 - accuracy: 0.8180 - sensitivity_at_specificity: 0.9619 - specificity_at_sensitivity: 0.9762 - recall: 0.7990 - precision: 0.8253\n",
            "Epoch 412: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.3863 - accuracy: 0.8180 - sensitivity_at_specificity: 0.9619 - specificity_at_sensitivity: 0.9762 - recall: 0.7990 - precision: 0.8253 - val_loss: 0.6054 - val_accuracy: 0.7523 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8240 - val_recall: 0.8512 - val_precision: 0.7250\n",
            "Epoch 413/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3627 - accuracy: 0.8254 - sensitivity_at_specificity: 0.9724 - specificity_at_sensitivity: 0.9899 - recall: 0.8008 - precision: 0.8398\n",
            "Epoch 413: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.3627 - accuracy: 0.8254 - sensitivity_at_specificity: 0.9724 - specificity_at_sensitivity: 0.9899 - recall: 0.8008 - precision: 0.8398 - val_loss: 0.5173 - val_accuracy: 0.7688 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8489 - val_recall: 0.8903 - val_precision: 0.7154\n",
            "Epoch 414/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3653 - accuracy: 0.8332 - sensitivity_at_specificity: 0.9676 - specificity_at_sensitivity: 0.9842 - recall: 0.8204 - precision: 0.8458\n",
            "Epoch 414: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.3653 - accuracy: 0.8332 - sensitivity_at_specificity: 0.9676 - specificity_at_sensitivity: 0.9842 - recall: 0.8204 - precision: 0.8458 - val_loss: 0.5345 - val_accuracy: 0.7812 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8541 - val_recall: 0.8424 - val_precision: 0.7422\n",
            "Epoch 415/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3471 - accuracy: 0.8297 - sensitivity_at_specificity: 0.9831 - specificity_at_sensitivity: 0.9901 - recall: 0.8329 - precision: 0.8198\n",
            "Epoch 415: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.3471 - accuracy: 0.8297 - sensitivity_at_specificity: 0.9831 - specificity_at_sensitivity: 0.9901 - recall: 0.8329 - precision: 0.8198 - val_loss: 0.5263 - val_accuracy: 0.7875 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8328 - val_recall: 0.8896 - val_precision: 0.7363\n",
            "Epoch 416/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3577 - accuracy: 0.8332 - sensitivity_at_specificity: 0.9683 - specificity_at_sensitivity: 0.9858 - recall: 0.8128 - precision: 0.8503\n",
            "Epoch 416: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.3577 - accuracy: 0.8332 - sensitivity_at_specificity: 0.9683 - specificity_at_sensitivity: 0.9858 - recall: 0.8128 - precision: 0.8503 - val_loss: 0.5147 - val_accuracy: 0.7906 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8600 - val_recall: 0.8760 - val_precision: 0.7470\n",
            "Epoch 417/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3640 - accuracy: 0.8273 - sensitivity_at_specificity: 0.9790 - specificity_at_sensitivity: 0.9780 - recall: 0.8182 - precision: 0.8351\n",
            "Epoch 417: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.3640 - accuracy: 0.8273 - sensitivity_at_specificity: 0.9790 - specificity_at_sensitivity: 0.9780 - recall: 0.8182 - precision: 0.8351 - val_loss: 0.4843 - val_accuracy: 0.8008 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8562 - val_recall: 0.8945 - val_precision: 0.7588\n",
            "Epoch 418/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3624 - accuracy: 0.8254 - sensitivity_at_specificity: 0.9744 - specificity_at_sensitivity: 0.9803 - recall: 0.8020 - precision: 0.8433\n",
            "Epoch 418: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.3624 - accuracy: 0.8254 - sensitivity_at_specificity: 0.9744 - specificity_at_sensitivity: 0.9803 - recall: 0.8020 - precision: 0.8433 - val_loss: 0.5654 - val_accuracy: 0.7758 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8671 - val_recall: 0.8935 - val_precision: 0.7265\n",
            "Epoch 419/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3518 - accuracy: 0.8348 - sensitivity_at_specificity: 0.9753 - specificity_at_sensitivity: 0.9857 - recall: 0.8313 - precision: 0.8410\n",
            "Epoch 419: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.3518 - accuracy: 0.8348 - sensitivity_at_specificity: 0.9753 - specificity_at_sensitivity: 0.9857 - recall: 0.8313 - precision: 0.8410 - val_loss: 0.5137 - val_accuracy: 0.7656 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.8569 - val_recall: 0.7795 - val_precision: 0.7606\n",
            "Epoch 420/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3608 - accuracy: 0.8328 - sensitivity_at_specificity: 0.9690 - specificity_at_sensitivity: 0.9843 - recall: 0.8248 - precision: 0.8404\n",
            "Epoch 420: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.3608 - accuracy: 0.8328 - sensitivity_at_specificity: 0.9690 - specificity_at_sensitivity: 0.9843 - recall: 0.8248 - precision: 0.8404 - val_loss: 0.5464 - val_accuracy: 0.7812 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8532 - val_recall: 0.8578 - val_precision: 0.7376\n",
            "Epoch 421/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3603 - accuracy: 0.8238 - sensitivity_at_specificity: 0.9673 - specificity_at_sensitivity: 0.9914 - recall: 0.7966 - precision: 0.8432\n",
            "Epoch 421: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.3603 - accuracy: 0.8238 - sensitivity_at_specificity: 0.9673 - specificity_at_sensitivity: 0.9914 - recall: 0.7966 - precision: 0.8432 - val_loss: 0.5565 - val_accuracy: 0.7914 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8640 - val_recall: 0.9115 - val_precision: 0.7407\n",
            "Epoch 422/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3463 - accuracy: 0.8355 - sensitivity_at_specificity: 0.9744 - specificity_at_sensitivity: 0.9882 - recall: 0.8223 - precision: 0.8466\n",
            "Epoch 422: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.3463 - accuracy: 0.8355 - sensitivity_at_specificity: 0.9744 - specificity_at_sensitivity: 0.9882 - recall: 0.8223 - precision: 0.8466 - val_loss: 0.5391 - val_accuracy: 0.7734 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8507 - val_recall: 0.8721 - val_precision: 0.7356\n",
            "Epoch 423/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3620 - accuracy: 0.8344 - sensitivity_at_specificity: 0.9722 - specificity_at_sensitivity: 0.9818 - recall: 0.8385 - precision: 0.8346\n",
            "Epoch 423: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.3620 - accuracy: 0.8344 - sensitivity_at_specificity: 0.9722 - specificity_at_sensitivity: 0.9818 - recall: 0.8385 - precision: 0.8346 - val_loss: 0.5639 - val_accuracy: 0.7727 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 0.8449 - val_recall: 0.8805 - val_precision: 0.7330\n",
            "Epoch 424/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3484 - accuracy: 0.8332 - sensitivity_at_specificity: 0.9698 - specificity_at_sensitivity: 0.9874 - recall: 0.8234 - precision: 0.8423\n",
            "Epoch 424: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.3484 - accuracy: 0.8332 - sensitivity_at_specificity: 0.9698 - specificity_at_sensitivity: 0.9874 - recall: 0.8234 - precision: 0.8423 - val_loss: 0.5290 - val_accuracy: 0.7750 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8490 - val_recall: 0.8725 - val_precision: 0.7348\n",
            "Epoch 425/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3519 - accuracy: 0.8324 - sensitivity_at_specificity: 0.9722 - specificity_at_sensitivity: 0.9900 - recall: 0.8211 - precision: 0.8351\n",
            "Epoch 425: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.3519 - accuracy: 0.8324 - sensitivity_at_specificity: 0.9722 - specificity_at_sensitivity: 0.9900 - recall: 0.8211 - precision: 0.8351 - val_loss: 0.5232 - val_accuracy: 0.7828 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8602 - val_recall: 0.8333 - val_precision: 0.7550\n",
            "Epoch 426/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3626 - accuracy: 0.8281 - sensitivity_at_specificity: 0.9670 - specificity_at_sensitivity: 0.9803 - recall: 0.8116 - precision: 0.8303\n",
            "Epoch 426: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.3626 - accuracy: 0.8281 - sensitivity_at_specificity: 0.9670 - specificity_at_sensitivity: 0.9803 - recall: 0.8116 - precision: 0.8303 - val_loss: 0.4790 - val_accuracy: 0.7969 - val_sensitivity_at_specificity: 0.9969 - val_specificity_at_sensitivity: 0.8823 - val_recall: 0.8694 - val_precision: 0.7605\n",
            "Epoch 427/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3548 - accuracy: 0.8301 - sensitivity_at_specificity: 0.9692 - specificity_at_sensitivity: 0.9892 - recall: 0.8144 - precision: 0.8375\n",
            "Epoch 427: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.3548 - accuracy: 0.8301 - sensitivity_at_specificity: 0.9692 - specificity_at_sensitivity: 0.9892 - recall: 0.8144 - precision: 0.8375 - val_loss: 0.5555 - val_accuracy: 0.7734 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8165 - val_recall: 0.8976 - val_precision: 0.7086\n",
            "Epoch 428/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3489 - accuracy: 0.8355 - sensitivity_at_specificity: 0.9766 - specificity_at_sensitivity: 0.9862 - recall: 0.8455 - precision: 0.8386\n",
            "Epoch 428: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.3489 - accuracy: 0.8355 - sensitivity_at_specificity: 0.9766 - specificity_at_sensitivity: 0.9862 - recall: 0.8455 - precision: 0.8386 - val_loss: 0.5444 - val_accuracy: 0.7891 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8604 - val_recall: 0.8969 - val_precision: 0.7300\n",
            "Epoch 429/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3464 - accuracy: 0.8430 - sensitivity_at_specificity: 0.9781 - specificity_at_sensitivity: 0.9867 - recall: 0.8192 - precision: 0.8596\n",
            "Epoch 429: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 174ms/step - loss: 0.3464 - accuracy: 0.8430 - sensitivity_at_specificity: 0.9781 - specificity_at_sensitivity: 0.9867 - recall: 0.8192 - precision: 0.8596 - val_loss: 0.6605 - val_accuracy: 0.7594 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8128 - val_recall: 0.8929 - val_precision: 0.6904\n",
            "Epoch 430/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3326 - accuracy: 0.8468 - sensitivity_at_specificity: 0.9737 - specificity_at_sensitivity: 0.9916 - recall: 0.8424 - precision: 0.8529\n",
            "Epoch 430: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.3326 - accuracy: 0.8468 - sensitivity_at_specificity: 0.9737 - specificity_at_sensitivity: 0.9916 - recall: 0.8424 - precision: 0.8529 - val_loss: 0.5337 - val_accuracy: 0.7727 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8433 - val_recall: 0.8490 - val_precision: 0.7315\n",
            "Epoch 431/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3579 - accuracy: 0.8297 - sensitivity_at_specificity: 0.9737 - specificity_at_sensitivity: 0.9850 - recall: 0.8059 - precision: 0.8492\n",
            "Epoch 431: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.3579 - accuracy: 0.8297 - sensitivity_at_specificity: 0.9737 - specificity_at_sensitivity: 0.9850 - recall: 0.8059 - precision: 0.8492 - val_loss: 0.5373 - val_accuracy: 0.7797 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8627 - val_recall: 0.8593 - val_precision: 0.7503\n",
            "Epoch 432/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3579 - accuracy: 0.8320 - sensitivity_at_specificity: 0.9606 - specificity_at_sensitivity: 0.9881 - recall: 0.8179 - precision: 0.8453\n",
            "Epoch 432: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.3579 - accuracy: 0.8320 - sensitivity_at_specificity: 0.9606 - specificity_at_sensitivity: 0.9881 - recall: 0.8179 - precision: 0.8453 - val_loss: 0.5599 - val_accuracy: 0.7703 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8253 - val_recall: 0.8468 - val_precision: 0.7516\n",
            "Epoch 433/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3485 - accuracy: 0.8309 - sensitivity_at_specificity: 0.9756 - specificity_at_sensitivity: 0.9872 - recall: 0.8229 - precision: 0.8428\n",
            "Epoch 433: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.3485 - accuracy: 0.8309 - sensitivity_at_specificity: 0.9756 - specificity_at_sensitivity: 0.9872 - recall: 0.8229 - precision: 0.8428 - val_loss: 0.5192 - val_accuracy: 0.7867 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8662 - val_recall: 0.8651 - val_precision: 0.7435\n",
            "Epoch 434/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3456 - accuracy: 0.8383 - sensitivity_at_specificity: 0.9731 - specificity_at_sensitivity: 0.9865 - recall: 0.8187 - precision: 0.8569\n",
            "Epoch 434: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.3456 - accuracy: 0.8383 - sensitivity_at_specificity: 0.9731 - specificity_at_sensitivity: 0.9865 - recall: 0.8187 - precision: 0.8569 - val_loss: 0.5852 - val_accuracy: 0.7789 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8458 - val_recall: 0.8624 - val_precision: 0.7323\n",
            "Epoch 435/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3495 - accuracy: 0.8414 - sensitivity_at_specificity: 0.9775 - specificity_at_sensitivity: 0.9827 - recall: 0.8205 - precision: 0.8578\n",
            "Epoch 435: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.3495 - accuracy: 0.8414 - sensitivity_at_specificity: 0.9775 - specificity_at_sensitivity: 0.9827 - recall: 0.8205 - precision: 0.8578 - val_loss: 0.5167 - val_accuracy: 0.7906 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8872 - val_recall: 0.9022 - val_precision: 0.7312\n",
            "Epoch 436/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3174 - accuracy: 0.8543 - sensitivity_at_specificity: 0.9875 - specificity_at_sensitivity: 0.9899 - recall: 0.8559 - precision: 0.8526\n",
            "Epoch 436: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.3174 - accuracy: 0.8543 - sensitivity_at_specificity: 0.9875 - specificity_at_sensitivity: 0.9899 - recall: 0.8559 - precision: 0.8526 - val_loss: 0.5876 - val_accuracy: 0.7648 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8303 - val_recall: 0.8626 - val_precision: 0.7152\n",
            "Epoch 437/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3461 - accuracy: 0.8379 - sensitivity_at_specificity: 0.9729 - specificity_at_sensitivity: 0.9885 - recall: 0.8223 - precision: 0.8431\n",
            "Epoch 437: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.3461 - accuracy: 0.8379 - sensitivity_at_specificity: 0.9729 - specificity_at_sensitivity: 0.9885 - recall: 0.8223 - precision: 0.8431 - val_loss: 0.5276 - val_accuracy: 0.7852 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8702 - val_recall: 0.8910 - val_precision: 0.7325\n",
            "Epoch 438/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3417 - accuracy: 0.8406 - sensitivity_at_specificity: 0.9719 - specificity_at_sensitivity: 0.9930 - recall: 0.8430 - precision: 0.8390\n",
            "Epoch 438: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.3417 - accuracy: 0.8406 - sensitivity_at_specificity: 0.9719 - specificity_at_sensitivity: 0.9930 - recall: 0.8430 - precision: 0.8390 - val_loss: 0.5661 - val_accuracy: 0.7609 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8434 - val_recall: 0.8364 - val_precision: 0.7305\n",
            "Epoch 439/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3440 - accuracy: 0.8445 - sensitivity_at_specificity: 0.9675 - specificity_at_sensitivity: 0.9858 - recall: 0.8073 - precision: 0.8750\n",
            "Epoch 439: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.3440 - accuracy: 0.8445 - sensitivity_at_specificity: 0.9675 - specificity_at_sensitivity: 0.9858 - recall: 0.8073 - precision: 0.8750 - val_loss: 0.4994 - val_accuracy: 0.7750 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8850 - val_recall: 0.8583 - val_precision: 0.7304\n",
            "Epoch 440/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3498 - accuracy: 0.8398 - sensitivity_at_specificity: 0.9780 - specificity_at_sensitivity: 0.9853 - recall: 0.8261 - precision: 0.8475\n",
            "Epoch 440: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 174ms/step - loss: 0.3498 - accuracy: 0.8398 - sensitivity_at_specificity: 0.9780 - specificity_at_sensitivity: 0.9853 - recall: 0.8261 - precision: 0.8475 - val_loss: 0.5569 - val_accuracy: 0.7516 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8547 - val_recall: 0.8357 - val_precision: 0.7120\n",
            "Epoch 441/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3377 - accuracy: 0.8398 - sensitivity_at_specificity: 0.9775 - specificity_at_sensitivity: 0.9901 - recall: 0.8209 - precision: 0.8453\n",
            "Epoch 441: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 176ms/step - loss: 0.3377 - accuracy: 0.8398 - sensitivity_at_specificity: 0.9775 - specificity_at_sensitivity: 0.9901 - recall: 0.8209 - precision: 0.8453 - val_loss: 0.5308 - val_accuracy: 0.7688 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8609 - val_recall: 0.8344 - val_precision: 0.7376\n",
            "Epoch 442/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3539 - accuracy: 0.8371 - sensitivity_at_specificity: 0.9752 - specificity_at_sensitivity: 0.9819 - recall: 0.8287 - precision: 0.8451\n",
            "Epoch 442: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.3539 - accuracy: 0.8371 - sensitivity_at_specificity: 0.9752 - specificity_at_sensitivity: 0.9819 - recall: 0.8287 - precision: 0.8451 - val_loss: 0.5147 - val_accuracy: 0.7672 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8604 - val_recall: 0.8360 - val_precision: 0.7292\n",
            "Epoch 443/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3773 - accuracy: 0.8117 - sensitivity_at_specificity: 0.9616 - specificity_at_sensitivity: 0.9825 - recall: 0.7942 - precision: 0.8285\n",
            "Epoch 443: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.3773 - accuracy: 0.8117 - sensitivity_at_specificity: 0.9616 - specificity_at_sensitivity: 0.9825 - recall: 0.7942 - precision: 0.8285 - val_loss: 0.5967 - val_accuracy: 0.7594 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8137 - val_recall: 0.8960 - val_precision: 0.6974\n",
            "Epoch 444/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3691 - accuracy: 0.8230 - sensitivity_at_specificity: 0.9583 - specificity_at_sensitivity: 0.9882 - recall: 0.7921 - precision: 0.8478\n",
            "Epoch 444: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.3691 - accuracy: 0.8230 - sensitivity_at_specificity: 0.9583 - specificity_at_sensitivity: 0.9882 - recall: 0.7921 - precision: 0.8478 - val_loss: 0.5388 - val_accuracy: 0.7977 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8491 - val_recall: 0.9255 - val_precision: 0.7385\n",
            "Epoch 445/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3392 - accuracy: 0.8305 - sensitivity_at_specificity: 0.9745 - specificity_at_sensitivity: 0.9889 - recall: 0.8161 - precision: 0.8435\n",
            "Epoch 445: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.3392 - accuracy: 0.8305 - sensitivity_at_specificity: 0.9745 - specificity_at_sensitivity: 0.9889 - recall: 0.8161 - precision: 0.8435 - val_loss: 0.5454 - val_accuracy: 0.7844 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8458 - val_recall: 0.8720 - val_precision: 0.7355\n",
            "Epoch 446/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3339 - accuracy: 0.8461 - sensitivity_at_specificity: 0.9774 - specificity_at_sensitivity: 0.9898 - recall: 0.8329 - precision: 0.8557\n",
            "Epoch 446: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.3339 - accuracy: 0.8461 - sensitivity_at_specificity: 0.9774 - specificity_at_sensitivity: 0.9898 - recall: 0.8329 - precision: 0.8557 - val_loss: 0.5635 - val_accuracy: 0.7883 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8750 - val_recall: 0.8817 - val_precision: 0.7257\n",
            "Epoch 447/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3275 - accuracy: 0.8380 - sensitivity_at_specificity: 0.9802 - specificity_at_sensitivity: 0.9967 - recall: 0.8160 - precision: 0.8555\n",
            "Epoch 447: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.3275 - accuracy: 0.8380 - sensitivity_at_specificity: 0.9802 - specificity_at_sensitivity: 0.9967 - recall: 0.8160 - precision: 0.8555 - val_loss: 0.6025 - val_accuracy: 0.7719 - val_sensitivity_at_specificity: 0.9983 - val_specificity_at_sensitivity: 0.8567 - val_recall: 0.8955 - val_precision: 0.7022\n",
            "Epoch 448/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3237 - accuracy: 0.8543 - sensitivity_at_specificity: 0.9747 - specificity_at_sensitivity: 0.9918 - recall: 0.8307 - precision: 0.8596\n",
            "Epoch 448: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.3237 - accuracy: 0.8543 - sensitivity_at_specificity: 0.9747 - specificity_at_sensitivity: 0.9918 - recall: 0.8307 - precision: 0.8596 - val_loss: 0.6486 - val_accuracy: 0.7617 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.8315 - val_recall: 0.8641 - val_precision: 0.7141\n",
            "Epoch 449/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3410 - accuracy: 0.8434 - sensitivity_at_specificity: 0.9777 - specificity_at_sensitivity: 0.9905 - recall: 0.8291 - precision: 0.8575\n",
            "Epoch 449: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.3410 - accuracy: 0.8434 - sensitivity_at_specificity: 0.9777 - specificity_at_sensitivity: 0.9905 - recall: 0.8291 - precision: 0.8575 - val_loss: 0.6439 - val_accuracy: 0.7609 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8157 - val_recall: 0.8841 - val_precision: 0.7160\n",
            "Epoch 450/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3383 - accuracy: 0.8477 - sensitivity_at_specificity: 0.9769 - specificity_at_sensitivity: 0.9897 - recall: 0.8351 - precision: 0.8603\n",
            "Epoch 450: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.3383 - accuracy: 0.8477 - sensitivity_at_specificity: 0.9769 - specificity_at_sensitivity: 0.9897 - recall: 0.8351 - precision: 0.8603 - val_loss: 0.5587 - val_accuracy: 0.7742 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8350 - val_recall: 0.8837 - val_precision: 0.7340\n",
            "Epoch 451/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3248 - accuracy: 0.8480 - sensitivity_at_specificity: 0.9815 - specificity_at_sensitivity: 0.9894 - recall: 0.8418 - precision: 0.8452\n",
            "Epoch 451: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.3248 - accuracy: 0.8480 - sensitivity_at_specificity: 0.9815 - specificity_at_sensitivity: 0.9894 - recall: 0.8418 - precision: 0.8452 - val_loss: 0.5514 - val_accuracy: 0.7625 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8364 - val_recall: 0.8195 - val_precision: 0.7287\n",
            "Epoch 452/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3430 - accuracy: 0.8324 - sensitivity_at_specificity: 0.9764 - specificity_at_sensitivity: 0.9892 - recall: 0.8180 - precision: 0.8398\n",
            "Epoch 452: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 188ms/step - loss: 0.3430 - accuracy: 0.8324 - sensitivity_at_specificity: 0.9764 - specificity_at_sensitivity: 0.9892 - recall: 0.8180 - precision: 0.8398 - val_loss: 0.5237 - val_accuracy: 0.7750 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8734 - val_recall: 0.8375 - val_precision: 0.7444\n",
            "Epoch 453/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3293 - accuracy: 0.8457 - sensitivity_at_specificity: 0.9801 - specificity_at_sensitivity: 0.9893 - recall: 0.8178 - precision: 0.8610\n",
            "Epoch 453: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 214ms/step - loss: 0.3293 - accuracy: 0.8457 - sensitivity_at_specificity: 0.9801 - specificity_at_sensitivity: 0.9893 - recall: 0.8178 - precision: 0.8610 - val_loss: 0.5653 - val_accuracy: 0.7859 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8399 - val_recall: 0.8507 - val_precision: 0.7545\n",
            "Epoch 454/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3350 - accuracy: 0.8434 - sensitivity_at_specificity: 0.9792 - specificity_at_sensitivity: 0.9937 - recall: 0.8238 - precision: 0.8616\n",
            "Epoch 454: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.3350 - accuracy: 0.8434 - sensitivity_at_specificity: 0.9792 - specificity_at_sensitivity: 0.9937 - recall: 0.8238 - precision: 0.8616 - val_loss: 0.5886 - val_accuracy: 0.7891 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8401 - val_recall: 0.8614 - val_precision: 0.7534\n",
            "Epoch 455/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3470 - accuracy: 0.8430 - sensitivity_at_specificity: 0.9704 - specificity_at_sensitivity: 0.9906 - recall: 0.8326 - precision: 0.8511\n",
            "Epoch 455: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 189ms/step - loss: 0.3470 - accuracy: 0.8430 - sensitivity_at_specificity: 0.9704 - specificity_at_sensitivity: 0.9906 - recall: 0.8326 - precision: 0.8511 - val_loss: 0.5980 - val_accuracy: 0.7648 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8161 - val_recall: 0.8826 - val_precision: 0.7066\n",
            "Epoch 456/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3310 - accuracy: 0.8500 - sensitivity_at_specificity: 0.9762 - specificity_at_sensitivity: 0.9904 - recall: 0.8528 - precision: 0.8528\n",
            "Epoch 456: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 175ms/step - loss: 0.3310 - accuracy: 0.8500 - sensitivity_at_specificity: 0.9762 - specificity_at_sensitivity: 0.9904 - recall: 0.8528 - precision: 0.8528 - val_loss: 0.5458 - val_accuracy: 0.7867 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8430 - val_recall: 0.8771 - val_precision: 0.7441\n",
            "Epoch 457/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3345 - accuracy: 0.8492 - sensitivity_at_specificity: 0.9785 - specificity_at_sensitivity: 0.9905 - recall: 0.8427 - precision: 0.8585\n",
            "Epoch 457: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.3345 - accuracy: 0.8492 - sensitivity_at_specificity: 0.9785 - specificity_at_sensitivity: 0.9905 - recall: 0.8427 - precision: 0.8585 - val_loss: 0.5520 - val_accuracy: 0.7766 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8325 - val_recall: 0.8887 - val_precision: 0.7360\n",
            "Epoch 458/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3325 - accuracy: 0.8422 - sensitivity_at_specificity: 0.9784 - specificity_at_sensitivity: 0.9901 - recall: 0.8296 - precision: 0.8445\n",
            "Epoch 458: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.3325 - accuracy: 0.8422 - sensitivity_at_specificity: 0.9784 - specificity_at_sensitivity: 0.9901 - recall: 0.8296 - precision: 0.8445 - val_loss: 0.5802 - val_accuracy: 0.7758 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8482 - val_recall: 0.8455 - val_precision: 0.7365\n",
            "Epoch 459/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3159 - accuracy: 0.8574 - sensitivity_at_specificity: 0.9753 - specificity_at_sensitivity: 0.9921 - recall: 0.8236 - precision: 0.8871\n",
            "Epoch 459: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.3159 - accuracy: 0.8574 - sensitivity_at_specificity: 0.9753 - specificity_at_sensitivity: 0.9921 - recall: 0.8236 - precision: 0.8871 - val_loss: 0.5747 - val_accuracy: 0.7766 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8705 - val_recall: 0.8795 - val_precision: 0.7289\n",
            "Epoch 460/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2973 - accuracy: 0.8695 - sensitivity_at_specificity: 0.9876 - specificity_at_sensitivity: 0.9945 - recall: 0.8595 - precision: 0.8786\n",
            "Epoch 460: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 174ms/step - loss: 0.2973 - accuracy: 0.8695 - sensitivity_at_specificity: 0.9876 - specificity_at_sensitivity: 0.9945 - recall: 0.8595 - precision: 0.8786 - val_loss: 0.5536 - val_accuracy: 0.7633 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8673 - val_recall: 0.8465 - val_precision: 0.7220\n",
            "Epoch 461/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3081 - accuracy: 0.8648 - sensitivity_at_specificity: 0.9851 - specificity_at_sensitivity: 0.9901 - recall: 0.8815 - precision: 0.8635\n",
            "Epoch 461: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.3081 - accuracy: 0.8648 - sensitivity_at_specificity: 0.9851 - specificity_at_sensitivity: 0.9901 - recall: 0.8815 - precision: 0.8635 - val_loss: 0.5191 - val_accuracy: 0.7875 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8647 - val_recall: 0.8732 - val_precision: 0.7346\n",
            "Epoch 462/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3029 - accuracy: 0.8598 - sensitivity_at_specificity: 0.9904 - specificity_at_sensitivity: 0.9954 - recall: 0.8382 - precision: 0.8709\n",
            "Epoch 462: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.3029 - accuracy: 0.8598 - sensitivity_at_specificity: 0.9904 - specificity_at_sensitivity: 0.9954 - recall: 0.8382 - precision: 0.8709 - val_loss: 0.5762 - val_accuracy: 0.7797 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8339 - val_recall: 0.8561 - val_precision: 0.7513\n",
            "Epoch 463/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3265 - accuracy: 0.8463 - sensitivity_at_specificity: 0.9796 - specificity_at_sensitivity: 0.9938 - recall: 0.8359 - precision: 0.8687\n",
            "Epoch 463: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.3265 - accuracy: 0.8463 - sensitivity_at_specificity: 0.9796 - specificity_at_sensitivity: 0.9938 - recall: 0.8359 - precision: 0.8687 - val_loss: 0.5471 - val_accuracy: 0.7883 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8569 - val_recall: 0.8869 - val_precision: 0.7535\n",
            "Epoch 464/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3112 - accuracy: 0.8629 - sensitivity_at_specificity: 0.9784 - specificity_at_sensitivity: 0.9913 - recall: 0.8486 - precision: 0.8764\n",
            "Epoch 464: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.3112 - accuracy: 0.8629 - sensitivity_at_specificity: 0.9784 - specificity_at_sensitivity: 0.9913 - recall: 0.8486 - precision: 0.8764 - val_loss: 0.5973 - val_accuracy: 0.7875 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8257 - val_recall: 0.9067 - val_precision: 0.7333\n",
            "Epoch 465/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3345 - accuracy: 0.8441 - sensitivity_at_specificity: 0.9775 - specificity_at_sensitivity: 0.9898 - recall: 0.8317 - precision: 0.8549\n",
            "Epoch 465: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.3345 - accuracy: 0.8441 - sensitivity_at_specificity: 0.9775 - specificity_at_sensitivity: 0.9898 - recall: 0.8317 - precision: 0.8549 - val_loss: 0.5308 - val_accuracy: 0.7859 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 0.8662 - val_recall: 0.8891 - val_precision: 0.7478\n",
            "Epoch 466/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3319 - accuracy: 0.8434 - sensitivity_at_specificity: 0.9791 - specificity_at_sensitivity: 0.9921 - recall: 0.8516 - precision: 0.8406\n",
            "Epoch 466: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.3319 - accuracy: 0.8434 - sensitivity_at_specificity: 0.9791 - specificity_at_sensitivity: 0.9921 - recall: 0.8516 - precision: 0.8406 - val_loss: 0.5929 - val_accuracy: 0.7570 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.8385 - val_recall: 0.8553 - val_precision: 0.7130\n",
            "Epoch 467/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2994 - accuracy: 0.8602 - sensitivity_at_specificity: 0.9833 - specificity_at_sensitivity: 0.9946 - recall: 0.8408 - precision: 0.8699\n",
            "Epoch 467: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.2994 - accuracy: 0.8602 - sensitivity_at_specificity: 0.9833 - specificity_at_sensitivity: 0.9946 - recall: 0.8408 - precision: 0.8699 - val_loss: 0.6169 - val_accuracy: 0.7766 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8250 - val_recall: 0.8767 - val_precision: 0.7375\n",
            "Epoch 468/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3119 - accuracy: 0.8605 - sensitivity_at_specificity: 0.9826 - specificity_at_sensitivity: 0.9911 - recall: 0.8552 - precision: 0.8717\n",
            "Epoch 468: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.3119 - accuracy: 0.8605 - sensitivity_at_specificity: 0.9826 - specificity_at_sensitivity: 0.9911 - recall: 0.8552 - precision: 0.8717 - val_loss: 0.5183 - val_accuracy: 0.7781 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8492 - val_recall: 0.8612 - val_precision: 0.7513\n",
            "Epoch 469/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3111 - accuracy: 0.8621 - sensitivity_at_specificity: 0.9842 - specificity_at_sensitivity: 0.9938 - recall: 0.8508 - precision: 0.8680\n",
            "Epoch 469: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.3111 - accuracy: 0.8621 - sensitivity_at_specificity: 0.9842 - specificity_at_sensitivity: 0.9938 - recall: 0.8508 - precision: 0.8680 - val_loss: 0.5208 - val_accuracy: 0.8008 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8766 - val_recall: 0.8958 - val_precision: 0.7649\n",
            "Epoch 470/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3056 - accuracy: 0.8605 - sensitivity_at_specificity: 0.9844 - specificity_at_sensitivity: 0.9945 - recall: 0.8445 - precision: 0.8725\n",
            "Epoch 470: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 177ms/step - loss: 0.3056 - accuracy: 0.8605 - sensitivity_at_specificity: 0.9844 - specificity_at_sensitivity: 0.9945 - recall: 0.8445 - precision: 0.8725 - val_loss: 0.6135 - val_accuracy: 0.7734 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8505 - val_recall: 0.8791 - val_precision: 0.7413\n",
            "Epoch 471/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3201 - accuracy: 0.8535 - sensitivity_at_specificity: 0.9794 - specificity_at_sensitivity: 0.9892 - recall: 0.8216 - precision: 0.8735\n",
            "Epoch 471: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.3201 - accuracy: 0.8535 - sensitivity_at_specificity: 0.9794 - specificity_at_sensitivity: 0.9892 - recall: 0.8216 - precision: 0.8735 - val_loss: 0.5648 - val_accuracy: 0.7758 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8395 - val_recall: 0.8904 - val_precision: 0.7312\n",
            "Epoch 472/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3116 - accuracy: 0.8551 - sensitivity_at_specificity: 0.9829 - specificity_at_sensitivity: 0.9976 - recall: 0.8523 - precision: 0.8583\n",
            "Epoch 472: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 174ms/step - loss: 0.3116 - accuracy: 0.8551 - sensitivity_at_specificity: 0.9829 - specificity_at_sensitivity: 0.9976 - recall: 0.8523 - precision: 0.8583 - val_loss: 0.5715 - val_accuracy: 0.7758 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8222 - val_recall: 0.8741 - val_precision: 0.7417\n",
            "Epoch 473/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3270 - accuracy: 0.8590 - sensitivity_at_specificity: 0.9715 - specificity_at_sensitivity: 0.9923 - recall: 0.8263 - precision: 0.8801\n",
            "Epoch 473: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.3270 - accuracy: 0.8590 - sensitivity_at_specificity: 0.9715 - specificity_at_sensitivity: 0.9923 - recall: 0.8263 - precision: 0.8801 - val_loss: 0.5669 - val_accuracy: 0.7695 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.8544 - val_recall: 0.8436 - val_precision: 0.7225\n",
            "Epoch 474/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3093 - accuracy: 0.8598 - sensitivity_at_specificity: 0.9886 - specificity_at_sensitivity: 0.9912 - recall: 0.8337 - precision: 0.8857\n",
            "Epoch 474: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.3093 - accuracy: 0.8598 - sensitivity_at_specificity: 0.9886 - specificity_at_sensitivity: 0.9912 - recall: 0.8337 - precision: 0.8857 - val_loss: 0.5468 - val_accuracy: 0.7883 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 0.8435 - val_recall: 0.8848 - val_precision: 0.7497\n",
            "Epoch 475/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3100 - accuracy: 0.8566 - sensitivity_at_specificity: 0.9788 - specificity_at_sensitivity: 0.9968 - recall: 0.8569 - precision: 0.8641\n",
            "Epoch 475: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 174ms/step - loss: 0.3100 - accuracy: 0.8566 - sensitivity_at_specificity: 0.9788 - specificity_at_sensitivity: 0.9968 - recall: 0.8569 - precision: 0.8641 - val_loss: 0.6080 - val_accuracy: 0.7703 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8576 - val_recall: 0.9070 - val_precision: 0.7011\n",
            "Epoch 476/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3132 - accuracy: 0.8562 - sensitivity_at_specificity: 0.9797 - specificity_at_sensitivity: 0.9898 - recall: 0.8376 - precision: 0.8702\n",
            "Epoch 476: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 174ms/step - loss: 0.3132 - accuracy: 0.8562 - sensitivity_at_specificity: 0.9797 - specificity_at_sensitivity: 0.9898 - recall: 0.8376 - precision: 0.8702 - val_loss: 0.5880 - val_accuracy: 0.7766 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8475 - val_recall: 0.8602 - val_precision: 0.7387\n",
            "Epoch 477/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3069 - accuracy: 0.8645 - sensitivity_at_specificity: 0.9810 - specificity_at_sensitivity: 0.9954 - recall: 0.8389 - precision: 0.8813\n",
            "Epoch 477: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.3069 - accuracy: 0.8645 - sensitivity_at_specificity: 0.9810 - specificity_at_sensitivity: 0.9954 - recall: 0.8389 - precision: 0.8813 - val_loss: 0.5072 - val_accuracy: 0.7953 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8762 - val_recall: 0.8769 - val_precision: 0.7547\n",
            "Epoch 478/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3128 - accuracy: 0.8605 - sensitivity_at_specificity: 0.9820 - specificity_at_sensitivity: 0.9899 - recall: 0.8478 - precision: 0.8690\n",
            "Epoch 478: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.3128 - accuracy: 0.8605 - sensitivity_at_specificity: 0.9820 - specificity_at_sensitivity: 0.9899 - recall: 0.8478 - precision: 0.8690 - val_loss: 0.5850 - val_accuracy: 0.7758 - val_sensitivity_at_specificity: 0.9968 - val_specificity_at_sensitivity: 0.8604 - val_recall: 0.8631 - val_precision: 0.7295\n",
            "Epoch 479/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3126 - accuracy: 0.8578 - sensitivity_at_specificity: 0.9868 - specificity_at_sensitivity: 0.9937 - recall: 0.8392 - precision: 0.8731\n",
            "Epoch 479: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.3126 - accuracy: 0.8578 - sensitivity_at_specificity: 0.9868 - specificity_at_sensitivity: 0.9937 - recall: 0.8392 - precision: 0.8731 - val_loss: 0.5255 - val_accuracy: 0.7977 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 0.8710 - val_recall: 0.8742 - val_precision: 0.7631\n",
            "Epoch 480/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3109 - accuracy: 0.8676 - sensitivity_at_specificity: 0.9811 - specificity_at_sensitivity: 0.9922 - recall: 0.8726 - precision: 0.8625\n",
            "Epoch 480: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.3109 - accuracy: 0.8676 - sensitivity_at_specificity: 0.9811 - specificity_at_sensitivity: 0.9922 - recall: 0.8726 - precision: 0.8625 - val_loss: 0.6072 - val_accuracy: 0.7797 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8592 - val_recall: 0.9033 - val_precision: 0.7247\n",
            "Epoch 481/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3116 - accuracy: 0.8578 - sensitivity_at_specificity: 0.9822 - specificity_at_sensitivity: 0.9937 - recall: 0.8360 - precision: 0.8767\n",
            "Epoch 481: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.3116 - accuracy: 0.8578 - sensitivity_at_specificity: 0.9822 - specificity_at_sensitivity: 0.9937 - recall: 0.8360 - precision: 0.8767 - val_loss: 0.5682 - val_accuracy: 0.7883 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8511 - val_recall: 0.9236 - val_precision: 0.7172\n",
            "Epoch 482/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3094 - accuracy: 0.8574 - sensitivity_at_specificity: 0.9841 - specificity_at_sensitivity: 0.9939 - recall: 0.8400 - precision: 0.8655\n",
            "Epoch 482: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 177ms/step - loss: 0.3094 - accuracy: 0.8574 - sensitivity_at_specificity: 0.9841 - specificity_at_sensitivity: 0.9939 - recall: 0.8400 - precision: 0.8655 - val_loss: 0.5332 - val_accuracy: 0.7750 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8613 - val_recall: 0.8291 - val_precision: 0.7607\n",
            "Epoch 483/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3218 - accuracy: 0.8578 - sensitivity_at_specificity: 0.9728 - specificity_at_sensitivity: 0.9903 - recall: 0.8427 - precision: 0.8554\n",
            "Epoch 483: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.3218 - accuracy: 0.8578 - sensitivity_at_specificity: 0.9728 - specificity_at_sensitivity: 0.9903 - recall: 0.8427 - precision: 0.8554 - val_loss: 0.5902 - val_accuracy: 0.7773 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8464 - val_recall: 0.8919 - val_precision: 0.7211\n",
            "Epoch 484/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2989 - accuracy: 0.8605 - sensitivity_at_specificity: 0.9868 - specificity_at_sensitivity: 0.9941 - recall: 0.8261 - precision: 0.8728\n",
            "Epoch 484: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.2989 - accuracy: 0.8605 - sensitivity_at_specificity: 0.9868 - specificity_at_sensitivity: 0.9941 - recall: 0.8261 - precision: 0.8728 - val_loss: 0.5785 - val_accuracy: 0.7641 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 0.8519 - val_recall: 0.8788 - val_precision: 0.7198\n",
            "Epoch 485/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2732 - accuracy: 0.8750 - sensitivity_at_specificity: 0.9851 - specificity_at_sensitivity: 0.9977 - recall: 0.8640 - precision: 0.8833\n",
            "Epoch 485: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 174ms/step - loss: 0.2732 - accuracy: 0.8750 - sensitivity_at_specificity: 0.9851 - specificity_at_sensitivity: 0.9977 - recall: 0.8640 - precision: 0.8833 - val_loss: 0.5606 - val_accuracy: 0.7875 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8625 - val_recall: 0.8938 - val_precision: 0.7371\n",
            "Epoch 486/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3089 - accuracy: 0.8574 - sensitivity_at_specificity: 0.9791 - specificity_at_sensitivity: 0.9929 - recall: 0.8605 - precision: 0.8571\n",
            "Epoch 486: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.3089 - accuracy: 0.8574 - sensitivity_at_specificity: 0.9791 - specificity_at_sensitivity: 0.9929 - recall: 0.8605 - precision: 0.8571 - val_loss: 0.5549 - val_accuracy: 0.7750 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8899 - val_recall: 0.8571 - val_precision: 0.7380\n",
            "Epoch 487/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3125 - accuracy: 0.8605 - sensitivity_at_specificity: 0.9807 - specificity_at_sensitivity: 0.9934 - recall: 0.8228 - precision: 0.8869\n",
            "Epoch 487: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 174ms/step - loss: 0.3125 - accuracy: 0.8605 - sensitivity_at_specificity: 0.9807 - specificity_at_sensitivity: 0.9934 - recall: 0.8228 - precision: 0.8869 - val_loss: 0.5468 - val_accuracy: 0.8016 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8588 - val_recall: 0.8976 - val_precision: 0.7621\n",
            "Epoch 488/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3072 - accuracy: 0.8570 - sensitivity_at_specificity: 0.9867 - specificity_at_sensitivity: 0.9961 - recall: 0.8519 - precision: 0.8613\n",
            "Epoch 488: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.3072 - accuracy: 0.8570 - sensitivity_at_specificity: 0.9867 - specificity_at_sensitivity: 0.9961 - recall: 0.8519 - precision: 0.8613 - val_loss: 0.5451 - val_accuracy: 0.7852 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8631 - val_recall: 0.8756 - val_precision: 0.7494\n",
            "Epoch 489/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2903 - accuracy: 0.8645 - sensitivity_at_specificity: 0.9842 - specificity_at_sensitivity: 0.9938 - recall: 0.8541 - precision: 0.8699\n",
            "Epoch 489: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.2903 - accuracy: 0.8645 - sensitivity_at_specificity: 0.9842 - specificity_at_sensitivity: 0.9938 - recall: 0.8541 - precision: 0.8699 - val_loss: 0.5123 - val_accuracy: 0.7914 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8692 - val_recall: 0.8652 - val_precision: 0.7594\n",
            "Epoch 490/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2992 - accuracy: 0.8687 - sensitivity_at_specificity: 0.9883 - specificity_at_sensitivity: 0.9937 - recall: 0.8576 - precision: 0.8781\n",
            "Epoch 490: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 185ms/step - loss: 0.2992 - accuracy: 0.8687 - sensitivity_at_specificity: 0.9883 - specificity_at_sensitivity: 0.9937 - recall: 0.8576 - precision: 0.8781 - val_loss: 0.6457 - val_accuracy: 0.7773 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 0.8190 - val_recall: 0.8785 - val_precision: 0.7349\n",
            "Epoch 491/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3120 - accuracy: 0.8723 - sensitivity_at_specificity: 0.9763 - specificity_at_sensitivity: 0.9923 - recall: 0.8431 - precision: 0.8931\n",
            "Epoch 491: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.3120 - accuracy: 0.8723 - sensitivity_at_specificity: 0.9763 - specificity_at_sensitivity: 0.9923 - recall: 0.8431 - precision: 0.8931 - val_loss: 0.6210 - val_accuracy: 0.7844 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8545 - val_recall: 0.9452 - val_precision: 0.7077\n",
            "Epoch 492/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2983 - accuracy: 0.8691 - sensitivity_at_specificity: 0.9849 - specificity_at_sensitivity: 0.9911 - recall: 0.8604 - precision: 0.8837\n",
            "Epoch 492: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.2983 - accuracy: 0.8691 - sensitivity_at_specificity: 0.9849 - specificity_at_sensitivity: 0.9911 - recall: 0.8604 - precision: 0.8837 - val_loss: 0.5991 - val_accuracy: 0.7805 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8634 - val_recall: 0.9098 - val_precision: 0.7240\n",
            "Epoch 493/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3001 - accuracy: 0.8605 - sensitivity_at_specificity: 0.9858 - specificity_at_sensitivity: 0.9884 - recall: 0.8460 - precision: 0.8686\n",
            "Epoch 493: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.3001 - accuracy: 0.8605 - sensitivity_at_specificity: 0.9858 - specificity_at_sensitivity: 0.9884 - recall: 0.8460 - precision: 0.8686 - val_loss: 0.6139 - val_accuracy: 0.7727 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 0.8468 - val_recall: 0.8934 - val_precision: 0.7225\n",
            "Epoch 494/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2833 - accuracy: 0.8777 - sensitivity_at_specificity: 0.9874 - specificity_at_sensitivity: 0.9938 - recall: 0.8748 - precision: 0.8783\n",
            "Epoch 494: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.2833 - accuracy: 0.8777 - sensitivity_at_specificity: 0.9874 - specificity_at_sensitivity: 0.9938 - recall: 0.8748 - precision: 0.8783 - val_loss: 0.5984 - val_accuracy: 0.7773 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8630 - val_recall: 0.9025 - val_precision: 0.7324\n",
            "Epoch 495/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2978 - accuracy: 0.8703 - sensitivity_at_specificity: 0.9866 - specificity_at_sensitivity: 0.9954 - recall: 0.8507 - precision: 0.8828\n",
            "Epoch 495: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.2978 - accuracy: 0.8703 - sensitivity_at_specificity: 0.9866 - specificity_at_sensitivity: 0.9954 - recall: 0.8507 - precision: 0.8828 - val_loss: 0.6058 - val_accuracy: 0.7852 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8696 - val_recall: 0.9186 - val_precision: 0.7293\n",
            "Epoch 496/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3126 - accuracy: 0.8547 - sensitivity_at_specificity: 0.9855 - specificity_at_sensitivity: 0.9920 - recall: 0.8496 - precision: 0.8641\n",
            "Epoch 496: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 175ms/step - loss: 0.3126 - accuracy: 0.8547 - sensitivity_at_specificity: 0.9855 - specificity_at_sensitivity: 0.9920 - recall: 0.8496 - precision: 0.8641 - val_loss: 0.6046 - val_accuracy: 0.7734 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.8600 - val_recall: 0.8778 - val_precision: 0.7219\n",
            "Epoch 497/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2943 - accuracy: 0.8656 - sensitivity_at_specificity: 0.9815 - specificity_at_sensitivity: 0.9954 - recall: 0.8529 - precision: 0.8682\n",
            "Epoch 497: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.2943 - accuracy: 0.8656 - sensitivity_at_specificity: 0.9815 - specificity_at_sensitivity: 0.9954 - recall: 0.8529 - precision: 0.8682 - val_loss: 0.6005 - val_accuracy: 0.7672 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 0.8460 - val_recall: 0.8523 - val_precision: 0.7328\n",
            "Epoch 498/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2836 - accuracy: 0.8789 - sensitivity_at_specificity: 0.9868 - specificity_at_sensitivity: 0.9945 - recall: 0.8649 - precision: 0.8912\n",
            "Epoch 498: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.2836 - accuracy: 0.8789 - sensitivity_at_specificity: 0.9868 - specificity_at_sensitivity: 0.9945 - recall: 0.8649 - precision: 0.8912 - val_loss: 0.6164 - val_accuracy: 0.7898 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8614 - val_recall: 0.9028 - val_precision: 0.7356\n",
            "Epoch 499/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3010 - accuracy: 0.8667 - sensitivity_at_specificity: 0.9810 - specificity_at_sensitivity: 0.9967 - recall: 0.8425 - precision: 0.8872\n",
            "Epoch 499: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 185ms/step - loss: 0.3010 - accuracy: 0.8667 - sensitivity_at_specificity: 0.9810 - specificity_at_sensitivity: 0.9967 - recall: 0.8425 - precision: 0.8872 - val_loss: 0.5596 - val_accuracy: 0.7805 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8616 - val_recall: 0.8854 - val_precision: 0.7306\n",
            "Epoch 500/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2957 - accuracy: 0.8680 - sensitivity_at_specificity: 0.9880 - specificity_at_sensitivity: 0.9954 - recall: 0.8675 - precision: 0.8634\n",
            "Epoch 500: val_accuracy did not improve from 0.82344\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.2957 - accuracy: 0.8680 - sensitivity_at_specificity: 0.9880 - specificity_at_sensitivity: 0.9954 - recall: 0.8675 - precision: 0.8634 - val_loss: 0.5895 - val_accuracy: 0.7563 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8474 - val_recall: 0.8433 - val_precision: 0.7233\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Performance Metrics**"
      ],
      "metadata": {
        "id": "otAo_geEHXYG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Training_Accuracy=history.history['accuracy']\n",
        "Validation_Accuracy=history.history['val_accuracy']\n",
        "Validation_Specificity=history.history['val_specificity_at_sensitivity']\n",
        "Validation_Sensitivity=history.history['val_sensitivity_at_specificity']\n",
        "Validation_Recall=history.history['val_recall']\n",
        "Validation_Precision=history.history['val_precision']\n",
        "Validation_Loss=history.history['val_loss']\n",
        "\n",
        "print(\"Training Accuracy: \",max(Training_Accuracy))\n",
        "print(\"Validation Accuracy: \",max(Validation_Accuracy))\n",
        "print(\"Validation Specificity: \",max(Validation_Specificity))\n",
        "print(\"Validation Sensitivity: \",max(Validation_Sensitivity))\n",
        "print(\"Validation Recall: \",max(Validation_Recall))\n",
        "print(\"Validation Precision: \",max(Validation_Precision))\n",
        "print(\"Validation Loss: \",min(Validation_Loss))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCdS_0U65A0-",
        "outputId": "539cb928-6a95-4998-c78f-c2cd41de1539"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy:  0.87890625\n",
            "Validation Accuracy:  0.823437511920929\n",
            "Validation Specificity:  0.9086687564849854\n",
            "Validation Sensitivity:  1.0\n",
            "Validation Recall:  1.0\n",
            "Validation Precision:  0.8222621083259583\n",
            "Validation Loss:  0.40809646248817444\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Accuracy Graph**"
      ],
      "metadata": {
        "id": "q2fQBVlVHZow"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLqjG2X-vdLj",
        "outputId": "d10203e0-1e7c-4afe-c3d3-c1a83e1c25eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        }
      },
      "source": [
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loss Graph**"
      ],
      "metadata": {
        "id": "_n4g31YyHbm4"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBSAyVfivvHX",
        "outputId": "ac7aea02-5ba8-4058-b353-5c85038fa194",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        }
      },
      "source": [
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}