{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "7e88OLey6Bgd"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7e88OLey6Bgd"
      },
      "source": [
        "# **Image Classification with Convolutional Neural Networks (CNNs)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsTzc3oi726u"
      },
      "source": [
        "# **Building a Convolutional Neural Network with Keras**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import Libraries**"
      ],
      "metadata": {
        "id": "hAQPOlPJD2Il"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCglDGFy8AhT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "10bfee40-cf53-450c-9f2a-23c33e474cdd"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "tf.__version__\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import matplotlib.image as mpimg\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "import imageio\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.8.2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qf7eW3HC9XVL"
      },
      "source": [
        "**Data Acquisition and ImageDataGenerator**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0BfyGlJbx0l"
      },
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255) #Normalize the pixel values\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hsimgs7aqt6G"
      },
      "source": [
        "#File path to the folder containin images\n",
        "train_dir = os.path.join('/content/spectrograms-800/Train')\n",
        "validation_dir = os.path.join('/content/spectrograms-800/Validation')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NyvlF41oqxEP",
        "outputId": "e0f59053-57f4-4c92-8355-fd6d295f36f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(64,64),\n",
        "    batch_size=256,\n",
        "    shuffle=True,\n",
        "    class_mode='binary')\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    validation_dir,\n",
        "    target_size=(64,64),\n",
        "    batch_size=256,\n",
        "    shuffle=True,\n",
        "    class_mode='binary')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 33128 images belonging to 2 classes.\n",
            "Found 6780 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3yhwpN_-BaS"
      },
      "source": [
        "**Building the Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSzxq4KDtKN6"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "                                    \n",
        "    # First convolution layer \n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(64, 64, 3),use_bias=True),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "\n",
        "    # Second convolution layer \n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu',use_bias=True),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    \n",
        "\n",
        "    # Third convolution layer  \n",
        "    tf.keras.layers.Conv2D(256, (3,3), activation='relu',use_bias=True),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "\n",
        "  # Fourth convolution layer  \n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu',use_bias=True),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "\n",
        "\n",
        "    # Flatten the pooled feature maps\n",
        "    tf.keras.layers.Flatten(),\n",
        "\n",
        "    # Fully connected hidden layer\n",
        "    tf.keras.layers.Dense(8, activation='relu',use_bias=True),\n",
        "\n",
        "\n",
        "    # Output layer\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid',activity_regularizer=regularizers.L1(0.001))   \n",
        "\n",
        "])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDXufVt4-LFY"
      },
      "source": [
        "**Model Summary**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HU0RFGLtNJb",
        "outputId": "08c30a3c-9036-4547-f6ec-6ffdd88b7e8f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 62, 62, 64)        1792      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 31, 31, 64)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 31, 31, 64)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 29, 29, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 14, 14, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 12, 12, 256)       295168    \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 6, 6, 256)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 6, 6, 256)         0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 4, 4, 64)          147520    \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 2, 2, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 2, 2, 64)          0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 8)                 2056      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 520,401\n",
            "Trainable params: 520,401\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THk8lK3G-cdk"
      },
      "source": [
        "**Optimizer Implementation and model training/validation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBN3GBMItPMH"
      },
      "source": [
        "#from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import SensitivityAtSpecificity,SpecificityAtSensitivity,Recall,Precision\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=Adam(learning_rate=0.001),\n",
        "              metrics=['accuracy',SensitivityAtSpecificity(0.5),SpecificityAtSensitivity(0.5),Recall(0.5),Precision(0.5)])  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Q0MPMwh3EgY"
      },
      "source": [
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('val_accuracy')>0.99): \n",
        "      print(\"\\nReached 99% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "callbacks = myCallback()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7f6gDG3dx9sJ",
        "outputId": "3aa36a37-0a68-4b14-c4f0-1b646795edb2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "checkpoint = ModelCheckpoint(\"ECG_Spectrogram_Model.h5\", monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
        "\n",
        "history = model.fit(\n",
        "      train_generator,\n",
        "      steps_per_epoch=10, \n",
        "      epochs=500,\n",
        "      verbose=1,\n",
        "      validation_data = validation_generator,\n",
        "      validation_steps=5, \n",
        "      callbacks = [callbacks,checkpoint]\n",
        ") "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6989 - accuracy: 0.4949 - sensitivity_at_specificity: 0.3664 - specificity_at_sensitivity: 0.3211 - recall: 0.4203 - precision: 0.4940\n",
            "Epoch 1: val_accuracy improved from -inf to 0.48516, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 17s 244ms/step - loss: 0.6989 - accuracy: 0.4949 - sensitivity_at_specificity: 0.3664 - specificity_at_sensitivity: 0.3211 - recall: 0.4203 - precision: 0.4940 - val_loss: 0.6946 - val_accuracy: 0.4852 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.0000e+00 - val_recall: 1.0000 - val_precision: 0.4852\n",
            "Epoch 2/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6950 - accuracy: 0.4898 - sensitivity_at_specificity: 0.4183 - specificity_at_sensitivity: 0.4958 - recall: 0.6279 - precision: 0.4843\n",
            "Epoch 2: val_accuracy improved from 0.48516 to 0.49766, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.6950 - accuracy: 0.4898 - sensitivity_at_specificity: 0.4183 - specificity_at_sensitivity: 0.4958 - recall: 0.6279 - precision: 0.4843 - val_loss: 0.6937 - val_accuracy: 0.4977 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
            "Epoch 3/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6939 - accuracy: 0.4910 - sensitivity_at_specificity: 0.0306 - specificity_at_sensitivity: 0.2392 - recall: 0.0444 - precision: 0.5133\n",
            "Epoch 3: val_accuracy did not improve from 0.49766\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.6939 - accuracy: 0.4910 - sensitivity_at_specificity: 0.0306 - specificity_at_sensitivity: 0.2392 - recall: 0.0444 - precision: 0.5133 - val_loss: 0.6937 - val_accuracy: 0.4922 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
            "Epoch 4/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6937 - accuracy: 0.5083 - sensitivity_at_specificity: 0.0042 - specificity_at_sensitivity: 0.1413 - recall: 0.0076 - precision: 0.5000\n",
            "Epoch 4: val_accuracy improved from 0.49766 to 0.51094, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 198ms/step - loss: 0.6937 - accuracy: 0.5083 - sensitivity_at_specificity: 0.0042 - specificity_at_sensitivity: 0.1413 - recall: 0.0076 - precision: 0.5000 - val_loss: 0.6936 - val_accuracy: 0.5109 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
            "Epoch 5/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6938 - accuracy: 0.4973 - sensitivity_at_specificity: 0.0031 - specificity_at_sensitivity: 0.0737 - recall: 0.0039 - precision: 0.3846\n",
            "Epoch 5: val_accuracy did not improve from 0.51094\n",
            "10/10 [==============================] - 2s 156ms/step - loss: 0.6938 - accuracy: 0.4973 - sensitivity_at_specificity: 0.0031 - specificity_at_sensitivity: 0.0737 - recall: 0.0039 - precision: 0.3846 - val_loss: 0.6937 - val_accuracy: 0.4977 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
            "Epoch 6/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6937 - accuracy: 0.4977 - sensitivity_at_specificity: 0.0023 - specificity_at_sensitivity: 0.0188 - recall: 0.0054 - precision: 0.4667\n",
            "Epoch 6: val_accuracy did not improve from 0.51094\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.6937 - accuracy: 0.4977 - sensitivity_at_specificity: 0.0023 - specificity_at_sensitivity: 0.0188 - recall: 0.0054 - precision: 0.4667 - val_loss: 0.6936 - val_accuracy: 0.5086 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
            "Epoch 7/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6937 - accuracy: 0.4767 - sensitivity_at_specificity: 7.9554e-04 - specificity_at_sensitivity: 0.0087 - recall: 0.0040 - precision: 0.3846\n",
            "Epoch 7: val_accuracy did not improve from 0.51094\n",
            "10/10 [==============================] - 3s 268ms/step - loss: 0.6937 - accuracy: 0.4767 - sensitivity_at_specificity: 7.9554e-04 - specificity_at_sensitivity: 0.0087 - recall: 0.0040 - precision: 0.3846 - val_loss: 0.6936 - val_accuracy: 0.4992 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
            "Epoch 8/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6936 - accuracy: 0.4934 - sensitivity_at_specificity: 0.0016 - specificity_at_sensitivity: 0.0116 - recall: 0.6871 - precision: 0.4929\n",
            "Epoch 8: val_accuracy did not improve from 0.51094\n",
            "10/10 [==============================] - 3s 298ms/step - loss: 0.6936 - accuracy: 0.4934 - sensitivity_at_specificity: 0.0016 - specificity_at_sensitivity: 0.0116 - recall: 0.6871 - precision: 0.4929 - val_loss: 0.6937 - val_accuracy: 0.4875 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.0000e+00 - val_recall: 1.0000 - val_precision: 0.4875\n",
            "Epoch 9/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6937 - accuracy: 0.4883 - sensitivity_at_specificity: 8.0775e-04 - specificity_at_sensitivity: 0.0076 - recall: 0.5840 - precision: 0.4763\n",
            "Epoch 9: val_accuracy did not improve from 0.51094\n",
            "10/10 [==============================] - 2s 223ms/step - loss: 0.6937 - accuracy: 0.4883 - sensitivity_at_specificity: 8.0775e-04 - specificity_at_sensitivity: 0.0076 - recall: 0.5840 - precision: 0.4763 - val_loss: 0.6937 - val_accuracy: 0.4844 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
            "Epoch 10/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6937 - accuracy: 0.4883 - sensitivity_at_specificity: 7.6511e-04 - specificity_at_sensitivity: 0.0096 - recall: 7.6511e-04 - precision: 0.2000\n",
            "Epoch 10: val_accuracy did not improve from 0.51094\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.6937 - accuracy: 0.4883 - sensitivity_at_specificity: 7.6511e-04 - specificity_at_sensitivity: 0.0096 - recall: 7.6511e-04 - precision: 0.2000 - val_loss: 0.6937 - val_accuracy: 0.4906 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
            "Epoch 11/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6936 - accuracy: 0.5012 - sensitivity_at_specificity: 0.0000e+00 - specificity_at_sensitivity: 0.0133 - recall: 0.0047 - precision: 0.5000\n",
            "Epoch 11: val_accuracy improved from 0.51094 to 0.52031, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.6936 - accuracy: 0.5012 - sensitivity_at_specificity: 0.0000e+00 - specificity_at_sensitivity: 0.0133 - recall: 0.0047 - precision: 0.5000 - val_loss: 0.6936 - val_accuracy: 0.5203 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
            "Epoch 12/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6936 - accuracy: 0.5133 - sensitivity_at_specificity: 0.0024 - specificity_at_sensitivity: 0.0168 - recall: 0.0056 - precision: 0.5385\n",
            "Epoch 12: val_accuracy did not improve from 0.52031\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.6936 - accuracy: 0.5133 - sensitivity_at_specificity: 0.0024 - specificity_at_sensitivity: 0.0168 - recall: 0.0056 - precision: 0.5385 - val_loss: 0.6936 - val_accuracy: 0.4992 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
            "Epoch 13/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6937 - accuracy: 0.4988 - sensitivity_at_specificity: 0.0000e+00 - specificity_at_sensitivity: 0.0514 - recall: 0.0000e+00 - precision: 0.0000e+00\n",
            "Epoch 13: val_accuracy did not improve from 0.52031\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.6937 - accuracy: 0.4988 - sensitivity_at_specificity: 0.0000e+00 - specificity_at_sensitivity: 0.0514 - recall: 0.0000e+00 - precision: 0.0000e+00 - val_loss: 0.6937 - val_accuracy: 0.4898 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
            "Epoch 14/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6936 - accuracy: 0.5121 - sensitivity_at_specificity: 0.0024 - specificity_at_sensitivity: 0.0237 - recall: 0.0048 - precision: 0.6000\n",
            "Epoch 14: val_accuracy did not improve from 0.52031\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.6936 - accuracy: 0.5121 - sensitivity_at_specificity: 0.0024 - specificity_at_sensitivity: 0.0237 - recall: 0.0048 - precision: 0.6000 - val_loss: 0.6936 - val_accuracy: 0.5063 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
            "Epoch 15/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6937 - accuracy: 0.4996 - sensitivity_at_specificity: 0.0039 - specificity_at_sensitivity: 0.0063 - recall: 0.0055 - precision: 0.5833\n",
            "Epoch 15: val_accuracy improved from 0.52031 to 0.52188, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.6937 - accuracy: 0.4996 - sensitivity_at_specificity: 0.0039 - specificity_at_sensitivity: 0.0063 - recall: 0.0055 - precision: 0.5833 - val_loss: 0.6935 - val_accuracy: 0.5219 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
            "Epoch 16/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6937 - accuracy: 0.4992 - sensitivity_at_specificity: 0.0016 - specificity_at_sensitivity: 0.0063 - recall: 0.0093 - precision: 0.5455\n",
            "Epoch 16: val_accuracy did not improve from 0.52188\n",
            "10/10 [==============================] - 2s 154ms/step - loss: 0.6937 - accuracy: 0.4992 - sensitivity_at_specificity: 0.0016 - specificity_at_sensitivity: 0.0063 - recall: 0.0093 - precision: 0.5455 - val_loss: 0.6936 - val_accuracy: 0.5039 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
            "Epoch 17/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6937 - accuracy: 0.4914 - sensitivity_at_specificity: 0.0016 - specificity_at_sensitivity: 0.0031 - recall: 0.0031 - precision: 0.1818\n",
            "Epoch 17: val_accuracy did not improve from 0.52188\n",
            "10/10 [==============================] - 2s 156ms/step - loss: 0.6937 - accuracy: 0.4914 - sensitivity_at_specificity: 0.0016 - specificity_at_sensitivity: 0.0031 - recall: 0.0031 - precision: 0.1818 - val_loss: 0.6936 - val_accuracy: 0.5078 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
            "Epoch 18/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6935 - accuracy: 0.5180 - sensitivity_at_specificity: 8.0906e-04 - specificity_at_sensitivity: 0.0038 - recall: 0.0065 - precision: 0.5714\n",
            "Epoch 18: val_accuracy did not improve from 0.52188\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.6935 - accuracy: 0.5180 - sensitivity_at_specificity: 8.0906e-04 - specificity_at_sensitivity: 0.0038 - recall: 0.0065 - precision: 0.5714 - val_loss: 0.6937 - val_accuracy: 0.4891 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
            "Epoch 19/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6937 - accuracy: 0.4922 - sensitivity_at_specificity: 0.0000e+00 - specificity_at_sensitivity: 0.0095 - recall: 0.0031 - precision: 0.3333\n",
            "Epoch 19: val_accuracy did not improve from 0.52188\n",
            "10/10 [==============================] - 2s 157ms/step - loss: 0.6937 - accuracy: 0.4922 - sensitivity_at_specificity: 0.0000e+00 - specificity_at_sensitivity: 0.0095 - recall: 0.0031 - precision: 0.3333 - val_loss: 0.6935 - val_accuracy: 0.5148 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
            "Epoch 20/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6937 - accuracy: 0.4895 - sensitivity_at_specificity: 0.0000e+00 - specificity_at_sensitivity: 0.0080 - recall: 0.0015 - precision: 0.2857\n",
            "Epoch 20: val_accuracy did not improve from 0.52188\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.6937 - accuracy: 0.4895 - sensitivity_at_specificity: 0.0000e+00 - specificity_at_sensitivity: 0.0080 - recall: 0.0015 - precision: 0.2857 - val_loss: 0.6937 - val_accuracy: 0.4938 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
            "Epoch 21/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6936 - accuracy: 0.5120 - sensitivity_at_specificity: 0.0025 - specificity_at_sensitivity: 0.0130 - recall: 0.0042 - precision: 1.0000\n",
            "Epoch 21: val_accuracy did not improve from 0.52188\n",
            "10/10 [==============================] - 2s 156ms/step - loss: 0.6936 - accuracy: 0.5120 - sensitivity_at_specificity: 0.0025 - specificity_at_sensitivity: 0.0130 - recall: 0.0042 - precision: 1.0000 - val_loss: 0.6936 - val_accuracy: 0.5055 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
            "Epoch 22/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6937 - accuracy: 0.4879 - sensitivity_at_specificity: 0.0000e+00 - specificity_at_sensitivity: 0.0232 - recall: 7.6453e-04 - precision: 0.2000\n",
            "Epoch 22: val_accuracy did not improve from 0.52188\n",
            "10/10 [==============================] - 2s 153ms/step - loss: 0.6937 - accuracy: 0.4879 - sensitivity_at_specificity: 0.0000e+00 - specificity_at_sensitivity: 0.0232 - recall: 7.6453e-04 - precision: 0.2000 - val_loss: 0.6937 - val_accuracy: 0.4969 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
            "Epoch 23/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6936 - accuracy: 0.5055 - sensitivity_at_specificity: 0.0000e+00 - specificity_at_sensitivity: 0.0462 - recall: 7.9302e-04 - precision: 0.1429\n",
            "Epoch 23: val_accuracy did not improve from 0.52188\n",
            "10/10 [==============================] - 2s 157ms/step - loss: 0.6936 - accuracy: 0.5055 - sensitivity_at_specificity: 0.0000e+00 - specificity_at_sensitivity: 0.0462 - recall: 7.9302e-04 - precision: 0.1429 - val_loss: 0.6938 - val_accuracy: 0.4758 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
            "Epoch 24/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6932 - accuracy: 0.5117 - sensitivity_at_specificity: 7.9872e-04 - specificity_at_sensitivity: 0.3869 - recall: 0.0024 - precision: 0.7500\n",
            "Epoch 24: val_accuracy did not improve from 0.52188\n",
            "10/10 [==============================] - 2s 154ms/step - loss: 0.6932 - accuracy: 0.5117 - sensitivity_at_specificity: 7.9872e-04 - specificity_at_sensitivity: 0.3869 - recall: 0.0024 - precision: 0.7500 - val_loss: 0.6881 - val_accuracy: 0.4930 - val_sensitivity_at_specificity: 0.6549 - val_specificity_at_sensitivity: 0.6957 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
            "Epoch 25/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6915 - accuracy: 0.5008 - sensitivity_at_specificity: 0.5612 - specificity_at_sensitivity: 0.5029 - recall: 8.3264e-04 - precision: 0.3333\n",
            "Epoch 25: val_accuracy did not improve from 0.52188\n",
            "10/10 [==============================] - 2s 151ms/step - loss: 0.6915 - accuracy: 0.5008 - sensitivity_at_specificity: 0.5612 - specificity_at_sensitivity: 0.5029 - recall: 8.3264e-04 - precision: 0.3333 - val_loss: 0.6730 - val_accuracy: 0.4969 - val_sensitivity_at_specificity: 0.9938 - val_specificity_at_sensitivity: 0.6415 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
            "Epoch 26/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6769 - accuracy: 0.5172 - sensitivity_at_specificity: 0.5643 - specificity_at_sensitivity: 0.5506 - recall: 0.1270 - precision: 0.5704\n",
            "Epoch 26: val_accuracy improved from 0.52188 to 0.68203, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 177ms/step - loss: 0.6769 - accuracy: 0.5172 - sensitivity_at_specificity: 0.5643 - specificity_at_sensitivity: 0.5506 - recall: 0.1270 - precision: 0.5704 - val_loss: 0.5509 - val_accuracy: 0.6820 - val_sensitivity_at_specificity: 0.9969 - val_specificity_at_sensitivity: 0.7317 - val_recall: 0.6166 - val_precision: 0.7086\n",
            "Epoch 27/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.6467 - accuracy: 0.5699 - sensitivity_at_specificity: 0.1174 - specificity_at_sensitivity: 0.3915 - recall: 0.6774 - precision: 0.5653\n",
            "Epoch 27: val_accuracy improved from 0.68203 to 0.78750, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.6472 - accuracy: 0.5723 - sensitivity_at_specificity: 0.1580 - specificity_at_sensitivity: 0.3825 - recall: 0.6921 - precision: 0.5678 - val_loss: 0.4989 - val_accuracy: 0.7875 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.6036 - val_recall: 0.9592 - val_precision: 0.7216\n",
            "Epoch 28/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6346 - accuracy: 0.5809 - sensitivity_at_specificity: 0.0032 - specificity_at_sensitivity: 0.3323 - recall: 0.8530 - precision: 0.5441\n",
            "Epoch 28: val_accuracy did not improve from 0.78750\n",
            "10/10 [==============================] - 2s 195ms/step - loss: 0.6346 - accuracy: 0.5809 - sensitivity_at_specificity: 0.0032 - specificity_at_sensitivity: 0.3323 - recall: 0.8530 - precision: 0.5441 - val_loss: 0.5070 - val_accuracy: 0.7328 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.6547 - val_recall: 0.8188 - val_precision: 0.6987\n",
            "Epoch 29/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6347 - accuracy: 0.6008 - sensitivity_at_specificity: 0.0610 - specificity_at_sensitivity: 0.4820 - recall: 0.9008 - precision: 0.5697\n",
            "Epoch 29: val_accuracy did not improve from 0.78750\n",
            "10/10 [==============================] - 2s 156ms/step - loss: 0.6347 - accuracy: 0.6008 - sensitivity_at_specificity: 0.0610 - specificity_at_sensitivity: 0.4820 - recall: 0.9008 - precision: 0.5697 - val_loss: 0.5017 - val_accuracy: 0.7852 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5630 - val_recall: 1.0000 - val_precision: 0.7037\n",
            "Epoch 30/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6244 - accuracy: 0.6074 - sensitivity_at_specificity: 0.4345 - specificity_at_sensitivity: 0.2955 - recall: 0.9760 - precision: 0.5640\n",
            "Epoch 30: val_accuracy did not improve from 0.78750\n",
            "10/10 [==============================] - 2s 155ms/step - loss: 0.6244 - accuracy: 0.6074 - sensitivity_at_specificity: 0.4345 - specificity_at_sensitivity: 0.2955 - recall: 0.9760 - precision: 0.5640 - val_loss: 0.4990 - val_accuracy: 0.7742 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5698 - val_recall: 0.9714 - val_precision: 0.7049\n",
            "Epoch 31/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6211 - accuracy: 0.5959 - sensitivity_at_specificity: 0.5453 - specificity_at_sensitivity: 0.5584 - recall: 0.9799 - precision: 0.5517\n",
            "Epoch 31: val_accuracy did not improve from 0.78750\n",
            "10/10 [==============================] - 2s 152ms/step - loss: 0.6211 - accuracy: 0.5959 - sensitivity_at_specificity: 0.5453 - specificity_at_sensitivity: 0.5584 - recall: 0.9799 - precision: 0.5517 - val_loss: 0.4892 - val_accuracy: 0.7477 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5608 - val_recall: 0.9703 - val_precision: 0.6585\n",
            "Epoch 32/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6286 - accuracy: 0.6090 - sensitivity_at_specificity: 0.6255 - specificity_at_sensitivity: 0.5156 - recall: 0.9718 - precision: 0.5693\n",
            "Epoch 32: val_accuracy improved from 0.78750 to 0.80078, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.6286 - accuracy: 0.6090 - sensitivity_at_specificity: 0.6255 - specificity_at_sensitivity: 0.5156 - recall: 0.9718 - precision: 0.5693 - val_loss: 0.4713 - val_accuracy: 0.8008 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.6220 - val_recall: 0.9613 - val_precision: 0.7464\n",
            "Epoch 33/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.6222 - accuracy: 0.6181 - sensitivity_at_specificity: 0.5908 - specificity_at_sensitivity: 0.5284 - recall: 0.9769 - precision: 0.5815\n",
            "Epoch 33: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 153ms/step - loss: 0.6211 - accuracy: 0.6208 - sensitivity_at_specificity: 0.6055 - specificity_at_sensitivity: 0.5211 - recall: 0.9780 - precision: 0.5839 - val_loss: 0.4525 - val_accuracy: 0.7758 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5853 - val_recall: 1.0000 - val_precision: 0.6764\n",
            "Epoch 34/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6247 - accuracy: 0.5934 - sensitivity_at_specificity: 0.5936 - specificity_at_sensitivity: 0.5540 - recall: 0.8807 - precision: 0.5597\n",
            "Epoch 34: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 154ms/step - loss: 0.6247 - accuracy: 0.5934 - sensitivity_at_specificity: 0.5936 - specificity_at_sensitivity: 0.5540 - recall: 0.8807 - precision: 0.5597 - val_loss: 0.4606 - val_accuracy: 0.7914 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5801 - val_recall: 0.9939 - val_precision: 0.7126\n",
            "Epoch 35/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6158 - accuracy: 0.6148 - sensitivity_at_specificity: 0.5933 - specificity_at_sensitivity: 0.5256 - recall: 0.9839 - precision: 0.5715\n",
            "Epoch 35: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 152ms/step - loss: 0.6158 - accuracy: 0.6148 - sensitivity_at_specificity: 0.5933 - specificity_at_sensitivity: 0.5256 - recall: 0.9839 - precision: 0.5715 - val_loss: 0.4713 - val_accuracy: 0.7719 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5719 - val_recall: 0.9935 - val_precision: 0.6811\n",
            "Epoch 36/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6132 - accuracy: 0.6219 - sensitivity_at_specificity: 0.4728 - specificity_at_sensitivity: 0.4628 - recall: 0.9894 - precision: 0.5782\n",
            "Epoch 36: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 155ms/step - loss: 0.6132 - accuracy: 0.6219 - sensitivity_at_specificity: 0.4728 - specificity_at_sensitivity: 0.4628 - recall: 0.9894 - precision: 0.5782 - val_loss: 0.4580 - val_accuracy: 0.7867 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5875 - val_recall: 0.9984 - val_precision: 0.6957\n",
            "Epoch 37/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6181 - accuracy: 0.6020 - sensitivity_at_specificity: 0.3989 - specificity_at_sensitivity: 0.4833 - recall: 0.9953 - precision: 0.5553\n",
            "Epoch 37: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.6181 - accuracy: 0.6020 - sensitivity_at_specificity: 0.3989 - specificity_at_sensitivity: 0.4833 - recall: 0.9953 - precision: 0.5553 - val_loss: 0.4775 - val_accuracy: 0.7719 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5530 - val_recall: 0.9969 - val_precision: 0.6868\n",
            "Epoch 38/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6150 - accuracy: 0.6234 - sensitivity_at_specificity: 0.5083 - specificity_at_sensitivity: 0.5736 - recall: 0.9902 - precision: 0.5796\n",
            "Epoch 38: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 154ms/step - loss: 0.6150 - accuracy: 0.6234 - sensitivity_at_specificity: 0.5083 - specificity_at_sensitivity: 0.5736 - recall: 0.9902 - precision: 0.5796 - val_loss: 0.4678 - val_accuracy: 0.7664 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5537 - val_recall: 1.0000 - val_precision: 0.6711\n",
            "Epoch 39/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6186 - accuracy: 0.6008 - sensitivity_at_specificity: 0.6451 - specificity_at_sensitivity: 0.5050 - recall: 0.9968 - precision: 0.5533\n",
            "Epoch 39: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.6186 - accuracy: 0.6008 - sensitivity_at_specificity: 0.6451 - specificity_at_sensitivity: 0.5050 - recall: 0.9968 - precision: 0.5533 - val_loss: 0.4856 - val_accuracy: 0.7664 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5571 - val_recall: 0.9738 - val_precision: 0.6918\n",
            "Epoch 40/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6194 - accuracy: 0.6109 - sensitivity_at_specificity: 0.5860 - specificity_at_sensitivity: 0.5221 - recall: 0.9919 - precision: 0.5686\n",
            "Epoch 40: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 153ms/step - loss: 0.6194 - accuracy: 0.6109 - sensitivity_at_specificity: 0.5860 - specificity_at_sensitivity: 0.5221 - recall: 0.9919 - precision: 0.5686 - val_loss: 0.4716 - val_accuracy: 0.7719 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5648 - val_recall: 0.9968 - val_precision: 0.6792\n",
            "Epoch 41/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6159 - accuracy: 0.6051 - sensitivity_at_specificity: 0.5486 - specificity_at_sensitivity: 0.5722 - recall: 0.9905 - precision: 0.5564\n",
            "Epoch 41: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 157ms/step - loss: 0.6159 - accuracy: 0.6051 - sensitivity_at_specificity: 0.5486 - specificity_at_sensitivity: 0.5722 - recall: 0.9905 - precision: 0.5564 - val_loss: 0.4848 - val_accuracy: 0.7797 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5500 - val_recall: 0.9985 - val_precision: 0.7011\n",
            "Epoch 42/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6159 - accuracy: 0.6066 - sensitivity_at_specificity: 0.6134 - specificity_at_sensitivity: 0.5310 - recall: 0.9890 - precision: 0.5585\n",
            "Epoch 42: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.6159 - accuracy: 0.6066 - sensitivity_at_specificity: 0.6134 - specificity_at_sensitivity: 0.5310 - recall: 0.9890 - precision: 0.5585 - val_loss: 0.4724 - val_accuracy: 0.7953 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5804 - val_recall: 1.0000 - val_precision: 0.7152\n",
            "Epoch 43/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6326 - accuracy: 0.5875 - sensitivity_at_specificity: 0.4542 - specificity_at_sensitivity: 0.4022 - recall: 1.0000 - precision: 0.5474\n",
            "Epoch 43: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.6326 - accuracy: 0.5875 - sensitivity_at_specificity: 0.4542 - specificity_at_sensitivity: 0.4022 - recall: 1.0000 - precision: 0.5474 - val_loss: 0.4846 - val_accuracy: 0.7727 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5442 - val_recall: 1.0000 - val_precision: 0.6894\n",
            "Epoch 44/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6152 - accuracy: 0.6030 - sensitivity_at_specificity: 0.6084 - specificity_at_sensitivity: 0.5222 - recall: 0.9849 - precision: 0.5555\n",
            "Epoch 44: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 1s 149ms/step - loss: 0.6152 - accuracy: 0.6030 - sensitivity_at_specificity: 0.6084 - specificity_at_sensitivity: 0.5222 - recall: 0.9849 - precision: 0.5555 - val_loss: 0.4828 - val_accuracy: 0.7719 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5452 - val_recall: 1.0000 - val_precision: 0.6860\n",
            "Epoch 45/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6256 - accuracy: 0.5930 - sensitivity_at_specificity: 0.4824 - specificity_at_sensitivity: 0.3905 - recall: 0.9977 - precision: 0.5508\n",
            "Epoch 45: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 154ms/step - loss: 0.6256 - accuracy: 0.5930 - sensitivity_at_specificity: 0.4824 - specificity_at_sensitivity: 0.3905 - recall: 0.9977 - precision: 0.5508 - val_loss: 0.4806 - val_accuracy: 0.7805 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5613 - val_recall: 0.9984 - val_precision: 0.6966\n",
            "Epoch 46/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6232 - accuracy: 0.6059 - sensitivity_at_specificity: 0.6078 - specificity_at_sensitivity: 0.5227 - recall: 0.9839 - precision: 0.5648\n",
            "Epoch 46: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 156ms/step - loss: 0.6232 - accuracy: 0.6059 - sensitivity_at_specificity: 0.6078 - specificity_at_sensitivity: 0.5227 - recall: 0.9839 - precision: 0.5648 - val_loss: 0.4776 - val_accuracy: 0.7758 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5590 - val_recall: 0.9984 - val_precision: 0.6895\n",
            "Epoch 47/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6095 - accuracy: 0.6199 - sensitivity_at_specificity: 0.4646 - specificity_at_sensitivity: 0.4135 - recall: 0.9985 - precision: 0.5721\n",
            "Epoch 47: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 155ms/step - loss: 0.6095 - accuracy: 0.6199 - sensitivity_at_specificity: 0.4646 - specificity_at_sensitivity: 0.4135 - recall: 0.9985 - precision: 0.5721 - val_loss: 0.4862 - val_accuracy: 0.7680 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5571 - val_recall: 0.9769 - val_precision: 0.6925\n",
            "Epoch 48/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6203 - accuracy: 0.5992 - sensitivity_at_specificity: 0.4678 - specificity_at_sensitivity: 0.4137 - recall: 0.9882 - precision: 0.5546\n",
            "Epoch 48: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 154ms/step - loss: 0.6203 - accuracy: 0.5992 - sensitivity_at_specificity: 0.4678 - specificity_at_sensitivity: 0.4137 - recall: 0.9882 - precision: 0.5546 - val_loss: 0.4637 - val_accuracy: 0.7844 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5796 - val_recall: 0.9984 - val_precision: 0.6968\n",
            "Epoch 49/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6158 - accuracy: 0.6129 - sensitivity_at_specificity: 0.5111 - specificity_at_sensitivity: 0.6000 - recall: 0.9985 - precision: 0.5685\n",
            "Epoch 49: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 155ms/step - loss: 0.6158 - accuracy: 0.6129 - sensitivity_at_specificity: 0.5111 - specificity_at_sensitivity: 0.6000 - recall: 0.9985 - precision: 0.5685 - val_loss: 0.4708 - val_accuracy: 0.7781 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5745 - val_recall: 0.9890 - val_precision: 0.6943\n",
            "Epoch 50/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6273 - accuracy: 0.5875 - sensitivity_at_specificity: 0.3823 - specificity_at_sensitivity: 0.4586 - recall: 0.9888 - precision: 0.5416\n",
            "Epoch 50: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 154ms/step - loss: 0.6273 - accuracy: 0.5875 - sensitivity_at_specificity: 0.3823 - specificity_at_sensitivity: 0.4586 - recall: 0.9888 - precision: 0.5416 - val_loss: 0.4753 - val_accuracy: 0.7852 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5656 - val_recall: 1.0000 - val_precision: 0.7017\n",
            "Epoch 51/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6175 - accuracy: 0.6031 - sensitivity_at_specificity: 0.3784 - specificity_at_sensitivity: 0.4575 - recall: 0.9953 - precision: 0.5576\n",
            "Epoch 51: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 174ms/step - loss: 0.6175 - accuracy: 0.6031 - sensitivity_at_specificity: 0.3784 - specificity_at_sensitivity: 0.4575 - recall: 0.9953 - precision: 0.5576 - val_loss: 0.4882 - val_accuracy: 0.7758 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5584 - val_recall: 0.9847 - val_precision: 0.6996\n",
            "Epoch 52/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6313 - accuracy: 0.5930 - sensitivity_at_specificity: 0.4587 - specificity_at_sensitivity: 0.3529 - recall: 0.9906 - precision: 0.5522\n",
            "Epoch 52: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 155ms/step - loss: 0.6313 - accuracy: 0.5930 - sensitivity_at_specificity: 0.4587 - specificity_at_sensitivity: 0.3529 - recall: 0.9906 - precision: 0.5522 - val_loss: 0.4800 - val_accuracy: 0.7766 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5583 - val_recall: 1.0000 - val_precision: 0.6901\n",
            "Epoch 53/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6279 - accuracy: 0.5801 - sensitivity_at_specificity: 0.3393 - specificity_at_sensitivity: 0.3996 - recall: 0.9878 - precision: 0.5332\n",
            "Epoch 53: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.6279 - accuracy: 0.5801 - sensitivity_at_specificity: 0.3393 - specificity_at_sensitivity: 0.3996 - recall: 0.9878 - precision: 0.5332 - val_loss: 0.4737 - val_accuracy: 0.7656 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5564 - val_recall: 0.9983 - val_precision: 0.6692\n",
            "Epoch 54/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6093 - accuracy: 0.6187 - sensitivity_at_specificity: 0.5376 - specificity_at_sensitivity: 0.5751 - recall: 0.9969 - precision: 0.5693\n",
            "Epoch 54: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.6093 - accuracy: 0.6187 - sensitivity_at_specificity: 0.5376 - specificity_at_sensitivity: 0.5751 - recall: 0.9969 - precision: 0.5693 - val_loss: 0.4658 - val_accuracy: 0.7844 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5885 - val_recall: 1.0000 - val_precision: 0.6916\n",
            "Epoch 55/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6209 - accuracy: 0.6020 - sensitivity_at_specificity: 0.5601 - specificity_at_sensitivity: 0.5429 - recall: 0.9891 - precision: 0.5592\n",
            "Epoch 55: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.6209 - accuracy: 0.6020 - sensitivity_at_specificity: 0.5601 - specificity_at_sensitivity: 0.5429 - recall: 0.9891 - precision: 0.5592 - val_loss: 0.4792 - val_accuracy: 0.7602 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5398 - val_recall: 1.0000 - val_precision: 0.6670\n",
            "Epoch 56/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6237 - accuracy: 0.5965 - sensitivity_at_specificity: 0.3713 - specificity_at_sensitivity: 0.4417 - recall: 0.9969 - precision: 0.5524\n",
            "Epoch 56: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 157ms/step - loss: 0.6237 - accuracy: 0.5965 - sensitivity_at_specificity: 0.3713 - specificity_at_sensitivity: 0.4417 - recall: 0.9969 - precision: 0.5524 - val_loss: 0.4632 - val_accuracy: 0.7766 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5916 - val_recall: 0.9821 - val_precision: 0.6868\n",
            "Epoch 57/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6135 - accuracy: 0.6016 - sensitivity_at_specificity: 0.4104 - specificity_at_sensitivity: 0.4282 - recall: 0.9856 - precision: 0.5515\n",
            "Epoch 57: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 155ms/step - loss: 0.6135 - accuracy: 0.6016 - sensitivity_at_specificity: 0.4104 - specificity_at_sensitivity: 0.4282 - recall: 0.9856 - precision: 0.5515 - val_loss: 0.4741 - val_accuracy: 0.7812 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5641 - val_recall: 1.0000 - val_precision: 0.6957\n",
            "Epoch 58/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6230 - accuracy: 0.5930 - sensitivity_at_specificity: 0.5625 - specificity_at_sensitivity: 0.5363 - recall: 0.9834 - precision: 0.5490\n",
            "Epoch 58: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 152ms/step - loss: 0.6230 - accuracy: 0.5930 - sensitivity_at_specificity: 0.5625 - specificity_at_sensitivity: 0.5363 - recall: 0.9834 - precision: 0.5490 - val_loss: 0.4843 - val_accuracy: 0.7672 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5440 - val_recall: 1.0000 - val_precision: 0.6799\n",
            "Epoch 59/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6169 - accuracy: 0.5992 - sensitivity_at_specificity: 0.3240 - specificity_at_sensitivity: 0.4195 - recall: 0.9992 - precision: 0.5504\n",
            "Epoch 59: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.6169 - accuracy: 0.5992 - sensitivity_at_specificity: 0.3240 - specificity_at_sensitivity: 0.4195 - recall: 0.9992 - precision: 0.5504 - val_loss: 0.4877 - val_accuracy: 0.7656 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5439 - val_recall: 0.9875 - val_precision: 0.6847\n",
            "Epoch 60/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6169 - accuracy: 0.6109 - sensitivity_at_specificity: 0.5580 - specificity_at_sensitivity: 0.5711 - recall: 0.9861 - precision: 0.5661\n",
            "Epoch 60: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 157ms/step - loss: 0.6169 - accuracy: 0.6109 - sensitivity_at_specificity: 0.5580 - specificity_at_sensitivity: 0.5711 - recall: 0.9861 - precision: 0.5661 - val_loss: 0.4859 - val_accuracy: 0.7594 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5335 - val_recall: 0.9984 - val_precision: 0.6699\n",
            "Epoch 61/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6267 - accuracy: 0.5922 - sensitivity_at_specificity: 0.5615 - specificity_at_sensitivity: 0.5597 - recall: 0.9921 - precision: 0.5475\n",
            "Epoch 61: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 156ms/step - loss: 0.6267 - accuracy: 0.5922 - sensitivity_at_specificity: 0.5615 - specificity_at_sensitivity: 0.5597 - recall: 0.9921 - precision: 0.5475 - val_loss: 0.4717 - val_accuracy: 0.7727 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5699 - val_recall: 0.9904 - val_precision: 0.6837\n",
            "Epoch 62/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6191 - accuracy: 0.6008 - sensitivity_at_specificity: 0.3423 - specificity_at_sensitivity: 0.4458 - recall: 0.9866 - precision: 0.5545\n",
            "Epoch 62: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 155ms/step - loss: 0.6191 - accuracy: 0.6008 - sensitivity_at_specificity: 0.3423 - specificity_at_sensitivity: 0.4458 - recall: 0.9866 - precision: 0.5545 - val_loss: 0.4717 - val_accuracy: 0.7766 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5686 - val_recall: 1.0000 - val_precision: 0.6857\n",
            "Epoch 63/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6217 - accuracy: 0.6031 - sensitivity_at_specificity: 0.3167 - specificity_at_sensitivity: 0.4502 - recall: 0.9977 - precision: 0.5586\n",
            "Epoch 63: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.6217 - accuracy: 0.6031 - sensitivity_at_specificity: 0.3167 - specificity_at_sensitivity: 0.4502 - recall: 0.9977 - precision: 0.5586 - val_loss: 0.4799 - val_accuracy: 0.7711 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5569 - val_recall: 0.9906 - val_precision: 0.6880\n",
            "Epoch 64/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6130 - accuracy: 0.6246 - sensitivity_at_specificity: 0.3197 - specificity_at_sensitivity: 0.4656 - recall: 0.9909 - precision: 0.5801\n",
            "Epoch 64: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.6130 - accuracy: 0.6246 - sensitivity_at_specificity: 0.3197 - specificity_at_sensitivity: 0.4656 - recall: 0.9909 - precision: 0.5801 - val_loss: 0.4826 - val_accuracy: 0.7875 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5726 - val_recall: 0.9807 - val_precision: 0.7185\n",
            "Epoch 65/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6139 - accuracy: 0.6070 - sensitivity_at_specificity: 0.5825 - specificity_at_sensitivity: 0.5388 - recall: 0.9882 - precision: 0.5592\n",
            "Epoch 65: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 155ms/step - loss: 0.6139 - accuracy: 0.6070 - sensitivity_at_specificity: 0.5825 - specificity_at_sensitivity: 0.5388 - recall: 0.9882 - precision: 0.5592 - val_loss: 0.4696 - val_accuracy: 0.7883 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5680 - val_recall: 0.9985 - val_precision: 0.7078\n",
            "Epoch 66/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6238 - accuracy: 0.6023 - sensitivity_at_specificity: 0.3392 - specificity_at_sensitivity: 0.4778 - recall: 0.9869 - precision: 0.5617\n",
            "Epoch 66: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.6238 - accuracy: 0.6023 - sensitivity_at_specificity: 0.3392 - specificity_at_sensitivity: 0.4778 - recall: 0.9869 - precision: 0.5617 - val_loss: 0.4659 - val_accuracy: 0.7812 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5767 - val_recall: 0.9984 - val_precision: 0.6921\n",
            "Epoch 67/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6162 - accuracy: 0.6102 - sensitivity_at_specificity: 0.3372 - specificity_at_sensitivity: 0.4459 - recall: 0.9977 - precision: 0.5628\n",
            "Epoch 67: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 154ms/step - loss: 0.6162 - accuracy: 0.6102 - sensitivity_at_specificity: 0.3372 - specificity_at_sensitivity: 0.4459 - recall: 0.9977 - precision: 0.5628 - val_loss: 0.4724 - val_accuracy: 0.7727 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5620 - val_recall: 0.9936 - val_precision: 0.6846\n",
            "Epoch 68/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6179 - accuracy: 0.6027 - sensitivity_at_specificity: 0.4437 - specificity_at_sensitivity: 0.3734 - recall: 0.9859 - precision: 0.5582\n",
            "Epoch 68: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.6179 - accuracy: 0.6027 - sensitivity_at_specificity: 0.4437 - specificity_at_sensitivity: 0.3734 - recall: 0.9859 - precision: 0.5582 - val_loss: 0.4665 - val_accuracy: 0.7812 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5793 - val_recall: 0.9984 - val_precision: 0.6907\n",
            "Epoch 69/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6197 - accuracy: 0.6078 - sensitivity_at_specificity: 0.5216 - specificity_at_sensitivity: 0.5856 - recall: 0.9985 - precision: 0.5640\n",
            "Epoch 69: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 154ms/step - loss: 0.6197 - accuracy: 0.6078 - sensitivity_at_specificity: 0.5216 - specificity_at_sensitivity: 0.5856 - recall: 0.9985 - precision: 0.5640 - val_loss: 0.4839 - val_accuracy: 0.7734 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5485 - val_recall: 0.9939 - val_precision: 0.6935\n",
            "Epoch 70/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6154 - accuracy: 0.6039 - sensitivity_at_specificity: 0.5755 - specificity_at_sensitivity: 0.5590 - recall: 0.9866 - precision: 0.5573\n",
            "Epoch 70: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 157ms/step - loss: 0.6154 - accuracy: 0.6039 - sensitivity_at_specificity: 0.5755 - specificity_at_sensitivity: 0.5590 - recall: 0.9866 - precision: 0.5573 - val_loss: 0.4796 - val_accuracy: 0.7891 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5594 - val_recall: 0.9955 - val_precision: 0.7154\n",
            "Epoch 71/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6162 - accuracy: 0.6133 - sensitivity_at_specificity: 0.3077 - specificity_at_sensitivity: 0.4556 - recall: 0.9969 - precision: 0.5679\n",
            "Epoch 71: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.6162 - accuracy: 0.6133 - sensitivity_at_specificity: 0.3077 - specificity_at_sensitivity: 0.4556 - recall: 0.9969 - precision: 0.5679 - val_loss: 0.4788 - val_accuracy: 0.7937 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5622 - val_recall: 1.0000 - val_precision: 0.7194\n",
            "Epoch 72/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6127 - accuracy: 0.6133 - sensitivity_at_specificity: 0.3828 - specificity_at_sensitivity: 0.4183 - recall: 0.9977 - precision: 0.5665\n",
            "Epoch 72: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.6127 - accuracy: 0.6133 - sensitivity_at_specificity: 0.3828 - specificity_at_sensitivity: 0.4183 - recall: 0.9977 - precision: 0.5665 - val_loss: 0.4822 - val_accuracy: 0.7531 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5463 - val_recall: 0.9742 - val_precision: 0.6685\n",
            "Epoch 73/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6237 - accuracy: 0.5957 - sensitivity_at_specificity: 0.3552 - specificity_at_sensitivity: 0.4292 - recall: 0.9913 - precision: 0.5509\n",
            "Epoch 73: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.6237 - accuracy: 0.5957 - sensitivity_at_specificity: 0.3552 - specificity_at_sensitivity: 0.4292 - recall: 0.9913 - precision: 0.5509 - val_loss: 0.4799 - val_accuracy: 0.7695 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5455 - val_recall: 1.0000 - val_precision: 0.6814\n",
            "Epoch 74/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6182 - accuracy: 0.6094 - sensitivity_at_specificity: 0.3372 - specificity_at_sensitivity: 0.4381 - recall: 0.9977 - precision: 0.5623\n",
            "Epoch 74: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 156ms/step - loss: 0.6182 - accuracy: 0.6094 - sensitivity_at_specificity: 0.3372 - specificity_at_sensitivity: 0.4381 - recall: 0.9977 - precision: 0.5623 - val_loss: 0.4669 - val_accuracy: 0.7680 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5913 - val_recall: 0.9706 - val_precision: 0.6804\n",
            "Epoch 75/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6196 - accuracy: 0.6113 - sensitivity_at_specificity: 0.3476 - specificity_at_sensitivity: 0.4335 - recall: 0.9855 - precision: 0.5699\n",
            "Epoch 75: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 156ms/step - loss: 0.6196 - accuracy: 0.6113 - sensitivity_at_specificity: 0.3476 - specificity_at_sensitivity: 0.4335 - recall: 0.9855 - precision: 0.5699 - val_loss: 0.4919 - val_accuracy: 0.7688 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5265 - val_recall: 1.0000 - val_precision: 0.6894\n",
            "Epoch 76/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6155 - accuracy: 0.6047 - sensitivity_at_specificity: 0.4846 - specificity_at_sensitivity: 0.3596 - recall: 1.0000 - precision: 0.5559\n",
            "Epoch 76: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 178ms/step - loss: 0.6155 - accuracy: 0.6047 - sensitivity_at_specificity: 0.4846 - specificity_at_sensitivity: 0.3596 - recall: 1.0000 - precision: 0.5559 - val_loss: 0.4753 - val_accuracy: 0.7859 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5643 - val_recall: 0.9970 - val_precision: 0.7069\n",
            "Epoch 77/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6126 - accuracy: 0.6020 - sensitivity_at_specificity: 0.3508 - specificity_at_sensitivity: 0.4583 - recall: 0.9774 - precision: 0.5502\n",
            "Epoch 77: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 154ms/step - loss: 0.6126 - accuracy: 0.6020 - sensitivity_at_specificity: 0.3508 - specificity_at_sensitivity: 0.4583 - recall: 0.9774 - precision: 0.5502 - val_loss: 0.4703 - val_accuracy: 0.7922 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5789 - val_recall: 1.0000 - val_precision: 0.7106\n",
            "Epoch 78/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6145 - accuracy: 0.6156 - sensitivity_at_specificity: 0.4655 - specificity_at_sensitivity: 0.3557 - recall: 0.9992 - precision: 0.5704\n",
            "Epoch 78: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.6145 - accuracy: 0.6156 - sensitivity_at_specificity: 0.4655 - specificity_at_sensitivity: 0.3557 - recall: 0.9992 - precision: 0.5704 - val_loss: 0.4768 - val_accuracy: 0.7875 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5629 - val_recall: 1.0000 - val_precision: 0.7082\n",
            "Epoch 79/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6163 - accuracy: 0.6113 - sensitivity_at_specificity: 0.6357 - specificity_at_sensitivity: 0.5146 - recall: 0.9783 - precision: 0.5668\n",
            "Epoch 79: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 156ms/step - loss: 0.6163 - accuracy: 0.6113 - sensitivity_at_specificity: 0.6357 - specificity_at_sensitivity: 0.5146 - recall: 0.9783 - precision: 0.5668 - val_loss: 0.4658 - val_accuracy: 0.7953 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5840 - val_recall: 1.0000 - val_precision: 0.7143\n",
            "Epoch 80/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6150 - accuracy: 0.6098 - sensitivity_at_specificity: 0.3453 - specificity_at_sensitivity: 0.4664 - recall: 0.9898 - precision: 0.5624\n",
            "Epoch 80: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.6150 - accuracy: 0.6098 - sensitivity_at_specificity: 0.3453 - specificity_at_sensitivity: 0.4664 - recall: 0.9898 - precision: 0.5624 - val_loss: 0.4755 - val_accuracy: 0.7812 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5527 - val_recall: 1.0000 - val_precision: 0.7002\n",
            "Epoch 81/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6196 - accuracy: 0.5963 - sensitivity_at_specificity: 0.4996 - specificity_at_sensitivity: 0.3665 - recall: 0.9966 - precision: 0.5491\n",
            "Epoch 81: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 152ms/step - loss: 0.6196 - accuracy: 0.5963 - sensitivity_at_specificity: 0.4996 - specificity_at_sensitivity: 0.3665 - recall: 0.9966 - precision: 0.5491 - val_loss: 0.4650 - val_accuracy: 0.7922 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.6085 - val_recall: 0.9798 - val_precision: 0.7138\n",
            "Epoch 82/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6238 - accuracy: 0.6012 - sensitivity_at_specificity: 0.4806 - specificity_at_sensitivity: 0.3268 - recall: 0.9798 - precision: 0.5595\n",
            "Epoch 82: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 156ms/step - loss: 0.6238 - accuracy: 0.6012 - sensitivity_at_specificity: 0.4806 - specificity_at_sensitivity: 0.3268 - recall: 0.9798 - precision: 0.5595 - val_loss: 0.4684 - val_accuracy: 0.7883 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5807 - val_recall: 1.0000 - val_precision: 0.7012\n",
            "Epoch 83/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6317 - accuracy: 0.5855 - sensitivity_at_specificity: 0.2695 - specificity_at_sensitivity: 0.4485 - recall: 0.9984 - precision: 0.5447\n",
            "Epoch 83: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.6317 - accuracy: 0.5855 - sensitivity_at_specificity: 0.2695 - specificity_at_sensitivity: 0.4485 - recall: 0.9984 - precision: 0.5447 - val_loss: 0.4710 - val_accuracy: 0.7758 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5823 - val_recall: 0.9840 - val_precision: 0.6891\n",
            "Epoch 84/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6205 - accuracy: 0.6051 - sensitivity_at_specificity: 0.6106 - specificity_at_sensitivity: 0.5226 - recall: 0.9823 - precision: 0.5632\n",
            "Epoch 84: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.6205 - accuracy: 0.6051 - sensitivity_at_specificity: 0.6106 - specificity_at_sensitivity: 0.5226 - recall: 0.9823 - precision: 0.5632 - val_loss: 0.4876 - val_accuracy: 0.7695 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5550 - val_recall: 0.9953 - val_precision: 0.6870\n",
            "Epoch 85/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6090 - accuracy: 0.6156 - sensitivity_at_specificity: 0.5928 - specificity_at_sensitivity: 0.5542 - recall: 0.9930 - precision: 0.5653\n",
            "Epoch 85: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.6090 - accuracy: 0.6156 - sensitivity_at_specificity: 0.5928 - specificity_at_sensitivity: 0.5542 - recall: 0.9930 - precision: 0.5653 - val_loss: 0.4786 - val_accuracy: 0.7852 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5878 - val_recall: 0.9788 - val_precision: 0.7119\n",
            "Epoch 86/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6144 - accuracy: 0.6145 - sensitivity_at_specificity: 0.4782 - specificity_at_sensitivity: 0.3849 - recall: 0.9870 - precision: 0.5704\n",
            "Epoch 86: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.6144 - accuracy: 0.6145 - sensitivity_at_specificity: 0.4782 - specificity_at_sensitivity: 0.3849 - recall: 0.9870 - precision: 0.5704 - val_loss: 0.4852 - val_accuracy: 0.7680 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5434 - val_recall: 0.9878 - val_precision: 0.6922\n",
            "Epoch 87/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6181 - accuracy: 0.6047 - sensitivity_at_specificity: 0.3245 - specificity_at_sensitivity: 0.4945 - recall: 0.9953 - precision: 0.5580\n",
            "Epoch 87: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 157ms/step - loss: 0.6181 - accuracy: 0.6047 - sensitivity_at_specificity: 0.3245 - specificity_at_sensitivity: 0.4945 - recall: 0.9953 - precision: 0.5580 - val_loss: 0.4794 - val_accuracy: 0.7727 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5456 - val_recall: 1.0000 - val_precision: 0.6888\n",
            "Epoch 88/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6161 - accuracy: 0.6160 - sensitivity_at_specificity: 0.4885 - specificity_at_sensitivity: 0.3898 - recall: 0.9901 - precision: 0.5717\n",
            "Epoch 88: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.6161 - accuracy: 0.6160 - sensitivity_at_specificity: 0.4885 - specificity_at_sensitivity: 0.3898 - recall: 0.9901 - precision: 0.5717 - val_loss: 0.4736 - val_accuracy: 0.7867 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5664 - val_recall: 0.9985 - val_precision: 0.7063\n",
            "Epoch 89/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6193 - accuracy: 0.6062 - sensitivity_at_specificity: 0.4807 - specificity_at_sensitivity: 0.3494 - recall: 0.9985 - precision: 0.5618\n",
            "Epoch 89: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 157ms/step - loss: 0.6193 - accuracy: 0.6062 - sensitivity_at_specificity: 0.4807 - specificity_at_sensitivity: 0.3494 - recall: 0.9985 - precision: 0.5618 - val_loss: 0.4713 - val_accuracy: 0.7844 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5694 - val_recall: 0.9969 - val_precision: 0.7015\n",
            "Epoch 90/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6186 - accuracy: 0.6059 - sensitivity_at_specificity: 0.3687 - specificity_at_sensitivity: 0.4296 - recall: 0.9793 - precision: 0.5613\n",
            "Epoch 90: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 1s 151ms/step - loss: 0.6186 - accuracy: 0.6059 - sensitivity_at_specificity: 0.3687 - specificity_at_sensitivity: 0.4296 - recall: 0.9793 - precision: 0.5613 - val_loss: 0.4760 - val_accuracy: 0.7922 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5791 - val_recall: 0.9955 - val_precision: 0.7163\n",
            "Epoch 91/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6109 - accuracy: 0.6227 - sensitivity_at_specificity: 0.2593 - specificity_at_sensitivity: 0.4740 - recall: 0.9954 - precision: 0.5762\n",
            "Epoch 91: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 156ms/step - loss: 0.6109 - accuracy: 0.6227 - sensitivity_at_specificity: 0.2593 - specificity_at_sensitivity: 0.4740 - recall: 0.9954 - precision: 0.5762 - val_loss: 0.4689 - val_accuracy: 0.7867 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5739 - val_recall: 0.9984 - val_precision: 0.7027\n",
            "Epoch 92/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6141 - accuracy: 0.5973 - sensitivity_at_specificity: 0.5324 - specificity_at_sensitivity: 0.5921 - recall: 0.9838 - precision: 0.5460\n",
            "Epoch 92: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 157ms/step - loss: 0.6141 - accuracy: 0.5973 - sensitivity_at_specificity: 0.5324 - specificity_at_sensitivity: 0.5921 - recall: 0.9838 - precision: 0.5460 - val_loss: 0.4752 - val_accuracy: 0.7875 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5735 - val_recall: 0.9939 - val_precision: 0.7103\n",
            "Epoch 93/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6070 - accuracy: 0.6277 - sensitivity_at_specificity: 0.2809 - specificity_at_sensitivity: 0.4944 - recall: 0.9969 - precision: 0.5792\n",
            "Epoch 93: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.6070 - accuracy: 0.6277 - sensitivity_at_specificity: 0.2809 - specificity_at_sensitivity: 0.4944 - recall: 0.9969 - precision: 0.5792 - val_loss: 0.4779 - val_accuracy: 0.7727 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5710 - val_recall: 0.9859 - val_precision: 0.6908\n",
            "Epoch 94/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6212 - accuracy: 0.5902 - sensitivity_at_specificity: 0.4137 - specificity_at_sensitivity: 0.3985 - recall: 0.9863 - precision: 0.5434\n",
            "Epoch 94: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 157ms/step - loss: 0.6212 - accuracy: 0.5902 - sensitivity_at_specificity: 0.4137 - specificity_at_sensitivity: 0.3985 - recall: 0.9863 - precision: 0.5434 - val_loss: 0.4695 - val_accuracy: 0.7859 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5757 - val_recall: 0.9969 - val_precision: 0.7031\n",
            "Epoch 95/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6200 - accuracy: 0.6086 - sensitivity_at_specificity: 0.5238 - specificity_at_sensitivity: 0.5603 - recall: 0.9908 - precision: 0.5654\n",
            "Epoch 95: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.6200 - accuracy: 0.6086 - sensitivity_at_specificity: 0.5238 - specificity_at_sensitivity: 0.5603 - recall: 0.9908 - precision: 0.5654 - val_loss: 0.4694 - val_accuracy: 0.7703 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5798 - val_recall: 0.9713 - val_precision: 0.6885\n",
            "Epoch 96/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6194 - accuracy: 0.6125 - sensitivity_at_specificity: 0.3880 - specificity_at_sensitivity: 0.4232 - recall: 0.9879 - precision: 0.5714\n",
            "Epoch 96: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.6194 - accuracy: 0.6125 - sensitivity_at_specificity: 0.3880 - specificity_at_sensitivity: 0.4232 - recall: 0.9879 - precision: 0.5714 - val_loss: 0.4689 - val_accuracy: 0.7922 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5746 - val_recall: 0.9985 - val_precision: 0.7123\n",
            "Epoch 97/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6187 - accuracy: 0.6016 - sensitivity_at_specificity: 0.3019 - specificity_at_sensitivity: 0.4689 - recall: 0.9914 - precision: 0.5555\n",
            "Epoch 97: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 156ms/step - loss: 0.6187 - accuracy: 0.6016 - sensitivity_at_specificity: 0.3019 - specificity_at_sensitivity: 0.4689 - recall: 0.9914 - precision: 0.5555 - val_loss: 0.4738 - val_accuracy: 0.7891 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5696 - val_recall: 0.9955 - val_precision: 0.7117\n",
            "Epoch 98/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6110 - accuracy: 0.6070 - sensitivity_at_specificity: 0.5028 - specificity_at_sensitivity: 0.6159 - recall: 0.9856 - precision: 0.5556\n",
            "Epoch 98: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 157ms/step - loss: 0.6110 - accuracy: 0.6070 - sensitivity_at_specificity: 0.5028 - specificity_at_sensitivity: 0.6159 - recall: 0.9856 - precision: 0.5556 - val_loss: 0.4764 - val_accuracy: 0.7633 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5838 - val_recall: 0.9760 - val_precision: 0.6789\n",
            "Epoch 99/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6226 - accuracy: 0.5840 - sensitivity_at_specificity: 0.3633 - specificity_at_sensitivity: 0.3909 - recall: 0.9861 - precision: 0.5348\n",
            "Epoch 99: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.6226 - accuracy: 0.5840 - sensitivity_at_specificity: 0.3633 - specificity_at_sensitivity: 0.3909 - recall: 0.9861 - precision: 0.5348 - val_loss: 0.4749 - val_accuracy: 0.7719 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5802 - val_recall: 0.9792 - val_precision: 0.6869\n",
            "Epoch 100/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6186 - accuracy: 0.6043 - sensitivity_at_specificity: 0.3076 - specificity_at_sensitivity: 0.4003 - recall: 0.9670 - precision: 0.5586\n",
            "Epoch 100: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.6186 - accuracy: 0.6043 - sensitivity_at_specificity: 0.3076 - specificity_at_sensitivity: 0.4003 - recall: 0.9670 - precision: 0.5586 - val_loss: 0.4639 - val_accuracy: 0.7992 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5965 - val_recall: 1.0000 - val_precision: 0.7144\n",
            "Epoch 101/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6251 - accuracy: 0.5828 - sensitivity_at_specificity: 0.2551 - specificity_at_sensitivity: 0.4026 - recall: 0.9968 - precision: 0.5356\n",
            "Epoch 101: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.6251 - accuracy: 0.5828 - sensitivity_at_specificity: 0.2551 - specificity_at_sensitivity: 0.4026 - recall: 0.9968 - precision: 0.5356 - val_loss: 0.4892 - val_accuracy: 0.7656 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5689 - val_recall: 0.9649 - val_precision: 0.6956\n",
            "Epoch 102/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6186 - accuracy: 0.6043 - sensitivity_at_specificity: 0.5118 - specificity_at_sensitivity: 0.6071 - recall: 0.9670 - precision: 0.5588\n",
            "Epoch 102: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.6186 - accuracy: 0.6043 - sensitivity_at_specificity: 0.5118 - specificity_at_sensitivity: 0.6071 - recall: 0.9670 - precision: 0.5588 - val_loss: 0.4794 - val_accuracy: 0.7773 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5609 - val_recall: 0.9953 - val_precision: 0.6931\n",
            "Epoch 103/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6227 - accuracy: 0.5906 - sensitivity_at_specificity: 0.5846 - specificity_at_sensitivity: 0.5248 - recall: 0.9960 - precision: 0.5435\n",
            "Epoch 103: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.6227 - accuracy: 0.5906 - sensitivity_at_specificity: 0.5846 - specificity_at_sensitivity: 0.5248 - recall: 0.9960 - precision: 0.5435 - val_loss: 0.4761 - val_accuracy: 0.7805 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5663 - val_recall: 0.9969 - val_precision: 0.6954\n",
            "Epoch 104/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6139 - accuracy: 0.6066 - sensitivity_at_specificity: 0.3517 - specificity_at_sensitivity: 0.3285 - recall: 0.9825 - precision: 0.5557\n",
            "Epoch 104: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 154ms/step - loss: 0.6139 - accuracy: 0.6066 - sensitivity_at_specificity: 0.3517 - specificity_at_sensitivity: 0.3285 - recall: 0.9825 - precision: 0.5557 - val_loss: 0.4867 - val_accuracy: 0.7695 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5676 - val_recall: 0.9739 - val_precision: 0.6952\n",
            "Epoch 105/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6266 - accuracy: 0.5984 - sensitivity_at_specificity: 0.2339 - specificity_at_sensitivity: 0.4541 - recall: 0.9868 - precision: 0.5566\n",
            "Epoch 105: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 152ms/step - loss: 0.6266 - accuracy: 0.5984 - sensitivity_at_specificity: 0.2339 - specificity_at_sensitivity: 0.4541 - recall: 0.9868 - precision: 0.5566 - val_loss: 0.4864 - val_accuracy: 0.7750 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5515 - val_recall: 0.9969 - val_precision: 0.6935\n",
            "Epoch 106/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6250 - accuracy: 0.5953 - sensitivity_at_specificity: 0.5440 - specificity_at_sensitivity: 0.5466 - recall: 0.9827 - precision: 0.5521\n",
            "Epoch 106: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 157ms/step - loss: 0.6250 - accuracy: 0.5953 - sensitivity_at_specificity: 0.5440 - specificity_at_sensitivity: 0.5466 - recall: 0.9827 - precision: 0.5521 - val_loss: 0.4752 - val_accuracy: 0.7812 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5778 - val_recall: 0.9877 - val_precision: 0.7024\n",
            "Epoch 107/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6072 - accuracy: 0.6086 - sensitivity_at_specificity: 0.5097 - specificity_at_sensitivity: 0.6047 - recall: 0.9732 - precision: 0.5530\n",
            "Epoch 107: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.6072 - accuracy: 0.6086 - sensitivity_at_specificity: 0.5097 - specificity_at_sensitivity: 0.6047 - recall: 0.9732 - precision: 0.5530 - val_loss: 0.4827 - val_accuracy: 0.7508 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5514 - val_recall: 0.9803 - val_precision: 0.6604\n",
            "Epoch 108/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6184 - accuracy: 0.5980 - sensitivity_at_specificity: 0.4247 - specificity_at_sensitivity: 0.3402 - recall: 0.9904 - precision: 0.5500\n",
            "Epoch 108: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 157ms/step - loss: 0.6184 - accuracy: 0.5980 - sensitivity_at_specificity: 0.4247 - specificity_at_sensitivity: 0.3402 - recall: 0.9904 - precision: 0.5500 - val_loss: 0.4920 - val_accuracy: 0.7578 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5556 - val_recall: 0.9754 - val_precision: 0.6832\n",
            "Epoch 109/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6142 - accuracy: 0.6076 - sensitivity_at_specificity: 0.4925 - specificity_at_sensitivity: 0.3491 - recall: 0.9684 - precision: 0.5620\n",
            "Epoch 109: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 152ms/step - loss: 0.6142 - accuracy: 0.6076 - sensitivity_at_specificity: 0.4925 - specificity_at_sensitivity: 0.3491 - recall: 0.9684 - precision: 0.5620 - val_loss: 0.4835 - val_accuracy: 0.7570 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5745 - val_recall: 0.9698 - val_precision: 0.6763\n",
            "Epoch 110/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6241 - accuracy: 0.6047 - sensitivity_at_specificity: 0.5530 - specificity_at_sensitivity: 0.5453 - recall: 0.9877 - precision: 0.5635\n",
            "Epoch 110: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.6241 - accuracy: 0.6047 - sensitivity_at_specificity: 0.5530 - specificity_at_sensitivity: 0.5453 - recall: 0.9877 - precision: 0.5635 - val_loss: 0.4800 - val_accuracy: 0.7820 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5531 - val_recall: 1.0000 - val_precision: 0.7022\n",
            "Epoch 111/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6113 - accuracy: 0.6176 - sensitivity_at_specificity: 0.4312 - specificity_at_sensitivity: 0.4021 - recall: 0.9884 - precision: 0.5702\n",
            "Epoch 111: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.6113 - accuracy: 0.6176 - sensitivity_at_specificity: 0.4312 - specificity_at_sensitivity: 0.4021 - recall: 0.9884 - precision: 0.5702 - val_loss: 0.4803 - val_accuracy: 0.7594 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5677 - val_recall: 0.9778 - val_precision: 0.6769\n",
            "Epoch 112/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6127 - accuracy: 0.6023 - sensitivity_at_specificity: 0.5172 - specificity_at_sensitivity: 0.5867 - recall: 0.9840 - precision: 0.5523\n",
            "Epoch 112: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.6127 - accuracy: 0.6023 - sensitivity_at_specificity: 0.5172 - specificity_at_sensitivity: 0.5867 - recall: 0.9840 - precision: 0.5523 - val_loss: 0.4668 - val_accuracy: 0.7820 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5840 - val_recall: 0.9952 - val_precision: 0.6947\n",
            "Epoch 113/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6186 - accuracy: 0.5947 - sensitivity_at_specificity: 0.4842 - specificity_at_sensitivity: 0.3538 - recall: 0.9881 - precision: 0.5464\n",
            "Epoch 113: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 153ms/step - loss: 0.6186 - accuracy: 0.5947 - sensitivity_at_specificity: 0.4842 - specificity_at_sensitivity: 0.3538 - recall: 0.9881 - precision: 0.5464 - val_loss: 0.4807 - val_accuracy: 0.7898 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5954 - val_recall: 0.9866 - val_precision: 0.7183\n",
            "Epoch 114/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6131 - accuracy: 0.6176 - sensitivity_at_specificity: 0.2269 - specificity_at_sensitivity: 0.4683 - recall: 0.9800 - precision: 0.5721\n",
            "Epoch 114: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.6131 - accuracy: 0.6176 - sensitivity_at_specificity: 0.2269 - specificity_at_sensitivity: 0.4683 - recall: 0.9800 - precision: 0.5721 - val_loss: 0.4722 - val_accuracy: 0.7797 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5888 - val_recall: 0.9812 - val_precision: 0.6987\n",
            "Epoch 115/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6183 - accuracy: 0.6039 - sensitivity_at_specificity: 0.3284 - specificity_at_sensitivity: 0.3644 - recall: 0.9929 - precision: 0.5571\n",
            "Epoch 115: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.6183 - accuracy: 0.6039 - sensitivity_at_specificity: 0.3284 - specificity_at_sensitivity: 0.3644 - recall: 0.9929 - precision: 0.5571 - val_loss: 0.4767 - val_accuracy: 0.7695 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5833 - val_recall: 0.9778 - val_precision: 0.6874\n",
            "Epoch 116/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6114 - accuracy: 0.6109 - sensitivity_at_specificity: 0.4554 - specificity_at_sensitivity: 0.3720 - recall: 0.9787 - precision: 0.5613\n",
            "Epoch 116: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.6114 - accuracy: 0.6109 - sensitivity_at_specificity: 0.4554 - specificity_at_sensitivity: 0.3720 - recall: 0.9787 - precision: 0.5613 - val_loss: 0.4650 - val_accuracy: 0.7797 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5924 - val_recall: 0.9888 - val_precision: 0.6920\n",
            "Epoch 117/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6131 - accuracy: 0.6195 - sensitivity_at_specificity: 0.4428 - specificity_at_sensitivity: 0.3855 - recall: 0.9668 - precision: 0.5733\n",
            "Epoch 117: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.6131 - accuracy: 0.6195 - sensitivity_at_specificity: 0.4428 - specificity_at_sensitivity: 0.3855 - recall: 0.9668 - precision: 0.5733 - val_loss: 0.4781 - val_accuracy: 0.7695 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.6187 - val_recall: 0.9475 - val_precision: 0.7017\n",
            "Epoch 118/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6180 - accuracy: 0.5969 - sensitivity_at_specificity: 0.3320 - specificity_at_sensitivity: 0.4317 - recall: 0.9697 - precision: 0.5506\n",
            "Epoch 118: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.6180 - accuracy: 0.5969 - sensitivity_at_specificity: 0.3320 - specificity_at_sensitivity: 0.4317 - recall: 0.9697 - precision: 0.5506 - val_loss: 0.4575 - val_accuracy: 0.7883 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5972 - val_recall: 0.9936 - val_precision: 0.7000\n",
            "Epoch 119/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6114 - accuracy: 0.6133 - sensitivity_at_specificity: 0.6212 - specificity_at_sensitivity: 0.5097 - recall: 0.9757 - precision: 0.5647\n",
            "Epoch 119: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.6114 - accuracy: 0.6133 - sensitivity_at_specificity: 0.6212 - specificity_at_sensitivity: 0.5097 - recall: 0.9757 - precision: 0.5647 - val_loss: 0.4887 - val_accuracy: 0.7469 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.6003 - val_recall: 0.9745 - val_precision: 0.6649\n",
            "Epoch 120/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6202 - accuracy: 0.6098 - sensitivity_at_specificity: 0.4897 - specificity_at_sensitivity: 0.4158 - recall: 0.9801 - precision: 0.5683\n",
            "Epoch 120: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 157ms/step - loss: 0.6202 - accuracy: 0.6098 - sensitivity_at_specificity: 0.4897 - specificity_at_sensitivity: 0.4158 - recall: 0.9801 - precision: 0.5683 - val_loss: 0.4748 - val_accuracy: 0.7937 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.6602 - val_recall: 0.9940 - val_precision: 0.7177\n",
            "Epoch 121/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6134 - accuracy: 0.6066 - sensitivity_at_specificity: 0.6377 - specificity_at_sensitivity: 0.5299 - recall: 0.9522 - precision: 0.5581\n",
            "Epoch 121: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.6134 - accuracy: 0.6066 - sensitivity_at_specificity: 0.6377 - specificity_at_sensitivity: 0.5299 - recall: 0.9522 - precision: 0.5581 - val_loss: 0.4793 - val_accuracy: 0.7602 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.6498 - val_recall: 0.9698 - val_precision: 0.6793\n",
            "Epoch 122/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6173 - accuracy: 0.6070 - sensitivity_at_specificity: 0.4571 - specificity_at_sensitivity: 0.3967 - recall: 0.9836 - precision: 0.5614\n",
            "Epoch 122: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.6173 - accuracy: 0.6070 - sensitivity_at_specificity: 0.4571 - specificity_at_sensitivity: 0.3967 - recall: 0.9836 - precision: 0.5614 - val_loss: 0.4730 - val_accuracy: 0.7578 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5449 - val_recall: 1.0000 - val_precision: 0.6597\n",
            "Epoch 123/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6081 - accuracy: 0.6168 - sensitivity_at_specificity: 0.2983 - specificity_at_sensitivity: 0.4647 - recall: 0.9860 - precision: 0.5680\n",
            "Epoch 123: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.6081 - accuracy: 0.6168 - sensitivity_at_specificity: 0.2983 - specificity_at_sensitivity: 0.4647 - recall: 0.9860 - precision: 0.5680 - val_loss: 0.4737 - val_accuracy: 0.7836 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.6210 - val_recall: 0.9739 - val_precision: 0.7095\n",
            "Epoch 124/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6097 - accuracy: 0.6027 - sensitivity_at_specificity: 0.5575 - specificity_at_sensitivity: 0.5882 - recall: 0.9830 - precision: 0.5491\n",
            "Epoch 124: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.6097 - accuracy: 0.6027 - sensitivity_at_specificity: 0.5575 - specificity_at_sensitivity: 0.5882 - recall: 0.9830 - precision: 0.5491 - val_loss: 0.4727 - val_accuracy: 0.7859 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5981 - val_recall: 0.9985 - val_precision: 0.7033\n",
            "Epoch 125/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6204 - accuracy: 0.6059 - sensitivity_at_specificity: 0.5842 - specificity_at_sensitivity: 0.5409 - recall: 0.9408 - precision: 0.5677\n",
            "Epoch 125: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.6204 - accuracy: 0.6059 - sensitivity_at_specificity: 0.5842 - specificity_at_sensitivity: 0.5409 - recall: 0.9408 - precision: 0.5677 - val_loss: 0.4581 - val_accuracy: 0.7961 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.6022 - val_recall: 0.9922 - val_precision: 0.7140\n",
            "Epoch 126/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6153 - accuracy: 0.6117 - sensitivity_at_specificity: 0.5953 - specificity_at_sensitivity: 0.5233 - recall: 0.9890 - precision: 0.5617\n",
            "Epoch 126: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 157ms/step - loss: 0.6153 - accuracy: 0.6117 - sensitivity_at_specificity: 0.5953 - specificity_at_sensitivity: 0.5233 - recall: 0.9890 - precision: 0.5617 - val_loss: 0.4716 - val_accuracy: 0.7859 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5851 - val_recall: 0.9969 - val_precision: 0.7047\n",
            "Epoch 127/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6108 - accuracy: 0.6133 - sensitivity_at_specificity: 0.5303 - specificity_at_sensitivity: 0.6012 - recall: 0.9827 - precision: 0.5634\n",
            "Epoch 127: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 175ms/step - loss: 0.6108 - accuracy: 0.6133 - sensitivity_at_specificity: 0.5303 - specificity_at_sensitivity: 0.6012 - recall: 0.9827 - precision: 0.5634 - val_loss: 0.4636 - val_accuracy: 0.7875 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5910 - val_recall: 0.9968 - val_precision: 0.7000\n",
            "Epoch 128/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6242 - accuracy: 0.5973 - sensitivity_at_specificity: 0.2443 - specificity_at_sensitivity: 0.4477 - recall: 0.9850 - precision: 0.5526\n",
            "Epoch 128: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.6242 - accuracy: 0.5973 - sensitivity_at_specificity: 0.2443 - specificity_at_sensitivity: 0.4477 - recall: 0.9850 - precision: 0.5526 - val_loss: 0.4692 - val_accuracy: 0.7836 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5728 - val_recall: 1.0000 - val_precision: 0.6959\n",
            "Epoch 129/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6203 - accuracy: 0.6012 - sensitivity_at_specificity: 0.3659 - specificity_at_sensitivity: 0.3491 - recall: 0.9984 - precision: 0.5540\n",
            "Epoch 129: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.6203 - accuracy: 0.6012 - sensitivity_at_specificity: 0.3659 - specificity_at_sensitivity: 0.3491 - recall: 0.9984 - precision: 0.5540 - val_loss: 0.4669 - val_accuracy: 0.7789 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.6475 - val_recall: 0.9935 - val_precision: 0.6879\n",
            "Epoch 130/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6172 - accuracy: 0.6141 - sensitivity_at_specificity: 0.1865 - specificity_at_sensitivity: 0.4633 - recall: 0.9847 - precision: 0.5709\n",
            "Epoch 130: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.6172 - accuracy: 0.6141 - sensitivity_at_specificity: 0.1865 - specificity_at_sensitivity: 0.4633 - recall: 0.9847 - precision: 0.5709 - val_loss: 0.4803 - val_accuracy: 0.7797 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5685 - val_recall: 0.9985 - val_precision: 0.6985\n",
            "Epoch 131/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6123 - accuracy: 0.6109 - sensitivity_at_specificity: 0.5051 - specificity_at_sensitivity: 0.5966 - recall: 0.9836 - precision: 0.5638\n",
            "Epoch 131: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.6123 - accuracy: 0.6109 - sensitivity_at_specificity: 0.5051 - specificity_at_sensitivity: 0.5966 - recall: 0.9836 - precision: 0.5638 - val_loss: 0.4697 - val_accuracy: 0.7719 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.6039 - val_recall: 0.9855 - val_precision: 0.6838\n",
            "Epoch 132/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6160 - accuracy: 0.6086 - sensitivity_at_specificity: 0.4072 - specificity_at_sensitivity: 0.3858 - recall: 0.9922 - precision: 0.5609\n",
            "Epoch 132: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.6160 - accuracy: 0.6086 - sensitivity_at_specificity: 0.4072 - specificity_at_sensitivity: 0.3858 - recall: 0.9922 - precision: 0.5609 - val_loss: 0.4675 - val_accuracy: 0.7836 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.6167 - val_recall: 0.9968 - val_precision: 0.6965\n",
            "Epoch 133/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6077 - accuracy: 0.6172 - sensitivity_at_specificity: 0.6489 - specificity_at_sensitivity: 0.5101 - recall: 0.9577 - precision: 0.5689\n",
            "Epoch 133: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.6077 - accuracy: 0.6172 - sensitivity_at_specificity: 0.6489 - specificity_at_sensitivity: 0.5101 - recall: 0.9577 - precision: 0.5689 - val_loss: 0.4658 - val_accuracy: 0.7937 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.6529 - val_recall: 1.0000 - val_precision: 0.7108\n",
            "Epoch 134/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6150 - accuracy: 0.6129 - sensitivity_at_specificity: 0.4588 - specificity_at_sensitivity: 0.3674 - recall: 0.9954 - precision: 0.5672\n",
            "Epoch 134: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 156ms/step - loss: 0.6150 - accuracy: 0.6129 - sensitivity_at_specificity: 0.4588 - specificity_at_sensitivity: 0.3674 - recall: 0.9954 - precision: 0.5672 - val_loss: 0.4699 - val_accuracy: 0.7641 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5561 - val_recall: 0.9951 - val_precision: 0.6703\n",
            "Epoch 135/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6110 - accuracy: 0.6199 - sensitivity_at_specificity: 0.3188 - specificity_at_sensitivity: 0.4756 - recall: 0.9855 - precision: 0.5752\n",
            "Epoch 135: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.6110 - accuracy: 0.6199 - sensitivity_at_specificity: 0.3188 - specificity_at_sensitivity: 0.4756 - recall: 0.9855 - precision: 0.5752 - val_loss: 0.4645 - val_accuracy: 0.7734 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5684 - val_recall: 0.9967 - val_precision: 0.6804\n",
            "Epoch 136/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6223 - accuracy: 0.5961 - sensitivity_at_specificity: 0.4027 - specificity_at_sensitivity: 0.4345 - recall: 0.9850 - precision: 0.5519\n",
            "Epoch 136: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.6223 - accuracy: 0.5961 - sensitivity_at_specificity: 0.4027 - specificity_at_sensitivity: 0.4345 - recall: 0.9850 - precision: 0.5519 - val_loss: 0.4839 - val_accuracy: 0.7719 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5770 - val_recall: 0.9804 - val_precision: 0.6997\n",
            "Epoch 137/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6038 - accuracy: 0.6246 - sensitivity_at_specificity: 0.5460 - specificity_at_sensitivity: 0.5975 - recall: 0.9954 - precision: 0.5740\n",
            "Epoch 137: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 157ms/step - loss: 0.6038 - accuracy: 0.6246 - sensitivity_at_specificity: 0.5460 - specificity_at_sensitivity: 0.5975 - recall: 0.9954 - precision: 0.5740 - val_loss: 0.4745 - val_accuracy: 0.7672 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5695 - val_recall: 0.9936 - val_precision: 0.6787\n",
            "Epoch 138/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6125 - accuracy: 0.6074 - sensitivity_at_specificity: 0.4248 - specificity_at_sensitivity: 0.4183 - recall: 0.9809 - precision: 0.5569\n",
            "Epoch 138: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.6125 - accuracy: 0.6074 - sensitivity_at_specificity: 0.4248 - specificity_at_sensitivity: 0.4183 - recall: 0.9809 - precision: 0.5569 - val_loss: 0.4815 - val_accuracy: 0.7711 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.6475 - val_recall: 0.9755 - val_precision: 0.6969\n",
            "Epoch 139/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6171 - accuracy: 0.6184 - sensitivity_at_specificity: 0.5329 - specificity_at_sensitivity: 0.6034 - recall: 0.9856 - precision: 0.5772\n",
            "Epoch 139: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 152ms/step - loss: 0.6171 - accuracy: 0.6184 - sensitivity_at_specificity: 0.5329 - specificity_at_sensitivity: 0.6034 - recall: 0.9856 - precision: 0.5772 - val_loss: 0.4576 - val_accuracy: 0.8000 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.6151 - val_recall: 1.0000 - val_precision: 0.7162\n",
            "Epoch 140/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6142 - accuracy: 0.6160 - sensitivity_at_specificity: 0.5633 - specificity_at_sensitivity: 0.6052 - recall: 0.9606 - precision: 0.5719\n",
            "Epoch 140: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.6142 - accuracy: 0.6160 - sensitivity_at_specificity: 0.5633 - specificity_at_sensitivity: 0.6052 - recall: 0.9606 - precision: 0.5719 - val_loss: 0.4685 - val_accuracy: 0.7891 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.6427 - val_recall: 0.9820 - val_precision: 0.7174\n",
            "Epoch 141/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6211 - accuracy: 0.5988 - sensitivity_at_specificity: 0.6291 - specificity_at_sensitivity: 0.5133 - recall: 0.9789 - precision: 0.5558\n",
            "Epoch 141: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.6211 - accuracy: 0.5988 - sensitivity_at_specificity: 0.6291 - specificity_at_sensitivity: 0.5133 - recall: 0.9789 - precision: 0.5558 - val_loss: 0.4593 - val_accuracy: 0.7898 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.6445 - val_recall: 0.9984 - val_precision: 0.7022\n",
            "Epoch 142/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6070 - accuracy: 0.6199 - sensitivity_at_specificity: 0.5326 - specificity_at_sensitivity: 0.6228 - recall: 0.9884 - precision: 0.5710\n",
            "Epoch 142: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.6070 - accuracy: 0.6199 - sensitivity_at_specificity: 0.5326 - specificity_at_sensitivity: 0.6228 - recall: 0.9884 - precision: 0.5710 - val_loss: 0.4641 - val_accuracy: 0.7930 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7086 - val_recall: 0.9908 - val_precision: 0.7138\n",
            "Epoch 143/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6198 - accuracy: 0.5963 - sensitivity_at_specificity: 0.5026 - specificity_at_sensitivity: 0.6286 - recall: 0.9829 - precision: 0.5475\n",
            "Epoch 143: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 156ms/step - loss: 0.6198 - accuracy: 0.5963 - sensitivity_at_specificity: 0.5026 - specificity_at_sensitivity: 0.6286 - recall: 0.9829 - precision: 0.5475 - val_loss: 0.4697 - val_accuracy: 0.7758 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7419 - val_recall: 0.9762 - val_precision: 0.6930\n",
            "Epoch 144/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6097 - accuracy: 0.6090 - sensitivity_at_specificity: 0.6360 - specificity_at_sensitivity: 0.5101 - recall: 0.9544 - precision: 0.5628\n",
            "Epoch 144: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.6097 - accuracy: 0.6090 - sensitivity_at_specificity: 0.6360 - specificity_at_sensitivity: 0.5101 - recall: 0.9544 - precision: 0.5628 - val_loss: 0.4649 - val_accuracy: 0.7828 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.6018 - val_recall: 1.0000 - val_precision: 0.6928\n",
            "Epoch 145/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6136 - accuracy: 0.6117 - sensitivity_at_specificity: 0.4593 - specificity_at_sensitivity: 0.4327 - recall: 0.9946 - precision: 0.5650\n",
            "Epoch 145: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.6136 - accuracy: 0.6117 - sensitivity_at_specificity: 0.4593 - specificity_at_sensitivity: 0.4327 - recall: 0.9946 - precision: 0.5650 - val_loss: 0.4651 - val_accuracy: 0.7727 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.6763 - val_recall: 0.9696 - val_precision: 0.6902\n",
            "Epoch 146/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6064 - accuracy: 0.6234 - sensitivity_at_specificity: 0.5975 - specificity_at_sensitivity: 0.5564 - recall: 0.9708 - precision: 0.5772\n",
            "Epoch 146: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.6064 - accuracy: 0.6234 - sensitivity_at_specificity: 0.5975 - specificity_at_sensitivity: 0.5564 - recall: 0.9708 - precision: 0.5772 - val_loss: 0.4656 - val_accuracy: 0.7812 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.6167 - val_recall: 0.9984 - val_precision: 0.6937\n",
            "Epoch 147/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6145 - accuracy: 0.6070 - sensitivity_at_specificity: 0.4123 - specificity_at_sensitivity: 0.4946 - recall: 0.9771 - precision: 0.5587\n",
            "Epoch 147: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.6145 - accuracy: 0.6070 - sensitivity_at_specificity: 0.4123 - specificity_at_sensitivity: 0.4946 - recall: 0.9771 - precision: 0.5587 - val_loss: 0.4902 - val_accuracy: 0.7492 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.6972 - val_recall: 0.9025 - val_precision: 0.6932\n",
            "Epoch 148/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6205 - accuracy: 0.6078 - sensitivity_at_specificity: 0.5416 - specificity_at_sensitivity: 0.5675 - recall: 0.9748 - precision: 0.5679\n",
            "Epoch 148: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.6205 - accuracy: 0.6078 - sensitivity_at_specificity: 0.5416 - specificity_at_sensitivity: 0.5675 - recall: 0.9748 - precision: 0.5679 - val_loss: 0.4587 - val_accuracy: 0.7695 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5831 - val_recall: 0.9949 - val_precision: 0.6693\n",
            "Epoch 149/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6158 - accuracy: 0.5988 - sensitivity_at_specificity: 0.6359 - specificity_at_sensitivity: 0.5027 - recall: 0.9896 - precision: 0.5489\n",
            "Epoch 149: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.6158 - accuracy: 0.5988 - sensitivity_at_specificity: 0.6359 - specificity_at_sensitivity: 0.5027 - recall: 0.9896 - precision: 0.5489 - val_loss: 0.4728 - val_accuracy: 0.7805 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5627 - val_recall: 0.9969 - val_precision: 0.6964\n",
            "Epoch 150/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6129 - accuracy: 0.5953 - sensitivity_at_specificity: 0.3907 - specificity_at_sensitivity: 0.4740 - recall: 0.9911 - precision: 0.5434\n",
            "Epoch 150: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.6129 - accuracy: 0.5953 - sensitivity_at_specificity: 0.3907 - specificity_at_sensitivity: 0.4740 - recall: 0.9911 - precision: 0.5434 - val_loss: 0.4612 - val_accuracy: 0.7977 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.6140 - val_recall: 0.9906 - val_precision: 0.7132\n",
            "Epoch 151/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6114 - accuracy: 0.6008 - sensitivity_at_specificity: 0.3095 - specificity_at_sensitivity: 0.4240 - recall: 0.9799 - precision: 0.5501\n",
            "Epoch 151: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.6114 - accuracy: 0.6008 - sensitivity_at_specificity: 0.3095 - specificity_at_sensitivity: 0.4240 - recall: 0.9799 - precision: 0.5501 - val_loss: 0.4993 - val_accuracy: 0.7625 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5478 - val_recall: 0.9816 - val_precision: 0.6867\n",
            "Epoch 152/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6194 - accuracy: 0.5977 - sensitivity_at_specificity: 0.4611 - specificity_at_sensitivity: 0.2854 - recall: 0.9921 - precision: 0.5507\n",
            "Epoch 152: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.6194 - accuracy: 0.5977 - sensitivity_at_specificity: 0.4611 - specificity_at_sensitivity: 0.2854 - recall: 0.9921 - precision: 0.5507 - val_loss: 0.4837 - val_accuracy: 0.7797 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5596 - val_recall: 0.9985 - val_precision: 0.6982\n",
            "Epoch 153/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6195 - accuracy: 0.6078 - sensitivity_at_specificity: 0.2496 - specificity_at_sensitivity: 0.4638 - recall: 0.9876 - precision: 0.5632\n",
            "Epoch 153: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.6195 - accuracy: 0.6078 - sensitivity_at_specificity: 0.2496 - specificity_at_sensitivity: 0.4638 - recall: 0.9876 - precision: 0.5632 - val_loss: 0.4719 - val_accuracy: 0.7859 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.6287 - val_recall: 1.0000 - val_precision: 0.6999\n",
            "Epoch 154/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6137 - accuracy: 0.6047 - sensitivity_at_specificity: 0.2799 - specificity_at_sensitivity: 0.4443 - recall: 0.9839 - precision: 0.5542\n",
            "Epoch 154: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 156ms/step - loss: 0.6137 - accuracy: 0.6047 - sensitivity_at_specificity: 0.2799 - specificity_at_sensitivity: 0.4443 - recall: 0.9839 - precision: 0.5542 - val_loss: 0.4733 - val_accuracy: 0.7930 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.6222 - val_recall: 0.9970 - val_precision: 0.7138\n",
            "Epoch 155/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6129 - accuracy: 0.6031 - sensitivity_at_specificity: 0.6021 - specificity_at_sensitivity: 0.5526 - recall: 0.9709 - precision: 0.5511\n",
            "Epoch 155: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.6129 - accuracy: 0.6031 - sensitivity_at_specificity: 0.6021 - specificity_at_sensitivity: 0.5526 - recall: 0.9709 - precision: 0.5511 - val_loss: 0.4895 - val_accuracy: 0.7461 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7429 - val_recall: 0.8892 - val_precision: 0.6955\n",
            "Epoch 156/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6138 - accuracy: 0.6062 - sensitivity_at_specificity: 0.5973 - specificity_at_sensitivity: 0.5360 - recall: 0.9409 - precision: 0.5614\n",
            "Epoch 156: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.6138 - accuracy: 0.6062 - sensitivity_at_specificity: 0.5973 - specificity_at_sensitivity: 0.5360 - recall: 0.9409 - precision: 0.5614 - val_loss: 0.4697 - val_accuracy: 0.7734 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.6303 - val_recall: 0.9984 - val_precision: 0.6817\n",
            "Epoch 157/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6170 - accuracy: 0.5973 - sensitivity_at_specificity: 0.3789 - specificity_at_sensitivity: 0.4260 - recall: 0.9863 - precision: 0.5473\n",
            "Epoch 157: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.6170 - accuracy: 0.5973 - sensitivity_at_specificity: 0.3789 - specificity_at_sensitivity: 0.4260 - recall: 0.9863 - precision: 0.5473 - val_loss: 0.4794 - val_accuracy: 0.7789 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.6910 - val_recall: 0.9877 - val_precision: 0.6998\n",
            "Epoch 158/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6209 - accuracy: 0.5945 - sensitivity_at_specificity: 0.6154 - specificity_at_sensitivity: 0.5222 - recall: 0.9459 - precision: 0.5505\n",
            "Epoch 158: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.6209 - accuracy: 0.5945 - sensitivity_at_specificity: 0.6154 - specificity_at_sensitivity: 0.5222 - recall: 0.9459 - precision: 0.5505 - val_loss: 0.4736 - val_accuracy: 0.7844 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7208 - val_recall: 0.9737 - val_precision: 0.7083\n",
            "Epoch 159/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6190 - accuracy: 0.5949 - sensitivity_at_specificity: 0.5881 - specificity_at_sensitivity: 0.5602 - recall: 0.9808 - precision: 0.5472\n",
            "Epoch 159: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.6190 - accuracy: 0.5949 - sensitivity_at_specificity: 0.5881 - specificity_at_sensitivity: 0.5602 - recall: 0.9808 - precision: 0.5472 - val_loss: 0.4741 - val_accuracy: 0.7789 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.6229 - val_recall: 0.9968 - val_precision: 0.6919\n",
            "Epoch 160/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6114 - accuracy: 0.6176 - sensitivity_at_specificity: 0.2494 - specificity_at_sensitivity: 0.4829 - recall: 0.9670 - precision: 0.5738\n",
            "Epoch 160: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.6114 - accuracy: 0.6176 - sensitivity_at_specificity: 0.2494 - specificity_at_sensitivity: 0.4829 - recall: 0.9670 - precision: 0.5738 - val_loss: 0.4660 - val_accuracy: 0.7883 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.6186 - val_recall: 0.9984 - val_precision: 0.7013\n",
            "Epoch 161/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6090 - accuracy: 0.6141 - sensitivity_at_specificity: 0.2573 - specificity_at_sensitivity: 0.4578 - recall: 0.9961 - precision: 0.5621\n",
            "Epoch 161: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 157ms/step - loss: 0.6090 - accuracy: 0.6141 - sensitivity_at_specificity: 0.2573 - specificity_at_sensitivity: 0.4578 - recall: 0.9961 - precision: 0.5621 - val_loss: 0.4579 - val_accuracy: 0.7969 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.6625 - val_recall: 0.9937 - val_precision: 0.7111\n",
            "Epoch 162/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6124 - accuracy: 0.6137 - sensitivity_at_specificity: 0.3091 - specificity_at_sensitivity: 0.4715 - recall: 0.9805 - precision: 0.5658\n",
            "Epoch 162: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.6124 - accuracy: 0.6137 - sensitivity_at_specificity: 0.3091 - specificity_at_sensitivity: 0.4715 - recall: 0.9805 - precision: 0.5658 - val_loss: 0.4723 - val_accuracy: 0.7852 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.6530 - val_recall: 0.9954 - val_precision: 0.7027\n",
            "Epoch 163/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6251 - accuracy: 0.5969 - sensitivity_at_specificity: 0.4980 - specificity_at_sensitivity: 0.3854 - recall: 0.9835 - precision: 0.5532\n",
            "Epoch 163: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.6251 - accuracy: 0.5969 - sensitivity_at_specificity: 0.4980 - specificity_at_sensitivity: 0.3854 - recall: 0.9835 - precision: 0.5532 - val_loss: 0.4863 - val_accuracy: 0.7617 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.6372 - val_recall: 0.9783 - val_precision: 0.6847\n",
            "Epoch 164/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6200 - accuracy: 0.6034 - sensitivity_at_specificity: 0.6031 - specificity_at_sensitivity: 0.5567 - recall: 0.9260 - precision: 0.5658\n",
            "Epoch 164: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 154ms/step - loss: 0.6200 - accuracy: 0.6034 - sensitivity_at_specificity: 0.6031 - specificity_at_sensitivity: 0.5567 - recall: 0.9260 - precision: 0.5658 - val_loss: 0.4770 - val_accuracy: 0.7656 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.6923 - val_recall: 0.9937 - val_precision: 0.6790\n",
            "Epoch 165/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6114 - accuracy: 0.6328 - sensitivity_at_specificity: 0.5398 - specificity_at_sensitivity: 0.5523 - recall: 0.9919 - precision: 0.5915\n",
            "Epoch 165: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.6114 - accuracy: 0.6328 - sensitivity_at_specificity: 0.5398 - specificity_at_sensitivity: 0.5523 - recall: 0.9919 - precision: 0.5915 - val_loss: 0.4726 - val_accuracy: 0.7672 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5863 - val_recall: 1.0000 - val_precision: 0.6771\n",
            "Epoch 166/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6184 - accuracy: 0.6047 - sensitivity_at_specificity: 0.4858 - specificity_at_sensitivity: 0.4287 - recall: 0.9898 - precision: 0.5572\n",
            "Epoch 166: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.6184 - accuracy: 0.6047 - sensitivity_at_specificity: 0.4858 - specificity_at_sensitivity: 0.4287 - recall: 0.9898 - precision: 0.5572 - val_loss: 0.4708 - val_accuracy: 0.7805 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.6268 - val_recall: 0.9922 - val_precision: 0.6987\n",
            "Epoch 167/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6095 - accuracy: 0.6055 - sensitivity_at_specificity: 0.4731 - specificity_at_sensitivity: 0.4540 - recall: 0.9839 - precision: 0.5530\n",
            "Epoch 167: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.6095 - accuracy: 0.6055 - sensitivity_at_specificity: 0.4731 - specificity_at_sensitivity: 0.4540 - recall: 0.9839 - precision: 0.5530 - val_loss: 0.4684 - val_accuracy: 0.7719 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7528 - val_recall: 0.9337 - val_precision: 0.7088\n",
            "Epoch 168/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6207 - accuracy: 0.6070 - sensitivity_at_specificity: 0.5637 - specificity_at_sensitivity: 0.5472 - recall: 0.9581 - precision: 0.5645\n",
            "Epoch 168: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.6207 - accuracy: 0.6070 - sensitivity_at_specificity: 0.5637 - specificity_at_sensitivity: 0.5472 - recall: 0.9581 - precision: 0.5645 - val_loss: 0.4750 - val_accuracy: 0.7836 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7527 - val_recall: 1.0000 - val_precision: 0.6983\n",
            "Epoch 169/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6173 - accuracy: 0.6141 - sensitivity_at_specificity: 0.5928 - specificity_at_sensitivity: 0.5694 - recall: 0.9692 - precision: 0.5705\n",
            "Epoch 169: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.6173 - accuracy: 0.6141 - sensitivity_at_specificity: 0.5928 - specificity_at_sensitivity: 0.5694 - recall: 0.9692 - precision: 0.5705 - val_loss: 0.4891 - val_accuracy: 0.7625 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.6869 - val_recall: 0.9144 - val_precision: 0.7069\n",
            "Epoch 170/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6238 - accuracy: 0.5926 - sensitivity_at_specificity: 0.2379 - specificity_at_sensitivity: 0.4766 - recall: 0.9825 - precision: 0.5474\n",
            "Epoch 170: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.6238 - accuracy: 0.5926 - sensitivity_at_specificity: 0.2379 - specificity_at_sensitivity: 0.4766 - recall: 0.9825 - precision: 0.5474 - val_loss: 0.4641 - val_accuracy: 0.7773 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.6098 - val_recall: 0.9840 - val_precision: 0.6907\n",
            "Epoch 171/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6197 - accuracy: 0.5980 - sensitivity_at_specificity: 0.2608 - specificity_at_sensitivity: 0.4862 - recall: 0.9609 - precision: 0.5515\n",
            "Epoch 171: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.6197 - accuracy: 0.5980 - sensitivity_at_specificity: 0.2608 - specificity_at_sensitivity: 0.4862 - recall: 0.9609 - precision: 0.5515 - val_loss: 0.4840 - val_accuracy: 0.7383 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5901 - val_recall: 0.9463 - val_precision: 0.6580\n",
            "Epoch 172/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6188 - accuracy: 0.5969 - sensitivity_at_specificity: 0.3032 - specificity_at_sensitivity: 0.3793 - recall: 0.9731 - precision: 0.5519\n",
            "Epoch 172: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.6188 - accuracy: 0.5969 - sensitivity_at_specificity: 0.3032 - specificity_at_sensitivity: 0.3793 - recall: 0.9731 - precision: 0.5519 - val_loss: 0.4901 - val_accuracy: 0.7805 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.6027 - val_recall: 0.9721 - val_precision: 0.7165\n",
            "Epoch 173/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6013 - accuracy: 0.6297 - sensitivity_at_specificity: 0.2824 - specificity_at_sensitivity: 0.4415 - recall: 0.9739 - precision: 0.5813\n",
            "Epoch 173: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.6013 - accuracy: 0.6297 - sensitivity_at_specificity: 0.2824 - specificity_at_sensitivity: 0.4415 - recall: 0.9739 - precision: 0.5813 - val_loss: 0.4798 - val_accuracy: 0.7789 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5653 - val_recall: 0.9954 - val_precision: 0.6986\n",
            "Epoch 174/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6127 - accuracy: 0.6199 - sensitivity_at_specificity: 0.4432 - specificity_at_sensitivity: 0.3291 - recall: 0.9901 - precision: 0.5748\n",
            "Epoch 174: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 157ms/step - loss: 0.6127 - accuracy: 0.6199 - sensitivity_at_specificity: 0.4432 - specificity_at_sensitivity: 0.3291 - recall: 0.9901 - precision: 0.5748 - val_loss: 0.4628 - val_accuracy: 0.7789 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5869 - val_recall: 0.9920 - val_precision: 0.6901\n",
            "Epoch 175/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6215 - accuracy: 0.6039 - sensitivity_at_specificity: 0.5217 - specificity_at_sensitivity: 0.5748 - recall: 0.9915 - precision: 0.5605\n",
            "Epoch 175: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.6215 - accuracy: 0.6039 - sensitivity_at_specificity: 0.5217 - specificity_at_sensitivity: 0.5748 - recall: 0.9915 - precision: 0.5605 - val_loss: 0.4730 - val_accuracy: 0.7836 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5657 - val_recall: 0.9985 - val_precision: 0.7035\n",
            "Epoch 176/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6183 - accuracy: 0.6055 - sensitivity_at_specificity: 0.3320 - specificity_at_sensitivity: 0.3832 - recall: 0.9937 - precision: 0.5576\n",
            "Epoch 176: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.6183 - accuracy: 0.6055 - sensitivity_at_specificity: 0.3320 - specificity_at_sensitivity: 0.3832 - recall: 0.9937 - precision: 0.5576 - val_loss: 0.4704 - val_accuracy: 0.7719 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5933 - val_recall: 0.9776 - val_precision: 0.6876\n",
            "Epoch 177/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6155 - accuracy: 0.6074 - sensitivity_at_specificity: 0.2991 - specificity_at_sensitivity: 0.3951 - recall: 0.9866 - precision: 0.5579\n",
            "Epoch 177: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.6155 - accuracy: 0.6074 - sensitivity_at_specificity: 0.2991 - specificity_at_sensitivity: 0.3951 - recall: 0.9866 - precision: 0.5579 - val_loss: 0.4841 - val_accuracy: 0.7742 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.6052 - val_recall: 0.9713 - val_precision: 0.7043\n",
            "Epoch 178/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6229 - accuracy: 0.6043 - sensitivity_at_specificity: 0.5543 - specificity_at_sensitivity: 0.6077 - recall: 0.9736 - precision: 0.5616\n",
            "Epoch 178: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.6229 - accuracy: 0.6043 - sensitivity_at_specificity: 0.5543 - specificity_at_sensitivity: 0.6077 - recall: 0.9736 - precision: 0.5616 - val_loss: 0.4732 - val_accuracy: 0.7742 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.6960 - val_recall: 0.9778 - val_precision: 0.6920\n",
            "Epoch 179/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6204 - accuracy: 0.6062 - sensitivity_at_specificity: 0.5576 - specificity_at_sensitivity: 0.5981 - recall: 0.9413 - precision: 0.5700\n",
            "Epoch 179: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.6204 - accuracy: 0.6062 - sensitivity_at_specificity: 0.5576 - specificity_at_sensitivity: 0.5981 - recall: 0.9413 - precision: 0.5700 - val_loss: 0.4794 - val_accuracy: 0.7773 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.6719 - val_recall: 0.9891 - val_precision: 0.6958\n",
            "Epoch 180/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6083 - accuracy: 0.6145 - sensitivity_at_specificity: 0.5207 - specificity_at_sensitivity: 0.6286 - recall: 0.9500 - precision: 0.5687\n",
            "Epoch 180: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.6083 - accuracy: 0.6145 - sensitivity_at_specificity: 0.5207 - specificity_at_sensitivity: 0.6286 - recall: 0.9500 - precision: 0.5687 - val_loss: 0.4849 - val_accuracy: 0.7789 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5721 - val_recall: 0.9985 - val_precision: 0.7035\n",
            "Epoch 181/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6092 - accuracy: 0.6100 - sensitivity_at_specificity: 0.2884 - specificity_at_sensitivity: 0.4640 - recall: 0.9882 - precision: 0.5589\n",
            "Epoch 181: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.6092 - accuracy: 0.6100 - sensitivity_at_specificity: 0.2884 - specificity_at_sensitivity: 0.4640 - recall: 0.9882 - precision: 0.5589 - val_loss: 0.4676 - val_accuracy: 0.7891 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.6148 - val_recall: 0.9893 - val_precision: 0.7119\n",
            "Epoch 182/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6204 - accuracy: 0.6105 - sensitivity_at_specificity: 0.2609 - specificity_at_sensitivity: 0.4476 - recall: 0.9924 - precision: 0.5686\n",
            "Epoch 182: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.6204 - accuracy: 0.6105 - sensitivity_at_specificity: 0.2609 - specificity_at_sensitivity: 0.4476 - recall: 0.9924 - precision: 0.5686 - val_loss: 0.4770 - val_accuracy: 0.7656 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5407 - val_recall: 1.0000 - val_precision: 0.6771\n",
            "Epoch 183/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6209 - accuracy: 0.5969 - sensitivity_at_specificity: 0.3855 - specificity_at_sensitivity: 0.3671 - recall: 0.9952 - precision: 0.5496\n",
            "Epoch 183: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.6209 - accuracy: 0.5969 - sensitivity_at_specificity: 0.3855 - specificity_at_sensitivity: 0.3671 - recall: 0.9952 - precision: 0.5496 - val_loss: 0.4751 - val_accuracy: 0.7766 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5825 - val_recall: 0.9877 - val_precision: 0.6978\n",
            "Epoch 184/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6166 - accuracy: 0.6027 - sensitivity_at_specificity: 0.2649 - specificity_at_sensitivity: 0.4114 - recall: 0.9920 - precision: 0.5532\n",
            "Epoch 184: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.6166 - accuracy: 0.6027 - sensitivity_at_specificity: 0.2649 - specificity_at_sensitivity: 0.4114 - recall: 0.9920 - precision: 0.5532 - val_loss: 0.4717 - val_accuracy: 0.7883 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5877 - val_recall: 0.9969 - val_precision: 0.7057\n",
            "Epoch 185/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6114 - accuracy: 0.6164 - sensitivity_at_specificity: 0.4872 - specificity_at_sensitivity: 0.3021 - recall: 0.9969 - precision: 0.5678\n",
            "Epoch 185: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.6114 - accuracy: 0.6164 - sensitivity_at_specificity: 0.4872 - specificity_at_sensitivity: 0.3021 - recall: 0.9969 - precision: 0.5678 - val_loss: 0.4737 - val_accuracy: 0.7680 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5725 - val_recall: 0.9968 - val_precision: 0.6762\n",
            "Epoch 186/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6196 - accuracy: 0.5930 - sensitivity_at_specificity: 0.4221 - specificity_at_sensitivity: 0.3331 - recall: 0.9888 - precision: 0.5461\n",
            "Epoch 186: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.6196 - accuracy: 0.5930 - sensitivity_at_specificity: 0.4221 - specificity_at_sensitivity: 0.3331 - recall: 0.9888 - precision: 0.5461 - val_loss: 0.4738 - val_accuracy: 0.7836 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.6375 - val_recall: 0.9908 - val_precision: 0.7041\n",
            "Epoch 187/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6121 - accuracy: 0.6281 - sensitivity_at_specificity: 0.4213 - specificity_at_sensitivity: 0.4250 - recall: 0.9828 - precision: 0.5853\n",
            "Epoch 187: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.6121 - accuracy: 0.6281 - sensitivity_at_specificity: 0.4213 - specificity_at_sensitivity: 0.4250 - recall: 0.9828 - precision: 0.5853 - val_loss: 0.4676 - val_accuracy: 0.7812 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.6801 - val_recall: 0.9874 - val_precision: 0.6978\n",
            "Epoch 188/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6078 - accuracy: 0.6254 - sensitivity_at_specificity: 0.6707 - specificity_at_sensitivity: 0.5166 - recall: 0.9813 - precision: 0.5792\n",
            "Epoch 188: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.6078 - accuracy: 0.6254 - sensitivity_at_specificity: 0.6707 - specificity_at_sensitivity: 0.5166 - recall: 0.9813 - precision: 0.5792 - val_loss: 0.4747 - val_accuracy: 0.7914 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7188 - val_recall: 0.9881 - val_precision: 0.7194\n",
            "Epoch 189/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6194 - accuracy: 0.5969 - sensitivity_at_specificity: 0.6175 - specificity_at_sensitivity: 0.5184 - recall: 0.9329 - precision: 0.5582\n",
            "Epoch 189: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.6194 - accuracy: 0.5969 - sensitivity_at_specificity: 0.6175 - specificity_at_sensitivity: 0.5184 - recall: 0.9329 - precision: 0.5582 - val_loss: 0.4705 - val_accuracy: 0.7680 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.6833 - val_recall: 0.9968 - val_precision: 0.6769\n",
            "Epoch 190/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6164 - accuracy: 0.6008 - sensitivity_at_specificity: 0.2784 - specificity_at_sensitivity: 0.4725 - recall: 0.9944 - precision: 0.5505\n",
            "Epoch 190: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.6164 - accuracy: 0.6008 - sensitivity_at_specificity: 0.2784 - specificity_at_sensitivity: 0.4725 - recall: 0.9944 - precision: 0.5505 - val_loss: 0.4726 - val_accuracy: 0.7984 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5817 - val_recall: 0.9956 - val_precision: 0.7264\n",
            "Epoch 191/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6142 - accuracy: 0.6082 - sensitivity_at_specificity: 0.2235 - specificity_at_sensitivity: 0.4735 - recall: 0.9785 - precision: 0.5576\n",
            "Epoch 191: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.6142 - accuracy: 0.6082 - sensitivity_at_specificity: 0.2235 - specificity_at_sensitivity: 0.4735 - recall: 0.9785 - precision: 0.5576 - val_loss: 0.4731 - val_accuracy: 0.7633 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5775 - val_recall: 0.9775 - val_precision: 0.6778\n",
            "Epoch 192/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6156 - accuracy: 0.6066 - sensitivity_at_specificity: 0.2078 - specificity_at_sensitivity: 0.3992 - recall: 0.9867 - precision: 0.5596\n",
            "Epoch 192: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.6156 - accuracy: 0.6066 - sensitivity_at_specificity: 0.2078 - specificity_at_sensitivity: 0.3992 - recall: 0.9867 - precision: 0.5596 - val_loss: 0.4753 - val_accuracy: 0.7688 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.6146 - val_recall: 0.9795 - val_precision: 0.6869\n",
            "Epoch 193/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6176 - accuracy: 0.6027 - sensitivity_at_specificity: 0.1069 - specificity_at_sensitivity: 0.4930 - recall: 0.9696 - precision: 0.5597\n",
            "Epoch 193: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.6176 - accuracy: 0.6027 - sensitivity_at_specificity: 0.1069 - specificity_at_sensitivity: 0.4930 - recall: 0.9696 - precision: 0.5597 - val_loss: 0.4854 - val_accuracy: 0.7758 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5775 - val_recall: 0.9820 - val_precision: 0.7043\n",
            "Epoch 194/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6244 - accuracy: 0.5902 - sensitivity_at_specificity: 0.5316 - specificity_at_sensitivity: 0.5463 - recall: 0.9826 - precision: 0.5474\n",
            "Epoch 194: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.6244 - accuracy: 0.5902 - sensitivity_at_specificity: 0.5316 - specificity_at_sensitivity: 0.5463 - recall: 0.9826 - precision: 0.5474 - val_loss: 0.4695 - val_accuracy: 0.7727 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5723 - val_recall: 0.9968 - val_precision: 0.6800\n",
            "Epoch 195/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6139 - accuracy: 0.6180 - sensitivity_at_specificity: 0.4536 - specificity_at_sensitivity: 0.3076 - recall: 0.9801 - precision: 0.5733\n",
            "Epoch 195: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.6139 - accuracy: 0.6180 - sensitivity_at_specificity: 0.4536 - specificity_at_sensitivity: 0.3076 - recall: 0.9801 - precision: 0.5733 - val_loss: 0.4679 - val_accuracy: 0.7742 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5919 - val_recall: 0.9951 - val_precision: 0.6819\n",
            "Epoch 196/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6211 - accuracy: 0.5992 - sensitivity_at_specificity: 0.6107 - specificity_at_sensitivity: 0.5124 - recall: 0.9961 - precision: 0.5541\n",
            "Epoch 196: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.6211 - accuracy: 0.5992 - sensitivity_at_specificity: 0.6107 - specificity_at_sensitivity: 0.5124 - recall: 0.9961 - precision: 0.5541 - val_loss: 0.4787 - val_accuracy: 0.7695 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.5935 - val_recall: 0.9875 - val_precision: 0.6870\n",
            "Epoch 197/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6228 - accuracy: 0.6039 - sensitivity_at_specificity: 0.4809 - specificity_at_sensitivity: 0.3584 - recall: 0.9817 - precision: 0.5650\n",
            "Epoch 197: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.6228 - accuracy: 0.6039 - sensitivity_at_specificity: 0.4809 - specificity_at_sensitivity: 0.3584 - recall: 0.9817 - precision: 0.5650 - val_loss: 0.4757 - val_accuracy: 0.7758 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.6423 - val_recall: 0.9937 - val_precision: 0.6910\n",
            "Epoch 198/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6117 - accuracy: 0.6242 - sensitivity_at_specificity: 0.4509 - specificity_at_sensitivity: 0.3608 - recall: 0.9955 - precision: 0.5796\n",
            "Epoch 198: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.6117 - accuracy: 0.6242 - sensitivity_at_specificity: 0.4509 - specificity_at_sensitivity: 0.3608 - recall: 0.9955 - precision: 0.5796 - val_loss: 0.4866 - val_accuracy: 0.7789 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.6154 - val_recall: 0.9955 - val_precision: 0.7040\n",
            "Epoch 199/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6204 - accuracy: 0.6000 - sensitivity_at_specificity: 0.6238 - specificity_at_sensitivity: 0.5286 - recall: 0.9779 - precision: 0.5546\n",
            "Epoch 199: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.6204 - accuracy: 0.6000 - sensitivity_at_specificity: 0.6238 - specificity_at_sensitivity: 0.5286 - recall: 0.9779 - precision: 0.5546 - val_loss: 0.4784 - val_accuracy: 0.7898 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.6914 - val_recall: 0.9970 - val_precision: 0.7157\n",
            "Epoch 200/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6203 - accuracy: 0.6016 - sensitivity_at_specificity: 0.6532 - specificity_at_sensitivity: 0.5425 - recall: 0.9724 - precision: 0.5555\n",
            "Epoch 200: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.6203 - accuracy: 0.6016 - sensitivity_at_specificity: 0.6532 - specificity_at_sensitivity: 0.5425 - recall: 0.9724 - precision: 0.5555 - val_loss: 0.4782 - val_accuracy: 0.7797 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7257 - val_recall: 0.9663 - val_precision: 0.7082\n",
            "Epoch 201/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6081 - accuracy: 0.6150 - sensitivity_at_specificity: 0.6350 - specificity_at_sensitivity: 0.5564 - recall: 0.9472 - precision: 0.5706\n",
            "Epoch 201: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 155ms/step - loss: 0.6081 - accuracy: 0.6150 - sensitivity_at_specificity: 0.6350 - specificity_at_sensitivity: 0.5564 - recall: 0.9472 - precision: 0.5706 - val_loss: 0.4729 - val_accuracy: 0.7773 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7527 - val_recall: 0.9921 - val_precision: 0.6916\n",
            "Epoch 202/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6152 - accuracy: 0.6187 - sensitivity_at_specificity: 0.6161 - specificity_at_sensitivity: 0.5118 - recall: 0.9767 - precision: 0.5791\n",
            "Epoch 202: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.6152 - accuracy: 0.6187 - sensitivity_at_specificity: 0.6161 - specificity_at_sensitivity: 0.5118 - recall: 0.9767 - precision: 0.5791 - val_loss: 0.4754 - val_accuracy: 0.7633 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.6159 - val_recall: 0.9906 - val_precision: 0.6800\n",
            "Epoch 203/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6210 - accuracy: 0.6152 - sensitivity_at_specificity: 0.4651 - specificity_at_sensitivity: 0.4589 - recall: 0.9932 - precision: 0.5729\n",
            "Epoch 203: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.6210 - accuracy: 0.6152 - sensitivity_at_specificity: 0.4651 - specificity_at_sensitivity: 0.4589 - recall: 0.9932 - precision: 0.5729 - val_loss: 0.4570 - val_accuracy: 0.7805 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.6152 - val_recall: 1.0000 - val_precision: 0.6881\n",
            "Epoch 204/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6132 - accuracy: 0.6031 - sensitivity_at_specificity: 0.6106 - specificity_at_sensitivity: 0.5189 - recall: 0.9818 - precision: 0.5549\n",
            "Epoch 204: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.6132 - accuracy: 0.6031 - sensitivity_at_specificity: 0.6106 - specificity_at_sensitivity: 0.5189 - recall: 0.9818 - precision: 0.5549 - val_loss: 0.4720 - val_accuracy: 0.7805 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7752 - val_recall: 0.9732 - val_precision: 0.7007\n",
            "Epoch 205/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6085 - accuracy: 0.6179 - sensitivity_at_specificity: 0.6532 - specificity_at_sensitivity: 0.6352 - recall: 0.9412 - precision: 0.5687\n",
            "Epoch 205: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.6085 - accuracy: 0.6179 - sensitivity_at_specificity: 0.6532 - specificity_at_sensitivity: 0.6352 - recall: 0.9412 - precision: 0.5687 - val_loss: 0.4934 - val_accuracy: 0.7656 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7504 - val_recall: 0.9713 - val_precision: 0.6962\n",
            "Epoch 206/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6170 - accuracy: 0.6051 - sensitivity_at_specificity: 0.6341 - specificity_at_sensitivity: 0.6417 - recall: 0.8944 - precision: 0.5663\n",
            "Epoch 206: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.6170 - accuracy: 0.6051 - sensitivity_at_specificity: 0.6341 - specificity_at_sensitivity: 0.6417 - recall: 0.8944 - precision: 0.5663 - val_loss: 0.4650 - val_accuracy: 0.7977 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7391 - val_recall: 0.9985 - val_precision: 0.7183\n",
            "Epoch 207/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6174 - accuracy: 0.6074 - sensitivity_at_specificity: 0.4535 - specificity_at_sensitivity: 0.4871 - recall: 0.9836 - precision: 0.5611\n",
            "Epoch 207: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.6174 - accuracy: 0.6074 - sensitivity_at_specificity: 0.4535 - specificity_at_sensitivity: 0.4871 - recall: 0.9836 - precision: 0.5611 - val_loss: 0.4781 - val_accuracy: 0.7852 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7107 - val_recall: 0.9765 - val_precision: 0.7200\n",
            "Epoch 208/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6180 - accuracy: 0.6023 - sensitivity_at_specificity: 0.6530 - specificity_at_sensitivity: 0.6020 - recall: 0.9210 - precision: 0.5648\n",
            "Epoch 208: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.6180 - accuracy: 0.6023 - sensitivity_at_specificity: 0.6530 - specificity_at_sensitivity: 0.6020 - recall: 0.9210 - precision: 0.5648 - val_loss: 0.4777 - val_accuracy: 0.7797 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7463 - val_recall: 0.9444 - val_precision: 0.7194\n",
            "Epoch 209/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6056 - accuracy: 0.6285 - sensitivity_at_specificity: 0.4633 - specificity_at_sensitivity: 0.4856 - recall: 0.9664 - precision: 0.5822\n",
            "Epoch 209: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.6056 - accuracy: 0.6285 - sensitivity_at_specificity: 0.4633 - specificity_at_sensitivity: 0.4856 - recall: 0.9664 - precision: 0.5822 - val_loss: 0.4686 - val_accuracy: 0.7789 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.6646 - val_recall: 0.9844 - val_precision: 0.6983\n",
            "Epoch 210/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6126 - accuracy: 0.6191 - sensitivity_at_specificity: 0.2991 - specificity_at_sensitivity: 0.4817 - recall: 0.9893 - precision: 0.5731\n",
            "Epoch 210: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.6126 - accuracy: 0.6191 - sensitivity_at_specificity: 0.2991 - specificity_at_sensitivity: 0.4817 - recall: 0.9893 - precision: 0.5731 - val_loss: 0.4686 - val_accuracy: 0.7672 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.6012 - val_recall: 0.9968 - val_precision: 0.6754\n",
            "Epoch 211/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6252 - accuracy: 0.5836 - sensitivity_at_specificity: 0.6136 - specificity_at_sensitivity: 0.5200 - recall: 0.9814 - precision: 0.5379\n",
            "Epoch 211: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 177ms/step - loss: 0.6252 - accuracy: 0.5836 - sensitivity_at_specificity: 0.6136 - specificity_at_sensitivity: 0.5200 - recall: 0.9814 - precision: 0.5379 - val_loss: 0.4733 - val_accuracy: 0.7797 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7905 - val_recall: 0.9831 - val_precision: 0.7022\n",
            "Epoch 212/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6221 - accuracy: 0.5988 - sensitivity_at_specificity: 0.4367 - specificity_at_sensitivity: 0.4391 - recall: 0.9858 - precision: 0.5539\n",
            "Epoch 212: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.6221 - accuracy: 0.5988 - sensitivity_at_specificity: 0.4367 - specificity_at_sensitivity: 0.4391 - recall: 0.9858 - precision: 0.5539 - val_loss: 0.4727 - val_accuracy: 0.7734 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.6783 - val_recall: 0.9936 - val_precision: 0.6833\n",
            "Epoch 213/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6167 - accuracy: 0.6074 - sensitivity_at_specificity: 0.6830 - specificity_at_sensitivity: 0.5961 - recall: 0.9115 - precision: 0.5635\n",
            "Epoch 213: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.6167 - accuracy: 0.6074 - sensitivity_at_specificity: 0.6830 - specificity_at_sensitivity: 0.5961 - recall: 0.9115 - precision: 0.5635 - val_loss: 0.4788 - val_accuracy: 0.7633 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7619 - val_recall: 0.9292 - val_precision: 0.7015\n",
            "Epoch 214/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6200 - accuracy: 0.5876 - sensitivity_at_specificity: 0.6361 - specificity_at_sensitivity: 0.6129 - recall: 0.8510 - precision: 0.5483\n",
            "Epoch 214: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 156ms/step - loss: 0.6200 - accuracy: 0.5876 - sensitivity_at_specificity: 0.6361 - specificity_at_sensitivity: 0.6129 - recall: 0.8510 - precision: 0.5483 - val_loss: 0.4757 - val_accuracy: 0.7586 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7769 - val_recall: 0.9186 - val_precision: 0.6955\n",
            "Epoch 215/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6111 - accuracy: 0.6156 - sensitivity_at_specificity: 0.6850 - specificity_at_sensitivity: 0.6519 - recall: 0.9387 - precision: 0.5688\n",
            "Epoch 215: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.6111 - accuracy: 0.6156 - sensitivity_at_specificity: 0.6850 - specificity_at_sensitivity: 0.6519 - recall: 0.9387 - precision: 0.5688 - val_loss: 0.4728 - val_accuracy: 0.7922 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7235 - val_recall: 0.9970 - val_precision: 0.7130\n",
            "Epoch 216/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6147 - accuracy: 0.6012 - sensitivity_at_specificity: 0.6049 - specificity_at_sensitivity: 0.5559 - recall: 0.9794 - precision: 0.5542\n",
            "Epoch 216: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.6147 - accuracy: 0.6012 - sensitivity_at_specificity: 0.6049 - specificity_at_sensitivity: 0.5559 - recall: 0.9794 - precision: 0.5542 - val_loss: 0.4573 - val_accuracy: 0.7867 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7038 - val_recall: 0.9840 - val_precision: 0.7005\n",
            "Epoch 217/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6183 - accuracy: 0.6035 - sensitivity_at_specificity: 0.5179 - specificity_at_sensitivity: 0.5881 - recall: 0.9744 - precision: 0.5610\n",
            "Epoch 217: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.6183 - accuracy: 0.6035 - sensitivity_at_specificity: 0.5179 - specificity_at_sensitivity: 0.5881 - recall: 0.9744 - precision: 0.5610 - val_loss: 0.4758 - val_accuracy: 0.7812 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.6435 - val_recall: 0.9938 - val_precision: 0.6993\n",
            "Epoch 218/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6093 - accuracy: 0.6043 - sensitivity_at_specificity: 0.6450 - specificity_at_sensitivity: 0.5416 - recall: 0.9731 - precision: 0.5564\n",
            "Epoch 218: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.6093 - accuracy: 0.6043 - sensitivity_at_specificity: 0.6450 - specificity_at_sensitivity: 0.5416 - recall: 0.9731 - precision: 0.5564 - val_loss: 0.4760 - val_accuracy: 0.7578 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7436 - val_recall: 0.9869 - val_precision: 0.6670\n",
            "Epoch 219/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6202 - accuracy: 0.6074 - sensitivity_at_specificity: 0.6428 - specificity_at_sensitivity: 0.5202 - recall: 0.9808 - precision: 0.5652\n",
            "Epoch 219: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.6202 - accuracy: 0.6074 - sensitivity_at_specificity: 0.6428 - specificity_at_sensitivity: 0.5202 - recall: 0.9808 - precision: 0.5652 - val_loss: 0.4626 - val_accuracy: 0.7930 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8043 - val_recall: 0.9984 - val_precision: 0.7063\n",
            "Epoch 220/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6123 - accuracy: 0.6234 - sensitivity_at_specificity: 0.5175 - specificity_at_sensitivity: 0.6252 - recall: 0.9749 - precision: 0.5791\n",
            "Epoch 220: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.6123 - accuracy: 0.6234 - sensitivity_at_specificity: 0.5175 - specificity_at_sensitivity: 0.6252 - recall: 0.9749 - precision: 0.5791 - val_loss: 0.4842 - val_accuracy: 0.7742 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.6879 - val_recall: 0.9895 - val_precision: 0.7010\n",
            "Epoch 221/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6134 - accuracy: 0.6184 - sensitivity_at_specificity: 0.6537 - specificity_at_sensitivity: 0.5471 - recall: 0.9847 - precision: 0.5737\n",
            "Epoch 221: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.6134 - accuracy: 0.6184 - sensitivity_at_specificity: 0.6537 - specificity_at_sensitivity: 0.5471 - recall: 0.9847 - precision: 0.5737 - val_loss: 0.4652 - val_accuracy: 0.7930 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7309 - val_recall: 0.9939 - val_precision: 0.7129\n",
            "Epoch 222/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.6068 - accuracy: 0.6133 - sensitivity_at_specificity: 0.6728 - specificity_at_sensitivity: 0.6598 - recall: 0.9639 - precision: 0.5632\n",
            "Epoch 222: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.6049 - accuracy: 0.6171 - sensitivity_at_specificity: 0.6711 - specificity_at_sensitivity: 0.6628 - recall: 0.9622 - precision: 0.5667 - val_loss: 0.4710 - val_accuracy: 0.7680 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7492 - val_recall: 0.9667 - val_precision: 0.6881\n",
            "Epoch 223/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6073 - accuracy: 0.6230 - sensitivity_at_specificity: 0.6897 - specificity_at_sensitivity: 0.6550 - recall: 0.9256 - precision: 0.5872\n",
            "Epoch 223: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.6073 - accuracy: 0.6230 - sensitivity_at_specificity: 0.6897 - specificity_at_sensitivity: 0.6550 - recall: 0.9256 - precision: 0.5872 - val_loss: 0.4771 - val_accuracy: 0.7750 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7261 - val_recall: 0.9910 - val_precision: 0.6997\n",
            "Epoch 224/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6181 - accuracy: 0.6137 - sensitivity_at_specificity: 0.4699 - specificity_at_sensitivity: 0.4956 - recall: 0.9832 - precision: 0.5717\n",
            "Epoch 224: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.6181 - accuracy: 0.6137 - sensitivity_at_specificity: 0.4699 - specificity_at_sensitivity: 0.4956 - recall: 0.9832 - precision: 0.5717 - val_loss: 0.4621 - val_accuracy: 0.7992 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.6951 - val_recall: 1.0000 - val_precision: 0.7228\n",
            "Epoch 225/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6203 - accuracy: 0.6031 - sensitivity_at_specificity: 0.6023 - specificity_at_sensitivity: 0.5422 - recall: 0.9922 - precision: 0.5580\n",
            "Epoch 225: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.6203 - accuracy: 0.6031 - sensitivity_at_specificity: 0.6023 - specificity_at_sensitivity: 0.5422 - recall: 0.9922 - precision: 0.5580 - val_loss: 0.4649 - val_accuracy: 0.7781 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7298 - val_recall: 0.9856 - val_precision: 0.6914\n",
            "Epoch 226/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6159 - accuracy: 0.6082 - sensitivity_at_specificity: 0.6866 - specificity_at_sensitivity: 0.5016 - recall: 0.9717 - precision: 0.5607\n",
            "Epoch 226: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.6159 - accuracy: 0.6082 - sensitivity_at_specificity: 0.6866 - specificity_at_sensitivity: 0.5016 - recall: 0.9717 - precision: 0.5607 - val_loss: 0.4695 - val_accuracy: 0.7656 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7048 - val_recall: 0.9740 - val_precision: 0.6787\n",
            "Epoch 227/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6246 - accuracy: 0.5953 - sensitivity_at_specificity: 0.6133 - specificity_at_sensitivity: 0.5572 - recall: 0.9545 - precision: 0.5544\n",
            "Epoch 227: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.6246 - accuracy: 0.5953 - sensitivity_at_specificity: 0.6133 - specificity_at_sensitivity: 0.5572 - recall: 0.9545 - precision: 0.5544 - val_loss: 0.4696 - val_accuracy: 0.7719 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7608 - val_recall: 0.9731 - val_precision: 0.6910\n",
            "Epoch 228/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6093 - accuracy: 0.6066 - sensitivity_at_specificity: 0.6442 - specificity_at_sensitivity: 0.6186 - recall: 0.9208 - precision: 0.5616\n",
            "Epoch 228: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.6093 - accuracy: 0.6066 - sensitivity_at_specificity: 0.6442 - specificity_at_sensitivity: 0.6186 - recall: 0.9208 - precision: 0.5616 - val_loss: 0.4738 - val_accuracy: 0.7633 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7430 - val_recall: 0.9558 - val_precision: 0.6879\n",
            "Epoch 229/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6108 - accuracy: 0.6062 - sensitivity_at_specificity: 0.7162 - specificity_at_sensitivity: 0.5668 - recall: 0.9706 - precision: 0.5570\n",
            "Epoch 229: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.6108 - accuracy: 0.6062 - sensitivity_at_specificity: 0.7162 - specificity_at_sensitivity: 0.5668 - recall: 0.9706 - precision: 0.5570 - val_loss: 0.4801 - val_accuracy: 0.7789 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.6937 - val_recall: 0.9908 - val_precision: 0.6992\n",
            "Epoch 230/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6150 - accuracy: 0.6047 - sensitivity_at_specificity: 0.6265 - specificity_at_sensitivity: 0.6088 - recall: 0.9330 - precision: 0.5609\n",
            "Epoch 230: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.6150 - accuracy: 0.6047 - sensitivity_at_specificity: 0.6265 - specificity_at_sensitivity: 0.6088 - recall: 0.9330 - precision: 0.5609 - val_loss: 0.4756 - val_accuracy: 0.7531 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7462 - val_recall: 0.9304 - val_precision: 0.6781\n",
            "Epoch 231/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6144 - accuracy: 0.5957 - sensitivity_at_specificity: 0.6634 - specificity_at_sensitivity: 0.6389 - recall: 0.8983 - precision: 0.5504\n",
            "Epoch 231: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.6144 - accuracy: 0.5957 - sensitivity_at_specificity: 0.6634 - specificity_at_sensitivity: 0.6389 - recall: 0.8983 - precision: 0.5504 - val_loss: 0.4761 - val_accuracy: 0.7789 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7700 - val_recall: 0.9694 - val_precision: 0.7068\n",
            "Epoch 232/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6166 - accuracy: 0.5910 - sensitivity_at_specificity: 0.5946 - specificity_at_sensitivity: 0.5836 - recall: 0.8801 - precision: 0.5549\n",
            "Epoch 232: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.6166 - accuracy: 0.5910 - sensitivity_at_specificity: 0.5946 - specificity_at_sensitivity: 0.5836 - recall: 0.8801 - precision: 0.5549 - val_loss: 0.4787 - val_accuracy: 0.7781 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7190 - val_recall: 0.9938 - val_precision: 0.6953\n",
            "Epoch 233/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6211 - accuracy: 0.6121 - sensitivity_at_specificity: 0.6365 - specificity_at_sensitivity: 0.6112 - recall: 0.9757 - precision: 0.5717\n",
            "Epoch 233: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.6211 - accuracy: 0.6121 - sensitivity_at_specificity: 0.6365 - specificity_at_sensitivity: 0.6112 - recall: 0.9757 - precision: 0.5717 - val_loss: 0.4816 - val_accuracy: 0.7719 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7468 - val_recall: 0.9907 - val_precision: 0.6918\n",
            "Epoch 234/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6136 - accuracy: 0.5965 - sensitivity_at_specificity: 0.6742 - specificity_at_sensitivity: 0.6119 - recall: 0.9101 - precision: 0.5518\n",
            "Epoch 234: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.6136 - accuracy: 0.5965 - sensitivity_at_specificity: 0.6742 - specificity_at_sensitivity: 0.6119 - recall: 0.9101 - precision: 0.5518 - val_loss: 0.4807 - val_accuracy: 0.7609 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7596 - val_recall: 0.9683 - val_precision: 0.6812\n",
            "Epoch 235/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6139 - accuracy: 0.6129 - sensitivity_at_specificity: 0.6579 - specificity_at_sensitivity: 0.6041 - recall: 0.9241 - precision: 0.5721\n",
            "Epoch 235: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.6139 - accuracy: 0.6129 - sensitivity_at_specificity: 0.6579 - specificity_at_sensitivity: 0.6041 - recall: 0.9241 - precision: 0.5721 - val_loss: 0.4743 - val_accuracy: 0.7648 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7416 - val_recall: 0.9776 - val_precision: 0.6808\n",
            "Epoch 236/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6178 - accuracy: 0.6055 - sensitivity_at_specificity: 0.6732 - specificity_at_sensitivity: 0.6384 - recall: 0.9424 - precision: 0.5640\n",
            "Epoch 236: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.6178 - accuracy: 0.6055 - sensitivity_at_specificity: 0.6732 - specificity_at_sensitivity: 0.6384 - recall: 0.9424 - precision: 0.5640 - val_loss: 0.4671 - val_accuracy: 0.7586 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7257 - val_recall: 0.9585 - val_precision: 0.6702\n",
            "Epoch 237/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6147 - accuracy: 0.6082 - sensitivity_at_specificity: 0.6732 - specificity_at_sensitivity: 0.6045 - recall: 0.9317 - precision: 0.5642\n",
            "Epoch 237: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.6147 - accuracy: 0.6082 - sensitivity_at_specificity: 0.6732 - specificity_at_sensitivity: 0.6045 - recall: 0.9317 - precision: 0.5642 - val_loss: 0.4723 - val_accuracy: 0.7633 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7433 - val_recall: 0.9532 - val_precision: 0.6912\n",
            "Epoch 238/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6087 - accuracy: 0.6133 - sensitivity_at_specificity: 0.6842 - specificity_at_sensitivity: 0.6061 - recall: 0.9654 - precision: 0.5651\n",
            "Epoch 238: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.6087 - accuracy: 0.6133 - sensitivity_at_specificity: 0.6842 - specificity_at_sensitivity: 0.6061 - recall: 0.9654 - precision: 0.5651 - val_loss: 0.4715 - val_accuracy: 0.7844 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7792 - val_recall: 0.9864 - val_precision: 0.7104\n",
            "Epoch 239/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6073 - accuracy: 0.6230 - sensitivity_at_specificity: 0.7003 - specificity_at_sensitivity: 0.6629 - recall: 0.9694 - precision: 0.5782\n",
            "Epoch 239: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 179ms/step - loss: 0.6073 - accuracy: 0.6230 - sensitivity_at_specificity: 0.7003 - specificity_at_sensitivity: 0.6629 - recall: 0.9694 - precision: 0.5782 - val_loss: 0.4780 - val_accuracy: 0.7555 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7800 - val_recall: 0.9651 - val_precision: 0.6763\n",
            "Epoch 240/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6115 - accuracy: 0.6086 - sensitivity_at_specificity: 0.6436 - specificity_at_sensitivity: 0.6166 - recall: 0.9129 - precision: 0.5662\n",
            "Epoch 240: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.6115 - accuracy: 0.6086 - sensitivity_at_specificity: 0.6436 - specificity_at_sensitivity: 0.6166 - recall: 0.9129 - precision: 0.5662 - val_loss: 0.4785 - val_accuracy: 0.7680 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7535 - val_recall: 0.9596 - val_precision: 0.6948\n",
            "Epoch 241/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6118 - accuracy: 0.6102 - sensitivity_at_specificity: 0.6609 - specificity_at_sensitivity: 0.6379 - recall: 0.8867 - precision: 0.5669\n",
            "Epoch 241: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.6118 - accuracy: 0.6102 - sensitivity_at_specificity: 0.6609 - specificity_at_sensitivity: 0.6379 - recall: 0.8867 - precision: 0.5669 - val_loss: 0.4968 - val_accuracy: 0.7500 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7262 - val_recall: 0.9469 - val_precision: 0.6865\n",
            "Epoch 242/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6149 - accuracy: 0.6094 - sensitivity_at_specificity: 0.6941 - specificity_at_sensitivity: 0.6162 - recall: 0.9577 - precision: 0.5641\n",
            "Epoch 242: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 182ms/step - loss: 0.6149 - accuracy: 0.6094 - sensitivity_at_specificity: 0.6941 - specificity_at_sensitivity: 0.6162 - recall: 0.9577 - precision: 0.5641 - val_loss: 0.4683 - val_accuracy: 0.7820 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7865 - val_recall: 0.9696 - val_precision: 0.7109\n",
            "Epoch 243/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6079 - accuracy: 0.6219 - sensitivity_at_specificity: 0.6654 - specificity_at_sensitivity: 0.6066 - recall: 0.9389 - precision: 0.5775\n",
            "Epoch 243: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.6079 - accuracy: 0.6219 - sensitivity_at_specificity: 0.6654 - specificity_at_sensitivity: 0.6066 - recall: 0.9389 - precision: 0.5775 - val_loss: 0.4776 - val_accuracy: 0.7625 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7783 - val_recall: 0.9808 - val_precision: 0.6777\n",
            "Epoch 244/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6080 - accuracy: 0.6180 - sensitivity_at_specificity: 0.7161 - specificity_at_sensitivity: 0.6412 - recall: 0.9506 - precision: 0.5698\n",
            "Epoch 244: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.6080 - accuracy: 0.6180 - sensitivity_at_specificity: 0.7161 - specificity_at_sensitivity: 0.6412 - recall: 0.9506 - precision: 0.5698 - val_loss: 0.4686 - val_accuracy: 0.7797 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7684 - val_recall: 0.9828 - val_precision: 0.6992\n",
            "Epoch 245/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6134 - accuracy: 0.6098 - sensitivity_at_specificity: 0.6766 - specificity_at_sensitivity: 0.6253 - recall: 0.9355 - precision: 0.5646\n",
            "Epoch 245: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.6134 - accuracy: 0.6098 - sensitivity_at_specificity: 0.6766 - specificity_at_sensitivity: 0.6253 - recall: 0.9355 - precision: 0.5646 - val_loss: 0.4681 - val_accuracy: 0.7555 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7896 - val_recall: 0.9686 - val_precision: 0.6659\n",
            "Epoch 246/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6125 - accuracy: 0.6023 - sensitivity_at_specificity: 0.6768 - specificity_at_sensitivity: 0.6230 - recall: 0.9254 - precision: 0.5551\n",
            "Epoch 246: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.6125 - accuracy: 0.6023 - sensitivity_at_specificity: 0.6768 - specificity_at_sensitivity: 0.6230 - recall: 0.9254 - precision: 0.5551 - val_loss: 0.4779 - val_accuracy: 0.7711 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7697 - val_recall: 0.9412 - val_precision: 0.7045\n",
            "Epoch 247/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6185 - accuracy: 0.6080 - sensitivity_at_specificity: 0.6557 - specificity_at_sensitivity: 0.6180 - recall: 0.9133 - precision: 0.5633\n",
            "Epoch 247: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.6185 - accuracy: 0.6080 - sensitivity_at_specificity: 0.6557 - specificity_at_sensitivity: 0.6180 - recall: 0.9133 - precision: 0.5633 - val_loss: 0.4637 - val_accuracy: 0.7742 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7488 - val_recall: 0.9417 - val_precision: 0.7035\n",
            "Epoch 248/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6083 - accuracy: 0.6156 - sensitivity_at_specificity: 0.6884 - specificity_at_sensitivity: 0.6396 - recall: 0.8744 - precision: 0.5821\n",
            "Epoch 248: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.6083 - accuracy: 0.6156 - sensitivity_at_specificity: 0.6884 - specificity_at_sensitivity: 0.6396 - recall: 0.8744 - precision: 0.5821 - val_loss: 0.4634 - val_accuracy: 0.7945 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7213 - val_recall: 0.9785 - val_precision: 0.7193\n",
            "Epoch 249/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6183 - accuracy: 0.5955 - sensitivity_at_specificity: 0.6380 - specificity_at_sensitivity: 0.5325 - recall: 0.9708 - precision: 0.5457\n",
            "Epoch 249: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.6183 - accuracy: 0.5955 - sensitivity_at_specificity: 0.6380 - specificity_at_sensitivity: 0.5325 - recall: 0.9708 - precision: 0.5457 - val_loss: 0.4733 - val_accuracy: 0.7750 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7746 - val_recall: 0.9891 - val_precision: 0.6929\n",
            "Epoch 250/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6125 - accuracy: 0.6270 - sensitivity_at_specificity: 0.6502 - specificity_at_sensitivity: 0.5208 - recall: 0.9723 - precision: 0.5857\n",
            "Epoch 250: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.6125 - accuracy: 0.6270 - sensitivity_at_specificity: 0.6502 - specificity_at_sensitivity: 0.5208 - recall: 0.9723 - precision: 0.5857 - val_loss: 0.4634 - val_accuracy: 0.7836 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7068 - val_recall: 0.9968 - val_precision: 0.6961\n",
            "Epoch 251/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6168 - accuracy: 0.6154 - sensitivity_at_specificity: 0.6579 - specificity_at_sensitivity: 0.5805 - recall: 0.9449 - precision: 0.5722\n",
            "Epoch 251: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.6168 - accuracy: 0.6154 - sensitivity_at_specificity: 0.6579 - specificity_at_sensitivity: 0.5805 - recall: 0.9449 - precision: 0.5722 - val_loss: 0.4618 - val_accuracy: 0.7836 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7727 - val_recall: 0.9766 - val_precision: 0.7053\n",
            "Epoch 252/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6208 - accuracy: 0.5891 - sensitivity_at_specificity: 0.6483 - specificity_at_sensitivity: 0.6005 - recall: 0.9321 - precision: 0.5466\n",
            "Epoch 252: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.6208 - accuracy: 0.5891 - sensitivity_at_specificity: 0.6483 - specificity_at_sensitivity: 0.6005 - recall: 0.9321 - precision: 0.5466 - val_loss: 0.4830 - val_accuracy: 0.7672 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7546 - val_recall: 0.9905 - val_precision: 0.6819\n",
            "Epoch 253/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6173 - accuracy: 0.5977 - sensitivity_at_specificity: 0.6961 - specificity_at_sensitivity: 0.6375 - recall: 0.9190 - precision: 0.5523\n",
            "Epoch 253: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.6173 - accuracy: 0.5977 - sensitivity_at_specificity: 0.6961 - specificity_at_sensitivity: 0.6375 - recall: 0.9190 - precision: 0.5523 - val_loss: 0.4844 - val_accuracy: 0.7422 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7372 - val_recall: 0.9560 - val_precision: 0.6596\n",
            "Epoch 254/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6066 - accuracy: 0.6148 - sensitivity_at_specificity: 0.6808 - specificity_at_sensitivity: 0.6241 - recall: 0.8761 - precision: 0.5743\n",
            "Epoch 254: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.6066 - accuracy: 0.6148 - sensitivity_at_specificity: 0.6808 - specificity_at_sensitivity: 0.6241 - recall: 0.8761 - precision: 0.5743 - val_loss: 0.4742 - val_accuracy: 0.7508 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7364 - val_recall: 0.9355 - val_precision: 0.6752\n",
            "Epoch 255/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6110 - accuracy: 0.6074 - sensitivity_at_specificity: 0.6743 - specificity_at_sensitivity: 0.6238 - recall: 0.9148 - precision: 0.5639\n",
            "Epoch 255: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.6110 - accuracy: 0.6074 - sensitivity_at_specificity: 0.6743 - specificity_at_sensitivity: 0.6238 - recall: 0.9148 - precision: 0.5639 - val_loss: 0.4800 - val_accuracy: 0.7852 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7781 - val_recall: 0.9852 - val_precision: 0.7154\n",
            "Epoch 256/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6138 - accuracy: 0.6117 - sensitivity_at_specificity: 0.6573 - specificity_at_sensitivity: 0.6033 - recall: 0.9837 - precision: 0.5654\n",
            "Epoch 256: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.6138 - accuracy: 0.6117 - sensitivity_at_specificity: 0.6573 - specificity_at_sensitivity: 0.6033 - recall: 0.9837 - precision: 0.5654 - val_loss: 0.4670 - val_accuracy: 0.7789 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7757 - val_recall: 0.9906 - val_precision: 0.6953\n",
            "Epoch 257/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6086 - accuracy: 0.6223 - sensitivity_at_specificity: 0.6799 - specificity_at_sensitivity: 0.5915 - recall: 0.9549 - precision: 0.5748\n",
            "Epoch 257: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.6086 - accuracy: 0.6223 - sensitivity_at_specificity: 0.6799 - specificity_at_sensitivity: 0.5915 - recall: 0.9549 - precision: 0.5748 - val_loss: 0.4688 - val_accuracy: 0.7688 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7277 - val_recall: 0.9903 - val_precision: 0.6788\n",
            "Epoch 258/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6133 - accuracy: 0.6156 - sensitivity_at_specificity: 0.6704 - specificity_at_sensitivity: 0.6015 - recall: 0.9375 - precision: 0.5672\n",
            "Epoch 258: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.6133 - accuracy: 0.6156 - sensitivity_at_specificity: 0.6704 - specificity_at_sensitivity: 0.6015 - recall: 0.9375 - precision: 0.5672 - val_loss: 0.4887 - val_accuracy: 0.7375 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7293 - val_recall: 0.9002 - val_precision: 0.6796\n",
            "Epoch 259/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6091 - accuracy: 0.6145 - sensitivity_at_specificity: 0.7029 - specificity_at_sensitivity: 0.6875 - recall: 0.8372 - precision: 0.5830\n",
            "Epoch 259: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.6091 - accuracy: 0.6145 - sensitivity_at_specificity: 0.7029 - specificity_at_sensitivity: 0.6875 - recall: 0.8372 - precision: 0.5830 - val_loss: 0.4652 - val_accuracy: 0.7734 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7748 - val_recall: 0.9528 - val_precision: 0.6998\n",
            "Epoch 260/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6232 - accuracy: 0.6008 - sensitivity_at_specificity: 0.6611 - specificity_at_sensitivity: 0.5626 - recall: 0.9621 - precision: 0.5557\n",
            "Epoch 260: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.6232 - accuracy: 0.6008 - sensitivity_at_specificity: 0.6611 - specificity_at_sensitivity: 0.5626 - recall: 0.9621 - precision: 0.5557 - val_loss: 0.4528 - val_accuracy: 0.7953 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7637 - val_recall: 0.9605 - val_precision: 0.7281\n",
            "Epoch 261/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6140 - accuracy: 0.6047 - sensitivity_at_specificity: 0.6612 - specificity_at_sensitivity: 0.6185 - recall: 0.9071 - precision: 0.5655\n",
            "Epoch 261: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.6140 - accuracy: 0.6047 - sensitivity_at_specificity: 0.6612 - specificity_at_sensitivity: 0.6185 - recall: 0.9071 - precision: 0.5655 - val_loss: 0.4678 - val_accuracy: 0.7766 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7896 - val_recall: 0.9673 - val_precision: 0.7012\n",
            "Epoch 262/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6158 - accuracy: 0.6082 - sensitivity_at_specificity: 0.6641 - specificity_at_sensitivity: 0.6334 - recall: 0.9185 - precision: 0.5687\n",
            "Epoch 262: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.6158 - accuracy: 0.6082 - sensitivity_at_specificity: 0.6641 - specificity_at_sensitivity: 0.6334 - recall: 0.9185 - precision: 0.5687 - val_loss: 0.4860 - val_accuracy: 0.7531 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7570 - val_recall: 0.9511 - val_precision: 0.6791\n",
            "Epoch 263/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6064 - accuracy: 0.6117 - sensitivity_at_specificity: 0.7015 - specificity_at_sensitivity: 0.6500 - recall: 0.8730 - precision: 0.5741\n",
            "Epoch 263: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.6064 - accuracy: 0.6117 - sensitivity_at_specificity: 0.7015 - specificity_at_sensitivity: 0.6500 - recall: 0.8730 - precision: 0.5741 - val_loss: 0.4702 - val_accuracy: 0.7625 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7591 - val_recall: 0.9694 - val_precision: 0.6783\n",
            "Epoch 264/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6075 - accuracy: 0.6199 - sensitivity_at_specificity: 0.6442 - specificity_at_sensitivity: 0.6118 - recall: 0.9500 - precision: 0.5805\n",
            "Epoch 264: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.6075 - accuracy: 0.6199 - sensitivity_at_specificity: 0.6442 - specificity_at_sensitivity: 0.6118 - recall: 0.9500 - precision: 0.5805 - val_loss: 0.4573 - val_accuracy: 0.7836 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7813 - val_recall: 0.9888 - val_precision: 0.6963\n",
            "Epoch 265/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6196 - accuracy: 0.6172 - sensitivity_at_specificity: 0.6614 - specificity_at_sensitivity: 0.5608 - recall: 0.9715 - precision: 0.5793\n",
            "Epoch 265: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.6196 - accuracy: 0.6172 - sensitivity_at_specificity: 0.6614 - specificity_at_sensitivity: 0.5608 - recall: 0.9715 - precision: 0.5793 - val_loss: 0.4681 - val_accuracy: 0.7828 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7239 - val_recall: 0.9787 - val_precision: 0.7089\n",
            "Epoch 266/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6089 - accuracy: 0.6160 - sensitivity_at_specificity: 0.6950 - specificity_at_sensitivity: 0.6257 - recall: 0.9531 - precision: 0.5650\n",
            "Epoch 266: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.6089 - accuracy: 0.6160 - sensitivity_at_specificity: 0.6950 - specificity_at_sensitivity: 0.6257 - recall: 0.9531 - precision: 0.5650 - val_loss: 0.4722 - val_accuracy: 0.7641 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7984 - val_recall: 0.9473 - val_precision: 0.6951\n",
            "Epoch 267/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6129 - accuracy: 0.6125 - sensitivity_at_specificity: 0.6976 - specificity_at_sensitivity: 0.6434 - recall: 0.8984 - precision: 0.5694\n",
            "Epoch 267: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.6129 - accuracy: 0.6125 - sensitivity_at_specificity: 0.6976 - specificity_at_sensitivity: 0.6434 - recall: 0.8984 - precision: 0.5694 - val_loss: 0.4740 - val_accuracy: 0.7773 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8090 - val_recall: 0.9543 - val_precision: 0.7109\n",
            "Epoch 268/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6080 - accuracy: 0.6266 - sensitivity_at_specificity: 0.7244 - specificity_at_sensitivity: 0.6525 - recall: 0.9107 - precision: 0.5824\n",
            "Epoch 268: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 176ms/step - loss: 0.6080 - accuracy: 0.6266 - sensitivity_at_specificity: 0.7244 - specificity_at_sensitivity: 0.6525 - recall: 0.9107 - precision: 0.5824 - val_loss: 0.4667 - val_accuracy: 0.7578 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7898 - val_recall: 0.9544 - val_precision: 0.6751\n",
            "Epoch 269/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6030 - accuracy: 0.6313 - sensitivity_at_specificity: 0.6829 - specificity_at_sensitivity: 0.6537 - recall: 0.9034 - precision: 0.5788\n",
            "Epoch 269: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.6030 - accuracy: 0.6313 - sensitivity_at_specificity: 0.6829 - specificity_at_sensitivity: 0.6537 - recall: 0.9034 - precision: 0.5788 - val_loss: 0.4802 - val_accuracy: 0.7578 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7690 - val_recall: 0.9123 - val_precision: 0.7053\n",
            "Epoch 270/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6052 - accuracy: 0.6250 - sensitivity_at_specificity: 0.6583 - specificity_at_sensitivity: 0.6346 - recall: 0.9126 - precision: 0.5798\n",
            "Epoch 270: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.6052 - accuracy: 0.6250 - sensitivity_at_specificity: 0.6583 - specificity_at_sensitivity: 0.6346 - recall: 0.9126 - precision: 0.5798 - val_loss: 0.4581 - val_accuracy: 0.7805 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7935 - val_recall: 0.9827 - val_precision: 0.6983\n",
            "Epoch 271/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6101 - accuracy: 0.6094 - sensitivity_at_specificity: 0.7055 - specificity_at_sensitivity: 0.6651 - recall: 0.9575 - precision: 0.5624\n",
            "Epoch 271: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.6101 - accuracy: 0.6094 - sensitivity_at_specificity: 0.7055 - specificity_at_sensitivity: 0.6651 - recall: 0.9575 - precision: 0.5624 - val_loss: 0.4689 - val_accuracy: 0.7727 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7598 - val_recall: 0.9844 - val_precision: 0.6912\n",
            "Epoch 272/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6222 - accuracy: 0.5992 - sensitivity_at_specificity: 0.6429 - specificity_at_sensitivity: 0.6606 - recall: 0.8612 - precision: 0.5571\n",
            "Epoch 272: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.6222 - accuracy: 0.5992 - sensitivity_at_specificity: 0.6429 - specificity_at_sensitivity: 0.6606 - recall: 0.8612 - precision: 0.5571 - val_loss: 0.4785 - val_accuracy: 0.7492 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7896 - val_recall: 0.8622 - val_precision: 0.6960\n",
            "Epoch 273/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6067 - accuracy: 0.6195 - sensitivity_at_specificity: 0.6941 - specificity_at_sensitivity: 0.6101 - recall: 0.9317 - precision: 0.5753\n",
            "Epoch 273: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.6067 - accuracy: 0.6195 - sensitivity_at_specificity: 0.6941 - specificity_at_sensitivity: 0.6101 - recall: 0.9317 - precision: 0.5753 - val_loss: 0.4550 - val_accuracy: 0.7883 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7143 - val_recall: 0.9829 - val_precision: 0.7085\n",
            "Epoch 274/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6095 - accuracy: 0.6211 - sensitivity_at_specificity: 0.6449 - specificity_at_sensitivity: 0.5207 - recall: 0.9801 - precision: 0.5752\n",
            "Epoch 274: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.6095 - accuracy: 0.6211 - sensitivity_at_specificity: 0.6449 - specificity_at_sensitivity: 0.5207 - recall: 0.9801 - precision: 0.5752 - val_loss: 0.4546 - val_accuracy: 0.7906 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7943 - val_recall: 0.9689 - val_precision: 0.7153\n",
            "Epoch 275/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6063 - accuracy: 0.6164 - sensitivity_at_specificity: 0.6833 - specificity_at_sensitivity: 0.6423 - recall: 0.9325 - precision: 0.5671\n",
            "Epoch 275: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.6063 - accuracy: 0.6164 - sensitivity_at_specificity: 0.6833 - specificity_at_sensitivity: 0.6423 - recall: 0.9325 - precision: 0.5671 - val_loss: 0.4695 - val_accuracy: 0.7625 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7669 - val_recall: 0.9203 - val_precision: 0.6894\n",
            "Epoch 276/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6136 - accuracy: 0.6145 - sensitivity_at_specificity: 0.6614 - specificity_at_sensitivity: 0.6574 - recall: 0.8584 - precision: 0.5732\n",
            "Epoch 276: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.6136 - accuracy: 0.6145 - sensitivity_at_specificity: 0.6614 - specificity_at_sensitivity: 0.6574 - recall: 0.8584 - precision: 0.5732 - val_loss: 0.4747 - val_accuracy: 0.7516 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7911 - val_recall: 0.8792 - val_precision: 0.6956\n",
            "Epoch 277/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6076 - accuracy: 0.6062 - sensitivity_at_specificity: 0.7223 - specificity_at_sensitivity: 0.6709 - recall: 0.8324 - precision: 0.5621\n",
            "Epoch 277: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.6076 - accuracy: 0.6062 - sensitivity_at_specificity: 0.7223 - specificity_at_sensitivity: 0.6709 - recall: 0.8324 - precision: 0.5621 - val_loss: 0.4753 - val_accuracy: 0.7781 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7724 - val_recall: 0.9549 - val_precision: 0.7143\n",
            "Epoch 278/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6102 - accuracy: 0.6250 - sensitivity_at_specificity: 0.6871 - specificity_at_sensitivity: 0.6407 - recall: 0.9061 - precision: 0.5818\n",
            "Epoch 278: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.6102 - accuracy: 0.6250 - sensitivity_at_specificity: 0.6871 - specificity_at_sensitivity: 0.6407 - recall: 0.9061 - precision: 0.5818 - val_loss: 0.4580 - val_accuracy: 0.7805 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8152 - val_recall: 0.9660 - val_precision: 0.7070\n",
            "Epoch 279/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6075 - accuracy: 0.6184 - sensitivity_at_specificity: 0.7033 - specificity_at_sensitivity: 0.6613 - recall: 0.9153 - precision: 0.5708\n",
            "Epoch 279: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.6075 - accuracy: 0.6184 - sensitivity_at_specificity: 0.7033 - specificity_at_sensitivity: 0.6613 - recall: 0.9153 - precision: 0.5708 - val_loss: 0.4613 - val_accuracy: 0.7602 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7851 - val_recall: 0.9000 - val_precision: 0.6906\n",
            "Epoch 280/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6119 - accuracy: 0.6230 - sensitivity_at_specificity: 0.7259 - specificity_at_sensitivity: 0.6816 - recall: 0.8634 - precision: 0.5850\n",
            "Epoch 280: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.6119 - accuracy: 0.6230 - sensitivity_at_specificity: 0.7259 - specificity_at_sensitivity: 0.6816 - recall: 0.8634 - precision: 0.5850 - val_loss: 0.4708 - val_accuracy: 0.7531 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8230 - val_recall: 0.9057 - val_precision: 0.6923\n",
            "Epoch 281/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6067 - accuracy: 0.6160 - sensitivity_at_specificity: 0.7144 - specificity_at_sensitivity: 0.6408 - recall: 0.8961 - precision: 0.5724\n",
            "Epoch 281: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.6067 - accuracy: 0.6160 - sensitivity_at_specificity: 0.7144 - specificity_at_sensitivity: 0.6408 - recall: 0.8961 - precision: 0.5724 - val_loss: 0.4737 - val_accuracy: 0.7680 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8083 - val_recall: 0.9006 - val_precision: 0.7174\n",
            "Epoch 282/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6137 - accuracy: 0.6082 - sensitivity_at_specificity: 0.6869 - specificity_at_sensitivity: 0.6245 - recall: 0.8709 - precision: 0.5651\n",
            "Epoch 282: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 187ms/step - loss: 0.6137 - accuracy: 0.6082 - sensitivity_at_specificity: 0.6869 - specificity_at_sensitivity: 0.6245 - recall: 0.8709 - precision: 0.5651 - val_loss: 0.4607 - val_accuracy: 0.7672 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8015 - val_recall: 0.9765 - val_precision: 0.6717\n",
            "Epoch 283/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6129 - accuracy: 0.6105 - sensitivity_at_specificity: 0.6875 - specificity_at_sensitivity: 0.6620 - recall: 0.8972 - precision: 0.5667\n",
            "Epoch 283: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.6129 - accuracy: 0.6105 - sensitivity_at_specificity: 0.6875 - specificity_at_sensitivity: 0.6620 - recall: 0.8972 - precision: 0.5667 - val_loss: 0.4713 - val_accuracy: 0.7664 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7860 - val_recall: 0.9386 - val_precision: 0.6963\n",
            "Epoch 284/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6202 - accuracy: 0.6102 - sensitivity_at_specificity: 0.6537 - specificity_at_sensitivity: 0.6091 - recall: 0.9376 - precision: 0.5736\n",
            "Epoch 284: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.6202 - accuracy: 0.6102 - sensitivity_at_specificity: 0.6537 - specificity_at_sensitivity: 0.6091 - recall: 0.9376 - precision: 0.5736 - val_loss: 0.4621 - val_accuracy: 0.7797 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7825 - val_recall: 0.9828 - val_precision: 0.6992\n",
            "Epoch 285/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6103 - accuracy: 0.6039 - sensitivity_at_specificity: 0.6702 - specificity_at_sensitivity: 0.6508 - recall: 0.9040 - precision: 0.5561\n",
            "Epoch 285: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.6103 - accuracy: 0.6039 - sensitivity_at_specificity: 0.6702 - specificity_at_sensitivity: 0.6508 - recall: 0.9040 - precision: 0.5561 - val_loss: 0.4824 - val_accuracy: 0.7531 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7931 - val_recall: 0.9097 - val_precision: 0.6936\n",
            "Epoch 286/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6125 - accuracy: 0.6223 - sensitivity_at_specificity: 0.6986 - specificity_at_sensitivity: 0.6553 - recall: 0.8852 - precision: 0.5898\n",
            "Epoch 286: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.6125 - accuracy: 0.6223 - sensitivity_at_specificity: 0.6986 - specificity_at_sensitivity: 0.6553 - recall: 0.8852 - precision: 0.5898 - val_loss: 0.4622 - val_accuracy: 0.7922 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8170 - val_recall: 0.9768 - val_precision: 0.7154\n",
            "Epoch 287/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6042 - accuracy: 0.6164 - sensitivity_at_specificity: 0.7152 - specificity_at_sensitivity: 0.6654 - recall: 0.9421 - precision: 0.5701\n",
            "Epoch 287: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.6042 - accuracy: 0.6164 - sensitivity_at_specificity: 0.7152 - specificity_at_sensitivity: 0.6654 - recall: 0.9421 - precision: 0.5701 - val_loss: 0.4706 - val_accuracy: 0.7711 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7531 - val_recall: 0.9719 - val_precision: 0.6934\n",
            "Epoch 288/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6092 - accuracy: 0.6152 - sensitivity_at_specificity: 0.6659 - specificity_at_sensitivity: 0.6408 - recall: 0.8526 - precision: 0.5819\n",
            "Epoch 288: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.6092 - accuracy: 0.6152 - sensitivity_at_specificity: 0.6659 - specificity_at_sensitivity: 0.6408 - recall: 0.8526 - precision: 0.5819 - val_loss: 0.4668 - val_accuracy: 0.7734 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7667 - val_recall: 0.9608 - val_precision: 0.6978\n",
            "Epoch 289/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6144 - accuracy: 0.6156 - sensitivity_at_specificity: 0.6503 - specificity_at_sensitivity: 0.6443 - recall: 0.9149 - precision: 0.5725\n",
            "Epoch 289: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.6144 - accuracy: 0.6156 - sensitivity_at_specificity: 0.6503 - specificity_at_sensitivity: 0.6443 - recall: 0.9149 - precision: 0.5725 - val_loss: 0.4884 - val_accuracy: 0.7492 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7853 - val_recall: 0.9436 - val_precision: 0.6855\n",
            "Epoch 290/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6103 - accuracy: 0.6129 - sensitivity_at_specificity: 0.7006 - specificity_at_sensitivity: 0.6303 - recall: 0.8681 - precision: 0.5699\n",
            "Epoch 290: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.6103 - accuracy: 0.6129 - sensitivity_at_specificity: 0.7006 - specificity_at_sensitivity: 0.6303 - recall: 0.8681 - precision: 0.5699 - val_loss: 0.4802 - val_accuracy: 0.7664 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7928 - val_recall: 0.9596 - val_precision: 0.6933\n",
            "Epoch 291/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6061 - accuracy: 0.6293 - sensitivity_at_specificity: 0.7374 - specificity_at_sensitivity: 0.6798 - recall: 0.9102 - precision: 0.5900\n",
            "Epoch 291: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.6061 - accuracy: 0.6293 - sensitivity_at_specificity: 0.7374 - specificity_at_sensitivity: 0.6798 - recall: 0.9102 - precision: 0.5900 - val_loss: 0.4652 - val_accuracy: 0.7688 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7508 - val_recall: 0.9936 - val_precision: 0.6805\n",
            "Epoch 292/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6154 - accuracy: 0.6102 - sensitivity_at_specificity: 0.6559 - specificity_at_sensitivity: 0.5952 - recall: 0.9144 - precision: 0.5670\n",
            "Epoch 292: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 187ms/step - loss: 0.6154 - accuracy: 0.6102 - sensitivity_at_specificity: 0.6559 - specificity_at_sensitivity: 0.5952 - recall: 0.9144 - precision: 0.5670 - val_loss: 0.4605 - val_accuracy: 0.7867 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7869 - val_recall: 0.9969 - val_precision: 0.7009\n",
            "Epoch 293/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6174 - accuracy: 0.6027 - sensitivity_at_specificity: 0.6727 - specificity_at_sensitivity: 0.5949 - recall: 0.9890 - precision: 0.5568\n",
            "Epoch 293: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.6174 - accuracy: 0.6027 - sensitivity_at_specificity: 0.6727 - specificity_at_sensitivity: 0.5949 - recall: 0.9890 - precision: 0.5568 - val_loss: 0.4719 - val_accuracy: 0.7719 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7708 - val_recall: 0.9984 - val_precision: 0.6837\n",
            "Epoch 294/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6118 - accuracy: 0.6156 - sensitivity_at_specificity: 0.6836 - specificity_at_sensitivity: 0.5472 - recall: 0.9742 - precision: 0.5667\n",
            "Epoch 294: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.6118 - accuracy: 0.6156 - sensitivity_at_specificity: 0.6836 - specificity_at_sensitivity: 0.5472 - recall: 0.9742 - precision: 0.5667 - val_loss: 0.4717 - val_accuracy: 0.7734 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7425 - val_recall: 0.9813 - val_precision: 0.6942\n",
            "Epoch 295/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6126 - accuracy: 0.6156 - sensitivity_at_specificity: 0.6716 - specificity_at_sensitivity: 0.6370 - recall: 0.9445 - precision: 0.5695\n",
            "Epoch 295: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.6126 - accuracy: 0.6156 - sensitivity_at_specificity: 0.6716 - specificity_at_sensitivity: 0.6370 - recall: 0.9445 - precision: 0.5695 - val_loss: 0.4873 - val_accuracy: 0.7648 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8101 - val_recall: 0.9022 - val_precision: 0.7254\n",
            "Epoch 296/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5974 - accuracy: 0.6328 - sensitivity_at_specificity: 0.7288 - specificity_at_sensitivity: 0.6906 - recall: 0.8694 - precision: 0.5967\n",
            "Epoch 296: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.5974 - accuracy: 0.6328 - sensitivity_at_specificity: 0.7288 - specificity_at_sensitivity: 0.6906 - recall: 0.8694 - precision: 0.5967 - val_loss: 0.4737 - val_accuracy: 0.7711 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7767 - val_recall: 0.9816 - val_precision: 0.6952\n",
            "Epoch 297/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6071 - accuracy: 0.6168 - sensitivity_at_specificity: 0.6924 - specificity_at_sensitivity: 0.6622 - recall: 0.9516 - precision: 0.5702\n",
            "Epoch 297: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 176ms/step - loss: 0.6071 - accuracy: 0.6168 - sensitivity_at_specificity: 0.6924 - specificity_at_sensitivity: 0.6622 - recall: 0.9516 - precision: 0.5702 - val_loss: 0.4644 - val_accuracy: 0.7648 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7903 - val_recall: 0.9727 - val_precision: 0.6805\n",
            "Epoch 298/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.6125 - accuracy: 0.6211 - sensitivity_at_specificity: 0.7174 - specificity_at_sensitivity: 0.6720 - recall: 0.9010 - precision: 0.5848\n",
            "Epoch 298: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.6116 - accuracy: 0.6217 - sensitivity_at_specificity: 0.7139 - specificity_at_sensitivity: 0.6755 - recall: 0.8987 - precision: 0.5852 - val_loss: 0.4820 - val_accuracy: 0.7680 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8253 - val_recall: 0.9604 - val_precision: 0.6992\n",
            "Epoch 299/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6011 - accuracy: 0.6320 - sensitivity_at_specificity: 0.7281 - specificity_at_sensitivity: 0.6840 - recall: 0.8911 - precision: 0.5942\n",
            "Epoch 299: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.6011 - accuracy: 0.6320 - sensitivity_at_specificity: 0.7281 - specificity_at_sensitivity: 0.6840 - recall: 0.8911 - precision: 0.5942 - val_loss: 0.4563 - val_accuracy: 0.7719 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8147 - val_recall: 0.9394 - val_precision: 0.6987\n",
            "Epoch 300/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6034 - accuracy: 0.6242 - sensitivity_at_specificity: 0.7241 - specificity_at_sensitivity: 0.6869 - recall: 0.8284 - precision: 0.5872\n",
            "Epoch 300: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.6034 - accuracy: 0.6242 - sensitivity_at_specificity: 0.7241 - specificity_at_sensitivity: 0.6869 - recall: 0.8284 - precision: 0.5872 - val_loss: 0.4750 - val_accuracy: 0.7648 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7946 - val_recall: 0.9586 - val_precision: 0.6952\n",
            "Epoch 301/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6103 - accuracy: 0.6217 - sensitivity_at_specificity: 0.7526 - specificity_at_sensitivity: 0.6831 - recall: 0.8707 - precision: 0.5683\n",
            "Epoch 301: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 157ms/step - loss: 0.6103 - accuracy: 0.6217 - sensitivity_at_specificity: 0.7526 - specificity_at_sensitivity: 0.6831 - recall: 0.8707 - precision: 0.5683 - val_loss: 0.5028 - val_accuracy: 0.7102 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7848 - val_recall: 0.7432 - val_precision: 0.7100\n",
            "Epoch 302/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6090 - accuracy: 0.6195 - sensitivity_at_specificity: 0.7160 - specificity_at_sensitivity: 0.6659 - recall: 0.8078 - precision: 0.5881\n",
            "Epoch 302: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.6090 - accuracy: 0.6195 - sensitivity_at_specificity: 0.7160 - specificity_at_sensitivity: 0.6659 - recall: 0.8078 - precision: 0.5881 - val_loss: 0.4673 - val_accuracy: 0.7586 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8006 - val_recall: 0.9554 - val_precision: 0.6810\n",
            "Epoch 303/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6082 - accuracy: 0.6309 - sensitivity_at_specificity: 0.7327 - specificity_at_sensitivity: 0.6174 - recall: 0.8943 - precision: 0.5872\n",
            "Epoch 303: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.6082 - accuracy: 0.6309 - sensitivity_at_specificity: 0.7327 - specificity_at_sensitivity: 0.6174 - recall: 0.8943 - precision: 0.5872 - val_loss: 0.4739 - val_accuracy: 0.7523 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7841 - val_recall: 0.9282 - val_precision: 0.6815\n",
            "Epoch 304/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6088 - accuracy: 0.6113 - sensitivity_at_specificity: 0.6478 - specificity_at_sensitivity: 0.6595 - recall: 0.9559 - precision: 0.5652\n",
            "Epoch 304: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.6088 - accuracy: 0.6113 - sensitivity_at_specificity: 0.6478 - specificity_at_sensitivity: 0.6595 - recall: 0.9559 - precision: 0.5652 - val_loss: 0.4598 - val_accuracy: 0.7828 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7883 - val_recall: 0.9567 - val_precision: 0.7123\n",
            "Epoch 305/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6056 - accuracy: 0.6270 - sensitivity_at_specificity: 0.6233 - specificity_at_sensitivity: 0.6164 - recall: 0.9472 - precision: 0.5827\n",
            "Epoch 305: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.6056 - accuracy: 0.6270 - sensitivity_at_specificity: 0.6233 - specificity_at_sensitivity: 0.6164 - recall: 0.9472 - precision: 0.5827 - val_loss: 0.4717 - val_accuracy: 0.7812 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7729 - val_recall: 0.9742 - val_precision: 0.7094\n",
            "Epoch 306/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6119 - accuracy: 0.6191 - sensitivity_at_specificity: 0.7532 - specificity_at_sensitivity: 0.6685 - recall: 0.8937 - precision: 0.5724\n",
            "Epoch 306: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.6119 - accuracy: 0.6191 - sensitivity_at_specificity: 0.7532 - specificity_at_sensitivity: 0.6685 - recall: 0.8937 - precision: 0.5724 - val_loss: 0.4782 - val_accuracy: 0.7516 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8054 - val_recall: 0.8622 - val_precision: 0.7118\n",
            "Epoch 307/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6077 - accuracy: 0.6090 - sensitivity_at_specificity: 0.7378 - specificity_at_sensitivity: 0.6973 - recall: 0.8223 - precision: 0.5702\n",
            "Epoch 307: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.6077 - accuracy: 0.6090 - sensitivity_at_specificity: 0.7378 - specificity_at_sensitivity: 0.6973 - recall: 0.8223 - precision: 0.5702 - val_loss: 0.4641 - val_accuracy: 0.7617 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8289 - val_recall: 0.9105 - val_precision: 0.7005\n",
            "Epoch 308/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6200 - accuracy: 0.6086 - sensitivity_at_specificity: 0.6834 - specificity_at_sensitivity: 0.6435 - recall: 0.8785 - precision: 0.5732\n",
            "Epoch 308: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.6200 - accuracy: 0.6086 - sensitivity_at_specificity: 0.6834 - specificity_at_sensitivity: 0.6435 - recall: 0.8785 - precision: 0.5732 - val_loss: 0.4762 - val_accuracy: 0.7570 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8341 - val_recall: 0.8239 - val_precision: 0.7330\n",
            "Epoch 309/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6101 - accuracy: 0.6293 - sensitivity_at_specificity: 0.7455 - specificity_at_sensitivity: 0.6949 - recall: 0.7339 - precision: 0.6084\n",
            "Epoch 309: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.6101 - accuracy: 0.6293 - sensitivity_at_specificity: 0.7455 - specificity_at_sensitivity: 0.6949 - recall: 0.7339 - precision: 0.6084 - val_loss: 0.4724 - val_accuracy: 0.7664 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8098 - val_recall: 0.9015 - val_precision: 0.7216\n",
            "Epoch 310/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6032 - accuracy: 0.6289 - sensitivity_at_specificity: 0.7414 - specificity_at_sensitivity: 0.6706 - recall: 0.8895 - precision: 0.5838\n",
            "Epoch 310: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.6032 - accuracy: 0.6289 - sensitivity_at_specificity: 0.7414 - specificity_at_sensitivity: 0.6706 - recall: 0.8895 - precision: 0.5838 - val_loss: 0.4821 - val_accuracy: 0.7734 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8264 - val_recall: 0.9289 - val_precision: 0.7215\n",
            "Epoch 311/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6039 - accuracy: 0.6387 - sensitivity_at_specificity: 0.7369 - specificity_at_sensitivity: 0.7017 - recall: 0.8750 - precision: 0.5978\n",
            "Epoch 311: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.6039 - accuracy: 0.6387 - sensitivity_at_specificity: 0.7369 - specificity_at_sensitivity: 0.7017 - recall: 0.8750 - precision: 0.5978 - val_loss: 0.4462 - val_accuracy: 0.7773 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8318 - val_recall: 0.9548 - val_precision: 0.6973\n",
            "Epoch 312/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5950 - accuracy: 0.6380 - sensitivity_at_specificity: 0.7650 - specificity_at_sensitivity: 0.7125 - recall: 0.8684 - precision: 0.5991\n",
            "Epoch 312: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.5959 - accuracy: 0.6354 - sensitivity_at_specificity: 0.7584 - specificity_at_sensitivity: 0.7145 - recall: 0.8636 - precision: 0.5961 - val_loss: 0.4525 - val_accuracy: 0.7539 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8582 - val_recall: 0.7672 - val_precision: 0.7301\n",
            "Epoch 313/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6044 - accuracy: 0.6293 - sensitivity_at_specificity: 0.7219 - specificity_at_sensitivity: 0.6807 - recall: 0.8213 - precision: 0.5979\n",
            "Epoch 313: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.6044 - accuracy: 0.6293 - sensitivity_at_specificity: 0.7219 - specificity_at_sensitivity: 0.6807 - recall: 0.8213 - precision: 0.5979 - val_loss: 0.4625 - val_accuracy: 0.7680 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8096 - val_recall: 0.9811 - val_precision: 0.6858\n",
            "Epoch 314/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6215 - accuracy: 0.6000 - sensitivity_at_specificity: 0.6766 - specificity_at_sensitivity: 0.6586 - recall: 0.9248 - precision: 0.5600\n",
            "Epoch 314: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.6215 - accuracy: 0.6000 - sensitivity_at_specificity: 0.6766 - specificity_at_sensitivity: 0.6586 - recall: 0.9248 - precision: 0.5600 - val_loss: 0.4695 - val_accuracy: 0.7781 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7695 - val_recall: 0.9734 - val_precision: 0.6993\n",
            "Epoch 315/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6108 - accuracy: 0.6172 - sensitivity_at_specificity: 0.6764 - specificity_at_sensitivity: 0.6552 - recall: 0.8064 - precision: 0.5918\n",
            "Epoch 315: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.6108 - accuracy: 0.6172 - sensitivity_at_specificity: 0.6764 - specificity_at_sensitivity: 0.6552 - recall: 0.8064 - precision: 0.5918 - val_loss: 0.4768 - val_accuracy: 0.7664 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7825 - val_recall: 0.9423 - val_precision: 0.6975\n",
            "Epoch 316/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6125 - accuracy: 0.6121 - sensitivity_at_specificity: 0.6892 - specificity_at_sensitivity: 0.6371 - recall: 0.9526 - precision: 0.5681\n",
            "Epoch 316: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.6125 - accuracy: 0.6121 - sensitivity_at_specificity: 0.6892 - specificity_at_sensitivity: 0.6371 - recall: 0.9526 - precision: 0.5681 - val_loss: 0.4781 - val_accuracy: 0.7617 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8003 - val_recall: 0.9457 - val_precision: 0.6928\n",
            "Epoch 317/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6023 - accuracy: 0.6258 - sensitivity_at_specificity: 0.7318 - specificity_at_sensitivity: 0.6845 - recall: 0.8958 - precision: 0.5871\n",
            "Epoch 317: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.6023 - accuracy: 0.6258 - sensitivity_at_specificity: 0.7318 - specificity_at_sensitivity: 0.6845 - recall: 0.8958 - precision: 0.5871 - val_loss: 0.4759 - val_accuracy: 0.7586 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8309 - val_recall: 0.8744 - val_precision: 0.7155\n",
            "Epoch 318/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6051 - accuracy: 0.6383 - sensitivity_at_specificity: 0.7435 - specificity_at_sensitivity: 0.6781 - recall: 0.8249 - precision: 0.6061\n",
            "Epoch 318: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.6051 - accuracy: 0.6383 - sensitivity_at_specificity: 0.7435 - specificity_at_sensitivity: 0.6781 - recall: 0.8249 - precision: 0.6061 - val_loss: 0.4718 - val_accuracy: 0.7547 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8260 - val_recall: 0.9289 - val_precision: 0.6805\n",
            "Epoch 319/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6036 - accuracy: 0.6273 - sensitivity_at_specificity: 0.7536 - specificity_at_sensitivity: 0.6746 - recall: 0.8381 - precision: 0.5832\n",
            "Epoch 319: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.6036 - accuracy: 0.6273 - sensitivity_at_specificity: 0.7536 - specificity_at_sensitivity: 0.6746 - recall: 0.8381 - precision: 0.5832 - val_loss: 0.4645 - val_accuracy: 0.7672 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8114 - val_recall: 0.9179 - val_precision: 0.7025\n",
            "Epoch 320/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5976 - accuracy: 0.6359 - sensitivity_at_specificity: 0.7553 - specificity_at_sensitivity: 0.7046 - recall: 0.8074 - precision: 0.5979\n",
            "Epoch 320: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.5976 - accuracy: 0.6359 - sensitivity_at_specificity: 0.7553 - specificity_at_sensitivity: 0.7046 - recall: 0.8074 - precision: 0.5979 - val_loss: 0.4766 - val_accuracy: 0.7500 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8133 - val_recall: 0.8904 - val_precision: 0.6985\n",
            "Epoch 321/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6004 - accuracy: 0.6348 - sensitivity_at_specificity: 0.7488 - specificity_at_sensitivity: 0.6835 - recall: 0.8815 - precision: 0.5889\n",
            "Epoch 321: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.6004 - accuracy: 0.6348 - sensitivity_at_specificity: 0.7488 - specificity_at_sensitivity: 0.6835 - recall: 0.8815 - precision: 0.5889 - val_loss: 0.4571 - val_accuracy: 0.7906 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8371 - val_recall: 0.9121 - val_precision: 0.7414\n",
            "Epoch 322/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6034 - accuracy: 0.6215 - sensitivity_at_specificity: 0.7363 - specificity_at_sensitivity: 0.7293 - recall: 0.8760 - precision: 0.5810\n",
            "Epoch 322: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.6034 - accuracy: 0.6215 - sensitivity_at_specificity: 0.7363 - specificity_at_sensitivity: 0.7293 - recall: 0.8760 - precision: 0.5810 - val_loss: 0.4795 - val_accuracy: 0.7602 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8096 - val_recall: 0.8975 - val_precision: 0.7016\n",
            "Epoch 323/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5990 - accuracy: 0.6348 - sensitivity_at_specificity: 0.7863 - specificity_at_sensitivity: 0.7260 - recall: 0.8233 - precision: 0.5949\n",
            "Epoch 323: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.5990 - accuracy: 0.6348 - sensitivity_at_specificity: 0.7863 - specificity_at_sensitivity: 0.7260 - recall: 0.8233 - precision: 0.5949 - val_loss: 0.4558 - val_accuracy: 0.7625 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8580 - val_recall: 0.8736 - val_precision: 0.7082\n",
            "Epoch 324/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6042 - accuracy: 0.6324 - sensitivity_at_specificity: 0.7360 - specificity_at_sensitivity: 0.6923 - recall: 0.7898 - precision: 0.6057\n",
            "Epoch 324: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.6042 - accuracy: 0.6324 - sensitivity_at_specificity: 0.7360 - specificity_at_sensitivity: 0.6923 - recall: 0.7898 - precision: 0.6057 - val_loss: 0.4748 - val_accuracy: 0.7437 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8310 - val_recall: 0.8252 - val_precision: 0.7072\n",
            "Epoch 325/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5942 - accuracy: 0.6402 - sensitivity_at_specificity: 0.7806 - specificity_at_sensitivity: 0.7276 - recall: 0.8605 - precision: 0.5997\n",
            "Epoch 325: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.5942 - accuracy: 0.6402 - sensitivity_at_specificity: 0.7806 - specificity_at_sensitivity: 0.7276 - recall: 0.8605 - precision: 0.5997 - val_loss: 0.4826 - val_accuracy: 0.7203 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8135 - val_recall: 0.8243 - val_precision: 0.6754\n",
            "Epoch 326/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6047 - accuracy: 0.6234 - sensitivity_at_specificity: 0.7144 - specificity_at_sensitivity: 0.6983 - recall: 0.8283 - precision: 0.5836\n",
            "Epoch 326: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.6047 - accuracy: 0.6234 - sensitivity_at_specificity: 0.7144 - specificity_at_sensitivity: 0.6983 - recall: 0.8283 - precision: 0.5836 - val_loss: 0.4762 - val_accuracy: 0.7477 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8000 - val_recall: 0.8754 - val_precision: 0.7016\n",
            "Epoch 327/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6115 - accuracy: 0.6125 - sensitivity_at_specificity: 0.6883 - specificity_at_sensitivity: 0.6438 - recall: 0.8512 - precision: 0.5754\n",
            "Epoch 327: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.6115 - accuracy: 0.6125 - sensitivity_at_specificity: 0.6883 - specificity_at_sensitivity: 0.6438 - recall: 0.8512 - precision: 0.5754 - val_loss: 0.4700 - val_accuracy: 0.7648 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8312 - val_recall: 0.8854 - val_precision: 0.7159\n",
            "Epoch 328/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6070 - accuracy: 0.6273 - sensitivity_at_specificity: 0.7172 - specificity_at_sensitivity: 0.6826 - recall: 0.8435 - precision: 0.5838\n",
            "Epoch 328: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.6070 - accuracy: 0.6273 - sensitivity_at_specificity: 0.7172 - specificity_at_sensitivity: 0.6826 - recall: 0.8435 - precision: 0.5838 - val_loss: 0.4794 - val_accuracy: 0.7266 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8388 - val_recall: 0.7426 - val_precision: 0.7201\n",
            "Epoch 329/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6091 - accuracy: 0.6250 - sensitivity_at_specificity: 0.7492 - specificity_at_sensitivity: 0.6915 - recall: 0.8765 - precision: 0.5868\n",
            "Epoch 329: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.6091 - accuracy: 0.6250 - sensitivity_at_specificity: 0.7492 - specificity_at_sensitivity: 0.6915 - recall: 0.8765 - precision: 0.5868 - val_loss: 0.4600 - val_accuracy: 0.7742 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8174 - val_recall: 0.9053 - val_precision: 0.7103\n",
            "Epoch 330/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6056 - accuracy: 0.6238 - sensitivity_at_specificity: 0.7288 - specificity_at_sensitivity: 0.6962 - recall: 0.7833 - precision: 0.5947\n",
            "Epoch 330: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.6056 - accuracy: 0.6238 - sensitivity_at_specificity: 0.7288 - specificity_at_sensitivity: 0.6962 - recall: 0.7833 - precision: 0.5947 - val_loss: 0.4734 - val_accuracy: 0.7391 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8288 - val_recall: 0.7863 - val_precision: 0.7264\n",
            "Epoch 331/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5920 - accuracy: 0.6520 - sensitivity_at_specificity: 0.7886 - specificity_at_sensitivity: 0.6978 - recall: 0.9167 - precision: 0.6027\n",
            "Epoch 331: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.5920 - accuracy: 0.6520 - sensitivity_at_specificity: 0.7886 - specificity_at_sensitivity: 0.6978 - recall: 0.9167 - precision: 0.6027 - val_loss: 0.4629 - val_accuracy: 0.7680 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8131 - val_recall: 0.9450 - val_precision: 0.7031\n",
            "Epoch 332/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6083 - accuracy: 0.6184 - sensitivity_at_specificity: 0.7189 - specificity_at_sensitivity: 0.6662 - recall: 0.7888 - precision: 0.5790\n",
            "Epoch 332: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.6083 - accuracy: 0.6184 - sensitivity_at_specificity: 0.7189 - specificity_at_sensitivity: 0.6662 - recall: 0.7888 - precision: 0.5790 - val_loss: 0.4791 - val_accuracy: 0.7391 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8328 - val_recall: 0.8186 - val_precision: 0.7033\n",
            "Epoch 333/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6007 - accuracy: 0.6074 - sensitivity_at_specificity: 0.7252 - specificity_at_sensitivity: 0.6892 - recall: 0.7921 - precision: 0.5604\n",
            "Epoch 333: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.6007 - accuracy: 0.6074 - sensitivity_at_specificity: 0.7252 - specificity_at_sensitivity: 0.6892 - recall: 0.7921 - precision: 0.5604 - val_loss: 0.4621 - val_accuracy: 0.7664 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8401 - val_recall: 0.8525 - val_precision: 0.7166\n",
            "Epoch 334/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5966 - accuracy: 0.6445 - sensitivity_at_specificity: 0.7555 - specificity_at_sensitivity: 0.7188 - recall: 0.8336 - precision: 0.6049\n",
            "Epoch 334: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.5966 - accuracy: 0.6445 - sensitivity_at_specificity: 0.7555 - specificity_at_sensitivity: 0.7188 - recall: 0.8336 - precision: 0.6049 - val_loss: 0.4649 - val_accuracy: 0.7656 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8237 - val_recall: 0.9108 - val_precision: 0.7055\n",
            "Epoch 335/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5957 - accuracy: 0.6341 - sensitivity_at_specificity: 0.7728 - specificity_at_sensitivity: 0.7316 - recall: 0.8622 - precision: 0.5904\n",
            "Epoch 335: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.5957 - accuracy: 0.6341 - sensitivity_at_specificity: 0.7728 - specificity_at_sensitivity: 0.7316 - recall: 0.8622 - precision: 0.5904 - val_loss: 0.4478 - val_accuracy: 0.7836 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8321 - val_recall: 0.9248 - val_precision: 0.7153\n",
            "Epoch 336/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5990 - accuracy: 0.6398 - sensitivity_at_specificity: 0.7527 - specificity_at_sensitivity: 0.7185 - recall: 0.8507 - precision: 0.6045\n",
            "Epoch 336: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.5990 - accuracy: 0.6398 - sensitivity_at_specificity: 0.7527 - specificity_at_sensitivity: 0.7185 - recall: 0.8507 - precision: 0.6045 - val_loss: 0.4612 - val_accuracy: 0.7617 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8351 - val_recall: 0.8681 - val_precision: 0.7145\n",
            "Epoch 337/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6077 - accuracy: 0.6156 - sensitivity_at_specificity: 0.7165 - specificity_at_sensitivity: 0.6859 - recall: 0.7972 - precision: 0.5841\n",
            "Epoch 337: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.6077 - accuracy: 0.6156 - sensitivity_at_specificity: 0.7165 - specificity_at_sensitivity: 0.6859 - recall: 0.7972 - precision: 0.5841 - val_loss: 0.4635 - val_accuracy: 0.7609 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8154 - val_recall: 0.8762 - val_precision: 0.7077\n",
            "Epoch 338/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5873 - accuracy: 0.6383 - sensitivity_at_specificity: 0.7574 - specificity_at_sensitivity: 0.7182 - recall: 0.7978 - precision: 0.6064\n",
            "Epoch 338: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.5873 - accuracy: 0.6383 - sensitivity_at_specificity: 0.7574 - specificity_at_sensitivity: 0.7182 - recall: 0.7978 - precision: 0.6064 - val_loss: 0.4662 - val_accuracy: 0.7648 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8424 - val_recall: 0.9271 - val_precision: 0.7068\n",
            "Epoch 339/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5878 - accuracy: 0.6535 - sensitivity_at_specificity: 0.8037 - specificity_at_sensitivity: 0.7474 - recall: 0.8891 - precision: 0.6063\n",
            "Epoch 339: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.5878 - accuracy: 0.6535 - sensitivity_at_specificity: 0.8037 - specificity_at_sensitivity: 0.7474 - recall: 0.8891 - precision: 0.6063 - val_loss: 0.4597 - val_accuracy: 0.7852 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8466 - val_recall: 0.9205 - val_precision: 0.7297\n",
            "Epoch 340/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5986 - accuracy: 0.6410 - sensitivity_at_specificity: 0.7799 - specificity_at_sensitivity: 0.7325 - recall: 0.7712 - precision: 0.6072\n",
            "Epoch 340: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.5986 - accuracy: 0.6410 - sensitivity_at_specificity: 0.7799 - specificity_at_sensitivity: 0.7325 - recall: 0.7712 - precision: 0.6072 - val_loss: 0.4507 - val_accuracy: 0.7781 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8326 - val_recall: 0.8876 - val_precision: 0.7210\n",
            "Epoch 341/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5925 - accuracy: 0.6496 - sensitivity_at_specificity: 0.7871 - specificity_at_sensitivity: 0.7512 - recall: 0.8323 - precision: 0.6159\n",
            "Epoch 341: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.5925 - accuracy: 0.6496 - sensitivity_at_specificity: 0.7871 - specificity_at_sensitivity: 0.7512 - recall: 0.8323 - precision: 0.6159 - val_loss: 0.4657 - val_accuracy: 0.7508 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8479 - val_recall: 0.8076 - val_precision: 0.7195\n",
            "Epoch 342/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5960 - accuracy: 0.6445 - sensitivity_at_specificity: 0.7622 - specificity_at_sensitivity: 0.7326 - recall: 0.7323 - precision: 0.6200\n",
            "Epoch 342: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.5960 - accuracy: 0.6445 - sensitivity_at_specificity: 0.7622 - specificity_at_sensitivity: 0.7326 - recall: 0.7323 - precision: 0.6200 - val_loss: 0.4592 - val_accuracy: 0.7656 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8457 - val_recall: 0.8212 - val_precision: 0.7351\n",
            "Epoch 343/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5969 - accuracy: 0.6430 - sensitivity_at_specificity: 0.7737 - specificity_at_sensitivity: 0.7284 - recall: 0.8095 - precision: 0.6088\n",
            "Epoch 343: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.5969 - accuracy: 0.6430 - sensitivity_at_specificity: 0.7737 - specificity_at_sensitivity: 0.7284 - recall: 0.8095 - precision: 0.6088 - val_loss: 0.4624 - val_accuracy: 0.7664 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8354 - val_recall: 0.8100 - val_precision: 0.7461\n",
            "Epoch 344/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5924 - accuracy: 0.6457 - sensitivity_at_specificity: 0.7853 - specificity_at_sensitivity: 0.7330 - recall: 0.7965 - precision: 0.6048\n",
            "Epoch 344: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.5924 - accuracy: 0.6457 - sensitivity_at_specificity: 0.7853 - specificity_at_sensitivity: 0.7330 - recall: 0.7965 - precision: 0.6048 - val_loss: 0.4682 - val_accuracy: 0.7523 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8501 - val_recall: 0.7393 - val_precision: 0.7548\n",
            "Epoch 345/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5907 - accuracy: 0.6445 - sensitivity_at_specificity: 0.7809 - specificity_at_sensitivity: 0.7392 - recall: 0.8204 - precision: 0.6029\n",
            "Epoch 345: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.5907 - accuracy: 0.6445 - sensitivity_at_specificity: 0.7809 - specificity_at_sensitivity: 0.7392 - recall: 0.8204 - precision: 0.6029 - val_loss: 0.4617 - val_accuracy: 0.7602 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8478 - val_recall: 0.7736 - val_precision: 0.7511\n",
            "Epoch 346/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5959 - accuracy: 0.6418 - sensitivity_at_specificity: 0.7569 - specificity_at_sensitivity: 0.7381 - recall: 0.7977 - precision: 0.6132\n",
            "Epoch 346: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.5959 - accuracy: 0.6418 - sensitivity_at_specificity: 0.7569 - specificity_at_sensitivity: 0.7381 - recall: 0.7977 - precision: 0.6132 - val_loss: 0.4418 - val_accuracy: 0.7828 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8563 - val_recall: 0.9352 - val_precision: 0.7141\n",
            "Epoch 347/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5876 - accuracy: 0.6621 - sensitivity_at_specificity: 0.8183 - specificity_at_sensitivity: 0.7739 - recall: 0.8367 - precision: 0.6259\n",
            "Epoch 347: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.5876 - accuracy: 0.6621 - sensitivity_at_specificity: 0.8183 - specificity_at_sensitivity: 0.7739 - recall: 0.8367 - precision: 0.6259 - val_loss: 0.4645 - val_accuracy: 0.7688 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8346 - val_recall: 0.8153 - val_precision: 0.7454\n",
            "Epoch 348/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5897 - accuracy: 0.6492 - sensitivity_at_specificity: 0.7895 - specificity_at_sensitivity: 0.7453 - recall: 0.8406 - precision: 0.6108\n",
            "Epoch 348: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.5897 - accuracy: 0.6492 - sensitivity_at_specificity: 0.7895 - specificity_at_sensitivity: 0.7453 - recall: 0.8406 - precision: 0.6108 - val_loss: 0.4550 - val_accuracy: 0.7828 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8264 - val_recall: 0.8929 - val_precision: 0.7297\n",
            "Epoch 349/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5946 - accuracy: 0.6457 - sensitivity_at_specificity: 0.7908 - specificity_at_sensitivity: 0.7355 - recall: 0.8069 - precision: 0.6165\n",
            "Epoch 349: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.5946 - accuracy: 0.6457 - sensitivity_at_specificity: 0.7908 - specificity_at_sensitivity: 0.7355 - recall: 0.8069 - precision: 0.6165 - val_loss: 0.4395 - val_accuracy: 0.7711 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8498 - val_recall: 0.8857 - val_precision: 0.7124\n",
            "Epoch 350/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5904 - accuracy: 0.6512 - sensitivity_at_specificity: 0.7953 - specificity_at_sensitivity: 0.7279 - recall: 0.8008 - precision: 0.6138\n",
            "Epoch 350: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.5904 - accuracy: 0.6512 - sensitivity_at_specificity: 0.7953 - specificity_at_sensitivity: 0.7279 - recall: 0.8008 - precision: 0.6138 - val_loss: 0.4581 - val_accuracy: 0.7641 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8218 - val_recall: 0.8498 - val_precision: 0.7281\n",
            "Epoch 351/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5941 - accuracy: 0.6445 - sensitivity_at_specificity: 0.7800 - specificity_at_sensitivity: 0.7407 - recall: 0.7986 - precision: 0.6133\n",
            "Epoch 351: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.5941 - accuracy: 0.6445 - sensitivity_at_specificity: 0.7800 - specificity_at_sensitivity: 0.7407 - recall: 0.7986 - precision: 0.6133 - val_loss: 0.4586 - val_accuracy: 0.7469 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8418 - val_recall: 0.7793 - val_precision: 0.7362\n",
            "Epoch 352/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5886 - accuracy: 0.6320 - sensitivity_at_specificity: 0.7752 - specificity_at_sensitivity: 0.7688 - recall: 0.7631 - precision: 0.5937\n",
            "Epoch 352: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.5886 - accuracy: 0.6320 - sensitivity_at_specificity: 0.7752 - specificity_at_sensitivity: 0.7688 - recall: 0.7631 - precision: 0.5937 - val_loss: 0.4474 - val_accuracy: 0.7797 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8387 - val_recall: 0.8839 - val_precision: 0.7268\n",
            "Epoch 353/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5923 - accuracy: 0.6430 - sensitivity_at_specificity: 0.7919 - specificity_at_sensitivity: 0.7525 - recall: 0.8044 - precision: 0.6088\n",
            "Epoch 353: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.5923 - accuracy: 0.6430 - sensitivity_at_specificity: 0.7919 - specificity_at_sensitivity: 0.7525 - recall: 0.8044 - precision: 0.6088 - val_loss: 0.4661 - val_accuracy: 0.7656 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8396 - val_recall: 0.8119 - val_precision: 0.7421\n",
            "Epoch 354/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5865 - accuracy: 0.6594 - sensitivity_at_specificity: 0.7989 - specificity_at_sensitivity: 0.7367 - recall: 0.8209 - precision: 0.6298\n",
            "Epoch 354: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.5865 - accuracy: 0.6594 - sensitivity_at_specificity: 0.7989 - specificity_at_sensitivity: 0.7367 - recall: 0.8209 - precision: 0.6298 - val_loss: 0.4555 - val_accuracy: 0.7891 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8299 - val_recall: 0.9101 - val_precision: 0.7347\n",
            "Epoch 355/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5722 - accuracy: 0.6621 - sensitivity_at_specificity: 0.8251 - specificity_at_sensitivity: 0.7805 - recall: 0.8821 - precision: 0.6166\n",
            "Epoch 355: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.5722 - accuracy: 0.6621 - sensitivity_at_specificity: 0.8251 - specificity_at_sensitivity: 0.7805 - recall: 0.8821 - precision: 0.6166 - val_loss: 0.4795 - val_accuracy: 0.7297 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7911 - val_recall: 0.7440 - val_precision: 0.7167\n",
            "Epoch 356/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5768 - accuracy: 0.6621 - sensitivity_at_specificity: 0.8140 - specificity_at_sensitivity: 0.7788 - recall: 0.7541 - precision: 0.6383\n",
            "Epoch 356: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.5768 - accuracy: 0.6621 - sensitivity_at_specificity: 0.8140 - specificity_at_sensitivity: 0.7788 - recall: 0.7541 - precision: 0.6383 - val_loss: 0.4638 - val_accuracy: 0.7695 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8122 - val_recall: 0.8624 - val_precision: 0.7206\n",
            "Epoch 357/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5908 - accuracy: 0.6555 - sensitivity_at_specificity: 0.7849 - specificity_at_sensitivity: 0.7854 - recall: 0.7268 - precision: 0.6242\n",
            "Epoch 357: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.5908 - accuracy: 0.6555 - sensitivity_at_specificity: 0.7849 - specificity_at_sensitivity: 0.7854 - recall: 0.7268 - precision: 0.6242 - val_loss: 0.4384 - val_accuracy: 0.7953 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8282 - val_recall: 0.8896 - val_precision: 0.7460\n",
            "Epoch 358/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6006 - accuracy: 0.6391 - sensitivity_at_specificity: 0.7311 - specificity_at_sensitivity: 0.6586 - recall: 0.8965 - precision: 0.6013\n",
            "Epoch 358: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.6006 - accuracy: 0.6391 - sensitivity_at_specificity: 0.7311 - specificity_at_sensitivity: 0.6586 - recall: 0.8965 - precision: 0.6013 - val_loss: 0.4607 - val_accuracy: 0.7664 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8304 - val_recall: 0.8916 - val_precision: 0.7192\n",
            "Epoch 359/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6049 - accuracy: 0.6391 - sensitivity_at_specificity: 0.7355 - specificity_at_sensitivity: 0.6577 - recall: 0.8774 - precision: 0.5962\n",
            "Epoch 359: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.6049 - accuracy: 0.6391 - sensitivity_at_specificity: 0.7355 - specificity_at_sensitivity: 0.6577 - recall: 0.8774 - precision: 0.5962 - val_loss: 0.4597 - val_accuracy: 0.7609 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8217 - val_recall: 0.9193 - val_precision: 0.6847\n",
            "Epoch 360/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5961 - accuracy: 0.6438 - sensitivity_at_specificity: 0.7794 - specificity_at_sensitivity: 0.7103 - recall: 0.7903 - precision: 0.6119\n",
            "Epoch 360: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.5961 - accuracy: 0.6438 - sensitivity_at_specificity: 0.7794 - specificity_at_sensitivity: 0.7103 - recall: 0.7903 - precision: 0.6119 - val_loss: 0.4523 - val_accuracy: 0.7672 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8438 - val_recall: 0.9326 - val_precision: 0.6881\n",
            "Epoch 361/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5839 - accuracy: 0.6594 - sensitivity_at_specificity: 0.8203 - specificity_at_sensitivity: 0.7586 - recall: 0.8914 - precision: 0.6089\n",
            "Epoch 361: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.5839 - accuracy: 0.6594 - sensitivity_at_specificity: 0.8203 - specificity_at_sensitivity: 0.7586 - recall: 0.8914 - precision: 0.6089 - val_loss: 0.4659 - val_accuracy: 0.7641 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8406 - val_recall: 0.7922 - val_precision: 0.7500\n",
            "Epoch 362/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5904 - accuracy: 0.6617 - sensitivity_at_specificity: 0.8103 - specificity_at_sensitivity: 0.7332 - recall: 0.8186 - precision: 0.6337\n",
            "Epoch 362: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.5904 - accuracy: 0.6617 - sensitivity_at_specificity: 0.8103 - specificity_at_sensitivity: 0.7332 - recall: 0.8186 - precision: 0.6337 - val_loss: 0.4538 - val_accuracy: 0.7781 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8406 - val_recall: 0.9180 - val_precision: 0.7150\n",
            "Epoch 363/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5830 - accuracy: 0.6539 - sensitivity_at_specificity: 0.8040 - specificity_at_sensitivity: 0.7537 - recall: 0.7826 - precision: 0.6184\n",
            "Epoch 363: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.5830 - accuracy: 0.6539 - sensitivity_at_specificity: 0.8040 - specificity_at_sensitivity: 0.7537 - recall: 0.7826 - precision: 0.6184 - val_loss: 0.4678 - val_accuracy: 0.7625 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8547 - val_recall: 0.8642 - val_precision: 0.7118\n",
            "Epoch 364/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5851 - accuracy: 0.6586 - sensitivity_at_specificity: 0.8053 - specificity_at_sensitivity: 0.7735 - recall: 0.7882 - precision: 0.6270\n",
            "Epoch 364: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.5851 - accuracy: 0.6586 - sensitivity_at_specificity: 0.8053 - specificity_at_sensitivity: 0.7735 - recall: 0.7882 - precision: 0.6270 - val_loss: 0.4465 - val_accuracy: 0.7906 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8668 - val_recall: 0.8798 - val_precision: 0.7536\n",
            "Epoch 365/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5752 - accuracy: 0.6633 - sensitivity_at_specificity: 0.8138 - specificity_at_sensitivity: 0.7646 - recall: 0.7774 - precision: 0.6367\n",
            "Epoch 365: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.5752 - accuracy: 0.6633 - sensitivity_at_specificity: 0.8138 - specificity_at_sensitivity: 0.7646 - recall: 0.7774 - precision: 0.6367 - val_loss: 0.4544 - val_accuracy: 0.7891 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8089 - val_recall: 0.9417 - val_precision: 0.7258\n",
            "Epoch 366/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5744 - accuracy: 0.6715 - sensitivity_at_specificity: 0.8346 - specificity_at_sensitivity: 0.7775 - recall: 0.8300 - precision: 0.6322\n",
            "Epoch 366: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.5744 - accuracy: 0.6715 - sensitivity_at_specificity: 0.8346 - specificity_at_sensitivity: 0.7775 - recall: 0.8300 - precision: 0.6322 - val_loss: 0.4692 - val_accuracy: 0.7500 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8388 - val_recall: 0.7323 - val_precision: 0.7561\n",
            "Epoch 367/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5778 - accuracy: 0.6570 - sensitivity_at_specificity: 0.8234 - specificity_at_sensitivity: 0.7885 - recall: 0.7292 - precision: 0.6354\n",
            "Epoch 367: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.5778 - accuracy: 0.6570 - sensitivity_at_specificity: 0.8234 - specificity_at_sensitivity: 0.7885 - recall: 0.7292 - precision: 0.6354 - val_loss: 0.4387 - val_accuracy: 0.7859 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8424 - val_recall: 0.9048 - val_precision: 0.7229\n",
            "Epoch 368/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5817 - accuracy: 0.6641 - sensitivity_at_specificity: 0.8213 - specificity_at_sensitivity: 0.7736 - recall: 0.7556 - precision: 0.6295\n",
            "Epoch 368: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.5817 - accuracy: 0.6641 - sensitivity_at_specificity: 0.8213 - specificity_at_sensitivity: 0.7736 - recall: 0.7556 - precision: 0.6295 - val_loss: 0.4460 - val_accuracy: 0.7797 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8328 - val_recall: 0.8988 - val_precision: 0.7307\n",
            "Epoch 369/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5960 - accuracy: 0.6305 - sensitivity_at_specificity: 0.7502 - specificity_at_sensitivity: 0.7090 - recall: 0.8148 - precision: 0.5966\n",
            "Epoch 369: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.5960 - accuracy: 0.6305 - sensitivity_at_specificity: 0.7502 - specificity_at_sensitivity: 0.7090 - recall: 0.8148 - precision: 0.5966 - val_loss: 0.4628 - val_accuracy: 0.7422 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8320 - val_recall: 0.7639 - val_precision: 0.7270\n",
            "Epoch 370/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5897 - accuracy: 0.6422 - sensitivity_at_specificity: 0.7721 - specificity_at_sensitivity: 0.7436 - recall: 0.7552 - precision: 0.6052\n",
            "Epoch 370: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.5897 - accuracy: 0.6422 - sensitivity_at_specificity: 0.7721 - specificity_at_sensitivity: 0.7436 - recall: 0.7552 - precision: 0.6052 - val_loss: 0.4623 - val_accuracy: 0.7805 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8422 - val_recall: 0.8953 - val_precision: 0.7357\n",
            "Epoch 371/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5703 - accuracy: 0.6734 - sensitivity_at_specificity: 0.8515 - specificity_at_sensitivity: 0.7890 - recall: 0.8286 - precision: 0.6289\n",
            "Epoch 371: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.5703 - accuracy: 0.6734 - sensitivity_at_specificity: 0.8515 - specificity_at_sensitivity: 0.7890 - recall: 0.8286 - precision: 0.6289 - val_loss: 0.4696 - val_accuracy: 0.7578 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8228 - val_recall: 0.7865 - val_precision: 0.7569\n",
            "Epoch 372/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5842 - accuracy: 0.6574 - sensitivity_at_specificity: 0.8084 - specificity_at_sensitivity: 0.7608 - recall: 0.7587 - precision: 0.6334\n",
            "Epoch 372: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.5842 - accuracy: 0.6574 - sensitivity_at_specificity: 0.8084 - specificity_at_sensitivity: 0.7608 - recall: 0.7587 - precision: 0.6334 - val_loss: 0.4590 - val_accuracy: 0.7609 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8383 - val_recall: 0.8163 - val_precision: 0.7334\n",
            "Epoch 373/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5824 - accuracy: 0.6574 - sensitivity_at_specificity: 0.8052 - specificity_at_sensitivity: 0.7756 - recall: 0.7883 - precision: 0.6298\n",
            "Epoch 373: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.5824 - accuracy: 0.6574 - sensitivity_at_specificity: 0.8052 - specificity_at_sensitivity: 0.7756 - recall: 0.7883 - precision: 0.6298 - val_loss: 0.4657 - val_accuracy: 0.7641 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8295 - val_recall: 0.8283 - val_precision: 0.7316\n",
            "Epoch 374/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5831 - accuracy: 0.6480 - sensitivity_at_specificity: 0.7791 - specificity_at_sensitivity: 0.7676 - recall: 0.7974 - precision: 0.6212\n",
            "Epoch 374: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.5831 - accuracy: 0.6480 - sensitivity_at_specificity: 0.7791 - specificity_at_sensitivity: 0.7676 - recall: 0.7974 - precision: 0.6212 - val_loss: 0.4700 - val_accuracy: 0.7594 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8336 - val_recall: 0.8431 - val_precision: 0.7179\n",
            "Epoch 375/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5695 - accuracy: 0.6652 - sensitivity_at_specificity: 0.8162 - specificity_at_sensitivity: 0.7960 - recall: 0.7954 - precision: 0.6350\n",
            "Epoch 375: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.5695 - accuracy: 0.6652 - sensitivity_at_specificity: 0.8162 - specificity_at_sensitivity: 0.7960 - recall: 0.7954 - precision: 0.6350 - val_loss: 0.4442 - val_accuracy: 0.7812 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8415 - val_recall: 0.8675 - val_precision: 0.7437\n",
            "Epoch 376/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5738 - accuracy: 0.6699 - sensitivity_at_specificity: 0.8246 - specificity_at_sensitivity: 0.7991 - recall: 0.7654 - precision: 0.6388\n",
            "Epoch 376: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.5738 - accuracy: 0.6699 - sensitivity_at_specificity: 0.8246 - specificity_at_sensitivity: 0.7991 - recall: 0.7654 - precision: 0.6388 - val_loss: 0.4484 - val_accuracy: 0.7742 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8276 - val_recall: 0.8748 - val_precision: 0.7137\n",
            "Epoch 377/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5866 - accuracy: 0.6512 - sensitivity_at_specificity: 0.8024 - specificity_at_sensitivity: 0.7506 - recall: 0.7613 - precision: 0.6197\n",
            "Epoch 377: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.5866 - accuracy: 0.6512 - sensitivity_at_specificity: 0.8024 - specificity_at_sensitivity: 0.7506 - recall: 0.7613 - precision: 0.6197 - val_loss: 0.4628 - val_accuracy: 0.7445 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8083 - val_recall: 0.7644 - val_precision: 0.7160\n",
            "Epoch 378/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5827 - accuracy: 0.6711 - sensitivity_at_specificity: 0.8199 - specificity_at_sensitivity: 0.7747 - recall: 0.7244 - precision: 0.6537\n",
            "Epoch 378: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.5827 - accuracy: 0.6711 - sensitivity_at_specificity: 0.8199 - specificity_at_sensitivity: 0.7747 - recall: 0.7244 - precision: 0.6537 - val_loss: 0.4478 - val_accuracy: 0.7852 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8360 - val_recall: 0.9006 - val_precision: 0.7410\n",
            "Epoch 379/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5950 - accuracy: 0.6355 - sensitivity_at_specificity: 0.7643 - specificity_at_sensitivity: 0.7451 - recall: 0.7800 - precision: 0.6033\n",
            "Epoch 379: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.5950 - accuracy: 0.6355 - sensitivity_at_specificity: 0.7643 - specificity_at_sensitivity: 0.7451 - recall: 0.7800 - precision: 0.6033 - val_loss: 0.4557 - val_accuracy: 0.7672 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8385 - val_recall: 0.8635 - val_precision: 0.7196\n",
            "Epoch 380/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5784 - accuracy: 0.6527 - sensitivity_at_specificity: 0.8067 - specificity_at_sensitivity: 0.7712 - recall: 0.8370 - precision: 0.6135\n",
            "Epoch 380: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.5784 - accuracy: 0.6527 - sensitivity_at_specificity: 0.8067 - specificity_at_sensitivity: 0.7712 - recall: 0.8370 - precision: 0.6135 - val_loss: 0.4601 - val_accuracy: 0.7766 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8477 - val_recall: 0.8834 - val_precision: 0.7291\n",
            "Epoch 381/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5847 - accuracy: 0.6594 - sensitivity_at_specificity: 0.8065 - specificity_at_sensitivity: 0.7688 - recall: 0.7585 - precision: 0.6305\n",
            "Epoch 381: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.5847 - accuracy: 0.6594 - sensitivity_at_specificity: 0.8065 - specificity_at_sensitivity: 0.7688 - recall: 0.7585 - precision: 0.6305 - val_loss: 0.4632 - val_accuracy: 0.7602 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8206 - val_recall: 0.8569 - val_precision: 0.7224\n",
            "Epoch 382/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5763 - accuracy: 0.6645 - sensitivity_at_specificity: 0.8213 - specificity_at_sensitivity: 0.7934 - recall: 0.7772 - precision: 0.6254\n",
            "Epoch 382: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.5763 - accuracy: 0.6645 - sensitivity_at_specificity: 0.8213 - specificity_at_sensitivity: 0.7934 - recall: 0.7772 - precision: 0.6254 - val_loss: 0.4538 - val_accuracy: 0.7742 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8462 - val_recall: 0.8810 - val_precision: 0.7217\n",
            "Epoch 383/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5787 - accuracy: 0.6582 - sensitivity_at_specificity: 0.8168 - specificity_at_sensitivity: 0.7583 - recall: 0.7542 - precision: 0.6273\n",
            "Epoch 383: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.5787 - accuracy: 0.6582 - sensitivity_at_specificity: 0.8168 - specificity_at_sensitivity: 0.7583 - recall: 0.7542 - precision: 0.6273 - val_loss: 0.4607 - val_accuracy: 0.7672 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8022 - val_recall: 0.8849 - val_precision: 0.7175\n",
            "Epoch 384/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5658 - accuracy: 0.6703 - sensitivity_at_specificity: 0.8288 - specificity_at_sensitivity: 0.7955 - recall: 0.7144 - precision: 0.6359\n",
            "Epoch 384: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.5658 - accuracy: 0.6703 - sensitivity_at_specificity: 0.8288 - specificity_at_sensitivity: 0.7955 - recall: 0.7144 - precision: 0.6359 - val_loss: 0.4466 - val_accuracy: 0.7773 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8689 - val_recall: 0.7885 - val_precision: 0.7826\n",
            "Epoch 385/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5807 - accuracy: 0.6582 - sensitivity_at_specificity: 0.8175 - specificity_at_sensitivity: 0.7680 - recall: 0.7718 - precision: 0.6264\n",
            "Epoch 385: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.5807 - accuracy: 0.6582 - sensitivity_at_specificity: 0.8175 - specificity_at_sensitivity: 0.7680 - recall: 0.7718 - precision: 0.6264 - val_loss: 0.4772 - val_accuracy: 0.7195 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8434 - val_recall: 0.6802 - val_precision: 0.7212\n",
            "Epoch 386/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5702 - accuracy: 0.6766 - sensitivity_at_specificity: 0.8429 - specificity_at_sensitivity: 0.7746 - recall: 0.7678 - precision: 0.6597\n",
            "Epoch 386: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.5702 - accuracy: 0.6766 - sensitivity_at_specificity: 0.8429 - specificity_at_sensitivity: 0.7746 - recall: 0.7678 - precision: 0.6597 - val_loss: 0.4637 - val_accuracy: 0.7656 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8317 - val_recall: 0.8476 - val_precision: 0.7354\n",
            "Epoch 387/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5653 - accuracy: 0.6805 - sensitivity_at_specificity: 0.8341 - specificity_at_sensitivity: 0.8066 - recall: 0.7298 - precision: 0.6508\n",
            "Epoch 387: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.5653 - accuracy: 0.6805 - sensitivity_at_specificity: 0.8341 - specificity_at_sensitivity: 0.8066 - recall: 0.7298 - precision: 0.6508 - val_loss: 0.4641 - val_accuracy: 0.7484 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8399 - val_recall: 0.8188 - val_precision: 0.7067\n",
            "Epoch 388/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5652 - accuracy: 0.6812 - sensitivity_at_specificity: 0.8421 - specificity_at_sensitivity: 0.8072 - recall: 0.7463 - precision: 0.6432\n",
            "Epoch 388: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.5652 - accuracy: 0.6812 - sensitivity_at_specificity: 0.8421 - specificity_at_sensitivity: 0.8072 - recall: 0.7463 - precision: 0.6432 - val_loss: 0.4575 - val_accuracy: 0.7516 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8410 - val_recall: 0.7696 - val_precision: 0.7489\n",
            "Epoch 389/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5629 - accuracy: 0.6855 - sensitivity_at_specificity: 0.8526 - specificity_at_sensitivity: 0.8088 - recall: 0.8022 - precision: 0.6528\n",
            "Epoch 389: val_accuracy improved from 0.80078 to 0.80313, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.5629 - accuracy: 0.6855 - sensitivity_at_specificity: 0.8526 - specificity_at_sensitivity: 0.8088 - recall: 0.8022 - precision: 0.6528 - val_loss: 0.4292 - val_accuracy: 0.8031 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8556 - val_recall: 0.9098 - val_precision: 0.7510\n",
            "Epoch 390/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5565 - accuracy: 0.6879 - sensitivity_at_specificity: 0.8639 - specificity_at_sensitivity: 0.8232 - recall: 0.7664 - precision: 0.6660\n",
            "Epoch 390: val_accuracy did not improve from 0.80313\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.5565 - accuracy: 0.6879 - sensitivity_at_specificity: 0.8639 - specificity_at_sensitivity: 0.8232 - recall: 0.7664 - precision: 0.6660 - val_loss: 0.4326 - val_accuracy: 0.7883 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8560 - val_recall: 0.8796 - val_precision: 0.7471\n",
            "Epoch 391/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5674 - accuracy: 0.6797 - sensitivity_at_specificity: 0.8383 - specificity_at_sensitivity: 0.8008 - recall: 0.7801 - precision: 0.6564\n",
            "Epoch 391: val_accuracy did not improve from 0.80313\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.5674 - accuracy: 0.6797 - sensitivity_at_specificity: 0.8383 - specificity_at_sensitivity: 0.8008 - recall: 0.7801 - precision: 0.6564 - val_loss: 0.4569 - val_accuracy: 0.7625 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8384 - val_recall: 0.8074 - val_precision: 0.7454\n",
            "Epoch 392/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5788 - accuracy: 0.6621 - sensitivity_at_specificity: 0.8151 - specificity_at_sensitivity: 0.7903 - recall: 0.7387 - precision: 0.6412\n",
            "Epoch 392: val_accuracy did not improve from 0.80313\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.5788 - accuracy: 0.6621 - sensitivity_at_specificity: 0.8151 - specificity_at_sensitivity: 0.7903 - recall: 0.7387 - precision: 0.6412 - val_loss: 0.4497 - val_accuracy: 0.7906 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8180 - val_recall: 0.8528 - val_precision: 0.7667\n",
            "Epoch 393/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5640 - accuracy: 0.6828 - sensitivity_at_specificity: 0.8529 - specificity_at_sensitivity: 0.7995 - recall: 0.7920 - precision: 0.6548\n",
            "Epoch 393: val_accuracy did not improve from 0.80313\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.5640 - accuracy: 0.6828 - sensitivity_at_specificity: 0.8529 - specificity_at_sensitivity: 0.7995 - recall: 0.7920 - precision: 0.6548 - val_loss: 0.4358 - val_accuracy: 0.7773 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8763 - val_recall: 0.8006 - val_precision: 0.7530\n",
            "Epoch 394/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5555 - accuracy: 0.6840 - sensitivity_at_specificity: 0.8389 - specificity_at_sensitivity: 0.8195 - recall: 0.8065 - precision: 0.6521\n",
            "Epoch 394: val_accuracy did not improve from 0.80313\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.5555 - accuracy: 0.6840 - sensitivity_at_specificity: 0.8389 - specificity_at_sensitivity: 0.8195 - recall: 0.8065 - precision: 0.6521 - val_loss: 0.4424 - val_accuracy: 0.7859 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8537 - val_recall: 0.8379 - val_precision: 0.7482\n",
            "Epoch 395/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5652 - accuracy: 0.6703 - sensitivity_at_specificity: 0.8336 - specificity_at_sensitivity: 0.7799 - recall: 0.7030 - precision: 0.6521\n",
            "Epoch 395: val_accuracy did not improve from 0.80313\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.5652 - accuracy: 0.6703 - sensitivity_at_specificity: 0.8336 - specificity_at_sensitivity: 0.7799 - recall: 0.7030 - precision: 0.6521 - val_loss: 0.4491 - val_accuracy: 0.7469 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8496 - val_recall: 0.7386 - val_precision: 0.7480\n",
            "Epoch 396/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5592 - accuracy: 0.6856 - sensitivity_at_specificity: 0.8612 - specificity_at_sensitivity: 0.8080 - recall: 0.7830 - precision: 0.6510\n",
            "Epoch 396: val_accuracy did not improve from 0.80313\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.5592 - accuracy: 0.6856 - sensitivity_at_specificity: 0.8612 - specificity_at_sensitivity: 0.8080 - recall: 0.7830 - precision: 0.6510 - val_loss: 0.4642 - val_accuracy: 0.7516 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8476 - val_recall: 0.7949 - val_precision: 0.7230\n",
            "Epoch 397/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5762 - accuracy: 0.6668 - sensitivity_at_specificity: 0.8226 - specificity_at_sensitivity: 0.7784 - recall: 0.7292 - precision: 0.6465\n",
            "Epoch 397: val_accuracy did not improve from 0.80313\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.5762 - accuracy: 0.6668 - sensitivity_at_specificity: 0.8226 - specificity_at_sensitivity: 0.7784 - recall: 0.7292 - precision: 0.6465 - val_loss: 0.4511 - val_accuracy: 0.7563 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8599 - val_recall: 0.7853 - val_precision: 0.7558\n",
            "Epoch 398/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5686 - accuracy: 0.6723 - sensitivity_at_specificity: 0.8340 - specificity_at_sensitivity: 0.7987 - recall: 0.8192 - precision: 0.6339\n",
            "Epoch 398: val_accuracy did not improve from 0.80313\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.5686 - accuracy: 0.6723 - sensitivity_at_specificity: 0.8340 - specificity_at_sensitivity: 0.7987 - recall: 0.8192 - precision: 0.6339 - val_loss: 0.4525 - val_accuracy: 0.7641 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8390 - val_recall: 0.8091 - val_precision: 0.7392\n",
            "Epoch 399/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5622 - accuracy: 0.6789 - sensitivity_at_specificity: 0.8366 - specificity_at_sensitivity: 0.8314 - recall: 0.7185 - precision: 0.6599\n",
            "Epoch 399: val_accuracy did not improve from 0.80313\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.5622 - accuracy: 0.6789 - sensitivity_at_specificity: 0.8366 - specificity_at_sensitivity: 0.8314 - recall: 0.7185 - precision: 0.6599 - val_loss: 0.4585 - val_accuracy: 0.7617 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8268 - val_recall: 0.8140 - val_precision: 0.7394\n",
            "Epoch 400/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5645 - accuracy: 0.6855 - sensitivity_at_specificity: 0.8378 - specificity_at_sensitivity: 0.8111 - recall: 0.7162 - precision: 0.6679\n",
            "Epoch 400: val_accuracy did not improve from 0.80313\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.5645 - accuracy: 0.6855 - sensitivity_at_specificity: 0.8378 - specificity_at_sensitivity: 0.8111 - recall: 0.7162 - precision: 0.6679 - val_loss: 0.4395 - val_accuracy: 0.7937 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8349 - val_recall: 0.9108 - val_precision: 0.7419\n",
            "Epoch 401/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5658 - accuracy: 0.6820 - sensitivity_at_specificity: 0.8472 - specificity_at_sensitivity: 0.8042 - recall: 0.7561 - precision: 0.6537\n",
            "Epoch 401: val_accuracy did not improve from 0.80313\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.5658 - accuracy: 0.6820 - sensitivity_at_specificity: 0.8472 - specificity_at_sensitivity: 0.8042 - recall: 0.7561 - precision: 0.6537 - val_loss: 0.4428 - val_accuracy: 0.7617 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8410 - val_recall: 0.8403 - val_precision: 0.7196\n",
            "Epoch 402/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5686 - accuracy: 0.6680 - sensitivity_at_specificity: 0.8332 - specificity_at_sensitivity: 0.7908 - recall: 0.7736 - precision: 0.6279\n",
            "Epoch 402: val_accuracy did not improve from 0.80313\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.5686 - accuracy: 0.6680 - sensitivity_at_specificity: 0.8332 - specificity_at_sensitivity: 0.7908 - recall: 0.7736 - precision: 0.6279 - val_loss: 0.4618 - val_accuracy: 0.7320 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8459 - val_recall: 0.7055 - val_precision: 0.7303\n",
            "Epoch 403/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5631 - accuracy: 0.6770 - sensitivity_at_specificity: 0.8130 - specificity_at_sensitivity: 0.8182 - recall: 0.7203 - precision: 0.6607\n",
            "Epoch 403: val_accuracy did not improve from 0.80313\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.5631 - accuracy: 0.6770 - sensitivity_at_specificity: 0.8130 - specificity_at_sensitivity: 0.8182 - recall: 0.7203 - precision: 0.6607 - val_loss: 0.4309 - val_accuracy: 0.7742 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8482 - val_recall: 0.8185 - val_precision: 0.7460\n",
            "Epoch 404/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5569 - accuracy: 0.6836 - sensitivity_at_specificity: 0.8540 - specificity_at_sensitivity: 0.8223 - recall: 0.7325 - precision: 0.6612\n",
            "Epoch 404: val_accuracy did not improve from 0.80313\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.5569 - accuracy: 0.6836 - sensitivity_at_specificity: 0.8540 - specificity_at_sensitivity: 0.8223 - recall: 0.7325 - precision: 0.6612 - val_loss: 0.4606 - val_accuracy: 0.7523 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8331 - val_recall: 0.7930 - val_precision: 0.7297\n",
            "Epoch 405/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5455 - accuracy: 0.7035 - sensitivity_at_specificity: 0.8534 - specificity_at_sensitivity: 0.8496 - recall: 0.7702 - precision: 0.6878\n",
            "Epoch 405: val_accuracy did not improve from 0.80313\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.5455 - accuracy: 0.7035 - sensitivity_at_specificity: 0.8534 - specificity_at_sensitivity: 0.8496 - recall: 0.7702 - precision: 0.6878 - val_loss: 0.4506 - val_accuracy: 0.7648 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8558 - val_recall: 0.8378 - val_precision: 0.7288\n",
            "Epoch 406/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5512 - accuracy: 0.6957 - sensitivity_at_specificity: 0.8620 - specificity_at_sensitivity: 0.8368 - recall: 0.7359 - precision: 0.6754\n",
            "Epoch 406: val_accuracy did not improve from 0.80313\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.5512 - accuracy: 0.6957 - sensitivity_at_specificity: 0.8620 - specificity_at_sensitivity: 0.8368 - recall: 0.7359 - precision: 0.6754 - val_loss: 0.4549 - val_accuracy: 0.7516 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8567 - val_recall: 0.7721 - val_precision: 0.7246\n",
            "Epoch 407/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5551 - accuracy: 0.6812 - sensitivity_at_specificity: 0.8621 - specificity_at_sensitivity: 0.8201 - recall: 0.7226 - precision: 0.6662\n",
            "Epoch 407: val_accuracy did not improve from 0.80313\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.5551 - accuracy: 0.6812 - sensitivity_at_specificity: 0.8621 - specificity_at_sensitivity: 0.8201 - recall: 0.7226 - precision: 0.6662 - val_loss: 0.4546 - val_accuracy: 0.7641 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8372 - val_recall: 0.8203 - val_precision: 0.7319\n",
            "Epoch 408/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5535 - accuracy: 0.6914 - sensitivity_at_specificity: 0.8537 - specificity_at_sensitivity: 0.8335 - recall: 0.7614 - precision: 0.6732\n",
            "Epoch 408: val_accuracy did not improve from 0.80313\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.5535 - accuracy: 0.6914 - sensitivity_at_specificity: 0.8537 - specificity_at_sensitivity: 0.8335 - recall: 0.7614 - precision: 0.6732 - val_loss: 0.4503 - val_accuracy: 0.7531 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8401 - val_recall: 0.7664 - val_precision: 0.7477\n",
            "Epoch 409/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5529 - accuracy: 0.6871 - sensitivity_at_specificity: 0.8403 - specificity_at_sensitivity: 0.8410 - recall: 0.7600 - precision: 0.6607\n",
            "Epoch 409: val_accuracy did not improve from 0.80313\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.5529 - accuracy: 0.6871 - sensitivity_at_specificity: 0.8403 - specificity_at_sensitivity: 0.8410 - recall: 0.7600 - precision: 0.6607 - val_loss: 0.4596 - val_accuracy: 0.7367 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8596 - val_recall: 0.6935 - val_precision: 0.7632\n",
            "Epoch 410/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5573 - accuracy: 0.6984 - sensitivity_at_specificity: 0.8499 - specificity_at_sensitivity: 0.8267 - recall: 0.7420 - precision: 0.6822\n",
            "Epoch 410: val_accuracy did not improve from 0.80313\n",
            "10/10 [==============================] - 2s 177ms/step - loss: 0.5573 - accuracy: 0.6984 - sensitivity_at_specificity: 0.8499 - specificity_at_sensitivity: 0.8267 - recall: 0.7420 - precision: 0.6822 - val_loss: 0.4725 - val_accuracy: 0.7617 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8092 - val_recall: 0.9007 - val_precision: 0.6895\n",
            "Epoch 411/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5474 - accuracy: 0.6996 - sensitivity_at_specificity: 0.8598 - specificity_at_sensitivity: 0.8301 - recall: 0.7345 - precision: 0.6857\n",
            "Epoch 411: val_accuracy did not improve from 0.80313\n",
            "10/10 [==============================] - 2s 174ms/step - loss: 0.5474 - accuracy: 0.6996 - sensitivity_at_specificity: 0.8598 - specificity_at_sensitivity: 0.8301 - recall: 0.7345 - precision: 0.6857 - val_loss: 0.4490 - val_accuracy: 0.7727 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8259 - val_recall: 0.8257 - val_precision: 0.7531\n",
            "Epoch 412/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5589 - accuracy: 0.6926 - sensitivity_at_specificity: 0.8508 - specificity_at_sensitivity: 0.8300 - recall: 0.8164 - precision: 0.6611\n",
            "Epoch 412: val_accuracy did not improve from 0.80313\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.5589 - accuracy: 0.6926 - sensitivity_at_specificity: 0.8508 - specificity_at_sensitivity: 0.8300 - recall: 0.8164 - precision: 0.6611 - val_loss: 0.4666 - val_accuracy: 0.7320 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8629 - val_recall: 0.6894 - val_precision: 0.7673\n",
            "Epoch 413/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5572 - accuracy: 0.6852 - sensitivity_at_specificity: 0.8567 - specificity_at_sensitivity: 0.8360 - recall: 0.7080 - precision: 0.6828\n",
            "Epoch 413: val_accuracy did not improve from 0.80313\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.5572 - accuracy: 0.6852 - sensitivity_at_specificity: 0.8567 - specificity_at_sensitivity: 0.8360 - recall: 0.7080 - precision: 0.6828 - val_loss: 0.4392 - val_accuracy: 0.7898 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8484 - val_recall: 0.8788 - val_precision: 0.7406\n",
            "Epoch 414/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5602 - accuracy: 0.6832 - sensitivity_at_specificity: 0.8451 - specificity_at_sensitivity: 0.8337 - recall: 0.7673 - precision: 0.6582\n",
            "Epoch 414: val_accuracy did not improve from 0.80313\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.5602 - accuracy: 0.6832 - sensitivity_at_specificity: 0.8451 - specificity_at_sensitivity: 0.8337 - recall: 0.7673 - precision: 0.6582 - val_loss: 0.4421 - val_accuracy: 0.7680 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8393 - val_recall: 0.7997 - val_precision: 0.7515\n",
            "Epoch 415/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5430 - accuracy: 0.7035 - sensitivity_at_specificity: 0.8683 - specificity_at_sensitivity: 0.8374 - recall: 0.8121 - precision: 0.6811\n",
            "Epoch 415: val_accuracy did not improve from 0.80313\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.5430 - accuracy: 0.7035 - sensitivity_at_specificity: 0.8683 - specificity_at_sensitivity: 0.8374 - recall: 0.8121 - precision: 0.6811 - val_loss: 0.4341 - val_accuracy: 0.8000 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8406 - val_recall: 0.9031 - val_precision: 0.7487\n",
            "Epoch 416/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5712 - accuracy: 0.6750 - sensitivity_at_specificity: 0.8335 - specificity_at_sensitivity: 0.8115 - recall: 0.7260 - precision: 0.6657\n",
            "Epoch 416: val_accuracy did not improve from 0.80313\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.5712 - accuracy: 0.6750 - sensitivity_at_specificity: 0.8335 - specificity_at_sensitivity: 0.8115 - recall: 0.7260 - precision: 0.6657 - val_loss: 0.4335 - val_accuracy: 0.7812 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8394 - val_recall: 0.8818 - val_precision: 0.7282\n",
            "Epoch 417/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5460 - accuracy: 0.7016 - sensitivity_at_specificity: 0.8685 - specificity_at_sensitivity: 0.8264 - recall: 0.7842 - precision: 0.6765\n",
            "Epoch 417: val_accuracy did not improve from 0.80313\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.5460 - accuracy: 0.7016 - sensitivity_at_specificity: 0.8685 - specificity_at_sensitivity: 0.8264 - recall: 0.7842 - precision: 0.6765 - val_loss: 0.4573 - val_accuracy: 0.7563 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8427 - val_recall: 0.8245 - val_precision: 0.7245\n",
            "Epoch 418/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5523 - accuracy: 0.6938 - sensitivity_at_specificity: 0.8487 - specificity_at_sensitivity: 0.8405 - recall: 0.7187 - precision: 0.6789\n",
            "Epoch 418: val_accuracy did not improve from 0.80313\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.5523 - accuracy: 0.6938 - sensitivity_at_specificity: 0.8487 - specificity_at_sensitivity: 0.8405 - recall: 0.7187 - precision: 0.6789 - val_loss: 0.4255 - val_accuracy: 0.7906 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8571 - val_recall: 0.8615 - val_precision: 0.7588\n",
            "Epoch 419/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5659 - accuracy: 0.6809 - sensitivity_at_specificity: 0.8433 - specificity_at_sensitivity: 0.8049 - recall: 0.8223 - precision: 0.6432\n",
            "Epoch 419: val_accuracy did not improve from 0.80313\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.5659 - accuracy: 0.6809 - sensitivity_at_specificity: 0.8433 - specificity_at_sensitivity: 0.8049 - recall: 0.8223 - precision: 0.6432 - val_loss: 0.4210 - val_accuracy: 0.7641 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8852 - val_recall: 0.7915 - val_precision: 0.7336\n",
            "Epoch 420/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5579 - accuracy: 0.6770 - sensitivity_at_specificity: 0.8457 - specificity_at_sensitivity: 0.8270 - recall: 0.7455 - precision: 0.6547\n",
            "Epoch 420: val_accuracy did not improve from 0.80313\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.5579 - accuracy: 0.6770 - sensitivity_at_specificity: 0.8457 - specificity_at_sensitivity: 0.8270 - recall: 0.7455 - precision: 0.6547 - val_loss: 0.4578 - val_accuracy: 0.7344 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8471 - val_recall: 0.7230 - val_precision: 0.7392\n",
            "Epoch 421/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5544 - accuracy: 0.6953 - sensitivity_at_specificity: 0.8495 - specificity_at_sensitivity: 0.8427 - recall: 0.7422 - precision: 0.6774\n",
            "Epoch 421: val_accuracy did not improve from 0.80313\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.5544 - accuracy: 0.6953 - sensitivity_at_specificity: 0.8495 - specificity_at_sensitivity: 0.8427 - recall: 0.7422 - precision: 0.6774 - val_loss: 0.4410 - val_accuracy: 0.7578 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8587 - val_recall: 0.7776 - val_precision: 0.7496\n",
            "Epoch 422/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5393 - accuracy: 0.6977 - sensitivity_at_specificity: 0.8657 - specificity_at_sensitivity: 0.8449 - recall: 0.7974 - precision: 0.6708\n",
            "Epoch 422: val_accuracy did not improve from 0.80313\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.5393 - accuracy: 0.6977 - sensitivity_at_specificity: 0.8657 - specificity_at_sensitivity: 0.8449 - recall: 0.7974 - precision: 0.6708 - val_loss: 0.4396 - val_accuracy: 0.7789 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8608 - val_recall: 0.8473 - val_precision: 0.7520\n",
            "Epoch 423/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5355 - accuracy: 0.7035 - sensitivity_at_specificity: 0.8810 - specificity_at_sensitivity: 0.8446 - recall: 0.7387 - precision: 0.6919\n",
            "Epoch 423: val_accuracy did not improve from 0.80313\n",
            "10/10 [==============================] - 2s 188ms/step - loss: 0.5355 - accuracy: 0.7035 - sensitivity_at_specificity: 0.8810 - specificity_at_sensitivity: 0.8446 - recall: 0.7387 - precision: 0.6919 - val_loss: 0.4494 - val_accuracy: 0.7750 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8524 - val_recall: 0.8831 - val_precision: 0.7303\n",
            "Epoch 424/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5397 - accuracy: 0.7039 - sensitivity_at_specificity: 0.8779 - specificity_at_sensitivity: 0.8526 - recall: 0.7653 - precision: 0.6811\n",
            "Epoch 424: val_accuracy did not improve from 0.80313\n",
            "10/10 [==============================] - 2s 174ms/step - loss: 0.5397 - accuracy: 0.7039 - sensitivity_at_specificity: 0.8779 - specificity_at_sensitivity: 0.8526 - recall: 0.7653 - precision: 0.6811 - val_loss: 0.4347 - val_accuracy: 0.7820 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8680 - val_recall: 0.8712 - val_precision: 0.7311\n",
            "Epoch 425/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5514 - accuracy: 0.6828 - sensitivity_at_specificity: 0.8348 - specificity_at_sensitivity: 0.8465 - recall: 0.7525 - precision: 0.6596\n",
            "Epoch 425: val_accuracy did not improve from 0.80313\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.5514 - accuracy: 0.6828 - sensitivity_at_specificity: 0.8348 - specificity_at_sensitivity: 0.8465 - recall: 0.7525 - precision: 0.6596 - val_loss: 0.4463 - val_accuracy: 0.7570 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8477 - val_recall: 0.8196 - val_precision: 0.7299\n",
            "Epoch 426/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5429 - accuracy: 0.6977 - sensitivity_at_specificity: 0.8718 - specificity_at_sensitivity: 0.8302 - recall: 0.7468 - precision: 0.6753\n",
            "Epoch 426: val_accuracy did not improve from 0.80313\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.5429 - accuracy: 0.6977 - sensitivity_at_specificity: 0.8718 - specificity_at_sensitivity: 0.8302 - recall: 0.7468 - precision: 0.6753 - val_loss: 0.4468 - val_accuracy: 0.7578 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8663 - val_recall: 0.7614 - val_precision: 0.7543\n",
            "Epoch 427/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5345 - accuracy: 0.7168 - sensitivity_at_specificity: 0.8852 - specificity_at_sensitivity: 0.8616 - recall: 0.7283 - precision: 0.7122\n",
            "Epoch 427: val_accuracy did not improve from 0.80313\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.5345 - accuracy: 0.7168 - sensitivity_at_specificity: 0.8852 - specificity_at_sensitivity: 0.8616 - recall: 0.7283 - precision: 0.7122 - val_loss: 0.4645 - val_accuracy: 0.7500 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8112 - val_recall: 0.7966 - val_precision: 0.7282\n",
            "Epoch 428/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5254 - accuracy: 0.7184 - sensitivity_at_specificity: 0.8899 - specificity_at_sensitivity: 0.8535 - recall: 0.7823 - precision: 0.6890\n",
            "Epoch 428: val_accuracy did not improve from 0.80313\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.5254 - accuracy: 0.7184 - sensitivity_at_specificity: 0.8899 - specificity_at_sensitivity: 0.8535 - recall: 0.7823 - precision: 0.6890 - val_loss: 0.4656 - val_accuracy: 0.7602 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8202 - val_recall: 0.8311 - val_precision: 0.7358\n",
            "Epoch 429/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5369 - accuracy: 0.7105 - sensitivity_at_specificity: 0.8753 - specificity_at_sensitivity: 0.8555 - recall: 0.7554 - precision: 0.6871\n",
            "Epoch 429: val_accuracy did not improve from 0.80313\n",
            "10/10 [==============================] - 2s 187ms/step - loss: 0.5369 - accuracy: 0.7105 - sensitivity_at_specificity: 0.8753 - specificity_at_sensitivity: 0.8555 - recall: 0.7554 - precision: 0.6871 - val_loss: 0.4554 - val_accuracy: 0.7656 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8249 - val_recall: 0.8315 - val_precision: 0.7294\n",
            "Epoch 430/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5421 - accuracy: 0.6938 - sensitivity_at_specificity: 0.8444 - specificity_at_sensitivity: 0.8637 - recall: 0.7218 - precision: 0.6911\n",
            "Epoch 430: val_accuracy did not improve from 0.80313\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.5421 - accuracy: 0.6938 - sensitivity_at_specificity: 0.8444 - specificity_at_sensitivity: 0.8637 - recall: 0.7218 - precision: 0.6911 - val_loss: 0.4643 - val_accuracy: 0.7555 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8385 - val_recall: 0.8190 - val_precision: 0.7217\n",
            "Epoch 431/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5371 - accuracy: 0.7152 - sensitivity_at_specificity: 0.8799 - specificity_at_sensitivity: 0.8569 - recall: 0.7512 - precision: 0.6991\n",
            "Epoch 431: val_accuracy did not improve from 0.80313\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.5371 - accuracy: 0.7152 - sensitivity_at_specificity: 0.8799 - specificity_at_sensitivity: 0.8569 - recall: 0.7512 - precision: 0.6991 - val_loss: 0.4543 - val_accuracy: 0.7555 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8376 - val_recall: 0.8229 - val_precision: 0.7157\n",
            "Epoch 432/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5387 - accuracy: 0.7074 - sensitivity_at_specificity: 0.8598 - specificity_at_sensitivity: 0.8575 - recall: 0.7380 - precision: 0.6858\n",
            "Epoch 432: val_accuracy did not improve from 0.80313\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.5387 - accuracy: 0.7074 - sensitivity_at_specificity: 0.8598 - specificity_at_sensitivity: 0.8575 - recall: 0.7380 - precision: 0.6858 - val_loss: 0.4434 - val_accuracy: 0.7492 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8716 - val_recall: 0.7412 - val_precision: 0.7448\n",
            "Epoch 433/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5426 - accuracy: 0.7000 - sensitivity_at_specificity: 0.8737 - specificity_at_sensitivity: 0.8319 - recall: 0.7921 - precision: 0.6739\n",
            "Epoch 433: val_accuracy did not improve from 0.80313\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.5426 - accuracy: 0.7000 - sensitivity_at_specificity: 0.8737 - specificity_at_sensitivity: 0.8319 - recall: 0.7921 - precision: 0.6739 - val_loss: 0.4481 - val_accuracy: 0.7609 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8598 - val_recall: 0.7680 - val_precision: 0.7562\n",
            "Epoch 434/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5424 - accuracy: 0.7055 - sensitivity_at_specificity: 0.8765 - specificity_at_sensitivity: 0.8389 - recall: 0.7614 - precision: 0.6938\n",
            "Epoch 434: val_accuracy improved from 0.80313 to 0.81016, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.5424 - accuracy: 0.7055 - sensitivity_at_specificity: 0.8765 - specificity_at_sensitivity: 0.8389 - recall: 0.7614 - precision: 0.6938 - val_loss: 0.4133 - val_accuracy: 0.8102 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8621 - val_recall: 0.8937 - val_precision: 0.7692\n",
            "Epoch 435/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5394 - accuracy: 0.7063 - sensitivity_at_specificity: 0.8802 - specificity_at_sensitivity: 0.8602 - recall: 0.7620 - precision: 0.6895\n",
            "Epoch 435: val_accuracy did not improve from 0.81016\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.5394 - accuracy: 0.7063 - sensitivity_at_specificity: 0.8802 - specificity_at_sensitivity: 0.8602 - recall: 0.7620 - precision: 0.6895 - val_loss: 0.4459 - val_accuracy: 0.7641 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8424 - val_recall: 0.8545 - val_precision: 0.7232\n",
            "Epoch 436/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5258 - accuracy: 0.7172 - sensitivity_at_specificity: 0.8966 - specificity_at_sensitivity: 0.8685 - recall: 0.7801 - precision: 0.6997\n",
            "Epoch 436: val_accuracy did not improve from 0.81016\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.5258 - accuracy: 0.7172 - sensitivity_at_specificity: 0.8966 - specificity_at_sensitivity: 0.8685 - recall: 0.7801 - precision: 0.6997 - val_loss: 0.4537 - val_accuracy: 0.7688 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8183 - val_recall: 0.8454 - val_precision: 0.7362\n",
            "Epoch 437/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5311 - accuracy: 0.7114 - sensitivity_at_specificity: 0.8743 - specificity_at_sensitivity: 0.8604 - recall: 0.7322 - precision: 0.6914\n",
            "Epoch 437: val_accuracy did not improve from 0.81016\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.5311 - accuracy: 0.7114 - sensitivity_at_specificity: 0.8743 - specificity_at_sensitivity: 0.8604 - recall: 0.7322 - precision: 0.6914 - val_loss: 0.4420 - val_accuracy: 0.7688 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8563 - val_recall: 0.7867 - val_precision: 0.7557\n",
            "Epoch 438/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5245 - accuracy: 0.7117 - sensitivity_at_specificity: 0.9021 - specificity_at_sensitivity: 0.8610 - recall: 0.7395 - precision: 0.6872\n",
            "Epoch 438: val_accuracy did not improve from 0.81016\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.5245 - accuracy: 0.7117 - sensitivity_at_specificity: 0.9021 - specificity_at_sensitivity: 0.8610 - recall: 0.7395 - precision: 0.6872 - val_loss: 0.4647 - val_accuracy: 0.7609 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8589 - val_recall: 0.7748 - val_precision: 0.7511\n",
            "Epoch 439/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5476 - accuracy: 0.6996 - sensitivity_at_specificity: 0.8598 - specificity_at_sensitivity: 0.8229 - recall: 0.7453 - precision: 0.6841\n",
            "Epoch 439: val_accuracy did not improve from 0.81016\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.5476 - accuracy: 0.6996 - sensitivity_at_specificity: 0.8598 - specificity_at_sensitivity: 0.8229 - recall: 0.7453 - precision: 0.6841 - val_loss: 0.4546 - val_accuracy: 0.7570 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8396 - val_recall: 0.7562 - val_precision: 0.7598\n",
            "Epoch 440/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5438 - accuracy: 0.6910 - sensitivity_at_specificity: 0.8526 - specificity_at_sensitivity: 0.8498 - recall: 0.7496 - precision: 0.6657\n",
            "Epoch 440: val_accuracy did not improve from 0.81016\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.5438 - accuracy: 0.6910 - sensitivity_at_specificity: 0.8526 - specificity_at_sensitivity: 0.8498 - recall: 0.7496 - precision: 0.6657 - val_loss: 0.4337 - val_accuracy: 0.7750 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8413 - val_recall: 0.8446 - val_precision: 0.7459\n",
            "Epoch 441/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5241 - accuracy: 0.7219 - sensitivity_at_specificity: 0.9014 - specificity_at_sensitivity: 0.8802 - recall: 0.7560 - precision: 0.7013\n",
            "Epoch 441: val_accuracy did not improve from 0.81016\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.5241 - accuracy: 0.7219 - sensitivity_at_specificity: 0.9014 - specificity_at_sensitivity: 0.8802 - recall: 0.7560 - precision: 0.7013 - val_loss: 0.4331 - val_accuracy: 0.7766 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8637 - val_recall: 0.8596 - val_precision: 0.7313\n",
            "Epoch 442/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5170 - accuracy: 0.7211 - sensitivity_at_specificity: 0.8986 - specificity_at_sensitivity: 0.8685 - recall: 0.7473 - precision: 0.7107\n",
            "Epoch 442: val_accuracy did not improve from 0.81016\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.5170 - accuracy: 0.7211 - sensitivity_at_specificity: 0.8986 - specificity_at_sensitivity: 0.8685 - recall: 0.7473 - precision: 0.7107 - val_loss: 0.4567 - val_accuracy: 0.7586 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8463 - val_recall: 0.7982 - val_precision: 0.7443\n",
            "Epoch 443/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5446 - accuracy: 0.6965 - sensitivity_at_specificity: 0.8536 - specificity_at_sensitivity: 0.8621 - recall: 0.7808 - precision: 0.6711\n",
            "Epoch 443: val_accuracy did not improve from 0.81016\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.5446 - accuracy: 0.6965 - sensitivity_at_specificity: 0.8536 - specificity_at_sensitivity: 0.8621 - recall: 0.7808 - precision: 0.6711 - val_loss: 0.4499 - val_accuracy: 0.7625 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8578 - val_recall: 0.7691 - val_precision: 0.7668\n",
            "Epoch 444/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5390 - accuracy: 0.7063 - sensitivity_at_specificity: 0.8752 - specificity_at_sensitivity: 0.8606 - recall: 0.7279 - precision: 0.7007\n",
            "Epoch 444: val_accuracy did not improve from 0.81016\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.5390 - accuracy: 0.7063 - sensitivity_at_specificity: 0.8752 - specificity_at_sensitivity: 0.8606 - recall: 0.7279 - precision: 0.7007 - val_loss: 0.4397 - val_accuracy: 0.7656 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8680 - val_recall: 0.8372 - val_precision: 0.7375\n",
            "Epoch 445/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5290 - accuracy: 0.7207 - sensitivity_at_specificity: 0.8849 - specificity_at_sensitivity: 0.8613 - recall: 0.7565 - precision: 0.7028\n",
            "Epoch 445: val_accuracy did not improve from 0.81016\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.5290 - accuracy: 0.7207 - sensitivity_at_specificity: 0.8849 - specificity_at_sensitivity: 0.8613 - recall: 0.7565 - precision: 0.7028 - val_loss: 0.4399 - val_accuracy: 0.7523 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8545 - val_recall: 0.7988 - val_precision: 0.7314\n",
            "Epoch 446/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5371 - accuracy: 0.7043 - sensitivity_at_specificity: 0.8823 - specificity_at_sensitivity: 0.8554 - recall: 0.7300 - precision: 0.6925\n",
            "Epoch 446: val_accuracy did not improve from 0.81016\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.5371 - accuracy: 0.7043 - sensitivity_at_specificity: 0.8823 - specificity_at_sensitivity: 0.8554 - recall: 0.7300 - precision: 0.6925 - val_loss: 0.4298 - val_accuracy: 0.7852 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8768 - val_recall: 0.8599 - val_precision: 0.7612\n",
            "Epoch 447/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5380 - accuracy: 0.7014 - sensitivity_at_specificity: 0.8725 - specificity_at_sensitivity: 0.8502 - recall: 0.7617 - precision: 0.6785\n",
            "Epoch 447: val_accuracy did not improve from 0.81016\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.5380 - accuracy: 0.7014 - sensitivity_at_specificity: 0.8725 - specificity_at_sensitivity: 0.8502 - recall: 0.7617 - precision: 0.6785 - val_loss: 0.4508 - val_accuracy: 0.7633 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8442 - val_recall: 0.8433 - val_precision: 0.7170\n",
            "Epoch 448/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5382 - accuracy: 0.6980 - sensitivity_at_specificity: 0.8825 - specificity_at_sensitivity: 0.8521 - recall: 0.7573 - precision: 0.6833\n",
            "Epoch 448: val_accuracy did not improve from 0.81016\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.5382 - accuracy: 0.6980 - sensitivity_at_specificity: 0.8825 - specificity_at_sensitivity: 0.8521 - recall: 0.7573 - precision: 0.6833 - val_loss: 0.4781 - val_accuracy: 0.7078 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8437 - val_recall: 0.6769 - val_precision: 0.7306\n",
            "Epoch 449/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5230 - accuracy: 0.7262 - sensitivity_at_specificity: 0.9034 - specificity_at_sensitivity: 0.8622 - recall: 0.7771 - precision: 0.7061\n",
            "Epoch 449: val_accuracy did not improve from 0.81016\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.5230 - accuracy: 0.7262 - sensitivity_at_specificity: 0.9034 - specificity_at_sensitivity: 0.8622 - recall: 0.7771 - precision: 0.7061 - val_loss: 0.4433 - val_accuracy: 0.7703 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8383 - val_recall: 0.8523 - val_precision: 0.7336\n",
            "Epoch 450/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5392 - accuracy: 0.7022 - sensitivity_at_specificity: 0.8775 - specificity_at_sensitivity: 0.8464 - recall: 0.7069 - precision: 0.6935\n",
            "Epoch 450: val_accuracy did not improve from 0.81016\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.5392 - accuracy: 0.7022 - sensitivity_at_specificity: 0.8775 - specificity_at_sensitivity: 0.8464 - recall: 0.7069 - precision: 0.6935 - val_loss: 0.4375 - val_accuracy: 0.7867 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8460 - val_recall: 0.9105 - val_precision: 0.7286\n",
            "Epoch 451/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5358 - accuracy: 0.7039 - sensitivity_at_specificity: 0.8700 - specificity_at_sensitivity: 0.8603 - recall: 0.7307 - precision: 0.6847\n",
            "Epoch 451: val_accuracy did not improve from 0.81016\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.5358 - accuracy: 0.7039 - sensitivity_at_specificity: 0.8700 - specificity_at_sensitivity: 0.8603 - recall: 0.7307 - precision: 0.6847 - val_loss: 0.4731 - val_accuracy: 0.7250 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8553 - val_recall: 0.6790 - val_precision: 0.7556\n",
            "Epoch 452/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5288 - accuracy: 0.7090 - sensitivity_at_specificity: 0.8686 - specificity_at_sensitivity: 0.8836 - recall: 0.7679 - precision: 0.6844\n",
            "Epoch 452: val_accuracy did not improve from 0.81016\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.5288 - accuracy: 0.7090 - sensitivity_at_specificity: 0.8686 - specificity_at_sensitivity: 0.8836 - recall: 0.7679 - precision: 0.6844 - val_loss: 0.4749 - val_accuracy: 0.7422 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8220 - val_recall: 0.8170 - val_precision: 0.7077\n",
            "Epoch 453/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5130 - accuracy: 0.7266 - sensitivity_at_specificity: 0.9019 - specificity_at_sensitivity: 0.8841 - recall: 0.7520 - precision: 0.7139\n",
            "Epoch 453: val_accuracy did not improve from 0.81016\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.5130 - accuracy: 0.7266 - sensitivity_at_specificity: 0.9019 - specificity_at_sensitivity: 0.8841 - recall: 0.7520 - precision: 0.7139 - val_loss: 0.4237 - val_accuracy: 0.7844 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8667 - val_recall: 0.8724 - val_precision: 0.7397\n",
            "Epoch 454/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5499 - accuracy: 0.6969 - sensitivity_at_specificity: 0.8533 - specificity_at_sensitivity: 0.8433 - recall: 0.7555 - precision: 0.6844\n",
            "Epoch 454: val_accuracy did not improve from 0.81016\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.5499 - accuracy: 0.6969 - sensitivity_at_specificity: 0.8533 - specificity_at_sensitivity: 0.8433 - recall: 0.7555 - precision: 0.6844 - val_loss: 0.4630 - val_accuracy: 0.7430 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8175 - val_recall: 0.7559 - val_precision: 0.7363\n",
            "Epoch 455/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5385 - accuracy: 0.6977 - sensitivity_at_specificity: 0.8675 - specificity_at_sensitivity: 0.8489 - recall: 0.7178 - precision: 0.6909\n",
            "Epoch 455: val_accuracy did not improve from 0.81016\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.5385 - accuracy: 0.6977 - sensitivity_at_specificity: 0.8675 - specificity_at_sensitivity: 0.8489 - recall: 0.7178 - precision: 0.6909 - val_loss: 0.4560 - val_accuracy: 0.7367 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8388 - val_recall: 0.7344 - val_precision: 0.7191\n",
            "Epoch 456/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5275 - accuracy: 0.7063 - sensitivity_at_specificity: 0.8680 - specificity_at_sensitivity: 0.8710 - recall: 0.7641 - precision: 0.6740\n",
            "Epoch 456: val_accuracy did not improve from 0.81016\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.5275 - accuracy: 0.7063 - sensitivity_at_specificity: 0.8680 - specificity_at_sensitivity: 0.8710 - recall: 0.7641 - precision: 0.6740 - val_loss: 0.4467 - val_accuracy: 0.7547 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8476 - val_recall: 0.7933 - val_precision: 0.7279\n",
            "Epoch 457/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5229 - accuracy: 0.7102 - sensitivity_at_specificity: 0.8986 - specificity_at_sensitivity: 0.8699 - recall: 0.7111 - precision: 0.7010\n",
            "Epoch 457: val_accuracy did not improve from 0.81016\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.5229 - accuracy: 0.7102 - sensitivity_at_specificity: 0.8986 - specificity_at_sensitivity: 0.8699 - recall: 0.7111 - precision: 0.7010 - val_loss: 0.4387 - val_accuracy: 0.7797 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8524 - val_recall: 0.8587 - val_precision: 0.7339\n",
            "Epoch 458/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5235 - accuracy: 0.7070 - sensitivity_at_specificity: 0.8815 - specificity_at_sensitivity: 0.8780 - recall: 0.7613 - precision: 0.6933\n",
            "Epoch 458: val_accuracy did not improve from 0.81016\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.5254 - accuracy: 0.7051 - sensitivity_at_specificity: 0.8799 - specificity_at_sensitivity: 0.8792 - recall: 0.7582 - precision: 0.6915 - val_loss: 0.4783 - val_accuracy: 0.7281 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8237 - val_recall: 0.8013 - val_precision: 0.6985\n",
            "Epoch 459/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5293 - accuracy: 0.7172 - sensitivity_at_specificity: 0.8682 - specificity_at_sensitivity: 0.8820 - recall: 0.7679 - precision: 0.7019\n",
            "Epoch 459: val_accuracy did not improve from 0.81016\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.5293 - accuracy: 0.7172 - sensitivity_at_specificity: 0.8682 - specificity_at_sensitivity: 0.8820 - recall: 0.7679 - precision: 0.7019 - val_loss: 0.4446 - val_accuracy: 0.7594 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8378 - val_recall: 0.8124 - val_precision: 0.7370\n",
            "Epoch 460/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5174 - accuracy: 0.7342 - sensitivity_at_specificity: 0.9000 - specificity_at_sensitivity: 0.8573 - recall: 0.7471 - precision: 0.7302\n",
            "Epoch 460: val_accuracy did not improve from 0.81016\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.5174 - accuracy: 0.7342 - sensitivity_at_specificity: 0.9000 - specificity_at_sensitivity: 0.8573 - recall: 0.7471 - precision: 0.7302 - val_loss: 0.4354 - val_accuracy: 0.7937 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8479 - val_recall: 0.9154 - val_precision: 0.7445\n",
            "Epoch 461/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5282 - accuracy: 0.7145 - sensitivity_at_specificity: 0.8751 - specificity_at_sensitivity: 0.8818 - recall: 0.7486 - precision: 0.6940\n",
            "Epoch 461: val_accuracy did not improve from 0.81016\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.5282 - accuracy: 0.7145 - sensitivity_at_specificity: 0.8751 - specificity_at_sensitivity: 0.8818 - recall: 0.7486 - precision: 0.6940 - val_loss: 0.4545 - val_accuracy: 0.7555 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8362 - val_recall: 0.7891 - val_precision: 0.7420\n",
            "Epoch 462/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5141 - accuracy: 0.7320 - sensitivity_at_specificity: 0.9116 - specificity_at_sensitivity: 0.8673 - recall: 0.7611 - precision: 0.7124\n",
            "Epoch 462: val_accuracy did not improve from 0.81016\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.5141 - accuracy: 0.7320 - sensitivity_at_specificity: 0.9116 - specificity_at_sensitivity: 0.8673 - recall: 0.7611 - precision: 0.7124 - val_loss: 0.4662 - val_accuracy: 0.7555 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8080 - val_recall: 0.8155 - val_precision: 0.7251\n",
            "Epoch 463/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5341 - accuracy: 0.7086 - sensitivity_at_specificity: 0.8786 - specificity_at_sensitivity: 0.8631 - recall: 0.7397 - precision: 0.6904\n",
            "Epoch 463: val_accuracy did not improve from 0.81016\n",
            "10/10 [==============================] - 2s 179ms/step - loss: 0.5341 - accuracy: 0.7086 - sensitivity_at_specificity: 0.8786 - specificity_at_sensitivity: 0.8631 - recall: 0.7397 - precision: 0.6904 - val_loss: 0.4438 - val_accuracy: 0.7641 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8543 - val_recall: 0.7914 - val_precision: 0.7687\n",
            "Epoch 464/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5210 - accuracy: 0.7199 - sensitivity_at_specificity: 0.8796 - specificity_at_sensitivity: 0.8813 - recall: 0.7404 - precision: 0.7110\n",
            "Epoch 464: val_accuracy did not improve from 0.81016\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.5210 - accuracy: 0.7199 - sensitivity_at_specificity: 0.8796 - specificity_at_sensitivity: 0.8813 - recall: 0.7404 - precision: 0.7110 - val_loss: 0.4504 - val_accuracy: 0.7594 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8499 - val_recall: 0.8102 - val_precision: 0.7288\n",
            "Epoch 465/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5239 - accuracy: 0.7223 - sensitivity_at_specificity: 0.8893 - specificity_at_sensitivity: 0.8824 - recall: 0.7641 - precision: 0.7135\n",
            "Epoch 465: val_accuracy did not improve from 0.81016\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.5239 - accuracy: 0.7223 - sensitivity_at_specificity: 0.8893 - specificity_at_sensitivity: 0.8824 - recall: 0.7641 - precision: 0.7135 - val_loss: 0.4467 - val_accuracy: 0.7695 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8326 - val_recall: 0.8175 - val_precision: 0.7464\n",
            "Epoch 466/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5239 - accuracy: 0.7176 - sensitivity_at_specificity: 0.8959 - specificity_at_sensitivity: 0.8674 - recall: 0.7682 - precision: 0.7075\n",
            "Epoch 466: val_accuracy did not improve from 0.81016\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.5239 - accuracy: 0.7176 - sensitivity_at_specificity: 0.8959 - specificity_at_sensitivity: 0.8674 - recall: 0.7682 - precision: 0.7075 - val_loss: 0.4588 - val_accuracy: 0.7602 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8312 - val_recall: 0.8173 - val_precision: 0.7364\n",
            "Epoch 467/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5104 - accuracy: 0.7223 - sensitivity_at_specificity: 0.9063 - specificity_at_sensitivity: 0.8842 - recall: 0.7614 - precision: 0.7092\n",
            "Epoch 467: val_accuracy did not improve from 0.81016\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.5104 - accuracy: 0.7223 - sensitivity_at_specificity: 0.9063 - specificity_at_sensitivity: 0.8842 - recall: 0.7614 - precision: 0.7092 - val_loss: 0.4356 - val_accuracy: 0.7914 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8317 - val_recall: 0.8954 - val_precision: 0.7452\n",
            "Epoch 468/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5199 - accuracy: 0.7176 - sensitivity_at_specificity: 0.9015 - specificity_at_sensitivity: 0.8655 - recall: 0.7458 - precision: 0.6997\n",
            "Epoch 468: val_accuracy did not improve from 0.81016\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.5199 - accuracy: 0.7176 - sensitivity_at_specificity: 0.9015 - specificity_at_sensitivity: 0.8655 - recall: 0.7458 - precision: 0.6997 - val_loss: 0.4608 - val_accuracy: 0.7633 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8357 - val_recall: 0.8149 - val_precision: 0.7479\n",
            "Epoch 469/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5158 - accuracy: 0.7267 - sensitivity_at_specificity: 0.8852 - specificity_at_sensitivity: 0.8617 - recall: 0.7343 - precision: 0.7198\n",
            "Epoch 469: val_accuracy did not improve from 0.81016\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.5158 - accuracy: 0.7267 - sensitivity_at_specificity: 0.8852 - specificity_at_sensitivity: 0.8617 - recall: 0.7343 - precision: 0.7198 - val_loss: 0.4385 - val_accuracy: 0.7867 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8490 - val_recall: 0.8163 - val_precision: 0.7821\n",
            "Epoch 470/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5180 - accuracy: 0.7164 - sensitivity_at_specificity: 0.8945 - specificity_at_sensitivity: 0.8886 - recall: 0.7539 - precision: 0.6845\n",
            "Epoch 470: val_accuracy did not improve from 0.81016\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.5180 - accuracy: 0.7164 - sensitivity_at_specificity: 0.8945 - specificity_at_sensitivity: 0.8886 - recall: 0.7539 - precision: 0.6845 - val_loss: 0.4631 - val_accuracy: 0.7320 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8524 - val_recall: 0.6921 - val_precision: 0.7542\n",
            "Epoch 471/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5323 - accuracy: 0.7180 - sensitivity_at_specificity: 0.8949 - specificity_at_sensitivity: 0.8588 - recall: 0.7471 - precision: 0.7074\n",
            "Epoch 471: val_accuracy did not improve from 0.81016\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.5323 - accuracy: 0.7180 - sensitivity_at_specificity: 0.8949 - specificity_at_sensitivity: 0.8588 - recall: 0.7471 - precision: 0.7074 - val_loss: 0.4421 - val_accuracy: 0.7844 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8404 - val_recall: 0.8841 - val_precision: 0.7400\n",
            "Epoch 472/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5484 - accuracy: 0.6848 - sensitivity_at_specificity: 0.8611 - specificity_at_sensitivity: 0.8214 - recall: 0.7828 - precision: 0.6569\n",
            "Epoch 472: val_accuracy did not improve from 0.81016\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.5484 - accuracy: 0.6848 - sensitivity_at_specificity: 0.8611 - specificity_at_sensitivity: 0.8214 - recall: 0.7828 - precision: 0.6569 - val_loss: 0.4359 - val_accuracy: 0.7922 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8460 - val_recall: 0.8688 - val_precision: 0.7629\n",
            "Epoch 473/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5390 - accuracy: 0.7039 - sensitivity_at_specificity: 0.8774 - specificity_at_sensitivity: 0.8595 - recall: 0.7698 - precision: 0.6936\n",
            "Epoch 473: val_accuracy did not improve from 0.81016\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.5390 - accuracy: 0.7039 - sensitivity_at_specificity: 0.8774 - specificity_at_sensitivity: 0.8595 - recall: 0.7698 - precision: 0.6936 - val_loss: 0.4747 - val_accuracy: 0.7625 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8206 - val_recall: 0.8498 - val_precision: 0.7230\n",
            "Epoch 474/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5321 - accuracy: 0.7188 - sensitivity_at_specificity: 0.8856 - specificity_at_sensitivity: 0.8520 - recall: 0.7712 - precision: 0.6969\n",
            "Epoch 474: val_accuracy did not improve from 0.81016\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.5321 - accuracy: 0.7188 - sensitivity_at_specificity: 0.8856 - specificity_at_sensitivity: 0.8520 - recall: 0.7712 - precision: 0.6969 - val_loss: 0.4572 - val_accuracy: 0.7516 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8635 - val_recall: 0.7831 - val_precision: 0.7420\n",
            "Epoch 475/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5274 - accuracy: 0.7191 - sensitivity_at_specificity: 0.8784 - specificity_at_sensitivity: 0.8692 - recall: 0.7266 - precision: 0.7193\n",
            "Epoch 475: val_accuracy did not improve from 0.81016\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.5274 - accuracy: 0.7191 - sensitivity_at_specificity: 0.8784 - specificity_at_sensitivity: 0.8692 - recall: 0.7266 - precision: 0.7193 - val_loss: 0.4368 - val_accuracy: 0.7844 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8571 - val_recall: 0.8989 - val_precision: 0.7326\n",
            "Epoch 476/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5270 - accuracy: 0.7113 - sensitivity_at_specificity: 0.8836 - specificity_at_sensitivity: 0.8702 - recall: 0.7673 - precision: 0.6926\n",
            "Epoch 476: val_accuracy did not improve from 0.81016\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.5270 - accuracy: 0.7113 - sensitivity_at_specificity: 0.8836 - specificity_at_sensitivity: 0.8702 - recall: 0.7673 - precision: 0.6926 - val_loss: 0.4203 - val_accuracy: 0.7922 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8638 - val_recall: 0.8433 - val_precision: 0.7554\n",
            "Epoch 477/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5339 - accuracy: 0.6996 - sensitivity_at_specificity: 0.8650 - specificity_at_sensitivity: 0.8513 - recall: 0.7673 - precision: 0.6783\n",
            "Epoch 477: val_accuracy did not improve from 0.81016\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.5339 - accuracy: 0.6996 - sensitivity_at_specificity: 0.8650 - specificity_at_sensitivity: 0.8513 - recall: 0.7673 - precision: 0.6783 - val_loss: 0.4653 - val_accuracy: 0.7359 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8398 - val_recall: 0.7211 - val_precision: 0.7374\n",
            "Epoch 478/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5127 - accuracy: 0.7184 - sensitivity_at_specificity: 0.8949 - specificity_at_sensitivity: 0.8934 - recall: 0.7421 - precision: 0.6955\n",
            "Epoch 478: val_accuracy did not improve from 0.81016\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.5127 - accuracy: 0.7184 - sensitivity_at_specificity: 0.8949 - specificity_at_sensitivity: 0.8934 - recall: 0.7421 - precision: 0.6955 - val_loss: 0.4418 - val_accuracy: 0.7594 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8449 - val_recall: 0.7973 - val_precision: 0.7518\n",
            "Epoch 479/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5035 - accuracy: 0.7316 - sensitivity_at_specificity: 0.9049 - specificity_at_sensitivity: 0.8983 - recall: 0.7382 - precision: 0.7262\n",
            "Epoch 479: val_accuracy did not improve from 0.81016\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.5035 - accuracy: 0.7316 - sensitivity_at_specificity: 0.9049 - specificity_at_sensitivity: 0.8983 - recall: 0.7382 - precision: 0.7262 - val_loss: 0.4770 - val_accuracy: 0.7328 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8251 - val_recall: 0.7619 - val_precision: 0.7262\n",
            "Epoch 480/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5008 - accuracy: 0.7402 - sensitivity_at_specificity: 0.9103 - specificity_at_sensitivity: 0.8944 - recall: 0.7847 - precision: 0.7211\n",
            "Epoch 480: val_accuracy did not improve from 0.81016\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.5008 - accuracy: 0.7402 - sensitivity_at_specificity: 0.9103 - specificity_at_sensitivity: 0.8944 - recall: 0.7847 - precision: 0.7211 - val_loss: 0.4642 - val_accuracy: 0.7688 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8307 - val_recall: 0.8553 - val_precision: 0.7273\n",
            "Epoch 481/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5173 - accuracy: 0.7277 - sensitivity_at_specificity: 0.8976 - specificity_at_sensitivity: 0.8706 - recall: 0.7683 - precision: 0.7184\n",
            "Epoch 481: val_accuracy did not improve from 0.81016\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.5173 - accuracy: 0.7277 - sensitivity_at_specificity: 0.8976 - specificity_at_sensitivity: 0.8706 - recall: 0.7683 - precision: 0.7184 - val_loss: 0.4529 - val_accuracy: 0.7742 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8368 - val_recall: 0.8593 - val_precision: 0.7435\n",
            "Epoch 482/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5094 - accuracy: 0.7273 - sensitivity_at_specificity: 0.9195 - specificity_at_sensitivity: 0.8837 - recall: 0.7443 - precision: 0.7196\n",
            "Epoch 482: val_accuracy did not improve from 0.81016\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.5094 - accuracy: 0.7273 - sensitivity_at_specificity: 0.9195 - specificity_at_sensitivity: 0.8837 - recall: 0.7443 - precision: 0.7196 - val_loss: 0.4408 - val_accuracy: 0.7875 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8536 - val_recall: 0.8386 - val_precision: 0.7599\n",
            "Epoch 483/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5042 - accuracy: 0.7227 - sensitivity_at_specificity: 0.9073 - specificity_at_sensitivity: 0.8774 - recall: 0.7488 - precision: 0.6967\n",
            "Epoch 483: val_accuracy did not improve from 0.81016\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.5042 - accuracy: 0.7227 - sensitivity_at_specificity: 0.9073 - specificity_at_sensitivity: 0.8774 - recall: 0.7488 - precision: 0.6967 - val_loss: 0.4636 - val_accuracy: 0.7492 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8408 - val_recall: 0.7947 - val_precision: 0.7472\n",
            "Epoch 484/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5019 - accuracy: 0.7348 - sensitivity_at_specificity: 0.9086 - specificity_at_sensitivity: 0.8883 - recall: 0.7547 - precision: 0.7258\n",
            "Epoch 484: val_accuracy did not improve from 0.81016\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.5019 - accuracy: 0.7348 - sensitivity_at_specificity: 0.9086 - specificity_at_sensitivity: 0.8883 - recall: 0.7547 - precision: 0.7258 - val_loss: 0.4525 - val_accuracy: 0.7734 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8156 - val_recall: 0.8479 - val_precision: 0.7429\n",
            "Epoch 485/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5078 - accuracy: 0.7305 - sensitivity_at_specificity: 0.8945 - specificity_at_sensitivity: 0.9097 - recall: 0.7550 - precision: 0.7249\n",
            "Epoch 485: val_accuracy did not improve from 0.81016\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.5078 - accuracy: 0.7305 - sensitivity_at_specificity: 0.8945 - specificity_at_sensitivity: 0.9097 - recall: 0.7550 - precision: 0.7249 - val_loss: 0.4467 - val_accuracy: 0.7914 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8368 - val_recall: 0.8992 - val_precision: 0.7456\n",
            "Epoch 486/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4841 - accuracy: 0.7562 - sensitivity_at_specificity: 0.9215 - specificity_at_sensitivity: 0.9132 - recall: 0.7796 - precision: 0.7430\n",
            "Epoch 486: val_accuracy did not improve from 0.81016\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.4841 - accuracy: 0.7562 - sensitivity_at_specificity: 0.9215 - specificity_at_sensitivity: 0.9132 - recall: 0.7796 - precision: 0.7430 - val_loss: 0.4497 - val_accuracy: 0.7586 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8378 - val_recall: 0.8078 - val_precision: 0.7380\n",
            "Epoch 487/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4938 - accuracy: 0.7340 - sensitivity_at_specificity: 0.9310 - specificity_at_sensitivity: 0.8907 - recall: 0.7898 - precision: 0.7054\n",
            "Epoch 487: val_accuracy did not improve from 0.81016\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.4938 - accuracy: 0.7340 - sensitivity_at_specificity: 0.9310 - specificity_at_sensitivity: 0.8907 - recall: 0.7898 - precision: 0.7054 - val_loss: 0.4688 - val_accuracy: 0.7664 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8307 - val_recall: 0.8131 - val_precision: 0.7447\n",
            "Epoch 488/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4974 - accuracy: 0.7309 - sensitivity_at_specificity: 0.9114 - specificity_at_sensitivity: 0.9037 - recall: 0.7389 - precision: 0.7153\n",
            "Epoch 488: val_accuracy did not improve from 0.81016\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.4974 - accuracy: 0.7309 - sensitivity_at_specificity: 0.9114 - specificity_at_sensitivity: 0.9037 - recall: 0.7389 - precision: 0.7153 - val_loss: 0.4518 - val_accuracy: 0.7516 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8609 - val_recall: 0.7409 - val_precision: 0.7528\n",
            "Epoch 489/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5062 - accuracy: 0.7340 - sensitivity_at_specificity: 0.9074 - specificity_at_sensitivity: 0.8871 - recall: 0.7463 - precision: 0.7298\n",
            "Epoch 489: val_accuracy did not improve from 0.81016\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.5062 - accuracy: 0.7340 - sensitivity_at_specificity: 0.9074 - specificity_at_sensitivity: 0.8871 - recall: 0.7463 - precision: 0.7298 - val_loss: 0.4607 - val_accuracy: 0.7766 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8356 - val_recall: 0.8507 - val_precision: 0.7331\n",
            "Epoch 490/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5019 - accuracy: 0.7191 - sensitivity_at_specificity: 0.9103 - specificity_at_sensitivity: 0.8967 - recall: 0.7574 - precision: 0.7041\n",
            "Epoch 490: val_accuracy did not improve from 0.81016\n",
            "10/10 [==============================] - 2s 174ms/step - loss: 0.5019 - accuracy: 0.7191 - sensitivity_at_specificity: 0.9103 - specificity_at_sensitivity: 0.8967 - recall: 0.7574 - precision: 0.7041 - val_loss: 0.4638 - val_accuracy: 0.7523 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8152 - val_recall: 0.8242 - val_precision: 0.7107\n",
            "Epoch 491/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5157 - accuracy: 0.7270 - sensitivity_at_specificity: 0.8979 - specificity_at_sensitivity: 0.8819 - recall: 0.7832 - precision: 0.6996\n",
            "Epoch 491: val_accuracy did not improve from 0.81016\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.5157 - accuracy: 0.7270 - sensitivity_at_specificity: 0.8979 - specificity_at_sensitivity: 0.8819 - recall: 0.7832 - precision: 0.6996 - val_loss: 0.4575 - val_accuracy: 0.7648 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8571 - val_recall: 0.7663 - val_precision: 0.7579\n",
            "Epoch 492/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5083 - accuracy: 0.7285 - sensitivity_at_specificity: 0.8896 - specificity_at_sensitivity: 0.9019 - recall: 0.7387 - precision: 0.7257\n",
            "Epoch 492: val_accuracy did not improve from 0.81016\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.5083 - accuracy: 0.7285 - sensitivity_at_specificity: 0.8896 - specificity_at_sensitivity: 0.9019 - recall: 0.7387 - precision: 0.7257 - val_loss: 0.4398 - val_accuracy: 0.7719 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8416 - val_recall: 0.8314 - val_precision: 0.7318\n",
            "Epoch 493/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5055 - accuracy: 0.7371 - sensitivity_at_specificity: 0.8978 - specificity_at_sensitivity: 0.8884 - recall: 0.7321 - precision: 0.7280\n",
            "Epoch 493: val_accuracy did not improve from 0.81016\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.5055 - accuracy: 0.7371 - sensitivity_at_specificity: 0.8978 - specificity_at_sensitivity: 0.8884 - recall: 0.7321 - precision: 0.7280 - val_loss: 0.4705 - val_accuracy: 0.7648 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8163 - val_recall: 0.8700 - val_precision: 0.7248\n",
            "Epoch 494/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5036 - accuracy: 0.7398 - sensitivity_at_specificity: 0.8911 - specificity_at_sensitivity: 0.9019 - recall: 0.7613 - precision: 0.7317\n",
            "Epoch 494: val_accuracy did not improve from 0.81016\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.5036 - accuracy: 0.7398 - sensitivity_at_specificity: 0.8911 - specificity_at_sensitivity: 0.9019 - recall: 0.7613 - precision: 0.7317 - val_loss: 0.4710 - val_accuracy: 0.7711 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8214 - val_recall: 0.8836 - val_precision: 0.7196\n",
            "Epoch 495/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5147 - accuracy: 0.7207 - sensitivity_at_specificity: 0.9010 - specificity_at_sensitivity: 0.8803 - recall: 0.7549 - precision: 0.7045\n",
            "Epoch 495: val_accuracy did not improve from 0.81016\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.5147 - accuracy: 0.7207 - sensitivity_at_specificity: 0.9010 - specificity_at_sensitivity: 0.8803 - recall: 0.7549 - precision: 0.7045 - val_loss: 0.4629 - val_accuracy: 0.7547 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8313 - val_recall: 0.8506 - val_precision: 0.7024\n",
            "Epoch 496/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5001 - accuracy: 0.7418 - sensitivity_at_specificity: 0.8997 - specificity_at_sensitivity: 0.9132 - recall: 0.7440 - precision: 0.7305\n",
            "Epoch 496: val_accuracy did not improve from 0.81016\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.5001 - accuracy: 0.7418 - sensitivity_at_specificity: 0.8997 - specificity_at_sensitivity: 0.9132 - recall: 0.7440 - precision: 0.7305 - val_loss: 0.4641 - val_accuracy: 0.7523 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8161 - val_recall: 0.8094 - val_precision: 0.7470\n",
            "Epoch 497/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5039 - accuracy: 0.7277 - sensitivity_at_specificity: 0.8932 - specificity_at_sensitivity: 0.8983 - recall: 0.7788 - precision: 0.7126\n",
            "Epoch 497: val_accuracy did not improve from 0.81016\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.5039 - accuracy: 0.7277 - sensitivity_at_specificity: 0.8932 - specificity_at_sensitivity: 0.8983 - recall: 0.7788 - precision: 0.7126 - val_loss: 0.4777 - val_accuracy: 0.7375 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8262 - val_recall: 0.7667 - val_precision: 0.7188\n",
            "Epoch 498/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5019 - accuracy: 0.7355 - sensitivity_at_specificity: 0.9104 - specificity_at_sensitivity: 0.8963 - recall: 0.7665 - precision: 0.7291\n",
            "Epoch 498: val_accuracy did not improve from 0.81016\n",
            "10/10 [==============================] - 2s 175ms/step - loss: 0.5019 - accuracy: 0.7355 - sensitivity_at_specificity: 0.9104 - specificity_at_sensitivity: 0.8963 - recall: 0.7665 - precision: 0.7291 - val_loss: 0.4591 - val_accuracy: 0.7781 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8264 - val_recall: 0.8992 - val_precision: 0.7219\n",
            "Epoch 499/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4897 - accuracy: 0.7414 - sensitivity_at_specificity: 0.9258 - specificity_at_sensitivity: 0.8942 - recall: 0.7821 - precision: 0.7270\n",
            "Epoch 499: val_accuracy did not improve from 0.81016\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.4897 - accuracy: 0.7414 - sensitivity_at_specificity: 0.9258 - specificity_at_sensitivity: 0.8942 - recall: 0.7821 - precision: 0.7270 - val_loss: 0.4665 - val_accuracy: 0.7500 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8360 - val_recall: 0.7807 - val_precision: 0.7420\n",
            "Epoch 500/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5045 - accuracy: 0.7352 - sensitivity_at_specificity: 0.9075 - specificity_at_sensitivity: 0.8945 - recall: 0.7372 - precision: 0.7197\n",
            "Epoch 500: val_accuracy did not improve from 0.81016\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.5045 - accuracy: 0.7352 - sensitivity_at_specificity: 0.9075 - specificity_at_sensitivity: 0.8945 - recall: 0.7372 - precision: 0.7197 - val_loss: 0.4640 - val_accuracy: 0.7750 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8191 - val_recall: 0.8698 - val_precision: 0.7233\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Performance Metrics**"
      ],
      "metadata": {
        "id": "u1LMcfAeEs7T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Training_Accuracy=history.history['accuracy']\n",
        "Validation_Accuracy=history.history['val_accuracy']\n",
        "Validation_Specificity=history.history['val_specificity_at_sensitivity']\n",
        "Validation_Sensitivity=history.history['val_sensitivity_at_specificity']\n",
        "Validation_Recall=history.history['val_recall']\n",
        "Validation_Precision=history.history['val_precision']\n",
        "Validation_Loss=history.history['val_loss']\n",
        "\n",
        "print(\"Training Accuracy: \",max(Training_Accuracy))\n",
        "print(\"Validation Accuracy: \",max(Validation_Accuracy))\n",
        "print(\"Validation Specificity: \",max(Validation_Specificity))\n",
        "print(\"Validation Sensitivity: \",max(Validation_Sensitivity))\n",
        "print(\"Validation Recall: \",max(Validation_Recall))\n",
        "print(\"Validation Precision: \",max(Validation_Precision))\n",
        "print(\"Validation Loss: \",min(Validation_Loss))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCdS_0U65A0-",
        "outputId": "d4b6bfe3-80f4-4b61-c3d8-cf6a59b9e62a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy:  0.7562292218208313\n",
            "Validation Accuracy:  0.8101562261581421\n",
            "Validation Specificity:  0.8852459192276001\n",
            "Validation Sensitivity:  1.0\n",
            "Validation Recall:  1.0\n",
            "Validation Precision:  0.782608687877655\n",
            "Validation Loss:  0.4133087694644928\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Accuracy Graph**"
      ],
      "metadata": {
        "id": "OHshGOuJEwOy"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLqjG2X-vdLj",
        "outputId": "dcf48de2-44e8-485e-8afb-83c45183f374",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        }
      },
      "source": [
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loss Graph**"
      ],
      "metadata": {
        "id": "KALzPw5kEx7x"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBSAyVfivvHX",
        "outputId": "51510247-5675-4a68-cb5c-0f2ec2c5d4ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        }
      },
      "source": [
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}