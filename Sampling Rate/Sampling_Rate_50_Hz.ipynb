{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "7e88OLey6Bgd"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7e88OLey6Bgd"
      },
      "source": [
        "# **Image Classification with Convolutional Neural Networks (CNNs)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsTzc3oi726u"
      },
      "source": [
        "# **Building a Convolutional Neural Network with Keras**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import Libraries**"
      ],
      "metadata": {
        "id": "uAGaQ4sJLid6"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCglDGFy8AhT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "bc080075-0c12-4665-dce1-5f61bf65e218"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "tf.__version__\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import matplotlib.image as mpimg\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "import imageio\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.8.2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qf7eW3HC9XVL"
      },
      "source": [
        "**Data Acquisition and ImageDataGenerator**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0BfyGlJbx0l"
      },
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255) #Normalize the pixel values\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hsimgs7aqt6G"
      },
      "source": [
        "#File path to the folder containin images\n",
        "train_dir = os.path.join('/content/spectrograms_50/Train')\n",
        "validation_dir = os.path.join('/content/spectrograms_50/Validation')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NyvlF41oqxEP",
        "outputId": "531874e7-ff17-4540-d555-6f7e652c69c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(64,64),\n",
        "    batch_size=256,\n",
        "    shuffle=True,\n",
        "    class_mode='binary')\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    validation_dir,\n",
        "    target_size=(64,64),\n",
        "    batch_size=256,\n",
        "    shuffle=True,\n",
        "    class_mode='binary')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 33128 images belonging to 2 classes.\n",
            "Found 6780 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3yhwpN_-BaS"
      },
      "source": [
        "**Building the Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSzxq4KDtKN6"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "                                    \n",
        "    # First convolution layer \n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(64, 64, 3),use_bias=True),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "\n",
        "    # Second convolution layer \n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu',use_bias=True),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    \n",
        "\n",
        "    # Third convolution layer  \n",
        "    tf.keras.layers.Conv2D(256, (3,3), activation='relu',use_bias=True),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "\n",
        "  # Fourth convolution layer  \n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu',use_bias=True),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "\n",
        "\n",
        "    # Flatten the pooled feature maps\n",
        "    tf.keras.layers.Flatten(),\n",
        "\n",
        "    # Fully connected hidden layer\n",
        "    tf.keras.layers.Dense(8, activation='relu',use_bias=True),\n",
        "\n",
        "\n",
        "    # Output layer\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid',activity_regularizer=regularizers.L1(0.001))   \n",
        "\n",
        "])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDXufVt4-LFY"
      },
      "source": [
        "**Model Summary**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HU0RFGLtNJb",
        "outputId": "08c30a3c-9036-4547-f6ec-6ffdd88b7e8f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 62, 62, 64)        1792      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 31, 31, 64)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 31, 31, 64)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 29, 29, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 14, 14, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 12, 12, 256)       295168    \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 6, 6, 256)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 6, 6, 256)         0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 4, 4, 64)          147520    \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 2, 2, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 2, 2, 64)          0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 8)                 2056      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 520,401\n",
            "Trainable params: 520,401\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THk8lK3G-cdk"
      },
      "source": [
        "**Optimizer Implementation and model training/validation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBN3GBMItPMH"
      },
      "source": [
        "#from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import SensitivityAtSpecificity,SpecificityAtSensitivity,Recall,Precision\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=Adam(learning_rate=0.001),\n",
        "              metrics=['accuracy',SensitivityAtSpecificity(0.5),SpecificityAtSensitivity(0.5),Recall(0.5),Precision(0.5)]) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Q0MPMwh3EgY"
      },
      "source": [
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('val_accuracy')>0.99): \n",
        "      print(\"\\nReached 99% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "callbacks = myCallback()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7f6gDG3dx9sJ",
        "outputId": "051d63e0-98c7-43a6-d9ad-d3511641936b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "checkpoint = ModelCheckpoint(\"ECG_Spectrogram_Model.h5\", monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
        "\n",
        "history = model.fit(\n",
        "      train_generator,\n",
        "      steps_per_epoch=10,  \n",
        "      epochs=500,\n",
        "      verbose=1,\n",
        "      validation_data = validation_generator,\n",
        "      validation_steps=5, \n",
        "      callbacks = [callbacks,checkpoint]\n",
        ") "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6952 - accuracy: 0.4953 - sensitivity_at_specificity: 0.4582 - specificity_at_sensitivity: 0.4247 - recall: 0.1790 - precision: 0.4862\n",
            "Epoch 1: val_accuracy improved from -inf to 0.51406, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 17s 269ms/step - loss: 0.6952 - accuracy: 0.4953 - sensitivity_at_specificity: 0.4582 - specificity_at_sensitivity: 0.4247 - recall: 0.1790 - precision: 0.4862 - val_loss: 0.6936 - val_accuracy: 0.5141 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.0000e+00 - val_recall: 0.9985 - val_precision: 0.5114\n",
            "Epoch 2/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6935 - accuracy: 0.5207 - sensitivity_at_specificity: 0.0895 - specificity_at_sensitivity: 0.2000 - recall: 0.7805 - precision: 0.5261\n",
            "Epoch 2: val_accuracy improved from 0.51406 to 0.73594, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 205ms/step - loss: 0.6935 - accuracy: 0.5207 - sensitivity_at_specificity: 0.0895 - specificity_at_sensitivity: 0.2000 - recall: 0.7805 - precision: 0.5261 - val_loss: 0.6915 - val_accuracy: 0.7359 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.3857 - val_recall: 0.7356 - val_precision: 0.7263\n",
            "Epoch 3/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6917 - accuracy: 0.5281 - sensitivity_at_specificity: 0.5654 - specificity_at_sensitivity: 0.5004 - recall: 0.4988 - precision: 0.5286\n",
            "Epoch 3: val_accuracy did not improve from 0.73594\n",
            "10/10 [==============================] - 2s 196ms/step - loss: 0.6917 - accuracy: 0.5281 - sensitivity_at_specificity: 0.5654 - specificity_at_sensitivity: 0.5004 - recall: 0.4988 - precision: 0.5286 - val_loss: 0.6744 - val_accuracy: 0.5172 - val_sensitivity_at_specificity: 0.9920 - val_specificity_at_sensitivity: 0.8144 - val_recall: 0.0175 - val_precision: 0.9167\n",
            "Epoch 4/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6788 - accuracy: 0.5258 - sensitivity_at_specificity: 0.6860 - specificity_at_sensitivity: 0.7024 - recall: 0.1078 - precision: 0.6881\n",
            "Epoch 4: val_accuracy did not improve from 0.73594\n",
            "10/10 [==============================] - 2s 196ms/step - loss: 0.6788 - accuracy: 0.5258 - sensitivity_at_specificity: 0.6860 - specificity_at_sensitivity: 0.7024 - recall: 0.1078 - precision: 0.6881 - val_loss: 0.5989 - val_accuracy: 0.6820 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.8863 - val_recall: 0.4326 - val_precision: 0.8598\n",
            "Epoch 5/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6382 - accuracy: 0.6221 - sensitivity_at_specificity: 0.8075 - specificity_at_sensitivity: 0.7254 - recall: 0.4783 - precision: 0.6814\n",
            "Epoch 5: val_accuracy improved from 0.73594 to 0.77344, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 230ms/step - loss: 0.6382 - accuracy: 0.6221 - sensitivity_at_specificity: 0.8075 - specificity_at_sensitivity: 0.7254 - recall: 0.4783 - precision: 0.6814 - val_loss: 0.4905 - val_accuracy: 0.7734 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8223 - val_recall: 0.7212 - val_precision: 0.7784\n",
            "Epoch 6/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6171 - accuracy: 0.6418 - sensitivity_at_specificity: 0.6476 - specificity_at_sensitivity: 0.5697 - recall: 0.7947 - precision: 0.6114\n",
            "Epoch 6: val_accuracy improved from 0.77344 to 0.80078, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 0.6171 - accuracy: 0.6418 - sensitivity_at_specificity: 0.6476 - specificity_at_sensitivity: 0.5697 - recall: 0.7947 - precision: 0.6114 - val_loss: 0.4622 - val_accuracy: 0.8008 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8848 - val_recall: 0.8521 - val_precision: 0.7679\n",
            "Epoch 7/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6008 - accuracy: 0.6624 - sensitivity_at_specificity: 0.7293 - specificity_at_sensitivity: 0.6842 - recall: 0.8477 - precision: 0.6195\n",
            "Epoch 7: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 188ms/step - loss: 0.6008 - accuracy: 0.6624 - sensitivity_at_specificity: 0.7293 - specificity_at_sensitivity: 0.6842 - recall: 0.8477 - precision: 0.6195 - val_loss: 0.4579 - val_accuracy: 0.7953 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8161 - val_recall: 0.8842 - val_precision: 0.7432\n",
            "Epoch 8/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6039 - accuracy: 0.6461 - sensitivity_at_specificity: 0.7901 - specificity_at_sensitivity: 0.6912 - recall: 0.8370 - precision: 0.6003\n",
            "Epoch 8: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 196ms/step - loss: 0.6039 - accuracy: 0.6461 - sensitivity_at_specificity: 0.7901 - specificity_at_sensitivity: 0.6912 - recall: 0.8370 - precision: 0.6003 - val_loss: 0.4532 - val_accuracy: 0.7937 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8487 - val_recall: 0.8247 - val_precision: 0.7761\n",
            "Epoch 9/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5798 - accuracy: 0.6785 - sensitivity_at_specificity: 0.8557 - specificity_at_sensitivity: 0.7129 - recall: 0.8358 - precision: 0.6311\n",
            "Epoch 9: val_accuracy did not improve from 0.80078\n",
            "10/10 [==============================] - 2s 196ms/step - loss: 0.5798 - accuracy: 0.6785 - sensitivity_at_specificity: 0.8557 - specificity_at_sensitivity: 0.7129 - recall: 0.8358 - precision: 0.6311 - val_loss: 0.4406 - val_accuracy: 0.7937 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8477 - val_recall: 0.8266 - val_precision: 0.7646\n",
            "Epoch 10/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5870 - accuracy: 0.6570 - sensitivity_at_specificity: 0.8195 - specificity_at_sensitivity: 0.7164 - recall: 0.8211 - precision: 0.6112\n",
            "Epoch 10: val_accuracy improved from 0.80078 to 0.80781, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 196ms/step - loss: 0.5870 - accuracy: 0.6570 - sensitivity_at_specificity: 0.8195 - specificity_at_sensitivity: 0.7164 - recall: 0.8211 - precision: 0.6112 - val_loss: 0.4396 - val_accuracy: 0.8078 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8569 - val_recall: 0.8696 - val_precision: 0.7756\n",
            "Epoch 11/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5710 - accuracy: 0.6820 - sensitivity_at_specificity: 0.8650 - specificity_at_sensitivity: 0.7548 - recall: 0.8298 - precision: 0.6464\n",
            "Epoch 11: val_accuracy improved from 0.80781 to 0.81406, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 200ms/step - loss: 0.5710 - accuracy: 0.6820 - sensitivity_at_specificity: 0.8650 - specificity_at_sensitivity: 0.7548 - recall: 0.8298 - precision: 0.6464 - val_loss: 0.4171 - val_accuracy: 0.8141 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8521 - val_recall: 0.9231 - val_precision: 0.7520\n",
            "Epoch 12/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5839 - accuracy: 0.6730 - sensitivity_at_specificity: 0.8245 - specificity_at_sensitivity: 0.7547 - recall: 0.8312 - precision: 0.6470\n",
            "Epoch 12: val_accuracy improved from 0.81406 to 0.82031, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 195ms/step - loss: 0.5839 - accuracy: 0.6730 - sensitivity_at_specificity: 0.8245 - specificity_at_sensitivity: 0.7547 - recall: 0.8312 - precision: 0.6470 - val_loss: 0.4370 - val_accuracy: 0.8203 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8580 - val_recall: 0.9613 - val_precision: 0.7518\n",
            "Epoch 13/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5842 - accuracy: 0.6762 - sensitivity_at_specificity: 0.8322 - specificity_at_sensitivity: 0.7787 - recall: 0.8091 - precision: 0.6440\n",
            "Epoch 13: val_accuracy did not improve from 0.82031\n",
            "10/10 [==============================] - 2s 193ms/step - loss: 0.5842 - accuracy: 0.6762 - sensitivity_at_specificity: 0.8322 - specificity_at_sensitivity: 0.7787 - recall: 0.8091 - precision: 0.6440 - val_loss: 0.4405 - val_accuracy: 0.7937 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8664 - val_recall: 0.8370 - val_precision: 0.7722\n",
            "Epoch 14/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5747 - accuracy: 0.6848 - sensitivity_at_specificity: 0.8564 - specificity_at_sensitivity: 0.7714 - recall: 0.8342 - precision: 0.6492\n",
            "Epoch 14: val_accuracy did not improve from 0.82031\n",
            "10/10 [==============================] - 2s 191ms/step - loss: 0.5747 - accuracy: 0.6848 - sensitivity_at_specificity: 0.8564 - specificity_at_sensitivity: 0.7714 - recall: 0.8342 - precision: 0.6492 - val_loss: 0.4443 - val_accuracy: 0.7750 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8784 - val_recall: 0.7622 - val_precision: 0.7672\n",
            "Epoch 15/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5647 - accuracy: 0.6805 - sensitivity_at_specificity: 0.8637 - specificity_at_sensitivity: 0.7973 - recall: 0.7878 - precision: 0.6478\n",
            "Epoch 15: val_accuracy did not improve from 0.82031\n",
            "10/10 [==============================] - 2s 190ms/step - loss: 0.5647 - accuracy: 0.6805 - sensitivity_at_specificity: 0.8637 - specificity_at_sensitivity: 0.7973 - recall: 0.7878 - precision: 0.6478 - val_loss: 0.4646 - val_accuracy: 0.7594 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8782 - val_recall: 0.6898 - val_precision: 0.8069\n",
            "Epoch 16/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5453 - accuracy: 0.7137 - sensitivity_at_specificity: 0.8821 - specificity_at_sensitivity: 0.8307 - recall: 0.7785 - precision: 0.6823\n",
            "Epoch 16: val_accuracy did not improve from 0.82031\n",
            "10/10 [==============================] - 2s 193ms/step - loss: 0.5453 - accuracy: 0.7137 - sensitivity_at_specificity: 0.8821 - specificity_at_sensitivity: 0.8307 - recall: 0.7785 - precision: 0.6823 - val_loss: 0.4295 - val_accuracy: 0.8070 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9132 - val_recall: 0.7737 - val_precision: 0.8197\n",
            "Epoch 17/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5534 - accuracy: 0.7016 - sensitivity_at_specificity: 0.8704 - specificity_at_sensitivity: 0.8163 - recall: 0.7588 - precision: 0.6811\n",
            "Epoch 17: val_accuracy did not improve from 0.82031\n",
            "10/10 [==============================] - 2s 193ms/step - loss: 0.5534 - accuracy: 0.7016 - sensitivity_at_specificity: 0.8704 - specificity_at_sensitivity: 0.8163 - recall: 0.7588 - precision: 0.6811 - val_loss: 0.4164 - val_accuracy: 0.8117 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9460 - val_recall: 0.7690 - val_precision: 0.8365\n",
            "Epoch 18/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5467 - accuracy: 0.6957 - sensitivity_at_specificity: 0.8660 - specificity_at_sensitivity: 0.8604 - recall: 0.7596 - precision: 0.6809\n",
            "Epoch 18: val_accuracy did not improve from 0.82031\n",
            "10/10 [==============================] - 2s 191ms/step - loss: 0.5467 - accuracy: 0.6957 - sensitivity_at_specificity: 0.8660 - specificity_at_sensitivity: 0.8604 - recall: 0.7596 - precision: 0.6809 - val_loss: 0.4184 - val_accuracy: 0.8039 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9486 - val_recall: 0.7356 - val_precision: 0.8627\n",
            "Epoch 19/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5458 - accuracy: 0.7137 - sensitivity_at_specificity: 0.8707 - specificity_at_sensitivity: 0.8418 - recall: 0.7468 - precision: 0.7106\n",
            "Epoch 19: val_accuracy improved from 0.82031 to 0.82891, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 200ms/step - loss: 0.5458 - accuracy: 0.7137 - sensitivity_at_specificity: 0.8707 - specificity_at_sensitivity: 0.8418 - recall: 0.7468 - precision: 0.7106 - val_loss: 0.3953 - val_accuracy: 0.8289 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9532 - val_recall: 0.8075 - val_precision: 0.8431\n",
            "Epoch 20/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5245 - accuracy: 0.7258 - sensitivity_at_specificity: 0.8885 - specificity_at_sensitivity: 0.8779 - recall: 0.7955 - precision: 0.7010\n",
            "Epoch 20: val_accuracy improved from 0.82891 to 0.83203, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 0.5245 - accuracy: 0.7258 - sensitivity_at_specificity: 0.8885 - specificity_at_sensitivity: 0.8779 - recall: 0.7955 - precision: 0.7010 - val_loss: 0.3729 - val_accuracy: 0.8320 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9454 - val_recall: 0.8232 - val_precision: 0.8376\n",
            "Epoch 21/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5193 - accuracy: 0.7230 - sensitivity_at_specificity: 0.8847 - specificity_at_sensitivity: 0.8911 - recall: 0.7490 - precision: 0.7106\n",
            "Epoch 21: val_accuracy did not improve from 0.83203\n",
            "10/10 [==============================] - 2s 197ms/step - loss: 0.5193 - accuracy: 0.7230 - sensitivity_at_specificity: 0.8847 - specificity_at_sensitivity: 0.8911 - recall: 0.7490 - precision: 0.7106 - val_loss: 0.3741 - val_accuracy: 0.8258 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9457 - val_recall: 0.8239 - val_precision: 0.8252\n",
            "Epoch 22/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5170 - accuracy: 0.7273 - sensitivity_at_specificity: 0.9004 - specificity_at_sensitivity: 0.8809 - recall: 0.7427 - precision: 0.7191\n",
            "Epoch 22: val_accuracy did not improve from 0.83203\n",
            "10/10 [==============================] - 2s 194ms/step - loss: 0.5170 - accuracy: 0.7273 - sensitivity_at_specificity: 0.9004 - specificity_at_sensitivity: 0.8809 - recall: 0.7427 - precision: 0.7191 - val_loss: 0.3927 - val_accuracy: 0.8234 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9416 - val_recall: 0.7651 - val_precision: 0.8789\n",
            "Epoch 23/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5120 - accuracy: 0.7309 - sensitivity_at_specificity: 0.8811 - specificity_at_sensitivity: 0.8928 - recall: 0.7373 - precision: 0.7172\n",
            "Epoch 23: val_accuracy did not improve from 0.83203\n",
            "10/10 [==============================] - 2s 190ms/step - loss: 0.5120 - accuracy: 0.7309 - sensitivity_at_specificity: 0.8811 - specificity_at_sensitivity: 0.8928 - recall: 0.7373 - precision: 0.7172 - val_loss: 0.3723 - val_accuracy: 0.8266 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9311 - val_recall: 0.8643 - val_precision: 0.8041\n",
            "Epoch 24/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5188 - accuracy: 0.7230 - sensitivity_at_specificity: 0.8879 - specificity_at_sensitivity: 0.8941 - recall: 0.7547 - precision: 0.7086\n",
            "Epoch 24: val_accuracy did not improve from 0.83203\n",
            "10/10 [==============================] - 2s 194ms/step - loss: 0.5188 - accuracy: 0.7230 - sensitivity_at_specificity: 0.8879 - specificity_at_sensitivity: 0.8941 - recall: 0.7547 - precision: 0.7086 - val_loss: 0.4020 - val_accuracy: 0.8109 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9469 - val_recall: 0.7477 - val_precision: 0.8662\n",
            "Epoch 25/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5220 - accuracy: 0.7191 - sensitivity_at_specificity: 0.8857 - specificity_at_sensitivity: 0.8689 - recall: 0.6742 - precision: 0.7429\n",
            "Epoch 25: val_accuracy improved from 0.83203 to 0.84297, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 198ms/step - loss: 0.5220 - accuracy: 0.7191 - sensitivity_at_specificity: 0.8857 - specificity_at_sensitivity: 0.8689 - recall: 0.6742 - precision: 0.7429 - val_loss: 0.3635 - val_accuracy: 0.8430 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9329 - val_recall: 0.8714 - val_precision: 0.8352\n",
            "Epoch 26/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5137 - accuracy: 0.7301 - sensitivity_at_specificity: 0.8925 - specificity_at_sensitivity: 0.8965 - recall: 0.7914 - precision: 0.7036\n",
            "Epoch 26: val_accuracy did not improve from 0.84297\n",
            "10/10 [==============================] - 2s 191ms/step - loss: 0.5137 - accuracy: 0.7301 - sensitivity_at_specificity: 0.8925 - specificity_at_sensitivity: 0.8965 - recall: 0.7914 - precision: 0.7036 - val_loss: 0.3847 - val_accuracy: 0.8258 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9496 - val_recall: 0.7895 - val_precision: 0.8635\n",
            "Epoch 27/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5144 - accuracy: 0.7355 - sensitivity_at_specificity: 0.8941 - specificity_at_sensitivity: 0.8903 - recall: 0.7165 - precision: 0.7461\n",
            "Epoch 27: val_accuracy did not improve from 0.84297\n",
            "10/10 [==============================] - 2s 183ms/step - loss: 0.5144 - accuracy: 0.7355 - sensitivity_at_specificity: 0.8941 - specificity_at_sensitivity: 0.8903 - recall: 0.7165 - precision: 0.7461 - val_loss: 0.3709 - val_accuracy: 0.8164 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9545 - val_recall: 0.7336 - val_precision: 0.8804\n",
            "Epoch 28/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4964 - accuracy: 0.7517 - sensitivity_at_specificity: 0.9071 - specificity_at_sensitivity: 0.8879 - recall: 0.7504 - precision: 0.7556\n",
            "Epoch 28: val_accuracy improved from 0.84297 to 0.84531, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 191ms/step - loss: 0.4965 - accuracy: 0.7508 - sensitivity_at_specificity: 0.9094 - specificity_at_sensitivity: 0.8819 - recall: 0.7521 - precision: 0.7533 - val_loss: 0.3541 - val_accuracy: 0.8453 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9432 - val_recall: 0.8378 - val_precision: 0.8459\n",
            "Epoch 29/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5082 - accuracy: 0.7371 - sensitivity_at_specificity: 0.9045 - specificity_at_sensitivity: 0.8860 - recall: 0.7482 - precision: 0.7185\n",
            "Epoch 29: val_accuracy did not improve from 0.84531\n",
            "10/10 [==============================] - 2s 194ms/step - loss: 0.5082 - accuracy: 0.7371 - sensitivity_at_specificity: 0.9045 - specificity_at_sensitivity: 0.8860 - recall: 0.7482 - precision: 0.7185 - val_loss: 0.3542 - val_accuracy: 0.8367 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9575 - val_recall: 0.8406 - val_precision: 0.8259\n",
            "Epoch 30/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5165 - accuracy: 0.7305 - sensitivity_at_specificity: 0.9129 - specificity_at_sensitivity: 0.8756 - recall: 0.7253 - precision: 0.7310\n",
            "Epoch 30: val_accuracy improved from 0.84531 to 0.84922, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 199ms/step - loss: 0.5165 - accuracy: 0.7305 - sensitivity_at_specificity: 0.9129 - specificity_at_sensitivity: 0.8756 - recall: 0.7253 - precision: 0.7310 - val_loss: 0.3573 - val_accuracy: 0.8492 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9447 - val_recall: 0.8521 - val_precision: 0.8428\n",
            "Epoch 31/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5023 - accuracy: 0.7324 - sensitivity_at_specificity: 0.8989 - specificity_at_sensitivity: 0.9019 - recall: 0.7665 - precision: 0.7165\n",
            "Epoch 31: val_accuracy did not improve from 0.84922\n",
            "10/10 [==============================] - 2s 191ms/step - loss: 0.5023 - accuracy: 0.7324 - sensitivity_at_specificity: 0.8989 - specificity_at_sensitivity: 0.9019 - recall: 0.7665 - precision: 0.7165 - val_loss: 0.3544 - val_accuracy: 0.8438 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9393 - val_recall: 0.8713 - val_precision: 0.8247\n",
            "Epoch 32/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5202 - accuracy: 0.7293 - sensitivity_at_specificity: 0.8913 - specificity_at_sensitivity: 0.8737 - recall: 0.7084 - precision: 0.7357\n",
            "Epoch 32: val_accuracy did not improve from 0.84922\n",
            "10/10 [==============================] - 2s 189ms/step - loss: 0.5202 - accuracy: 0.7293 - sensitivity_at_specificity: 0.8913 - specificity_at_sensitivity: 0.8737 - recall: 0.7084 - precision: 0.7357 - val_loss: 0.3592 - val_accuracy: 0.8219 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9536 - val_recall: 0.8529 - val_precision: 0.7909\n",
            "Epoch 33/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5120 - accuracy: 0.7254 - sensitivity_at_specificity: 0.9106 - specificity_at_sensitivity: 0.8748 - recall: 0.7617 - precision: 0.6992\n",
            "Epoch 33: val_accuracy did not improve from 0.84922\n",
            "10/10 [==============================] - 2s 195ms/step - loss: 0.5120 - accuracy: 0.7254 - sensitivity_at_specificity: 0.9106 - specificity_at_sensitivity: 0.8748 - recall: 0.7617 - precision: 0.6992 - val_loss: 0.3896 - val_accuracy: 0.8078 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9577 - val_recall: 0.7301 - val_precision: 0.8651\n",
            "Epoch 34/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5240 - accuracy: 0.7344 - sensitivity_at_specificity: 0.8643 - specificity_at_sensitivity: 0.8934 - recall: 0.7020 - precision: 0.7490\n",
            "Epoch 34: val_accuracy did not improve from 0.84922\n",
            "10/10 [==============================] - 2s 194ms/step - loss: 0.5240 - accuracy: 0.7344 - sensitivity_at_specificity: 0.8643 - specificity_at_sensitivity: 0.8934 - recall: 0.7020 - precision: 0.7490 - val_loss: 0.4238 - val_accuracy: 0.7563 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9526 - val_recall: 0.5997 - val_precision: 0.8798\n",
            "Epoch 35/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5206 - accuracy: 0.7081 - sensitivity_at_specificity: 0.8782 - specificity_at_sensitivity: 0.8711 - recall: 0.7064 - precision: 0.7011\n",
            "Epoch 35: val_accuracy did not improve from 0.84922\n",
            "10/10 [==============================] - 2s 186ms/step - loss: 0.5206 - accuracy: 0.7081 - sensitivity_at_specificity: 0.8782 - specificity_at_sensitivity: 0.8711 - recall: 0.7064 - precision: 0.7011 - val_loss: 0.4064 - val_accuracy: 0.8008 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9462 - val_recall: 0.6948 - val_precision: 0.8740\n",
            "Epoch 36/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5222 - accuracy: 0.7238 - sensitivity_at_specificity: 0.8895 - specificity_at_sensitivity: 0.8736 - recall: 0.7396 - precision: 0.7212\n",
            "Epoch 36: val_accuracy did not improve from 0.84922\n",
            "10/10 [==============================] - 2s 192ms/step - loss: 0.5222 - accuracy: 0.7238 - sensitivity_at_specificity: 0.8895 - specificity_at_sensitivity: 0.8736 - recall: 0.7396 - precision: 0.7212 - val_loss: 0.3664 - val_accuracy: 0.8406 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9353 - val_recall: 0.8922 - val_precision: 0.8054\n",
            "Epoch 37/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5010 - accuracy: 0.7391 - sensitivity_at_specificity: 0.9033 - specificity_at_sensitivity: 0.9045 - recall: 0.7367 - precision: 0.7344\n",
            "Epoch 37: val_accuracy did not improve from 0.84922\n",
            "10/10 [==============================] - 2s 198ms/step - loss: 0.5010 - accuracy: 0.7391 - sensitivity_at_specificity: 0.9033 - specificity_at_sensitivity: 0.9045 - recall: 0.7367 - precision: 0.7344 - val_loss: 0.3562 - val_accuracy: 0.8273 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9423 - val_recall: 0.8451 - val_precision: 0.8157\n",
            "Epoch 38/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5001 - accuracy: 0.7430 - sensitivity_at_specificity: 0.9067 - specificity_at_sensitivity: 0.8905 - recall: 0.7368 - precision: 0.7380\n",
            "Epoch 38: val_accuracy did not improve from 0.84922\n",
            "10/10 [==============================] - 2s 198ms/step - loss: 0.5001 - accuracy: 0.7430 - sensitivity_at_specificity: 0.9067 - specificity_at_sensitivity: 0.8905 - recall: 0.7368 - precision: 0.7380 - val_loss: 0.3569 - val_accuracy: 0.8391 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9575 - val_recall: 0.8174 - val_precision: 0.8667\n",
            "Epoch 39/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5003 - accuracy: 0.7359 - sensitivity_at_specificity: 0.9080 - specificity_at_sensitivity: 0.9044 - recall: 0.7573 - precision: 0.7303\n",
            "Epoch 39: val_accuracy improved from 0.84922 to 0.85000, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 0.5003 - accuracy: 0.7359 - sensitivity_at_specificity: 0.9080 - specificity_at_sensitivity: 0.9044 - recall: 0.7573 - precision: 0.7303 - val_loss: 0.3451 - val_accuracy: 0.8500 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9649 - val_recall: 0.8622 - val_precision: 0.8354\n",
            "Epoch 40/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5267 - accuracy: 0.7195 - sensitivity_at_specificity: 0.8780 - specificity_at_sensitivity: 0.8645 - recall: 0.7263 - precision: 0.7059\n",
            "Epoch 40: val_accuracy did not improve from 0.85000\n",
            "10/10 [==============================] - 2s 196ms/step - loss: 0.5267 - accuracy: 0.7195 - sensitivity_at_specificity: 0.8780 - specificity_at_sensitivity: 0.8645 - recall: 0.7263 - precision: 0.7059 - val_loss: 0.3648 - val_accuracy: 0.8344 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9466 - val_recall: 0.8381 - val_precision: 0.8249\n",
            "Epoch 41/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4972 - accuracy: 0.7461 - sensitivity_at_specificity: 0.9092 - specificity_at_sensitivity: 0.8899 - recall: 0.7609 - precision: 0.7413\n",
            "Epoch 41: val_accuracy did not improve from 0.85000\n",
            "10/10 [==============================] - 2s 194ms/step - loss: 0.4972 - accuracy: 0.7461 - sensitivity_at_specificity: 0.9092 - specificity_at_sensitivity: 0.8899 - recall: 0.7609 - precision: 0.7413 - val_loss: 0.3456 - val_accuracy: 0.8438 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9422 - val_recall: 0.8408 - val_precision: 0.8381\n",
            "Epoch 42/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4974 - accuracy: 0.7479 - sensitivity_at_specificity: 0.9158 - specificity_at_sensitivity: 0.8990 - recall: 0.7208 - precision: 0.7608\n",
            "Epoch 42: val_accuracy did not improve from 0.85000\n",
            "10/10 [==============================] - 2s 185ms/step - loss: 0.4974 - accuracy: 0.7479 - sensitivity_at_specificity: 0.9158 - specificity_at_sensitivity: 0.8990 - recall: 0.7208 - precision: 0.7608 - val_loss: 0.3611 - val_accuracy: 0.8406 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9497 - val_recall: 0.8373 - val_precision: 0.8528\n",
            "Epoch 43/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4899 - accuracy: 0.7492 - sensitivity_at_specificity: 0.9204 - specificity_at_sensitivity: 0.9018 - recall: 0.7835 - precision: 0.7404\n",
            "Epoch 43: val_accuracy improved from 0.85000 to 0.85781, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 196ms/step - loss: 0.4899 - accuracy: 0.7492 - sensitivity_at_specificity: 0.9204 - specificity_at_sensitivity: 0.9018 - recall: 0.7835 - precision: 0.7404 - val_loss: 0.3372 - val_accuracy: 0.8578 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9529 - val_recall: 0.8714 - val_precision: 0.8416\n",
            "Epoch 44/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5048 - accuracy: 0.7234 - sensitivity_at_specificity: 0.8984 - specificity_at_sensitivity: 0.9023 - recall: 0.7168 - precision: 0.7168\n",
            "Epoch 44: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 197ms/step - loss: 0.5048 - accuracy: 0.7234 - sensitivity_at_specificity: 0.8984 - specificity_at_sensitivity: 0.9023 - recall: 0.7168 - precision: 0.7168 - val_loss: 0.3604 - val_accuracy: 0.8367 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9454 - val_recall: 0.8529 - val_precision: 0.8258\n",
            "Epoch 45/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4987 - accuracy: 0.7297 - sensitivity_at_specificity: 0.9014 - specificity_at_sensitivity: 0.8908 - recall: 0.7504 - precision: 0.7200\n",
            "Epoch 45: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 192ms/step - loss: 0.4987 - accuracy: 0.7297 - sensitivity_at_specificity: 0.9014 - specificity_at_sensitivity: 0.8908 - recall: 0.7504 - precision: 0.7200 - val_loss: 0.3663 - val_accuracy: 0.8406 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9416 - val_recall: 0.8638 - val_precision: 0.8279\n",
            "Epoch 46/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4930 - accuracy: 0.7395 - sensitivity_at_specificity: 0.8990 - specificity_at_sensitivity: 0.9078 - recall: 0.7488 - precision: 0.7285\n",
            "Epoch 46: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 194ms/step - loss: 0.4930 - accuracy: 0.7395 - sensitivity_at_specificity: 0.8990 - specificity_at_sensitivity: 0.9078 - recall: 0.7488 - precision: 0.7285 - val_loss: 0.3692 - val_accuracy: 0.8195 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9449 - val_recall: 0.7685 - val_precision: 0.8387\n",
            "Epoch 47/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4875 - accuracy: 0.7496 - sensitivity_at_specificity: 0.9060 - specificity_at_sensitivity: 0.9148 - recall: 0.7512 - precision: 0.7351\n",
            "Epoch 47: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 193ms/step - loss: 0.4875 - accuracy: 0.7496 - sensitivity_at_specificity: 0.9060 - specificity_at_sensitivity: 0.9148 - recall: 0.7512 - precision: 0.7351 - val_loss: 0.3732 - val_accuracy: 0.8133 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9364 - val_recall: 0.8141 - val_precision: 0.8179\n",
            "Epoch 48/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4989 - accuracy: 0.7430 - sensitivity_at_specificity: 0.9085 - specificity_at_sensitivity: 0.9056 - recall: 0.7151 - precision: 0.7462\n",
            "Epoch 48: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 193ms/step - loss: 0.4989 - accuracy: 0.7430 - sensitivity_at_specificity: 0.9085 - specificity_at_sensitivity: 0.9056 - recall: 0.7151 - precision: 0.7462 - val_loss: 0.3608 - val_accuracy: 0.8391 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9562 - val_recall: 0.8315 - val_precision: 0.8447\n",
            "Epoch 49/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4953 - accuracy: 0.7367 - sensitivity_at_specificity: 0.9099 - specificity_at_sensitivity: 0.9002 - recall: 0.7446 - precision: 0.7354\n",
            "Epoch 49: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 192ms/step - loss: 0.4953 - accuracy: 0.7367 - sensitivity_at_specificity: 0.9099 - specificity_at_sensitivity: 0.9002 - recall: 0.7446 - precision: 0.7354 - val_loss: 0.3237 - val_accuracy: 0.8570 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9643 - val_recall: 0.8740 - val_precision: 0.8435\n",
            "Epoch 50/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4943 - accuracy: 0.7434 - sensitivity_at_specificity: 0.9309 - specificity_at_sensitivity: 0.8927 - recall: 0.7657 - precision: 0.7391\n",
            "Epoch 50: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 184ms/step - loss: 0.4943 - accuracy: 0.7434 - sensitivity_at_specificity: 0.9309 - specificity_at_sensitivity: 0.8927 - recall: 0.7657 - precision: 0.7391 - val_loss: 0.3703 - val_accuracy: 0.8367 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9343 - val_recall: 0.8420 - val_precision: 0.8458\n",
            "Epoch 51/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4843 - accuracy: 0.7531 - sensitivity_at_specificity: 0.9190 - specificity_at_sensitivity: 0.9092 - recall: 0.7508 - precision: 0.7520\n",
            "Epoch 51: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 192ms/step - loss: 0.4843 - accuracy: 0.7531 - sensitivity_at_specificity: 0.9190 - specificity_at_sensitivity: 0.9092 - recall: 0.7508 - precision: 0.7520 - val_loss: 0.3523 - val_accuracy: 0.8258 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9355 - val_recall: 0.8633 - val_precision: 0.7985\n",
            "Epoch 52/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4923 - accuracy: 0.7477 - sensitivity_at_specificity: 0.9126 - specificity_at_sensitivity: 0.8973 - recall: 0.7684 - precision: 0.7444\n",
            "Epoch 52: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 192ms/step - loss: 0.4923 - accuracy: 0.7477 - sensitivity_at_specificity: 0.9126 - specificity_at_sensitivity: 0.8973 - recall: 0.7684 - precision: 0.7444 - val_loss: 0.3295 - val_accuracy: 0.8430 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9510 - val_recall: 0.8841 - val_precision: 0.8195\n",
            "Epoch 53/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4903 - accuracy: 0.7355 - sensitivity_at_specificity: 0.9233 - specificity_at_sensitivity: 0.8994 - recall: 0.7189 - precision: 0.7301\n",
            "Epoch 53: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 192ms/step - loss: 0.4903 - accuracy: 0.7355 - sensitivity_at_specificity: 0.9233 - specificity_at_sensitivity: 0.8994 - recall: 0.7189 - precision: 0.7301 - val_loss: 0.3784 - val_accuracy: 0.8219 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9437 - val_recall: 0.7675 - val_precision: 0.8707\n",
            "Epoch 54/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4982 - accuracy: 0.7352 - sensitivity_at_specificity: 0.9039 - specificity_at_sensitivity: 0.9039 - recall: 0.7415 - precision: 0.7194\n",
            "Epoch 54: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 194ms/step - loss: 0.4982 - accuracy: 0.7352 - sensitivity_at_specificity: 0.9039 - specificity_at_sensitivity: 0.9039 - recall: 0.7415 - precision: 0.7194 - val_loss: 0.3650 - val_accuracy: 0.8359 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9540 - val_recall: 0.7831 - val_precision: 0.8806\n",
            "Epoch 55/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4849 - accuracy: 0.7435 - sensitivity_at_specificity: 0.9221 - specificity_at_sensitivity: 0.9226 - recall: 0.7263 - precision: 0.7441\n",
            "Epoch 55: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 190ms/step - loss: 0.4822 - accuracy: 0.7442 - sensitivity_at_specificity: 0.9283 - specificity_at_sensitivity: 0.9223 - recall: 0.7260 - precision: 0.7474 - val_loss: 0.3572 - val_accuracy: 0.8203 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9325 - val_recall: 0.7993 - val_precision: 0.8208\n",
            "Epoch 56/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4826 - accuracy: 0.7594 - sensitivity_at_specificity: 0.9348 - specificity_at_sensitivity: 0.9032 - recall: 0.7894 - precision: 0.7551\n",
            "Epoch 56: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 194ms/step - loss: 0.4826 - accuracy: 0.7594 - sensitivity_at_specificity: 0.9348 - specificity_at_sensitivity: 0.9032 - recall: 0.7894 - precision: 0.7551 - val_loss: 0.3451 - val_accuracy: 0.8305 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9592 - val_recall: 0.8212 - val_precision: 0.8381\n",
            "Epoch 57/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4815 - accuracy: 0.7469 - sensitivity_at_specificity: 0.9256 - specificity_at_sensitivity: 0.9098 - recall: 0.7451 - precision: 0.7589\n",
            "Epoch 57: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 195ms/step - loss: 0.4815 - accuracy: 0.7469 - sensitivity_at_specificity: 0.9256 - specificity_at_sensitivity: 0.9098 - recall: 0.7451 - precision: 0.7589 - val_loss: 0.3705 - val_accuracy: 0.8133 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9525 - val_recall: 0.7484 - val_precision: 0.8530\n",
            "Epoch 58/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4800 - accuracy: 0.7531 - sensitivity_at_specificity: 0.9181 - specificity_at_sensitivity: 0.9194 - recall: 0.7576 - precision: 0.7445\n",
            "Epoch 58: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 189ms/step - loss: 0.4800 - accuracy: 0.7531 - sensitivity_at_specificity: 0.9181 - specificity_at_sensitivity: 0.9194 - recall: 0.7576 - precision: 0.7445 - val_loss: 0.3371 - val_accuracy: 0.8461 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9583 - val_recall: 0.8402 - val_precision: 0.8469\n",
            "Epoch 59/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4797 - accuracy: 0.7461 - sensitivity_at_specificity: 0.9273 - specificity_at_sensitivity: 0.9151 - recall: 0.7524 - precision: 0.7348\n",
            "Epoch 59: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 193ms/step - loss: 0.4797 - accuracy: 0.7461 - sensitivity_at_specificity: 0.9273 - specificity_at_sensitivity: 0.9151 - recall: 0.7524 - precision: 0.7348 - val_loss: 0.3754 - val_accuracy: 0.8109 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9441 - val_recall: 0.7421 - val_precision: 0.8582\n",
            "Epoch 60/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4692 - accuracy: 0.7539 - sensitivity_at_specificity: 0.9353 - specificity_at_sensitivity: 0.9134 - recall: 0.7640 - precision: 0.7452\n",
            "Epoch 60: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 189ms/step - loss: 0.4692 - accuracy: 0.7539 - sensitivity_at_specificity: 0.9353 - specificity_at_sensitivity: 0.9134 - recall: 0.7640 - precision: 0.7452 - val_loss: 0.3806 - val_accuracy: 0.8148 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9412 - val_recall: 0.7429 - val_precision: 0.8642\n",
            "Epoch 61/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4727 - accuracy: 0.7609 - sensitivity_at_specificity: 0.9167 - specificity_at_sensitivity: 0.9234 - recall: 0.7689 - precision: 0.7678\n",
            "Epoch 61: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 189ms/step - loss: 0.4727 - accuracy: 0.7609 - sensitivity_at_specificity: 0.9167 - specificity_at_sensitivity: 0.9234 - recall: 0.7689 - precision: 0.7678 - val_loss: 0.3731 - val_accuracy: 0.8195 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9495 - val_recall: 0.7412 - val_precision: 0.8705\n",
            "Epoch 62/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4717 - accuracy: 0.7496 - sensitivity_at_specificity: 0.9416 - specificity_at_sensitivity: 0.9098 - recall: 0.7704 - precision: 0.7410\n",
            "Epoch 62: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 190ms/step - loss: 0.4717 - accuracy: 0.7496 - sensitivity_at_specificity: 0.9416 - specificity_at_sensitivity: 0.9098 - recall: 0.7704 - precision: 0.7410 - val_loss: 0.3566 - val_accuracy: 0.8328 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9477 - val_recall: 0.7905 - val_precision: 0.8586\n",
            "Epoch 63/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4752 - accuracy: 0.7504 - sensitivity_at_specificity: 0.9271 - specificity_at_sensitivity: 0.9124 - recall: 0.7641 - precision: 0.7488\n",
            "Epoch 63: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 184ms/step - loss: 0.4752 - accuracy: 0.7504 - sensitivity_at_specificity: 0.9271 - specificity_at_sensitivity: 0.9124 - recall: 0.7641 - precision: 0.7488 - val_loss: 0.3621 - val_accuracy: 0.8352 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9604 - val_recall: 0.7858 - val_precision: 0.8763\n",
            "Epoch 64/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4857 - accuracy: 0.7469 - sensitivity_at_specificity: 0.9295 - specificity_at_sensitivity: 0.9005 - recall: 0.7342 - precision: 0.7390\n",
            "Epoch 64: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 191ms/step - loss: 0.4857 - accuracy: 0.7469 - sensitivity_at_specificity: 0.9295 - specificity_at_sensitivity: 0.9005 - recall: 0.7342 - precision: 0.7390 - val_loss: 0.3843 - val_accuracy: 0.8125 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9457 - val_recall: 0.7280 - val_precision: 0.8736\n",
            "Epoch 65/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4622 - accuracy: 0.7616 - sensitivity_at_specificity: 0.9419 - specificity_at_sensitivity: 0.9233 - recall: 0.7913 - precision: 0.7519\n",
            "Epoch 65: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 183ms/step - loss: 0.4622 - accuracy: 0.7616 - sensitivity_at_specificity: 0.9419 - specificity_at_sensitivity: 0.9233 - recall: 0.7913 - precision: 0.7519 - val_loss: 0.3680 - val_accuracy: 0.8125 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9473 - val_recall: 0.7370 - val_precision: 0.8651\n",
            "Epoch 66/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4698 - accuracy: 0.7590 - sensitivity_at_specificity: 0.9338 - specificity_at_sensitivity: 0.9190 - recall: 0.7408 - precision: 0.7747\n",
            "Epoch 66: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 190ms/step - loss: 0.4698 - accuracy: 0.7590 - sensitivity_at_specificity: 0.9338 - specificity_at_sensitivity: 0.9190 - recall: 0.7408 - precision: 0.7747 - val_loss: 0.3540 - val_accuracy: 0.8273 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9375 - val_recall: 0.8000 - val_precision: 0.8463\n",
            "Epoch 67/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4547 - accuracy: 0.7656 - sensitivity_at_specificity: 0.9510 - specificity_at_sensitivity: 0.9315 - recall: 0.8138 - precision: 0.7484\n",
            "Epoch 67: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 193ms/step - loss: 0.4547 - accuracy: 0.7656 - sensitivity_at_specificity: 0.9510 - specificity_at_sensitivity: 0.9315 - recall: 0.8138 - precision: 0.7484 - val_loss: 0.3521 - val_accuracy: 0.8258 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9448 - val_recall: 0.7988 - val_precision: 0.8473\n",
            "Epoch 68/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4559 - accuracy: 0.7625 - sensitivity_at_specificity: 0.9474 - specificity_at_sensitivity: 0.9219 - recall: 0.7572 - precision: 0.7690\n",
            "Epoch 68: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 194ms/step - loss: 0.4559 - accuracy: 0.7625 - sensitivity_at_specificity: 0.9474 - specificity_at_sensitivity: 0.9219 - recall: 0.7572 - precision: 0.7690 - val_loss: 0.3332 - val_accuracy: 0.8484 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9484 - val_recall: 0.8551 - val_precision: 0.8362\n",
            "Epoch 69/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4607 - accuracy: 0.7660 - sensitivity_at_specificity: 0.9421 - specificity_at_sensitivity: 0.9238 - recall: 0.7994 - precision: 0.7445\n",
            "Epoch 69: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 195ms/step - loss: 0.4607 - accuracy: 0.7660 - sensitivity_at_specificity: 0.9421 - specificity_at_sensitivity: 0.9238 - recall: 0.7994 - precision: 0.7445 - val_loss: 0.3562 - val_accuracy: 0.8203 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9451 - val_recall: 0.7882 - val_precision: 0.8433\n",
            "Epoch 70/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4802 - accuracy: 0.7441 - sensitivity_at_specificity: 0.9237 - specificity_at_sensitivity: 0.9177 - recall: 0.7487 - precision: 0.7469\n",
            "Epoch 70: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 199ms/step - loss: 0.4802 - accuracy: 0.7441 - sensitivity_at_specificity: 0.9237 - specificity_at_sensitivity: 0.9177 - recall: 0.7487 - precision: 0.7469 - val_loss: 0.3701 - val_accuracy: 0.8195 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9358 - val_recall: 0.7925 - val_precision: 0.8383\n",
            "Epoch 71/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4794 - accuracy: 0.7543 - sensitivity_at_specificity: 0.9350 - specificity_at_sensitivity: 0.9115 - recall: 0.7748 - precision: 0.7390\n",
            "Epoch 71: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 187ms/step - loss: 0.4794 - accuracy: 0.7543 - sensitivity_at_specificity: 0.9350 - specificity_at_sensitivity: 0.9115 - recall: 0.7748 - precision: 0.7390 - val_loss: 0.3398 - val_accuracy: 0.8422 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9580 - val_recall: 0.8367 - val_precision: 0.8447\n",
            "Epoch 72/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4513 - accuracy: 0.7715 - sensitivity_at_specificity: 0.9428 - specificity_at_sensitivity: 0.9335 - recall: 0.7620 - precision: 0.7854\n",
            "Epoch 72: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 196ms/step - loss: 0.4513 - accuracy: 0.7715 - sensitivity_at_specificity: 0.9428 - specificity_at_sensitivity: 0.9335 - recall: 0.7620 - precision: 0.7854 - val_loss: 0.3508 - val_accuracy: 0.8250 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9542 - val_recall: 0.8096 - val_precision: 0.8282\n",
            "Epoch 73/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4591 - accuracy: 0.7629 - sensitivity_at_specificity: 0.9325 - specificity_at_sensitivity: 0.9323 - recall: 0.7969 - precision: 0.7449\n",
            "Epoch 73: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 195ms/step - loss: 0.4591 - accuracy: 0.7629 - sensitivity_at_specificity: 0.9325 - specificity_at_sensitivity: 0.9323 - recall: 0.7969 - precision: 0.7449 - val_loss: 0.3924 - val_accuracy: 0.7992 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9386 - val_recall: 0.7186 - val_precision: 0.8700\n",
            "Epoch 74/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4666 - accuracy: 0.7743 - sensitivity_at_specificity: 0.9333 - specificity_at_sensitivity: 0.9124 - recall: 0.8008 - precision: 0.7697\n",
            "Epoch 74: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 191ms/step - loss: 0.4643 - accuracy: 0.7757 - sensitivity_at_specificity: 0.9363 - specificity_at_sensitivity: 0.9144 - recall: 0.7992 - precision: 0.7730 - val_loss: 0.3876 - val_accuracy: 0.8055 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9348 - val_recall: 0.7435 - val_precision: 0.8551\n",
            "Epoch 75/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4348 - accuracy: 0.7801 - sensitivity_at_specificity: 0.9622 - specificity_at_sensitivity: 0.9450 - recall: 0.7677 - precision: 0.7844\n",
            "Epoch 75: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 199ms/step - loss: 0.4348 - accuracy: 0.7801 - sensitivity_at_specificity: 0.9622 - specificity_at_sensitivity: 0.9450 - recall: 0.7677 - precision: 0.7844 - val_loss: 0.3462 - val_accuracy: 0.8328 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9446 - val_recall: 0.8056 - val_precision: 0.8384\n",
            "Epoch 76/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4522 - accuracy: 0.7727 - sensitivity_at_specificity: 0.9460 - specificity_at_sensitivity: 0.9216 - recall: 0.7840 - precision: 0.7610\n",
            "Epoch 76: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 195ms/step - loss: 0.4522 - accuracy: 0.7727 - sensitivity_at_specificity: 0.9460 - specificity_at_sensitivity: 0.9216 - recall: 0.7840 - precision: 0.7610 - val_loss: 0.3726 - val_accuracy: 0.8211 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9440 - val_recall: 0.7630 - val_precision: 0.8617\n",
            "Epoch 77/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4354 - accuracy: 0.7805 - sensitivity_at_specificity: 0.9519 - specificity_at_sensitivity: 0.9435 - recall: 0.7689 - precision: 0.7838\n",
            "Epoch 77: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 194ms/step - loss: 0.4354 - accuracy: 0.7805 - sensitivity_at_specificity: 0.9519 - specificity_at_sensitivity: 0.9435 - recall: 0.7689 - precision: 0.7838 - val_loss: 0.3797 - val_accuracy: 0.7922 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9519 - val_recall: 0.7118 - val_precision: 0.8449\n",
            "Epoch 78/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4467 - accuracy: 0.7703 - sensitivity_at_specificity: 0.9499 - specificity_at_sensitivity: 0.9322 - recall: 0.7666 - precision: 0.7715\n",
            "Epoch 78: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 193ms/step - loss: 0.4467 - accuracy: 0.7703 - sensitivity_at_specificity: 0.9499 - specificity_at_sensitivity: 0.9322 - recall: 0.7666 - precision: 0.7715 - val_loss: 0.3521 - val_accuracy: 0.8227 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9340 - val_recall: 0.7818 - val_precision: 0.8451\n",
            "Epoch 79/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4515 - accuracy: 0.7656 - sensitivity_at_specificity: 0.9448 - specificity_at_sensitivity: 0.9402 - recall: 0.7853 - precision: 0.7668\n",
            "Epoch 79: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 198ms/step - loss: 0.4515 - accuracy: 0.7656 - sensitivity_at_specificity: 0.9448 - specificity_at_sensitivity: 0.9402 - recall: 0.7853 - precision: 0.7668 - val_loss: 0.3351 - val_accuracy: 0.8461 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9468 - val_recall: 0.8606 - val_precision: 0.8440\n",
            "Epoch 80/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4423 - accuracy: 0.7750 - sensitivity_at_specificity: 0.9494 - specificity_at_sensitivity: 0.9393 - recall: 0.7684 - precision: 0.7634\n",
            "Epoch 80: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 195ms/step - loss: 0.4423 - accuracy: 0.7750 - sensitivity_at_specificity: 0.9494 - specificity_at_sensitivity: 0.9393 - recall: 0.7684 - precision: 0.7634 - val_loss: 0.3973 - val_accuracy: 0.7828 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9319 - val_recall: 0.6814 - val_precision: 0.8504\n",
            "Epoch 81/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4310 - accuracy: 0.7781 - sensitivity_at_specificity: 0.9620 - specificity_at_sensitivity: 0.9483 - recall: 0.7538 - precision: 0.7874\n",
            "Epoch 81: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 197ms/step - loss: 0.4310 - accuracy: 0.7781 - sensitivity_at_specificity: 0.9620 - specificity_at_sensitivity: 0.9483 - recall: 0.7538 - precision: 0.7874 - val_loss: 0.3514 - val_accuracy: 0.8094 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9589 - val_recall: 0.7303 - val_precision: 0.8569\n",
            "Epoch 82/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4300 - accuracy: 0.7840 - sensitivity_at_specificity: 0.9494 - specificity_at_sensitivity: 0.9443 - recall: 0.7745 - precision: 0.7959\n",
            "Epoch 82: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 194ms/step - loss: 0.4300 - accuracy: 0.7840 - sensitivity_at_specificity: 0.9494 - specificity_at_sensitivity: 0.9443 - recall: 0.7745 - precision: 0.7959 - val_loss: 0.3383 - val_accuracy: 0.8359 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9509 - val_recall: 0.8043 - val_precision: 0.8431\n",
            "Epoch 83/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4130 - accuracy: 0.7969 - sensitivity_at_specificity: 0.9638 - specificity_at_sensitivity: 0.9548 - recall: 0.8216 - precision: 0.7776\n",
            "Epoch 83: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 188ms/step - loss: 0.4174 - accuracy: 0.7949 - sensitivity_at_specificity: 0.9604 - specificity_at_sensitivity: 0.9525 - recall: 0.8170 - precision: 0.7777 - val_loss: 0.3405 - val_accuracy: 0.8266 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9596 - val_recall: 0.7975 - val_precision: 0.8453\n",
            "Epoch 84/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4258 - accuracy: 0.7879 - sensitivity_at_specificity: 0.9617 - specificity_at_sensitivity: 0.9449 - recall: 0.7919 - precision: 0.7788\n",
            "Epoch 84: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 193ms/step - loss: 0.4258 - accuracy: 0.7879 - sensitivity_at_specificity: 0.9617 - specificity_at_sensitivity: 0.9449 - recall: 0.7919 - precision: 0.7788 - val_loss: 0.3399 - val_accuracy: 0.8266 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9522 - val_recall: 0.8193 - val_precision: 0.8372\n",
            "Epoch 85/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4215 - accuracy: 0.7879 - sensitivity_at_specificity: 0.9463 - specificity_at_sensitivity: 0.9553 - recall: 0.7866 - precision: 0.7897\n",
            "Epoch 85: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 199ms/step - loss: 0.4215 - accuracy: 0.7879 - sensitivity_at_specificity: 0.9463 - specificity_at_sensitivity: 0.9553 - recall: 0.7866 - precision: 0.7897 - val_loss: 0.3790 - val_accuracy: 0.8117 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9335 - val_recall: 0.7855 - val_precision: 0.8331\n",
            "Epoch 86/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4339 - accuracy: 0.7699 - sensitivity_at_specificity: 0.9470 - specificity_at_sensitivity: 0.9475 - recall: 0.7857 - precision: 0.7625\n",
            "Epoch 86: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 192ms/step - loss: 0.4339 - accuracy: 0.7699 - sensitivity_at_specificity: 0.9470 - specificity_at_sensitivity: 0.9475 - recall: 0.7857 - precision: 0.7625 - val_loss: 0.3691 - val_accuracy: 0.8234 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9275 - val_recall: 0.8376 - val_precision: 0.8227\n",
            "Epoch 87/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4136 - accuracy: 0.7918 - sensitivity_at_specificity: 0.9596 - specificity_at_sensitivity: 0.9624 - recall: 0.7979 - precision: 0.7960\n",
            "Epoch 87: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 194ms/step - loss: 0.4136 - accuracy: 0.7918 - sensitivity_at_specificity: 0.9596 - specificity_at_sensitivity: 0.9624 - recall: 0.7979 - precision: 0.7960 - val_loss: 0.3488 - val_accuracy: 0.8281 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9363 - val_recall: 0.8645 - val_precision: 0.7912\n",
            "Epoch 88/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4203 - accuracy: 0.7871 - sensitivity_at_specificity: 0.9609 - specificity_at_sensitivity: 0.9625 - recall: 0.8084 - precision: 0.7815\n",
            "Epoch 88: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 194ms/step - loss: 0.4203 - accuracy: 0.7871 - sensitivity_at_specificity: 0.9609 - specificity_at_sensitivity: 0.9625 - recall: 0.8084 - precision: 0.7815 - val_loss: 0.3718 - val_accuracy: 0.8141 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9323 - val_recall: 0.7712 - val_precision: 0.8540\n",
            "Epoch 89/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4173 - accuracy: 0.7863 - sensitivity_at_specificity: 0.9573 - specificity_at_sensitivity: 0.9576 - recall: 0.7601 - precision: 0.7839\n",
            "Epoch 89: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 194ms/step - loss: 0.4173 - accuracy: 0.7863 - sensitivity_at_specificity: 0.9573 - specificity_at_sensitivity: 0.9576 - recall: 0.7601 - precision: 0.7839 - val_loss: 0.3766 - val_accuracy: 0.8094 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9220 - val_recall: 0.7928 - val_precision: 0.8060\n",
            "Epoch 90/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4064 - accuracy: 0.7949 - sensitivity_at_specificity: 0.9663 - specificity_at_sensitivity: 0.9641 - recall: 0.7886 - precision: 0.7979\n",
            "Epoch 90: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 194ms/step - loss: 0.4064 - accuracy: 0.7949 - sensitivity_at_specificity: 0.9663 - specificity_at_sensitivity: 0.9641 - recall: 0.7886 - precision: 0.7979 - val_loss: 0.3787 - val_accuracy: 0.8148 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9409 - val_recall: 0.8129 - val_precision: 0.8064\n",
            "Epoch 91/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4084 - accuracy: 0.8035 - sensitivity_at_specificity: 0.9580 - specificity_at_sensitivity: 0.9639 - recall: 0.8000 - precision: 0.8069\n",
            "Epoch 91: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 194ms/step - loss: 0.4084 - accuracy: 0.8035 - sensitivity_at_specificity: 0.9580 - specificity_at_sensitivity: 0.9639 - recall: 0.8000 - precision: 0.8069 - val_loss: 0.3752 - val_accuracy: 0.8266 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9321 - val_recall: 0.8165 - val_precision: 0.8296\n",
            "Epoch 92/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4099 - accuracy: 0.7988 - sensitivity_at_specificity: 0.9578 - specificity_at_sensitivity: 0.9656 - recall: 0.8086 - precision: 0.7931\n",
            "Epoch 92: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 193ms/step - loss: 0.4099 - accuracy: 0.7988 - sensitivity_at_specificity: 0.9578 - specificity_at_sensitivity: 0.9656 - recall: 0.8086 - precision: 0.7931 - val_loss: 0.3512 - val_accuracy: 0.8281 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9410 - val_recall: 0.7948 - val_precision: 0.8410\n",
            "Epoch 93/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4175 - accuracy: 0.7941 - sensitivity_at_specificity: 0.9541 - specificity_at_sensitivity: 0.9591 - recall: 0.7840 - precision: 0.7898\n",
            "Epoch 93: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 192ms/step - loss: 0.4175 - accuracy: 0.7941 - sensitivity_at_specificity: 0.9541 - specificity_at_sensitivity: 0.9591 - recall: 0.7840 - precision: 0.7898 - val_loss: 0.3423 - val_accuracy: 0.8359 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9446 - val_recall: 0.8364 - val_precision: 0.8390\n",
            "Epoch 94/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4170 - accuracy: 0.7973 - sensitivity_at_specificity: 0.9500 - specificity_at_sensitivity: 0.9554 - recall: 0.7984 - precision: 0.8010\n",
            "Epoch 94: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 187ms/step - loss: 0.4170 - accuracy: 0.7973 - sensitivity_at_specificity: 0.9500 - specificity_at_sensitivity: 0.9554 - recall: 0.7984 - precision: 0.8010 - val_loss: 0.3674 - val_accuracy: 0.8219 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9358 - val_recall: 0.8189 - val_precision: 0.8315\n",
            "Epoch 95/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4158 - accuracy: 0.7980 - sensitivity_at_specificity: 0.9515 - specificity_at_sensitivity: 0.9532 - recall: 0.8129 - precision: 0.7940\n",
            "Epoch 95: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 193ms/step - loss: 0.4158 - accuracy: 0.7980 - sensitivity_at_specificity: 0.9515 - specificity_at_sensitivity: 0.9532 - recall: 0.8129 - precision: 0.7940 - val_loss: 0.3513 - val_accuracy: 0.8320 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9405 - val_recall: 0.8419 - val_precision: 0.8331\n",
            "Epoch 96/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4041 - accuracy: 0.7941 - sensitivity_at_specificity: 0.9605 - specificity_at_sensitivity: 0.9637 - recall: 0.7879 - precision: 0.8009\n",
            "Epoch 96: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 192ms/step - loss: 0.4041 - accuracy: 0.7941 - sensitivity_at_specificity: 0.9605 - specificity_at_sensitivity: 0.9637 - recall: 0.7879 - precision: 0.8009 - val_loss: 0.3604 - val_accuracy: 0.8320 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9276 - val_recall: 0.8732 - val_precision: 0.8032\n",
            "Epoch 97/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4074 - accuracy: 0.7949 - sensitivity_at_specificity: 0.9583 - specificity_at_sensitivity: 0.9684 - recall: 0.8063 - precision: 0.7923\n",
            "Epoch 97: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 198ms/step - loss: 0.4074 - accuracy: 0.7949 - sensitivity_at_specificity: 0.9583 - specificity_at_sensitivity: 0.9684 - recall: 0.8063 - precision: 0.7923 - val_loss: 0.3522 - val_accuracy: 0.8438 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9260 - val_recall: 0.8977 - val_precision: 0.8121\n",
            "Epoch 98/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4087 - accuracy: 0.8023 - sensitivity_at_specificity: 0.9595 - specificity_at_sensitivity: 0.9592 - recall: 0.8189 - precision: 0.7994\n",
            "Epoch 98: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 192ms/step - loss: 0.4087 - accuracy: 0.8023 - sensitivity_at_specificity: 0.9595 - specificity_at_sensitivity: 0.9592 - recall: 0.8189 - precision: 0.7994 - val_loss: 0.3352 - val_accuracy: 0.8461 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9489 - val_recall: 0.8565 - val_precision: 0.8367\n",
            "Epoch 99/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3858 - accuracy: 0.8027 - sensitivity_at_specificity: 0.9772 - specificity_at_sensitivity: 0.9783 - recall: 0.7932 - precision: 0.8066\n",
            "Epoch 99: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 192ms/step - loss: 0.3858 - accuracy: 0.8027 - sensitivity_at_specificity: 0.9772 - specificity_at_sensitivity: 0.9783 - recall: 0.7932 - precision: 0.8066 - val_loss: 0.3580 - val_accuracy: 0.8242 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9306 - val_recall: 0.8470 - val_precision: 0.8184\n",
            "Epoch 100/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4019 - accuracy: 0.7982 - sensitivity_at_specificity: 0.9637 - specificity_at_sensitivity: 0.9607 - recall: 0.7929 - precision: 0.8035\n",
            "Epoch 100: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 190ms/step - loss: 0.4019 - accuracy: 0.7982 - sensitivity_at_specificity: 0.9637 - specificity_at_sensitivity: 0.9607 - recall: 0.7929 - precision: 0.8035 - val_loss: 0.3755 - val_accuracy: 0.8000 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9288 - val_recall: 0.7747 - val_precision: 0.8203\n",
            "Epoch 101/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4092 - accuracy: 0.7965 - sensitivity_at_specificity: 0.9554 - specificity_at_sensitivity: 0.9595 - recall: 0.8051 - precision: 0.8021\n",
            "Epoch 101: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 193ms/step - loss: 0.4092 - accuracy: 0.7965 - sensitivity_at_specificity: 0.9554 - specificity_at_sensitivity: 0.9595 - recall: 0.8051 - precision: 0.8021 - val_loss: 0.3732 - val_accuracy: 0.8180 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9323 - val_recall: 0.8186 - val_precision: 0.8199\n",
            "Epoch 102/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3961 - accuracy: 0.8055 - sensitivity_at_specificity: 0.9661 - specificity_at_sensitivity: 0.9714 - recall: 0.8052 - precision: 0.8027\n",
            "Epoch 102: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 193ms/step - loss: 0.3961 - accuracy: 0.8055 - sensitivity_at_specificity: 0.9661 - specificity_at_sensitivity: 0.9714 - recall: 0.8052 - precision: 0.8027 - val_loss: 0.3734 - val_accuracy: 0.8117 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9241 - val_recall: 0.7902 - val_precision: 0.8227\n",
            "Epoch 103/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3990 - accuracy: 0.8098 - sensitivity_at_specificity: 0.9578 - specificity_at_sensitivity: 0.9624 - recall: 0.7789 - precision: 0.8248\n",
            "Epoch 103: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 184ms/step - loss: 0.3990 - accuracy: 0.8098 - sensitivity_at_specificity: 0.9578 - specificity_at_sensitivity: 0.9624 - recall: 0.7789 - precision: 0.8248 - val_loss: 0.3792 - val_accuracy: 0.8289 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9306 - val_recall: 0.9066 - val_precision: 0.7817\n",
            "Epoch 104/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3937 - accuracy: 0.8043 - sensitivity_at_specificity: 0.9536 - specificity_at_sensitivity: 0.9787 - recall: 0.8161 - precision: 0.8006\n",
            "Epoch 104: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 191ms/step - loss: 0.3937 - accuracy: 0.8043 - sensitivity_at_specificity: 0.9536 - specificity_at_sensitivity: 0.9787 - recall: 0.8161 - precision: 0.8006 - val_loss: 0.3769 - val_accuracy: 0.8266 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9397 - val_recall: 0.8266 - val_precision: 0.8160\n",
            "Epoch 105/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3908 - accuracy: 0.8000 - sensitivity_at_specificity: 0.9638 - specificity_at_sensitivity: 0.9752 - recall: 0.8017 - precision: 0.7967\n",
            "Epoch 105: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 196ms/step - loss: 0.3908 - accuracy: 0.8000 - sensitivity_at_specificity: 0.9638 - specificity_at_sensitivity: 0.9752 - recall: 0.8017 - precision: 0.7967 - val_loss: 0.3848 - val_accuracy: 0.8000 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9314 - val_recall: 0.7570 - val_precision: 0.8102\n",
            "Epoch 106/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4127 - accuracy: 0.7922 - sensitivity_at_specificity: 0.9507 - specificity_at_sensitivity: 0.9672 - recall: 0.7723 - precision: 0.8037\n",
            "Epoch 106: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 195ms/step - loss: 0.4127 - accuracy: 0.7922 - sensitivity_at_specificity: 0.9507 - specificity_at_sensitivity: 0.9672 - recall: 0.7723 - precision: 0.8037 - val_loss: 0.3577 - val_accuracy: 0.8078 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9534 - val_recall: 0.7406 - val_precision: 0.8533\n",
            "Epoch 107/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3988 - accuracy: 0.8086 - sensitivity_at_specificity: 0.9663 - specificity_at_sensitivity: 0.9627 - recall: 0.7888 - precision: 0.8122\n",
            "Epoch 107: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 196ms/step - loss: 0.3988 - accuracy: 0.8086 - sensitivity_at_specificity: 0.9663 - specificity_at_sensitivity: 0.9627 - recall: 0.7888 - precision: 0.8122 - val_loss: 0.3964 - val_accuracy: 0.7953 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9255 - val_recall: 0.7350 - val_precision: 0.8413\n",
            "Epoch 108/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3998 - accuracy: 0.8023 - sensitivity_at_specificity: 0.9656 - specificity_at_sensitivity: 0.9648 - recall: 0.7961 - precision: 0.8062\n",
            "Epoch 108: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 195ms/step - loss: 0.3998 - accuracy: 0.8023 - sensitivity_at_specificity: 0.9656 - specificity_at_sensitivity: 0.9648 - recall: 0.7961 - precision: 0.8062 - val_loss: 0.3282 - val_accuracy: 0.8344 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9477 - val_recall: 0.8314 - val_precision: 0.8233\n",
            "Epoch 109/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3812 - accuracy: 0.8168 - sensitivity_at_specificity: 0.9652 - specificity_at_sensitivity: 0.9792 - recall: 0.7880 - precision: 0.8321\n",
            "Epoch 109: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 192ms/step - loss: 0.3812 - accuracy: 0.8168 - sensitivity_at_specificity: 0.9652 - specificity_at_sensitivity: 0.9792 - recall: 0.7880 - precision: 0.8321 - val_loss: 0.3684 - val_accuracy: 0.8297 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9301 - val_recall: 0.8255 - val_precision: 0.8307\n",
            "Epoch 110/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3775 - accuracy: 0.8086 - sensitivity_at_specificity: 0.9706 - specificity_at_sensitivity: 0.9813 - recall: 0.8306 - precision: 0.8063\n",
            "Epoch 110: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 192ms/step - loss: 0.3775 - accuracy: 0.8086 - sensitivity_at_specificity: 0.9706 - specificity_at_sensitivity: 0.9813 - recall: 0.8306 - precision: 0.8063 - val_loss: 0.3873 - val_accuracy: 0.8117 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9191 - val_recall: 0.8148 - val_precision: 0.8084\n",
            "Epoch 111/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3757 - accuracy: 0.8125 - sensitivity_at_specificity: 0.9713 - specificity_at_sensitivity: 0.9811 - recall: 0.8064 - precision: 0.8190\n",
            "Epoch 111: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 193ms/step - loss: 0.3757 - accuracy: 0.8125 - sensitivity_at_specificity: 0.9713 - specificity_at_sensitivity: 0.9811 - recall: 0.8064 - precision: 0.8190 - val_loss: 0.3619 - val_accuracy: 0.8430 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9296 - val_recall: 0.8534 - val_precision: 0.8364\n",
            "Epoch 112/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3563 - accuracy: 0.8234 - sensitivity_at_specificity: 0.9716 - specificity_at_sensitivity: 0.9899 - recall: 0.8085 - precision: 0.8308\n",
            "Epoch 112: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 197ms/step - loss: 0.3563 - accuracy: 0.8234 - sensitivity_at_specificity: 0.9716 - specificity_at_sensitivity: 0.9899 - recall: 0.8085 - precision: 0.8308 - val_loss: 0.4355 - val_accuracy: 0.8039 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8983 - val_recall: 0.8352 - val_precision: 0.7819\n",
            "Epoch 113/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3566 - accuracy: 0.8301 - sensitivity_at_specificity: 0.9758 - specificity_at_sensitivity: 0.9875 - recall: 0.8125 - precision: 0.8421\n",
            "Epoch 113: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 197ms/step - loss: 0.3566 - accuracy: 0.8301 - sensitivity_at_specificity: 0.9758 - specificity_at_sensitivity: 0.9875 - recall: 0.8125 - precision: 0.8421 - val_loss: 0.3954 - val_accuracy: 0.8305 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9226 - val_recall: 0.8696 - val_precision: 0.7988\n",
            "Epoch 114/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3733 - accuracy: 0.8117 - sensitivity_at_specificity: 0.9616 - specificity_at_sensitivity: 0.9885 - recall: 0.7826 - precision: 0.8234\n",
            "Epoch 114: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 198ms/step - loss: 0.3733 - accuracy: 0.8117 - sensitivity_at_specificity: 0.9616 - specificity_at_sensitivity: 0.9885 - recall: 0.7826 - precision: 0.8234 - val_loss: 0.3731 - val_accuracy: 0.8336 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9328 - val_recall: 0.8516 - val_precision: 0.8220\n",
            "Epoch 115/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3520 - accuracy: 0.8340 - sensitivity_at_specificity: 0.9621 - specificity_at_sensitivity: 0.9907 - recall: 0.8096 - precision: 0.8478\n",
            "Epoch 115: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 195ms/step - loss: 0.3520 - accuracy: 0.8340 - sensitivity_at_specificity: 0.9621 - specificity_at_sensitivity: 0.9907 - recall: 0.8096 - precision: 0.8478 - val_loss: 0.3528 - val_accuracy: 0.8313 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9449 - val_recall: 0.8292 - val_precision: 0.8185\n",
            "Epoch 116/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3417 - accuracy: 0.8324 - sensitivity_at_specificity: 0.9742 - specificity_at_sensitivity: 0.9930 - recall: 0.8100 - precision: 0.8478\n",
            "Epoch 116: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 199ms/step - loss: 0.3417 - accuracy: 0.8324 - sensitivity_at_specificity: 0.9742 - specificity_at_sensitivity: 0.9930 - recall: 0.8100 - precision: 0.8478 - val_loss: 0.3851 - val_accuracy: 0.8156 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9304 - val_recall: 0.8086 - val_precision: 0.8239\n",
            "Epoch 117/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3434 - accuracy: 0.8414 - sensitivity_at_specificity: 0.9690 - specificity_at_sensitivity: 0.9895 - recall: 0.8166 - precision: 0.8470\n",
            "Epoch 117: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 196ms/step - loss: 0.3434 - accuracy: 0.8414 - sensitivity_at_specificity: 0.9690 - specificity_at_sensitivity: 0.9895 - recall: 0.8166 - precision: 0.8470 - val_loss: 0.4296 - val_accuracy: 0.8008 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9205 - val_recall: 0.8012 - val_precision: 0.8122\n",
            "Epoch 118/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3391 - accuracy: 0.8410 - sensitivity_at_specificity: 0.9693 - specificity_at_sensitivity: 0.9927 - recall: 0.8441 - precision: 0.8498\n",
            "Epoch 118: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 192ms/step - loss: 0.3391 - accuracy: 0.8410 - sensitivity_at_specificity: 0.9693 - specificity_at_sensitivity: 0.9927 - recall: 0.8441 - precision: 0.8498 - val_loss: 0.4022 - val_accuracy: 0.8070 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9218 - val_recall: 0.8159 - val_precision: 0.8021\n",
            "Epoch 119/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3503 - accuracy: 0.8355 - sensitivity_at_specificity: 0.9680 - specificity_at_sensitivity: 0.9906 - recall: 0.7937 - precision: 0.8662\n",
            "Epoch 119: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 195ms/step - loss: 0.3503 - accuracy: 0.8355 - sensitivity_at_specificity: 0.9680 - specificity_at_sensitivity: 0.9906 - recall: 0.7937 - precision: 0.8662 - val_loss: 0.3706 - val_accuracy: 0.8156 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9298 - val_recall: 0.7746 - val_precision: 0.8433\n",
            "Epoch 120/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3663 - accuracy: 0.8215 - sensitivity_at_specificity: 0.9715 - specificity_at_sensitivity: 0.9846 - recall: 0.7987 - precision: 0.8324\n",
            "Epoch 120: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 197ms/step - loss: 0.3663 - accuracy: 0.8215 - sensitivity_at_specificity: 0.9715 - specificity_at_sensitivity: 0.9846 - recall: 0.7987 - precision: 0.8324 - val_loss: 0.3916 - val_accuracy: 0.8055 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9290 - val_recall: 0.7786 - val_precision: 0.8259\n",
            "Epoch 121/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3456 - accuracy: 0.8309 - sensitivity_at_specificity: 0.9706 - specificity_at_sensitivity: 0.9927 - recall: 0.8151 - precision: 0.8517\n",
            "Epoch 121: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 192ms/step - loss: 0.3456 - accuracy: 0.8309 - sensitivity_at_specificity: 0.9706 - specificity_at_sensitivity: 0.9927 - recall: 0.8151 - precision: 0.8517 - val_loss: 0.3823 - val_accuracy: 0.8234 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9354 - val_recall: 0.8048 - val_precision: 0.8311\n",
            "Epoch 122/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3331 - accuracy: 0.8473 - sensitivity_at_specificity: 0.9658 - specificity_at_sensitivity: 0.9939 - recall: 0.8258 - precision: 0.8579\n",
            "Epoch 122: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 196ms/step - loss: 0.3331 - accuracy: 0.8473 - sensitivity_at_specificity: 0.9658 - specificity_at_sensitivity: 0.9939 - recall: 0.8258 - precision: 0.8579 - val_loss: 0.3596 - val_accuracy: 0.8430 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9372 - val_recall: 0.8504 - val_precision: 0.8516\n",
            "Epoch 123/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3608 - accuracy: 0.8262 - sensitivity_at_specificity: 0.9669 - specificity_at_sensitivity: 0.9891 - recall: 0.8008 - precision: 0.8412\n",
            "Epoch 123: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 193ms/step - loss: 0.3608 - accuracy: 0.8262 - sensitivity_at_specificity: 0.9669 - specificity_at_sensitivity: 0.9891 - recall: 0.8008 - precision: 0.8412 - val_loss: 0.4174 - val_accuracy: 0.8141 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9181 - val_recall: 0.8512 - val_precision: 0.7945\n",
            "Epoch 124/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3278 - accuracy: 0.8496 - sensitivity_at_specificity: 0.9770 - specificity_at_sensitivity: 0.9931 - recall: 0.8306 - precision: 0.8598\n",
            "Epoch 124: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 193ms/step - loss: 0.3278 - accuracy: 0.8496 - sensitivity_at_specificity: 0.9770 - specificity_at_sensitivity: 0.9931 - recall: 0.8306 - precision: 0.8598 - val_loss: 0.3977 - val_accuracy: 0.8211 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9313 - val_recall: 0.8180 - val_precision: 0.8088\n",
            "Epoch 125/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3234 - accuracy: 0.8461 - sensitivity_at_specificity: 0.9853 - specificity_at_sensitivity: 0.9921 - recall: 0.8457 - precision: 0.8484\n",
            "Epoch 125: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 196ms/step - loss: 0.3234 - accuracy: 0.8461 - sensitivity_at_specificity: 0.9853 - specificity_at_sensitivity: 0.9921 - recall: 0.8457 - precision: 0.8484 - val_loss: 0.4473 - val_accuracy: 0.8078 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9149 - val_recall: 0.8246 - val_precision: 0.7835\n",
            "Epoch 126/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3111 - accuracy: 0.8543 - sensitivity_at_specificity: 0.9829 - specificity_at_sensitivity: 0.9961 - recall: 0.8236 - precision: 0.8789\n",
            "Epoch 126: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 192ms/step - loss: 0.3111 - accuracy: 0.8543 - sensitivity_at_specificity: 0.9829 - specificity_at_sensitivity: 0.9961 - recall: 0.8236 - precision: 0.8789 - val_loss: 0.4389 - val_accuracy: 0.8125 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9319 - val_recall: 0.8069 - val_precision: 0.8269\n",
            "Epoch 127/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3089 - accuracy: 0.8605 - sensitivity_at_specificity: 0.9850 - specificity_at_sensitivity: 0.9959 - recall: 0.8558 - precision: 0.8630\n",
            "Epoch 127: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 187ms/step - loss: 0.3089 - accuracy: 0.8605 - sensitivity_at_specificity: 0.9850 - specificity_at_sensitivity: 0.9959 - recall: 0.8558 - precision: 0.8630 - val_loss: 0.4115 - val_accuracy: 0.8313 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9188 - val_recall: 0.8485 - val_precision: 0.8147\n",
            "Epoch 128/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3172 - accuracy: 0.8551 - sensitivity_at_specificity: 0.9741 - specificity_at_sensitivity: 0.9953 - recall: 0.8329 - precision: 0.8705\n",
            "Epoch 128: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 200ms/step - loss: 0.3172 - accuracy: 0.8551 - sensitivity_at_specificity: 0.9741 - specificity_at_sensitivity: 0.9953 - recall: 0.8329 - precision: 0.8705 - val_loss: 0.4565 - val_accuracy: 0.8008 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9112 - val_recall: 0.8276 - val_precision: 0.7845\n",
            "Epoch 129/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3325 - accuracy: 0.8461 - sensitivity_at_specificity: 0.9781 - specificity_at_sensitivity: 0.9938 - recall: 0.8103 - precision: 0.8718\n",
            "Epoch 129: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 194ms/step - loss: 0.3325 - accuracy: 0.8461 - sensitivity_at_specificity: 0.9781 - specificity_at_sensitivity: 0.9938 - recall: 0.8103 - precision: 0.8718 - val_loss: 0.4519 - val_accuracy: 0.8281 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9056 - val_recall: 0.8702 - val_precision: 0.8085\n",
            "Epoch 130/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3230 - accuracy: 0.8383 - sensitivity_at_specificity: 0.9733 - specificity_at_sensitivity: 0.9961 - recall: 0.8180 - precision: 0.8514\n",
            "Epoch 130: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 194ms/step - loss: 0.3230 - accuracy: 0.8383 - sensitivity_at_specificity: 0.9733 - specificity_at_sensitivity: 0.9961 - recall: 0.8180 - precision: 0.8514 - val_loss: 0.4484 - val_accuracy: 0.8289 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9224 - val_recall: 0.8925 - val_precision: 0.7853\n",
            "Epoch 131/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3077 - accuracy: 0.8574 - sensitivity_at_specificity: 0.9807 - specificity_at_sensitivity: 0.9984 - recall: 0.8409 - precision: 0.8726\n",
            "Epoch 131: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 192ms/step - loss: 0.3077 - accuracy: 0.8574 - sensitivity_at_specificity: 0.9807 - specificity_at_sensitivity: 0.9984 - recall: 0.8409 - precision: 0.8726 - val_loss: 0.4566 - val_accuracy: 0.8148 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8986 - val_recall: 0.8659 - val_precision: 0.7768\n",
            "Epoch 132/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2936 - accuracy: 0.8633 - sensitivity_at_specificity: 0.9811 - specificity_at_sensitivity: 0.9977 - recall: 0.8489 - precision: 0.8723\n",
            "Epoch 132: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 195ms/step - loss: 0.2936 - accuracy: 0.8633 - sensitivity_at_specificity: 0.9811 - specificity_at_sensitivity: 0.9977 - recall: 0.8489 - precision: 0.8723 - val_loss: 0.4127 - val_accuracy: 0.8047 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9277 - val_recall: 0.7794 - val_precision: 0.8156\n",
            "Epoch 133/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3333 - accuracy: 0.8391 - sensitivity_at_specificity: 0.9751 - specificity_at_sensitivity: 0.9945 - recall: 0.8034 - precision: 0.8667\n",
            "Epoch 133: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 194ms/step - loss: 0.3333 - accuracy: 0.8391 - sensitivity_at_specificity: 0.9751 - specificity_at_sensitivity: 0.9945 - recall: 0.8034 - precision: 0.8667 - val_loss: 0.3951 - val_accuracy: 0.8289 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9326 - val_recall: 0.8598 - val_precision: 0.8106\n",
            "Epoch 134/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3070 - accuracy: 0.8637 - sensitivity_at_specificity: 0.9745 - specificity_at_sensitivity: 0.9939 - recall: 0.8417 - precision: 0.8758\n",
            "Epoch 134: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 194ms/step - loss: 0.3070 - accuracy: 0.8637 - sensitivity_at_specificity: 0.9745 - specificity_at_sensitivity: 0.9939 - recall: 0.8417 - precision: 0.8758 - val_loss: 0.4265 - val_accuracy: 0.8438 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9136 - val_recall: 0.8855 - val_precision: 0.8227\n",
            "Epoch 135/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2950 - accuracy: 0.8633 - sensitivity_at_specificity: 0.9857 - specificity_at_sensitivity: 0.9985 - recall: 0.8382 - precision: 0.8786\n",
            "Epoch 135: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 194ms/step - loss: 0.2950 - accuracy: 0.8633 - sensitivity_at_specificity: 0.9857 - specificity_at_sensitivity: 0.9985 - recall: 0.8382 - precision: 0.8786 - val_loss: 0.4223 - val_accuracy: 0.8141 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9304 - val_recall: 0.8353 - val_precision: 0.8109\n",
            "Epoch 136/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3038 - accuracy: 0.8711 - sensitivity_at_specificity: 0.9791 - specificity_at_sensitivity: 0.9945 - recall: 0.8550 - precision: 0.8852\n",
            "Epoch 136: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 194ms/step - loss: 0.3038 - accuracy: 0.8711 - sensitivity_at_specificity: 0.9791 - specificity_at_sensitivity: 0.9945 - recall: 0.8550 - precision: 0.8852 - val_loss: 0.4334 - val_accuracy: 0.8195 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9227 - val_recall: 0.8194 - val_precision: 0.8282\n",
            "Epoch 137/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2812 - accuracy: 0.8727 - sensitivity_at_specificity: 0.9875 - specificity_at_sensitivity: 0.9992 - recall: 0.8508 - precision: 0.8897\n",
            "Epoch 137: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 190ms/step - loss: 0.2812 - accuracy: 0.8727 - sensitivity_at_specificity: 0.9875 - specificity_at_sensitivity: 0.9992 - recall: 0.8508 - precision: 0.8897 - val_loss: 0.4270 - val_accuracy: 0.8250 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9340 - val_recall: 0.8217 - val_precision: 0.8217\n",
            "Epoch 138/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2927 - accuracy: 0.8711 - sensitivity_at_specificity: 0.9784 - specificity_at_sensitivity: 0.9976 - recall: 0.8499 - precision: 0.8910\n",
            "Epoch 138: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 195ms/step - loss: 0.2927 - accuracy: 0.8711 - sensitivity_at_specificity: 0.9784 - specificity_at_sensitivity: 0.9976 - recall: 0.8499 - precision: 0.8910 - val_loss: 0.4286 - val_accuracy: 0.8305 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9301 - val_recall: 0.8633 - val_precision: 0.8027\n",
            "Epoch 139/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2713 - accuracy: 0.8797 - sensitivity_at_specificity: 0.9852 - specificity_at_sensitivity: 0.9976 - recall: 0.8647 - precision: 0.8925\n",
            "Epoch 139: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 194ms/step - loss: 0.2713 - accuracy: 0.8797 - sensitivity_at_specificity: 0.9852 - specificity_at_sensitivity: 0.9976 - recall: 0.8647 - precision: 0.8925 - val_loss: 0.4140 - val_accuracy: 0.8313 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9410 - val_recall: 0.8453 - val_precision: 0.8276\n",
            "Epoch 140/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2861 - accuracy: 0.8738 - sensitivity_at_specificity: 0.9820 - specificity_at_sensitivity: 0.9984 - recall: 0.8489 - precision: 0.8929\n",
            "Epoch 140: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 191ms/step - loss: 0.2861 - accuracy: 0.8738 - sensitivity_at_specificity: 0.9820 - specificity_at_sensitivity: 0.9984 - recall: 0.8489 - precision: 0.8929 - val_loss: 0.4980 - val_accuracy: 0.8133 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9069 - val_recall: 0.8690 - val_precision: 0.7661\n",
            "Epoch 141/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2795 - accuracy: 0.8773 - sensitivity_at_specificity: 0.9829 - specificity_at_sensitivity: 0.9976 - recall: 0.8545 - precision: 0.8963\n",
            "Epoch 141: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 191ms/step - loss: 0.2795 - accuracy: 0.8773 - sensitivity_at_specificity: 0.9829 - specificity_at_sensitivity: 0.9976 - recall: 0.8545 - precision: 0.8963 - val_loss: 0.4794 - val_accuracy: 0.8273 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9228 - val_recall: 0.8623 - val_precision: 0.8027\n",
            "Epoch 142/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2854 - accuracy: 0.8711 - sensitivity_at_specificity: 0.9847 - specificity_at_sensitivity: 0.9960 - recall: 0.8605 - precision: 0.8836\n",
            "Epoch 142: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 197ms/step - loss: 0.2854 - accuracy: 0.8711 - sensitivity_at_specificity: 0.9847 - specificity_at_sensitivity: 0.9960 - recall: 0.8605 - precision: 0.8836 - val_loss: 0.4715 - val_accuracy: 0.8258 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9223 - val_recall: 0.8822 - val_precision: 0.8011\n",
            "Epoch 143/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2743 - accuracy: 0.8738 - sensitivity_at_specificity: 0.9878 - specificity_at_sensitivity: 0.9985 - recall: 0.8371 - precision: 0.8931\n",
            "Epoch 143: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 196ms/step - loss: 0.2743 - accuracy: 0.8738 - sensitivity_at_specificity: 0.9878 - specificity_at_sensitivity: 0.9985 - recall: 0.8371 - precision: 0.8931 - val_loss: 0.4715 - val_accuracy: 0.8305 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9181 - val_recall: 0.8651 - val_precision: 0.8110\n",
            "Epoch 144/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2733 - accuracy: 0.8824 - sensitivity_at_specificity: 0.9829 - specificity_at_sensitivity: 0.9984 - recall: 0.8668 - precision: 0.8954\n",
            "Epoch 144: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 196ms/step - loss: 0.2733 - accuracy: 0.8824 - sensitivity_at_specificity: 0.9829 - specificity_at_sensitivity: 0.9984 - recall: 0.8668 - precision: 0.8954 - val_loss: 0.5011 - val_accuracy: 0.8313 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8992 - val_recall: 0.9056 - val_precision: 0.7828\n",
            "Epoch 145/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2510 - accuracy: 0.8918 - sensitivity_at_specificity: 0.9906 - specificity_at_sensitivity: 0.9992 - recall: 0.8579 - precision: 0.9193\n",
            "Epoch 145: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 195ms/step - loss: 0.2510 - accuracy: 0.8918 - sensitivity_at_specificity: 0.9906 - specificity_at_sensitivity: 0.9992 - recall: 0.8579 - precision: 0.9193 - val_loss: 0.5499 - val_accuracy: 0.8266 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9134 - val_recall: 0.8667 - val_precision: 0.8043\n",
            "Epoch 146/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2712 - accuracy: 0.8789 - sensitivity_at_specificity: 0.9887 - specificity_at_sensitivity: 0.9976 - recall: 0.8646 - precision: 0.8972\n",
            "Epoch 146: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 192ms/step - loss: 0.2712 - accuracy: 0.8789 - sensitivity_at_specificity: 0.9887 - specificity_at_sensitivity: 0.9976 - recall: 0.8646 - precision: 0.8972 - val_loss: 0.4611 - val_accuracy: 0.8258 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9089 - val_recall: 0.8807 - val_precision: 0.7989\n",
            "Epoch 147/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2795 - accuracy: 0.8754 - sensitivity_at_specificity: 0.9808 - specificity_at_sensitivity: 0.9984 - recall: 0.8574 - precision: 0.8937\n",
            "Epoch 147: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 198ms/step - loss: 0.2795 - accuracy: 0.8754 - sensitivity_at_specificity: 0.9808 - specificity_at_sensitivity: 0.9984 - recall: 0.8574 - precision: 0.8937 - val_loss: 0.4711 - val_accuracy: 0.7969 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9212 - val_recall: 0.7757 - val_precision: 0.8062\n",
            "Epoch 148/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2615 - accuracy: 0.8852 - sensitivity_at_specificity: 0.9878 - specificity_at_sensitivity: 0.9984 - recall: 0.8783 - precision: 0.8948\n",
            "Epoch 148: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 197ms/step - loss: 0.2615 - accuracy: 0.8852 - sensitivity_at_specificity: 0.9878 - specificity_at_sensitivity: 0.9984 - recall: 0.8783 - precision: 0.8948 - val_loss: 0.4495 - val_accuracy: 0.7984 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9132 - val_recall: 0.7881 - val_precision: 0.7958\n",
            "Epoch 149/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2757 - accuracy: 0.8773 - sensitivity_at_specificity: 0.9913 - specificity_at_sensitivity: 0.9969 - recall: 0.8488 - precision: 0.8983\n",
            "Epoch 149: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 196ms/step - loss: 0.2757 - accuracy: 0.8773 - sensitivity_at_specificity: 0.9913 - specificity_at_sensitivity: 0.9969 - recall: 0.8488 - precision: 0.8983 - val_loss: 0.4762 - val_accuracy: 0.8203 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9122 - val_recall: 0.8304 - val_precision: 0.8099\n",
            "Epoch 150/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2549 - accuracy: 0.8891 - sensitivity_at_specificity: 0.9861 - specificity_at_sensitivity: 0.9992 - recall: 0.8707 - precision: 0.9058\n",
            "Epoch 150: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 197ms/step - loss: 0.2549 - accuracy: 0.8891 - sensitivity_at_specificity: 0.9861 - specificity_at_sensitivity: 0.9992 - recall: 0.8707 - precision: 0.9058 - val_loss: 0.4500 - val_accuracy: 0.8242 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 0.9214 - val_recall: 0.8580 - val_precision: 0.8153\n",
            "Epoch 151/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2555 - accuracy: 0.8906 - sensitivity_at_specificity: 0.9894 - specificity_at_sensitivity: 0.9984 - recall: 0.8764 - precision: 0.9081\n",
            "Epoch 151: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 199ms/step - loss: 0.2555 - accuracy: 0.8906 - sensitivity_at_specificity: 0.9894 - specificity_at_sensitivity: 0.9984 - recall: 0.8764 - precision: 0.9081 - val_loss: 0.4562 - val_accuracy: 0.8258 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9403 - val_recall: 0.8804 - val_precision: 0.7952\n",
            "Epoch 152/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2559 - accuracy: 0.8898 - sensitivity_at_specificity: 0.9854 - specificity_at_sensitivity: 0.9984 - recall: 0.8736 - precision: 0.9057\n",
            "Epoch 152: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 198ms/step - loss: 0.2559 - accuracy: 0.8898 - sensitivity_at_specificity: 0.9854 - specificity_at_sensitivity: 0.9984 - recall: 0.8736 - precision: 0.9057 - val_loss: 0.4354 - val_accuracy: 0.8188 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9366 - val_recall: 0.8290 - val_precision: 0.8164\n",
            "Epoch 153/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2528 - accuracy: 0.8891 - sensitivity_at_specificity: 0.9856 - specificity_at_sensitivity: 1.0000 - recall: 0.8570 - precision: 0.9109\n",
            "Epoch 153: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 197ms/step - loss: 0.2528 - accuracy: 0.8891 - sensitivity_at_specificity: 0.9856 - specificity_at_sensitivity: 1.0000 - recall: 0.8570 - precision: 0.9109 - val_loss: 0.5367 - val_accuracy: 0.8039 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8963 - val_recall: 0.8486 - val_precision: 0.7763\n",
            "Epoch 154/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2409 - accuracy: 0.8999 - sensitivity_at_specificity: 0.9891 - specificity_at_sensitivity: 1.0000 - recall: 0.8766 - precision: 0.9174\n",
            "Epoch 154: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 191ms/step - loss: 0.2409 - accuracy: 0.8999 - sensitivity_at_specificity: 0.9891 - specificity_at_sensitivity: 1.0000 - recall: 0.8766 - precision: 0.9174 - val_loss: 0.4885 - val_accuracy: 0.8086 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9188 - val_recall: 0.8198 - val_precision: 0.7957\n",
            "Epoch 155/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2476 - accuracy: 0.8922 - sensitivity_at_specificity: 0.9869 - specificity_at_sensitivity: 0.9992 - recall: 0.8775 - precision: 0.9068\n",
            "Epoch 155: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 194ms/step - loss: 0.2476 - accuracy: 0.8922 - sensitivity_at_specificity: 0.9869 - specificity_at_sensitivity: 0.9992 - recall: 0.8775 - precision: 0.9068 - val_loss: 0.5602 - val_accuracy: 0.8031 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8943 - val_recall: 0.8341 - val_precision: 0.7794\n",
            "Epoch 156/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2518 - accuracy: 0.8938 - sensitivity_at_specificity: 0.9864 - specificity_at_sensitivity: 0.9977 - recall: 0.8606 - precision: 0.9164\n",
            "Epoch 156: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 198ms/step - loss: 0.2518 - accuracy: 0.8938 - sensitivity_at_specificity: 0.9864 - specificity_at_sensitivity: 0.9977 - recall: 0.8606 - precision: 0.9164 - val_loss: 0.4107 - val_accuracy: 0.8500 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9484 - val_recall: 0.8906 - val_precision: 0.8237\n",
            "Epoch 157/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2471 - accuracy: 0.8926 - sensitivity_at_specificity: 0.9898 - specificity_at_sensitivity: 0.9992 - recall: 0.8707 - precision: 0.9099\n",
            "Epoch 157: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 200ms/step - loss: 0.2471 - accuracy: 0.8926 - sensitivity_at_specificity: 0.9898 - specificity_at_sensitivity: 0.9992 - recall: 0.8707 - precision: 0.9099 - val_loss: 0.4829 - val_accuracy: 0.8352 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9149 - val_recall: 0.8721 - val_precision: 0.8186\n",
            "Epoch 158/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2531 - accuracy: 0.8875 - sensitivity_at_specificity: 0.9901 - specificity_at_sensitivity: 0.9984 - recall: 0.8646 - precision: 0.9106\n",
            "Epoch 158: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 0.2531 - accuracy: 0.8875 - sensitivity_at_specificity: 0.9901 - specificity_at_sensitivity: 0.9984 - recall: 0.8646 - precision: 0.9106 - val_loss: 0.4860 - val_accuracy: 0.8313 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9474 - val_recall: 0.8644 - val_precision: 0.8083\n",
            "Epoch 159/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2368 - accuracy: 0.9043 - sensitivity_at_specificity: 0.9871 - specificity_at_sensitivity: 1.0000 - recall: 0.8867 - precision: 0.9138\n",
            "Epoch 159: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 196ms/step - loss: 0.2368 - accuracy: 0.9043 - sensitivity_at_specificity: 0.9871 - specificity_at_sensitivity: 1.0000 - recall: 0.8867 - precision: 0.9138 - val_loss: 0.5924 - val_accuracy: 0.8266 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9255 - val_recall: 0.8851 - val_precision: 0.7800\n",
            "Epoch 160/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2595 - accuracy: 0.8941 - sensitivity_at_specificity: 0.9855 - specificity_at_sensitivity: 0.9992 - recall: 0.8607 - precision: 0.9160\n",
            "Epoch 160: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 199ms/step - loss: 0.2595 - accuracy: 0.8941 - sensitivity_at_specificity: 0.9855 - specificity_at_sensitivity: 0.9992 - recall: 0.8607 - precision: 0.9160 - val_loss: 0.5733 - val_accuracy: 0.8344 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9183 - val_recall: 0.9273 - val_precision: 0.7746\n",
            "Epoch 161/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2294 - accuracy: 0.9004 - sensitivity_at_specificity: 0.9945 - specificity_at_sensitivity: 0.9984 - recall: 0.8722 - precision: 0.9248\n",
            "Epoch 161: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 199ms/step - loss: 0.2294 - accuracy: 0.9004 - sensitivity_at_specificity: 0.9945 - specificity_at_sensitivity: 0.9984 - recall: 0.8722 - precision: 0.9248 - val_loss: 0.5719 - val_accuracy: 0.8328 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9194 - val_recall: 0.9136 - val_precision: 0.7934\n",
            "Epoch 162/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2376 - accuracy: 0.8898 - sensitivity_at_specificity: 0.9912 - specificity_at_sensitivity: 0.9969 - recall: 0.8697 - precision: 0.9014\n",
            "Epoch 162: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 198ms/step - loss: 0.2376 - accuracy: 0.8898 - sensitivity_at_specificity: 0.9912 - specificity_at_sensitivity: 0.9969 - recall: 0.8697 - precision: 0.9014 - val_loss: 0.5524 - val_accuracy: 0.8398 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9142 - val_recall: 0.9171 - val_precision: 0.7898\n",
            "Epoch 163/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2411 - accuracy: 0.9012 - sensitivity_at_specificity: 0.9902 - specificity_at_sensitivity: 0.9985 - recall: 0.8803 - precision: 0.9107\n",
            "Epoch 163: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 195ms/step - loss: 0.2411 - accuracy: 0.9012 - sensitivity_at_specificity: 0.9902 - specificity_at_sensitivity: 0.9985 - recall: 0.8803 - precision: 0.9107 - val_loss: 0.4654 - val_accuracy: 0.8227 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9345 - val_recall: 0.8435 - val_precision: 0.8093\n",
            "Epoch 164/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2390 - accuracy: 0.8980 - sensitivity_at_specificity: 0.9939 - specificity_at_sensitivity: 0.9960 - recall: 0.8777 - precision: 0.9191\n",
            "Epoch 164: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 195ms/step - loss: 0.2390 - accuracy: 0.8980 - sensitivity_at_specificity: 0.9939 - specificity_at_sensitivity: 0.9960 - recall: 0.8777 - precision: 0.9191 - val_loss: 0.5195 - val_accuracy: 0.8297 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9196 - val_recall: 0.8768 - val_precision: 0.7986\n",
            "Epoch 165/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2123 - accuracy: 0.9102 - sensitivity_at_specificity: 0.9969 - specificity_at_sensitivity: 0.9984 - recall: 0.8861 - precision: 0.9335\n",
            "Epoch 165: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 198ms/step - loss: 0.2123 - accuracy: 0.9102 - sensitivity_at_specificity: 0.9969 - specificity_at_sensitivity: 0.9984 - recall: 0.8861 - precision: 0.9335 - val_loss: 0.5441 - val_accuracy: 0.8227 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9020 - val_recall: 0.8870 - val_precision: 0.7847\n",
            "Epoch 166/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2011 - accuracy: 0.9195 - sensitivity_at_specificity: 0.9930 - specificity_at_sensitivity: 0.9992 - recall: 0.8967 - precision: 0.9393\n",
            "Epoch 166: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 196ms/step - loss: 0.2011 - accuracy: 0.9195 - sensitivity_at_specificity: 0.9930 - specificity_at_sensitivity: 0.9992 - recall: 0.8967 - precision: 0.9393 - val_loss: 0.5381 - val_accuracy: 0.8320 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9330 - val_recall: 0.8867 - val_precision: 0.8042\n",
            "Epoch 167/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2249 - accuracy: 0.9086 - sensitivity_at_specificity: 0.9898 - specificity_at_sensitivity: 0.9992 - recall: 0.8930 - precision: 0.9205\n",
            "Epoch 167: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 197ms/step - loss: 0.2249 - accuracy: 0.9086 - sensitivity_at_specificity: 0.9898 - specificity_at_sensitivity: 0.9992 - recall: 0.8930 - precision: 0.9205 - val_loss: 0.5516 - val_accuracy: 0.7969 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9062 - val_recall: 0.8304 - val_precision: 0.7683\n",
            "Epoch 168/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2235 - accuracy: 0.9070 - sensitivity_at_specificity: 0.9909 - specificity_at_sensitivity: 1.0000 - recall: 0.8837 - precision: 0.9319\n",
            "Epoch 168: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 199ms/step - loss: 0.2235 - accuracy: 0.9070 - sensitivity_at_specificity: 0.9909 - specificity_at_sensitivity: 1.0000 - recall: 0.8837 - precision: 0.9319 - val_loss: 0.4497 - val_accuracy: 0.8297 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9358 - val_recall: 0.8549 - val_precision: 0.8143\n",
            "Epoch 169/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2018 - accuracy: 0.9191 - sensitivity_at_specificity: 0.9938 - specificity_at_sensitivity: 0.9992 - recall: 0.9080 - precision: 0.9290\n",
            "Epoch 169: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 196ms/step - loss: 0.2018 - accuracy: 0.9191 - sensitivity_at_specificity: 0.9938 - specificity_at_sensitivity: 0.9992 - recall: 0.9080 - precision: 0.9290 - val_loss: 0.5534 - val_accuracy: 0.8344 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9153 - val_recall: 0.8837 - val_precision: 0.7962\n",
            "Epoch 170/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2145 - accuracy: 0.9152 - sensitivity_at_specificity: 0.9919 - specificity_at_sensitivity: 1.0000 - recall: 0.8945 - precision: 0.9282\n",
            "Epoch 170: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 199ms/step - loss: 0.2145 - accuracy: 0.9152 - sensitivity_at_specificity: 0.9919 - specificity_at_sensitivity: 1.0000 - recall: 0.8945 - precision: 0.9282 - val_loss: 0.5342 - val_accuracy: 0.8148 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 0.9130 - val_recall: 0.8457 - val_precision: 0.8000\n",
            "Epoch 171/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2155 - accuracy: 0.9066 - sensitivity_at_specificity: 0.9962 - specificity_at_sensitivity: 0.9992 - recall: 0.8938 - precision: 0.9200\n",
            "Epoch 171: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 205ms/step - loss: 0.2155 - accuracy: 0.9066 - sensitivity_at_specificity: 0.9962 - specificity_at_sensitivity: 0.9992 - recall: 0.8938 - precision: 0.9200 - val_loss: 0.5312 - val_accuracy: 0.8227 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9173 - val_recall: 0.8788 - val_precision: 0.7849\n",
            "Epoch 172/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2062 - accuracy: 0.9141 - sensitivity_at_specificity: 0.9937 - specificity_at_sensitivity: 0.9992 - recall: 0.8830 - precision: 0.9406\n",
            "Epoch 172: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 200ms/step - loss: 0.2062 - accuracy: 0.9141 - sensitivity_at_specificity: 0.9937 - specificity_at_sensitivity: 0.9992 - recall: 0.8830 - precision: 0.9406 - val_loss: 0.5497 - val_accuracy: 0.8297 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9319 - val_recall: 0.8754 - val_precision: 0.7997\n",
            "Epoch 173/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2089 - accuracy: 0.9109 - sensitivity_at_specificity: 0.9891 - specificity_at_sensitivity: 1.0000 - recall: 0.8949 - precision: 0.9252\n",
            "Epoch 173: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 198ms/step - loss: 0.2089 - accuracy: 0.9109 - sensitivity_at_specificity: 0.9891 - specificity_at_sensitivity: 1.0000 - recall: 0.8949 - precision: 0.9252 - val_loss: 0.5930 - val_accuracy: 0.8375 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9092 - val_recall: 0.9126 - val_precision: 0.7976\n",
            "Epoch 174/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1992 - accuracy: 0.9242 - sensitivity_at_specificity: 0.9899 - specificity_at_sensitivity: 0.9984 - recall: 0.9012 - precision: 0.9454\n",
            "Epoch 174: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 196ms/step - loss: 0.1992 - accuracy: 0.9242 - sensitivity_at_specificity: 0.9899 - specificity_at_sensitivity: 0.9984 - recall: 0.9012 - precision: 0.9454 - val_loss: 0.6055 - val_accuracy: 0.8297 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9112 - val_recall: 0.9107 - val_precision: 0.7790\n",
            "Epoch 175/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2092 - accuracy: 0.9121 - sensitivity_at_specificity: 0.9920 - specificity_at_sensitivity: 0.9992 - recall: 0.8902 - precision: 0.9279\n",
            "Epoch 175: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 198ms/step - loss: 0.2092 - accuracy: 0.9121 - sensitivity_at_specificity: 0.9920 - specificity_at_sensitivity: 0.9992 - recall: 0.8902 - precision: 0.9279 - val_loss: 0.6539 - val_accuracy: 0.8242 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9037 - val_recall: 0.8995 - val_precision: 0.7880\n",
            "Epoch 176/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2023 - accuracy: 0.9168 - sensitivity_at_specificity: 0.9903 - specificity_at_sensitivity: 1.0000 - recall: 0.9011 - precision: 0.9244\n",
            "Epoch 176: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 198ms/step - loss: 0.2023 - accuracy: 0.9168 - sensitivity_at_specificity: 0.9903 - specificity_at_sensitivity: 1.0000 - recall: 0.9011 - precision: 0.9244 - val_loss: 0.5187 - val_accuracy: 0.8383 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9257 - val_recall: 0.8911 - val_precision: 0.8135\n",
            "Epoch 177/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1936 - accuracy: 0.9168 - sensitivity_at_specificity: 0.9939 - specificity_at_sensitivity: 1.0000 - recall: 0.9006 - precision: 0.9354\n",
            "Epoch 177: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 197ms/step - loss: 0.1936 - accuracy: 0.9168 - sensitivity_at_specificity: 0.9939 - specificity_at_sensitivity: 1.0000 - recall: 0.9006 - precision: 0.9354 - val_loss: 0.6031 - val_accuracy: 0.8086 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9220 - val_recall: 0.8626 - val_precision: 0.7725\n",
            "Epoch 178/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1945 - accuracy: 0.9199 - sensitivity_at_specificity: 0.9938 - specificity_at_sensitivity: 1.0000 - recall: 0.8910 - precision: 0.9462\n",
            "Epoch 178: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 202ms/step - loss: 0.1945 - accuracy: 0.9199 - sensitivity_at_specificity: 0.9938 - specificity_at_sensitivity: 1.0000 - recall: 0.8910 - precision: 0.9462 - val_loss: 0.6529 - val_accuracy: 0.8141 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9138 - val_recall: 0.8805 - val_precision: 0.7687\n",
            "Epoch 179/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2051 - accuracy: 0.9165 - sensitivity_at_specificity: 0.9933 - specificity_at_sensitivity: 0.9992 - recall: 0.8926 - precision: 0.9358\n",
            "Epoch 179: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 199ms/step - loss: 0.2051 - accuracy: 0.9165 - sensitivity_at_specificity: 0.9933 - specificity_at_sensitivity: 0.9992 - recall: 0.8926 - precision: 0.9358 - val_loss: 0.6311 - val_accuracy: 0.8281 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9130 - val_recall: 0.9136 - val_precision: 0.7831\n",
            "Epoch 180/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2046 - accuracy: 0.9160 - sensitivity_at_specificity: 0.9936 - specificity_at_sensitivity: 1.0000 - recall: 0.8950 - precision: 0.9313\n",
            "Epoch 180: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 199ms/step - loss: 0.2046 - accuracy: 0.9160 - sensitivity_at_specificity: 0.9936 - specificity_at_sensitivity: 1.0000 - recall: 0.8950 - precision: 0.9313 - val_loss: 0.5664 - val_accuracy: 0.8367 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9188 - val_recall: 0.9034 - val_precision: 0.8014\n",
            "Epoch 181/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1942 - accuracy: 0.9258 - sensitivity_at_specificity: 0.9898 - specificity_at_sensitivity: 0.9992 - recall: 0.8998 - precision: 0.9488\n",
            "Epoch 181: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 200ms/step - loss: 0.1942 - accuracy: 0.9258 - sensitivity_at_specificity: 0.9898 - specificity_at_sensitivity: 0.9992 - recall: 0.8998 - precision: 0.9488 - val_loss: 0.5522 - val_accuracy: 0.8359 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9019 - val_recall: 0.9119 - val_precision: 0.7979\n",
            "Epoch 182/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1903 - accuracy: 0.9176 - sensitivity_at_specificity: 0.9948 - specificity_at_sensitivity: 0.9992 - recall: 0.8934 - precision: 0.9463\n",
            "Epoch 182: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 197ms/step - loss: 0.1903 - accuracy: 0.9176 - sensitivity_at_specificity: 0.9948 - specificity_at_sensitivity: 0.9992 - recall: 0.8934 - precision: 0.9463 - val_loss: 0.7080 - val_accuracy: 0.8438 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9059 - val_recall: 0.9387 - val_precision: 0.7930\n",
            "Epoch 183/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1919 - accuracy: 0.9199 - sensitivity_at_specificity: 0.9938 - specificity_at_sensitivity: 1.0000 - recall: 0.9043 - precision: 0.9354\n",
            "Epoch 183: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 204ms/step - loss: 0.1919 - accuracy: 0.9199 - sensitivity_at_specificity: 0.9938 - specificity_at_sensitivity: 1.0000 - recall: 0.9043 - precision: 0.9354 - val_loss: 0.6106 - val_accuracy: 0.8375 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9108 - val_recall: 0.8970 - val_precision: 0.8020\n",
            "Epoch 184/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1996 - accuracy: 0.9191 - sensitivity_at_specificity: 0.9930 - specificity_at_sensitivity: 1.0000 - recall: 0.8978 - precision: 0.9381\n",
            "Epoch 184: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 0.1996 - accuracy: 0.9191 - sensitivity_at_specificity: 0.9930 - specificity_at_sensitivity: 1.0000 - recall: 0.8978 - precision: 0.9381 - val_loss: 0.6671 - val_accuracy: 0.8430 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9029 - val_recall: 0.9494 - val_precision: 0.7865\n",
            "Epoch 185/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2002 - accuracy: 0.9160 - sensitivity_at_specificity: 0.9944 - specificity_at_sensitivity: 0.9992 - recall: 0.8975 - precision: 0.9280\n",
            "Epoch 185: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 202ms/step - loss: 0.2002 - accuracy: 0.9160 - sensitivity_at_specificity: 0.9944 - specificity_at_sensitivity: 0.9992 - recall: 0.8975 - precision: 0.9280 - val_loss: 0.6414 - val_accuracy: 0.8453 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9153 - val_recall: 0.9266 - val_precision: 0.8016\n",
            "Epoch 186/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1911 - accuracy: 0.9199 - sensitivity_at_specificity: 0.9961 - specificity_at_sensitivity: 0.9992 - recall: 0.9082 - precision: 0.9306\n",
            "Epoch 186: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 197ms/step - loss: 0.1911 - accuracy: 0.9199 - sensitivity_at_specificity: 0.9961 - specificity_at_sensitivity: 0.9992 - recall: 0.9082 - precision: 0.9306 - val_loss: 0.5417 - val_accuracy: 0.8336 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9244 - val_recall: 0.8899 - val_precision: 0.8017\n",
            "Epoch 187/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1791 - accuracy: 0.9316 - sensitivity_at_specificity: 0.9937 - specificity_at_sensitivity: 1.0000 - recall: 0.9060 - precision: 0.9546\n",
            "Epoch 187: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 199ms/step - loss: 0.1791 - accuracy: 0.9316 - sensitivity_at_specificity: 0.9937 - specificity_at_sensitivity: 1.0000 - recall: 0.9060 - precision: 0.9546 - val_loss: 0.6215 - val_accuracy: 0.8383 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9174 - val_recall: 0.9310 - val_precision: 0.7847\n",
            "Epoch 188/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1782 - accuracy: 0.9312 - sensitivity_at_specificity: 0.9937 - specificity_at_sensitivity: 0.9992 - recall: 0.9170 - precision: 0.9436\n",
            "Epoch 188: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 199ms/step - loss: 0.1782 - accuracy: 0.9312 - sensitivity_at_specificity: 0.9937 - specificity_at_sensitivity: 0.9992 - recall: 0.9170 - precision: 0.9436 - val_loss: 0.5665 - val_accuracy: 0.8438 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9279 - val_recall: 0.8847 - val_precision: 0.8184\n",
            "Epoch 189/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1753 - accuracy: 0.9297 - sensitivity_at_specificity: 0.9946 - specificity_at_sensitivity: 1.0000 - recall: 0.9129 - precision: 0.9465\n",
            "Epoch 189: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 199ms/step - loss: 0.1753 - accuracy: 0.9297 - sensitivity_at_specificity: 0.9946 - specificity_at_sensitivity: 1.0000 - recall: 0.9129 - precision: 0.9465 - val_loss: 0.6832 - val_accuracy: 0.8297 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9119 - val_recall: 0.9162 - val_precision: 0.7866\n",
            "Epoch 190/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1885 - accuracy: 0.9289 - sensitivity_at_specificity: 0.9931 - specificity_at_sensitivity: 0.9992 - recall: 0.9161 - precision: 0.9434\n",
            "Epoch 190: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 0.1885 - accuracy: 0.9289 - sensitivity_at_specificity: 0.9931 - specificity_at_sensitivity: 0.9992 - recall: 0.9161 - precision: 0.9434 - val_loss: 0.5379 - val_accuracy: 0.8352 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9203 - val_recall: 0.8806 - val_precision: 0.8121\n",
            "Epoch 191/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1825 - accuracy: 0.9242 - sensitivity_at_specificity: 0.9954 - specificity_at_sensitivity: 1.0000 - recall: 0.9063 - precision: 0.9425\n",
            "Epoch 191: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 197ms/step - loss: 0.1825 - accuracy: 0.9242 - sensitivity_at_specificity: 0.9954 - specificity_at_sensitivity: 1.0000 - recall: 0.9063 - precision: 0.9425 - val_loss: 0.5786 - val_accuracy: 0.8438 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8992 - val_recall: 0.9226 - val_precision: 0.8113\n",
            "Epoch 192/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1741 - accuracy: 0.9316 - sensitivity_at_specificity: 0.9960 - specificity_at_sensitivity: 1.0000 - recall: 0.9065 - precision: 0.9514\n",
            "Epoch 192: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 199ms/step - loss: 0.1741 - accuracy: 0.9316 - sensitivity_at_specificity: 0.9960 - specificity_at_sensitivity: 1.0000 - recall: 0.9065 - precision: 0.9514 - val_loss: 0.6985 - val_accuracy: 0.8477 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9092 - val_recall: 0.9413 - val_precision: 0.7896\n",
            "Epoch 193/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1610 - accuracy: 0.9365 - sensitivity_at_specificity: 0.9967 - specificity_at_sensitivity: 1.0000 - recall: 0.9231 - precision: 0.9490\n",
            "Epoch 193: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 188ms/step - loss: 0.1610 - accuracy: 0.9365 - sensitivity_at_specificity: 0.9967 - specificity_at_sensitivity: 1.0000 - recall: 0.9231 - precision: 0.9490 - val_loss: 0.6563 - val_accuracy: 0.8242 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9145 - val_recall: 0.8970 - val_precision: 0.7904\n",
            "Epoch 194/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1675 - accuracy: 0.9406 - sensitivity_at_specificity: 0.9913 - specificity_at_sensitivity: 1.0000 - recall: 0.9219 - precision: 0.9566\n",
            "Epoch 194: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 195ms/step - loss: 0.1675 - accuracy: 0.9406 - sensitivity_at_specificity: 0.9913 - specificity_at_sensitivity: 1.0000 - recall: 0.9219 - precision: 0.9566 - val_loss: 0.6742 - val_accuracy: 0.8430 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9259 - val_recall: 0.9272 - val_precision: 0.7955\n",
            "Epoch 195/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1640 - accuracy: 0.9328 - sensitivity_at_specificity: 0.9969 - specificity_at_sensitivity: 1.0000 - recall: 0.9249 - precision: 0.9396\n",
            "Epoch 195: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 195ms/step - loss: 0.1640 - accuracy: 0.9328 - sensitivity_at_specificity: 0.9969 - specificity_at_sensitivity: 1.0000 - recall: 0.9249 - precision: 0.9396 - val_loss: 0.6836 - val_accuracy: 0.8297 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9017 - val_recall: 0.8918 - val_precision: 0.7852\n",
            "Epoch 196/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1714 - accuracy: 0.9352 - sensitivity_at_specificity: 0.9952 - specificity_at_sensitivity: 0.9992 - recall: 0.9140 - precision: 0.9519\n",
            "Epoch 196: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 199ms/step - loss: 0.1714 - accuracy: 0.9352 - sensitivity_at_specificity: 0.9952 - specificity_at_sensitivity: 0.9992 - recall: 0.9140 - precision: 0.9519 - val_loss: 0.7289 - val_accuracy: 0.8359 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9121 - val_recall: 0.9128 - val_precision: 0.7960\n",
            "Epoch 197/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1676 - accuracy: 0.9340 - sensitivity_at_specificity: 0.9969 - specificity_at_sensitivity: 1.0000 - recall: 0.9262 - precision: 0.9402\n",
            "Epoch 197: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 197ms/step - loss: 0.1676 - accuracy: 0.9340 - sensitivity_at_specificity: 0.9969 - specificity_at_sensitivity: 1.0000 - recall: 0.9262 - precision: 0.9402 - val_loss: 0.5966 - val_accuracy: 0.8375 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9318 - val_recall: 0.9150 - val_precision: 0.7905\n",
            "Epoch 198/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1721 - accuracy: 0.9340 - sensitivity_at_specificity: 0.9930 - specificity_at_sensitivity: 0.9992 - recall: 0.9126 - precision: 0.9547\n",
            "Epoch 198: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 198ms/step - loss: 0.1721 - accuracy: 0.9340 - sensitivity_at_specificity: 0.9930 - specificity_at_sensitivity: 0.9992 - recall: 0.9126 - precision: 0.9547 - val_loss: 0.6267 - val_accuracy: 0.8539 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9203 - val_recall: 0.9308 - val_precision: 0.8145\n",
            "Epoch 199/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1616 - accuracy: 0.9383 - sensitivity_at_specificity: 0.9947 - specificity_at_sensitivity: 1.0000 - recall: 0.9175 - precision: 0.9611\n",
            "Epoch 199: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 197ms/step - loss: 0.1616 - accuracy: 0.9383 - sensitivity_at_specificity: 0.9947 - specificity_at_sensitivity: 1.0000 - recall: 0.9175 - precision: 0.9611 - val_loss: 0.8231 - val_accuracy: 0.8375 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8941 - val_recall: 0.9451 - val_precision: 0.7771\n",
            "Epoch 200/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1607 - accuracy: 0.9383 - sensitivity_at_specificity: 0.9938 - specificity_at_sensitivity: 1.0000 - recall: 0.9298 - precision: 0.9474\n",
            "Epoch 200: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 195ms/step - loss: 0.1607 - accuracy: 0.9383 - sensitivity_at_specificity: 0.9938 - specificity_at_sensitivity: 1.0000 - recall: 0.9298 - precision: 0.9474 - val_loss: 0.7115 - val_accuracy: 0.8492 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9068 - val_recall: 0.9382 - val_precision: 0.7987\n",
            "Epoch 201/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1630 - accuracy: 0.9375 - sensitivity_at_specificity: 0.9944 - specificity_at_sensitivity: 1.0000 - recall: 0.9230 - precision: 0.9486\n",
            "Epoch 201: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 195ms/step - loss: 0.1630 - accuracy: 0.9375 - sensitivity_at_specificity: 0.9944 - specificity_at_sensitivity: 1.0000 - recall: 0.9230 - precision: 0.9486 - val_loss: 0.7660 - val_accuracy: 0.8531 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8961 - val_recall: 0.9606 - val_precision: 0.7891\n",
            "Epoch 202/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1707 - accuracy: 0.9281 - sensitivity_at_specificity: 0.9947 - specificity_at_sensitivity: 1.0000 - recall: 0.9090 - precision: 0.9505\n",
            "Epoch 202: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 197ms/step - loss: 0.1707 - accuracy: 0.9281 - sensitivity_at_specificity: 0.9947 - specificity_at_sensitivity: 1.0000 - recall: 0.9090 - precision: 0.9505 - val_loss: 0.8637 - val_accuracy: 0.8188 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8845 - val_recall: 0.9537 - val_precision: 0.7537\n",
            "Epoch 203/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1729 - accuracy: 0.9367 - sensitivity_at_specificity: 0.9938 - specificity_at_sensitivity: 1.0000 - recall: 0.9187 - precision: 0.9542\n",
            "Epoch 203: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 199ms/step - loss: 0.1729 - accuracy: 0.9367 - sensitivity_at_specificity: 0.9938 - specificity_at_sensitivity: 1.0000 - recall: 0.9187 - precision: 0.9542 - val_loss: 0.6837 - val_accuracy: 0.8531 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9078 - val_recall: 0.9350 - val_precision: 0.8102\n",
            "Epoch 204/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1725 - accuracy: 0.9383 - sensitivity_at_specificity: 0.9928 - specificity_at_sensitivity: 1.0000 - recall: 0.9237 - precision: 0.9493\n",
            "Epoch 204: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 199ms/step - loss: 0.1725 - accuracy: 0.9383 - sensitivity_at_specificity: 0.9928 - specificity_at_sensitivity: 1.0000 - recall: 0.9237 - precision: 0.9493 - val_loss: 0.6604 - val_accuracy: 0.8391 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9160 - val_recall: 0.9368 - val_precision: 0.7865\n",
            "Epoch 205/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1740 - accuracy: 0.9395 - sensitivity_at_specificity: 0.9923 - specificity_at_sensitivity: 0.9992 - recall: 0.9203 - precision: 0.9581\n",
            "Epoch 205: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 200ms/step - loss: 0.1740 - accuracy: 0.9395 - sensitivity_at_specificity: 0.9923 - specificity_at_sensitivity: 0.9992 - recall: 0.9203 - precision: 0.9581 - val_loss: 0.7740 - val_accuracy: 0.8156 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8819 - val_recall: 0.9085 - val_precision: 0.7680\n",
            "Epoch 206/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1539 - accuracy: 0.9426 - sensitivity_at_specificity: 0.9976 - specificity_at_sensitivity: 0.9992 - recall: 0.9263 - precision: 0.9558\n",
            "Epoch 206: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 197ms/step - loss: 0.1539 - accuracy: 0.9426 - sensitivity_at_specificity: 0.9976 - specificity_at_sensitivity: 0.9992 - recall: 0.9263 - precision: 0.9558 - val_loss: 0.7446 - val_accuracy: 0.8258 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9199 - val_recall: 0.9033 - val_precision: 0.7787\n",
            "Epoch 207/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1543 - accuracy: 0.9398 - sensitivity_at_specificity: 0.9953 - specificity_at_sensitivity: 1.0000 - recall: 0.9258 - precision: 0.9526\n",
            "Epoch 207: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 196ms/step - loss: 0.1543 - accuracy: 0.9398 - sensitivity_at_specificity: 0.9953 - specificity_at_sensitivity: 1.0000 - recall: 0.9258 - precision: 0.9526 - val_loss: 0.6181 - val_accuracy: 0.8281 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9269 - val_recall: 0.9157 - val_precision: 0.7876\n",
            "Epoch 208/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1425 - accuracy: 0.9422 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 1.0000 - recall: 0.9309 - precision: 0.9544\n",
            "Epoch 208: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 197ms/step - loss: 0.1425 - accuracy: 0.9422 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 1.0000 - recall: 0.9309 - precision: 0.9544 - val_loss: 0.8696 - val_accuracy: 0.8320 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8730 - val_recall: 0.9271 - val_precision: 0.7851\n",
            "Epoch 209/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1406 - accuracy: 0.9438 - sensitivity_at_specificity: 0.9977 - specificity_at_sensitivity: 1.0000 - recall: 0.9256 - precision: 0.9602\n",
            "Epoch 209: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 200ms/step - loss: 0.1406 - accuracy: 0.9438 - sensitivity_at_specificity: 0.9977 - specificity_at_sensitivity: 1.0000 - recall: 0.9256 - precision: 0.9602 - val_loss: 0.8459 - val_accuracy: 0.8203 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8914 - val_recall: 0.9217 - val_precision: 0.7612\n",
            "Epoch 210/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1411 - accuracy: 0.9418 - sensitivity_at_specificity: 0.9961 - specificity_at_sensitivity: 1.0000 - recall: 0.9448 - precision: 0.9397\n",
            "Epoch 210: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 193ms/step - loss: 0.1411 - accuracy: 0.9418 - sensitivity_at_specificity: 0.9961 - specificity_at_sensitivity: 1.0000 - recall: 0.9448 - precision: 0.9397 - val_loss: 0.6765 - val_accuracy: 0.8352 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9150 - val_recall: 0.9057 - val_precision: 0.8035\n",
            "Epoch 211/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1539 - accuracy: 0.9395 - sensitivity_at_specificity: 0.9977 - specificity_at_sensitivity: 1.0000 - recall: 0.9171 - precision: 0.9599\n",
            "Epoch 211: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 196ms/step - loss: 0.1539 - accuracy: 0.9395 - sensitivity_at_specificity: 0.9977 - specificity_at_sensitivity: 1.0000 - recall: 0.9171 - precision: 0.9599 - val_loss: 0.8577 - val_accuracy: 0.8062 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8909 - val_recall: 0.9173 - val_precision: 0.7464\n",
            "Epoch 212/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1540 - accuracy: 0.9438 - sensitivity_at_specificity: 0.9968 - specificity_at_sensitivity: 1.0000 - recall: 0.9265 - precision: 0.9583\n",
            "Epoch 212: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 198ms/step - loss: 0.1540 - accuracy: 0.9438 - sensitivity_at_specificity: 0.9968 - specificity_at_sensitivity: 1.0000 - recall: 0.9265 - precision: 0.9583 - val_loss: 0.6348 - val_accuracy: 0.8430 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9246 - val_recall: 0.9287 - val_precision: 0.7849\n",
            "Epoch 213/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1463 - accuracy: 0.9480 - sensitivity_at_specificity: 0.9961 - specificity_at_sensitivity: 1.0000 - recall: 0.9301 - precision: 0.9642\n",
            "Epoch 213: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 197ms/step - loss: 0.1463 - accuracy: 0.9480 - sensitivity_at_specificity: 0.9961 - specificity_at_sensitivity: 1.0000 - recall: 0.9301 - precision: 0.9642 - val_loss: 0.7818 - val_accuracy: 0.8297 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8973 - val_recall: 0.9337 - val_precision: 0.7653\n",
            "Epoch 214/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1516 - accuracy: 0.9387 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9209 - precision: 0.9521\n",
            "Epoch 214: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 200ms/step - loss: 0.1516 - accuracy: 0.9387 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9209 - precision: 0.9521 - val_loss: 0.7455 - val_accuracy: 0.8383 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8995 - val_recall: 0.9321 - val_precision: 0.7825\n",
            "Epoch 215/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1329 - accuracy: 0.9484 - sensitivity_at_specificity: 0.9977 - specificity_at_sensitivity: 1.0000 - recall: 0.9413 - precision: 0.9548\n",
            "Epoch 215: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 204ms/step - loss: 0.1329 - accuracy: 0.9484 - sensitivity_at_specificity: 0.9977 - specificity_at_sensitivity: 1.0000 - recall: 0.9413 - precision: 0.9548 - val_loss: 0.7389 - val_accuracy: 0.8352 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9000 - val_recall: 0.9215 - val_precision: 0.7892\n",
            "Epoch 216/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1288 - accuracy: 0.9502 - sensitivity_at_specificity: 0.9975 - specificity_at_sensitivity: 1.0000 - recall: 0.9355 - precision: 0.9642\n",
            "Epoch 216: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 191ms/step - loss: 0.1288 - accuracy: 0.9502 - sensitivity_at_specificity: 0.9975 - specificity_at_sensitivity: 1.0000 - recall: 0.9355 - precision: 0.9642 - val_loss: 0.7648 - val_accuracy: 0.8352 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9090 - val_recall: 0.9243 - val_precision: 0.7778\n",
            "Epoch 217/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1411 - accuracy: 0.9438 - sensitivity_at_specificity: 0.9961 - specificity_at_sensitivity: 0.9992 - recall: 0.9276 - precision: 0.9590\n",
            "Epoch 217: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 197ms/step - loss: 0.1411 - accuracy: 0.9438 - sensitivity_at_specificity: 0.9961 - specificity_at_sensitivity: 0.9992 - recall: 0.9276 - precision: 0.9590 - val_loss: 0.8186 - val_accuracy: 0.8414 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8808 - val_recall: 0.9543 - val_precision: 0.7766\n",
            "Epoch 218/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1438 - accuracy: 0.9484 - sensitivity_at_specificity: 0.9960 - specificity_at_sensitivity: 0.9992 - recall: 0.9335 - precision: 0.9609\n",
            "Epoch 218: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 204ms/step - loss: 0.1438 - accuracy: 0.9484 - sensitivity_at_specificity: 0.9960 - specificity_at_sensitivity: 0.9992 - recall: 0.9335 - precision: 0.9609 - val_loss: 0.9610 - val_accuracy: 0.8203 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8616 - val_recall: 0.9429 - val_precision: 0.7659\n",
            "Epoch 219/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1550 - accuracy: 0.9395 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9233 - precision: 0.9551\n",
            "Epoch 219: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 202ms/step - loss: 0.1550 - accuracy: 0.9395 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9233 - precision: 0.9551 - val_loss: 0.7195 - val_accuracy: 0.8281 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8949 - val_recall: 0.9233 - val_precision: 0.7798\n",
            "Epoch 220/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1621 - accuracy: 0.9383 - sensitivity_at_specificity: 0.9954 - specificity_at_sensitivity: 0.9992 - recall: 0.9276 - precision: 0.9508\n",
            "Epoch 220: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 197ms/step - loss: 0.1621 - accuracy: 0.9383 - sensitivity_at_specificity: 0.9954 - specificity_at_sensitivity: 0.9992 - recall: 0.9276 - precision: 0.9508 - val_loss: 0.6490 - val_accuracy: 0.8273 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9150 - val_recall: 0.8989 - val_precision: 0.7837\n",
            "Epoch 221/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1519 - accuracy: 0.9445 - sensitivity_at_specificity: 0.9961 - specificity_at_sensitivity: 0.9992 - recall: 0.9244 - precision: 0.9646\n",
            "Epoch 221: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 204ms/step - loss: 0.1519 - accuracy: 0.9445 - sensitivity_at_specificity: 0.9961 - specificity_at_sensitivity: 0.9992 - recall: 0.9244 - precision: 0.9646 - val_loss: 0.7689 - val_accuracy: 0.8133 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8866 - val_recall: 0.8821 - val_precision: 0.7738\n",
            "Epoch 222/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1329 - accuracy: 0.9460 - sensitivity_at_specificity: 0.9975 - specificity_at_sensitivity: 1.0000 - recall: 0.9383 - precision: 0.9526\n",
            "Epoch 222: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 196ms/step - loss: 0.1329 - accuracy: 0.9460 - sensitivity_at_specificity: 0.9975 - specificity_at_sensitivity: 1.0000 - recall: 0.9383 - precision: 0.9526 - val_loss: 0.7939 - val_accuracy: 0.8125 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8989 - val_recall: 0.9028 - val_precision: 0.7558\n",
            "Epoch 223/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1386 - accuracy: 0.9492 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 0.9992 - recall: 0.9395 - precision: 0.9601\n",
            "Epoch 223: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 206ms/step - loss: 0.1386 - accuracy: 0.9492 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 0.9992 - recall: 0.9395 - precision: 0.9601 - val_loss: 0.7006 - val_accuracy: 0.8328 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9085 - val_recall: 0.9257 - val_precision: 0.7827\n",
            "Epoch 224/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1392 - accuracy: 0.9445 - sensitivity_at_specificity: 0.9968 - specificity_at_sensitivity: 1.0000 - recall: 0.9227 - precision: 0.9637\n",
            "Epoch 224: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 203ms/step - loss: 0.1392 - accuracy: 0.9445 - sensitivity_at_specificity: 0.9968 - specificity_at_sensitivity: 1.0000 - recall: 0.9227 - precision: 0.9637 - val_loss: 0.7307 - val_accuracy: 0.8375 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9068 - val_recall: 0.9382 - val_precision: 0.7832\n",
            "Epoch 225/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1328 - accuracy: 0.9473 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9384 - precision: 0.9581\n",
            "Epoch 225: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 195ms/step - loss: 0.1328 - accuracy: 0.9473 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9384 - precision: 0.9581 - val_loss: 0.7172 - val_accuracy: 0.8352 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9009 - val_recall: 0.9235 - val_precision: 0.7756\n",
            "Epoch 226/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1399 - accuracy: 0.9484 - sensitivity_at_specificity: 0.9961 - specificity_at_sensitivity: 0.9992 - recall: 0.9322 - precision: 0.9649\n",
            "Epoch 226: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 197ms/step - loss: 0.1399 - accuracy: 0.9484 - sensitivity_at_specificity: 0.9961 - specificity_at_sensitivity: 0.9992 - recall: 0.9322 - precision: 0.9649 - val_loss: 0.7201 - val_accuracy: 0.8344 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 0.9010 - val_recall: 0.9174 - val_precision: 0.7916\n",
            "Epoch 227/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1455 - accuracy: 0.9426 - sensitivity_at_specificity: 0.9976 - specificity_at_sensitivity: 0.9992 - recall: 0.9273 - precision: 0.9552\n",
            "Epoch 227: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 202ms/step - loss: 0.1455 - accuracy: 0.9426 - sensitivity_at_specificity: 0.9976 - specificity_at_sensitivity: 0.9992 - recall: 0.9273 - precision: 0.9552 - val_loss: 0.5539 - val_accuracy: 0.8375 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9409 - val_recall: 0.8901 - val_precision: 0.8043\n",
            "Epoch 228/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1340 - accuracy: 0.9520 - sensitivity_at_specificity: 0.9969 - specificity_at_sensitivity: 1.0000 - recall: 0.9344 - precision: 0.9696\n",
            "Epoch 228: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 197ms/step - loss: 0.1340 - accuracy: 0.9520 - sensitivity_at_specificity: 0.9969 - specificity_at_sensitivity: 1.0000 - recall: 0.9344 - precision: 0.9696 - val_loss: 0.8586 - val_accuracy: 0.8367 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8847 - val_recall: 0.9565 - val_precision: 0.7655\n",
            "Epoch 229/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1402 - accuracy: 0.9535 - sensitivity_at_specificity: 0.9944 - specificity_at_sensitivity: 0.9992 - recall: 0.9387 - precision: 0.9656\n",
            "Epoch 229: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 204ms/step - loss: 0.1402 - accuracy: 0.9535 - sensitivity_at_specificity: 0.9944 - specificity_at_sensitivity: 0.9992 - recall: 0.9387 - precision: 0.9656 - val_loss: 0.8567 - val_accuracy: 0.8203 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8852 - val_recall: 0.9372 - val_precision: 0.7640\n",
            "Epoch 230/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1404 - accuracy: 0.9480 - sensitivity_at_specificity: 0.9977 - specificity_at_sensitivity: 0.9992 - recall: 0.9387 - precision: 0.9586\n",
            "Epoch 230: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 199ms/step - loss: 0.1404 - accuracy: 0.9480 - sensitivity_at_specificity: 0.9977 - specificity_at_sensitivity: 0.9992 - recall: 0.9387 - precision: 0.9586 - val_loss: 0.7341 - val_accuracy: 0.8250 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8927 - val_recall: 0.9365 - val_precision: 0.7678\n",
            "Epoch 231/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1214 - accuracy: 0.9586 - sensitivity_at_specificity: 0.9969 - specificity_at_sensitivity: 1.0000 - recall: 0.9468 - precision: 0.9707\n",
            "Epoch 231: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 197ms/step - loss: 0.1214 - accuracy: 0.9586 - sensitivity_at_specificity: 0.9969 - specificity_at_sensitivity: 1.0000 - recall: 0.9468 - precision: 0.9707 - val_loss: 0.9120 - val_accuracy: 0.8219 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8779 - val_recall: 0.9258 - val_precision: 0.7640\n",
            "Epoch 232/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1345 - accuracy: 0.9492 - sensitivity_at_specificity: 0.9969 - specificity_at_sensitivity: 0.9992 - recall: 0.9303 - precision: 0.9666\n",
            "Epoch 232: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 0.1345 - accuracy: 0.9492 - sensitivity_at_specificity: 0.9969 - specificity_at_sensitivity: 0.9992 - recall: 0.9303 - precision: 0.9666 - val_loss: 0.8135 - val_accuracy: 0.8250 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 0.8986 - val_recall: 0.9091 - val_precision: 0.7815\n",
            "Epoch 233/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1133 - accuracy: 0.9586 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9476 - precision: 0.9663\n",
            "Epoch 233: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 197ms/step - loss: 0.1133 - accuracy: 0.9586 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9476 - precision: 0.9663 - val_loss: 0.8341 - val_accuracy: 0.8391 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8784 - val_recall: 0.9293 - val_precision: 0.7811\n",
            "Epoch 234/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1274 - accuracy: 0.9480 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 0.9992 - recall: 0.9368 - precision: 0.9597\n",
            "Epoch 234: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 199ms/step - loss: 0.1274 - accuracy: 0.9480 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 0.9992 - recall: 0.9368 - precision: 0.9597 - val_loss: 0.7404 - val_accuracy: 0.8414 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9130 - val_recall: 0.9277 - val_precision: 0.7898\n",
            "Epoch 235/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1172 - accuracy: 0.9574 - sensitivity_at_specificity: 0.9977 - specificity_at_sensitivity: 0.9992 - recall: 0.9485 - precision: 0.9683\n",
            "Epoch 235: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 0.1172 - accuracy: 0.9574 - sensitivity_at_specificity: 0.9977 - specificity_at_sensitivity: 0.9992 - recall: 0.9485 - precision: 0.9683 - val_loss: 0.8606 - val_accuracy: 0.8141 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8878 - val_recall: 0.9026 - val_precision: 0.7694\n",
            "Epoch 236/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1262 - accuracy: 0.9493 - sensitivity_at_specificity: 0.9983 - specificity_at_sensitivity: 1.0000 - recall: 0.9280 - precision: 0.9697\n",
            "Epoch 236: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 192ms/step - loss: 0.1262 - accuracy: 0.9493 - sensitivity_at_specificity: 0.9983 - specificity_at_sensitivity: 1.0000 - recall: 0.9280 - precision: 0.9697 - val_loss: 0.7575 - val_accuracy: 0.8445 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9049 - val_recall: 0.9260 - val_precision: 0.7992\n",
            "Epoch 237/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1413 - accuracy: 0.9444 - sensitivity_at_specificity: 0.9991 - specificity_at_sensitivity: 0.9992 - recall: 0.9267 - precision: 0.9577\n",
            "Epoch 237: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 192ms/step - loss: 0.1413 - accuracy: 0.9444 - sensitivity_at_specificity: 0.9991 - specificity_at_sensitivity: 0.9992 - recall: 0.9267 - precision: 0.9577 - val_loss: 0.6557 - val_accuracy: 0.8258 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 0.9036 - val_recall: 0.9057 - val_precision: 0.7908\n",
            "Epoch 238/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1156 - accuracy: 0.9520 - sensitivity_at_specificity: 0.9976 - specificity_at_sensitivity: 0.9992 - recall: 0.9392 - precision: 0.9615\n",
            "Epoch 238: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 202ms/step - loss: 0.1156 - accuracy: 0.9520 - sensitivity_at_specificity: 0.9976 - specificity_at_sensitivity: 0.9992 - recall: 0.9392 - precision: 0.9615 - val_loss: 0.9370 - val_accuracy: 0.8250 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8540 - val_recall: 0.9354 - val_precision: 0.7696\n",
            "Epoch 239/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1247 - accuracy: 0.9480 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9992 - recall: 0.9322 - precision: 0.9630\n",
            "Epoch 239: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 203ms/step - loss: 0.1247 - accuracy: 0.9480 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9992 - recall: 0.9322 - precision: 0.9630 - val_loss: 0.9476 - val_accuracy: 0.8305 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8612 - val_recall: 0.9660 - val_precision: 0.7525\n",
            "Epoch 240/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1098 - accuracy: 0.9586 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9504 - precision: 0.9681\n",
            "Epoch 240: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 199ms/step - loss: 0.1098 - accuracy: 0.9586 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9504 - precision: 0.9681 - val_loss: 0.8654 - val_accuracy: 0.8516 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8508 - val_recall: 0.9567 - val_precision: 0.7993\n",
            "Epoch 241/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1241 - accuracy: 0.9512 - sensitivity_at_specificity: 0.9969 - specificity_at_sensitivity: 0.9992 - recall: 0.9439 - precision: 0.9594\n",
            "Epoch 241: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 197ms/step - loss: 0.1241 - accuracy: 0.9512 - sensitivity_at_specificity: 0.9969 - specificity_at_sensitivity: 0.9992 - recall: 0.9439 - precision: 0.9594 - val_loss: 0.8970 - val_accuracy: 0.8180 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8764 - val_recall: 0.9353 - val_precision: 0.7607\n",
            "Epoch 242/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1233 - accuracy: 0.9504 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 0.9992 - recall: 0.9431 - precision: 0.9586\n",
            "Epoch 242: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 200ms/step - loss: 0.1233 - accuracy: 0.9504 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 0.9992 - recall: 0.9431 - precision: 0.9586 - val_loss: 0.8848 - val_accuracy: 0.8203 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8787 - val_recall: 0.9504 - val_precision: 0.7559\n",
            "Epoch 243/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1011 - accuracy: 0.9629 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9580 - precision: 0.9678\n",
            "Epoch 243: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 200ms/step - loss: 0.1011 - accuracy: 0.9629 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9580 - precision: 0.9678 - val_loss: 0.8532 - val_accuracy: 0.8344 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8907 - val_recall: 0.9243 - val_precision: 0.7767\n",
            "Epoch 244/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1120 - accuracy: 0.9539 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9992 - recall: 0.9376 - precision: 0.9670\n",
            "Epoch 244: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 200ms/step - loss: 0.1120 - accuracy: 0.9539 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9992 - recall: 0.9376 - precision: 0.9670 - val_loss: 0.6942 - val_accuracy: 0.8211 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9187 - val_recall: 0.8882 - val_precision: 0.7880\n",
            "Epoch 245/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1328 - accuracy: 0.9502 - sensitivity_at_specificity: 0.9975 - specificity_at_sensitivity: 0.9992 - recall: 0.9408 - precision: 0.9584\n",
            "Epoch 245: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 208ms/step - loss: 0.1328 - accuracy: 0.9502 - sensitivity_at_specificity: 0.9975 - specificity_at_sensitivity: 0.9992 - recall: 0.9408 - precision: 0.9584 - val_loss: 0.8513 - val_accuracy: 0.8203 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8842 - val_recall: 0.9203 - val_precision: 0.7577\n",
            "Epoch 246/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1157 - accuracy: 0.9563 - sensitivity_at_specificity: 0.9968 - specificity_at_sensitivity: 0.9985 - recall: 0.9495 - precision: 0.9617\n",
            "Epoch 246: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 0.1157 - accuracy: 0.9563 - sensitivity_at_specificity: 0.9968 - specificity_at_sensitivity: 0.9985 - recall: 0.9495 - precision: 0.9617 - val_loss: 0.7619 - val_accuracy: 0.8273 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8958 - val_recall: 0.8979 - val_precision: 0.7927\n",
            "Epoch 247/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1169 - accuracy: 0.9527 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 1.0000 - recall: 0.9424 - precision: 0.9651\n",
            "Epoch 247: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 198ms/step - loss: 0.1169 - accuracy: 0.9527 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 1.0000 - recall: 0.9424 - precision: 0.9651 - val_loss: 0.7975 - val_accuracy: 0.8266 - val_sensitivity_at_specificity: 0.9983 - val_specificity_at_sensitivity: 0.8996 - val_recall: 0.9420 - val_precision: 0.7523\n",
            "Epoch 248/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1193 - accuracy: 0.9535 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 1.0000 - recall: 0.9468 - precision: 0.9622\n",
            "Epoch 248: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 0.1193 - accuracy: 0.9535 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 1.0000 - recall: 0.9468 - precision: 0.9622 - val_loss: 0.9178 - val_accuracy: 0.8258 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8685 - val_recall: 0.9460 - val_precision: 0.7526\n",
            "Epoch 249/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1194 - accuracy: 0.9539 - sensitivity_at_specificity: 0.9976 - specificity_at_sensitivity: 0.9992 - recall: 0.9329 - precision: 0.9717\n",
            "Epoch 249: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 204ms/step - loss: 0.1194 - accuracy: 0.9539 - sensitivity_at_specificity: 0.9976 - specificity_at_sensitivity: 0.9992 - recall: 0.9329 - precision: 0.9717 - val_loss: 1.1311 - val_accuracy: 0.8180 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 0.8218 - val_recall: 0.9489 - val_precision: 0.7540\n",
            "Epoch 250/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1181 - accuracy: 0.9555 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9472 - precision: 0.9636\n",
            "Epoch 250: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 200ms/step - loss: 0.1181 - accuracy: 0.9555 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9472 - precision: 0.9636 - val_loss: 0.8654 - val_accuracy: 0.8352 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8891 - val_recall: 0.9445 - val_precision: 0.7659\n",
            "Epoch 251/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1037 - accuracy: 0.9578 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9481 - precision: 0.9650\n",
            "Epoch 251: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 204ms/step - loss: 0.1037 - accuracy: 0.9578 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9481 - precision: 0.9650 - val_loss: 0.9500 - val_accuracy: 0.8273 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8556 - val_recall: 0.9421 - val_precision: 0.7601\n",
            "Epoch 252/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1114 - accuracy: 0.9566 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9427 - precision: 0.9669\n",
            "Epoch 252: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 209ms/step - loss: 0.1114 - accuracy: 0.9566 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9427 - precision: 0.9669 - val_loss: 0.7745 - val_accuracy: 0.8414 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.9053 - val_recall: 0.9408 - val_precision: 0.7798\n",
            "Epoch 253/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1014 - accuracy: 0.9652 - sensitivity_at_specificity: 0.9977 - specificity_at_sensitivity: 1.0000 - recall: 0.9525 - precision: 0.9776\n",
            "Epoch 253: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 202ms/step - loss: 0.1014 - accuracy: 0.9652 - sensitivity_at_specificity: 0.9977 - specificity_at_sensitivity: 1.0000 - recall: 0.9525 - precision: 0.9776 - val_loss: 1.0899 - val_accuracy: 0.8133 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8476 - val_recall: 0.9503 - val_precision: 0.7403\n",
            "Epoch 254/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1054 - accuracy: 0.9574 - sensitivity_at_specificity: 0.9977 - specificity_at_sensitivity: 1.0000 - recall: 0.9487 - precision: 0.9672\n",
            "Epoch 254: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 206ms/step - loss: 0.1054 - accuracy: 0.9574 - sensitivity_at_specificity: 0.9977 - specificity_at_sensitivity: 1.0000 - recall: 0.9487 - precision: 0.9672 - val_loss: 1.0389 - val_accuracy: 0.8328 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.8458 - val_recall: 0.9545 - val_precision: 0.7670\n",
            "Epoch 255/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1045 - accuracy: 0.9602 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9554 - precision: 0.9658\n",
            "Epoch 255: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 203ms/step - loss: 0.1045 - accuracy: 0.9602 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9554 - precision: 0.9658 - val_loss: 0.9471 - val_accuracy: 0.8391 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8558 - val_recall: 0.9470 - val_precision: 0.7795\n",
            "Epoch 256/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1251 - accuracy: 0.9504 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9992 - recall: 0.9409 - precision: 0.9595\n",
            "Epoch 256: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 205ms/step - loss: 0.1251 - accuracy: 0.9504 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9992 - recall: 0.9409 - precision: 0.9595 - val_loss: 0.8356 - val_accuracy: 0.8492 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8784 - val_recall: 0.9614 - val_precision: 0.7873\n",
            "Epoch 257/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1027 - accuracy: 0.9586 - sensitivity_at_specificity: 0.9969 - specificity_at_sensitivity: 1.0000 - recall: 0.9505 - precision: 0.9657\n",
            "Epoch 257: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 202ms/step - loss: 0.1027 - accuracy: 0.9586 - sensitivity_at_specificity: 0.9969 - specificity_at_sensitivity: 1.0000 - recall: 0.9505 - precision: 0.9657 - val_loss: 1.0093 - val_accuracy: 0.8313 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8452 - val_recall: 0.9527 - val_precision: 0.7646\n",
            "Epoch 258/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1233 - accuracy: 0.9570 - sensitivity_at_specificity: 0.9961 - specificity_at_sensitivity: 1.0000 - recall: 0.9461 - precision: 0.9672\n",
            "Epoch 258: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 0.1233 - accuracy: 0.9570 - sensitivity_at_specificity: 0.9961 - specificity_at_sensitivity: 1.0000 - recall: 0.9461 - precision: 0.9672 - val_loss: 1.0242 - val_accuracy: 0.8289 - val_sensitivity_at_specificity: 0.9983 - val_specificity_at_sensitivity: 0.8603 - val_recall: 0.9467 - val_precision: 0.7523\n",
            "Epoch 259/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1131 - accuracy: 0.9621 - sensitivity_at_specificity: 0.9977 - specificity_at_sensitivity: 0.9992 - recall: 0.9483 - precision: 0.9762\n",
            "Epoch 259: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 206ms/step - loss: 0.1131 - accuracy: 0.9621 - sensitivity_at_specificity: 0.9977 - specificity_at_sensitivity: 0.9992 - recall: 0.9483 - precision: 0.9762 - val_loss: 0.9885 - val_accuracy: 0.8391 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8639 - val_recall: 0.9614 - val_precision: 0.7749\n",
            "Epoch 260/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1060 - accuracy: 0.9586 - sensitivity_at_specificity: 0.9976 - specificity_at_sensitivity: 1.0000 - recall: 0.9454 - precision: 0.9688\n",
            "Epoch 260: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 204ms/step - loss: 0.1060 - accuracy: 0.9586 - sensitivity_at_specificity: 0.9976 - specificity_at_sensitivity: 1.0000 - recall: 0.9454 - precision: 0.9688 - val_loss: 0.8030 - val_accuracy: 0.8227 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.8985 - val_recall: 0.9175 - val_precision: 0.7676\n",
            "Epoch 261/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0938 - accuracy: 0.9711 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9605 - precision: 0.9795\n",
            "Epoch 261: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 0.0938 - accuracy: 0.9711 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9605 - precision: 0.9795 - val_loss: 0.9515 - val_accuracy: 0.8352 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8655 - val_recall: 0.9510 - val_precision: 0.7698\n",
            "Epoch 262/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1126 - accuracy: 0.9563 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9992 - recall: 0.9505 - precision: 0.9611\n",
            "Epoch 262: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 200ms/step - loss: 0.1126 - accuracy: 0.9563 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9992 - recall: 0.9505 - precision: 0.9611 - val_loss: 0.7471 - val_accuracy: 0.8266 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8910 - val_recall: 0.9088 - val_precision: 0.7830\n",
            "Epoch 263/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1185 - accuracy: 0.9564 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9481 - precision: 0.9661\n",
            "Epoch 263: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 193ms/step - loss: 0.1185 - accuracy: 0.9564 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9481 - precision: 0.9661 - val_loss: 0.7859 - val_accuracy: 0.8391 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8849 - val_recall: 0.9309 - val_precision: 0.7854\n",
            "Epoch 264/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1151 - accuracy: 0.9582 - sensitivity_at_specificity: 0.9944 - specificity_at_sensitivity: 1.0000 - recall: 0.9484 - precision: 0.9660\n",
            "Epoch 264: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 0.1151 - accuracy: 0.9582 - sensitivity_at_specificity: 0.9944 - specificity_at_sensitivity: 1.0000 - recall: 0.9484 - precision: 0.9660 - val_loss: 0.9215 - val_accuracy: 0.8289 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8618 - val_recall: 0.9450 - val_precision: 0.7656\n",
            "Epoch 265/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1038 - accuracy: 0.9566 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9468 - precision: 0.9631\n",
            "Epoch 265: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 0.1038 - accuracy: 0.9566 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9468 - precision: 0.9631 - val_loss: 0.9353 - val_accuracy: 0.8406 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8571 - val_recall: 0.9631 - val_precision: 0.7849\n",
            "Epoch 266/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1111 - accuracy: 0.9574 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9985 - recall: 0.9468 - precision: 0.9660\n",
            "Epoch 266: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 199ms/step - loss: 0.1111 - accuracy: 0.9574 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9985 - recall: 0.9468 - precision: 0.9660 - val_loss: 1.0371 - val_accuracy: 0.8391 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 0.8400 - val_recall: 0.9496 - val_precision: 0.7824\n",
            "Epoch 267/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0939 - accuracy: 0.9637 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 0.9992 - recall: 0.9544 - precision: 0.9732\n",
            "Epoch 267: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 200ms/step - loss: 0.0939 - accuracy: 0.9637 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 0.9992 - recall: 0.9544 - precision: 0.9732 - val_loss: 0.9647 - val_accuracy: 0.8328 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.8680 - val_recall: 0.9403 - val_precision: 0.7726\n",
            "Epoch 268/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1190 - accuracy: 0.9516 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9446 - precision: 0.9580\n",
            "Epoch 268: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 204ms/step - loss: 0.1190 - accuracy: 0.9516 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9446 - precision: 0.9580 - val_loss: 0.8757 - val_accuracy: 0.8305 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8700 - val_recall: 0.9476 - val_precision: 0.7707\n",
            "Epoch 269/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0974 - accuracy: 0.9641 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9548 - precision: 0.9691\n",
            "Epoch 269: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 199ms/step - loss: 0.0974 - accuracy: 0.9641 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9548 - precision: 0.9691 - val_loss: 0.8583 - val_accuracy: 0.8492 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8627 - val_recall: 0.9410 - val_precision: 0.8015\n",
            "Epoch 270/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1080 - accuracy: 0.9630 - sensitivity_at_specificity: 0.9975 - specificity_at_sensitivity: 1.0000 - recall: 0.9484 - precision: 0.9781\n",
            "Epoch 270: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 192ms/step - loss: 0.1080 - accuracy: 0.9630 - sensitivity_at_specificity: 0.9975 - specificity_at_sensitivity: 1.0000 - recall: 0.9484 - precision: 0.9781 - val_loss: 0.8464 - val_accuracy: 0.8430 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 0.8780 - val_recall: 0.9461 - val_precision: 0.7872\n",
            "Epoch 271/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1037 - accuracy: 0.9617 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 0.9984 - recall: 0.9572 - precision: 0.9689\n",
            "Epoch 271: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 0.1037 - accuracy: 0.9617 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 0.9984 - recall: 0.9572 - precision: 0.9689 - val_loss: 0.8557 - val_accuracy: 0.8359 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8885 - val_recall: 0.9369 - val_precision: 0.7775\n",
            "Epoch 272/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0884 - accuracy: 0.9691 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 0.9992 - recall: 0.9626 - precision: 0.9767\n",
            "Epoch 272: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 202ms/step - loss: 0.0884 - accuracy: 0.9691 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 0.9992 - recall: 0.9626 - precision: 0.9767 - val_loss: 1.2856 - val_accuracy: 0.8180 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8142 - val_recall: 0.9563 - val_precision: 0.7415\n",
            "Epoch 273/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0941 - accuracy: 0.9660 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9561 - precision: 0.9752\n",
            "Epoch 273: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 206ms/step - loss: 0.0941 - accuracy: 0.9660 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9561 - precision: 0.9752 - val_loss: 0.8766 - val_accuracy: 0.8281 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8859 - val_recall: 0.9397 - val_precision: 0.7592\n",
            "Epoch 274/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0874 - accuracy: 0.9699 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9685 - precision: 0.9693\n",
            "Epoch 274: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 205ms/step - loss: 0.0874 - accuracy: 0.9699 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9685 - precision: 0.9693 - val_loss: 0.9590 - val_accuracy: 0.8219 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8683 - val_recall: 0.9199 - val_precision: 0.7588\n",
            "Epoch 275/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1245 - accuracy: 0.9551 - sensitivity_at_specificity: 0.9962 - specificity_at_sensitivity: 0.9992 - recall: 0.9430 - precision: 0.9699\n",
            "Epoch 275: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 0.1245 - accuracy: 0.9551 - sensitivity_at_specificity: 0.9962 - specificity_at_sensitivity: 0.9992 - recall: 0.9430 - precision: 0.9699 - val_loss: 0.8721 - val_accuracy: 0.8344 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8619 - val_recall: 0.9611 - val_precision: 0.7677\n",
            "Epoch 276/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0966 - accuracy: 0.9639 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9580 - precision: 0.9700\n",
            "Epoch 276: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 190ms/step - loss: 0.0966 - accuracy: 0.9639 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9580 - precision: 0.9700 - val_loss: 0.9446 - val_accuracy: 0.8305 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8690 - val_recall: 0.9390 - val_precision: 0.7712\n",
            "Epoch 277/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0995 - accuracy: 0.9613 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 0.9992 - recall: 0.9521 - precision: 0.9708\n",
            "Epoch 277: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 198ms/step - loss: 0.0995 - accuracy: 0.9613 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 0.9992 - recall: 0.9521 - precision: 0.9708 - val_loss: 0.9577 - val_accuracy: 0.8422 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 0.8610 - val_recall: 0.9583 - val_precision: 0.7799\n",
            "Epoch 278/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0907 - accuracy: 0.9668 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9992 - recall: 0.9537 - precision: 0.9791\n",
            "Epoch 278: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 200ms/step - loss: 0.0907 - accuracy: 0.9668 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9992 - recall: 0.9537 - precision: 0.9791 - val_loss: 1.0222 - val_accuracy: 0.8227 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8304 - val_recall: 0.9414 - val_precision: 0.7638\n",
            "Epoch 279/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1008 - accuracy: 0.9641 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 1.0000 - recall: 0.9607 - precision: 0.9695\n",
            "Epoch 279: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 199ms/step - loss: 0.1008 - accuracy: 0.9641 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 1.0000 - recall: 0.9607 - precision: 0.9695 - val_loss: 0.7816 - val_accuracy: 0.8477 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8970 - val_recall: 0.9171 - val_precision: 0.8049\n",
            "Epoch 280/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0896 - accuracy: 0.9688 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9591 - precision: 0.9788\n",
            "Epoch 280: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 199ms/step - loss: 0.0896 - accuracy: 0.9688 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9591 - precision: 0.9788 - val_loss: 1.1953 - val_accuracy: 0.8336 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.8203 - val_recall: 0.9571 - val_precision: 0.7640\n",
            "Epoch 281/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1207 - accuracy: 0.9531 - sensitivity_at_specificity: 0.9969 - specificity_at_sensitivity: 0.9984 - recall: 0.9441 - precision: 0.9633\n",
            "Epoch 281: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 202ms/step - loss: 0.1207 - accuracy: 0.9531 - sensitivity_at_specificity: 0.9969 - specificity_at_sensitivity: 0.9984 - recall: 0.9441 - precision: 0.9633 - val_loss: 1.0693 - val_accuracy: 0.8281 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8502 - val_recall: 0.9521 - val_precision: 0.7583\n",
            "Epoch 282/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1159 - accuracy: 0.9586 - sensitivity_at_specificity: 0.9969 - specificity_at_sensitivity: 0.9992 - recall: 0.9516 - precision: 0.9665\n",
            "Epoch 282: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 0.1159 - accuracy: 0.9586 - sensitivity_at_specificity: 0.9969 - specificity_at_sensitivity: 0.9992 - recall: 0.9516 - precision: 0.9665 - val_loss: 1.0688 - val_accuracy: 0.8375 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8428 - val_recall: 0.9572 - val_precision: 0.7694\n",
            "Epoch 283/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0968 - accuracy: 0.9637 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9992 - recall: 0.9474 - precision: 0.9778\n",
            "Epoch 283: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 204ms/step - loss: 0.0968 - accuracy: 0.9637 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9992 - recall: 0.9474 - precision: 0.9778 - val_loss: 0.7917 - val_accuracy: 0.8422 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 0.8784 - val_recall: 0.9412 - val_precision: 0.7929\n",
            "Epoch 284/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0842 - accuracy: 0.9652 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9621 - precision: 0.9675\n",
            "Epoch 284: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 202ms/step - loss: 0.0842 - accuracy: 0.9652 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9621 - precision: 0.9675 - val_loss: 0.9862 - val_accuracy: 0.8289 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 0.8601 - val_recall: 0.9255 - val_precision: 0.7818\n",
            "Epoch 285/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0990 - accuracy: 0.9613 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9532 - precision: 0.9664\n",
            "Epoch 285: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 200ms/step - loss: 0.0990 - accuracy: 0.9613 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9532 - precision: 0.9664 - val_loss: 0.8593 - val_accuracy: 0.8352 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.8684 - val_recall: 0.9479 - val_precision: 0.7715\n",
            "Epoch 286/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0925 - accuracy: 0.9676 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9589 - precision: 0.9775\n",
            "Epoch 286: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 205ms/step - loss: 0.0925 - accuracy: 0.9676 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9589 - precision: 0.9775 - val_loss: 0.9683 - val_accuracy: 0.8430 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8418 - val_recall: 0.9614 - val_precision: 0.7797\n",
            "Epoch 287/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0928 - accuracy: 0.9660 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9985 - recall: 0.9610 - precision: 0.9695\n",
            "Epoch 287: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 204ms/step - loss: 0.0928 - accuracy: 0.9660 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9985 - recall: 0.9610 - precision: 0.9695 - val_loss: 1.0174 - val_accuracy: 0.8461 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 0.8369 - val_recall: 0.9520 - val_precision: 0.7937\n",
            "Epoch 288/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0860 - accuracy: 0.9656 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9510 - precision: 0.9800\n",
            "Epoch 288: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 199ms/step - loss: 0.0860 - accuracy: 0.9656 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9510 - precision: 0.9800 - val_loss: 1.0396 - val_accuracy: 0.8297 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8336 - val_recall: 0.9607 - val_precision: 0.7678\n",
            "Epoch 289/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0970 - accuracy: 0.9609 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9531 - precision: 0.9670\n",
            "Epoch 289: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 0.0970 - accuracy: 0.9609 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9531 - precision: 0.9670 - val_loss: 1.0809 - val_accuracy: 0.8234 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8360 - val_recall: 0.9494 - val_precision: 0.7623\n",
            "Epoch 290/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0793 - accuracy: 0.9699 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9636 - precision: 0.9777\n",
            "Epoch 290: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 199ms/step - loss: 0.0793 - accuracy: 0.9699 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9636 - precision: 0.9777 - val_loss: 0.9808 - val_accuracy: 0.8445 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.8670 - val_recall: 0.9532 - val_precision: 0.7833\n",
            "Epoch 291/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0974 - accuracy: 0.9641 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9613 - precision: 0.9673\n",
            "Epoch 291: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 199ms/step - loss: 0.0974 - accuracy: 0.9641 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9613 - precision: 0.9673 - val_loss: 0.9294 - val_accuracy: 0.8180 - val_sensitivity_at_specificity: 0.9968 - val_specificity_at_sensitivity: 0.8863 - val_recall: 0.9141 - val_precision: 0.7626\n",
            "Epoch 292/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0853 - accuracy: 0.9680 - sensitivity_at_specificity: 0.9977 - specificity_at_sensitivity: 1.0000 - recall: 0.9577 - precision: 0.9788\n",
            "Epoch 292: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 202ms/step - loss: 0.0853 - accuracy: 0.9680 - sensitivity_at_specificity: 0.9977 - specificity_at_sensitivity: 1.0000 - recall: 0.9577 - precision: 0.9788 - val_loss: 1.0897 - val_accuracy: 0.8203 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8593 - val_recall: 0.9370 - val_precision: 0.7523\n",
            "Epoch 293/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1076 - accuracy: 0.9633 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9969 - recall: 0.9568 - precision: 0.9677\n",
            "Epoch 293: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 204ms/step - loss: 0.1076 - accuracy: 0.9633 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9969 - recall: 0.9568 - precision: 0.9677 - val_loss: 0.9495 - val_accuracy: 0.8320 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.8679 - val_recall: 0.9379 - val_precision: 0.7754\n",
            "Epoch 294/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0955 - accuracy: 0.9637 - sensitivity_at_specificity: 0.9993 - specificity_at_sensitivity: 1.0000 - recall: 0.9544 - precision: 0.9755\n",
            "Epoch 294: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 205ms/step - loss: 0.0955 - accuracy: 0.9637 - sensitivity_at_specificity: 0.9993 - specificity_at_sensitivity: 1.0000 - recall: 0.9544 - precision: 0.9755 - val_loss: 1.0252 - val_accuracy: 0.8273 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8462 - val_recall: 0.9611 - val_precision: 0.7592\n",
            "Epoch 295/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0705 - accuracy: 0.9738 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9661 - precision: 0.9831\n",
            "Epoch 295: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 202ms/step - loss: 0.0705 - accuracy: 0.9738 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9661 - precision: 0.9831 - val_loss: 1.0023 - val_accuracy: 0.8500 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8533 - val_recall: 0.9644 - val_precision: 0.7866\n",
            "Epoch 296/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1004 - accuracy: 0.9656 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9977 - recall: 0.9558 - precision: 0.9743\n",
            "Epoch 296: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 204ms/step - loss: 0.1004 - accuracy: 0.9656 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9977 - recall: 0.9558 - precision: 0.9743 - val_loss: 0.9807 - val_accuracy: 0.8398 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8571 - val_recall: 0.9580 - val_precision: 0.7758\n",
            "Epoch 297/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0958 - accuracy: 0.9598 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9558 - precision: 0.9612\n",
            "Epoch 297: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 200ms/step - loss: 0.0958 - accuracy: 0.9598 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9558 - precision: 0.9612 - val_loss: 0.9387 - val_accuracy: 0.8375 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8675 - val_recall: 0.9365 - val_precision: 0.7837\n",
            "Epoch 298/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0819 - accuracy: 0.9641 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9534 - precision: 0.9746\n",
            "Epoch 298: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 0.0819 - accuracy: 0.9641 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9534 - precision: 0.9746 - val_loss: 0.9745 - val_accuracy: 0.8477 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8578 - val_recall: 0.9598 - val_precision: 0.7861\n",
            "Epoch 299/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0838 - accuracy: 0.9688 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9648 - precision: 0.9724\n",
            "Epoch 299: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 199ms/step - loss: 0.0838 - accuracy: 0.9688 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9648 - precision: 0.9724 - val_loss: 0.9834 - val_accuracy: 0.8141 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 0.8611 - val_recall: 0.9092 - val_precision: 0.7715\n",
            "Epoch 300/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0785 - accuracy: 0.9723 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9669 - precision: 0.9794\n",
            "Epoch 300: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 206ms/step - loss: 0.0785 - accuracy: 0.9723 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9669 - precision: 0.9794 - val_loss: 1.1340 - val_accuracy: 0.8281 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8400 - val_recall: 0.9508 - val_precision: 0.7602\n",
            "Epoch 301/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0972 - accuracy: 0.9637 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9521 - precision: 0.9719\n",
            "Epoch 301: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 200ms/step - loss: 0.0972 - accuracy: 0.9637 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9521 - precision: 0.9719 - val_loss: 1.0633 - val_accuracy: 0.8141 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8539 - val_recall: 0.9454 - val_precision: 0.7427\n",
            "Epoch 302/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0757 - accuracy: 0.9734 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9696 - precision: 0.9776\n",
            "Epoch 302: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 190ms/step - loss: 0.0757 - accuracy: 0.9734 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9696 - precision: 0.9776 - val_loss: 0.9069 - val_accuracy: 0.8445 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8635 - val_recall: 0.9523 - val_precision: 0.7865\n",
            "Epoch 303/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0832 - accuracy: 0.9709 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9611 - precision: 0.9793\n",
            "Epoch 303: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 193ms/step - loss: 0.0832 - accuracy: 0.9709 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9611 - precision: 0.9793 - val_loss: 1.0024 - val_accuracy: 0.8398 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8593 - val_recall: 0.9657 - val_precision: 0.7626\n",
            "Epoch 304/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0719 - accuracy: 0.9762 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9746 - precision: 0.9783\n",
            "Epoch 304: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 199ms/step - loss: 0.0719 - accuracy: 0.9762 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9746 - precision: 0.9783 - val_loss: 1.0465 - val_accuracy: 0.8523 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8434 - val_recall: 0.9685 - val_precision: 0.7936\n",
            "Epoch 305/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0784 - accuracy: 0.9715 - sensitivity_at_specificity: 0.9969 - specificity_at_sensitivity: 1.0000 - recall: 0.9612 - precision: 0.9818\n",
            "Epoch 305: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 200ms/step - loss: 0.0784 - accuracy: 0.9715 - sensitivity_at_specificity: 0.9969 - specificity_at_sensitivity: 1.0000 - recall: 0.9612 - precision: 0.9818 - val_loss: 1.2292 - val_accuracy: 0.8242 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.8227 - val_recall: 0.9498 - val_precision: 0.7581\n",
            "Epoch 306/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0639 - accuracy: 0.9781 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9767 - precision: 0.9782\n",
            "Epoch 306: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 198ms/step - loss: 0.0639 - accuracy: 0.9781 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9767 - precision: 0.9782 - val_loss: 1.0562 - val_accuracy: 0.8352 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.8495 - val_recall: 0.9393 - val_precision: 0.7781\n",
            "Epoch 307/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0807 - accuracy: 0.9709 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9610 - precision: 0.9793\n",
            "Epoch 307: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 190ms/step - loss: 0.0807 - accuracy: 0.9709 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9610 - precision: 0.9793 - val_loss: 1.1984 - val_accuracy: 0.8320 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8349 - val_recall: 0.9639 - val_precision: 0.7621\n",
            "Epoch 308/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0779 - accuracy: 0.9695 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9615 - precision: 0.9769\n",
            "Epoch 308: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 202ms/step - loss: 0.0779 - accuracy: 0.9695 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9615 - precision: 0.9769 - val_loss: 1.2272 - val_accuracy: 0.8273 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.8343 - val_recall: 0.9646 - val_precision: 0.7509\n",
            "Epoch 309/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0883 - accuracy: 0.9684 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9625 - precision: 0.9726\n",
            "Epoch 309: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 200ms/step - loss: 0.0883 - accuracy: 0.9684 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9625 - precision: 0.9726 - val_loss: 0.9400 - val_accuracy: 0.8367 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8658 - val_recall: 0.9480 - val_precision: 0.7799\n",
            "Epoch 310/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0821 - accuracy: 0.9711 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9644 - precision: 0.9792\n",
            "Epoch 310: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 0.0821 - accuracy: 0.9711 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9644 - precision: 0.9792 - val_loss: 1.1946 - val_accuracy: 0.8219 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8141 - val_recall: 0.9703 - val_precision: 0.7482\n",
            "Epoch 311/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0769 - accuracy: 0.9699 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9627 - precision: 0.9771\n",
            "Epoch 311: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 199ms/step - loss: 0.0769 - accuracy: 0.9699 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9627 - precision: 0.9771 - val_loss: 1.0606 - val_accuracy: 0.8242 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.8526 - val_recall: 0.9437 - val_precision: 0.7555\n",
            "Epoch 312/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0796 - accuracy: 0.9719 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9602 - precision: 0.9832\n",
            "Epoch 312: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 0.0796 - accuracy: 0.9719 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9602 - precision: 0.9832 - val_loss: 1.2979 - val_accuracy: 0.8242 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8058 - val_recall: 0.9650 - val_precision: 0.7584\n",
            "Epoch 313/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0699 - accuracy: 0.9754 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9721 - precision: 0.9776\n",
            "Epoch 313: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 206ms/step - loss: 0.0699 - accuracy: 0.9754 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9721 - precision: 0.9776 - val_loss: 1.0801 - val_accuracy: 0.8281 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.8525 - val_recall: 0.9332 - val_precision: 0.7673\n",
            "Epoch 314/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0754 - accuracy: 0.9723 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9627 - precision: 0.9818\n",
            "Epoch 314: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 0.0754 - accuracy: 0.9723 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9627 - precision: 0.9818 - val_loss: 1.2643 - val_accuracy: 0.8203 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8254 - val_recall: 0.9537 - val_precision: 0.7484\n",
            "Epoch 315/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0751 - accuracy: 0.9758 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9686 - precision: 0.9825\n",
            "Epoch 315: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 200ms/step - loss: 0.0751 - accuracy: 0.9758 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9686 - precision: 0.9825 - val_loss: 1.1846 - val_accuracy: 0.8297 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8310 - val_recall: 0.9666 - val_precision: 0.7553\n",
            "Epoch 316/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0728 - accuracy: 0.9727 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9976 - recall: 0.9669 - precision: 0.9789\n",
            "Epoch 316: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 205ms/step - loss: 0.0728 - accuracy: 0.9727 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9976 - recall: 0.9669 - precision: 0.9789 - val_loss: 1.0867 - val_accuracy: 0.8297 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8449 - val_recall: 0.9555 - val_precision: 0.7598\n",
            "Epoch 317/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0761 - accuracy: 0.9770 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9692 - precision: 0.9862\n",
            "Epoch 317: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 203ms/step - loss: 0.0761 - accuracy: 0.9770 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9692 - precision: 0.9862 - val_loss: 1.1908 - val_accuracy: 0.8250 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8227 - val_recall: 0.9587 - val_precision: 0.7609\n",
            "Epoch 318/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0737 - accuracy: 0.9754 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9714 - precision: 0.9798\n",
            "Epoch 318: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 199ms/step - loss: 0.0737 - accuracy: 0.9754 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9714 - precision: 0.9798 - val_loss: 1.1998 - val_accuracy: 0.8406 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8313 - val_recall: 0.9578 - val_precision: 0.7759\n",
            "Epoch 319/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0839 - accuracy: 0.9691 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9598 - precision: 0.9787\n",
            "Epoch 319: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 0.0839 - accuracy: 0.9691 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9598 - precision: 0.9787 - val_loss: 1.0821 - val_accuracy: 0.8234 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.8536 - val_recall: 0.9420 - val_precision: 0.7608\n",
            "Epoch 320/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0799 - accuracy: 0.9719 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9655 - precision: 0.9778\n",
            "Epoch 320: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 0.0799 - accuracy: 0.9719 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9655 - precision: 0.9778 - val_loss: 1.1646 - val_accuracy: 0.8344 - val_sensitivity_at_specificity: 0.9967 - val_specificity_at_sensitivity: 0.8529 - val_recall: 0.9544 - val_precision: 0.7610\n",
            "Epoch 321/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0753 - accuracy: 0.9738 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9695 - precision: 0.9779\n",
            "Epoch 321: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 202ms/step - loss: 0.0753 - accuracy: 0.9738 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9695 - precision: 0.9779 - val_loss: 1.2316 - val_accuracy: 0.8336 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8189 - val_recall: 0.9674 - val_precision: 0.7647\n",
            "Epoch 322/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0616 - accuracy: 0.9762 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9660 - precision: 0.9855\n",
            "Epoch 322: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 200ms/step - loss: 0.0616 - accuracy: 0.9762 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9660 - precision: 0.9855 - val_loss: 1.1310 - val_accuracy: 0.8242 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.8362 - val_recall: 0.9457 - val_precision: 0.7625\n",
            "Epoch 323/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0722 - accuracy: 0.9723 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9679 - precision: 0.9763\n",
            "Epoch 323: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 208ms/step - loss: 0.0722 - accuracy: 0.9723 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9679 - precision: 0.9763 - val_loss: 1.1050 - val_accuracy: 0.8359 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 0.8447 - val_recall: 0.9305 - val_precision: 0.7897\n",
            "Epoch 324/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0797 - accuracy: 0.9668 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9610 - precision: 0.9710\n",
            "Epoch 324: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 200ms/step - loss: 0.0797 - accuracy: 0.9668 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9610 - precision: 0.9710 - val_loss: 1.1657 - val_accuracy: 0.8359 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.8318 - val_recall: 0.9665 - val_precision: 0.7620\n",
            "Epoch 325/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0754 - accuracy: 0.9746 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9642 - precision: 0.9849\n",
            "Epoch 325: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 0.0754 - accuracy: 0.9746 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9642 - precision: 0.9849 - val_loss: 0.9810 - val_accuracy: 0.8430 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8585 - val_recall: 0.9601 - val_precision: 0.7812\n",
            "Epoch 326/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0765 - accuracy: 0.9684 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9588 - precision: 0.9754\n",
            "Epoch 326: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 202ms/step - loss: 0.0765 - accuracy: 0.9684 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9588 - precision: 0.9754 - val_loss: 1.1712 - val_accuracy: 0.8242 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8285 - val_recall: 0.9405 - val_precision: 0.7684\n",
            "Epoch 327/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0782 - accuracy: 0.9695 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9673 - precision: 0.9719\n",
            "Epoch 327: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 200ms/step - loss: 0.0782 - accuracy: 0.9695 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9673 - precision: 0.9719 - val_loss: 0.9945 - val_accuracy: 0.8414 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8578 - val_recall: 0.9373 - val_precision: 0.7910\n",
            "Epoch 328/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0745 - accuracy: 0.9738 - sensitivity_at_specificity: 0.9976 - specificity_at_sensitivity: 1.0000 - recall: 0.9636 - precision: 0.9818\n",
            "Epoch 328: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 0.0745 - accuracy: 0.9738 - sensitivity_at_specificity: 0.9976 - specificity_at_sensitivity: 1.0000 - recall: 0.9636 - precision: 0.9818 - val_loss: 1.2526 - val_accuracy: 0.8359 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 0.8285 - val_recall: 0.9562 - val_precision: 0.7776\n",
            "Epoch 329/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0859 - accuracy: 0.9676 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9585 - precision: 0.9761\n",
            "Epoch 329: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 205ms/step - loss: 0.0859 - accuracy: 0.9676 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9585 - precision: 0.9761 - val_loss: 1.2663 - val_accuracy: 0.8227 - val_sensitivity_at_specificity: 0.9983 - val_specificity_at_sensitivity: 0.8191 - val_recall: 0.9533 - val_precision: 0.7419\n",
            "Epoch 330/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0662 - accuracy: 0.9789 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9735 - precision: 0.9830\n",
            "Epoch 330: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 202ms/step - loss: 0.0662 - accuracy: 0.9789 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9735 - precision: 0.9830 - val_loss: 1.0977 - val_accuracy: 0.8344 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8423 - val_recall: 0.9573 - val_precision: 0.7661\n",
            "Epoch 331/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0686 - accuracy: 0.9746 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9728 - precision: 0.9752\n",
            "Epoch 331: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 205ms/step - loss: 0.0686 - accuracy: 0.9746 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9728 - precision: 0.9752 - val_loss: 1.1577 - val_accuracy: 0.8242 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8425 - val_recall: 0.9364 - val_precision: 0.7665\n",
            "Epoch 332/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0667 - accuracy: 0.9746 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9681 - precision: 0.9811\n",
            "Epoch 332: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 204ms/step - loss: 0.0667 - accuracy: 0.9746 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9681 - precision: 0.9811 - val_loss: 1.3843 - val_accuracy: 0.8164 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8034 - val_recall: 0.9606 - val_precision: 0.7436\n",
            "Epoch 333/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0707 - accuracy: 0.9746 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9677 - precision: 0.9832\n",
            "Epoch 333: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 202ms/step - loss: 0.0707 - accuracy: 0.9746 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9677 - precision: 0.9832 - val_loss: 1.1421 - val_accuracy: 0.8453 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8373 - val_recall: 0.9536 - val_precision: 0.7860\n",
            "Epoch 334/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0671 - accuracy: 0.9789 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9748 - precision: 0.9838\n",
            "Epoch 334: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 207ms/step - loss: 0.0671 - accuracy: 0.9789 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9748 - precision: 0.9838 - val_loss: 1.3496 - val_accuracy: 0.8164 - val_sensitivity_at_specificity: 0.9967 - val_specificity_at_sensitivity: 0.8123 - val_recall: 0.9593 - val_precision: 0.7372\n",
            "Epoch 335/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0624 - accuracy: 0.9797 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9731 - precision: 0.9856\n",
            "Epoch 335: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 207ms/step - loss: 0.0624 - accuracy: 0.9797 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9731 - precision: 0.9856 - val_loss: 1.0756 - val_accuracy: 0.8391 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 0.8325 - val_recall: 0.9474 - val_precision: 0.7809\n",
            "Epoch 336/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0776 - accuracy: 0.9762 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9703 - precision: 0.9818\n",
            "Epoch 336: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 202ms/step - loss: 0.0776 - accuracy: 0.9762 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9703 - precision: 0.9818 - val_loss: 1.0632 - val_accuracy: 0.8375 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 0.8537 - val_recall: 0.9453 - val_precision: 0.7834\n",
            "Epoch 337/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0799 - accuracy: 0.9723 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9650 - precision: 0.9769\n",
            "Epoch 337: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 0.0799 - accuracy: 0.9723 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9650 - precision: 0.9769 - val_loss: 1.2781 - val_accuracy: 0.8375 - val_sensitivity_at_specificity: 0.9970 - val_specificity_at_sensitivity: 0.8167 - val_recall: 0.9626 - val_precision: 0.7787\n",
            "Epoch 338/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0698 - accuracy: 0.9746 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9992 - recall: 0.9681 - precision: 0.9811\n",
            "Epoch 338: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 203ms/step - loss: 0.0698 - accuracy: 0.9746 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9992 - recall: 0.9681 - precision: 0.9811 - val_loss: 1.0996 - val_accuracy: 0.8313 - val_sensitivity_at_specificity: 0.9970 - val_specificity_at_sensitivity: 0.8315 - val_recall: 0.9406 - val_precision: 0.7774\n",
            "Epoch 339/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0661 - accuracy: 0.9777 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9703 - precision: 0.9849\n",
            "Epoch 339: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 0.0661 - accuracy: 0.9777 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9703 - precision: 0.9849 - val_loss: 1.2391 - val_accuracy: 0.8242 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8222 - val_recall: 0.9437 - val_precision: 0.7614\n",
            "Epoch 340/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0707 - accuracy: 0.9766 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9737 - precision: 0.9798\n",
            "Epoch 340: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 205ms/step - loss: 0.0707 - accuracy: 0.9766 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9737 - precision: 0.9798 - val_loss: 1.2255 - val_accuracy: 0.8383 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 0.8256 - val_recall: 0.9481 - val_precision: 0.7821\n",
            "Epoch 341/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0796 - accuracy: 0.9703 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9628 - precision: 0.9779\n",
            "Epoch 341: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 203ms/step - loss: 0.0796 - accuracy: 0.9703 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9628 - precision: 0.9779 - val_loss: 1.2573 - val_accuracy: 0.8117 - val_sensitivity_at_specificity: 0.9969 - val_specificity_at_sensitivity: 0.8025 - val_recall: 0.9444 - val_precision: 0.7488\n",
            "Epoch 342/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0779 - accuracy: 0.9711 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9691 - precision: 0.9736\n",
            "Epoch 342: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 207ms/step - loss: 0.0779 - accuracy: 0.9711 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9691 - precision: 0.9736 - val_loss: 1.1023 - val_accuracy: 0.8352 - val_sensitivity_at_specificity: 0.9969 - val_specificity_at_sensitivity: 0.8323 - val_recall: 0.9607 - val_precision: 0.7666\n",
            "Epoch 343/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0708 - accuracy: 0.9766 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9700 - precision: 0.9824\n",
            "Epoch 343: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 204ms/step - loss: 0.0708 - accuracy: 0.9766 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9700 - precision: 0.9824 - val_loss: 1.1252 - val_accuracy: 0.8211 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 0.8379 - val_recall: 0.9513 - val_precision: 0.7603\n",
            "Epoch 344/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0554 - accuracy: 0.9805 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9767 - precision: 0.9844\n",
            "Epoch 344: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 202ms/step - loss: 0.0554 - accuracy: 0.9805 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9767 - precision: 0.9844 - val_loss: 1.1457 - val_accuracy: 0.8406 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 0.8246 - val_recall: 0.9629 - val_precision: 0.7758\n",
            "Epoch 345/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0564 - accuracy: 0.9801 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9773 - precision: 0.9827\n",
            "Epoch 345: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 207ms/step - loss: 0.0564 - accuracy: 0.9801 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9773 - precision: 0.9827 - val_loss: 1.2736 - val_accuracy: 0.8352 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8110 - val_recall: 0.9486 - val_precision: 0.7799\n",
            "Epoch 346/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0758 - accuracy: 0.9746 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 0.9984 - recall: 0.9695 - precision: 0.9807\n",
            "Epoch 346: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 203ms/step - loss: 0.0758 - accuracy: 0.9746 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 0.9984 - recall: 0.9695 - precision: 0.9807 - val_loss: 1.0337 - val_accuracy: 0.8297 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.8452 - val_recall: 0.9401 - val_precision: 0.7680\n",
            "Epoch 347/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0605 - accuracy: 0.9793 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9724 - precision: 0.9856\n",
            "Epoch 347: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 208ms/step - loss: 0.0605 - accuracy: 0.9793 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9724 - precision: 0.9856 - val_loss: 1.2969 - val_accuracy: 0.8211 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.8159 - val_recall: 0.9608 - val_precision: 0.7415\n",
            "Epoch 348/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0630 - accuracy: 0.9766 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9755 - precision: 0.9785\n",
            "Epoch 348: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 200ms/step - loss: 0.0630 - accuracy: 0.9766 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9755 - precision: 0.9785 - val_loss: 0.9028 - val_accuracy: 0.8430 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 0.8607 - val_recall: 0.9313 - val_precision: 0.8053\n",
            "Epoch 349/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0735 - accuracy: 0.9688 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9630 - precision: 0.9750\n",
            "Epoch 349: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 204ms/step - loss: 0.0735 - accuracy: 0.9688 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9630 - precision: 0.9750 - val_loss: 1.1087 - val_accuracy: 0.8227 - val_sensitivity_at_specificity: 0.9968 - val_specificity_at_sensitivity: 0.8426 - val_recall: 0.9304 - val_precision: 0.7626\n",
            "Epoch 350/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0660 - accuracy: 0.9762 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9716 - precision: 0.9814\n",
            "Epoch 350: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 200ms/step - loss: 0.0660 - accuracy: 0.9762 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9716 - precision: 0.9814 - val_loss: 1.1486 - val_accuracy: 0.8289 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8354 - val_recall: 0.9508 - val_precision: 0.7611\n",
            "Epoch 351/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0659 - accuracy: 0.9770 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9726 - precision: 0.9810\n",
            "Epoch 351: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 0.0659 - accuracy: 0.9770 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9726 - precision: 0.9810 - val_loss: 1.1373 - val_accuracy: 0.8445 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8331 - val_recall: 0.9690 - val_precision: 0.7774\n",
            "Epoch 352/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0700 - accuracy: 0.9754 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9692 - precision: 0.9808\n",
            "Epoch 352: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 199ms/step - loss: 0.0700 - accuracy: 0.9754 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9692 - precision: 0.9808 - val_loss: 1.3285 - val_accuracy: 0.8219 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8169 - val_recall: 0.9540 - val_precision: 0.7513\n",
            "Epoch 353/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0633 - accuracy: 0.9742 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9684 - precision: 0.9817\n",
            "Epoch 353: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 207ms/step - loss: 0.0633 - accuracy: 0.9742 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9684 - precision: 0.9817 - val_loss: 1.2800 - val_accuracy: 0.8414 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8271 - val_recall: 0.9843 - val_precision: 0.7649\n",
            "Epoch 354/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0697 - accuracy: 0.9734 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9704 - precision: 0.9765\n",
            "Epoch 354: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 208ms/step - loss: 0.0697 - accuracy: 0.9734 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9704 - precision: 0.9765 - val_loss: 1.2082 - val_accuracy: 0.8336 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 0.8092 - val_recall: 0.9508 - val_precision: 0.7738\n",
            "Epoch 355/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0621 - accuracy: 0.9789 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9727 - precision: 0.9850\n",
            "Epoch 355: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 0.0621 - accuracy: 0.9789 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9727 - precision: 0.9850 - val_loss: 1.2650 - val_accuracy: 0.8414 - val_sensitivity_at_specificity: 0.9969 - val_specificity_at_sensitivity: 0.8214 - val_recall: 0.9560 - val_precision: 0.7765\n",
            "Epoch 356/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0850 - accuracy: 0.9668 - sensitivity_at_specificity: 0.9974 - specificity_at_sensitivity: 0.9992 - recall: 0.9596 - precision: 0.9713\n",
            "Epoch 356: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 206ms/step - loss: 0.0850 - accuracy: 0.9668 - sensitivity_at_specificity: 0.9974 - specificity_at_sensitivity: 0.9992 - recall: 0.9596 - precision: 0.9713 - val_loss: 1.2410 - val_accuracy: 0.8266 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.8257 - val_recall: 0.9565 - val_precision: 0.7602\n",
            "Epoch 357/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0609 - accuracy: 0.9762 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9689 - precision: 0.9834\n",
            "Epoch 357: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 200ms/step - loss: 0.0609 - accuracy: 0.9762 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9689 - precision: 0.9834 - val_loss: 1.0052 - val_accuracy: 0.8414 - val_sensitivity_at_specificity: 0.9969 - val_specificity_at_sensitivity: 0.8663 - val_recall: 0.9466 - val_precision: 0.7811\n",
            "Epoch 358/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0678 - accuracy: 0.9777 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9665 - precision: 0.9878\n",
            "Epoch 358: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 206ms/step - loss: 0.0678 - accuracy: 0.9777 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9665 - precision: 0.9878 - val_loss: 1.2441 - val_accuracy: 0.8328 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8169 - val_recall: 0.9778 - val_precision: 0.7549\n",
            "Epoch 359/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0534 - accuracy: 0.9812 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9799 - precision: 0.9829\n",
            "Epoch 359: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 0.0534 - accuracy: 0.9812 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9799 - precision: 0.9829 - val_loss: 1.2116 - val_accuracy: 0.8430 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8370 - val_recall: 0.9688 - val_precision: 0.7746\n",
            "Epoch 360/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0548 - accuracy: 0.9801 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9778 - precision: 0.9830\n",
            "Epoch 360: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 208ms/step - loss: 0.0548 - accuracy: 0.9801 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9778 - precision: 0.9830 - val_loss: 1.2712 - val_accuracy: 0.8289 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 0.8102 - val_recall: 0.9587 - val_precision: 0.7653\n",
            "Epoch 361/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0567 - accuracy: 0.9789 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9724 - precision: 0.9848\n",
            "Epoch 361: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 0.0567 - accuracy: 0.9789 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9724 - precision: 0.9848 - val_loss: 1.1870 - val_accuracy: 0.8195 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8182 - val_recall: 0.9477 - val_precision: 0.7513\n",
            "Epoch 362/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0564 - accuracy: 0.9824 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9790 - precision: 0.9859\n",
            "Epoch 362: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 202ms/step - loss: 0.0564 - accuracy: 0.9824 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9790 - precision: 0.9859 - val_loss: 1.3431 - val_accuracy: 0.8219 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8193 - val_recall: 0.9610 - val_precision: 0.7437\n",
            "Epoch 363/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0559 - accuracy: 0.9805 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9790 - precision: 0.9834\n",
            "Epoch 363: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 203ms/step - loss: 0.0559 - accuracy: 0.9805 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9790 - precision: 0.9834 - val_loss: 1.2400 - val_accuracy: 0.8266 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8254 - val_recall: 0.9600 - val_precision: 0.7610\n",
            "Epoch 364/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0754 - accuracy: 0.9742 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9685 - precision: 0.9793\n",
            "Epoch 364: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 204ms/step - loss: 0.0754 - accuracy: 0.9742 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9685 - precision: 0.9793 - val_loss: 1.0455 - val_accuracy: 0.8414 - val_sensitivity_at_specificity: 0.9971 - val_specificity_at_sensitivity: 0.8197 - val_recall: 0.9457 - val_precision: 0.7951\n",
            "Epoch 365/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0683 - accuracy: 0.9770 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9639 - precision: 0.9895\n",
            "Epoch 365: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 195ms/step - loss: 0.0683 - accuracy: 0.9770 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9639 - precision: 0.9895 - val_loss: 1.4382 - val_accuracy: 0.8148 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7929 - val_recall: 0.9696 - val_precision: 0.7459\n",
            "Epoch 366/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0679 - accuracy: 0.9781 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9774 - precision: 0.9774\n",
            "Epoch 366: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 0.0679 - accuracy: 0.9781 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9774 - precision: 0.9774 - val_loss: 0.9653 - val_accuracy: 0.8289 - val_sensitivity_at_specificity: 0.9967 - val_specificity_at_sensitivity: 0.8722 - val_recall: 0.9317 - val_precision: 0.7640\n",
            "Epoch 367/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0729 - accuracy: 0.9711 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9984 - recall: 0.9645 - precision: 0.9781\n",
            "Epoch 367: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 207ms/step - loss: 0.0729 - accuracy: 0.9711 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9984 - recall: 0.9645 - precision: 0.9781 - val_loss: 1.2933 - val_accuracy: 0.8227 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.8152 - val_recall: 0.9575 - val_precision: 0.7528\n",
            "Epoch 368/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0580 - accuracy: 0.9793 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9746 - precision: 0.9832\n",
            "Epoch 368: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 206ms/step - loss: 0.0580 - accuracy: 0.9793 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9746 - precision: 0.9832 - val_loss: 1.2029 - val_accuracy: 0.8266 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8291 - val_recall: 0.9537 - val_precision: 0.7630\n",
            "Epoch 369/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0586 - accuracy: 0.9797 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9770 - precision: 0.9817\n",
            "Epoch 369: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 206ms/step - loss: 0.0586 - accuracy: 0.9797 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9770 - precision: 0.9817 - val_loss: 1.2184 - val_accuracy: 0.8320 - val_sensitivity_at_specificity: 0.9969 - val_specificity_at_sensitivity: 0.8294 - val_recall: 0.9382 - val_precision: 0.7762\n",
            "Epoch 370/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0584 - accuracy: 0.9785 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9742 - precision: 0.9813\n",
            "Epoch 370: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 203ms/step - loss: 0.0584 - accuracy: 0.9785 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9742 - precision: 0.9813 - val_loss: 1.2941 - val_accuracy: 0.8266 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8144 - val_recall: 0.9697 - val_precision: 0.7500\n",
            "Epoch 371/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0668 - accuracy: 0.9762 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9992 - recall: 0.9654 - precision: 0.9863\n",
            "Epoch 371: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 197ms/step - loss: 0.0668 - accuracy: 0.9762 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9992 - recall: 0.9654 - precision: 0.9863 - val_loss: 1.3399 - val_accuracy: 0.8227 - val_sensitivity_at_specificity: 0.9969 - val_specificity_at_sensitivity: 0.8092 - val_recall: 0.9662 - val_precision: 0.7542\n",
            "Epoch 372/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0603 - accuracy: 0.9773 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9764 - precision: 0.9794\n",
            "Epoch 372: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 0.0603 - accuracy: 0.9773 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9764 - precision: 0.9794 - val_loss: 1.3043 - val_accuracy: 0.8320 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8019 - val_recall: 0.9557 - val_precision: 0.7707\n",
            "Epoch 373/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0644 - accuracy: 0.9750 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9752 - precision: 0.9737\n",
            "Epoch 373: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 205ms/step - loss: 0.0644 - accuracy: 0.9750 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9752 - precision: 0.9737 - val_loss: 1.3616 - val_accuracy: 0.8141 - val_sensitivity_at_specificity: 0.9954 - val_specificity_at_sensitivity: 0.8048 - val_recall: 0.9450 - val_precision: 0.7540\n",
            "Epoch 374/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0648 - accuracy: 0.9785 - sensitivity_at_specificity: 0.9977 - specificity_at_sensitivity: 0.9992 - recall: 0.9696 - precision: 0.9873\n",
            "Epoch 374: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 206ms/step - loss: 0.0648 - accuracy: 0.9785 - sensitivity_at_specificity: 0.9977 - specificity_at_sensitivity: 0.9992 - recall: 0.9696 - precision: 0.9873 - val_loss: 1.3822 - val_accuracy: 0.8234 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7727 - val_recall: 0.9639 - val_precision: 0.7601\n",
            "Epoch 375/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0712 - accuracy: 0.9746 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9992 - recall: 0.9696 - precision: 0.9796\n",
            "Epoch 375: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 0.0712 - accuracy: 0.9746 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9992 - recall: 0.9696 - precision: 0.9796 - val_loss: 1.2584 - val_accuracy: 0.8109 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 0.8057 - val_recall: 0.9382 - val_precision: 0.7503\n",
            "Epoch 376/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0761 - accuracy: 0.9734 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9984 - recall: 0.9672 - precision: 0.9794\n",
            "Epoch 376: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 198ms/step - loss: 0.0761 - accuracy: 0.9734 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9984 - recall: 0.9672 - precision: 0.9794 - val_loss: 1.0947 - val_accuracy: 0.8328 - val_sensitivity_at_specificity: 0.9969 - val_specificity_at_sensitivity: 0.8315 - val_recall: 0.9539 - val_precision: 0.7714\n",
            "Epoch 377/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0746 - accuracy: 0.9758 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9684 - precision: 0.9823\n",
            "Epoch 377: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 0.0746 - accuracy: 0.9758 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9684 - precision: 0.9823 - val_loss: 1.2156 - val_accuracy: 0.8406 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8318 - val_recall: 0.9744 - val_precision: 0.7644\n",
            "Epoch 378/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0513 - accuracy: 0.9824 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9806 - precision: 0.9829\n",
            "Epoch 378: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 0.0513 - accuracy: 0.9824 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9806 - precision: 0.9829 - val_loss: 1.1586 - val_accuracy: 0.8180 - val_sensitivity_at_specificity: 0.9970 - val_specificity_at_sensitivity: 0.8371 - val_recall: 0.9182 - val_precision: 0.7720\n",
            "Epoch 379/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0773 - accuracy: 0.9754 - sensitivity_at_specificity: 0.9968 - specificity_at_sensitivity: 0.9977 - recall: 0.9671 - precision: 0.9821\n",
            "Epoch 379: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 202ms/step - loss: 0.0773 - accuracy: 0.9754 - sensitivity_at_specificity: 0.9968 - specificity_at_sensitivity: 0.9977 - recall: 0.9671 - precision: 0.9821 - val_loss: 1.3447 - val_accuracy: 0.8297 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8227 - val_recall: 0.9572 - val_precision: 0.7672\n",
            "Epoch 380/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0659 - accuracy: 0.9742 - sensitivity_at_specificity: 0.9976 - specificity_at_sensitivity: 1.0000 - recall: 0.9699 - precision: 0.9763\n",
            "Epoch 380: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 199ms/step - loss: 0.0659 - accuracy: 0.9742 - sensitivity_at_specificity: 0.9976 - specificity_at_sensitivity: 1.0000 - recall: 0.9699 - precision: 0.9763 - val_loss: 1.0920 - val_accuracy: 0.8453 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.8351 - val_recall: 0.9482 - val_precision: 0.7854\n",
            "Epoch 381/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0567 - accuracy: 0.9785 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9985 - recall: 0.9732 - precision: 0.9833\n",
            "Epoch 381: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 0.0567 - accuracy: 0.9785 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9985 - recall: 0.9732 - precision: 0.9833 - val_loss: 1.1382 - val_accuracy: 0.8477 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8139 - val_recall: 0.9728 - val_precision: 0.7844\n",
            "Epoch 382/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0546 - accuracy: 0.9820 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9756 - precision: 0.9869\n",
            "Epoch 382: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 202ms/step - loss: 0.0546 - accuracy: 0.9820 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9756 - precision: 0.9869 - val_loss: 1.2494 - val_accuracy: 0.8391 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 0.8127 - val_recall: 0.9565 - val_precision: 0.7826\n",
            "Epoch 383/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0546 - accuracy: 0.9812 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9777 - precision: 0.9840\n",
            "Epoch 383: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 203ms/step - loss: 0.0546 - accuracy: 0.9812 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9777 - precision: 0.9840 - val_loss: 1.2058 - val_accuracy: 0.8469 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.8361 - val_recall: 0.9533 - val_precision: 0.7800\n",
            "Epoch 384/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0619 - accuracy: 0.9758 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9745 - precision: 0.9775\n",
            "Epoch 384: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 203ms/step - loss: 0.0619 - accuracy: 0.9758 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9745 - precision: 0.9775 - val_loss: 1.4630 - val_accuracy: 0.8117 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8063 - val_recall: 0.9392 - val_precision: 0.7371\n",
            "Epoch 385/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0583 - accuracy: 0.9777 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9731 - precision: 0.9841\n",
            "Epoch 385: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 0.0583 - accuracy: 0.9777 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9731 - precision: 0.9841 - val_loss: 1.3542 - val_accuracy: 0.8367 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8085 - val_recall: 0.9611 - val_precision: 0.7706\n",
            "Epoch 386/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0682 - accuracy: 0.9723 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9636 - precision: 0.9799\n",
            "Epoch 386: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 202ms/step - loss: 0.0682 - accuracy: 0.9723 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9636 - precision: 0.9799 - val_loss: 1.2533 - val_accuracy: 0.8289 - val_sensitivity_at_specificity: 0.9969 - val_specificity_at_sensitivity: 0.8231 - val_recall: 0.9583 - val_precision: 0.7635\n",
            "Epoch 387/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0680 - accuracy: 0.9742 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9977 - recall: 0.9701 - precision: 0.9778\n",
            "Epoch 387: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 209ms/step - loss: 0.0680 - accuracy: 0.9742 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9977 - recall: 0.9701 - precision: 0.9778 - val_loss: 1.2696 - val_accuracy: 0.8414 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8117 - val_recall: 0.9738 - val_precision: 0.7723\n",
            "Epoch 388/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0659 - accuracy: 0.9777 - sensitivity_at_specificity: 0.9976 - specificity_at_sensitivity: 0.9992 - recall: 0.9709 - precision: 0.9841\n",
            "Epoch 388: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 202ms/step - loss: 0.0659 - accuracy: 0.9777 - sensitivity_at_specificity: 0.9976 - specificity_at_sensitivity: 0.9992 - recall: 0.9709 - precision: 0.9841 - val_loss: 1.4386 - val_accuracy: 0.8273 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7876 - val_recall: 0.9685 - val_precision: 0.7537\n",
            "Epoch 389/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0591 - accuracy: 0.9805 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9727 - precision: 0.9881\n",
            "Epoch 389: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 204ms/step - loss: 0.0591 - accuracy: 0.9805 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9727 - precision: 0.9881 - val_loss: 1.2181 - val_accuracy: 0.8328 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8108 - val_recall: 0.9565 - val_precision: 0.7752\n",
            "Epoch 390/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0611 - accuracy: 0.9793 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9758 - precision: 0.9814\n",
            "Epoch 390: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 200ms/step - loss: 0.0611 - accuracy: 0.9793 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9758 - precision: 0.9814 - val_loss: 1.2692 - val_accuracy: 0.8180 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8204 - val_recall: 0.9606 - val_precision: 0.7454\n",
            "Epoch 391/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0612 - accuracy: 0.9801 - sensitivity_at_specificity: 0.9976 - specificity_at_sensitivity: 0.9992 - recall: 0.9707 - precision: 0.9887\n",
            "Epoch 391: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 204ms/step - loss: 0.0612 - accuracy: 0.9801 - sensitivity_at_specificity: 0.9976 - specificity_at_sensitivity: 0.9992 - recall: 0.9707 - precision: 0.9887 - val_loss: 1.3443 - val_accuracy: 0.8320 - val_sensitivity_at_specificity: 0.9969 - val_specificity_at_sensitivity: 0.8121 - val_recall: 0.9560 - val_precision: 0.7648\n",
            "Epoch 392/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0621 - accuracy: 0.9777 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9761 - precision: 0.9799\n",
            "Epoch 392: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 203ms/step - loss: 0.0621 - accuracy: 0.9777 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9761 - precision: 0.9799 - val_loss: 1.0023 - val_accuracy: 0.8305 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8580 - val_recall: 0.9381 - val_precision: 0.7739\n",
            "Epoch 393/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0556 - accuracy: 0.9789 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9741 - precision: 0.9833\n",
            "Epoch 393: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 209ms/step - loss: 0.0556 - accuracy: 0.9789 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9741 - precision: 0.9833 - val_loss: 1.2242 - val_accuracy: 0.8281 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 0.8217 - val_recall: 0.9601 - val_precision: 0.7634\n",
            "Epoch 394/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.0500 - accuracy: 0.9839 - sensitivity_at_specificity: 0.9991 - specificity_at_sensitivity: 0.9983 - recall: 0.9793 - precision: 0.9887\n",
            "Epoch 394: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 202ms/step - loss: 0.0497 - accuracy: 0.9838 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9983 - recall: 0.9785 - precision: 0.9891 - val_loss: 1.2665 - val_accuracy: 0.8422 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 0.8207 - val_recall: 0.9637 - val_precision: 0.7816\n",
            "Epoch 395/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0486 - accuracy: 0.9809 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9818 - precision: 0.9810\n",
            "Epoch 395: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 207ms/step - loss: 0.0486 - accuracy: 0.9809 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9818 - precision: 0.9810 - val_loss: 1.3043 - val_accuracy: 0.8383 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8069 - val_recall: 0.9659 - val_precision: 0.7796\n",
            "Epoch 396/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0609 - accuracy: 0.9801 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9706 - precision: 0.9908\n",
            "Epoch 396: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 204ms/step - loss: 0.0609 - accuracy: 0.9801 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9706 - precision: 0.9908 - val_loss: 1.2389 - val_accuracy: 0.8297 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.8273 - val_recall: 0.9689 - val_precision: 0.7588\n",
            "Epoch 397/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0510 - accuracy: 0.9844 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9848 - precision: 0.9848\n",
            "Epoch 397: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 204ms/step - loss: 0.0510 - accuracy: 0.9844 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9848 - precision: 0.9848 - val_loss: 1.3084 - val_accuracy: 0.8273 - val_sensitivity_at_specificity: 0.9968 - val_specificity_at_sensitivity: 0.8211 - val_recall: 0.9521 - val_precision: 0.7573\n",
            "Epoch 398/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0602 - accuracy: 0.9773 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9684 - precision: 0.9843\n",
            "Epoch 398: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 0.0602 - accuracy: 0.9773 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9684 - precision: 0.9843 - val_loss: 1.3049 - val_accuracy: 0.8305 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8107 - val_recall: 0.9600 - val_precision: 0.7576\n",
            "Epoch 399/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0486 - accuracy: 0.9840 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9825 - precision: 0.9849\n",
            "Epoch 399: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 205ms/step - loss: 0.0486 - accuracy: 0.9840 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9825 - precision: 0.9849 - val_loss: 1.4272 - val_accuracy: 0.8180 - val_sensitivity_at_specificity: 0.9951 - val_specificity_at_sensitivity: 0.8093 - val_recall: 0.9511 - val_precision: 0.7421\n",
            "Epoch 400/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0635 - accuracy: 0.9777 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9722 - precision: 0.9824\n",
            "Epoch 400: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 202ms/step - loss: 0.0635 - accuracy: 0.9777 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9722 - precision: 0.9824 - val_loss: 1.3844 - val_accuracy: 0.8250 - val_sensitivity_at_specificity: 0.9970 - val_specificity_at_sensitivity: 0.8039 - val_recall: 0.9590 - val_precision: 0.7621\n",
            "Epoch 401/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0595 - accuracy: 0.9785 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9717 - precision: 0.9849\n",
            "Epoch 401: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 202ms/step - loss: 0.0595 - accuracy: 0.9785 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9717 - precision: 0.9849 - val_loss: 1.3090 - val_accuracy: 0.8281 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8018 - val_recall: 0.9682 - val_precision: 0.7528\n",
            "Epoch 402/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0612 - accuracy: 0.9777 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9993 - recall: 0.9703 - precision: 0.9825\n",
            "Epoch 402: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 203ms/step - loss: 0.0612 - accuracy: 0.9777 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9993 - recall: 0.9703 - precision: 0.9825 - val_loss: 1.1194 - val_accuracy: 0.8453 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.8365 - val_recall: 0.9503 - val_precision: 0.7866\n",
            "Epoch 403/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0602 - accuracy: 0.9770 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9795 - precision: 0.9741\n",
            "Epoch 403: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 204ms/step - loss: 0.0602 - accuracy: 0.9770 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9795 - precision: 0.9741 - val_loss: 1.2131 - val_accuracy: 0.8297 - val_sensitivity_at_specificity: 0.9969 - val_specificity_at_sensitivity: 0.8247 - val_recall: 0.9610 - val_precision: 0.7614\n",
            "Epoch 404/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0561 - accuracy: 0.9777 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9725 - precision: 0.9826\n",
            "Epoch 404: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 202ms/step - loss: 0.0561 - accuracy: 0.9777 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9725 - precision: 0.9826 - val_loss: 1.2419 - val_accuracy: 0.8266 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 0.8111 - val_recall: 0.9631 - val_precision: 0.7597\n",
            "Epoch 405/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0617 - accuracy: 0.9773 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9758 - precision: 0.9788\n",
            "Epoch 405: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 202ms/step - loss: 0.0617 - accuracy: 0.9773 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9758 - precision: 0.9788 - val_loss: 1.0278 - val_accuracy: 0.8555 - val_sensitivity_at_specificity: 0.9970 - val_specificity_at_sensitivity: 0.8423 - val_recall: 0.9504 - val_precision: 0.8061\n",
            "Epoch 406/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0401 - accuracy: 0.9863 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9829 - precision: 0.9898\n",
            "Epoch 406: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 0.0401 - accuracy: 0.9863 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9829 - precision: 0.9898 - val_loss: 1.8549 - val_accuracy: 0.7922 - val_sensitivity_at_specificity: 0.9968 - val_specificity_at_sensitivity: 0.7446 - val_recall: 0.9521 - val_precision: 0.7163\n",
            "Epoch 407/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0653 - accuracy: 0.9758 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 0.9992 - recall: 0.9655 - precision: 0.9867\n",
            "Epoch 407: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 209ms/step - loss: 0.0653 - accuracy: 0.9758 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 0.9992 - recall: 0.9655 - precision: 0.9867 - val_loss: 1.0179 - val_accuracy: 0.8492 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 0.8446 - val_recall: 0.9585 - val_precision: 0.7968\n",
            "Epoch 408/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0737 - accuracy: 0.9738 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9711 - precision: 0.9778\n",
            "Epoch 408: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 208ms/step - loss: 0.0737 - accuracy: 0.9738 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9711 - precision: 0.9778 - val_loss: 1.1579 - val_accuracy: 0.8266 - val_sensitivity_at_specificity: 0.9953 - val_specificity_at_sensitivity: 0.8320 - val_recall: 0.9372 - val_precision: 0.7664\n",
            "Epoch 409/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0651 - accuracy: 0.9812 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9796 - precision: 0.9827\n",
            "Epoch 409: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 203ms/step - loss: 0.0651 - accuracy: 0.9812 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9796 - precision: 0.9827 - val_loss: 1.4989 - val_accuracy: 0.8195 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.7944 - val_recall: 0.9494 - val_precision: 0.7513\n",
            "Epoch 410/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0534 - accuracy: 0.9797 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9747 - precision: 0.9841\n",
            "Epoch 410: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 203ms/step - loss: 0.0534 - accuracy: 0.9797 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9747 - precision: 0.9841 - val_loss: 1.4287 - val_accuracy: 0.8367 - val_sensitivity_at_specificity: 0.9970 - val_specificity_at_sensitivity: 0.7950 - val_recall: 0.9556 - val_precision: 0.7828\n",
            "Epoch 411/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0622 - accuracy: 0.9766 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9688 - precision: 0.9830\n",
            "Epoch 411: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 200ms/step - loss: 0.0622 - accuracy: 0.9766 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9688 - precision: 0.9830 - val_loss: 1.1982 - val_accuracy: 0.8297 - val_sensitivity_at_specificity: 0.9938 - val_specificity_at_sensitivity: 0.8239 - val_recall: 0.9410 - val_precision: 0.7710\n",
            "Epoch 412/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0539 - accuracy: 0.9824 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9826 - precision: 0.9834\n",
            "Epoch 412: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 197ms/step - loss: 0.0539 - accuracy: 0.9824 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9826 - precision: 0.9834 - val_loss: 1.1770 - val_accuracy: 0.8406 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 0.8152 - val_recall: 0.9675 - val_precision: 0.7738\n",
            "Epoch 413/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0476 - accuracy: 0.9809 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9743 - precision: 0.9874\n",
            "Epoch 413: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 202ms/step - loss: 0.0476 - accuracy: 0.9809 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9743 - precision: 0.9874 - val_loss: 1.3390 - val_accuracy: 0.8359 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8010 - val_recall: 0.9601 - val_precision: 0.7728\n",
            "Epoch 414/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0570 - accuracy: 0.9785 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9757 - precision: 0.9824\n",
            "Epoch 414: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 202ms/step - loss: 0.0570 - accuracy: 0.9785 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9757 - precision: 0.9824 - val_loss: 1.3845 - val_accuracy: 0.8344 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7897 - val_recall: 0.9513 - val_precision: 0.7764\n",
            "Epoch 415/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0520 - accuracy: 0.9836 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9992 - recall: 0.9797 - precision: 0.9874\n",
            "Epoch 415: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 199ms/step - loss: 0.0520 - accuracy: 0.9836 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9992 - recall: 0.9797 - precision: 0.9874 - val_loss: 1.4419 - val_accuracy: 0.8375 - val_sensitivity_at_specificity: 0.9968 - val_specificity_at_sensitivity: 0.8070 - val_recall: 0.9678 - val_precision: 0.7620\n",
            "Epoch 416/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0538 - accuracy: 0.9836 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9802 - precision: 0.9877\n",
            "Epoch 416: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 203ms/step - loss: 0.0538 - accuracy: 0.9836 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9802 - precision: 0.9877 - val_loss: 1.3109 - val_accuracy: 0.8328 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.8142 - val_recall: 0.9628 - val_precision: 0.7657\n",
            "Epoch 417/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0516 - accuracy: 0.9812 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9787 - precision: 0.9833\n",
            "Epoch 417: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 204ms/step - loss: 0.0516 - accuracy: 0.9812 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9787 - precision: 0.9833 - val_loss: 1.3599 - val_accuracy: 0.8383 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.8200 - val_recall: 0.9657 - val_precision: 0.7699\n",
            "Epoch 418/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0625 - accuracy: 0.9793 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9753 - precision: 0.9836\n",
            "Epoch 418: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 202ms/step - loss: 0.0625 - accuracy: 0.9793 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9753 - precision: 0.9836 - val_loss: 1.4019 - val_accuracy: 0.8281 - val_sensitivity_at_specificity: 0.9952 - val_specificity_at_sensitivity: 0.8083 - val_recall: 0.9522 - val_precision: 0.7589\n",
            "Epoch 419/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0614 - accuracy: 0.9789 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9977 - recall: 0.9735 - precision: 0.9830\n",
            "Epoch 419: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 206ms/step - loss: 0.0614 - accuracy: 0.9789 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9977 - recall: 0.9735 - precision: 0.9830 - val_loss: 1.4433 - val_accuracy: 0.8313 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7897 - val_recall: 0.9635 - val_precision: 0.7673\n",
            "Epoch 420/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0616 - accuracy: 0.9809 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9767 - precision: 0.9851\n",
            "Epoch 420: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 204ms/step - loss: 0.0616 - accuracy: 0.9809 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9767 - precision: 0.9851 - val_loss: 1.4883 - val_accuracy: 0.8305 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7901 - val_recall: 0.9804 - val_precision: 0.7457\n",
            "Epoch 421/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0474 - accuracy: 0.9836 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9800 - precision: 0.9876\n",
            "Epoch 421: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 0.0474 - accuracy: 0.9836 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9800 - precision: 0.9876 - val_loss: 1.2289 - val_accuracy: 0.8219 - val_sensitivity_at_specificity: 0.9955 - val_specificity_at_sensitivity: 0.8282 - val_recall: 0.9351 - val_precision: 0.7702\n",
            "Epoch 422/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0563 - accuracy: 0.9801 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9983 - recall: 0.9815 - precision: 0.9808\n",
            "Epoch 422: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 213ms/step - loss: 0.0563 - accuracy: 0.9801 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9983 - recall: 0.9815 - precision: 0.9808 - val_loss: 1.2343 - val_accuracy: 0.8289 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 0.8198 - val_recall: 0.9510 - val_precision: 0.7686\n",
            "Epoch 423/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0554 - accuracy: 0.9816 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9730 - precision: 0.9884\n",
            "Epoch 423: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 202ms/step - loss: 0.0554 - accuracy: 0.9816 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9730 - precision: 0.9884 - val_loss: 1.4019 - val_accuracy: 0.8328 - val_sensitivity_at_specificity: 0.9953 - val_specificity_at_sensitivity: 0.8083 - val_recall: 0.9589 - val_precision: 0.7635\n",
            "Epoch 424/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0463 - accuracy: 0.9809 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9810 - precision: 0.9810\n",
            "Epoch 424: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 200ms/step - loss: 0.0463 - accuracy: 0.9809 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9810 - precision: 0.9810 - val_loss: 1.3126 - val_accuracy: 0.8320 - val_sensitivity_at_specificity: 0.9969 - val_specificity_at_sensitivity: 0.8276 - val_recall: 0.9455 - val_precision: 0.7713\n",
            "Epoch 425/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0583 - accuracy: 0.9777 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9985 - recall: 0.9762 - precision: 0.9785\n",
            "Epoch 425: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 211ms/step - loss: 0.0583 - accuracy: 0.9777 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9985 - recall: 0.9762 - precision: 0.9785 - val_loss: 1.5307 - val_accuracy: 0.8219 - val_sensitivity_at_specificity: 0.9922 - val_specificity_at_sensitivity: 0.8059 - val_recall: 0.9516 - val_precision: 0.7559\n",
            "Epoch 426/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0604 - accuracy: 0.9770 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9691 - precision: 0.9839\n",
            "Epoch 426: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 202ms/step - loss: 0.0604 - accuracy: 0.9770 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9691 - precision: 0.9839 - val_loss: 1.3239 - val_accuracy: 0.8391 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 0.8159 - val_recall: 0.9677 - val_precision: 0.7727\n",
            "Epoch 427/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0441 - accuracy: 0.9840 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9993 - recall: 0.9828 - precision: 0.9836\n",
            "Epoch 427: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 204ms/step - loss: 0.0441 - accuracy: 0.9840 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9993 - recall: 0.9828 - precision: 0.9836 - val_loss: 1.4539 - val_accuracy: 0.8250 - val_sensitivity_at_specificity: 0.9969 - val_specificity_at_sensitivity: 0.7987 - val_recall: 0.9602 - val_precision: 0.7603\n",
            "Epoch 428/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0411 - accuracy: 0.9867 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9816 - precision: 0.9911\n",
            "Epoch 428: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 209ms/step - loss: 0.0411 - accuracy: 0.9867 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9816 - precision: 0.9911 - val_loss: 1.7368 - val_accuracy: 0.8203 - val_sensitivity_at_specificity: 0.9968 - val_specificity_at_sensitivity: 0.7853 - val_recall: 0.9490 - val_precision: 0.7506\n",
            "Epoch 429/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0512 - accuracy: 0.9844 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9977 - recall: 0.9801 - precision: 0.9879\n",
            "Epoch 429: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 207ms/step - loss: 0.0512 - accuracy: 0.9844 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9977 - recall: 0.9801 - precision: 0.9879 - val_loss: 1.6811 - val_accuracy: 0.8266 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7603 - val_recall: 0.9723 - val_precision: 0.7560\n",
            "Epoch 430/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0373 - accuracy: 0.9871 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9868 - precision: 0.9876\n",
            "Epoch 430: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 208ms/step - loss: 0.0373 - accuracy: 0.9871 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9868 - precision: 0.9876 - val_loss: 1.4279 - val_accuracy: 0.8188 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7867 - val_recall: 0.9521 - val_precision: 0.7540\n",
            "Epoch 431/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0420 - accuracy: 0.9848 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9758 - precision: 0.9937\n",
            "Epoch 431: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 207ms/step - loss: 0.0420 - accuracy: 0.9848 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9758 - precision: 0.9937 - val_loss: 1.4751 - val_accuracy: 0.8508 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8024 - val_recall: 0.9839 - val_precision: 0.7718\n",
            "Epoch 432/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0598 - accuracy: 0.9801 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9731 - precision: 0.9864\n",
            "Epoch 432: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 207ms/step - loss: 0.0598 - accuracy: 0.9801 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9731 - precision: 0.9864 - val_loss: 1.2023 - val_accuracy: 0.8289 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8268 - val_recall: 0.9333 - val_precision: 0.7738\n",
            "Epoch 433/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0457 - accuracy: 0.9820 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9819 - precision: 0.9834\n",
            "Epoch 433: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 203ms/step - loss: 0.0457 - accuracy: 0.9820 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9819 - precision: 0.9834 - val_loss: 1.2868 - val_accuracy: 0.8328 - val_sensitivity_at_specificity: 0.9969 - val_specificity_at_sensitivity: 0.8206 - val_recall: 0.9390 - val_precision: 0.7742\n",
            "Epoch 434/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0503 - accuracy: 0.9840 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9778 - precision: 0.9896\n",
            "Epoch 434: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 204ms/step - loss: 0.0503 - accuracy: 0.9840 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9778 - precision: 0.9896 - val_loss: 1.4451 - val_accuracy: 0.8367 - val_sensitivity_at_specificity: 0.9970 - val_specificity_at_sensitivity: 0.7842 - val_recall: 0.9697 - val_precision: 0.7717\n",
            "Epoch 435/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0460 - accuracy: 0.9832 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9780 - precision: 0.9869\n",
            "Epoch 435: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 211ms/step - loss: 0.0460 - accuracy: 0.9832 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9780 - precision: 0.9869 - val_loss: 1.3317 - val_accuracy: 0.8422 - val_sensitivity_at_specificity: 0.9954 - val_specificity_at_sensitivity: 0.8323 - val_recall: 0.9660 - val_precision: 0.7767\n",
            "Epoch 436/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0442 - accuracy: 0.9855 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9867 - precision: 0.9844\n",
            "Epoch 436: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 205ms/step - loss: 0.0442 - accuracy: 0.9855 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9867 - precision: 0.9844 - val_loss: 1.4434 - val_accuracy: 0.8250 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7950 - val_recall: 0.9607 - val_precision: 0.7543\n",
            "Epoch 437/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0432 - accuracy: 0.9871 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9794 - precision: 0.9944\n",
            "Epoch 437: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 202ms/step - loss: 0.0432 - accuracy: 0.9871 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9794 - precision: 0.9944 - val_loss: 1.3439 - val_accuracy: 0.8328 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.8132 - val_recall: 0.9627 - val_precision: 0.7651\n",
            "Epoch 438/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0559 - accuracy: 0.9789 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9790 - precision: 0.9790\n",
            "Epoch 438: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 0.0559 - accuracy: 0.9789 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9790 - precision: 0.9790 - val_loss: 1.3687 - val_accuracy: 0.8172 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.7967 - val_recall: 0.9562 - val_precision: 0.7399\n",
            "Epoch 439/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0417 - accuracy: 0.9840 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9809 - precision: 0.9877\n",
            "Epoch 439: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 204ms/step - loss: 0.0417 - accuracy: 0.9840 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9809 - precision: 0.9877 - val_loss: 1.5866 - val_accuracy: 0.8180 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.7771 - val_recall: 0.9616 - val_precision: 0.7420\n",
            "Epoch 440/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0430 - accuracy: 0.9852 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9828 - precision: 0.9874\n",
            "Epoch 440: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 0.0430 - accuracy: 0.9852 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9828 - precision: 0.9874 - val_loss: 1.0925 - val_accuracy: 0.8406 - val_sensitivity_at_specificity: 0.9954 - val_specificity_at_sensitivity: 0.8352 - val_recall: 0.9481 - val_precision: 0.7851\n",
            "Epoch 441/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0514 - accuracy: 0.9812 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9816 - precision: 0.9816\n",
            "Epoch 441: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 0.0514 - accuracy: 0.9812 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9816 - precision: 0.9816 - val_loss: 1.4349 - val_accuracy: 0.8320 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8130 - val_recall: 0.9643 - val_precision: 0.7551\n",
            "Epoch 442/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0508 - accuracy: 0.9801 - sensitivity_at_specificity: 0.9991 - specificity_at_sensitivity: 1.0000 - recall: 0.9759 - precision: 0.9827\n",
            "Epoch 442: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 189ms/step - loss: 0.0508 - accuracy: 0.9801 - sensitivity_at_specificity: 0.9991 - specificity_at_sensitivity: 1.0000 - recall: 0.9759 - precision: 0.9827 - val_loss: 1.4398 - val_accuracy: 0.8391 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.8112 - val_recall: 0.9703 - val_precision: 0.7683\n",
            "Epoch 443/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0510 - accuracy: 0.9820 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9793 - precision: 0.9840\n",
            "Epoch 443: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 196ms/step - loss: 0.0510 - accuracy: 0.9820 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9793 - precision: 0.9840 - val_loss: 1.2705 - val_accuracy: 0.8344 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.8302 - val_recall: 0.9494 - val_precision: 0.7692\n",
            "Epoch 444/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0569 - accuracy: 0.9793 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9806 - precision: 0.9783\n",
            "Epoch 444: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 199ms/step - loss: 0.0569 - accuracy: 0.9793 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9806 - precision: 0.9783 - val_loss: 1.3118 - val_accuracy: 0.8383 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 0.8121 - val_recall: 0.9476 - val_precision: 0.7863\n",
            "Epoch 445/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0387 - accuracy: 0.9875 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9836 - precision: 0.9913\n",
            "Epoch 445: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 204ms/step - loss: 0.0387 - accuracy: 0.9875 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9836 - precision: 0.9913 - val_loss: 1.4526 - val_accuracy: 0.8242 - val_sensitivity_at_specificity: 0.9968 - val_specificity_at_sensitivity: 0.8012 - val_recall: 0.9553 - val_precision: 0.7522\n",
            "Epoch 446/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0520 - accuracy: 0.9812 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9772 - precision: 0.9862\n",
            "Epoch 446: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 208ms/step - loss: 0.0520 - accuracy: 0.9812 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9772 - precision: 0.9862 - val_loss: 1.4146 - val_accuracy: 0.8297 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 0.8039 - val_recall: 0.9653 - val_precision: 0.7665\n",
            "Epoch 447/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0471 - accuracy: 0.9828 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9791 - precision: 0.9867\n",
            "Epoch 447: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 203ms/step - loss: 0.0471 - accuracy: 0.9828 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9791 - precision: 0.9867 - val_loss: 1.7066 - val_accuracy: 0.8289 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.7814 - val_recall: 0.9674 - val_precision: 0.7588\n",
            "Epoch 448/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0650 - accuracy: 0.9750 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9722 - precision: 0.9783\n",
            "Epoch 448: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 207ms/step - loss: 0.0650 - accuracy: 0.9750 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9722 - precision: 0.9783 - val_loss: 1.5173 - val_accuracy: 0.8266 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7915 - val_recall: 0.9679 - val_precision: 0.7491\n",
            "Epoch 449/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0500 - accuracy: 0.9820 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9743 - precision: 0.9897\n",
            "Epoch 449: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 209ms/step - loss: 0.0500 - accuracy: 0.9820 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9743 - precision: 0.9897 - val_loss: 1.3884 - val_accuracy: 0.8375 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 0.7929 - val_recall: 0.9713 - val_precision: 0.7728\n",
            "Epoch 450/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0472 - accuracy: 0.9824 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9777 - precision: 0.9863\n",
            "Epoch 450: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 203ms/step - loss: 0.0472 - accuracy: 0.9824 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9777 - precision: 0.9863 - val_loss: 1.3149 - val_accuracy: 0.8133 - val_sensitivity_at_specificity: 0.9968 - val_specificity_at_sensitivity: 0.8168 - val_recall: 0.9472 - val_precision: 0.7419\n",
            "Epoch 451/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0505 - accuracy: 0.9852 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9984 - recall: 0.9804 - precision: 0.9897\n",
            "Epoch 451: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 205ms/step - loss: 0.0505 - accuracy: 0.9852 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9984 - recall: 0.9804 - precision: 0.9897 - val_loss: 1.2780 - val_accuracy: 0.8273 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 0.8136 - val_recall: 0.9614 - val_precision: 0.7604\n",
            "Epoch 452/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0408 - accuracy: 0.9852 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9823 - precision: 0.9871\n",
            "Epoch 452: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 202ms/step - loss: 0.0408 - accuracy: 0.9852 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9823 - precision: 0.9871 - val_loss: 1.3784 - val_accuracy: 0.8453 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 0.8006 - val_recall: 0.9707 - val_precision: 0.7785\n",
            "Epoch 453/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0543 - accuracy: 0.9809 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9782 - precision: 0.9836\n",
            "Epoch 453: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 205ms/step - loss: 0.0543 - accuracy: 0.9809 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9782 - precision: 0.9836 - val_loss: 1.5562 - val_accuracy: 0.8328 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.7800 - val_recall: 0.9730 - val_precision: 0.7568\n",
            "Epoch 454/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0492 - accuracy: 0.9828 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9767 - precision: 0.9901\n",
            "Epoch 454: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 207ms/step - loss: 0.0492 - accuracy: 0.9828 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9767 - precision: 0.9901 - val_loss: 1.5930 - val_accuracy: 0.8266 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 0.7833 - val_recall: 0.9543 - val_precision: 0.7656\n",
            "Epoch 455/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0570 - accuracy: 0.9793 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9985 - recall: 0.9749 - precision: 0.9820\n",
            "Epoch 455: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 205ms/step - loss: 0.0570 - accuracy: 0.9793 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9985 - recall: 0.9749 - precision: 0.9820 - val_loss: 1.2839 - val_accuracy: 0.8375 - val_sensitivity_at_specificity: 0.9953 - val_specificity_at_sensitivity: 0.8193 - val_recall: 0.9514 - val_precision: 0.7742\n",
            "Epoch 456/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0533 - accuracy: 0.9797 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9803 - precision: 0.9803\n",
            "Epoch 456: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 206ms/step - loss: 0.0533 - accuracy: 0.9797 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9803 - precision: 0.9803 - val_loss: 1.3987 - val_accuracy: 0.8289 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.8025 - val_recall: 0.9617 - val_precision: 0.7556\n",
            "Epoch 457/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0576 - accuracy: 0.9784 - sensitivity_at_specificity: 0.9983 - specificity_at_sensitivity: 1.0000 - recall: 0.9742 - precision: 0.9824\n",
            "Epoch 457: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 194ms/step - loss: 0.0576 - accuracy: 0.9784 - sensitivity_at_specificity: 0.9983 - specificity_at_sensitivity: 1.0000 - recall: 0.9742 - precision: 0.9824 - val_loss: 1.6176 - val_accuracy: 0.8273 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.7855 - val_recall: 0.9699 - val_precision: 0.7521\n",
            "Epoch 458/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0516 - accuracy: 0.9820 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9771 - precision: 0.9864\n",
            "Epoch 458: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 206ms/step - loss: 0.0516 - accuracy: 0.9820 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9771 - precision: 0.9864 - val_loss: 1.4861 - val_accuracy: 0.8352 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7955 - val_recall: 0.9664 - val_precision: 0.7698\n",
            "Epoch 459/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0441 - accuracy: 0.9828 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9803 - precision: 0.9863\n",
            "Epoch 459: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 206ms/step - loss: 0.0441 - accuracy: 0.9828 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9803 - precision: 0.9863 - val_loss: 1.4418 - val_accuracy: 0.8211 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.7935 - val_recall: 0.9604 - val_precision: 0.7481\n",
            "Epoch 460/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0690 - accuracy: 0.9773 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9725 - precision: 0.9817\n",
            "Epoch 460: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 209ms/step - loss: 0.0690 - accuracy: 0.9773 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9725 - precision: 0.9817 - val_loss: 1.2953 - val_accuracy: 0.8391 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.8186 - val_recall: 0.9679 - val_precision: 0.7646\n",
            "Epoch 461/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0458 - accuracy: 0.9848 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9828 - precision: 0.9867\n",
            "Epoch 461: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 199ms/step - loss: 0.0458 - accuracy: 0.9848 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9828 - precision: 0.9867 - val_loss: 1.4057 - val_accuracy: 0.8133 - val_sensitivity_at_specificity: 0.9939 - val_specificity_at_sensitivity: 0.7981 - val_recall: 0.9370 - val_precision: 0.7550\n",
            "Epoch 462/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0520 - accuracy: 0.9816 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9775 - precision: 0.9859\n",
            "Epoch 462: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 207ms/step - loss: 0.0520 - accuracy: 0.9816 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9984 - recall: 0.9775 - precision: 0.9859 - val_loss: 1.2938 - val_accuracy: 0.8422 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.8169 - val_recall: 0.9683 - val_precision: 0.7702\n",
            "Epoch 463/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0561 - accuracy: 0.9789 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9761 - precision: 0.9822\n",
            "Epoch 463: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 203ms/step - loss: 0.0561 - accuracy: 0.9789 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9761 - precision: 0.9822 - val_loss: 1.3949 - val_accuracy: 0.8414 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7994 - val_recall: 0.9799 - val_precision: 0.7694\n",
            "Epoch 464/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0510 - accuracy: 0.9793 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9770 - precision: 0.9809\n",
            "Epoch 464: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 0.0510 - accuracy: 0.9793 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9770 - precision: 0.9809 - val_loss: 1.5185 - val_accuracy: 0.8383 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 0.7761 - val_recall: 0.9790 - val_precision: 0.7721\n",
            "Epoch 465/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0527 - accuracy: 0.9805 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9768 - precision: 0.9841\n",
            "Epoch 465: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 193ms/step - loss: 0.0527 - accuracy: 0.9805 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9768 - precision: 0.9841 - val_loss: 1.3675 - val_accuracy: 0.8273 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 0.7984 - val_recall: 0.9652 - val_precision: 0.7629\n",
            "Epoch 466/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0758 - accuracy: 0.9711 - sensitivity_at_specificity: 0.9977 - specificity_at_sensitivity: 1.0000 - recall: 0.9676 - precision: 0.9751\n",
            "Epoch 466: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 207ms/step - loss: 0.0758 - accuracy: 0.9711 - sensitivity_at_specificity: 0.9977 - specificity_at_sensitivity: 1.0000 - recall: 0.9676 - precision: 0.9751 - val_loss: 1.1438 - val_accuracy: 0.8227 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8298 - val_recall: 0.9570 - val_precision: 0.7503\n",
            "Epoch 467/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0595 - accuracy: 0.9738 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9633 - precision: 0.9840\n",
            "Epoch 467: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 203ms/step - loss: 0.0595 - accuracy: 0.9738 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9633 - precision: 0.9840 - val_loss: 1.3737 - val_accuracy: 0.8375 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 0.7949 - val_recall: 0.9693 - val_precision: 0.7705\n",
            "Epoch 468/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0530 - accuracy: 0.9809 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9768 - precision: 0.9852\n",
            "Epoch 468: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 207ms/step - loss: 0.0530 - accuracy: 0.9809 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9768 - precision: 0.9852 - val_loss: 1.4021 - val_accuracy: 0.8313 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7997 - val_recall: 0.9662 - val_precision: 0.7643\n",
            "Epoch 469/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0483 - accuracy: 0.9844 - sensitivity_at_specificity: 0.9976 - specificity_at_sensitivity: 1.0000 - recall: 0.9843 - precision: 0.9843\n",
            "Epoch 469: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 211ms/step - loss: 0.0483 - accuracy: 0.9844 - sensitivity_at_specificity: 0.9976 - specificity_at_sensitivity: 1.0000 - recall: 0.9843 - precision: 0.9843 - val_loss: 1.1201 - val_accuracy: 0.8297 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.8223 - val_recall: 0.9270 - val_precision: 0.7773\n",
            "Epoch 470/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0527 - accuracy: 0.9809 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9750 - precision: 0.9853\n",
            "Epoch 470: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 206ms/step - loss: 0.0527 - accuracy: 0.9809 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9750 - precision: 0.9853 - val_loss: 1.3587 - val_accuracy: 0.8219 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8006 - val_recall: 0.9586 - val_precision: 0.7488\n",
            "Epoch 471/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0568 - accuracy: 0.9781 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9747 - precision: 0.9809\n",
            "Epoch 471: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 208ms/step - loss: 0.0568 - accuracy: 0.9781 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9747 - precision: 0.9809 - val_loss: 1.2239 - val_accuracy: 0.8305 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.8126 - val_recall: 0.9581 - val_precision: 0.7649\n",
            "Epoch 472/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0445 - accuracy: 0.9830 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9825 - precision: 0.9833\n",
            "Epoch 472: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 215ms/step - loss: 0.0445 - accuracy: 0.9830 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9825 - precision: 0.9833 - val_loss: 1.5040 - val_accuracy: 0.8281 - val_sensitivity_at_specificity: 0.9954 - val_specificity_at_sensitivity: 0.7965 - val_recall: 0.9662 - val_precision: 0.7606\n",
            "Epoch 473/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0498 - accuracy: 0.9832 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9770 - precision: 0.9888\n",
            "Epoch 473: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 204ms/step - loss: 0.0498 - accuracy: 0.9832 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9770 - precision: 0.9888 - val_loss: 1.4903 - val_accuracy: 0.8250 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.7997 - val_recall: 0.9501 - val_precision: 0.7535\n",
            "Epoch 474/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0401 - accuracy: 0.9859 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9808 - precision: 0.9903\n",
            "Epoch 474: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 207ms/step - loss: 0.0401 - accuracy: 0.9859 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9808 - precision: 0.9903 - val_loss: 1.4837 - val_accuracy: 0.8367 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.8000 - val_recall: 0.9625 - val_precision: 0.7690\n",
            "Epoch 475/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0510 - accuracy: 0.9844 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9815 - precision: 0.9876\n",
            "Epoch 475: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 214ms/step - loss: 0.0510 - accuracy: 0.9844 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9815 - precision: 0.9876 - val_loss: 1.2497 - val_accuracy: 0.8453 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 0.8058 - val_recall: 0.9713 - val_precision: 0.7822\n",
            "Epoch 476/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0435 - accuracy: 0.9871 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9858 - precision: 0.9881\n",
            "Epoch 476: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 204ms/step - loss: 0.0435 - accuracy: 0.9871 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9858 - precision: 0.9881 - val_loss: 1.3439 - val_accuracy: 0.8281 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 0.8146 - val_recall: 0.9461 - val_precision: 0.7685\n",
            "Epoch 477/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0435 - accuracy: 0.9852 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9820 - precision: 0.9869\n",
            "Epoch 477: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 206ms/step - loss: 0.0435 - accuracy: 0.9852 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9820 - precision: 0.9869 - val_loss: 1.6113 - val_accuracy: 0.8313 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7831 - val_recall: 0.9762 - val_precision: 0.7537\n",
            "Epoch 478/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0407 - accuracy: 0.9836 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9803 - precision: 0.9865\n",
            "Epoch 478: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 208ms/step - loss: 0.0407 - accuracy: 0.9836 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9803 - precision: 0.9865 - val_loss: 1.5956 - val_accuracy: 0.8258 - val_sensitivity_at_specificity: 0.9951 - val_specificity_at_sensitivity: 0.8024 - val_recall: 0.9526 - val_precision: 0.7503\n",
            "Epoch 479/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0537 - accuracy: 0.9840 - sensitivity_at_specificity: 0.9976 - specificity_at_sensitivity: 0.9992 - recall: 0.9796 - precision: 0.9881\n",
            "Epoch 479: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 206ms/step - loss: 0.0537 - accuracy: 0.9840 - sensitivity_at_specificity: 0.9976 - specificity_at_sensitivity: 0.9992 - recall: 0.9796 - precision: 0.9881 - val_loss: 1.6936 - val_accuracy: 0.8180 - val_sensitivity_at_specificity: 0.9969 - val_specificity_at_sensitivity: 0.7550 - val_recall: 0.9764 - val_precision: 0.7399\n",
            "Epoch 480/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0393 - accuracy: 0.9859 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9883 - precision: 0.9837\n",
            "Epoch 480: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 205ms/step - loss: 0.0393 - accuracy: 0.9859 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9883 - precision: 0.9837 - val_loss: 1.3116 - val_accuracy: 0.8313 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8179 - val_recall: 0.9549 - val_precision: 0.7593\n",
            "Epoch 481/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0419 - accuracy: 0.9859 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9789 - precision: 0.9929\n",
            "Epoch 481: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 211ms/step - loss: 0.0419 - accuracy: 0.9859 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9789 - precision: 0.9929 - val_loss: 2.0756 - val_accuracy: 0.8117 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7333 - val_recall: 0.9806 - val_precision: 0.7264\n",
            "Epoch 482/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0437 - accuracy: 0.9863 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 1.0000 - recall: 0.9854 - precision: 0.9876\n",
            "Epoch 482: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 200ms/step - loss: 0.0437 - accuracy: 0.9863 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 1.0000 - recall: 0.9854 - precision: 0.9876 - val_loss: 1.7163 - val_accuracy: 0.8313 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7842 - val_recall: 0.9791 - val_precision: 0.7500\n",
            "Epoch 483/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.0510 - accuracy: 0.9809 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9789 - precision: 0.9823\n",
            "Epoch 483: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 200ms/step - loss: 0.0520 - accuracy: 0.9809 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9790 - precision: 0.9823 - val_loss: 1.4203 - val_accuracy: 0.8313 - val_sensitivity_at_specificity: 0.9953 - val_specificity_at_sensitivity: 0.7984 - val_recall: 0.9654 - val_precision: 0.7596\n",
            "Epoch 484/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0390 - accuracy: 0.9848 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9808 - precision: 0.9891\n",
            "Epoch 484: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 206ms/step - loss: 0.0390 - accuracy: 0.9848 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9808 - precision: 0.9891 - val_loss: 1.4607 - val_accuracy: 0.8281 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.8024 - val_recall: 0.9595 - val_precision: 0.7522\n",
            "Epoch 485/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0482 - accuracy: 0.9832 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9850 - precision: 0.9811\n",
            "Epoch 485: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 208ms/step - loss: 0.0482 - accuracy: 0.9832 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9850 - precision: 0.9811 - val_loss: 1.6170 - val_accuracy: 0.8289 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7887 - val_recall: 0.9641 - val_precision: 0.7592\n",
            "Epoch 486/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0409 - accuracy: 0.9855 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9769 - precision: 0.9935\n",
            "Epoch 486: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 204ms/step - loss: 0.0409 - accuracy: 0.9855 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9769 - precision: 0.9935 - val_loss: 1.5098 - val_accuracy: 0.8289 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.7966 - val_recall: 0.9665 - val_precision: 0.7534\n",
            "Epoch 487/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0513 - accuracy: 0.9832 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 0.9992 - recall: 0.9864 - precision: 0.9812\n",
            "Epoch 487: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 207ms/step - loss: 0.0513 - accuracy: 0.9832 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 0.9992 - recall: 0.9864 - precision: 0.9812 - val_loss: 1.3334 - val_accuracy: 0.8336 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.8037 - val_recall: 0.9592 - val_precision: 0.7660\n",
            "Epoch 488/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0510 - accuracy: 0.9816 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9763 - precision: 0.9876\n",
            "Epoch 488: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 212ms/step - loss: 0.0510 - accuracy: 0.9816 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9763 - precision: 0.9876 - val_loss: 1.4654 - val_accuracy: 0.8297 - val_sensitivity_at_specificity: 0.9984 - val_specificity_at_sensitivity: 0.7909 - val_recall: 0.9694 - val_precision: 0.7513\n",
            "Epoch 489/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0431 - accuracy: 0.9855 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9847 - precision: 0.9870\n",
            "Epoch 489: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 206ms/step - loss: 0.0431 - accuracy: 0.9855 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9847 - precision: 0.9870 - val_loss: 1.3194 - val_accuracy: 0.8313 - val_sensitivity_at_specificity: 0.9985 - val_specificity_at_sensitivity: 0.7940 - val_recall: 0.9661 - val_precision: 0.7637\n",
            "Epoch 490/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0476 - accuracy: 0.9816 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9813 - precision: 0.9805\n",
            "Epoch 490: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 210ms/step - loss: 0.0476 - accuracy: 0.9816 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9813 - precision: 0.9805 - val_loss: 1.3132 - val_accuracy: 0.8266 - val_sensitivity_at_specificity: 0.9970 - val_specificity_at_sensitivity: 0.8122 - val_recall: 0.9528 - val_precision: 0.7662\n",
            "Epoch 491/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0402 - accuracy: 0.9848 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9815 - precision: 0.9871\n",
            "Epoch 491: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 210ms/step - loss: 0.0402 - accuracy: 0.9848 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9815 - precision: 0.9871 - val_loss: 1.4332 - val_accuracy: 0.8273 - val_sensitivity_at_specificity: 0.9983 - val_specificity_at_sensitivity: 0.8085 - val_recall: 0.9750 - val_precision: 0.7399\n",
            "Epoch 492/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0395 - accuracy: 0.9848 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9819 - precision: 0.9874\n",
            "Epoch 492: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 209ms/step - loss: 0.0395 - accuracy: 0.9848 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9819 - precision: 0.9874 - val_loss: 1.6152 - val_accuracy: 0.8273 - val_sensitivity_at_specificity: 0.9969 - val_specificity_at_sensitivity: 0.7972 - val_recall: 0.9627 - val_precision: 0.7589\n",
            "Epoch 493/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0363 - accuracy: 0.9887 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 1.0000 - recall: 0.9869 - precision: 0.9907\n",
            "Epoch 493: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 207ms/step - loss: 0.0363 - accuracy: 0.9887 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 1.0000 - recall: 0.9869 - precision: 0.9907 - val_loss: 1.6256 - val_accuracy: 0.8313 - val_sensitivity_at_specificity: 0.9969 - val_specificity_at_sensitivity: 0.7734 - val_recall: 0.9781 - val_precision: 0.7560\n",
            "Epoch 494/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0474 - accuracy: 0.9844 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9817 - precision: 0.9877\n",
            "Epoch 494: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 209ms/step - loss: 0.0474 - accuracy: 0.9844 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9817 - precision: 0.9877 - val_loss: 1.3457 - val_accuracy: 0.8516 - val_sensitivity_at_specificity: 0.9969 - val_specificity_at_sensitivity: 0.8009 - val_recall: 0.9704 - val_precision: 0.7846\n",
            "Epoch 495/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0488 - accuracy: 0.9828 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9827 - precision: 0.9827\n",
            "Epoch 495: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 210ms/step - loss: 0.0488 - accuracy: 0.9828 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9827 - precision: 0.9827 - val_loss: 1.4407 - val_accuracy: 0.8383 - val_sensitivity_at_specificity: 0.9968 - val_specificity_at_sensitivity: 0.8124 - val_recall: 0.9709 - val_precision: 0.7608\n",
            "Epoch 496/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0445 - accuracy: 0.9848 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9766 - precision: 0.9939\n",
            "Epoch 496: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 208ms/step - loss: 0.0445 - accuracy: 0.9848 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9766 - precision: 0.9939 - val_loss: 1.4633 - val_accuracy: 0.8305 - val_sensitivity_at_specificity: 0.9969 - val_specificity_at_sensitivity: 0.7799 - val_recall: 0.9736 - val_precision: 0.7582\n",
            "Epoch 497/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0460 - accuracy: 0.9820 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9792 - precision: 0.9853\n",
            "Epoch 497: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 210ms/step - loss: 0.0460 - accuracy: 0.9820 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9792 - precision: 0.9853 - val_loss: 1.3574 - val_accuracy: 0.8328 - val_sensitivity_at_specificity: 0.9968 - val_specificity_at_sensitivity: 0.8108 - val_recall: 0.9429 - val_precision: 0.7694\n",
            "Epoch 498/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0458 - accuracy: 0.9832 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9801 - precision: 0.9856\n",
            "Epoch 498: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 208ms/step - loss: 0.0458 - accuracy: 0.9832 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9801 - precision: 0.9856 - val_loss: 1.4721 - val_accuracy: 0.8227 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.8087 - val_recall: 0.9655 - val_precision: 0.7500\n",
            "Epoch 499/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0374 - accuracy: 0.9879 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9850 - precision: 0.9905\n",
            "Epoch 499: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 207ms/step - loss: 0.0374 - accuracy: 0.9879 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9850 - precision: 0.9905 - val_loss: 1.5499 - val_accuracy: 0.8367 - val_sensitivity_at_specificity: 0.9952 - val_specificity_at_sensitivity: 0.8018 - val_recall: 0.9696 - val_precision: 0.7610\n",
            "Epoch 500/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0363 - accuracy: 0.9863 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9844 - precision: 0.9882\n",
            "Epoch 500: val_accuracy did not improve from 0.85781\n",
            "10/10 [==============================] - 2s 208ms/step - loss: 0.0363 - accuracy: 0.9863 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9844 - precision: 0.9882 - val_loss: 1.7505 - val_accuracy: 0.8266 - val_sensitivity_at_specificity: 1.0000 - val_specificity_at_sensitivity: 0.7622 - val_recall: 0.9792 - val_precision: 0.7451\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Performance Metrics**"
      ],
      "metadata": {
        "id": "dZqprJUwKVbU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Training_Accuracy=history.history['accuracy']\n",
        "Validation_Accuracy=history.history['val_accuracy']\n",
        "Validation_Specificity=history.history['val_specificity_at_sensitivity']\n",
        "Validation_Sensitivity=history.history['val_sensitivity_at_specificity']\n",
        "Validation_Recall=history.history['val_recall']\n",
        "Validation_Precision=history.history['val_precision']\n",
        "Validation_Loss=history.history['val_loss']\n",
        "\n",
        "print(\"Training Accuracy: \",max(Training_Accuracy))\n",
        "print(\"Validation Accuracy: \",max(Validation_Accuracy))\n",
        "print(\"Validation Specificity: \",max(Validation_Specificity))\n",
        "print(\"Validation Sensitivity: \",max(Validation_Sensitivity))\n",
        "print(\"Validation Recall: \",max(Validation_Recall))\n",
        "print(\"Validation Precision: \",max(Validation_Precision))\n",
        "print(\"Validation Loss: \",min(Validation_Loss))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCdS_0U65A0-",
        "outputId": "be57f82d-5924-48a3-a1cf-ef552ef34ebd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy:  0.9886718988418579\n",
            "Validation Accuracy:  0.8578125238418579\n",
            "Validation Specificity:  0.9649389982223511\n",
            "Validation Sensitivity:  1.0\n",
            "Validation Recall:  0.9984639286994934\n",
            "Validation Precision:  0.9166666865348816\n",
            "Validation Loss:  0.32372456789016724\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Accuracy Graph**"
      ],
      "metadata": {
        "id": "SlxHYVZeKYic"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLqjG2X-vdLj",
        "outputId": "fa0bae3d-ebfa-4f68-bd10-121c1d58c8a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        }
      },
      "source": [
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loss Graph**"
      ],
      "metadata": {
        "id": "WrNNat5eKasV"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBSAyVfivvHX",
        "outputId": "ff0cab23-9cfa-4819-d97f-5449878a9a85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        }
      },
      "source": [
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}