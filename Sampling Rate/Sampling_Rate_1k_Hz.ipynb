{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "7e88OLey6Bgd"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7e88OLey6Bgd"
      },
      "source": [
        "# **Image Classification with Convolutional Neural Networks (CNNs)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsTzc3oi726u"
      },
      "source": [
        "# **Building a Convolutional Neural Network with Keras**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import Libraries**"
      ],
      "metadata": {
        "id": "sfcLWPq-B3Ae"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCglDGFy8AhT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "66fccecc-1834-4703-fa87-af261eec5301"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "tf.__version__\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import matplotlib.image as mpimg\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "import imageio\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.8.2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qf7eW3HC9XVL"
      },
      "source": [
        "**Data Acquisition and ImageDataGenerator**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0BfyGlJbx0l"
      },
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255) #Normalize the pixel values\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hsimgs7aqt6G"
      },
      "source": [
        "#File path to the folder containin images\n",
        "train_dir = os.path.join('/content/spectrograms-1000/Train')\n",
        "validation_dir = os.path.join('/content/spectrograms-1000/Validation')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NyvlF41oqxEP",
        "outputId": "fff843b7-bc7f-47c9-f3b9-7a1f6c97c4f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(64,64),\n",
        "    batch_size=256,\n",
        "    shuffle=True,\n",
        "    class_mode='binary')\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    validation_dir,\n",
        "    target_size=(64,64),\n",
        "    batch_size=256,\n",
        "    shuffle=True,\n",
        "    class_mode='binary')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 33128 images belonging to 2 classes.\n",
            "Found 6780 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3yhwpN_-BaS"
      },
      "source": [
        "**Building the Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSzxq4KDtKN6"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "                                    \n",
        "    # First convolution layer \n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(64, 64, 3),use_bias=True),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "\n",
        "    # Second convolution layer \n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu',use_bias=True),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    \n",
        "\n",
        "    # Third convolution layer  \n",
        "    tf.keras.layers.Conv2D(256, (3,3), activation='relu',use_bias=True),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "\n",
        "  # Fourth convolution layer  \n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu',use_bias=True),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "\n",
        "\n",
        "    # Flatten the pooled feature maps\n",
        "    tf.keras.layers.Flatten(),\n",
        "\n",
        "    # Fully connected hidden layer\n",
        "    tf.keras.layers.Dense(8, activation='relu',use_bias=True),\n",
        "\n",
        "\n",
        "    # Output layer\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid',activity_regularizer=regularizers.L1(0.001))   \n",
        "\n",
        "])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MODEL SUMMARY**"
      ],
      "metadata": {
        "id": "pwBUcWprCcpe"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HU0RFGLtNJb",
        "outputId": "08c30a3c-9036-4547-f6ec-6ffdd88b7e8f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 62, 62, 64)        1792      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 31, 31, 64)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 31, 31, 64)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 29, 29, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 14, 14, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 12, 12, 256)       295168    \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 6, 6, 256)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 6, 6, 256)         0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 4, 4, 64)          147520    \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 2, 2, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 2, 2, 64)          0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 8)                 2056      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 520,401\n",
            "Trainable params: 520,401\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Optimizer Implementation and model training/validation**"
      ],
      "metadata": {
        "id": "BJeROSMQCgT2"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBN3GBMItPMH"
      },
      "source": [
        "#from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import SensitivityAtSpecificity,SpecificityAtSensitivity,Recall,Precision\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=Adam(learning_rate=0.001),\n",
        "              metrics=['accuracy',SensitivityAtSpecificity(0.5),SpecificityAtSensitivity(0.5),Recall(0.5),Precision(0.5)]) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Q0MPMwh3EgY"
      },
      "source": [
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('val_accuracy')>0.99): \n",
        "      print(\"\\nReached 99% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "callbacks = myCallback()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7f6gDG3dx9sJ",
        "outputId": "d167fbb7-1619-4876-a708-b2587db9251d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "checkpoint = ModelCheckpoint(\"ECG_Spectrogram_Model.h5\", monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
        "\n",
        "history = model.fit(\n",
        "      train_generator,\n",
        "      steps_per_epoch=10,  \n",
        "      epochs=500,\n",
        "      verbose=1,\n",
        "      validation_data = validation_generator,\n",
        "      validation_steps=5, \n",
        "      callbacks = [callbacks,checkpoint]\n",
        ") "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.7090 - accuracy: 0.5051 - sensitivity_at_specificity_1: 0.4721 - specificity_at_sensitivity_1: 0.4645 - recall_1: 0.5723 - precision_1: 0.5137\n",
            "Epoch 1: val_accuracy improved from -inf to 0.50234, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 17s 245ms/step - loss: 0.7090 - accuracy: 0.5051 - sensitivity_at_specificity_1: 0.4721 - specificity_at_sensitivity_1: 0.4645 - recall_1: 0.5723 - precision_1: 0.5137 - val_loss: 0.6937 - val_accuracy: 0.5023 - val_sensitivity_at_specificity_1: 0.0000e+00 - val_specificity_at_sensitivity_1: 0.0000e+00 - val_recall_1: 1.0000 - val_precision_1: 0.5023\n",
            "Epoch 2/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6953 - accuracy: 0.5016 - sensitivity_at_specificity_1: 0.4776 - specificity_at_sensitivity_1: 0.4033 - recall_1: 0.7337 - precision_1: 0.4992\n",
            "Epoch 2: val_accuracy did not improve from 0.50234\n",
            "10/10 [==============================] - 2s 175ms/step - loss: 0.6953 - accuracy: 0.5016 - sensitivity_at_specificity_1: 0.4776 - specificity_at_sensitivity_1: 0.4033 - recall_1: 0.7337 - precision_1: 0.4992 - val_loss: 0.6937 - val_accuracy: 0.4961 - val_sensitivity_at_specificity_1: 0.0000e+00 - val_specificity_at_sensitivity_1: 0.0000e+00 - val_recall_1: 1.0000 - val_precision_1: 0.4957\n",
            "Epoch 3/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6948 - accuracy: 0.4766 - sensitivity_at_specificity_1: 0.3150 - specificity_at_sensitivity_1: 0.4765 - recall_1: 0.2213 - precision_1: 0.4867\n",
            "Epoch 3: val_accuracy improved from 0.50234 to 0.51484, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.6948 - accuracy: 0.4766 - sensitivity_at_specificity_1: 0.3150 - specificity_at_sensitivity_1: 0.4765 - recall_1: 0.2213 - precision_1: 0.4867 - val_loss: 0.6933 - val_accuracy: 0.5148 - val_sensitivity_at_specificity_1: 0.0000e+00 - val_specificity_at_sensitivity_1: 0.0000e+00 - val_recall_1: 0.0000e+00 - val_precision_1: 0.0000e+00\n",
            "Epoch 4/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6931 - accuracy: 0.5250 - sensitivity_at_specificity_1: 0.5506 - specificity_at_sensitivity_1: 0.5159 - recall_1: 0.2699 - precision_1: 0.5714\n",
            "Epoch 4: val_accuracy improved from 0.51484 to 0.56797, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.6931 - accuracy: 0.5250 - sensitivity_at_specificity_1: 0.5506 - specificity_at_sensitivity_1: 0.5159 - recall_1: 0.2699 - precision_1: 0.5714 - val_loss: 0.6933 - val_accuracy: 0.5680 - val_sensitivity_at_specificity_1: 0.0000e+00 - val_specificity_at_sensitivity_1: 0.0226 - val_recall_1: 0.6888 - val_precision_1: 0.5407\n",
            "Epoch 5/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6886 - accuracy: 0.5641 - sensitivity_at_specificity_1: 0.5908 - specificity_at_sensitivity_1: 0.5976 - recall_1: 0.3792 - precision_1: 0.6147\n",
            "Epoch 5: val_accuracy did not improve from 0.56797\n",
            "10/10 [==============================] - 2s 156ms/step - loss: 0.6886 - accuracy: 0.5641 - sensitivity_at_specificity_1: 0.5908 - specificity_at_sensitivity_1: 0.5976 - recall_1: 0.3792 - precision_1: 0.6147 - val_loss: 0.6888 - val_accuracy: 0.5094 - val_sensitivity_at_specificity_1: 0.5283 - val_specificity_at_sensitivity_1: 0.6196 - val_recall_1: 0.0157 - val_precision_1: 0.8333\n",
            "Epoch 6/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6349 - accuracy: 0.5500 - sensitivity_at_specificity_1: 0.8618 - specificity_at_sensitivity_1: 0.7490 - recall_1: 0.1522 - precision_1: 0.7471\n",
            "Epoch 6: val_accuracy improved from 0.56797 to 0.58125, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.6349 - accuracy: 0.5500 - sensitivity_at_specificity_1: 0.8618 - specificity_at_sensitivity_1: 0.7490 - recall_1: 0.1522 - precision_1: 0.7471 - val_loss: 0.6611 - val_accuracy: 0.5813 - val_sensitivity_at_specificity_1: 0.6762 - val_specificity_at_sensitivity_1: 0.6003 - val_recall_1: 0.5774 - val_precision_1: 0.5719\n",
            "Epoch 7/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5194 - accuracy: 0.7320 - sensitivity_at_specificity_1: 0.9953 - specificity_at_sensitivity_1: 0.7500 - recall_1: 0.8860 - precision_1: 0.6757\n",
            "Epoch 7: val_accuracy improved from 0.58125 to 0.61250, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.5194 - accuracy: 0.7320 - sensitivity_at_specificity_1: 0.9953 - specificity_at_sensitivity_1: 0.7500 - recall_1: 0.8860 - precision_1: 0.6757 - val_loss: 0.6427 - val_accuracy: 0.6125 - val_sensitivity_at_specificity_1: 0.5677 - val_specificity_at_sensitivity_1: 0.5048 - val_recall_1: 0.9677 - val_precision_1: 0.5697\n",
            "Epoch 8/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4709 - accuracy: 0.7516 - sensitivity_at_specificity_1: 0.9992 - specificity_at_sensitivity_1: 0.7864 - recall_1: 0.9674 - precision_1: 0.6655\n",
            "Epoch 8: val_accuracy did not improve from 0.61250\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.4709 - accuracy: 0.7516 - sensitivity_at_specificity_1: 0.9992 - specificity_at_sensitivity_1: 0.7864 - recall_1: 0.9674 - precision_1: 0.6655 - val_loss: 0.6410 - val_accuracy: 0.5828 - val_sensitivity_at_specificity_1: 0.4904 - val_specificity_at_sensitivity_1: 0.2340 - val_recall_1: 0.9839 - val_precision_1: 0.5387\n",
            "Epoch 9/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4803 - accuracy: 0.7484 - sensitivity_at_specificity_1: 0.9992 - specificity_at_sensitivity_1: 0.7390 - recall_1: 0.9992 - precision_1: 0.6587\n",
            "Epoch 9: val_accuracy improved from 0.61250 to 0.61406, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.4803 - accuracy: 0.7484 - sensitivity_at_specificity_1: 0.9992 - specificity_at_sensitivity_1: 0.7390 - recall_1: 0.9992 - precision_1: 0.6587 - val_loss: 0.6128 - val_accuracy: 0.6141 - val_sensitivity_at_specificity_1: 0.1844 - val_specificity_at_sensitivity_1: 0.2672 - val_recall_1: 0.9891 - val_precision_1: 0.5652\n",
            "Epoch 10/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4936 - accuracy: 0.7406 - sensitivity_at_specificity_1: 0.9880 - specificity_at_sensitivity_1: 0.7504 - recall_1: 0.9825 - precision_1: 0.6574\n",
            "Epoch 10: val_accuracy did not improve from 0.61406\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.4936 - accuracy: 0.7406 - sensitivity_at_specificity_1: 0.9880 - specificity_at_sensitivity_1: 0.7504 - recall_1: 0.9825 - precision_1: 0.6574 - val_loss: 0.6886 - val_accuracy: 0.5445 - val_sensitivity_at_specificity_1: 0.0341 - val_specificity_at_sensitivity_1: 0.0961 - val_recall_1: 1.0000 - val_precision_1: 0.5252\n",
            "Epoch 11/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4896 - accuracy: 0.7437 - sensitivity_at_specificity_1: 0.9944 - specificity_at_sensitivity_1: 0.7268 - recall_1: 1.0000 - precision_1: 0.6571\n",
            "Epoch 11: val_accuracy did not improve from 0.61406\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.4896 - accuracy: 0.7437 - sensitivity_at_specificity_1: 0.9944 - specificity_at_sensitivity_1: 0.7268 - recall_1: 1.0000 - precision_1: 0.6571 - val_loss: 0.6225 - val_accuracy: 0.6141 - val_sensitivity_at_specificity_1: 0.0831 - val_specificity_at_sensitivity_1: 0.3366 - val_recall_1: 0.9789 - val_precision_1: 0.5745\n",
            "Epoch 12/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4700 - accuracy: 0.7703 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7581 - recall_1: 0.9895 - precision_1: 0.6960\n",
            "Epoch 12: val_accuracy did not improve from 0.61406\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.4700 - accuracy: 0.7703 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7581 - recall_1: 0.9895 - precision_1: 0.6960 - val_loss: 0.6655 - val_accuracy: 0.5906 - val_sensitivity_at_specificity_1: 0.2697 - val_specificity_at_sensitivity_1: 0.1981 - val_recall_1: 0.9984 - val_precision_1: 0.5476\n",
            "Epoch 13/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4643 - accuracy: 0.7625 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7633 - recall_1: 0.9850 - precision_1: 0.6794\n",
            "Epoch 13: val_accuracy improved from 0.61406 to 0.61875, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.4643 - accuracy: 0.7625 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7633 - recall_1: 0.9850 - precision_1: 0.6794 - val_loss: 0.6193 - val_accuracy: 0.6187 - val_sensitivity_at_specificity_1: 0.1504 - val_specificity_at_sensitivity_1: 0.2146 - val_recall_1: 0.9985 - val_precision_1: 0.5769\n",
            "Epoch 14/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4755 - accuracy: 0.7535 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7483 - recall_1: 0.9976 - precision_1: 0.6691\n",
            "Epoch 14: val_accuracy did not improve from 0.61875\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.4755 - accuracy: 0.7535 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7483 - recall_1: 0.9976 - precision_1: 0.6691 - val_loss: 0.6279 - val_accuracy: 0.6039 - val_sensitivity_at_specificity_1: 0.1945 - val_specificity_at_sensitivity_1: 0.3062 - val_recall_1: 0.9692 - val_precision_1: 0.5506\n",
            "Epoch 15/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4682 - accuracy: 0.7570 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7513 - recall_1: 0.9912 - precision_1: 0.6696\n",
            "Epoch 15: val_accuracy did not improve from 0.61875\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.4682 - accuracy: 0.7570 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7513 - recall_1: 0.9912 - precision_1: 0.6696 - val_loss: 0.6221 - val_accuracy: 0.6156 - val_sensitivity_at_specificity_1: 0.0498 - val_specificity_at_sensitivity_1: 0.2107 - val_recall_1: 0.9985 - val_precision_1: 0.5742\n",
            "Epoch 16/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4506 - accuracy: 0.7801 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7736 - recall_1: 0.9946 - precision_1: 0.6995\n",
            "Epoch 16: val_accuracy did not improve from 0.61875\n",
            "10/10 [==============================] - 2s 177ms/step - loss: 0.4506 - accuracy: 0.7801 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7736 - recall_1: 0.9946 - precision_1: 0.6995 - val_loss: 0.6491 - val_accuracy: 0.5992 - val_sensitivity_at_specificity_1: 0.1500 - val_specificity_at_sensitivity_1: 0.2047 - val_recall_1: 0.9984 - val_precision_1: 0.5552\n",
            "Epoch 17/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4550 - accuracy: 0.7777 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7488 - recall_1: 0.9939 - precision_1: 0.6976\n",
            "Epoch 17: val_accuracy did not improve from 0.61875\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.4550 - accuracy: 0.7777 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7488 - recall_1: 0.9939 - precision_1: 0.6976 - val_loss: 0.6341 - val_accuracy: 0.5945 - val_sensitivity_at_specificity_1: 0.0320 - val_specificity_at_sensitivity_1: 0.2137 - val_recall_1: 1.0000 - val_precision_1: 0.5463\n",
            "Epoch 18/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4488 - accuracy: 0.7781 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7484 - recall_1: 0.9984 - precision_1: 0.6937\n",
            "Epoch 18: val_accuracy did not improve from 0.61875\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.4488 - accuracy: 0.7781 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7484 - recall_1: 0.9984 - precision_1: 0.6937 - val_loss: 0.6327 - val_accuracy: 0.6094 - val_sensitivity_at_specificity_1: 0.5174 - val_specificity_at_sensitivity_1: 0.5331 - val_recall_1: 0.9652 - val_precision_1: 0.5722\n",
            "Epoch 19/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4493 - accuracy: 0.7746 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7481 - recall_1: 0.9937 - precision_1: 0.6886\n",
            "Epoch 19: val_accuracy did not improve from 0.61875\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.4493 - accuracy: 0.7746 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7481 - recall_1: 0.9937 - precision_1: 0.6886 - val_loss: 0.6328 - val_accuracy: 0.6047 - val_sensitivity_at_specificity_1: 0.1045 - val_specificity_at_sensitivity_1: 0.1971 - val_recall_1: 1.0000 - val_precision_1: 0.5627\n",
            "Epoch 20/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4590 - accuracy: 0.7781 - sensitivity_at_specificity_1: 0.9992 - specificity_at_sensitivity_1: 0.7842 - recall_1: 0.9932 - precision_1: 0.7030\n",
            "Epoch 20: val_accuracy did not improve from 0.61875\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.4590 - accuracy: 0.7781 - sensitivity_at_specificity_1: 0.9992 - specificity_at_sensitivity_1: 0.7842 - recall_1: 0.9932 - precision_1: 0.7030 - val_loss: 0.6631 - val_accuracy: 0.5891 - val_sensitivity_at_specificity_1: 0.0062 - val_specificity_at_sensitivity_1: 0.1815 - val_recall_1: 1.0000 - val_precision_1: 0.5493\n",
            "Epoch 21/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4566 - accuracy: 0.7723 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7402 - recall_1: 0.9968 - precision_1: 0.6843\n",
            "Epoch 21: val_accuracy did not improve from 0.61875\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.4566 - accuracy: 0.7723 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7402 - recall_1: 0.9968 - precision_1: 0.6843 - val_loss: 0.6209 - val_accuracy: 0.6070 - val_sensitivity_at_specificity_1: 0.0998 - val_specificity_at_sensitivity_1: 0.2645 - val_recall_1: 0.9797 - val_precision_1: 0.5617\n",
            "Epoch 22/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4539 - accuracy: 0.7723 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7544 - recall_1: 0.9936 - precision_1: 0.6848\n",
            "Epoch 22: val_accuracy improved from 0.61875 to 0.62266, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.4539 - accuracy: 0.7723 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7544 - recall_1: 0.9936 - precision_1: 0.6848 - val_loss: 0.6201 - val_accuracy: 0.6227 - val_sensitivity_at_specificity_1: 0.1246 - val_specificity_at_sensitivity_1: 0.2428 - val_recall_1: 0.9985 - val_precision_1: 0.5768\n",
            "Epoch 23/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4543 - accuracy: 0.7762 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7757 - recall_1: 0.9977 - precision_1: 0.6952\n",
            "Epoch 23: val_accuracy did not improve from 0.62266\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.4543 - accuracy: 0.7762 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7757 - recall_1: 0.9977 - precision_1: 0.6952 - val_loss: 0.6352 - val_accuracy: 0.5961 - val_sensitivity_at_specificity_1: 0.3365 - val_specificity_at_sensitivity_1: 0.2071 - val_recall_1: 0.9984 - val_precision_1: 0.5505\n",
            "Epoch 24/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4549 - accuracy: 0.7738 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7453 - recall_1: 0.9945 - precision_1: 0.6900\n",
            "Epoch 24: val_accuracy did not improve from 0.62266\n",
            "10/10 [==============================] - 2s 157ms/step - loss: 0.4549 - accuracy: 0.7738 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7453 - recall_1: 0.9945 - precision_1: 0.6900 - val_loss: 0.6508 - val_accuracy: 0.5797 - val_sensitivity_at_specificity_1: 0.2196 - val_specificity_at_sensitivity_1: 0.1716 - val_recall_1: 1.0000 - val_precision_1: 0.5406\n",
            "Epoch 25/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4543 - accuracy: 0.7727 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7690 - recall_1: 0.9953 - precision_1: 0.6870\n",
            "Epoch 25: val_accuracy improved from 0.62266 to 0.63203, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 245ms/step - loss: 0.4543 - accuracy: 0.7727 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7690 - recall_1: 0.9953 - precision_1: 0.6870 - val_loss: 0.6087 - val_accuracy: 0.6320 - val_sensitivity_at_specificity_1: 0.0852 - val_specificity_at_sensitivity_1: 0.2793 - val_recall_1: 0.9863 - val_precision_1: 0.5838\n",
            "Epoch 26/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4603 - accuracy: 0.7629 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7490 - recall_1: 0.9944 - precision_1: 0.6750\n",
            "Epoch 26: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 157ms/step - loss: 0.4603 - accuracy: 0.7629 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7490 - recall_1: 0.9944 - precision_1: 0.6750 - val_loss: 0.6081 - val_accuracy: 0.6172 - val_sensitivity_at_specificity_1: 0.0398 - val_specificity_at_sensitivity_1: 0.2715 - val_recall_1: 0.9904 - val_precision_1: 0.5624\n",
            "Epoch 27/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4399 - accuracy: 0.7832 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7521 - recall_1: 0.9936 - precision_1: 0.6948\n",
            "Epoch 27: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.4399 - accuracy: 0.7832 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7521 - recall_1: 0.9936 - precision_1: 0.6948 - val_loss: 0.6341 - val_accuracy: 0.6086 - val_sensitivity_at_specificity_1: 0.0016 - val_specificity_at_sensitivity_1: 0.4448 - val_recall_1: 1.0000 - val_precision_1: 0.5598\n",
            "Epoch 28/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4550 - accuracy: 0.7699 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7644 - recall_1: 0.9936 - precision_1: 0.6825\n",
            "Epoch 28: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.4550 - accuracy: 0.7699 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7644 - recall_1: 0.9936 - precision_1: 0.6825 - val_loss: 0.6200 - val_accuracy: 0.6086 - val_sensitivity_at_specificity_1: 0.1469 - val_specificity_at_sensitivity_1: 0.2219 - val_recall_1: 1.0000 - val_precision_1: 0.5609\n",
            "Epoch 29/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4602 - accuracy: 0.7605 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7672 - recall_1: 0.9919 - precision_1: 0.6705\n",
            "Epoch 29: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.4602 - accuracy: 0.7605 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7672 - recall_1: 0.9919 - precision_1: 0.6705 - val_loss: 0.6404 - val_accuracy: 0.6031 - val_sensitivity_at_specificity_1: 0.0277 - val_specificity_at_sensitivity_1: 0.1997 - val_recall_1: 0.9985 - val_precision_1: 0.5610\n",
            "Epoch 30/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4589 - accuracy: 0.7738 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7839 - recall_1: 0.9955 - precision_1: 0.6963\n",
            "Epoch 30: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.4589 - accuracy: 0.7738 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7839 - recall_1: 0.9955 - precision_1: 0.6963 - val_loss: 0.6560 - val_accuracy: 0.5813 - val_sensitivity_at_specificity_1: 0.0049 - val_specificity_at_sensitivity_1: 0.2027 - val_recall_1: 1.0000 - val_precision_1: 0.5319\n",
            "Epoch 31/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4551 - accuracy: 0.7781 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7553 - recall_1: 0.9985 - precision_1: 0.6999\n",
            "Epoch 31: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 157ms/step - loss: 0.4551 - accuracy: 0.7781 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7553 - recall_1: 0.9985 - precision_1: 0.6999 - val_loss: 0.6325 - val_accuracy: 0.6039 - val_sensitivity_at_specificity_1: 0.0378 - val_specificity_at_sensitivity_1: 0.2202 - val_recall_1: 1.0000 - val_precision_1: 0.5560\n",
            "Epoch 32/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4514 - accuracy: 0.7727 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7647 - recall_1: 0.9960 - precision_1: 0.6835\n",
            "Epoch 32: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.4514 - accuracy: 0.7727 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7647 - recall_1: 0.9960 - precision_1: 0.6835 - val_loss: 0.6238 - val_accuracy: 0.6141 - val_sensitivity_at_specificity_1: 0.0093 - val_specificity_at_sensitivity_1: 0.2275 - val_recall_1: 1.0000 - val_precision_1: 0.5670\n",
            "Epoch 33/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4480 - accuracy: 0.7781 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7658 - recall_1: 0.9875 - precision_1: 0.6959\n",
            "Epoch 33: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.4480 - accuracy: 0.7781 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7658 - recall_1: 0.9875 - precision_1: 0.6959 - val_loss: 0.6578 - val_accuracy: 0.5938 - val_sensitivity_at_specificity_1: 0.0063 - val_specificity_at_sensitivity_1: 0.1981 - val_recall_1: 1.0000 - val_precision_1: 0.5513\n",
            "Epoch 34/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4729 - accuracy: 0.7586 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7722 - recall_1: 1.0000 - precision_1: 0.6771\n",
            "Epoch 34: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.4729 - accuracy: 0.7586 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7722 - recall_1: 1.0000 - precision_1: 0.6771 - val_loss: 0.6394 - val_accuracy: 0.5844 - val_sensitivity_at_specificity_1: 0.0000e+00 - val_specificity_at_sensitivity_1: 0.1889 - val_recall_1: 1.0000 - val_precision_1: 0.5418\n",
            "Epoch 35/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4595 - accuracy: 0.7711 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7146 - recall_1: 0.9969 - precision_1: 0.6869\n",
            "Epoch 35: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.4595 - accuracy: 0.7711 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7146 - recall_1: 0.9969 - precision_1: 0.6869 - val_loss: 0.6305 - val_accuracy: 0.5961 - val_sensitivity_at_specificity_1: 0.0833 - val_specificity_at_sensitivity_1: 0.2454 - val_recall_1: 0.9872 - val_precision_1: 0.5476\n",
            "Epoch 36/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4533 - accuracy: 0.7801 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7646 - recall_1: 0.9932 - precision_1: 0.7042\n",
            "Epoch 36: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.4533 - accuracy: 0.7801 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7646 - recall_1: 0.9932 - precision_1: 0.7042 - val_loss: 0.6674 - val_accuracy: 0.5750 - val_sensitivity_at_specificity_1: 0.0200 - val_specificity_at_sensitivity_1: 0.2115 - val_recall_1: 0.9967 - val_precision_1: 0.5241\n",
            "Epoch 37/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4551 - accuracy: 0.7703 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7692 - recall_1: 0.9937 - precision_1: 0.6856\n",
            "Epoch 37: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.4551 - accuracy: 0.7703 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7692 - recall_1: 0.9937 - precision_1: 0.6856 - val_loss: 0.6451 - val_accuracy: 0.5945 - val_sensitivity_at_specificity_1: 0.0000e+00 - val_specificity_at_sensitivity_1: 0.1860 - val_recall_1: 1.0000 - val_precision_1: 0.5564\n",
            "Epoch 38/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4553 - accuracy: 0.7762 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7329 - recall_1: 0.9969 - precision_1: 0.6959\n",
            "Epoch 38: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.4553 - accuracy: 0.7762 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7329 - recall_1: 0.9969 - precision_1: 0.6959 - val_loss: 0.6397 - val_accuracy: 0.5906 - val_sensitivity_at_specificity_1: 0.0096 - val_specificity_at_sensitivity_1: 0.2702 - val_recall_1: 0.9888 - val_precision_1: 0.5445\n",
            "Epoch 39/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4515 - accuracy: 0.7805 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7429 - recall_1: 0.9970 - precision_1: 0.7027\n",
            "Epoch 39: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.4515 - accuracy: 0.7805 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7429 - recall_1: 0.9970 - precision_1: 0.7027 - val_loss: 0.6585 - val_accuracy: 0.5961 - val_sensitivity_at_specificity_1: 0.0293 - val_specificity_at_sensitivity_1: 0.2092 - val_recall_1: 0.9908 - val_precision_1: 0.5572\n",
            "Epoch 40/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4540 - accuracy: 0.7730 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7691 - recall_1: 0.9954 - precision_1: 0.6909\n",
            "Epoch 40: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.4540 - accuracy: 0.7730 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7691 - recall_1: 0.9954 - precision_1: 0.6909 - val_loss: 0.6093 - val_accuracy: 0.6195 - val_sensitivity_at_specificity_1: 0.0789 - val_specificity_at_sensitivity_1: 0.2601 - val_recall_1: 0.9968 - val_precision_1: 0.5658\n",
            "Epoch 41/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4524 - accuracy: 0.7832 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7633 - recall_1: 0.9963 - precision_1: 0.7074\n",
            "Epoch 41: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 157ms/step - loss: 0.4524 - accuracy: 0.7832 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7633 - recall_1: 0.9963 - precision_1: 0.7074 - val_loss: 0.6339 - val_accuracy: 0.6180 - val_sensitivity_at_specificity_1: 0.0104 - val_specificity_at_sensitivity_1: 0.2082 - val_recall_1: 1.0000 - val_precision_1: 0.5781\n",
            "Epoch 42/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4536 - accuracy: 0.7727 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7500 - recall_1: 0.9953 - precision_1: 0.6859\n",
            "Epoch 42: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.4536 - accuracy: 0.7727 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7500 - recall_1: 0.9953 - precision_1: 0.6859 - val_loss: 0.6597 - val_accuracy: 0.5766 - val_sensitivity_at_specificity_1: 0.0016 - val_specificity_at_sensitivity_1: 0.1792 - val_recall_1: 1.0000 - val_precision_1: 0.5364\n",
            "Epoch 43/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4654 - accuracy: 0.7641 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7164 - recall_1: 0.9953 - precision_1: 0.6817\n",
            "Epoch 43: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.4654 - accuracy: 0.7641 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7164 - recall_1: 0.9953 - precision_1: 0.6817 - val_loss: 0.6141 - val_accuracy: 0.6305 - val_sensitivity_at_specificity_1: 0.0045 - val_specificity_at_sensitivity_1: 0.2471 - val_recall_1: 0.9970 - val_precision_1: 0.5861\n",
            "Epoch 44/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4459 - accuracy: 0.7758 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7618 - recall_1: 0.9992 - precision_1: 0.6884\n",
            "Epoch 44: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.4459 - accuracy: 0.7758 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7618 - recall_1: 0.9992 - precision_1: 0.6884 - val_loss: 0.6427 - val_accuracy: 0.6070 - val_sensitivity_at_specificity_1: 0.0329 - val_specificity_at_sensitivity_1: 0.2402 - val_recall_1: 0.9937 - val_precision_1: 0.5600\n",
            "Epoch 45/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4500 - accuracy: 0.7742 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7760 - recall_1: 0.9944 - precision_1: 0.6871\n",
            "Epoch 45: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 157ms/step - loss: 0.4500 - accuracy: 0.7742 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7760 - recall_1: 0.9944 - precision_1: 0.6871 - val_loss: 0.6466 - val_accuracy: 0.5781 - val_sensitivity_at_specificity_1: 0.1987 - val_specificity_at_sensitivity_1: 0.1997 - val_recall_1: 1.0000 - val_precision_1: 0.5300\n",
            "Epoch 46/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4529 - accuracy: 0.7730 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7523 - recall_1: 0.9968 - precision_1: 0.6866\n",
            "Epoch 46: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.4529 - accuracy: 0.7730 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7523 - recall_1: 0.9968 - precision_1: 0.6866 - val_loss: 0.6654 - val_accuracy: 0.5906 - val_sensitivity_at_specificity_1: 0.0166 - val_specificity_at_sensitivity_1: 0.3580 - val_recall_1: 0.9156 - val_precision_1: 0.5390\n",
            "Epoch 47/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4576 - accuracy: 0.7668 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7741 - recall_1: 0.9895 - precision_1: 0.6777\n",
            "Epoch 47: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.4576 - accuracy: 0.7668 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7741 - recall_1: 0.9895 - precision_1: 0.6777 - val_loss: 0.6219 - val_accuracy: 0.6211 - val_sensitivity_at_specificity_1: 0.0015 - val_specificity_at_sensitivity_1: 0.2251 - val_recall_1: 1.0000 - val_precision_1: 0.5757\n",
            "Epoch 48/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4455 - accuracy: 0.7816 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7380 - recall_1: 0.9922 - precision_1: 0.6990\n",
            "Epoch 48: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.4455 - accuracy: 0.7816 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7380 - recall_1: 0.9922 - precision_1: 0.6990 - val_loss: 0.6416 - val_accuracy: 0.6023 - val_sensitivity_at_specificity_1: 0.0629 - val_specificity_at_sensitivity_1: 0.2158 - val_recall_1: 1.0000 - val_precision_1: 0.5555\n",
            "Epoch 49/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4521 - accuracy: 0.7762 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7793 - recall_1: 0.9915 - precision_1: 0.6957\n",
            "Epoch 49: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.4521 - accuracy: 0.7762 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7793 - recall_1: 0.9915 - precision_1: 0.6957 - val_loss: 0.6284 - val_accuracy: 0.6164 - val_sensitivity_at_specificity_1: 0.0670 - val_specificity_at_sensitivity_1: 0.3856 - val_recall_1: 0.9953 - val_precision_1: 0.5670\n",
            "Epoch 50/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4478 - accuracy: 0.7805 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7647 - recall_1: 0.9946 - precision_1: 0.6993\n",
            "Epoch 50: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.4478 - accuracy: 0.7805 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7647 - recall_1: 0.9946 - precision_1: 0.6993 - val_loss: 0.6394 - val_accuracy: 0.6016 - val_sensitivity_at_specificity_1: 0.0078 - val_specificity_at_sensitivity_1: 0.2240 - val_recall_1: 0.9984 - val_precision_1: 0.5555\n",
            "Epoch 51/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4682 - accuracy: 0.7594 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7401 - recall_1: 0.9920 - precision_1: 0.6707\n",
            "Epoch 51: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.4682 - accuracy: 0.7594 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7401 - recall_1: 0.9920 - precision_1: 0.6707 - val_loss: 0.6519 - val_accuracy: 0.5820 - val_sensitivity_at_specificity_1: 0.0000e+00 - val_specificity_at_sensitivity_1: 0.1958 - val_recall_1: 1.0000 - val_precision_1: 0.5372\n",
            "Epoch 52/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4677 - accuracy: 0.7648 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7559 - recall_1: 1.0000 - precision_1: 0.6825\n",
            "Epoch 52: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.4677 - accuracy: 0.7648 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7559 - recall_1: 1.0000 - precision_1: 0.6825 - val_loss: 0.6230 - val_accuracy: 0.6117 - val_sensitivity_at_specificity_1: 0.0000e+00 - val_specificity_at_sensitivity_1: 0.2125 - val_recall_1: 1.0000 - val_precision_1: 0.5682\n",
            "Epoch 53/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4554 - accuracy: 0.7738 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7715 - recall_1: 0.9984 - precision_1: 0.6886\n",
            "Epoch 53: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.4554 - accuracy: 0.7738 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7715 - recall_1: 0.9984 - precision_1: 0.6886 - val_loss: 0.6508 - val_accuracy: 0.5875 - val_sensitivity_at_specificity_1: 0.0632 - val_specificity_at_sensitivity_1: 0.3360 - val_recall_1: 0.9430 - val_precision_1: 0.5549\n",
            "Epoch 54/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4509 - accuracy: 0.7778 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7477 - recall_1: 0.9925 - precision_1: 0.6949\n",
            "Epoch 54: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 196ms/step - loss: 0.4509 - accuracy: 0.7778 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7477 - recall_1: 0.9925 - precision_1: 0.6949 - val_loss: 0.6243 - val_accuracy: 0.6203 - val_sensitivity_at_specificity_1: 0.2063 - val_specificity_at_sensitivity_1: 0.2240 - val_recall_1: 0.9970 - val_precision_1: 0.5777\n",
            "Epoch 55/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4612 - accuracy: 0.7684 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7692 - recall_1: 0.9962 - precision_1: 0.6876\n",
            "Epoch 55: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.4612 - accuracy: 0.7684 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7692 - recall_1: 0.9962 - precision_1: 0.6876 - val_loss: 0.6345 - val_accuracy: 0.6125 - val_sensitivity_at_specificity_1: 0.1031 - val_specificity_at_sensitivity_1: 0.2413 - val_recall_1: 0.9985 - val_precision_1: 0.5673\n",
            "Epoch 56/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4459 - accuracy: 0.7801 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7632 - recall_1: 0.9938 - precision_1: 0.6984\n",
            "Epoch 56: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.4459 - accuracy: 0.7801 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7632 - recall_1: 0.9938 - precision_1: 0.6984 - val_loss: 0.6495 - val_accuracy: 0.5906 - val_sensitivity_at_specificity_1: 0.2061 - val_specificity_at_sensitivity_1: 0.2398 - val_recall_1: 0.9984 - val_precision_1: 0.5424\n",
            "Epoch 57/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4639 - accuracy: 0.7578 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7394 - recall_1: 0.9847 - precision_1: 0.6709\n",
            "Epoch 57: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.4639 - accuracy: 0.7578 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7394 - recall_1: 0.9847 - precision_1: 0.6709 - val_loss: 0.6249 - val_accuracy: 0.6031 - val_sensitivity_at_specificity_1: 0.1198 - val_specificity_at_sensitivity_1: 0.3670 - val_recall_1: 0.9888 - val_precision_1: 0.5527\n",
            "Epoch 58/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4472 - accuracy: 0.7778 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7465 - recall_1: 0.9958 - precision_1: 0.6922\n",
            "Epoch 58: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.4472 - accuracy: 0.7778 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7465 - recall_1: 0.9958 - precision_1: 0.6922 - val_loss: 0.6308 - val_accuracy: 0.6109 - val_sensitivity_at_specificity_1: 0.4772 - val_specificity_at_sensitivity_1: 0.2589 - val_recall_1: 0.9984 - val_precision_1: 0.5606\n",
            "Epoch 59/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4490 - accuracy: 0.7766 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7682 - recall_1: 0.9942 - precision_1: 0.6920\n",
            "Epoch 59: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 153ms/step - loss: 0.4490 - accuracy: 0.7766 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7682 - recall_1: 0.9942 - precision_1: 0.6920 - val_loss: 0.6290 - val_accuracy: 0.6094 - val_sensitivity_at_specificity_1: 0.0096 - val_specificity_at_sensitivity_1: 0.2588 - val_recall_1: 1.0000 - val_precision_1: 0.5563\n",
            "Epoch 60/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4436 - accuracy: 0.7855 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7595 - recall_1: 0.9977 - precision_1: 0.7037\n",
            "Epoch 60: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.4436 - accuracy: 0.7855 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7595 - recall_1: 0.9977 - precision_1: 0.7037 - val_loss: 0.6269 - val_accuracy: 0.6227 - val_sensitivity_at_specificity_1: 0.0424 - val_specificity_at_sensitivity_1: 0.2597 - val_recall_1: 0.9985 - val_precision_1: 0.5776\n",
            "Epoch 61/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4419 - accuracy: 0.7785 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7677 - recall_1: 0.9968 - precision_1: 0.6860\n",
            "Epoch 61: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 177ms/step - loss: 0.4419 - accuracy: 0.7785 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7677 - recall_1: 0.9968 - precision_1: 0.6860 - val_loss: 0.6139 - val_accuracy: 0.6313 - val_sensitivity_at_specificity_1: 0.1044 - val_specificity_at_sensitivity_1: 0.2956 - val_recall_1: 0.9970 - val_precision_1: 0.5837\n",
            "Epoch 62/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4571 - accuracy: 0.7738 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7342 - recall_1: 0.9961 - precision_1: 0.6916\n",
            "Epoch 62: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.4571 - accuracy: 0.7738 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7342 - recall_1: 0.9961 - precision_1: 0.6916 - val_loss: 0.6499 - val_accuracy: 0.5930 - val_sensitivity_at_specificity_1: 0.0000e+00 - val_specificity_at_sensitivity_1: 0.1981 - val_recall_1: 1.0000 - val_precision_1: 0.5509\n",
            "Epoch 63/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4583 - accuracy: 0.7707 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7387 - recall_1: 0.9869 - precision_1: 0.6919\n",
            "Epoch 63: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.4583 - accuracy: 0.7707 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7387 - recall_1: 0.9869 - precision_1: 0.6919 - val_loss: 0.6536 - val_accuracy: 0.5875 - val_sensitivity_at_specificity_1: 0.3177 - val_specificity_at_sensitivity_1: 0.2030 - val_recall_1: 1.0000 - val_precision_1: 0.5401\n",
            "Epoch 64/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4464 - accuracy: 0.7793 - sensitivity_at_specificity_1: 0.9992 - specificity_at_sensitivity_1: 0.7642 - recall_1: 0.9897 - precision_1: 0.6928\n",
            "Epoch 64: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.4464 - accuracy: 0.7793 - sensitivity_at_specificity_1: 0.9992 - specificity_at_sensitivity_1: 0.7642 - recall_1: 0.9897 - precision_1: 0.6928 - val_loss: 0.6431 - val_accuracy: 0.6102 - val_sensitivity_at_specificity_1: 0.0000e+00 - val_specificity_at_sensitivity_1: 0.2137 - val_recall_1: 1.0000 - val_precision_1: 0.5668\n",
            "Epoch 65/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4589 - accuracy: 0.7684 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7696 - recall_1: 1.0000 - precision_1: 0.6803\n",
            "Epoch 65: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.4589 - accuracy: 0.7684 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7696 - recall_1: 1.0000 - precision_1: 0.6803 - val_loss: 0.6360 - val_accuracy: 0.5875 - val_sensitivity_at_specificity_1: 0.0081 - val_specificity_at_sensitivity_1: 0.2432 - val_recall_1: 0.9984 - val_precision_1: 0.5377\n",
            "Epoch 66/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4701 - accuracy: 0.7527 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7458 - recall_1: 0.9871 - precision_1: 0.6645\n",
            "Epoch 66: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.4701 - accuracy: 0.7527 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7458 - recall_1: 0.9871 - precision_1: 0.6645 - val_loss: 0.6342 - val_accuracy: 0.5852 - val_sensitivity_at_specificity_1: 0.0098 - val_specificity_at_sensitivity_1: 0.2108 - val_recall_1: 1.0000 - val_precision_1: 0.5350\n",
            "Epoch 67/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4530 - accuracy: 0.7793 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7550 - recall_1: 0.9962 - precision_1: 0.6999\n",
            "Epoch 67: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.4530 - accuracy: 0.7793 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7550 - recall_1: 0.9962 - precision_1: 0.6999 - val_loss: 0.6425 - val_accuracy: 0.6062 - val_sensitivity_at_specificity_1: 0.1108 - val_specificity_at_sensitivity_1: 0.1932 - val_recall_1: 0.9985 - val_precision_1: 0.5668\n",
            "Epoch 68/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4541 - accuracy: 0.7754 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7553 - recall_1: 0.9969 - precision_1: 0.6937\n",
            "Epoch 68: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.4541 - accuracy: 0.7754 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7553 - recall_1: 0.9969 - precision_1: 0.6937 - val_loss: 0.6535 - val_accuracy: 0.5914 - val_sensitivity_at_specificity_1: 0.0223 - val_specificity_at_sensitivity_1: 0.2083 - val_recall_1: 1.0000 - val_precision_1: 0.5452\n",
            "Epoch 69/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4471 - accuracy: 0.7816 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7464 - recall_1: 0.9939 - precision_1: 0.7033\n",
            "Epoch 69: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.4471 - accuracy: 0.7816 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7464 - recall_1: 0.9939 - precision_1: 0.7033 - val_loss: 0.6359 - val_accuracy: 0.6117 - val_sensitivity_at_specificity_1: 0.0108 - val_specificity_at_sensitivity_1: 0.2178 - val_recall_1: 0.9985 - val_precision_1: 0.5672\n",
            "Epoch 70/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4511 - accuracy: 0.7762 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7321 - recall_1: 0.9977 - precision_1: 0.6926\n",
            "Epoch 70: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.4511 - accuracy: 0.7762 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7321 - recall_1: 0.9977 - precision_1: 0.6926 - val_loss: 0.6610 - val_accuracy: 0.5773 - val_sensitivity_at_specificity_1: 0.2562 - val_specificity_at_sensitivity_1: 0.2296 - val_recall_1: 0.9983 - val_precision_1: 0.5280\n",
            "Epoch 71/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4311 - accuracy: 0.7914 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7486 - recall_1: 0.9929 - precision_1: 0.7062\n",
            "Epoch 71: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.4311 - accuracy: 0.7914 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7486 - recall_1: 0.9929 - precision_1: 0.7062 - val_loss: 0.6344 - val_accuracy: 0.6156 - val_sensitivity_at_specificity_1: 0.0376 - val_specificity_at_sensitivity_1: 0.2445 - val_recall_1: 1.0000 - val_precision_1: 0.5646\n",
            "Epoch 72/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4531 - accuracy: 0.7742 - sensitivity_at_specificity_1: 0.9992 - specificity_at_sensitivity_1: 0.7835 - recall_1: 0.9976 - precision_1: 0.6889\n",
            "Epoch 72: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.4531 - accuracy: 0.7742 - sensitivity_at_specificity_1: 0.9992 - specificity_at_sensitivity_1: 0.7835 - recall_1: 0.9976 - precision_1: 0.6889 - val_loss: 0.6274 - val_accuracy: 0.6148 - val_sensitivity_at_specificity_1: 0.0556 - val_specificity_at_sensitivity_1: 0.2862 - val_recall_1: 0.9952 - val_precision_1: 0.5613\n",
            "Epoch 73/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4424 - accuracy: 0.7898 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7946 - recall_1: 0.9933 - precision_1: 0.7160\n",
            "Epoch 73: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.4424 - accuracy: 0.7898 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7946 - recall_1: 0.9933 - precision_1: 0.7160 - val_loss: 0.6529 - val_accuracy: 0.5953 - val_sensitivity_at_specificity_1: 0.0240 - val_specificity_at_sensitivity_1: 0.2137 - val_recall_1: 1.0000 - val_precision_1: 0.5468\n",
            "Epoch 74/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4572 - accuracy: 0.7703 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7541 - recall_1: 0.9969 - precision_1: 0.6865\n",
            "Epoch 74: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.4572 - accuracy: 0.7703 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7541 - recall_1: 0.9969 - precision_1: 0.6865 - val_loss: 0.6287 - val_accuracy: 0.6242 - val_sensitivity_at_specificity_1: 0.2063 - val_specificity_at_sensitivity_1: 0.2209 - val_recall_1: 1.0000 - val_precision_1: 0.5817\n",
            "Epoch 75/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4668 - accuracy: 0.7620 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7277 - recall_1: 0.9992 - precision_1: 0.6783\n",
            "Epoch 75: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 157ms/step - loss: 0.4668 - accuracy: 0.7620 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7277 - recall_1: 0.9992 - precision_1: 0.6783 - val_loss: 0.6422 - val_accuracy: 0.5930 - val_sensitivity_at_specificity_1: 0.0464 - val_specificity_at_sensitivity_1: 0.2275 - val_recall_1: 0.9952 - val_precision_1: 0.5456\n",
            "Epoch 76/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4529 - accuracy: 0.7746 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7508 - recall_1: 0.9914 - precision_1: 0.6916\n",
            "Epoch 76: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.4529 - accuracy: 0.7746 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7508 - recall_1: 0.9914 - precision_1: 0.6916 - val_loss: 0.6347 - val_accuracy: 0.6172 - val_sensitivity_at_specificity_1: 0.0000e+00 - val_specificity_at_sensitivity_1: 0.3922 - val_recall_1: 1.0000 - val_precision_1: 0.5750\n",
            "Epoch 77/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4344 - accuracy: 0.7945 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7390 - recall_1: 0.9954 - precision_1: 0.7157\n",
            "Epoch 77: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.4344 - accuracy: 0.7945 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7390 - recall_1: 0.9954 - precision_1: 0.7157 - val_loss: 0.6560 - val_accuracy: 0.6039 - val_sensitivity_at_specificity_1: 0.0124 - val_specificity_at_sensitivity_1: 0.2123 - val_recall_1: 1.0000 - val_precision_1: 0.5595\n",
            "Epoch 78/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4501 - accuracy: 0.7762 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7432 - recall_1: 0.9945 - precision_1: 0.6921\n",
            "Epoch 78: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.4501 - accuracy: 0.7762 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7432 - recall_1: 0.9945 - precision_1: 0.6921 - val_loss: 0.6382 - val_accuracy: 0.6148 - val_sensitivity_at_specificity_1: 0.0138 - val_specificity_at_sensitivity_1: 0.2220 - val_recall_1: 0.9985 - val_precision_1: 0.5703\n",
            "Epoch 79/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4494 - accuracy: 0.7746 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7618 - recall_1: 0.9960 - precision_1: 0.6874\n",
            "Epoch 79: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 157ms/step - loss: 0.4494 - accuracy: 0.7746 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7618 - recall_1: 0.9960 - precision_1: 0.6874 - val_loss: 0.6416 - val_accuracy: 0.5898 - val_sensitivity_at_specificity_1: 0.0000e+00 - val_specificity_at_sensitivity_1: 0.2780 - val_recall_1: 0.9967 - val_precision_1: 0.5380\n",
            "Epoch 80/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4536 - accuracy: 0.7809 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7290 - recall_1: 0.9970 - precision_1: 0.7044\n",
            "Epoch 80: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 157ms/step - loss: 0.4536 - accuracy: 0.7809 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7290 - recall_1: 0.9970 - precision_1: 0.7044 - val_loss: 0.6561 - val_accuracy: 0.5984 - val_sensitivity_at_specificity_1: 0.0764 - val_specificity_at_sensitivity_1: 0.2347 - val_recall_1: 0.9938 - val_precision_1: 0.5554\n",
            "Epoch 81/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4371 - accuracy: 0.7848 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7686 - recall_1: 0.9944 - precision_1: 0.6949\n",
            "Epoch 81: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.4371 - accuracy: 0.7848 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7686 - recall_1: 0.9944 - precision_1: 0.6949 - val_loss: 0.6494 - val_accuracy: 0.5992 - val_sensitivity_at_specificity_1: 0.0016 - val_specificity_at_sensitivity_1: 0.2304 - val_recall_1: 1.0000 - val_precision_1: 0.5558\n",
            "Epoch 82/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4488 - accuracy: 0.7730 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7644 - recall_1: 0.9905 - precision_1: 0.6870\n",
            "Epoch 82: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 156ms/step - loss: 0.4488 - accuracy: 0.7730 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7644 - recall_1: 0.9905 - precision_1: 0.6870 - val_loss: 0.6681 - val_accuracy: 0.5844 - val_sensitivity_at_specificity_1: 0.0032 - val_specificity_at_sensitivity_1: 0.1941 - val_recall_1: 1.0000 - val_precision_1: 0.5426\n",
            "Epoch 83/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4567 - accuracy: 0.7738 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7196 - recall_1: 0.9992 - precision_1: 0.6911\n",
            "Epoch 83: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.4567 - accuracy: 0.7738 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7196 - recall_1: 0.9992 - precision_1: 0.6911 - val_loss: 0.6497 - val_accuracy: 0.5969 - val_sensitivity_at_specificity_1: 0.0000e+00 - val_specificity_at_sensitivity_1: 0.2729 - val_recall_1: 0.9622 - val_precision_1: 0.5539\n",
            "Epoch 84/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4571 - accuracy: 0.7699 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7628 - recall_1: 0.9930 - precision_1: 0.6878\n",
            "Epoch 84: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.4571 - accuracy: 0.7699 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7628 - recall_1: 0.9930 - precision_1: 0.6878 - val_loss: 0.6633 - val_accuracy: 0.5859 - val_sensitivity_at_specificity_1: 0.0063 - val_specificity_at_sensitivity_1: 0.1825 - val_recall_1: 1.0000 - val_precision_1: 0.5466\n",
            "Epoch 85/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4526 - accuracy: 0.7754 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7745 - recall_1: 0.9893 - precision_1: 0.6971\n",
            "Epoch 85: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.4526 - accuracy: 0.7754 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7745 - recall_1: 0.9893 - precision_1: 0.6971 - val_loss: 0.6422 - val_accuracy: 0.6094 - val_sensitivity_at_specificity_1: 0.0000e+00 - val_specificity_at_sensitivity_1: 0.2273 - val_recall_1: 1.0000 - val_precision_1: 0.5622\n",
            "Epoch 86/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4395 - accuracy: 0.7848 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7845 - recall_1: 0.9921 - precision_1: 0.6996\n",
            "Epoch 86: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 174ms/step - loss: 0.4395 - accuracy: 0.7848 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7845 - recall_1: 0.9921 - precision_1: 0.6996 - val_loss: 0.6623 - val_accuracy: 0.5938 - val_sensitivity_at_specificity_1: 0.0000e+00 - val_specificity_at_sensitivity_1: 0.2093 - val_recall_1: 1.0000 - val_precision_1: 0.5498\n",
            "Epoch 87/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4514 - accuracy: 0.7762 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7504 - recall_1: 0.9914 - precision_1: 0.6927\n",
            "Epoch 87: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.4514 - accuracy: 0.7762 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7504 - recall_1: 0.9914 - precision_1: 0.6927 - val_loss: 0.6231 - val_accuracy: 0.6227 - val_sensitivity_at_specificity_1: 0.0000e+00 - val_specificity_at_sensitivity_1: 0.2973 - val_recall_1: 0.9984 - val_precision_1: 0.5704\n",
            "Epoch 88/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4512 - accuracy: 0.7762 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7814 - recall_1: 0.9992 - precision_1: 0.6931\n",
            "Epoch 88: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.4512 - accuracy: 0.7762 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7814 - recall_1: 0.9992 - precision_1: 0.6931 - val_loss: 0.6455 - val_accuracy: 0.6023 - val_sensitivity_at_specificity_1: 0.0109 - val_specificity_at_sensitivity_1: 0.2578 - val_recall_1: 0.9937 - val_precision_1: 0.5574\n",
            "Epoch 89/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4546 - accuracy: 0.7715 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7407 - recall_1: 0.9937 - precision_1: 0.6873\n",
            "Epoch 89: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.4546 - accuracy: 0.7715 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7407 - recall_1: 0.9937 - precision_1: 0.6873 - val_loss: 0.6373 - val_accuracy: 0.6117 - val_sensitivity_at_specificity_1: 0.0015 - val_specificity_at_sensitivity_1: 0.2326 - val_recall_1: 0.9969 - val_precision_1: 0.5662\n",
            "Epoch 90/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4385 - accuracy: 0.7883 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7831 - recall_1: 0.9961 - precision_1: 0.7064\n",
            "Epoch 90: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.4385 - accuracy: 0.7883 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7831 - recall_1: 0.9961 - precision_1: 0.7064 - val_loss: 0.6358 - val_accuracy: 0.6203 - val_sensitivity_at_specificity_1: 0.0000e+00 - val_specificity_at_sensitivity_1: 0.2813 - val_recall_1: 0.9925 - val_precision_1: 0.5784\n",
            "Epoch 91/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4522 - accuracy: 0.7811 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7158 - recall_1: 0.9968 - precision_1: 0.7027\n",
            "Epoch 91: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 157ms/step - loss: 0.4522 - accuracy: 0.7811 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7158 - recall_1: 0.9968 - precision_1: 0.7027 - val_loss: 0.6319 - val_accuracy: 0.6273 - val_sensitivity_at_specificity_1: 0.0000e+00 - val_specificity_at_sensitivity_1: 0.3268 - val_recall_1: 0.9985 - val_precision_1: 0.5825\n",
            "Epoch 92/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4511 - accuracy: 0.7762 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7665 - recall_1: 0.9946 - precision_1: 0.6936\n",
            "Epoch 92: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.4511 - accuracy: 0.7762 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7665 - recall_1: 0.9946 - precision_1: 0.6936 - val_loss: 0.6438 - val_accuracy: 0.6117 - val_sensitivity_at_specificity_1: 0.0000e+00 - val_specificity_at_sensitivity_1: 0.2049 - val_recall_1: 1.0000 - val_precision_1: 0.5723\n",
            "Epoch 93/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4595 - accuracy: 0.7676 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7360 - recall_1: 0.9984 - precision_1: 0.6817\n",
            "Epoch 93: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.4595 - accuracy: 0.7676 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7360 - recall_1: 0.9984 - precision_1: 0.6817 - val_loss: 0.6177 - val_accuracy: 0.6313 - val_sensitivity_at_specificity_1: 0.0000e+00 - val_specificity_at_sensitivity_1: 0.3010 - val_recall_1: 0.9896 - val_precision_1: 0.5885\n",
            "Epoch 94/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4467 - accuracy: 0.7785 - sensitivity_at_specificity_1: 0.9992 - specificity_at_sensitivity_1: 0.7807 - recall_1: 0.9921 - precision_1: 0.6926\n",
            "Epoch 94: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.4467 - accuracy: 0.7785 - sensitivity_at_specificity_1: 0.9992 - specificity_at_sensitivity_1: 0.7807 - recall_1: 0.9921 - precision_1: 0.6926 - val_loss: 0.6529 - val_accuracy: 0.5961 - val_sensitivity_at_specificity_1: 0.0000e+00 - val_specificity_at_sensitivity_1: 0.1997 - val_recall_1: 1.0000 - val_precision_1: 0.5528\n",
            "Epoch 95/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4544 - accuracy: 0.7707 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7619 - recall_1: 0.9913 - precision_1: 0.6847\n",
            "Epoch 95: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.4544 - accuracy: 0.7707 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7619 - recall_1: 0.9913 - precision_1: 0.6847 - val_loss: 0.6415 - val_accuracy: 0.6141 - val_sensitivity_at_specificity_1: 0.0000e+00 - val_specificity_at_sensitivity_1: 0.2074 - val_recall_1: 1.0000 - val_precision_1: 0.5712\n",
            "Epoch 96/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4518 - accuracy: 0.7766 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7363 - recall_1: 0.9992 - precision_1: 0.6923\n",
            "Epoch 96: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.4518 - accuracy: 0.7766 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7363 - recall_1: 0.9992 - precision_1: 0.6923 - val_loss: 0.6381 - val_accuracy: 0.6148 - val_sensitivity_at_specificity_1: 0.4114 - val_specificity_at_sensitivity_1: 0.2101 - val_recall_1: 1.0000 - val_precision_1: 0.5746\n",
            "Epoch 97/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4528 - accuracy: 0.7734 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7391 - recall_1: 0.9820 - precision_1: 0.6923\n",
            "Epoch 97: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.4528 - accuracy: 0.7734 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7391 - recall_1: 0.9820 - precision_1: 0.6923 - val_loss: 0.6548 - val_accuracy: 0.6023 - val_sensitivity_at_specificity_1: 0.0061 - val_specificity_at_sensitivity_1: 0.1946 - val_recall_1: 1.0000 - val_precision_1: 0.5620\n",
            "Epoch 98/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4460 - accuracy: 0.7844 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7472 - recall_1: 0.9962 - precision_1: 0.7065\n",
            "Epoch 98: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.4460 - accuracy: 0.7844 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7472 - recall_1: 0.9962 - precision_1: 0.7065 - val_loss: 0.6294 - val_accuracy: 0.6320 - val_sensitivity_at_specificity_1: 0.0000e+00 - val_specificity_at_sensitivity_1: 0.2998 - val_recall_1: 0.9839 - val_precision_1: 0.5936\n",
            "Epoch 99/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4539 - accuracy: 0.7746 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7677 - recall_1: 0.9961 - precision_1: 0.6920\n",
            "Epoch 99: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.4539 - accuracy: 0.7746 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7677 - recall_1: 0.9961 - precision_1: 0.6920 - val_loss: 0.6372 - val_accuracy: 0.6164 - val_sensitivity_at_specificity_1: 0.0000e+00 - val_specificity_at_sensitivity_1: 0.2256 - val_recall_1: 1.0000 - val_precision_1: 0.5716\n",
            "Epoch 100/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4390 - accuracy: 0.7875 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7804 - recall_1: 0.9923 - precision_1: 0.7077\n",
            "Epoch 100: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.4390 - accuracy: 0.7875 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7804 - recall_1: 0.9923 - precision_1: 0.7077 - val_loss: 0.6450 - val_accuracy: 0.6008 - val_sensitivity_at_specificity_1: 0.0000e+00 - val_specificity_at_sensitivity_1: 0.2622 - val_recall_1: 0.9968 - val_precision_1: 0.5500\n",
            "Epoch 101/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4428 - accuracy: 0.7841 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7458 - recall_1: 0.9967 - precision_1: 0.7028\n",
            "Epoch 101: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 156ms/step - loss: 0.4428 - accuracy: 0.7841 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7458 - recall_1: 0.9967 - precision_1: 0.7028 - val_loss: 0.6535 - val_accuracy: 0.6039 - val_sensitivity_at_specificity_1: 0.1104 - val_specificity_at_sensitivity_1: 0.2214 - val_recall_1: 0.9984 - val_precision_1: 0.5592\n",
            "Epoch 102/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4324 - accuracy: 0.7902 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7661 - recall_1: 0.9946 - precision_1: 0.7077\n",
            "Epoch 102: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.4324 - accuracy: 0.7902 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7661 - recall_1: 0.9946 - precision_1: 0.7077 - val_loss: 0.6504 - val_accuracy: 0.6023 - val_sensitivity_at_specificity_1: 0.0000e+00 - val_specificity_at_sensitivity_1: 0.2605 - val_recall_1: 0.9953 - val_precision_1: 0.5554\n",
            "Epoch 103/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4468 - accuracy: 0.7805 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7486 - recall_1: 0.9961 - precision_1: 0.6971\n",
            "Epoch 103: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.4468 - accuracy: 0.7805 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7486 - recall_1: 0.9961 - precision_1: 0.6971 - val_loss: 0.6373 - val_accuracy: 0.6086 - val_sensitivity_at_specificity_1: 0.0095 - val_specificity_at_sensitivity_1: 0.2688 - val_recall_1: 0.9873 - val_precision_1: 0.5575\n",
            "Epoch 104/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4454 - accuracy: 0.7785 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7238 - recall_1: 0.9945 - precision_1: 0.6918\n",
            "Epoch 104: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.4454 - accuracy: 0.7785 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7238 - recall_1: 0.9945 - precision_1: 0.6918 - val_loss: 0.6190 - val_accuracy: 0.6305 - val_sensitivity_at_specificity_1: 0.0000e+00 - val_specificity_at_sensitivity_1: 0.2857 - val_recall_1: 0.9954 - val_precision_1: 0.5819\n",
            "Epoch 105/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4359 - accuracy: 0.7945 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7496 - recall_1: 0.9992 - precision_1: 0.7150\n",
            "Epoch 105: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.4359 - accuracy: 0.7945 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7496 - recall_1: 0.9992 - precision_1: 0.7150 - val_loss: 0.6399 - val_accuracy: 0.6117 - val_sensitivity_at_specificity_1: 0.0683 - val_specificity_at_sensitivity_1: 0.2579 - val_recall_1: 0.9922 - val_precision_1: 0.5650\n",
            "Epoch 106/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4509 - accuracy: 0.7742 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7625 - recall_1: 0.9928 - precision_1: 0.6865\n",
            "Epoch 106: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.4509 - accuracy: 0.7742 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7625 - recall_1: 0.9928 - precision_1: 0.6865 - val_loss: 0.6567 - val_accuracy: 0.5938 - val_sensitivity_at_specificity_1: 0.0063 - val_specificity_at_sensitivity_1: 0.2083 - val_recall_1: 1.0000 - val_precision_1: 0.5486\n",
            "Epoch 107/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4552 - accuracy: 0.7676 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7500 - recall_1: 0.9849 - precision_1: 0.6830\n",
            "Epoch 107: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.4552 - accuracy: 0.7676 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7500 - recall_1: 0.9849 - precision_1: 0.6830 - val_loss: 0.6393 - val_accuracy: 0.6031 - val_sensitivity_at_specificity_1: 0.0000e+00 - val_specificity_at_sensitivity_1: 0.2210 - val_recall_1: 0.9984 - val_precision_1: 0.5584\n",
            "Epoch 108/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4528 - accuracy: 0.7719 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7570 - recall_1: 0.9992 - precision_1: 0.6855\n",
            "Epoch 108: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.4528 - accuracy: 0.7719 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7570 - recall_1: 0.9992 - precision_1: 0.6855 - val_loss: 0.6295 - val_accuracy: 0.6219 - val_sensitivity_at_specificity_1: 0.0000e+00 - val_specificity_at_sensitivity_1: 0.2652 - val_recall_1: 1.0000 - val_precision_1: 0.5747\n",
            "Epoch 109/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4637 - accuracy: 0.7637 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7245 - recall_1: 0.9897 - precision_1: 0.6795\n",
            "Epoch 109: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.4637 - accuracy: 0.7637 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7245 - recall_1: 0.9897 - precision_1: 0.6795 - val_loss: 0.6262 - val_accuracy: 0.6156 - val_sensitivity_at_specificity_1: 0.0000e+00 - val_specificity_at_sensitivity_1: 0.2689 - val_recall_1: 0.9984 - val_precision_1: 0.5628\n",
            "Epoch 110/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4476 - accuracy: 0.7781 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7395 - recall_1: 0.9992 - precision_1: 0.6925\n",
            "Epoch 110: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.4476 - accuracy: 0.7781 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7395 - recall_1: 0.9992 - precision_1: 0.6925 - val_loss: 0.6406 - val_accuracy: 0.6164 - val_sensitivity_at_specificity_1: 0.0000e+00 - val_specificity_at_sensitivity_1: 0.4812 - val_recall_1: 0.9940 - val_precision_1: 0.5765\n",
            "Epoch 111/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4477 - accuracy: 0.7820 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7181 - recall_1: 0.9939 - precision_1: 0.7038\n",
            "Epoch 111: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.4477 - accuracy: 0.7820 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7181 - recall_1: 0.9939 - precision_1: 0.7038 - val_loss: 0.6307 - val_accuracy: 0.6242 - val_sensitivity_at_specificity_1: 0.0000e+00 - val_specificity_at_sensitivity_1: 0.2625 - val_recall_1: 0.9985 - val_precision_1: 0.5782\n",
            "Epoch 112/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4562 - accuracy: 0.7691 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7581 - recall_1: 0.9889 - precision_1: 0.6845\n",
            "Epoch 112: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.4562 - accuracy: 0.7691 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7581 - recall_1: 0.9889 - precision_1: 0.6845 - val_loss: 0.6574 - val_accuracy: 0.6000 - val_sensitivity_at_specificity_1: 0.0000e+00 - val_specificity_at_sensitivity_1: 0.2094 - val_recall_1: 1.0000 - val_precision_1: 0.5575\n",
            "Epoch 113/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4389 - accuracy: 0.7863 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7752 - recall_1: 0.9938 - precision_1: 0.7037\n",
            "Epoch 113: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.4389 - accuracy: 0.7863 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7752 - recall_1: 0.9938 - precision_1: 0.7037 - val_loss: 0.6420 - val_accuracy: 0.6109 - val_sensitivity_at_specificity_1: 0.0000e+00 - val_specificity_at_sensitivity_1: 0.2296 - val_recall_1: 1.0000 - val_precision_1: 0.5639\n",
            "Epoch 114/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4407 - accuracy: 0.7832 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7408 - recall_1: 0.9984 - precision_1: 0.6985\n",
            "Epoch 114: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.4407 - accuracy: 0.7832 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7408 - recall_1: 0.9984 - precision_1: 0.6985 - val_loss: 0.6404 - val_accuracy: 0.6187 - val_sensitivity_at_specificity_1: 0.0317 - val_specificity_at_sensitivity_1: 0.2330 - val_recall_1: 0.9985 - val_precision_1: 0.5758\n",
            "Epoch 115/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4743 - accuracy: 0.7594 - sensitivity_at_specificity_1: 0.9992 - specificity_at_sensitivity_1: 0.7023 - recall_1: 0.9970 - precision_1: 0.6821\n",
            "Epoch 115: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.4743 - accuracy: 0.7594 - sensitivity_at_specificity_1: 0.9992 - specificity_at_sensitivity_1: 0.7023 - recall_1: 0.9970 - precision_1: 0.6821 - val_loss: 0.6729 - val_accuracy: 0.5727 - val_sensitivity_at_specificity_1: 0.0000e+00 - val_specificity_at_sensitivity_1: 0.2110 - val_recall_1: 0.9984 - val_precision_1: 0.5260\n",
            "Epoch 116/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4535 - accuracy: 0.7695 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7647 - recall_1: 0.9882 - precision_1: 0.6854\n",
            "Epoch 116: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.4535 - accuracy: 0.7695 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7647 - recall_1: 0.9882 - precision_1: 0.6854 - val_loss: 0.6471 - val_accuracy: 0.6039 - val_sensitivity_at_specificity_1: 0.0015 - val_specificity_at_sensitivity_1: 0.2133 - val_recall_1: 1.0000 - val_precision_1: 0.5607\n",
            "Epoch 117/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4619 - accuracy: 0.7637 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7120 - recall_1: 0.9889 - precision_1: 0.6779\n",
            "Epoch 117: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.4619 - accuracy: 0.7637 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7120 - recall_1: 0.9889 - precision_1: 0.6779 - val_loss: 0.6374 - val_accuracy: 0.6109 - val_sensitivity_at_specificity_1: 0.0000e+00 - val_specificity_at_sensitivity_1: 0.2289 - val_recall_1: 0.9985 - val_precision_1: 0.5667\n",
            "Epoch 118/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4502 - accuracy: 0.7758 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7774 - recall_1: 0.9914 - precision_1: 0.6918\n",
            "Epoch 118: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.4502 - accuracy: 0.7758 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7774 - recall_1: 0.9914 - precision_1: 0.6918 - val_loss: 0.6617 - val_accuracy: 0.5867 - val_sensitivity_at_specificity_1: 0.0000e+00 - val_specificity_at_sensitivity_1: 0.3845 - val_recall_1: 0.9953 - val_precision_1: 0.5458\n",
            "Epoch 119/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4307 - accuracy: 0.7926 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7876 - recall_1: 0.9961 - precision_1: 0.7094\n",
            "Epoch 119: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.4307 - accuracy: 0.7926 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7876 - recall_1: 0.9961 - precision_1: 0.7094 - val_loss: 0.6598 - val_accuracy: 0.6023 - val_sensitivity_at_specificity_1: 0.3251 - val_specificity_at_sensitivity_1: 0.3155 - val_recall_1: 0.9876 - val_precision_1: 0.5601\n",
            "Epoch 120/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4470 - accuracy: 0.7812 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7575 - recall_1: 0.9946 - precision_1: 0.6988\n",
            "Epoch 120: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.4470 - accuracy: 0.7812 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7575 - recall_1: 0.9946 - precision_1: 0.6988 - val_loss: 0.6463 - val_accuracy: 0.6062 - val_sensitivity_at_specificity_1: 0.0000e+00 - val_specificity_at_sensitivity_1: 0.2672 - val_recall_1: 0.9968 - val_precision_1: 0.5538\n",
            "Epoch 121/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4449 - accuracy: 0.7832 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7250 - recall_1: 0.9939 - precision_1: 0.7058\n",
            "Epoch 121: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.4449 - accuracy: 0.7832 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7250 - recall_1: 0.9939 - precision_1: 0.7058 - val_loss: 0.6515 - val_accuracy: 0.5984 - val_sensitivity_at_specificity_1: 0.0000e+00 - val_specificity_at_sensitivity_1: 0.2561 - val_recall_1: 0.9968 - val_precision_1: 0.5469\n",
            "Epoch 122/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4352 - accuracy: 0.7898 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7484 - recall_1: 0.9923 - precision_1: 0.7089\n",
            "Epoch 122: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.4352 - accuracy: 0.7898 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7484 - recall_1: 0.9923 - precision_1: 0.7089 - val_loss: 0.6541 - val_accuracy: 0.6055 - val_sensitivity_at_specificity_1: 0.1935 - val_specificity_at_sensitivity_1: 0.2287 - val_recall_1: 1.0000 - val_precision_1: 0.5613\n",
            "Epoch 123/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4481 - accuracy: 0.7773 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7364 - recall_1: 0.9984 - precision_1: 0.6913\n",
            "Epoch 123: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.4481 - accuracy: 0.7773 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7364 - recall_1: 0.9984 - precision_1: 0.6913 - val_loss: 0.6663 - val_accuracy: 0.5898 - val_sensitivity_at_specificity_1: 0.0000e+00 - val_specificity_at_sensitivity_1: 0.1934 - val_recall_1: 0.9984 - val_precision_1: 0.5510\n",
            "Epoch 124/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4511 - accuracy: 0.7719 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7132 - recall_1: 0.9920 - precision_1: 0.6846\n",
            "Epoch 124: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.4511 - accuracy: 0.7719 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7132 - recall_1: 0.9920 - precision_1: 0.6846 - val_loss: 0.6417 - val_accuracy: 0.6039 - val_sensitivity_at_specificity_1: 0.0000e+00 - val_specificity_at_sensitivity_1: 0.2174 - val_recall_1: 1.0000 - val_precision_1: 0.5564\n",
            "Epoch 125/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4555 - accuracy: 0.7629 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7213 - recall_1: 0.9878 - precision_1: 0.6715\n",
            "Epoch 125: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.4555 - accuracy: 0.7629 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7213 - recall_1: 0.9878 - precision_1: 0.6715 - val_loss: 0.6506 - val_accuracy: 0.5914 - val_sensitivity_at_specificity_1: 0.0205 - val_specificity_at_sensitivity_1: 0.1994 - val_recall_1: 1.0000 - val_precision_1: 0.5476\n",
            "Epoch 126/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4491 - accuracy: 0.7781 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7329 - recall_1: 1.0000 - precision_1: 0.6938\n",
            "Epoch 126: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.4491 - accuracy: 0.7781 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7329 - recall_1: 1.0000 - precision_1: 0.6938 - val_loss: 0.6747 - val_accuracy: 0.5773 - val_sensitivity_at_specificity_1: 0.0000e+00 - val_specificity_at_sensitivity_1: 0.1802 - val_recall_1: 1.0000 - val_precision_1: 0.5360\n",
            "Epoch 127/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4489 - accuracy: 0.7805 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7291 - recall_1: 0.9908 - precision_1: 0.7016\n",
            "Epoch 127: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.4489 - accuracy: 0.7805 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7291 - recall_1: 0.9908 - precision_1: 0.7016 - val_loss: 0.6644 - val_accuracy: 0.5813 - val_sensitivity_at_specificity_1: 0.0000e+00 - val_specificity_at_sensitivity_1: 0.2093 - val_recall_1: 1.0000 - val_precision_1: 0.5347\n",
            "Epoch 128/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4588 - accuracy: 0.7679 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7920 - recall_1: 0.9942 - precision_1: 0.6848\n",
            "Epoch 128: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.4588 - accuracy: 0.7679 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7920 - recall_1: 0.9942 - precision_1: 0.6848 - val_loss: 0.6509 - val_accuracy: 0.6016 - val_sensitivity_at_specificity_1: 0.0574 - val_specificity_at_sensitivity_1: 0.2079 - val_recall_1: 0.9984 - val_precision_1: 0.5585\n",
            "Epoch 129/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4566 - accuracy: 0.7680 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7454 - recall_1: 0.9937 - precision_1: 0.6826\n",
            "Epoch 129: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.4566 - accuracy: 0.7680 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7454 - recall_1: 0.9937 - precision_1: 0.6826 - val_loss: 0.6435 - val_accuracy: 0.6039 - val_sensitivity_at_specificity_1: 0.0000e+00 - val_specificity_at_sensitivity_1: 0.2212 - val_recall_1: 1.0000 - val_precision_1: 0.5572\n",
            "Epoch 130/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4426 - accuracy: 0.7832 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7823 - recall_1: 0.9945 - precision_1: 0.6996\n",
            "Epoch 130: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.4426 - accuracy: 0.7832 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7823 - recall_1: 0.9945 - precision_1: 0.6996 - val_loss: 0.6658 - val_accuracy: 0.5867 - val_sensitivity_at_specificity_1: 0.0224 - val_specificity_at_sensitivity_1: 0.2049 - val_recall_1: 0.9968 - val_precision_1: 0.5421\n",
            "Epoch 131/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4540 - accuracy: 0.7668 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7243 - recall_1: 0.9935 - precision_1: 0.6746\n",
            "Epoch 131: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.4540 - accuracy: 0.7668 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7243 - recall_1: 0.9935 - precision_1: 0.6746 - val_loss: 0.6495 - val_accuracy: 0.5906 - val_sensitivity_at_specificity_1: 0.0000e+00 - val_specificity_at_sensitivity_1: 0.2523 - val_recall_1: 0.9935 - val_precision_1: 0.5398\n",
            "Epoch 132/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4473 - accuracy: 0.7789 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7727 - recall_1: 0.9961 - precision_1: 0.6944\n",
            "Epoch 132: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.4473 - accuracy: 0.7789 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7727 - recall_1: 0.9961 - precision_1: 0.6944 - val_loss: 0.6338 - val_accuracy: 0.6148 - val_sensitivity_at_specificity_1: 0.0031 - val_specificity_at_sensitivity_1: 0.2319 - val_recall_1: 1.0000 - val_precision_1: 0.5672\n",
            "Epoch 133/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4598 - accuracy: 0.7660 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.6982 - recall_1: 0.9969 - precision_1: 0.6805\n",
            "Epoch 133: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.4598 - accuracy: 0.7660 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.6982 - recall_1: 0.9969 - precision_1: 0.6805 - val_loss: 0.6489 - val_accuracy: 0.6055 - val_sensitivity_at_specificity_1: 0.0381 - val_specificity_at_sensitivity_1: 0.2151 - val_recall_1: 0.9954 - val_precision_1: 0.5657\n",
            "Epoch 134/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4601 - accuracy: 0.7613 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7237 - recall_1: 0.9911 - precision_1: 0.6718\n",
            "Epoch 134: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.4601 - accuracy: 0.7613 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7237 - recall_1: 0.9911 - precision_1: 0.6718 - val_loss: 0.6266 - val_accuracy: 0.6187 - val_sensitivity_at_specificity_1: 0.0000e+00 - val_specificity_at_sensitivity_1: 0.2761 - val_recall_1: 0.9970 - val_precision_1: 0.5741\n",
            "Epoch 135/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4401 - accuracy: 0.7844 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7311 - recall_1: 0.9922 - precision_1: 0.7022\n",
            "Epoch 135: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.4401 - accuracy: 0.7844 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7311 - recall_1: 0.9922 - precision_1: 0.7022 - val_loss: 0.6452 - val_accuracy: 0.6102 - val_sensitivity_at_specificity_1: 0.0000e+00 - val_specificity_at_sensitivity_1: 0.2061 - val_recall_1: 1.0000 - val_precision_1: 0.5691\n",
            "Epoch 136/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4546 - accuracy: 0.7754 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7218 - recall_1: 0.9939 - precision_1: 0.6965\n",
            "Epoch 136: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.4546 - accuracy: 0.7754 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7218 - recall_1: 0.9939 - precision_1: 0.6965 - val_loss: 0.6466 - val_accuracy: 0.6070 - val_sensitivity_at_specificity_1: 0.0192 - val_specificity_at_sensitivity_1: 0.2470 - val_recall_1: 1.0000 - val_precision_1: 0.5537\n",
            "Epoch 137/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4502 - accuracy: 0.7777 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7454 - recall_1: 0.9969 - precision_1: 0.6962\n",
            "Epoch 137: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.4502 - accuracy: 0.7777 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7454 - recall_1: 0.9969 - precision_1: 0.6962 - val_loss: 0.6569 - val_accuracy: 0.5922 - val_sensitivity_at_specificity_1: 0.3398 - val_specificity_at_sensitivity_1: 0.2367 - val_recall_1: 0.9919 - val_precision_1: 0.5437\n",
            "Epoch 138/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4464 - accuracy: 0.7797 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7361 - recall_1: 0.9938 - precision_1: 0.6970\n",
            "Epoch 138: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.4464 - accuracy: 0.7797 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7361 - recall_1: 0.9938 - precision_1: 0.6970 - val_loss: 0.6520 - val_accuracy: 0.5969 - val_sensitivity_at_specificity_1: 0.0000e+00 - val_specificity_at_sensitivity_1: 0.2740 - val_recall_1: 0.9826 - val_precision_1: 0.5523\n",
            "Epoch 139/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4489 - accuracy: 0.7770 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7601 - recall_1: 0.9992 - precision_1: 0.6911\n",
            "Epoch 139: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.4489 - accuracy: 0.7770 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7601 - recall_1: 0.9992 - precision_1: 0.6911 - val_loss: 0.6484 - val_accuracy: 0.5984 - val_sensitivity_at_specificity_1: 0.0349 - val_specificity_at_sensitivity_1: 0.2554 - val_recall_1: 0.9952 - val_precision_1: 0.5510\n",
            "Epoch 140/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4407 - accuracy: 0.7844 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7674 - recall_1: 0.9969 - precision_1: 0.7001\n",
            "Epoch 140: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.4407 - accuracy: 0.7844 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7674 - recall_1: 0.9969 - precision_1: 0.7001 - val_loss: 0.6537 - val_accuracy: 0.6023 - val_sensitivity_at_specificity_1: 0.4292 - val_specificity_at_sensitivity_1: 0.2747 - val_recall_1: 0.9953 - val_precision_1: 0.5585\n",
            "Epoch 141/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4454 - accuracy: 0.7836 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7428 - recall_1: 0.9878 - precision_1: 0.7067\n",
            "Epoch 141: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.4454 - accuracy: 0.7836 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7428 - recall_1: 0.9878 - precision_1: 0.7067 - val_loss: 0.6780 - val_accuracy: 0.5781 - val_sensitivity_at_specificity_1: 0.0000e+00 - val_specificity_at_sensitivity_1: 0.2096 - val_recall_1: 1.0000 - val_precision_1: 0.5312\n",
            "Epoch 142/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4561 - accuracy: 0.7695 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7339 - recall_1: 0.9953 - precision_1: 0.6842\n",
            "Epoch 142: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.4561 - accuracy: 0.7695 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7339 - recall_1: 0.9953 - precision_1: 0.6842 - val_loss: 0.6404 - val_accuracy: 0.6047 - val_sensitivity_at_specificity_1: 0.0000e+00 - val_specificity_at_sensitivity_1: 0.3773 - val_recall_1: 0.9607 - val_precision_1: 0.5595\n",
            "Epoch 143/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4542 - accuracy: 0.7727 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7654 - recall_1: 0.9945 - precision_1: 0.6890\n",
            "Epoch 143: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.4542 - accuracy: 0.7727 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7654 - recall_1: 0.9945 - precision_1: 0.6890 - val_loss: 0.6355 - val_accuracy: 0.6086 - val_sensitivity_at_specificity_1: 0.0000e+00 - val_specificity_at_sensitivity_1: 0.3464 - val_recall_1: 0.9938 - val_precision_1: 0.5621\n",
            "Epoch 144/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4355 - accuracy: 0.7844 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7724 - recall_1: 0.9912 - precision_1: 0.6969\n",
            "Epoch 144: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.4355 - accuracy: 0.7844 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7724 - recall_1: 0.9912 - precision_1: 0.6969 - val_loss: 0.6427 - val_accuracy: 0.6156 - val_sensitivity_at_specificity_1: 0.0000e+00 - val_specificity_at_sensitivity_1: 0.3002 - val_recall_1: 0.9970 - val_precision_1: 0.5758\n",
            "Epoch 145/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4517 - accuracy: 0.7742 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7702 - recall_1: 0.9907 - precision_1: 0.6922\n",
            "Epoch 145: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.4517 - accuracy: 0.7742 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7702 - recall_1: 0.9907 - precision_1: 0.6922 - val_loss: 0.6648 - val_accuracy: 0.5922 - val_sensitivity_at_specificity_1: 0.0000e+00 - val_specificity_at_sensitivity_1: 0.2628 - val_recall_1: 0.9984 - val_precision_1: 0.5481\n",
            "Epoch 146/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4442 - accuracy: 0.7828 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7602 - recall_1: 0.9893 - precision_1: 0.7043\n",
            "Epoch 146: val_accuracy did not improve from 0.63203\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.4442 - accuracy: 0.7828 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7602 - recall_1: 0.9893 - precision_1: 0.7043 - val_loss: 0.6290 - val_accuracy: 0.6258 - val_sensitivity_at_specificity_1: 0.0000e+00 - val_specificity_at_sensitivity_1: 0.3684 - val_recall_1: 0.9969 - val_precision_1: 0.5771\n",
            "Epoch 147/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4655 - accuracy: 0.7620 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7728 - recall_1: 1.0000 - precision_1: 0.6755\n",
            "Epoch 147: val_accuracy improved from 0.63203 to 0.64219, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.4655 - accuracy: 0.7620 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7728 - recall_1: 1.0000 - precision_1: 0.6755 - val_loss: 0.6166 - val_accuracy: 0.6422 - val_sensitivity_at_specificity_1: 0.0000e+00 - val_specificity_at_sensitivity_1: 0.2576 - val_recall_1: 1.0000 - val_precision_1: 0.5997\n",
            "Epoch 148/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4515 - accuracy: 0.7734 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7892 - recall_1: 0.9961 - precision_1: 0.6890\n",
            "Epoch 148: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.4515 - accuracy: 0.7734 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7892 - recall_1: 0.9961 - precision_1: 0.6890 - val_loss: 0.6344 - val_accuracy: 0.6086 - val_sensitivity_at_specificity_1: 0.0000e+00 - val_specificity_at_sensitivity_1: 0.4248 - val_recall_1: 0.9938 - val_precision_1: 0.5621\n",
            "Epoch 149/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4496 - accuracy: 0.7797 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7500 - recall_1: 0.9931 - precision_1: 0.7000\n",
            "Epoch 149: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.4496 - accuracy: 0.7797 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7500 - recall_1: 0.9931 - precision_1: 0.7000 - val_loss: 0.6493 - val_accuracy: 0.6070 - val_sensitivity_at_specificity_1: 0.1088 - val_specificity_at_sensitivity_1: 0.2926 - val_recall_1: 0.9890 - val_precision_1: 0.5583\n",
            "Epoch 150/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4506 - accuracy: 0.7707 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7343 - recall_1: 0.9952 - precision_1: 0.6823\n",
            "Epoch 150: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.4506 - accuracy: 0.7707 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7343 - recall_1: 0.9952 - precision_1: 0.6823 - val_loss: 0.6511 - val_accuracy: 0.5992 - val_sensitivity_at_specificity_1: 0.0000e+00 - val_specificity_at_sensitivity_1: 0.3302 - val_recall_1: 1.0000 - val_precision_1: 0.5520\n",
            "Epoch 151/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4402 - accuracy: 0.7750 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7834 - recall_1: 0.9917 - precision_1: 0.6799\n",
            "Epoch 151: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.4402 - accuracy: 0.7750 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7834 - recall_1: 0.9917 - precision_1: 0.6799 - val_loss: 0.6291 - val_accuracy: 0.6078 - val_sensitivity_at_specificity_1: 0.0000e+00 - val_specificity_at_sensitivity_1: 0.4523 - val_recall_1: 0.9921 - val_precision_1: 0.5570\n",
            "Epoch 152/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4583 - accuracy: 0.7652 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7286 - recall_1: 0.9937 - precision_1: 0.6791\n",
            "Epoch 152: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.4583 - accuracy: 0.7652 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7286 - recall_1: 0.9937 - precision_1: 0.6791 - val_loss: 0.6573 - val_accuracy: 0.5891 - val_sensitivity_at_specificity_1: 0.4028 - val_specificity_at_sensitivity_1: 0.3801 - val_recall_1: 1.0000 - val_precision_1: 0.5481\n",
            "Epoch 153/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4458 - accuracy: 0.7812 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7202 - recall_1: 0.9938 - precision_1: 0.6980\n",
            "Epoch 153: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.4458 - accuracy: 0.7812 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7202 - recall_1: 0.9938 - precision_1: 0.6980 - val_loss: 0.6591 - val_accuracy: 0.6008 - val_sensitivity_at_specificity_1: 0.0000e+00 - val_specificity_at_sensitivity_1: 0.4261 - val_recall_1: 0.9984 - val_precision_1: 0.5577\n",
            "Epoch 154/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4399 - accuracy: 0.7832 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7428 - recall_1: 0.9992 - precision_1: 0.6966\n",
            "Epoch 154: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.4399 - accuracy: 0.7832 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7428 - recall_1: 0.9992 - precision_1: 0.6966 - val_loss: 0.6673 - val_accuracy: 0.5805 - val_sensitivity_at_specificity_1: 0.6689 - val_specificity_at_sensitivity_1: 0.5134 - val_recall_1: 0.9902 - val_precision_1: 0.5322\n",
            "Epoch 155/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4489 - accuracy: 0.7742 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7705 - recall_1: 0.9929 - precision_1: 0.6884\n",
            "Epoch 155: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.4489 - accuracy: 0.7742 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7705 - recall_1: 0.9929 - precision_1: 0.6884 - val_loss: 0.6286 - val_accuracy: 0.6164 - val_sensitivity_at_specificity_1: 0.6025 - val_specificity_at_sensitivity_1: 0.5820 - val_recall_1: 1.0000 - val_precision_1: 0.5636\n",
            "Epoch 156/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4478 - accuracy: 0.7789 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7686 - recall_1: 0.9954 - precision_1: 0.6970\n",
            "Epoch 156: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.4478 - accuracy: 0.7789 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7686 - recall_1: 0.9954 - precision_1: 0.6970 - val_loss: 0.6513 - val_accuracy: 0.6039 - val_sensitivity_at_specificity_1: 0.4846 - val_specificity_at_sensitivity_1: 0.4042 - val_recall_1: 1.0000 - val_precision_1: 0.5489\n",
            "Epoch 157/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4423 - accuracy: 0.7816 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7723 - recall_1: 0.9977 - precision_1: 0.6985\n",
            "Epoch 157: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.4423 - accuracy: 0.7816 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7723 - recall_1: 0.9977 - precision_1: 0.6985 - val_loss: 0.6555 - val_accuracy: 0.6062 - val_sensitivity_at_specificity_1: 0.6452 - val_specificity_at_sensitivity_1: 0.5056 - val_recall_1: 0.9985 - val_precision_1: 0.5637\n",
            "Epoch 158/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4369 - accuracy: 0.7836 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8150 - recall_1: 0.9961 - precision_1: 0.6970\n",
            "Epoch 158: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.4369 - accuracy: 0.7836 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8150 - recall_1: 0.9961 - precision_1: 0.6970 - val_loss: 0.6478 - val_accuracy: 0.6055 - val_sensitivity_at_specificity_1: 0.7089 - val_specificity_at_sensitivity_1: 0.6396 - val_recall_1: 1.0000 - val_precision_1: 0.5586\n",
            "Epoch 159/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4409 - accuracy: 0.7840 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7841 - recall_1: 0.9985 - precision_1: 0.7020\n",
            "Epoch 159: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.4409 - accuracy: 0.7840 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7841 - recall_1: 0.9985 - precision_1: 0.7020 - val_loss: 0.6766 - val_accuracy: 0.5805 - val_sensitivity_at_specificity_1: 0.6519 - val_specificity_at_sensitivity_1: 0.6667 - val_recall_1: 0.9984 - val_precision_1: 0.5407\n",
            "Epoch 160/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4328 - accuracy: 0.7852 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8072 - recall_1: 0.9976 - precision_1: 0.6973\n",
            "Epoch 160: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.4328 - accuracy: 0.7852 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8072 - recall_1: 0.9976 - precision_1: 0.6973 - val_loss: 0.6528 - val_accuracy: 0.6016 - val_sensitivity_at_specificity_1: 0.6463 - val_specificity_at_sensitivity_1: 0.5944 - val_recall_1: 0.9953 - val_precision_1: 0.5564\n",
            "Epoch 161/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4428 - accuracy: 0.7777 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8080 - recall_1: 0.9929 - precision_1: 0.6913\n",
            "Epoch 161: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.4428 - accuracy: 0.7777 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8080 - recall_1: 0.9929 - precision_1: 0.6913 - val_loss: 0.6487 - val_accuracy: 0.5977 - val_sensitivity_at_specificity_1: 0.6976 - val_specificity_at_sensitivity_1: 0.6388 - val_recall_1: 0.9984 - val_precision_1: 0.5523\n",
            "Epoch 162/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4406 - accuracy: 0.7914 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7848 - recall_1: 0.9956 - precision_1: 0.7182\n",
            "Epoch 162: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.4406 - accuracy: 0.7914 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7848 - recall_1: 0.9956 - precision_1: 0.7182 - val_loss: 0.6370 - val_accuracy: 0.6383 - val_sensitivity_at_specificity_1: 0.0000e+00 - val_specificity_at_sensitivity_1: 0.3279 - val_recall_1: 1.0000 - val_precision_1: 0.5914\n",
            "Epoch 163/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4524 - accuracy: 0.7770 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7668 - recall_1: 0.9969 - precision_1: 0.6948\n",
            "Epoch 163: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.4524 - accuracy: 0.7770 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7668 - recall_1: 0.9969 - precision_1: 0.6948 - val_loss: 0.6442 - val_accuracy: 0.6016 - val_sensitivity_at_specificity_1: 0.6345 - val_specificity_at_sensitivity_1: 0.5478 - val_recall_1: 0.9937 - val_precision_1: 0.5538\n",
            "Epoch 164/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4416 - accuracy: 0.7828 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7763 - recall_1: 0.9992 - precision_1: 0.6984\n",
            "Epoch 164: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.4416 - accuracy: 0.7828 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7763 - recall_1: 0.9992 - precision_1: 0.6984 - val_loss: 0.6260 - val_accuracy: 0.6336 - val_sensitivity_at_specificity_1: 0.0000e+00 - val_specificity_at_sensitivity_1: 0.3746 - val_recall_1: 1.0000 - val_precision_1: 0.5868\n",
            "Epoch 165/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4499 - accuracy: 0.7719 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7125 - recall_1: 0.9968 - precision_1: 0.6815\n",
            "Epoch 165: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.4499 - accuracy: 0.7719 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7125 - recall_1: 0.9968 - precision_1: 0.6815 - val_loss: 0.6655 - val_accuracy: 0.5938 - val_sensitivity_at_specificity_1: 0.0000e+00 - val_specificity_at_sensitivity_1: 0.2229 - val_recall_1: 1.0000 - val_precision_1: 0.5563\n",
            "Epoch 166/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4433 - accuracy: 0.7848 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7571 - recall_1: 0.9985 - precision_1: 0.7021\n",
            "Epoch 166: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.4433 - accuracy: 0.7848 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7571 - recall_1: 0.9985 - precision_1: 0.7021 - val_loss: 0.6271 - val_accuracy: 0.6180 - val_sensitivity_at_specificity_1: 0.0000e+00 - val_specificity_at_sensitivity_1: 0.3359 - val_recall_1: 0.9938 - val_precision_1: 0.5685\n",
            "Epoch 167/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4511 - accuracy: 0.7766 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7411 - recall_1: 0.9977 - precision_1: 0.6946\n",
            "Epoch 167: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.4511 - accuracy: 0.7766 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7411 - recall_1: 0.9977 - precision_1: 0.6946 - val_loss: 0.6434 - val_accuracy: 0.6133 - val_sensitivity_at_specificity_1: 0.0000e+00 - val_specificity_at_sensitivity_1: 0.2394 - val_recall_1: 1.0000 - val_precision_1: 0.5658\n",
            "Epoch 168/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4532 - accuracy: 0.7664 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7289 - recall_1: 0.9976 - precision_1: 0.6745\n",
            "Epoch 168: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.4532 - accuracy: 0.7664 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7289 - recall_1: 0.9976 - precision_1: 0.6745 - val_loss: 0.6412 - val_accuracy: 0.6062 - val_sensitivity_at_specificity_1: 0.0000e+00 - val_specificity_at_sensitivity_1: 0.2736 - val_recall_1: 0.9984 - val_precision_1: 0.5611\n",
            "Epoch 169/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4534 - accuracy: 0.7723 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7555 - recall_1: 0.9992 - precision_1: 0.6873\n",
            "Epoch 169: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.4534 - accuracy: 0.7723 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7555 - recall_1: 0.9992 - precision_1: 0.6873 - val_loss: 0.6223 - val_accuracy: 0.6242 - val_sensitivity_at_specificity_1: 0.5588 - val_specificity_at_sensitivity_1: 0.6000 - val_recall_1: 0.9985 - val_precision_1: 0.5767\n",
            "Epoch 170/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4443 - accuracy: 0.7855 - sensitivity_at_specificity_1: 0.9992 - specificity_at_sensitivity_1: 0.7550 - recall_1: 0.9962 - precision_1: 0.7047\n",
            "Epoch 170: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.4443 - accuracy: 0.7855 - sensitivity_at_specificity_1: 0.9992 - specificity_at_sensitivity_1: 0.7550 - recall_1: 0.9962 - precision_1: 0.7047 - val_loss: 0.6489 - val_accuracy: 0.6094 - val_sensitivity_at_specificity_1: 0.6313 - val_specificity_at_sensitivity_1: 0.5437 - val_recall_1: 1.0000 - val_precision_1: 0.5614\n",
            "Epoch 171/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4544 - accuracy: 0.7684 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7829 - recall_1: 0.9960 - precision_1: 0.6811\n",
            "Epoch 171: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.4544 - accuracy: 0.7684 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7829 - recall_1: 0.9960 - precision_1: 0.6811 - val_loss: 0.6434 - val_accuracy: 0.6078 - val_sensitivity_at_specificity_1: 0.7036 - val_specificity_at_sensitivity_1: 0.6150 - val_recall_1: 0.9953 - val_precision_1: 0.5611\n",
            "Epoch 172/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4467 - accuracy: 0.7738 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7908 - recall_1: 0.9914 - precision_1: 0.6898\n",
            "Epoch 172: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.4467 - accuracy: 0.7738 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7908 - recall_1: 0.9914 - precision_1: 0.6898 - val_loss: 0.6617 - val_accuracy: 0.5945 - val_sensitivity_at_specificity_1: 0.6741 - val_specificity_at_sensitivity_1: 0.6129 - val_recall_1: 0.9921 - val_precision_1: 0.5483\n",
            "Epoch 173/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4419 - accuracy: 0.7762 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8226 - recall_1: 0.9940 - precision_1: 0.6846\n",
            "Epoch 173: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 157ms/step - loss: 0.4419 - accuracy: 0.7762 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8226 - recall_1: 0.9940 - precision_1: 0.6846 - val_loss: 0.6477 - val_accuracy: 0.6156 - val_sensitivity_at_specificity_1: 0.5929 - val_specificity_at_sensitivity_1: 0.6200 - val_recall_1: 0.9923 - val_precision_1: 0.5702\n",
            "Epoch 174/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4512 - accuracy: 0.7777 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7895 - recall_1: 0.9977 - precision_1: 0.6972\n",
            "Epoch 174: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.4512 - accuracy: 0.7777 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7895 - recall_1: 0.9977 - precision_1: 0.6972 - val_loss: 0.6482 - val_accuracy: 0.6070 - val_sensitivity_at_specificity_1: 0.7002 - val_specificity_at_sensitivity_1: 0.6003 - val_recall_1: 1.0000 - val_precision_1: 0.5626\n",
            "Epoch 175/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4545 - accuracy: 0.7758 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7844 - recall_1: 0.9962 - precision_1: 0.6975\n",
            "Epoch 175: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.4545 - accuracy: 0.7758 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7844 - recall_1: 0.9962 - precision_1: 0.6975 - val_loss: 0.6458 - val_accuracy: 0.6125 - val_sensitivity_at_specificity_1: 0.7267 - val_specificity_at_sensitivity_1: 0.5552 - val_recall_1: 1.0000 - val_precision_1: 0.5691\n",
            "Epoch 176/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4427 - accuracy: 0.7820 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7902 - recall_1: 0.9931 - precision_1: 0.7011\n",
            "Epoch 176: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.4427 - accuracy: 0.7820 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7902 - recall_1: 0.9931 - precision_1: 0.7011 - val_loss: 0.6277 - val_accuracy: 0.6211 - val_sensitivity_at_specificity_1: 0.7030 - val_specificity_at_sensitivity_1: 0.6516 - val_recall_1: 0.9985 - val_precision_1: 0.5766\n",
            "Epoch 177/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4410 - accuracy: 0.7816 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8037 - recall_1: 0.9945 - precision_1: 0.6969\n",
            "Epoch 177: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.4410 - accuracy: 0.7816 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8037 - recall_1: 0.9945 - precision_1: 0.6969 - val_loss: 0.6643 - val_accuracy: 0.6047 - val_sensitivity_at_specificity_1: 0.6397 - val_specificity_at_sensitivity_1: 0.5968 - val_recall_1: 1.0000 - val_precision_1: 0.5642\n",
            "Epoch 178/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4356 - accuracy: 0.7863 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7953 - recall_1: 0.9984 - precision_1: 0.7010\n",
            "Epoch 178: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.4356 - accuracy: 0.7863 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7953 - recall_1: 0.9984 - precision_1: 0.7010 - val_loss: 0.6548 - val_accuracy: 0.6008 - val_sensitivity_at_specificity_1: 0.6714 - val_specificity_at_sensitivity_1: 0.6213 - val_recall_1: 0.9937 - val_precision_1: 0.5537\n",
            "Epoch 179/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4313 - accuracy: 0.7857 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8212 - recall_1: 0.9907 - precision_1: 0.6999\n",
            "Epoch 179: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 155ms/step - loss: 0.4313 - accuracy: 0.7857 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8212 - recall_1: 0.9907 - precision_1: 0.6999 - val_loss: 0.6313 - val_accuracy: 0.6070 - val_sensitivity_at_specificity_1: 0.6736 - val_specificity_at_sensitivity_1: 0.6350 - val_recall_1: 0.9920 - val_precision_1: 0.5558\n",
            "Epoch 180/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4453 - accuracy: 0.7781 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8249 - recall_1: 0.9916 - precision_1: 0.7007\n",
            "Epoch 180: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.4453 - accuracy: 0.7781 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8249 - recall_1: 0.9916 - precision_1: 0.7007 - val_loss: 0.6629 - val_accuracy: 0.6094 - val_sensitivity_at_specificity_1: 0.6748 - val_specificity_at_sensitivity_1: 0.6576 - val_recall_1: 1.0000 - val_precision_1: 0.5671\n",
            "Epoch 181/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4379 - accuracy: 0.7816 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8301 - recall_1: 0.9969 - precision_1: 0.6974\n",
            "Epoch 181: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.4379 - accuracy: 0.7816 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8301 - recall_1: 0.9969 - precision_1: 0.6974 - val_loss: 0.6415 - val_accuracy: 0.6109 - val_sensitivity_at_specificity_1: 0.7030 - val_specificity_at_sensitivity_1: 0.6291 - val_recall_1: 0.9984 - val_precision_1: 0.5598\n",
            "Epoch 182/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4464 - accuracy: 0.7727 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8206 - recall_1: 0.9961 - precision_1: 0.6862\n",
            "Epoch 182: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.4464 - accuracy: 0.7727 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8206 - recall_1: 0.9961 - precision_1: 0.6862 - val_loss: 0.6698 - val_accuracy: 0.5828 - val_sensitivity_at_specificity_1: 0.6656 - val_specificity_at_sensitivity_1: 0.6342 - val_recall_1: 0.9984 - val_precision_1: 0.5345\n",
            "Epoch 183/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4589 - accuracy: 0.7668 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8064 - recall_1: 0.9922 - precision_1: 0.6829\n",
            "Epoch 183: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.4589 - accuracy: 0.7668 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8064 - recall_1: 0.9922 - precision_1: 0.6829 - val_loss: 0.6471 - val_accuracy: 0.6164 - val_sensitivity_at_specificity_1: 0.7038 - val_specificity_at_sensitivity_1: 0.6455 - val_recall_1: 1.0000 - val_precision_1: 0.5814\n",
            "Epoch 184/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4526 - accuracy: 0.7617 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8319 - recall_1: 0.9976 - precision_1: 0.6728\n",
            "Epoch 184: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.4526 - accuracy: 0.7617 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8319 - recall_1: 0.9976 - precision_1: 0.6728 - val_loss: 0.6712 - val_accuracy: 0.5883 - val_sensitivity_at_specificity_1: 0.6865 - val_specificity_at_sensitivity_1: 0.6137 - val_recall_1: 0.9953 - val_precision_1: 0.5479\n",
            "Epoch 185/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4378 - accuracy: 0.7793 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8371 - recall_1: 0.9829 - precision_1: 0.7000\n",
            "Epoch 185: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.4378 - accuracy: 0.7793 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8371 - recall_1: 0.9829 - precision_1: 0.7000 - val_loss: 0.6665 - val_accuracy: 0.5930 - val_sensitivity_at_specificity_1: 0.7476 - val_specificity_at_sensitivity_1: 0.6717 - val_recall_1: 0.9984 - val_precision_1: 0.5443\n",
            "Epoch 186/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4467 - accuracy: 0.7629 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8382 - recall_1: 0.9887 - precision_1: 0.6735\n",
            "Epoch 186: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.4467 - accuracy: 0.7629 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8382 - recall_1: 0.9887 - precision_1: 0.6735 - val_loss: 0.6451 - val_accuracy: 0.6078 - val_sensitivity_at_specificity_1: 0.6501 - val_specificity_at_sensitivity_1: 0.6075 - val_recall_1: 0.9813 - val_precision_1: 0.5629\n",
            "Epoch 187/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4536 - accuracy: 0.7777 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7870 - recall_1: 0.9817 - precision_1: 0.7025\n",
            "Epoch 187: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.4536 - accuracy: 0.7777 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7870 - recall_1: 0.9817 - precision_1: 0.7025 - val_loss: 0.7108 - val_accuracy: 0.6086 - val_sensitivity_at_specificity_1: 0.0000e+00 - val_specificity_at_sensitivity_1: 0.3211 - val_recall_1: 1.0000 - val_precision_1: 0.5662\n",
            "Epoch 188/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4497 - accuracy: 0.7785 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7618 - recall_1: 0.9930 - precision_1: 0.6956\n",
            "Epoch 188: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.4497 - accuracy: 0.7785 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7618 - recall_1: 0.9930 - precision_1: 0.6956 - val_loss: 0.6590 - val_accuracy: 0.5906 - val_sensitivity_at_specificity_1: 0.0000e+00 - val_specificity_at_sensitivity_1: 0.2698 - val_recall_1: 1.0000 - val_precision_1: 0.5436\n",
            "Epoch 189/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4423 - accuracy: 0.7834 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7469 - recall_1: 1.0000 - precision_1: 0.6989\n",
            "Epoch 189: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.4436 - accuracy: 0.7828 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7525 - recall_1: 0.9992 - precision_1: 0.6995 - val_loss: 0.6343 - val_accuracy: 0.6062 - val_sensitivity_at_specificity_1: 0.0000e+00 - val_specificity_at_sensitivity_1: 0.3276 - val_recall_1: 0.9969 - val_precision_1: 0.5593\n",
            "Epoch 190/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4438 - accuracy: 0.7770 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7825 - recall_1: 0.9889 - precision_1: 0.6909\n",
            "Epoch 190: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.4438 - accuracy: 0.7770 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7825 - recall_1: 0.9889 - precision_1: 0.6909 - val_loss: 0.6515 - val_accuracy: 0.6016 - val_sensitivity_at_specificity_1: 0.0000e+00 - val_specificity_at_sensitivity_1: 0.2690 - val_recall_1: 1.0000 - val_precision_1: 0.5596\n",
            "Epoch 191/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4480 - accuracy: 0.7777 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7465 - recall_1: 0.9992 - precision_1: 0.6915\n",
            "Epoch 191: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.4480 - accuracy: 0.7777 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7465 - recall_1: 0.9992 - precision_1: 0.6915 - val_loss: 0.6463 - val_accuracy: 0.6133 - val_sensitivity_at_specificity_1: 0.0000e+00 - val_specificity_at_sensitivity_1: 0.3279 - val_recall_1: 0.9955 - val_precision_1: 0.5744\n",
            "Epoch 192/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4514 - accuracy: 0.7715 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7398 - recall_1: 0.9960 - precision_1: 0.6834\n",
            "Epoch 192: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.4514 - accuracy: 0.7715 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7398 - recall_1: 0.9960 - precision_1: 0.6834 - val_loss: 0.6460 - val_accuracy: 0.6023 - val_sensitivity_at_specificity_1: 0.0000e+00 - val_specificity_at_sensitivity_1: 0.4137 - val_recall_1: 0.9984 - val_precision_1: 0.5512\n",
            "Epoch 193/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4491 - accuracy: 0.7754 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7746 - recall_1: 0.9929 - precision_1: 0.6885\n",
            "Epoch 193: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.4491 - accuracy: 0.7754 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7746 - recall_1: 0.9929 - precision_1: 0.6885 - val_loss: 0.6427 - val_accuracy: 0.6133 - val_sensitivity_at_specificity_1: 0.0000e+00 - val_specificity_at_sensitivity_1: 0.4349 - val_recall_1: 0.9985 - val_precision_1: 0.5738\n",
            "Epoch 194/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4396 - accuracy: 0.7871 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7911 - recall_1: 0.9969 - precision_1: 0.7065\n",
            "Epoch 194: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.4396 - accuracy: 0.7871 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7911 - recall_1: 0.9969 - precision_1: 0.7065 - val_loss: 0.6326 - val_accuracy: 0.6172 - val_sensitivity_at_specificity_1: 0.7202 - val_specificity_at_sensitivity_1: 0.6550 - val_recall_1: 0.9709 - val_precision_1: 0.5741\n",
            "Epoch 195/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4416 - accuracy: 0.7797 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8051 - recall_1: 0.9898 - precision_1: 0.6956\n",
            "Epoch 195: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.4416 - accuracy: 0.7797 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8051 - recall_1: 0.9898 - precision_1: 0.6956 - val_loss: 0.6526 - val_accuracy: 0.6047 - val_sensitivity_at_specificity_1: 0.7104 - val_specificity_at_sensitivity_1: 0.6188 - val_recall_1: 1.0000 - val_precision_1: 0.5554\n",
            "Epoch 196/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4526 - accuracy: 0.7684 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7843 - recall_1: 0.9936 - precision_1: 0.6810\n",
            "Epoch 196: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.4526 - accuracy: 0.7684 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7843 - recall_1: 0.9936 - precision_1: 0.6810 - val_loss: 0.6769 - val_accuracy: 0.6055 - val_sensitivity_at_specificity_1: 0.6489 - val_specificity_at_sensitivity_1: 0.5452 - val_recall_1: 1.0000 - val_precision_1: 0.5582\n",
            "Epoch 197/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4530 - accuracy: 0.7594 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8163 - recall_1: 0.9902 - precision_1: 0.6678\n",
            "Epoch 197: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.4530 - accuracy: 0.7594 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8163 - recall_1: 0.9902 - precision_1: 0.6678 - val_loss: 0.6667 - val_accuracy: 0.5977 - val_sensitivity_at_specificity_1: 0.7030 - val_specificity_at_sensitivity_1: 0.5951 - val_recall_1: 1.0000 - val_precision_1: 0.5475\n",
            "Epoch 198/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4406 - accuracy: 0.7781 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8202 - recall_1: 0.9961 - precision_1: 0.6939\n",
            "Epoch 198: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.4406 - accuracy: 0.7781 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8202 - recall_1: 0.9961 - precision_1: 0.6939 - val_loss: 0.6880 - val_accuracy: 0.5867 - val_sensitivity_at_specificity_1: 0.7143 - val_specificity_at_sensitivity_1: 0.6051 - val_recall_1: 0.9984 - val_precision_1: 0.5352\n",
            "Epoch 199/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4443 - accuracy: 0.7750 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8143 - recall_1: 0.9952 - precision_1: 0.6870\n",
            "Epoch 199: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.4443 - accuracy: 0.7750 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8143 - recall_1: 0.9952 - precision_1: 0.6870 - val_loss: 0.6566 - val_accuracy: 0.6000 - val_sensitivity_at_specificity_1: 0.6672 - val_specificity_at_sensitivity_1: 0.6396 - val_recall_1: 1.0000 - val_precision_1: 0.5509\n",
            "Epoch 200/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4519 - accuracy: 0.7645 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8263 - recall_1: 0.9952 - precision_1: 0.6773\n",
            "Epoch 200: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.4519 - accuracy: 0.7645 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8263 - recall_1: 0.9952 - precision_1: 0.6773 - val_loss: 0.6582 - val_accuracy: 0.5945 - val_sensitivity_at_specificity_1: 0.6897 - val_specificity_at_sensitivity_1: 0.6717 - val_recall_1: 1.0000 - val_precision_1: 0.5451\n",
            "Epoch 201/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4297 - accuracy: 0.7883 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8190 - recall_1: 0.9906 - precision_1: 0.7041\n",
            "Epoch 201: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.4297 - accuracy: 0.7883 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8190 - recall_1: 0.9906 - precision_1: 0.7041 - val_loss: 0.6677 - val_accuracy: 0.5938 - val_sensitivity_at_specificity_1: 0.7301 - val_specificity_at_sensitivity_1: 0.6541 - val_recall_1: 1.0000 - val_precision_1: 0.5419\n",
            "Epoch 202/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4551 - accuracy: 0.7672 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8077 - recall_1: 0.9953 - precision_1: 0.6836\n",
            "Epoch 202: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.4551 - accuracy: 0.7672 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8077 - recall_1: 0.9953 - precision_1: 0.6836 - val_loss: 0.6736 - val_accuracy: 0.6047 - val_sensitivity_at_specificity_1: 0.6242 - val_specificity_at_sensitivity_1: 0.6162 - val_recall_1: 1.0000 - val_precision_1: 0.5630\n",
            "Epoch 203/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4453 - accuracy: 0.7730 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8264 - recall_1: 0.9921 - precision_1: 0.6871\n",
            "Epoch 203: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.4453 - accuracy: 0.7730 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8264 - recall_1: 0.9921 - precision_1: 0.6871 - val_loss: 0.6530 - val_accuracy: 0.6141 - val_sensitivity_at_specificity_1: 0.6515 - val_specificity_at_sensitivity_1: 0.6323 - val_recall_1: 0.9970 - val_precision_1: 0.5722\n",
            "Epoch 204/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4370 - accuracy: 0.7805 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8329 - recall_1: 0.9984 - precision_1: 0.6932\n",
            "Epoch 204: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.4370 - accuracy: 0.7805 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8329 - recall_1: 0.9984 - precision_1: 0.6932 - val_loss: 0.6585 - val_accuracy: 0.6000 - val_sensitivity_at_specificity_1: 0.6636 - val_specificity_at_sensitivity_1: 0.6177 - val_recall_1: 0.9985 - val_precision_1: 0.5632\n",
            "Epoch 205/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4500 - accuracy: 0.7688 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8313 - recall_1: 0.9953 - precision_1: 0.6849\n",
            "Epoch 205: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.4500 - accuracy: 0.7688 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8313 - recall_1: 0.9953 - precision_1: 0.6849 - val_loss: 0.6147 - val_accuracy: 0.6234 - val_sensitivity_at_specificity_1: 0.7843 - val_specificity_at_sensitivity_1: 0.6543 - val_recall_1: 0.9921 - val_precision_1: 0.5691\n",
            "Epoch 206/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4473 - accuracy: 0.7699 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8382 - recall_1: 0.9860 - precision_1: 0.6897\n",
            "Epoch 206: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.4473 - accuracy: 0.7699 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8382 - recall_1: 0.9860 - precision_1: 0.6897 - val_loss: 0.6674 - val_accuracy: 0.6031 - val_sensitivity_at_specificity_1: 0.6595 - val_specificity_at_sensitivity_1: 0.6117 - val_recall_1: 0.9985 - val_precision_1: 0.5610\n",
            "Epoch 207/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4513 - accuracy: 0.7691 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8171 - recall_1: 0.9937 - precision_1: 0.6830\n",
            "Epoch 207: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.4513 - accuracy: 0.7691 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8171 - recall_1: 0.9937 - precision_1: 0.6830 - val_loss: 0.6213 - val_accuracy: 0.6242 - val_sensitivity_at_specificity_1: 0.7603 - val_specificity_at_sensitivity_1: 0.6560 - val_recall_1: 0.9924 - val_precision_1: 0.5773\n",
            "Epoch 208/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4468 - accuracy: 0.7734 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8321 - recall_1: 0.9901 - precision_1: 0.6966\n",
            "Epoch 208: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.4468 - accuracy: 0.7734 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8321 - recall_1: 0.9901 - precision_1: 0.6966 - val_loss: 0.6525 - val_accuracy: 0.6148 - val_sensitivity_at_specificity_1: 0.7350 - val_specificity_at_sensitivity_1: 0.6846 - val_recall_1: 1.0000 - val_precision_1: 0.5683\n",
            "Epoch 209/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4472 - accuracy: 0.7652 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8247 - recall_1: 0.9858 - precision_1: 0.6814\n",
            "Epoch 209: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.4472 - accuracy: 0.7652 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8247 - recall_1: 0.9858 - precision_1: 0.6814 - val_loss: 0.6553 - val_accuracy: 0.6016 - val_sensitivity_at_specificity_1: 0.6364 - val_specificity_at_sensitivity_1: 0.5943 - val_recall_1: 1.0000 - val_precision_1: 0.5600\n",
            "Epoch 210/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4329 - accuracy: 0.7832 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8302 - recall_1: 0.9985 - precision_1: 0.7012\n",
            "Epoch 210: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.4329 - accuracy: 0.7832 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8302 - recall_1: 0.9985 - precision_1: 0.7012 - val_loss: 0.6908 - val_accuracy: 0.6000 - val_sensitivity_at_specificity_1: 0.6787 - val_specificity_at_sensitivity_1: 0.6417 - val_recall_1: 1.0000 - val_precision_1: 0.5548\n",
            "Epoch 211/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4457 - accuracy: 0.7750 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8133 - recall_1: 0.9913 - precision_1: 0.6901\n",
            "Epoch 211: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.4457 - accuracy: 0.7750 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8133 - recall_1: 0.9913 - precision_1: 0.6901 - val_loss: 0.6899 - val_accuracy: 0.5836 - val_sensitivity_at_specificity_1: 0.6947 - val_specificity_at_sensitivity_1: 0.6187 - val_recall_1: 1.0000 - val_precision_1: 0.5320\n",
            "Epoch 212/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4374 - accuracy: 0.7801 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8203 - recall_1: 0.9984 - precision_1: 0.6931\n",
            "Epoch 212: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.4374 - accuracy: 0.7801 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8203 - recall_1: 0.9984 - precision_1: 0.6931 - val_loss: 0.6548 - val_accuracy: 0.5977 - val_sensitivity_at_specificity_1: 0.7111 - val_specificity_at_sensitivity_1: 0.6971 - val_recall_1: 1.0000 - val_precision_1: 0.5475\n",
            "Epoch 213/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4369 - accuracy: 0.7820 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8391 - recall_1: 0.9845 - precision_1: 0.7028\n",
            "Epoch 213: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.4369 - accuracy: 0.7820 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8391 - recall_1: 0.9845 - precision_1: 0.7028 - val_loss: 0.6821 - val_accuracy: 0.6055 - val_sensitivity_at_specificity_1: 0.6809 - val_specificity_at_sensitivity_1: 0.6592 - val_recall_1: 1.0000 - val_precision_1: 0.5647\n",
            "Epoch 214/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4354 - accuracy: 0.7852 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8311 - recall_1: 0.9992 - precision_1: 0.6998\n",
            "Epoch 214: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.4354 - accuracy: 0.7852 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8311 - recall_1: 0.9992 - precision_1: 0.6998 - val_loss: 0.6910 - val_accuracy: 0.5844 - val_sensitivity_at_specificity_1: 0.6306 - val_specificity_at_sensitivity_1: 0.6045 - val_recall_1: 1.0000 - val_precision_1: 0.5382\n",
            "Epoch 215/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4337 - accuracy: 0.7801 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8583 - recall_1: 0.9992 - precision_1: 0.6964\n",
            "Epoch 215: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 156ms/step - loss: 0.4337 - accuracy: 0.7801 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8583 - recall_1: 0.9992 - precision_1: 0.6964 - val_loss: 0.6504 - val_accuracy: 0.6125 - val_sensitivity_at_specificity_1: 0.6819 - val_specificity_at_sensitivity_1: 0.6853 - val_recall_1: 0.9984 - val_precision_1: 0.5616\n",
            "Epoch 216/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4398 - accuracy: 0.7738 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8445 - recall_1: 0.9883 - precision_1: 0.6916\n",
            "Epoch 216: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.4398 - accuracy: 0.7738 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8445 - recall_1: 0.9883 - precision_1: 0.6916 - val_loss: 0.6969 - val_accuracy: 0.5969 - val_sensitivity_at_specificity_1: 0.6961 - val_specificity_at_sensitivity_1: 0.6481 - val_recall_1: 0.9969 - val_precision_1: 0.5519\n",
            "Epoch 217/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4530 - accuracy: 0.7695 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8104 - recall_1: 0.9892 - precision_1: 0.6897\n",
            "Epoch 217: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.4530 - accuracy: 0.7695 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8104 - recall_1: 0.9892 - precision_1: 0.6897 - val_loss: 0.7065 - val_accuracy: 0.6086 - val_sensitivity_at_specificity_1: 0.7285 - val_specificity_at_sensitivity_1: 0.6576 - val_recall_1: 1.0000 - val_precision_1: 0.5655\n",
            "Epoch 218/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4540 - accuracy: 0.7668 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8174 - recall_1: 0.9860 - precision_1: 0.6862\n",
            "Epoch 218: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.4540 - accuracy: 0.7668 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8174 - recall_1: 0.9860 - precision_1: 0.6862 - val_loss: 0.6725 - val_accuracy: 0.6047 - val_sensitivity_at_specificity_1: 0.7305 - val_specificity_at_sensitivity_1: 0.6505 - val_recall_1: 1.0000 - val_precision_1: 0.5592\n",
            "Epoch 219/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4410 - accuracy: 0.7777 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8198 - recall_1: 0.9891 - precision_1: 0.6967\n",
            "Epoch 219: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.4410 - accuracy: 0.7777 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8198 - recall_1: 0.9891 - precision_1: 0.6967 - val_loss: 0.6597 - val_accuracy: 0.6055 - val_sensitivity_at_specificity_1: 0.6513 - val_specificity_at_sensitivity_1: 0.6487 - val_recall_1: 0.9984 - val_precision_1: 0.5556\n",
            "Epoch 220/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4290 - accuracy: 0.7824 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8326 - recall_1: 0.9960 - precision_1: 0.6932\n",
            "Epoch 220: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.4290 - accuracy: 0.7824 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8326 - recall_1: 0.9960 - precision_1: 0.6932 - val_loss: 0.6469 - val_accuracy: 0.6328 - val_sensitivity_at_specificity_1: 0.7270 - val_specificity_at_sensitivity_1: 0.6402 - val_recall_1: 0.9985 - val_precision_1: 0.5853\n",
            "Epoch 221/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4469 - accuracy: 0.7742 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8084 - recall_1: 0.9946 - precision_1: 0.6940\n",
            "Epoch 221: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.4469 - accuracy: 0.7742 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8084 - recall_1: 0.9946 - precision_1: 0.6940 - val_loss: 0.6839 - val_accuracy: 0.5906 - val_sensitivity_at_specificity_1: 0.6833 - val_specificity_at_sensitivity_1: 0.6611 - val_recall_1: 1.0000 - val_precision_1: 0.5428\n",
            "Epoch 222/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4333 - accuracy: 0.7762 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8414 - recall_1: 0.9952 - precision_1: 0.6855\n",
            "Epoch 222: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.4333 - accuracy: 0.7762 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8414 - recall_1: 0.9952 - precision_1: 0.6855 - val_loss: 0.6567 - val_accuracy: 0.5984 - val_sensitivity_at_specificity_1: 0.6990 - val_specificity_at_sensitivity_1: 0.6457 - val_recall_1: 1.0000 - val_precision_1: 0.5499\n",
            "Epoch 223/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4395 - accuracy: 0.7699 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8452 - recall_1: 0.9976 - precision_1: 0.6812\n",
            "Epoch 223: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.4395 - accuracy: 0.7699 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8452 - recall_1: 0.9976 - precision_1: 0.6812 - val_loss: 0.6477 - val_accuracy: 0.6125 - val_sensitivity_at_specificity_1: 0.6725 - val_specificity_at_sensitivity_1: 0.6559 - val_recall_1: 0.9953 - val_precision_1: 0.5606\n",
            "Epoch 224/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4341 - accuracy: 0.7840 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8302 - recall_1: 0.9899 - precision_1: 0.7015\n",
            "Epoch 224: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.4341 - accuracy: 0.7840 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8302 - recall_1: 0.9899 - precision_1: 0.7015 - val_loss: 0.7027 - val_accuracy: 0.5906 - val_sensitivity_at_specificity_1: 0.6748 - val_specificity_at_sensitivity_1: 0.6451 - val_recall_1: 1.0000 - val_precision_1: 0.5399\n",
            "Epoch 225/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4343 - accuracy: 0.7871 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8209 - recall_1: 0.9985 - precision_1: 0.7065\n",
            "Epoch 225: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.4343 - accuracy: 0.7871 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8209 - recall_1: 0.9985 - precision_1: 0.7065 - val_loss: 0.6723 - val_accuracy: 0.6117 - val_sensitivity_at_specificity_1: 0.7096 - val_specificity_at_sensitivity_1: 0.5931 - val_recall_1: 0.9985 - val_precision_1: 0.5735\n",
            "Epoch 226/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4389 - accuracy: 0.7820 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8169 - recall_1: 0.9863 - precision_1: 0.7074\n",
            "Epoch 226: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 156ms/step - loss: 0.4389 - accuracy: 0.7820 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8169 - recall_1: 0.9863 - precision_1: 0.7074 - val_loss: 0.6998 - val_accuracy: 0.5984 - val_sensitivity_at_specificity_1: 0.6516 - val_specificity_at_sensitivity_1: 0.5773 - val_recall_1: 0.9968 - val_precision_1: 0.5469\n",
            "Epoch 227/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4426 - accuracy: 0.7691 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8154 - recall_1: 0.9861 - precision_1: 0.6773\n",
            "Epoch 227: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.4426 - accuracy: 0.7691 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8154 - recall_1: 0.9861 - precision_1: 0.6773 - val_loss: 0.6608 - val_accuracy: 0.5984 - val_sensitivity_at_specificity_1: 0.6825 - val_specificity_at_sensitivity_1: 0.6198 - val_recall_1: 0.9968 - val_precision_1: 0.5521\n",
            "Epoch 228/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4383 - accuracy: 0.7906 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8111 - recall_1: 0.9955 - precision_1: 0.7127\n",
            "Epoch 228: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.4383 - accuracy: 0.7906 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8111 - recall_1: 0.9955 - precision_1: 0.7127 - val_loss: 0.6642 - val_accuracy: 0.6234 - val_sensitivity_at_specificity_1: 0.7152 - val_specificity_at_sensitivity_1: 0.6332 - val_recall_1: 1.0000 - val_precision_1: 0.5753\n",
            "Epoch 229/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4408 - accuracy: 0.7766 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8140 - recall_1: 0.9992 - precision_1: 0.6887\n",
            "Epoch 229: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.4408 - accuracy: 0.7766 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8140 - recall_1: 0.9992 - precision_1: 0.6887 - val_loss: 0.6470 - val_accuracy: 0.6062 - val_sensitivity_at_specificity_1: 0.6881 - val_specificity_at_sensitivity_1: 0.6433 - val_recall_1: 0.9984 - val_precision_1: 0.5588\n",
            "Epoch 230/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4338 - accuracy: 0.7918 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7935 - recall_1: 0.9946 - precision_1: 0.7102\n",
            "Epoch 230: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.4338 - accuracy: 0.7918 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7935 - recall_1: 0.9946 - precision_1: 0.7102 - val_loss: 0.6964 - val_accuracy: 0.5984 - val_sensitivity_at_specificity_1: 0.4984 - val_specificity_at_sensitivity_1: 0.4892 - val_recall_1: 1.0000 - val_precision_1: 0.5507\n",
            "Epoch 231/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4333 - accuracy: 0.7902 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7959 - recall_1: 0.9954 - precision_1: 0.7084\n",
            "Epoch 231: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.4333 - accuracy: 0.7902 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7959 - recall_1: 0.9954 - precision_1: 0.7084 - val_loss: 0.6552 - val_accuracy: 0.5891 - val_sensitivity_at_specificity_1: 0.7041 - val_specificity_at_sensitivity_1: 0.6075 - val_recall_1: 0.9984 - val_precision_1: 0.5391\n",
            "Epoch 232/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4490 - accuracy: 0.7695 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8286 - recall_1: 0.9869 - precision_1: 0.6913\n",
            "Epoch 232: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.4490 - accuracy: 0.7695 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8286 - recall_1: 0.9869 - precision_1: 0.6913 - val_loss: 0.6511 - val_accuracy: 0.6070 - val_sensitivity_at_specificity_1: 0.7138 - val_specificity_at_sensitivity_1: 0.6329 - val_recall_1: 1.0000 - val_precision_1: 0.5557\n",
            "Epoch 233/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4468 - accuracy: 0.7762 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8021 - recall_1: 0.9923 - precision_1: 0.6973\n",
            "Epoch 233: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.4468 - accuracy: 0.7762 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8021 - recall_1: 0.9923 - precision_1: 0.6973 - val_loss: 0.6563 - val_accuracy: 0.6133 - val_sensitivity_at_specificity_1: 0.6972 - val_specificity_at_sensitivity_1: 0.6342 - val_recall_1: 0.9908 - val_precision_1: 0.5699\n",
            "Epoch 234/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4348 - accuracy: 0.7832 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8412 - recall_1: 0.9871 - precision_1: 0.7070\n",
            "Epoch 234: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.4348 - accuracy: 0.7832 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8412 - recall_1: 0.9871 - precision_1: 0.7070 - val_loss: 0.6494 - val_accuracy: 0.6227 - val_sensitivity_at_specificity_1: 0.7164 - val_specificity_at_sensitivity_1: 0.6451 - val_recall_1: 0.9985 - val_precision_1: 0.5787\n",
            "Epoch 235/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4506 - accuracy: 0.7719 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8145 - recall_1: 0.9862 - precision_1: 0.6944\n",
            "Epoch 235: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.4506 - accuracy: 0.7719 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8145 - recall_1: 0.9862 - precision_1: 0.6944 - val_loss: 0.6597 - val_accuracy: 0.6133 - val_sensitivity_at_specificity_1: 0.6563 - val_specificity_at_sensitivity_1: 0.6514 - val_recall_1: 0.9938 - val_precision_1: 0.5666\n",
            "Epoch 236/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4369 - accuracy: 0.7727 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8292 - recall_1: 0.9686 - precision_1: 0.6945\n",
            "Epoch 236: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.4369 - accuracy: 0.7727 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8292 - recall_1: 0.9686 - precision_1: 0.6945 - val_loss: 0.6543 - val_accuracy: 0.6094 - val_sensitivity_at_specificity_1: 0.6455 - val_specificity_at_sensitivity_1: 0.6356 - val_recall_1: 0.9799 - val_precision_1: 0.5652\n",
            "Epoch 237/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4476 - accuracy: 0.7652 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8313 - recall_1: 0.9779 - precision_1: 0.6839\n",
            "Epoch 237: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.4476 - accuracy: 0.7652 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8313 - recall_1: 0.9779 - precision_1: 0.6839 - val_loss: 0.6512 - val_accuracy: 0.5984 - val_sensitivity_at_specificity_1: 0.6506 - val_specificity_at_sensitivity_1: 0.6321 - val_recall_1: 0.9907 - val_precision_1: 0.5567\n",
            "Epoch 238/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4407 - accuracy: 0.7773 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8277 - recall_1: 0.9848 - precision_1: 0.6915\n",
            "Epoch 238: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.4407 - accuracy: 0.7773 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8277 - recall_1: 0.9848 - precision_1: 0.6915 - val_loss: 0.6746 - val_accuracy: 0.6156 - val_sensitivity_at_specificity_1: 0.6590 - val_specificity_at_sensitivity_1: 0.6392 - val_recall_1: 0.9985 - val_precision_1: 0.5685\n",
            "Epoch 239/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4468 - accuracy: 0.7703 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8257 - recall_1: 0.9952 - precision_1: 0.6827\n",
            "Epoch 239: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.4468 - accuracy: 0.7703 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8257 - recall_1: 0.9952 - precision_1: 0.6827 - val_loss: 0.6445 - val_accuracy: 0.5797 - val_sensitivity_at_specificity_1: 0.7294 - val_specificity_at_sensitivity_1: 0.6231 - val_recall_1: 0.9967 - val_precision_1: 0.5298\n",
            "Epoch 240/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4373 - accuracy: 0.7691 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8574 - recall_1: 0.9880 - precision_1: 0.6818\n",
            "Epoch 240: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.4373 - accuracy: 0.7691 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8574 - recall_1: 0.9880 - precision_1: 0.6818 - val_loss: 0.6327 - val_accuracy: 0.6078 - val_sensitivity_at_specificity_1: 0.6546 - val_specificity_at_sensitivity_1: 0.5988 - val_recall_1: 0.9906 - val_precision_1: 0.5599\n",
            "Epoch 241/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4446 - accuracy: 0.7629 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8369 - recall_1: 0.9831 - precision_1: 0.6757\n",
            "Epoch 241: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.4446 - accuracy: 0.7629 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8369 - recall_1: 0.9831 - precision_1: 0.6757 - val_loss: 0.6790 - val_accuracy: 0.6000 - val_sensitivity_at_specificity_1: 0.7322 - val_specificity_at_sensitivity_1: 0.6610 - val_recall_1: 0.9984 - val_precision_1: 0.5521\n",
            "Epoch 242/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4352 - accuracy: 0.7867 - sensitivity_at_specificity_1: 0.9992 - specificity_at_sensitivity_1: 0.8375 - recall_1: 0.9876 - precision_1: 0.7056\n",
            "Epoch 242: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.4352 - accuracy: 0.7867 - sensitivity_at_specificity_1: 0.9992 - specificity_at_sensitivity_1: 0.8375 - recall_1: 0.9876 - precision_1: 0.7056 - val_loss: 0.6378 - val_accuracy: 0.6211 - val_sensitivity_at_specificity_1: 0.6868 - val_specificity_at_sensitivity_1: 0.6756 - val_recall_1: 0.9969 - val_precision_1: 0.5710\n",
            "Epoch 243/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4354 - accuracy: 0.7843 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8436 - recall_1: 0.9877 - precision_1: 0.6998\n",
            "Epoch 243: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.4366 - accuracy: 0.7828 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8429 - recall_1: 0.9882 - precision_1: 0.6972 - val_loss: 0.6426 - val_accuracy: 0.6141 - val_sensitivity_at_specificity_1: 0.7171 - val_specificity_at_sensitivity_1: 0.6438 - val_recall_1: 0.9847 - val_precision_1: 0.5709\n",
            "Epoch 244/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4361 - accuracy: 0.7865 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8312 - recall_1: 0.9658 - precision_1: 0.7208\n",
            "Epoch 244: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.4361 - accuracy: 0.7865 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8312 - recall_1: 0.9658 - precision_1: 0.7208 - val_loss: 0.7002 - val_accuracy: 0.6109 - val_sensitivity_at_specificity_1: 0.6495 - val_specificity_at_sensitivity_1: 0.6214 - val_recall_1: 0.9985 - val_precision_1: 0.5708\n",
            "Epoch 245/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4531 - accuracy: 0.7645 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8227 - recall_1: 0.9766 - precision_1: 0.6857\n",
            "Epoch 245: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.4531 - accuracy: 0.7645 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8227 - recall_1: 0.9766 - precision_1: 0.6857 - val_loss: 0.6472 - val_accuracy: 0.5969 - val_sensitivity_at_specificity_1: 0.6771 - val_specificity_at_sensitivity_1: 0.6308 - val_recall_1: 0.9843 - val_precision_1: 0.5538\n",
            "Epoch 246/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4261 - accuracy: 0.7852 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8378 - recall_1: 0.9913 - precision_1: 0.6984\n",
            "Epoch 246: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.4261 - accuracy: 0.7852 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8378 - recall_1: 0.9913 - precision_1: 0.6984 - val_loss: 0.6677 - val_accuracy: 0.5992 - val_sensitivity_at_specificity_1: 0.7452 - val_specificity_at_sensitivity_1: 0.6646 - val_recall_1: 1.0000 - val_precision_1: 0.5488\n",
            "Epoch 247/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4269 - accuracy: 0.7890 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8382 - recall_1: 0.9926 - precision_1: 0.7063\n",
            "Epoch 247: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.4269 - accuracy: 0.7890 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8382 - recall_1: 0.9926 - precision_1: 0.7063 - val_loss: 0.6693 - val_accuracy: 0.6008 - val_sensitivity_at_specificity_1: 0.6866 - val_specificity_at_sensitivity_1: 0.6419 - val_recall_1: 1.0000 - val_precision_1: 0.5541\n",
            "Epoch 248/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4401 - accuracy: 0.7777 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8312 - recall_1: 0.9916 - precision_1: 0.6995\n",
            "Epoch 248: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 183ms/step - loss: 0.4401 - accuracy: 0.7777 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8312 - recall_1: 0.9916 - precision_1: 0.6995 - val_loss: 0.6453 - val_accuracy: 0.6102 - val_sensitivity_at_specificity_1: 0.7012 - val_specificity_at_sensitivity_1: 0.6356 - val_recall_1: 0.9969 - val_precision_1: 0.5644\n",
            "Epoch 249/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4368 - accuracy: 0.7707 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8429 - recall_1: 0.9800 - precision_1: 0.6853\n",
            "Epoch 249: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.4368 - accuracy: 0.7707 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8429 - recall_1: 0.9800 - precision_1: 0.6853 - val_loss: 0.6568 - val_accuracy: 0.5984 - val_sensitivity_at_specificity_1: 0.6715 - val_specificity_at_sensitivity_1: 0.6254 - val_recall_1: 0.9984 - val_precision_1: 0.5460\n",
            "Epoch 250/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4250 - accuracy: 0.7849 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8449 - recall_1: 0.9897 - precision_1: 0.6948\n",
            "Epoch 250: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 159ms/step - loss: 0.4250 - accuracy: 0.7849 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8449 - recall_1: 0.9897 - precision_1: 0.6948 - val_loss: 0.6383 - val_accuracy: 0.6320 - val_sensitivity_at_specificity_1: 0.6672 - val_specificity_at_sensitivity_1: 0.6320 - val_recall_1: 0.9969 - val_precision_1: 0.5820\n",
            "Epoch 251/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4152 - accuracy: 0.7859 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8640 - recall_1: 0.9830 - precision_1: 0.6975\n",
            "Epoch 251: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.4152 - accuracy: 0.7859 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8640 - recall_1: 0.9830 - precision_1: 0.6975 - val_loss: 0.6592 - val_accuracy: 0.6039 - val_sensitivity_at_specificity_1: 0.6562 - val_specificity_at_sensitivity_1: 0.6344 - val_recall_1: 0.9766 - val_precision_1: 0.5595\n",
            "Epoch 252/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4357 - accuracy: 0.7695 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8536 - recall_1: 0.9574 - precision_1: 0.6939\n",
            "Epoch 252: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 160ms/step - loss: 0.4357 - accuracy: 0.7695 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8536 - recall_1: 0.9574 - precision_1: 0.6939 - val_loss: 0.6779 - val_accuracy: 0.5883 - val_sensitivity_at_specificity_1: 0.6826 - val_specificity_at_sensitivity_1: 0.6369 - val_recall_1: 0.9967 - val_precision_1: 0.5358\n",
            "Epoch 253/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4205 - accuracy: 0.7848 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8611 - recall_1: 0.9842 - precision_1: 0.7008\n",
            "Epoch 253: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.4205 - accuracy: 0.7848 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8611 - recall_1: 0.9842 - precision_1: 0.7008 - val_loss: 0.6442 - val_accuracy: 0.6258 - val_sensitivity_at_specificity_1: 0.6901 - val_specificity_at_sensitivity_1: 0.6275 - val_recall_1: 0.9940 - val_precision_1: 0.5830\n",
            "Epoch 254/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4279 - accuracy: 0.7906 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8407 - recall_1: 0.9882 - precision_1: 0.7071\n",
            "Epoch 254: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.4279 - accuracy: 0.7906 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8407 - recall_1: 0.9882 - precision_1: 0.7071 - val_loss: 0.6656 - val_accuracy: 0.6133 - val_sensitivity_at_specificity_1: 0.6631 - val_specificity_at_sensitivity_1: 0.6175 - val_recall_1: 1.0000 - val_precision_1: 0.5677\n",
            "Epoch 255/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4457 - accuracy: 0.7641 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8465 - recall_1: 0.9924 - precision_1: 0.6763\n",
            "Epoch 255: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.4457 - accuracy: 0.7641 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8465 - recall_1: 0.9924 - precision_1: 0.6763 - val_loss: 0.6775 - val_accuracy: 0.6078 - val_sensitivity_at_specificity_1: 0.6614 - val_specificity_at_sensitivity_1: 0.6605 - val_recall_1: 0.9984 - val_precision_1: 0.5562\n",
            "Epoch 256/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4385 - accuracy: 0.7805 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8160 - recall_1: 0.9907 - precision_1: 0.6988\n",
            "Epoch 256: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.4385 - accuracy: 0.7805 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8160 - recall_1: 0.9907 - precision_1: 0.6988 - val_loss: 0.6654 - val_accuracy: 0.6055 - val_sensitivity_at_specificity_1: 0.6227 - val_specificity_at_sensitivity_1: 0.6164 - val_recall_1: 1.0000 - val_precision_1: 0.5605\n",
            "Epoch 257/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4435 - accuracy: 0.7716 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8246 - recall_1: 0.9923 - precision_1: 0.6823\n",
            "Epoch 257: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 155ms/step - loss: 0.4435 - accuracy: 0.7716 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8246 - recall_1: 0.9923 - precision_1: 0.6823 - val_loss: 0.6379 - val_accuracy: 0.6195 - val_sensitivity_at_specificity_1: 0.7484 - val_specificity_at_sensitivity_1: 0.6557 - val_recall_1: 0.9984 - val_precision_1: 0.5695\n",
            "Epoch 258/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4391 - accuracy: 0.7719 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8448 - recall_1: 0.9879 - precision_1: 0.6827\n",
            "Epoch 258: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.4391 - accuracy: 0.7719 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8448 - recall_1: 0.9879 - precision_1: 0.6827 - val_loss: 0.6582 - val_accuracy: 0.6141 - val_sensitivity_at_specificity_1: 0.6552 - val_specificity_at_sensitivity_1: 0.6085 - val_recall_1: 0.9970 - val_precision_1: 0.5748\n",
            "Epoch 259/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4212 - accuracy: 0.7906 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8397 - recall_1: 0.9898 - precision_1: 0.7070\n",
            "Epoch 259: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.4212 - accuracy: 0.7906 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8397 - recall_1: 0.9898 - precision_1: 0.7070 - val_loss: 0.6434 - val_accuracy: 0.6187 - val_sensitivity_at_specificity_1: 0.6900 - val_specificity_at_sensitivity_1: 0.6599 - val_recall_1: 0.9984 - val_precision_1: 0.5683\n",
            "Epoch 260/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4340 - accuracy: 0.7801 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8286 - recall_1: 0.9945 - precision_1: 0.6935\n",
            "Epoch 260: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.4340 - accuracy: 0.7801 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8286 - recall_1: 0.9945 - precision_1: 0.6935 - val_loss: 0.6407 - val_accuracy: 0.6125 - val_sensitivity_at_specificity_1: 0.6942 - val_specificity_at_sensitivity_1: 0.6369 - val_recall_1: 0.9969 - val_precision_1: 0.5640\n",
            "Epoch 261/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4290 - accuracy: 0.7770 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8483 - recall_1: 0.9897 - precision_1: 0.6910\n",
            "Epoch 261: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.4290 - accuracy: 0.7770 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8483 - recall_1: 0.9897 - precision_1: 0.6910 - val_loss: 0.6690 - val_accuracy: 0.6109 - val_sensitivity_at_specificity_1: 0.6920 - val_specificity_at_sensitivity_1: 0.6404 - val_recall_1: 0.9969 - val_precision_1: 0.5649\n",
            "Epoch 262/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4394 - accuracy: 0.7749 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8400 - recall_1: 0.9725 - precision_1: 0.6967\n",
            "Epoch 262: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 157ms/step - loss: 0.4394 - accuracy: 0.7749 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8400 - recall_1: 0.9725 - precision_1: 0.6967 - val_loss: 0.6585 - val_accuracy: 0.6117 - val_sensitivity_at_specificity_1: 0.7672 - val_specificity_at_sensitivity_1: 0.6703 - val_recall_1: 0.9906 - val_precision_1: 0.5636\n",
            "Epoch 263/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4289 - accuracy: 0.7907 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8270 - recall_1: 0.9714 - precision_1: 0.7170\n",
            "Epoch 263: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 157ms/step - loss: 0.4289 - accuracy: 0.7907 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8270 - recall_1: 0.9714 - precision_1: 0.7170 - val_loss: 0.6458 - val_accuracy: 0.6086 - val_sensitivity_at_specificity_1: 0.7328 - val_specificity_at_sensitivity_1: 0.6397 - val_recall_1: 0.9872 - val_precision_1: 0.5559\n",
            "Epoch 264/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4298 - accuracy: 0.7805 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8478 - recall_1: 0.9747 - precision_1: 0.6924\n",
            "Epoch 264: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.4298 - accuracy: 0.7805 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8478 - recall_1: 0.9747 - precision_1: 0.6924 - val_loss: 0.6675 - val_accuracy: 0.6000 - val_sensitivity_at_specificity_1: 0.6895 - val_specificity_at_sensitivity_1: 0.6150 - val_recall_1: 0.9920 - val_precision_1: 0.5513\n",
            "Epoch 265/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4452 - accuracy: 0.7719 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8033 - recall_1: 0.9749 - precision_1: 0.6923\n",
            "Epoch 265: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.4452 - accuracy: 0.7719 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8033 - recall_1: 0.9749 - precision_1: 0.6923 - val_loss: 0.6357 - val_accuracy: 0.6187 - val_sensitivity_at_specificity_1: 0.6570 - val_specificity_at_sensitivity_1: 0.6077 - val_recall_1: 0.9923 - val_precision_1: 0.5729\n",
            "Epoch 266/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4192 - accuracy: 0.7945 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8409 - recall_1: 0.9877 - precision_1: 0.7152\n",
            "Epoch 266: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.4192 - accuracy: 0.7945 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8409 - recall_1: 0.9877 - precision_1: 0.7152 - val_loss: 0.6503 - val_accuracy: 0.6102 - val_sensitivity_at_specificity_1: 0.7102 - val_specificity_at_sensitivity_1: 0.6258 - val_recall_1: 0.9825 - val_precision_1: 0.5584\n",
            "Epoch 267/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4246 - accuracy: 0.7883 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8575 - recall_1: 0.9736 - precision_1: 0.7120\n",
            "Epoch 267: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.4246 - accuracy: 0.7883 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8575 - recall_1: 0.9736 - precision_1: 0.7120 - val_loss: 0.6590 - val_accuracy: 0.6055 - val_sensitivity_at_specificity_1: 0.7608 - val_specificity_at_sensitivity_1: 0.6408 - val_recall_1: 0.9952 - val_precision_1: 0.5526\n",
            "Epoch 268/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4294 - accuracy: 0.7859 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8321 - recall_1: 0.9754 - precision_1: 0.7112\n",
            "Epoch 268: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.4294 - accuracy: 0.7859 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8321 - recall_1: 0.9754 - precision_1: 0.7112 - val_loss: 0.6661 - val_accuracy: 0.6031 - val_sensitivity_at_specificity_1: 0.6840 - val_specificity_at_sensitivity_1: 0.6398 - val_recall_1: 0.9575 - val_precision_1: 0.5587\n",
            "Epoch 269/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4434 - accuracy: 0.7707 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8268 - recall_1: 0.9574 - precision_1: 0.6947\n",
            "Epoch 269: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.4434 - accuracy: 0.7707 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8268 - recall_1: 0.9574 - precision_1: 0.6947 - val_loss: 0.6785 - val_accuracy: 0.6156 - val_sensitivity_at_specificity_1: 0.6292 - val_specificity_at_sensitivity_1: 0.5968 - val_recall_1: 0.9985 - val_precision_1: 0.5693\n",
            "Epoch 270/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4347 - accuracy: 0.7762 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8288 - recall_1: 0.9693 - precision_1: 0.6973\n",
            "Epoch 270: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.4347 - accuracy: 0.7762 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8288 - recall_1: 0.9693 - precision_1: 0.6973 - val_loss: 0.6385 - val_accuracy: 0.6234 - val_sensitivity_at_specificity_1: 0.6733 - val_specificity_at_sensitivity_1: 0.6306 - val_recall_1: 0.9877 - val_precision_1: 0.5760\n",
            "Epoch 271/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4193 - accuracy: 0.7934 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8558 - recall_1: 0.9914 - precision_1: 0.7096\n",
            "Epoch 271: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.4193 - accuracy: 0.7934 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8558 - recall_1: 0.9914 - precision_1: 0.7096 - val_loss: 0.6727 - val_accuracy: 0.6187 - val_sensitivity_at_specificity_1: 0.6723 - val_specificity_at_sensitivity_1: 0.6222 - val_recall_1: 0.9954 - val_precision_1: 0.5716\n",
            "Epoch 272/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4396 - accuracy: 0.7699 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8319 - recall_1: 0.9639 - precision_1: 0.6881\n",
            "Epoch 272: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.4396 - accuracy: 0.7699 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8319 - recall_1: 0.9639 - precision_1: 0.6881 - val_loss: 0.6207 - val_accuracy: 0.6195 - val_sensitivity_at_specificity_1: 0.7355 - val_specificity_at_sensitivity_1: 0.6396 - val_recall_1: 0.8967 - val_precision_1: 0.5765\n",
            "Epoch 273/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4334 - accuracy: 0.7871 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8266 - recall_1: 0.9409 - precision_1: 0.7237\n",
            "Epoch 273: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.4334 - accuracy: 0.7871 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8266 - recall_1: 0.9409 - precision_1: 0.7237 - val_loss: 0.6472 - val_accuracy: 0.6258 - val_sensitivity_at_specificity_1: 0.6697 - val_specificity_at_sensitivity_1: 0.6270 - val_recall_1: 0.9459 - val_precision_1: 0.5871\n",
            "Epoch 274/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4524 - accuracy: 0.7727 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7995 - recall_1: 0.9697 - precision_1: 0.7022\n",
            "Epoch 274: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.4524 - accuracy: 0.7727 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.7995 - recall_1: 0.9697 - precision_1: 0.7022 - val_loss: 0.6205 - val_accuracy: 0.6109 - val_sensitivity_at_specificity_1: 0.6738 - val_specificity_at_sensitivity_1: 0.6238 - val_recall_1: 0.9538 - val_precision_1: 0.5699\n",
            "Epoch 275/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4427 - accuracy: 0.7707 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8335 - recall_1: 0.9796 - precision_1: 0.6901\n",
            "Epoch 275: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.4427 - accuracy: 0.7707 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8335 - recall_1: 0.9796 - precision_1: 0.6901 - val_loss: 0.6446 - val_accuracy: 0.6086 - val_sensitivity_at_specificity_1: 0.7183 - val_specificity_at_sensitivity_1: 0.6474 - val_recall_1: 1.0000 - val_precision_1: 0.5605\n",
            "Epoch 276/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4262 - accuracy: 0.7875 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8366 - recall_1: 0.9961 - precision_1: 0.7011\n",
            "Epoch 276: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.4262 - accuracy: 0.7875 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8366 - recall_1: 0.9961 - precision_1: 0.7011 - val_loss: 0.6891 - val_accuracy: 0.5898 - val_sensitivity_at_specificity_1: 0.6879 - val_specificity_at_sensitivity_1: 0.6135 - val_recall_1: 0.9984 - val_precision_1: 0.5447\n",
            "Epoch 277/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4437 - accuracy: 0.7750 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8258 - recall_1: 0.9876 - precision_1: 0.6948\n",
            "Epoch 277: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.4437 - accuracy: 0.7750 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8258 - recall_1: 0.9876 - precision_1: 0.6948 - val_loss: 0.6741 - val_accuracy: 0.5953 - val_sensitivity_at_specificity_1: 0.6911 - val_specificity_at_sensitivity_1: 0.6396 - val_recall_1: 1.0000 - val_precision_1: 0.5480\n",
            "Epoch 278/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4485 - accuracy: 0.7711 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8044 - recall_1: 0.9930 - precision_1: 0.6889\n",
            "Epoch 278: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.4485 - accuracy: 0.7711 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8044 - recall_1: 0.9930 - precision_1: 0.6889 - val_loss: 0.6987 - val_accuracy: 0.6070 - val_sensitivity_at_specificity_1: 0.6635 - val_specificity_at_sensitivity_1: 0.5978 - val_recall_1: 1.0000 - val_precision_1: 0.5584\n",
            "Epoch 279/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4320 - accuracy: 0.7852 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8517 - recall_1: 0.9838 - precision_1: 0.7072\n",
            "Epoch 279: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.4320 - accuracy: 0.7852 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8517 - recall_1: 0.9838 - precision_1: 0.7072 - val_loss: 0.6663 - val_accuracy: 0.6234 - val_sensitivity_at_specificity_1: 0.7080 - val_specificity_at_sensitivity_1: 0.6629 - val_recall_1: 0.9878 - val_precision_1: 0.5768\n",
            "Epoch 280/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4395 - accuracy: 0.7730 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8335 - recall_1: 0.9381 - precision_1: 0.7077\n",
            "Epoch 280: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.4395 - accuracy: 0.7730 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8335 - recall_1: 0.9381 - precision_1: 0.7077 - val_loss: 0.6579 - val_accuracy: 0.6187 - val_sensitivity_at_specificity_1: 0.6969 - val_specificity_at_sensitivity_1: 0.6651 - val_recall_1: 0.9754 - val_precision_1: 0.5732\n",
            "Epoch 281/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4411 - accuracy: 0.7746 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8233 - recall_1: 0.9827 - precision_1: 0.6922\n",
            "Epoch 281: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 183ms/step - loss: 0.4411 - accuracy: 0.7746 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8233 - recall_1: 0.9827 - precision_1: 0.6922 - val_loss: 0.6644 - val_accuracy: 0.6094 - val_sensitivity_at_specificity_1: 0.6259 - val_specificity_at_sensitivity_1: 0.6467 - val_recall_1: 0.9925 - val_precision_1: 0.5707\n",
            "Epoch 282/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4323 - accuracy: 0.7848 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8361 - recall_1: 0.9812 - precision_1: 0.7043\n",
            "Epoch 282: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.4323 - accuracy: 0.7848 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8361 - recall_1: 0.9812 - precision_1: 0.7043 - val_loss: 0.6505 - val_accuracy: 0.6094 - val_sensitivity_at_specificity_1: 0.6817 - val_specificity_at_sensitivity_1: 0.6211 - val_recall_1: 0.9938 - val_precision_1: 0.5634\n",
            "Epoch 283/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4334 - accuracy: 0.7848 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8445 - recall_1: 0.9891 - precision_1: 0.7022\n",
            "Epoch 283: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.4334 - accuracy: 0.7848 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8445 - recall_1: 0.9891 - precision_1: 0.7022 - val_loss: 0.6616 - val_accuracy: 0.6141 - val_sensitivity_at_specificity_1: 0.7396 - val_specificity_at_sensitivity_1: 0.6894 - val_recall_1: 0.9954 - val_precision_1: 0.5682\n",
            "Epoch 284/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4387 - accuracy: 0.7773 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8403 - recall_1: 0.9823 - precision_1: 0.7003\n",
            "Epoch 284: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.4387 - accuracy: 0.7773 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8403 - recall_1: 0.9823 - precision_1: 0.7003 - val_loss: 0.6453 - val_accuracy: 0.6148 - val_sensitivity_at_specificity_1: 0.7263 - val_specificity_at_sensitivity_1: 0.6593 - val_recall_1: 0.9829 - val_precision_1: 0.5673\n",
            "Epoch 285/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4312 - accuracy: 0.7824 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8418 - recall_1: 0.9712 - precision_1: 0.7055\n",
            "Epoch 285: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.4312 - accuracy: 0.7824 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8418 - recall_1: 0.9712 - precision_1: 0.7055 - val_loss: 0.6607 - val_accuracy: 0.6008 - val_sensitivity_at_specificity_1: 0.6754 - val_specificity_at_sensitivity_1: 0.6240 - val_recall_1: 0.9784 - val_precision_1: 0.5602\n",
            "Epoch 286/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4289 - accuracy: 0.7793 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8631 - recall_1: 0.9738 - precision_1: 0.6976\n",
            "Epoch 286: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.4289 - accuracy: 0.7793 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8631 - recall_1: 0.9738 - precision_1: 0.6976 - val_loss: 0.6677 - val_accuracy: 0.6078 - val_sensitivity_at_specificity_1: 0.7266 - val_specificity_at_sensitivity_1: 0.6406 - val_recall_1: 0.9766 - val_precision_1: 0.5621\n",
            "Epoch 287/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4255 - accuracy: 0.7941 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8471 - recall_1: 0.9645 - precision_1: 0.7268\n",
            "Epoch 287: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.4255 - accuracy: 0.7941 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8471 - recall_1: 0.9645 - precision_1: 0.7268 - val_loss: 0.6607 - val_accuracy: 0.6172 - val_sensitivity_at_specificity_1: 0.6572 - val_specificity_at_sensitivity_1: 0.6388 - val_recall_1: 0.9762 - val_precision_1: 0.5802\n",
            "Epoch 288/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4330 - accuracy: 0.7859 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8234 - recall_1: 0.9701 - precision_1: 0.7129\n",
            "Epoch 288: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.4330 - accuracy: 0.7859 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8234 - recall_1: 0.9701 - precision_1: 0.7129 - val_loss: 0.6384 - val_accuracy: 0.6062 - val_sensitivity_at_specificity_1: 0.6312 - val_specificity_at_sensitivity_1: 0.6206 - val_recall_1: 0.9603 - val_precision_1: 0.5577\n",
            "Epoch 289/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4356 - accuracy: 0.7781 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8320 - recall_1: 0.9831 - precision_1: 0.7013\n",
            "Epoch 289: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.4356 - accuracy: 0.7781 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8320 - recall_1: 0.9831 - precision_1: 0.7013 - val_loss: 0.6721 - val_accuracy: 0.6148 - val_sensitivity_at_specificity_1: 0.7030 - val_specificity_at_sensitivity_1: 0.6229 - val_recall_1: 1.0000 - val_precision_1: 0.5622\n",
            "Epoch 290/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4351 - accuracy: 0.7828 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8252 - recall_1: 0.9861 - precision_1: 0.7037\n",
            "Epoch 290: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.4351 - accuracy: 0.7828 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8252 - recall_1: 0.9861 - precision_1: 0.7037 - val_loss: 0.6807 - val_accuracy: 0.6055 - val_sensitivity_at_specificity_1: 0.7344 - val_specificity_at_sensitivity_1: 0.6580 - val_recall_1: 1.0000 - val_precision_1: 0.5531\n",
            "Epoch 291/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4374 - accuracy: 0.7750 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8366 - recall_1: 0.9812 - precision_1: 0.6938\n",
            "Epoch 291: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.4374 - accuracy: 0.7750 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8366 - recall_1: 0.9812 - precision_1: 0.6938 - val_loss: 0.6602 - val_accuracy: 0.6148 - val_sensitivity_at_specificity_1: 0.6406 - val_specificity_at_sensitivity_1: 0.6057 - val_recall_1: 0.9739 - val_precision_1: 0.5712\n",
            "Epoch 292/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4310 - accuracy: 0.7781 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8448 - recall_1: 0.9700 - precision_1: 0.6983\n",
            "Epoch 292: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.4310 - accuracy: 0.7781 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8448 - recall_1: 0.9700 - precision_1: 0.6983 - val_loss: 0.6535 - val_accuracy: 0.6258 - val_sensitivity_at_specificity_1: 0.6769 - val_specificity_at_sensitivity_1: 0.6172 - val_recall_1: 0.9832 - val_precision_1: 0.5784\n",
            "Epoch 293/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4329 - accuracy: 0.7738 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8498 - recall_1: 0.9575 - precision_1: 0.6944\n",
            "Epoch 293: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.4329 - accuracy: 0.7738 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8498 - recall_1: 0.9575 - precision_1: 0.6944 - val_loss: 0.6588 - val_accuracy: 0.6039 - val_sensitivity_at_specificity_1: 0.6615 - val_specificity_at_sensitivity_1: 0.6541 - val_recall_1: 0.9485 - val_precision_1: 0.5619\n",
            "Epoch 294/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4402 - accuracy: 0.7789 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8180 - recall_1: 0.9614 - precision_1: 0.7024\n",
            "Epoch 294: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.4402 - accuracy: 0.7789 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8180 - recall_1: 0.9614 - precision_1: 0.7024 - val_loss: 0.6265 - val_accuracy: 0.6250 - val_sensitivity_at_specificity_1: 0.7241 - val_specificity_at_sensitivity_1: 0.6417 - val_recall_1: 0.9404 - val_precision_1: 0.5758\n",
            "Epoch 295/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4145 - accuracy: 0.7965 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8629 - recall_1: 0.9813 - precision_1: 0.7171\n",
            "Epoch 295: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 185ms/step - loss: 0.4145 - accuracy: 0.7965 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8629 - recall_1: 0.9813 - precision_1: 0.7171 - val_loss: 0.6399 - val_accuracy: 0.6094 - val_sensitivity_at_specificity_1: 0.6626 - val_specificity_at_sensitivity_1: 0.6077 - val_recall_1: 0.9483 - val_precision_1: 0.5725\n",
            "Epoch 296/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4253 - accuracy: 0.7891 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8535 - recall_1: 0.9673 - precision_1: 0.7027\n",
            "Epoch 296: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.4253 - accuracy: 0.7891 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8535 - recall_1: 0.9673 - precision_1: 0.7027 - val_loss: 0.6724 - val_accuracy: 0.5984 - val_sensitivity_at_specificity_1: 0.6641 - val_specificity_at_sensitivity_1: 0.6299 - val_recall_1: 0.9466 - val_precision_1: 0.5568\n",
            "Epoch 297/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4301 - accuracy: 0.7832 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8492 - recall_1: 0.9495 - precision_1: 0.7138\n",
            "Epoch 297: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.4301 - accuracy: 0.7832 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8492 - recall_1: 0.9495 - precision_1: 0.7138 - val_loss: 0.6972 - val_accuracy: 0.6164 - val_sensitivity_at_specificity_1: 0.6516 - val_specificity_at_sensitivity_1: 0.5997 - val_recall_1: 0.9879 - val_precision_1: 0.5756\n",
            "Epoch 298/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4277 - accuracy: 0.7871 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8305 - recall_1: 0.9891 - precision_1: 0.7045\n",
            "Epoch 298: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.4277 - accuracy: 0.7871 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8305 - recall_1: 0.9891 - precision_1: 0.7045 - val_loss: 0.6840 - val_accuracy: 0.5914 - val_sensitivity_at_specificity_1: 0.6357 - val_specificity_at_sensitivity_1: 0.6079 - val_recall_1: 0.9876 - val_precision_1: 0.5530\n",
            "Epoch 299/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4198 - accuracy: 0.7984 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8398 - recall_1: 0.9833 - precision_1: 0.7240\n",
            "Epoch 299: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.4198 - accuracy: 0.7984 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8398 - recall_1: 0.9833 - precision_1: 0.7240 - val_loss: 0.6671 - val_accuracy: 0.6320 - val_sensitivity_at_specificity_1: 0.6762 - val_specificity_at_sensitivity_1: 0.6444 - val_recall_1: 1.0000 - val_precision_1: 0.5861\n",
            "Epoch 300/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4493 - accuracy: 0.7641 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8309 - recall_1: 0.9847 - precision_1: 0.6763\n",
            "Epoch 300: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.4493 - accuracy: 0.7641 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8309 - recall_1: 0.9847 - precision_1: 0.6763 - val_loss: 0.6521 - val_accuracy: 0.6070 - val_sensitivity_at_specificity_1: 0.7253 - val_specificity_at_sensitivity_1: 0.6485 - val_recall_1: 0.9780 - val_precision_1: 0.5603\n",
            "Epoch 301/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4206 - accuracy: 0.7911 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8522 - recall_1: 0.9677 - precision_1: 0.7101\n",
            "Epoch 301: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.4206 - accuracy: 0.7911 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8522 - recall_1: 0.9677 - precision_1: 0.7101 - val_loss: 0.6294 - val_accuracy: 0.6141 - val_sensitivity_at_specificity_1: 0.7000 - val_specificity_at_sensitivity_1: 0.6187 - val_recall_1: 0.9062 - val_precision_1: 0.5720\n",
            "Epoch 302/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4385 - accuracy: 0.7770 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8405 - recall_1: 0.9554 - precision_1: 0.6997\n",
            "Epoch 302: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.4385 - accuracy: 0.7770 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8405 - recall_1: 0.9554 - precision_1: 0.6997 - val_loss: 0.6197 - val_accuracy: 0.6148 - val_sensitivity_at_specificity_1: 0.6896 - val_specificity_at_sensitivity_1: 0.6443 - val_recall_1: 0.8910 - val_precision_1: 0.5870\n",
            "Epoch 303/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4386 - accuracy: 0.7828 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8467 - recall_1: 0.9720 - precision_1: 0.7065\n",
            "Epoch 303: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.4386 - accuracy: 0.7828 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8467 - recall_1: 0.9720 - precision_1: 0.7065 - val_loss: 0.6550 - val_accuracy: 0.5953 - val_sensitivity_at_specificity_1: 0.6803 - val_specificity_at_sensitivity_1: 0.6279 - val_recall_1: 0.9543 - val_precision_1: 0.5534\n",
            "Epoch 304/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4229 - accuracy: 0.7949 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8449 - recall_1: 0.9660 - precision_1: 0.7224\n",
            "Epoch 304: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.4229 - accuracy: 0.7949 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8449 - recall_1: 0.9660 - precision_1: 0.7224 - val_loss: 0.7003 - val_accuracy: 0.5891 - val_sensitivity_at_specificity_1: 0.6726 - val_specificity_at_sensitivity_1: 0.5901 - val_recall_1: 0.9967 - val_precision_1: 0.5387\n",
            "Epoch 305/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4363 - accuracy: 0.7870 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8249 - recall_1: 0.9934 - precision_1: 0.7059\n",
            "Epoch 305: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.4363 - accuracy: 0.7870 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8249 - recall_1: 0.9934 - precision_1: 0.7059 - val_loss: 0.6476 - val_accuracy: 0.6109 - val_sensitivity_at_specificity_1: 0.7347 - val_specificity_at_sensitivity_1: 0.6292 - val_recall_1: 0.9871 - val_precision_1: 0.5562\n",
            "Epoch 306/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4253 - accuracy: 0.7918 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8641 - recall_1: 0.9805 - precision_1: 0.7119\n",
            "Epoch 306: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.4253 - accuracy: 0.7918 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8641 - recall_1: 0.9805 - precision_1: 0.7119 - val_loss: 0.6452 - val_accuracy: 0.6281 - val_sensitivity_at_specificity_1: 0.7169 - val_specificity_at_sensitivity_1: 0.6397 - val_recall_1: 0.9954 - val_precision_1: 0.5777\n",
            "Epoch 307/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4190 - accuracy: 0.8012 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8468 - recall_1: 0.9751 - precision_1: 0.7246\n",
            "Epoch 307: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.4190 - accuracy: 0.8012 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8468 - recall_1: 0.9751 - precision_1: 0.7246 - val_loss: 0.6828 - val_accuracy: 0.6141 - val_sensitivity_at_specificity_1: 0.6825 - val_specificity_at_sensitivity_1: 0.6213 - val_recall_1: 0.9889 - val_precision_1: 0.5624\n",
            "Epoch 308/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4300 - accuracy: 0.7910 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8393 - recall_1: 0.9704 - precision_1: 0.7149\n",
            "Epoch 308: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 174ms/step - loss: 0.4300 - accuracy: 0.7910 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8393 - recall_1: 0.9704 - precision_1: 0.7149 - val_loss: 0.6855 - val_accuracy: 0.6094 - val_sensitivity_at_specificity_1: 0.6378 - val_specificity_at_sensitivity_1: 0.6450 - val_recall_1: 0.9906 - val_precision_1: 0.5601\n",
            "Epoch 309/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4374 - accuracy: 0.7816 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8396 - recall_1: 0.9593 - precision_1: 0.7115\n",
            "Epoch 309: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.4374 - accuracy: 0.7816 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8396 - recall_1: 0.9593 - precision_1: 0.7115 - val_loss: 0.6476 - val_accuracy: 0.6086 - val_sensitivity_at_specificity_1: 0.6862 - val_specificity_at_sensitivity_1: 0.6210 - val_recall_1: 0.9160 - val_precision_1: 0.5634\n",
            "Epoch 310/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4132 - accuracy: 0.7973 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8595 - recall_1: 0.9686 - precision_1: 0.7200\n",
            "Epoch 310: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.4132 - accuracy: 0.7973 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8595 - recall_1: 0.9686 - precision_1: 0.7200 - val_loss: 0.7076 - val_accuracy: 0.6000 - val_sensitivity_at_specificity_1: 0.6587 - val_specificity_at_sensitivity_1: 0.6189 - val_recall_1: 0.9856 - val_precision_1: 0.5501\n",
            "Epoch 311/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4269 - accuracy: 0.7848 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8481 - recall_1: 0.9404 - precision_1: 0.7164\n",
            "Epoch 311: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.4269 - accuracy: 0.7848 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8481 - recall_1: 0.9404 - precision_1: 0.7164 - val_loss: 0.6697 - val_accuracy: 0.6266 - val_sensitivity_at_specificity_1: 0.6622 - val_specificity_at_sensitivity_1: 0.5977 - val_recall_1: 0.9670 - val_precision_1: 0.5855\n",
            "Epoch 312/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4265 - accuracy: 0.7879 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8491 - recall_1: 0.9671 - precision_1: 0.7063\n",
            "Epoch 312: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.4265 - accuracy: 0.7879 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8491 - recall_1: 0.9671 - precision_1: 0.7063 - val_loss: 0.6381 - val_accuracy: 0.6328 - val_sensitivity_at_specificity_1: 0.7550 - val_specificity_at_sensitivity_1: 0.6472 - val_recall_1: 0.9767 - val_precision_1: 0.5806\n",
            "Epoch 313/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4231 - accuracy: 0.7863 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8407 - recall_1: 0.9496 - precision_1: 0.7064\n",
            "Epoch 313: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.4231 - accuracy: 0.7863 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8407 - recall_1: 0.9496 - precision_1: 0.7064 - val_loss: 0.6501 - val_accuracy: 0.6031 - val_sensitivity_at_specificity_1: 0.6989 - val_specificity_at_sensitivity_1: 0.6479 - val_recall_1: 0.9048 - val_precision_1: 0.5648\n",
            "Epoch 314/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4433 - accuracy: 0.7746 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8461 - recall_1: 0.9487 - precision_1: 0.7084\n",
            "Epoch 314: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.4433 - accuracy: 0.7746 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8461 - recall_1: 0.9487 - precision_1: 0.7084 - val_loss: 0.6701 - val_accuracy: 0.6242 - val_sensitivity_at_specificity_1: 0.6995 - val_specificity_at_sensitivity_1: 0.6371 - val_recall_1: 0.9877 - val_precision_1: 0.5754\n",
            "Epoch 315/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4261 - accuracy: 0.7910 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8361 - recall_1: 0.9756 - precision_1: 0.7174\n",
            "Epoch 315: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.4261 - accuracy: 0.7910 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8361 - recall_1: 0.9756 - precision_1: 0.7174 - val_loss: 0.6664 - val_accuracy: 0.6078 - val_sensitivity_at_specificity_1: 0.6493 - val_specificity_at_sensitivity_1: 0.6300 - val_recall_1: 0.9663 - val_precision_1: 0.5680\n",
            "Epoch 316/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4359 - accuracy: 0.7785 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8569 - recall_1: 0.9635 - precision_1: 0.6997\n",
            "Epoch 316: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.4359 - accuracy: 0.7785 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8569 - recall_1: 0.9635 - precision_1: 0.6997 - val_loss: 0.6681 - val_accuracy: 0.5961 - val_sensitivity_at_specificity_1: 0.6279 - val_specificity_at_sensitivity_1: 0.6128 - val_recall_1: 0.9262 - val_precision_1: 0.5566\n",
            "Epoch 317/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4362 - accuracy: 0.7828 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8385 - recall_1: 0.9509 - precision_1: 0.7158\n",
            "Epoch 317: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.4362 - accuracy: 0.7828 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8385 - recall_1: 0.9509 - precision_1: 0.7158 - val_loss: 0.6784 - val_accuracy: 0.5930 - val_sensitivity_at_specificity_1: 0.7108 - val_specificity_at_sensitivity_1: 0.6233 - val_recall_1: 0.9855 - val_precision_1: 0.5437\n",
            "Epoch 318/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4250 - accuracy: 0.7887 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8411 - recall_1: 0.9891 - precision_1: 0.7075\n",
            "Epoch 318: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.4250 - accuracy: 0.7887 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8411 - recall_1: 0.9891 - precision_1: 0.7075 - val_loss: 0.6707 - val_accuracy: 0.6031 - val_sensitivity_at_specificity_1: 0.6900 - val_specificity_at_sensitivity_1: 0.6222 - val_recall_1: 0.9954 - val_precision_1: 0.5647\n",
            "Epoch 319/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4229 - accuracy: 0.7969 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8456 - recall_1: 0.9915 - precision_1: 0.7164\n",
            "Epoch 319: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.4229 - accuracy: 0.7969 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8456 - recall_1: 0.9915 - precision_1: 0.7164 - val_loss: 0.6391 - val_accuracy: 0.6281 - val_sensitivity_at_specificity_1: 0.7492 - val_specificity_at_sensitivity_1: 0.6803 - val_recall_1: 0.9875 - val_precision_1: 0.5753\n",
            "Epoch 320/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4405 - accuracy: 0.7684 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8319 - recall_1: 0.9596 - precision_1: 0.6865\n",
            "Epoch 320: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.4405 - accuracy: 0.7684 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8319 - recall_1: 0.9596 - precision_1: 0.6865 - val_loss: 0.6394 - val_accuracy: 0.6242 - val_sensitivity_at_specificity_1: 0.7075 - val_specificity_at_sensitivity_1: 0.6396 - val_recall_1: 0.9464 - val_precision_1: 0.5808\n",
            "Epoch 321/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4381 - accuracy: 0.7770 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8367 - recall_1: 0.9584 - precision_1: 0.7021\n",
            "Epoch 321: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.4381 - accuracy: 0.7770 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8367 - recall_1: 0.9584 - precision_1: 0.7021 - val_loss: 0.6592 - val_accuracy: 0.6164 - val_sensitivity_at_specificity_1: 0.6043 - val_specificity_at_sensitivity_1: 0.5618 - val_recall_1: 0.9559 - val_precision_1: 0.5761\n",
            "Epoch 322/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4394 - accuracy: 0.7715 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8398 - recall_1: 0.9709 - precision_1: 0.6863\n",
            "Epoch 322: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.4394 - accuracy: 0.7715 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8398 - recall_1: 0.9709 - precision_1: 0.6863 - val_loss: 0.6572 - val_accuracy: 0.6086 - val_sensitivity_at_specificity_1: 0.6697 - val_specificity_at_sensitivity_1: 0.6533 - val_recall_1: 0.9802 - val_precision_1: 0.5689\n",
            "Epoch 323/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4399 - accuracy: 0.7738 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8474 - recall_1: 0.9485 - precision_1: 0.7069\n",
            "Epoch 323: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.4399 - accuracy: 0.7738 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8474 - recall_1: 0.9485 - precision_1: 0.7069 - val_loss: 0.6609 - val_accuracy: 0.6148 - val_sensitivity_at_specificity_1: 0.7147 - val_specificity_at_sensitivity_1: 0.6497 - val_recall_1: 0.9739 - val_precision_1: 0.5716\n",
            "Epoch 324/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4420 - accuracy: 0.7801 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8283 - recall_1: 0.9693 - precision_1: 0.7070\n",
            "Epoch 324: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.4420 - accuracy: 0.7801 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8283 - recall_1: 0.9693 - precision_1: 0.7070 - val_loss: 0.7018 - val_accuracy: 0.5922 - val_sensitivity_at_specificity_1: 0.6992 - val_specificity_at_sensitivity_1: 0.6248 - val_recall_1: 0.9795 - val_precision_1: 0.5500\n",
            "Epoch 325/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4470 - accuracy: 0.7758 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8263 - recall_1: 0.9676 - precision_1: 0.6966\n",
            "Epoch 325: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.4470 - accuracy: 0.7758 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8263 - recall_1: 0.9676 - precision_1: 0.6966 - val_loss: 0.6574 - val_accuracy: 0.6125 - val_sensitivity_at_specificity_1: 0.7000 - val_specificity_at_sensitivity_1: 0.6419 - val_recall_1: 0.9682 - val_precision_1: 0.5736\n",
            "Epoch 326/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4237 - accuracy: 0.7848 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8555 - recall_1: 0.9491 - precision_1: 0.7066\n",
            "Epoch 326: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.4237 - accuracy: 0.7848 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8555 - recall_1: 0.9491 - precision_1: 0.7066 - val_loss: 0.6565 - val_accuracy: 0.6023 - val_sensitivity_at_specificity_1: 0.7136 - val_specificity_at_sensitivity_1: 0.6821 - val_recall_1: 0.9668 - val_precision_1: 0.5560\n",
            "Epoch 327/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4365 - accuracy: 0.7773 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8504 - recall_1: 0.9470 - precision_1: 0.7039\n",
            "Epoch 327: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 186ms/step - loss: 0.4365 - accuracy: 0.7773 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8504 - recall_1: 0.9470 - precision_1: 0.7039 - val_loss: 0.6639 - val_accuracy: 0.6016 - val_sensitivity_at_specificity_1: 0.6959 - val_specificity_at_sensitivity_1: 0.6227 - val_recall_1: 0.9268 - val_precision_1: 0.5564\n",
            "Epoch 328/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4243 - accuracy: 0.7891 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8642 - recall_1: 0.9463 - precision_1: 0.7275\n",
            "Epoch 328: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 178ms/step - loss: 0.4243 - accuracy: 0.7891 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8642 - recall_1: 0.9463 - precision_1: 0.7275 - val_loss: 0.6798 - val_accuracy: 0.5992 - val_sensitivity_at_specificity_1: 0.7043 - val_specificity_at_sensitivity_1: 0.6254 - val_recall_1: 0.9485 - val_precision_1: 0.5423\n",
            "Epoch 329/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4201 - accuracy: 0.7887 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8474 - recall_1: 0.9360 - precision_1: 0.7233\n",
            "Epoch 329: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 176ms/step - loss: 0.4201 - accuracy: 0.7887 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8474 - recall_1: 0.9360 - precision_1: 0.7233 - val_loss: 0.6815 - val_accuracy: 0.5984 - val_sensitivity_at_specificity_1: 0.6656 - val_specificity_at_sensitivity_1: 0.6000 - val_recall_1: 0.9406 - val_precision_1: 0.5584\n",
            "Epoch 330/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4412 - accuracy: 0.7805 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8233 - recall_1: 0.9709 - precision_1: 0.7014\n",
            "Epoch 330: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.4412 - accuracy: 0.7805 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8233 - recall_1: 0.9709 - precision_1: 0.7014 - val_loss: 0.6606 - val_accuracy: 0.6133 - val_sensitivity_at_specificity_1: 0.6948 - val_specificity_at_sensitivity_1: 0.6375 - val_recall_1: 0.9762 - val_precision_1: 0.5612\n",
            "Epoch 331/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4378 - accuracy: 0.7742 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8489 - recall_1: 0.9440 - precision_1: 0.6991\n",
            "Epoch 331: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.4378 - accuracy: 0.7742 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8489 - recall_1: 0.9440 - precision_1: 0.6991 - val_loss: 0.6492 - val_accuracy: 0.6148 - val_sensitivity_at_specificity_1: 0.7154 - val_specificity_at_sensitivity_1: 0.6134 - val_recall_1: 0.9214 - val_precision_1: 0.5695\n",
            "Epoch 332/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4353 - accuracy: 0.7859 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8383 - recall_1: 0.9388 - precision_1: 0.7179\n",
            "Epoch 332: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 0.4353 - accuracy: 0.7859 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8383 - recall_1: 0.9388 - precision_1: 0.7179 - val_loss: 0.6711 - val_accuracy: 0.6187 - val_sensitivity_at_specificity_1: 0.7105 - val_specificity_at_sensitivity_1: 0.6530 - val_recall_1: 0.9814 - val_precision_1: 0.5712\n",
            "Epoch 333/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4389 - accuracy: 0.7910 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8273 - recall_1: 0.9884 - precision_1: 0.7242\n",
            "Epoch 333: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.4389 - accuracy: 0.7910 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8273 - recall_1: 0.9884 - precision_1: 0.7242 - val_loss: 0.6483 - val_accuracy: 0.6328 - val_sensitivity_at_specificity_1: 0.7289 - val_specificity_at_sensitivity_1: 0.6314 - val_recall_1: 0.9644 - val_precision_1: 0.5934\n",
            "Epoch 334/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4297 - accuracy: 0.7855 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8426 - recall_1: 0.9472 - precision_1: 0.7174\n",
            "Epoch 334: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.4297 - accuracy: 0.7855 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8426 - recall_1: 0.9472 - precision_1: 0.7174 - val_loss: 0.6738 - val_accuracy: 0.6125 - val_sensitivity_at_specificity_1: 0.7123 - val_specificity_at_sensitivity_1: 0.6597 - val_recall_1: 0.9909 - val_precision_1: 0.5706\n",
            "Epoch 335/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4305 - accuracy: 0.7895 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8306 - recall_1: 0.9892 - precision_1: 0.7096\n",
            "Epoch 335: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.4305 - accuracy: 0.7895 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8306 - recall_1: 0.9892 - precision_1: 0.7096 - val_loss: 0.6717 - val_accuracy: 0.6078 - val_sensitivity_at_specificity_1: 0.6792 - val_specificity_at_sensitivity_1: 0.6162 - val_recall_1: 0.9828 - val_precision_1: 0.5612\n",
            "Epoch 336/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4138 - accuracy: 0.7977 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8580 - recall_1: 0.9684 - precision_1: 0.7192\n",
            "Epoch 336: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.4138 - accuracy: 0.7977 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8580 - recall_1: 0.9684 - precision_1: 0.7192 - val_loss: 0.6584 - val_accuracy: 0.6164 - val_sensitivity_at_specificity_1: 0.6940 - val_specificity_at_sensitivity_1: 0.6493 - val_recall_1: 0.9614 - val_precision_1: 0.5717\n",
            "Epoch 337/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4256 - accuracy: 0.7895 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8514 - recall_1: 0.9526 - precision_1: 0.7232\n",
            "Epoch 337: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 180ms/step - loss: 0.4256 - accuracy: 0.7895 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8514 - recall_1: 0.9526 - precision_1: 0.7232 - val_loss: 0.6896 - val_accuracy: 0.6016 - val_sensitivity_at_specificity_1: 0.7027 - val_specificity_at_sensitivity_1: 0.6303 - val_recall_1: 0.9828 - val_precision_1: 0.5572\n",
            "Epoch 338/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4081 - accuracy: 0.7998 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8649 - recall_1: 0.9663 - precision_1: 0.7218\n",
            "Epoch 338: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.4081 - accuracy: 0.7998 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8649 - recall_1: 0.9663 - precision_1: 0.7218 - val_loss: 0.6711 - val_accuracy: 0.5875 - val_sensitivity_at_specificity_1: 0.6884 - val_specificity_at_sensitivity_1: 0.6357 - val_recall_1: 0.8972 - val_precision_1: 0.5419\n",
            "Epoch 339/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4259 - accuracy: 0.7926 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8524 - recall_1: 0.9301 - precision_1: 0.7282\n",
            "Epoch 339: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 197ms/step - loss: 0.4259 - accuracy: 0.7926 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8524 - recall_1: 0.9301 - precision_1: 0.7282 - val_loss: 0.6765 - val_accuracy: 0.6094 - val_sensitivity_at_specificity_1: 0.7225 - val_specificity_at_sensitivity_1: 0.6447 - val_recall_1: 0.9585 - val_precision_1: 0.5591\n",
            "Epoch 340/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4463 - accuracy: 0.7727 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8254 - recall_1: 0.9457 - precision_1: 0.7009\n",
            "Epoch 340: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 174ms/step - loss: 0.4463 - accuracy: 0.7727 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8254 - recall_1: 0.9457 - precision_1: 0.7009 - val_loss: 0.6618 - val_accuracy: 0.6078 - val_sensitivity_at_specificity_1: 0.6853 - val_specificity_at_sensitivity_1: 0.6381 - val_recall_1: 0.9546 - val_precision_1: 0.5721\n",
            "Epoch 341/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4264 - accuracy: 0.7910 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8460 - recall_1: 0.9549 - precision_1: 0.7204\n",
            "Epoch 341: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.4264 - accuracy: 0.7910 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8460 - recall_1: 0.9549 - precision_1: 0.7204 - val_loss: 0.6589 - val_accuracy: 0.6086 - val_sensitivity_at_specificity_1: 0.6822 - val_specificity_at_sensitivity_1: 0.6299 - val_recall_1: 0.9581 - val_precision_1: 0.5659\n",
            "Epoch 342/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4343 - accuracy: 0.7742 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8498 - recall_1: 0.9369 - precision_1: 0.7046\n",
            "Epoch 342: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.4343 - accuracy: 0.7742 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8498 - recall_1: 0.9369 - precision_1: 0.7046 - val_loss: 0.6766 - val_accuracy: 0.6109 - val_sensitivity_at_specificity_1: 0.6453 - val_specificity_at_sensitivity_1: 0.6070 - val_recall_1: 0.9709 - val_precision_1: 0.5700\n",
            "Epoch 343/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4262 - accuracy: 0.7902 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8515 - recall_1: 0.9720 - precision_1: 0.7140\n",
            "Epoch 343: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.4262 - accuracy: 0.7902 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8515 - recall_1: 0.9720 - precision_1: 0.7140 - val_loss: 0.6702 - val_accuracy: 0.6164 - val_sensitivity_at_specificity_1: 0.6599 - val_specificity_at_sensitivity_1: 0.6228 - val_recall_1: 0.9704 - val_precision_1: 0.5686\n",
            "Epoch 344/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4383 - accuracy: 0.7844 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8091 - recall_1: 0.9613 - precision_1: 0.7122\n",
            "Epoch 344: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.4383 - accuracy: 0.7844 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8091 - recall_1: 0.9613 - precision_1: 0.7122 - val_loss: 0.6897 - val_accuracy: 0.6086 - val_sensitivity_at_specificity_1: 0.6567 - val_specificity_at_sensitivity_1: 0.6402 - val_recall_1: 1.0000 - val_precision_1: 0.5601\n",
            "Epoch 345/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4376 - accuracy: 0.7852 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8348 - recall_1: 0.9665 - precision_1: 0.7098\n",
            "Epoch 345: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.4376 - accuracy: 0.7852 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8348 - recall_1: 0.9665 - precision_1: 0.7098 - val_loss: 0.6297 - val_accuracy: 0.6031 - val_sensitivity_at_specificity_1: 0.7170 - val_specificity_at_sensitivity_1: 0.6277 - val_recall_1: 0.9212 - val_precision_1: 0.5552\n",
            "Epoch 346/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4367 - accuracy: 0.7887 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8435 - recall_1: 0.9792 - precision_1: 0.7125\n",
            "Epoch 346: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.4367 - accuracy: 0.7887 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8435 - recall_1: 0.9792 - precision_1: 0.7125 - val_loss: 0.6406 - val_accuracy: 0.6094 - val_sensitivity_at_specificity_1: 0.6929 - val_specificity_at_sensitivity_1: 0.6297 - val_recall_1: 0.9414 - val_precision_1: 0.5690\n",
            "Epoch 347/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4350 - accuracy: 0.7703 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8498 - recall_1: 0.9179 - precision_1: 0.7037\n",
            "Epoch 347: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.4350 - accuracy: 0.7703 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8498 - recall_1: 0.9179 - precision_1: 0.7037 - val_loss: 0.7001 - val_accuracy: 0.6047 - val_sensitivity_at_specificity_1: 0.6319 - val_specificity_at_sensitivity_1: 0.6306 - val_recall_1: 0.9985 - val_precision_1: 0.5631\n",
            "Epoch 348/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4337 - accuracy: 0.7840 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8403 - recall_1: 0.9921 - precision_1: 0.6978\n",
            "Epoch 348: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.4337 - accuracy: 0.7840 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8403 - recall_1: 0.9921 - precision_1: 0.6978 - val_loss: 0.6807 - val_accuracy: 0.5930 - val_sensitivity_at_specificity_1: 0.6757 - val_specificity_at_sensitivity_1: 0.5929 - val_recall_1: 0.9793 - val_precision_1: 0.5480\n",
            "Epoch 349/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4435 - accuracy: 0.7742 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8311 - recall_1: 0.9619 - precision_1: 0.7006\n",
            "Epoch 349: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.4435 - accuracy: 0.7742 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8311 - recall_1: 0.9619 - precision_1: 0.7006 - val_loss: 0.6521 - val_accuracy: 0.6227 - val_sensitivity_at_specificity_1: 0.6697 - val_specificity_at_sensitivity_1: 0.6238 - val_recall_1: 0.9459 - val_precision_1: 0.5850\n",
            "Epoch 350/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4159 - accuracy: 0.8023 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8542 - recall_1: 0.9695 - precision_1: 0.7319\n",
            "Epoch 350: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.4159 - accuracy: 0.8023 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8542 - recall_1: 0.9695 - precision_1: 0.7319 - val_loss: 0.6792 - val_accuracy: 0.6023 - val_sensitivity_at_specificity_1: 0.7203 - val_specificity_at_sensitivity_1: 0.6602 - val_recall_1: 0.9659 - val_precision_1: 0.5490\n",
            "Epoch 351/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4254 - accuracy: 0.7848 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8619 - recall_1: 0.9220 - precision_1: 0.7190\n",
            "Epoch 351: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 175ms/step - loss: 0.4254 - accuracy: 0.7848 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8619 - recall_1: 0.9220 - precision_1: 0.7190 - val_loss: 0.6833 - val_accuracy: 0.6180 - val_sensitivity_at_specificity_1: 0.6550 - val_specificity_at_sensitivity_1: 0.6032 - val_recall_1: 0.9817 - val_precision_1: 0.5741\n",
            "Epoch 352/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4347 - accuracy: 0.7828 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8373 - recall_1: 0.9685 - precision_1: 0.7097\n",
            "Epoch 352: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.4347 - accuracy: 0.7828 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8373 - recall_1: 0.9685 - precision_1: 0.7097 - val_loss: 0.6712 - val_accuracy: 0.6047 - val_sensitivity_at_specificity_1: 0.7200 - val_specificity_at_sensitivity_1: 0.6290 - val_recall_1: 0.9536 - val_precision_1: 0.5555\n",
            "Epoch 353/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4319 - accuracy: 0.7820 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8448 - recall_1: 0.9569 - precision_1: 0.7039\n",
            "Epoch 353: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 186ms/step - loss: 0.4319 - accuracy: 0.7820 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8448 - recall_1: 0.9569 - precision_1: 0.7039 - val_loss: 0.6435 - val_accuracy: 0.6234 - val_sensitivity_at_specificity_1: 0.7275 - val_specificity_at_sensitivity_1: 0.6196 - val_recall_1: 0.9772 - val_precision_1: 0.5789\n",
            "Epoch 354/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4285 - accuracy: 0.7906 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8307 - recall_1: 0.9798 - precision_1: 0.7115\n",
            "Epoch 354: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.4285 - accuracy: 0.7906 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8307 - recall_1: 0.9798 - precision_1: 0.7115 - val_loss: 0.6692 - val_accuracy: 0.6039 - val_sensitivity_at_specificity_1: 0.7019 - val_specificity_at_sensitivity_1: 0.6132 - val_recall_1: 0.9627 - val_precision_1: 0.5621\n",
            "Epoch 355/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4258 - accuracy: 0.7945 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8423 - recall_1: 0.9607 - precision_1: 0.7242\n",
            "Epoch 355: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.4258 - accuracy: 0.7945 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8423 - recall_1: 0.9607 - precision_1: 0.7242 - val_loss: 0.6633 - val_accuracy: 0.6180 - val_sensitivity_at_specificity_1: 0.6898 - val_specificity_at_sensitivity_1: 0.6329 - val_recall_1: 0.9660 - val_precision_1: 0.5727\n",
            "Epoch 356/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4309 - accuracy: 0.7875 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8276 - recall_1: 0.9705 - precision_1: 0.7122\n",
            "Epoch 356: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.4309 - accuracy: 0.7875 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8276 - recall_1: 0.9705 - precision_1: 0.7122 - val_loss: 0.6931 - val_accuracy: 0.5938 - val_sensitivity_at_specificity_1: 0.6899 - val_specificity_at_sensitivity_1: 0.6235 - val_recall_1: 0.9747 - val_precision_1: 0.5500\n",
            "Epoch 357/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4225 - accuracy: 0.7867 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8654 - recall_1: 0.9587 - precision_1: 0.7137\n",
            "Epoch 357: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.4225 - accuracy: 0.7867 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8654 - recall_1: 0.9587 - precision_1: 0.7137 - val_loss: 0.6793 - val_accuracy: 0.6031 - val_sensitivity_at_specificity_1: 0.6718 - val_specificity_at_sensitivity_1: 0.6420 - val_recall_1: 0.9768 - val_precision_1: 0.5614\n",
            "Epoch 358/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4170 - accuracy: 0.8020 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8592 - recall_1: 0.9769 - precision_1: 0.7263\n",
            "Epoch 358: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.4170 - accuracy: 0.8020 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8592 - recall_1: 0.9769 - precision_1: 0.7263 - val_loss: 0.6598 - val_accuracy: 0.6281 - val_sensitivity_at_specificity_1: 0.6960 - val_specificity_at_sensitivity_1: 0.6141 - val_recall_1: 0.9613 - val_precision_1: 0.5890\n",
            "Epoch 359/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4141 - accuracy: 0.7937 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8653 - recall_1: 0.9461 - precision_1: 0.7284\n",
            "Epoch 359: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.4141 - accuracy: 0.7937 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8653 - recall_1: 0.9461 - precision_1: 0.7284 - val_loss: 0.7066 - val_accuracy: 0.5922 - val_sensitivity_at_specificity_1: 0.6612 - val_specificity_at_sensitivity_1: 0.6205 - val_recall_1: 0.9457 - val_precision_1: 0.5404\n",
            "Epoch 360/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4496 - accuracy: 0.7711 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8429 - recall_1: 0.9600 - precision_1: 0.6957\n",
            "Epoch 360: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.4496 - accuracy: 0.7711 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8429 - recall_1: 0.9600 - precision_1: 0.6957 - val_loss: 0.6717 - val_accuracy: 0.5914 - val_sensitivity_at_specificity_1: 0.6882 - val_specificity_at_sensitivity_1: 0.6339 - val_recall_1: 0.9241 - val_precision_1: 0.5458\n",
            "Epoch 361/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4248 - accuracy: 0.7874 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8533 - recall_1: 0.9473 - precision_1: 0.7198\n",
            "Epoch 361: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.4248 - accuracy: 0.7874 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8533 - recall_1: 0.9473 - precision_1: 0.7198 - val_loss: 0.6647 - val_accuracy: 0.6203 - val_sensitivity_at_specificity_1: 0.7293 - val_specificity_at_sensitivity_1: 0.6715 - val_recall_1: 0.9805 - val_precision_1: 0.5796\n",
            "Epoch 362/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4403 - accuracy: 0.7711 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8386 - recall_1: 0.9509 - precision_1: 0.6884\n",
            "Epoch 362: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.4403 - accuracy: 0.7711 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8386 - recall_1: 0.9509 - precision_1: 0.6884 - val_loss: 0.6438 - val_accuracy: 0.6180 - val_sensitivity_at_specificity_1: 0.7247 - val_specificity_at_sensitivity_1: 0.6499 - val_recall_1: 0.9456 - val_precision_1: 0.5725\n",
            "Epoch 363/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4280 - accuracy: 0.7855 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8519 - recall_1: 0.9692 - precision_1: 0.7118\n",
            "Epoch 363: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.4280 - accuracy: 0.7855 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8519 - recall_1: 0.9692 - precision_1: 0.7118 - val_loss: 0.6618 - val_accuracy: 0.6148 - val_sensitivity_at_specificity_1: 0.7069 - val_specificity_at_sensitivity_1: 0.6417 - val_recall_1: 0.9639 - val_precision_1: 0.5668\n",
            "Epoch 364/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4339 - accuracy: 0.7875 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8261 - recall_1: 0.9585 - precision_1: 0.7179\n",
            "Epoch 364: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.4339 - accuracy: 0.7875 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8261 - recall_1: 0.9585 - precision_1: 0.7179 - val_loss: 0.6731 - val_accuracy: 0.6172 - val_sensitivity_at_specificity_1: 0.7166 - val_specificity_at_sensitivity_1: 0.6427 - val_recall_1: 0.9745 - val_precision_1: 0.5788\n",
            "Epoch 365/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4180 - accuracy: 0.7914 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8485 - recall_1: 0.9434 - precision_1: 0.7222\n",
            "Epoch 365: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.4180 - accuracy: 0.7914 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8485 - recall_1: 0.9434 - precision_1: 0.7222 - val_loss: 0.6786 - val_accuracy: 0.6133 - val_sensitivity_at_specificity_1: 0.7064 - val_specificity_at_sensitivity_1: 0.6166 - val_recall_1: 0.9924 - val_precision_1: 0.5698\n",
            "Epoch 366/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4249 - accuracy: 0.7832 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8606 - recall_1: 0.9498 - precision_1: 0.7117\n",
            "Epoch 366: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 175ms/step - loss: 0.4249 - accuracy: 0.7832 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8606 - recall_1: 0.9498 - precision_1: 0.7117 - val_loss: 0.6580 - val_accuracy: 0.6258 - val_sensitivity_at_specificity_1: 0.6321 - val_specificity_at_sensitivity_1: 0.6256 - val_recall_1: 0.9649 - val_precision_1: 0.5809\n",
            "Epoch 367/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4403 - accuracy: 0.7730 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8493 - recall_1: 0.9368 - precision_1: 0.7030\n",
            "Epoch 367: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.4403 - accuracy: 0.7730 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8493 - recall_1: 0.9368 - precision_1: 0.7030 - val_loss: 0.6980 - val_accuracy: 0.5820 - val_sensitivity_at_specificity_1: 0.6822 - val_specificity_at_sensitivity_1: 0.6141 - val_recall_1: 0.9451 - val_precision_1: 0.5308\n",
            "Epoch 368/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4192 - accuracy: 0.7977 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8598 - recall_1: 0.9557 - precision_1: 0.7351\n",
            "Epoch 368: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.4192 - accuracy: 0.7977 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8598 - recall_1: 0.9557 - precision_1: 0.7351 - val_loss: 0.6884 - val_accuracy: 0.6195 - val_sensitivity_at_specificity_1: 0.7271 - val_specificity_at_sensitivity_1: 0.6394 - val_recall_1: 0.9798 - val_precision_1: 0.5714\n",
            "Epoch 369/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4292 - accuracy: 0.7891 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8517 - recall_1: 0.9497 - precision_1: 0.7173\n",
            "Epoch 369: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.4292 - accuracy: 0.7891 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8517 - recall_1: 0.9497 - precision_1: 0.7173 - val_loss: 0.6387 - val_accuracy: 0.6266 - val_sensitivity_at_specificity_1: 0.7325 - val_specificity_at_sensitivity_1: 0.6608 - val_recall_1: 0.9377 - val_precision_1: 0.5854\n",
            "Epoch 370/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4283 - accuracy: 0.7848 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8691 - recall_1: 0.9386 - precision_1: 0.7129\n",
            "Epoch 370: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.4283 - accuracy: 0.7848 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8691 - recall_1: 0.9386 - precision_1: 0.7129 - val_loss: 0.6818 - val_accuracy: 0.6187 - val_sensitivity_at_specificity_1: 0.6895 - val_specificity_at_sensitivity_1: 0.6260 - val_recall_1: 0.9906 - val_precision_1: 0.5685\n",
            "Epoch 371/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4267 - accuracy: 0.7863 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8649 - recall_1: 0.9573 - precision_1: 0.7107\n",
            "Epoch 371: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.4267 - accuracy: 0.7863 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8649 - recall_1: 0.9573 - precision_1: 0.7107 - val_loss: 0.6673 - val_accuracy: 0.6195 - val_sensitivity_at_specificity_1: 0.7219 - val_specificity_at_sensitivity_1: 0.6438 - val_recall_1: 0.9766 - val_precision_1: 0.5697\n",
            "Epoch 372/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4259 - accuracy: 0.7898 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8561 - recall_1: 0.9480 - precision_1: 0.7216\n",
            "Epoch 372: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.4259 - accuracy: 0.7898 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8561 - recall_1: 0.9480 - precision_1: 0.7216 - val_loss: 0.6781 - val_accuracy: 0.6109 - val_sensitivity_at_specificity_1: 0.6987 - val_specificity_at_sensitivity_1: 0.6223 - val_recall_1: 0.9527 - val_precision_1: 0.5634\n",
            "Epoch 373/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4291 - accuracy: 0.7875 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8528 - recall_1: 0.9446 - precision_1: 0.7254\n",
            "Epoch 373: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.4291 - accuracy: 0.7875 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8528 - recall_1: 0.9446 - precision_1: 0.7254 - val_loss: 0.6938 - val_accuracy: 0.6117 - val_sensitivity_at_specificity_1: 0.6852 - val_specificity_at_sensitivity_1: 0.6203 - val_recall_1: 0.9583 - val_precision_1: 0.5692\n",
            "Epoch 374/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4403 - accuracy: 0.7766 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8313 - recall_1: 0.9381 - precision_1: 0.7022\n",
            "Epoch 374: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.4403 - accuracy: 0.7766 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8313 - recall_1: 0.9381 - precision_1: 0.7022 - val_loss: 0.6450 - val_accuracy: 0.6141 - val_sensitivity_at_specificity_1: 0.7387 - val_specificity_at_sensitivity_1: 0.6727 - val_recall_1: 0.9081 - val_precision_1: 0.5630\n",
            "Epoch 375/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4131 - accuracy: 0.8034 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8495 - recall_1: 0.9537 - precision_1: 0.7400\n",
            "Epoch 375: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.4137 - accuracy: 0.8036 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8452 - recall_1: 0.9558 - precision_1: 0.7400 - val_loss: 0.6976 - val_accuracy: 0.5992 - val_sensitivity_at_specificity_1: 0.7324 - val_specificity_at_sensitivity_1: 0.6692 - val_recall_1: 0.9920 - val_precision_1: 0.5492\n",
            "Epoch 376/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4164 - accuracy: 0.7879 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8784 - recall_1: 0.9617 - precision_1: 0.7087\n",
            "Epoch 376: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.4164 - accuracy: 0.7879 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8784 - recall_1: 0.9617 - precision_1: 0.7087 - val_loss: 0.6746 - val_accuracy: 0.6008 - val_sensitivity_at_specificity_1: 0.6834 - val_specificity_at_sensitivity_1: 0.6542 - val_recall_1: 0.9404 - val_precision_1: 0.5592\n",
            "Epoch 377/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4203 - accuracy: 0.7957 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8651 - recall_1: 0.9346 - precision_1: 0.7296\n",
            "Epoch 377: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.4203 - accuracy: 0.7957 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8651 - recall_1: 0.9346 - precision_1: 0.7296 - val_loss: 0.6977 - val_accuracy: 0.5961 - val_sensitivity_at_specificity_1: 0.6927 - val_specificity_at_sensitivity_1: 0.6273 - val_recall_1: 0.9650 - val_precision_1: 0.5504\n",
            "Epoch 378/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4216 - accuracy: 0.7915 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8480 - recall_1: 0.9645 - precision_1: 0.7129\n",
            "Epoch 378: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.4216 - accuracy: 0.7915 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8480 - recall_1: 0.9645 - precision_1: 0.7129 - val_loss: 0.6813 - val_accuracy: 0.5930 - val_sensitivity_at_specificity_1: 0.6902 - val_specificity_at_sensitivity_1: 0.6058 - val_recall_1: 0.9599 - val_precision_1: 0.5466\n",
            "Epoch 379/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4284 - accuracy: 0.7870 - sensitivity_at_specificity_1: 0.9992 - specificity_at_sensitivity_1: 0.8570 - recall_1: 0.9647 - precision_1: 0.7093\n",
            "Epoch 379: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.4284 - accuracy: 0.7870 - sensitivity_at_specificity_1: 0.9992 - specificity_at_sensitivity_1: 0.8570 - recall_1: 0.9647 - precision_1: 0.7093 - val_loss: 0.6773 - val_accuracy: 0.6008 - val_sensitivity_at_specificity_1: 0.6502 - val_specificity_at_sensitivity_1: 0.6120 - val_recall_1: 0.9752 - val_precision_1: 0.5600\n",
            "Epoch 380/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4339 - accuracy: 0.7785 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8535 - recall_1: 0.9472 - precision_1: 0.7064\n",
            "Epoch 380: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.4339 - accuracy: 0.7785 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8535 - recall_1: 0.9472 - precision_1: 0.7064 - val_loss: 0.6726 - val_accuracy: 0.6000 - val_sensitivity_at_specificity_1: 0.6739 - val_specificity_at_sensitivity_1: 0.6335 - val_recall_1: 0.9258 - val_precision_1: 0.5635\n",
            "Epoch 381/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4199 - accuracy: 0.7937 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8687 - recall_1: 0.9516 - precision_1: 0.7233\n",
            "Epoch 381: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.4199 - accuracy: 0.7937 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8687 - recall_1: 0.9516 - precision_1: 0.7233 - val_loss: 0.6838 - val_accuracy: 0.6102 - val_sensitivity_at_specificity_1: 0.7005 - val_specificity_at_sensitivity_1: 0.6088 - val_recall_1: 0.9828 - val_precision_1: 0.5635\n",
            "Epoch 382/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4286 - accuracy: 0.7801 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8347 - recall_1: 0.9558 - precision_1: 0.6967\n",
            "Epoch 382: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.4286 - accuracy: 0.7801 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8347 - recall_1: 0.9558 - precision_1: 0.6967 - val_loss: 0.6640 - val_accuracy: 0.6180 - val_sensitivity_at_specificity_1: 0.6612 - val_specificity_at_sensitivity_1: 0.6052 - val_recall_1: 0.9835 - val_precision_1: 0.5785\n",
            "Epoch 383/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4359 - accuracy: 0.7840 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8438 - recall_1: 0.9586 - precision_1: 0.7105\n",
            "Epoch 383: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 174ms/step - loss: 0.4359 - accuracy: 0.7840 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8438 - recall_1: 0.9586 - precision_1: 0.7105 - val_loss: 0.6510 - val_accuracy: 0.6242 - val_sensitivity_at_specificity_1: 0.7030 - val_specificity_at_sensitivity_1: 0.6355 - val_recall_1: 0.9227 - val_precision_1: 0.5861\n",
            "Epoch 384/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4155 - accuracy: 0.7973 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8513 - recall_1: 0.9509 - precision_1: 0.7278\n",
            "Epoch 384: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.4155 - accuracy: 0.7973 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8513 - recall_1: 0.9509 - precision_1: 0.7278 - val_loss: 0.6899 - val_accuracy: 0.6187 - val_sensitivity_at_specificity_1: 0.6929 - val_specificity_at_sensitivity_1: 0.6171 - val_recall_1: 0.9780 - val_precision_1: 0.5671\n",
            "Epoch 385/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4307 - accuracy: 0.7836 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8632 - recall_1: 0.9404 - precision_1: 0.7120\n",
            "Epoch 385: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.4307 - accuracy: 0.7836 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8632 - recall_1: 0.9404 - precision_1: 0.7120 - val_loss: 0.6864 - val_accuracy: 0.5922 - val_sensitivity_at_specificity_1: 0.6372 - val_specificity_at_sensitivity_1: 0.6195 - val_recall_1: 0.9599 - val_precision_1: 0.5461\n",
            "Epoch 386/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4255 - accuracy: 0.7957 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8403 - recall_1: 0.9792 - precision_1: 0.7188\n",
            "Epoch 386: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.4255 - accuracy: 0.7957 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8403 - recall_1: 0.9792 - precision_1: 0.7188 - val_loss: 0.6664 - val_accuracy: 0.6219 - val_sensitivity_at_specificity_1: 0.7158 - val_specificity_at_sensitivity_1: 0.6602 - val_recall_1: 0.9880 - val_precision_1: 0.5799\n",
            "Epoch 387/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4288 - accuracy: 0.7883 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8652 - recall_1: 0.9553 - precision_1: 0.7232\n",
            "Epoch 387: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.4288 - accuracy: 0.7883 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8652 - recall_1: 0.9553 - precision_1: 0.7232 - val_loss: 0.6770 - val_accuracy: 0.6102 - val_sensitivity_at_specificity_1: 0.7036 - val_specificity_at_sensitivity_1: 0.6379 - val_recall_1: 0.9556 - val_precision_1: 0.5615\n",
            "Epoch 388/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4282 - accuracy: 0.7859 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8493 - recall_1: 0.9384 - precision_1: 0.7165\n",
            "Epoch 388: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.4282 - accuracy: 0.7859 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8493 - recall_1: 0.9384 - precision_1: 0.7165 - val_loss: 0.6719 - val_accuracy: 0.5953 - val_sensitivity_at_specificity_1: 0.6615 - val_specificity_at_sensitivity_1: 0.6103 - val_recall_1: 0.8955 - val_precision_1: 0.5600\n",
            "Epoch 389/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4176 - accuracy: 0.7969 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8506 - recall_1: 0.9413 - precision_1: 0.7330\n",
            "Epoch 389: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.4176 - accuracy: 0.7969 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8506 - recall_1: 0.9413 - precision_1: 0.7330 - val_loss: 0.7406 - val_accuracy: 0.5930 - val_sensitivity_at_specificity_1: 0.6720 - val_specificity_at_sensitivity_1: 0.6231 - val_recall_1: 0.9952 - val_precision_1: 0.5444\n",
            "Epoch 390/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4222 - accuracy: 0.7926 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8561 - recall_1: 0.9625 - precision_1: 0.7185\n",
            "Epoch 390: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.4222 - accuracy: 0.7926 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8561 - recall_1: 0.9625 - precision_1: 0.7185 - val_loss: 0.6840 - val_accuracy: 0.5992 - val_sensitivity_at_specificity_1: 0.6186 - val_specificity_at_sensitivity_1: 0.5795 - val_recall_1: 0.9550 - val_precision_1: 0.5600\n",
            "Epoch 391/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4217 - accuracy: 0.7910 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8594 - recall_1: 0.9613 - precision_1: 0.7146\n",
            "Epoch 391: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.4217 - accuracy: 0.7910 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8594 - recall_1: 0.9613 - precision_1: 0.7146 - val_loss: 0.6608 - val_accuracy: 0.6281 - val_sensitivity_at_specificity_1: 0.6991 - val_specificity_at_sensitivity_1: 0.6431 - val_recall_1: 0.9726 - val_precision_1: 0.5829\n",
            "Epoch 392/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4242 - accuracy: 0.7924 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8537 - recall_1: 0.9442 - precision_1: 0.7164\n",
            "Epoch 392: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.4242 - accuracy: 0.7924 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8537 - recall_1: 0.9442 - precision_1: 0.7164 - val_loss: 0.6782 - val_accuracy: 0.5859 - val_sensitivity_at_specificity_1: 0.6657 - val_specificity_at_sensitivity_1: 0.6174 - val_recall_1: 0.9073 - val_precision_1: 0.5600\n",
            "Epoch 393/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4342 - accuracy: 0.7867 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8473 - recall_1: 0.9363 - precision_1: 0.7249\n",
            "Epoch 393: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.4342 - accuracy: 0.7867 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8473 - recall_1: 0.9363 - precision_1: 0.7249 - val_loss: 0.6746 - val_accuracy: 0.6281 - val_sensitivity_at_specificity_1: 0.7145 - val_specificity_at_sensitivity_1: 0.6384 - val_recall_1: 0.9725 - val_precision_1: 0.5817\n",
            "Epoch 394/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4205 - accuracy: 0.7977 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8576 - recall_1: 0.9447 - precision_1: 0.7340\n",
            "Epoch 394: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.4205 - accuracy: 0.7977 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8576 - recall_1: 0.9447 - precision_1: 0.7340 - val_loss: 0.6936 - val_accuracy: 0.5992 - val_sensitivity_at_specificity_1: 0.7192 - val_specificity_at_sensitivity_1: 0.6625 - val_recall_1: 0.9669 - val_precision_1: 0.5548\n",
            "Epoch 395/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4283 - accuracy: 0.7809 - sensitivity_at_specificity_1: 0.9992 - specificity_at_sensitivity_1: 0.8502 - recall_1: 0.9584 - precision_1: 0.7105\n",
            "Epoch 395: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.4283 - accuracy: 0.7809 - sensitivity_at_specificity_1: 0.9992 - specificity_at_sensitivity_1: 0.8502 - recall_1: 0.9584 - precision_1: 0.7105 - val_loss: 0.6742 - val_accuracy: 0.6000 - val_sensitivity_at_specificity_1: 0.7395 - val_specificity_at_sensitivity_1: 0.6511 - val_recall_1: 0.9806 - val_precision_1: 0.5479\n",
            "Epoch 396/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4221 - accuracy: 0.7937 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8627 - recall_1: 0.9619 - precision_1: 0.7207\n",
            "Epoch 396: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.4221 - accuracy: 0.7937 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8627 - recall_1: 0.9619 - precision_1: 0.7207 - val_loss: 0.7032 - val_accuracy: 0.6031 - val_sensitivity_at_specificity_1: 0.6889 - val_specificity_at_sensitivity_1: 0.6292 - val_recall_1: 0.9810 - val_precision_1: 0.5548\n",
            "Epoch 397/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4305 - accuracy: 0.7855 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8300 - recall_1: 0.9513 - precision_1: 0.7130\n",
            "Epoch 397: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.4305 - accuracy: 0.7855 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8300 - recall_1: 0.9513 - precision_1: 0.7130 - val_loss: 0.6749 - val_accuracy: 0.5977 - val_sensitivity_at_specificity_1: 0.6785 - val_specificity_at_sensitivity_1: 0.6248 - val_recall_1: 0.9661 - val_precision_1: 0.5476\n",
            "Epoch 398/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4344 - accuracy: 0.7785 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8491 - recall_1: 0.9783 - precision_1: 0.7004\n",
            "Epoch 398: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.4344 - accuracy: 0.7785 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8491 - recall_1: 0.9783 - precision_1: 0.7004 - val_loss: 0.6886 - val_accuracy: 0.5938 - val_sensitivity_at_specificity_1: 0.6534 - val_specificity_at_sensitivity_1: 0.6223 - val_recall_1: 0.9776 - val_precision_1: 0.5474\n",
            "Epoch 399/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4223 - accuracy: 0.7852 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8715 - recall_1: 0.9734 - precision_1: 0.7065\n",
            "Epoch 399: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 174ms/step - loss: 0.4223 - accuracy: 0.7852 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8715 - recall_1: 0.9734 - precision_1: 0.7065 - val_loss: 0.7120 - val_accuracy: 0.5844 - val_sensitivity_at_specificity_1: 0.6448 - val_specificity_at_sensitivity_1: 0.6069 - val_recall_1: 0.9705 - val_precision_1: 0.5357\n",
            "Epoch 400/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4349 - accuracy: 0.7828 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8385 - recall_1: 0.9365 - precision_1: 0.7126\n",
            "Epoch 400: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.4349 - accuracy: 0.7828 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8385 - recall_1: 0.9365 - precision_1: 0.7126 - val_loss: 0.7006 - val_accuracy: 0.5781 - val_sensitivity_at_specificity_1: 0.6386 - val_specificity_at_sensitivity_1: 0.6169 - val_recall_1: 0.9287 - val_precision_1: 0.5360\n",
            "Epoch 401/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4235 - accuracy: 0.7875 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8562 - recall_1: 0.9208 - precision_1: 0.7162\n",
            "Epoch 401: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.4235 - accuracy: 0.7875 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8562 - recall_1: 0.9208 - precision_1: 0.7162 - val_loss: 0.6796 - val_accuracy: 0.6016 - val_sensitivity_at_specificity_1: 0.6985 - val_specificity_at_sensitivity_1: 0.6315 - val_recall_1: 0.9605 - val_precision_1: 0.5454\n",
            "Epoch 402/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4163 - accuracy: 0.7941 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8602 - recall_1: 0.9567 - precision_1: 0.7244\n",
            "Epoch 402: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.4163 - accuracy: 0.7941 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8602 - recall_1: 0.9567 - precision_1: 0.7244 - val_loss: 0.7090 - val_accuracy: 0.5852 - val_sensitivity_at_specificity_1: 0.6990 - val_specificity_at_sensitivity_1: 0.6495 - val_recall_1: 0.9773 - val_precision_1: 0.5388\n",
            "Epoch 403/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4199 - accuracy: 0.7973 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8504 - recall_1: 0.9636 - precision_1: 0.7293\n",
            "Epoch 403: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.4199 - accuracy: 0.7973 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8504 - recall_1: 0.9636 - precision_1: 0.7293 - val_loss: 0.6946 - val_accuracy: 0.6000 - val_sensitivity_at_specificity_1: 0.6355 - val_specificity_at_sensitivity_1: 0.6288 - val_recall_1: 0.9823 - val_precision_1: 0.5486\n",
            "Epoch 404/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4267 - accuracy: 0.7848 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8653 - recall_1: 0.9448 - precision_1: 0.7135\n",
            "Epoch 404: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.4267 - accuracy: 0.7848 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8653 - recall_1: 0.9448 - precision_1: 0.7135 - val_loss: 0.6380 - val_accuracy: 0.6242 - val_sensitivity_at_specificity_1: 0.7238 - val_specificity_at_sensitivity_1: 0.6451 - val_recall_1: 0.9261 - val_precision_1: 0.5926\n",
            "Epoch 405/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4236 - accuracy: 0.7855 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8607 - recall_1: 0.9205 - precision_1: 0.7155\n",
            "Epoch 405: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.4236 - accuracy: 0.7855 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8607 - recall_1: 0.9205 - precision_1: 0.7155 - val_loss: 0.6914 - val_accuracy: 0.6109 - val_sensitivity_at_specificity_1: 0.6419 - val_specificity_at_sensitivity_1: 0.5780 - val_recall_1: 0.9659 - val_precision_1: 0.5669\n",
            "Epoch 406/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4252 - accuracy: 0.7934 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8495 - recall_1: 0.9491 - precision_1: 0.7233\n",
            "Epoch 406: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.4252 - accuracy: 0.7934 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8495 - recall_1: 0.9491 - precision_1: 0.7233 - val_loss: 0.6933 - val_accuracy: 0.5906 - val_sensitivity_at_specificity_1: 0.6470 - val_specificity_at_sensitivity_1: 0.6162 - val_recall_1: 0.9473 - val_precision_1: 0.5470\n",
            "Epoch 407/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4232 - accuracy: 0.7926 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8612 - recall_1: 0.9466 - precision_1: 0.7258\n",
            "Epoch 407: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 174ms/step - loss: 0.4232 - accuracy: 0.7926 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8612 - recall_1: 0.9466 - precision_1: 0.7258 - val_loss: 0.6923 - val_accuracy: 0.6102 - val_sensitivity_at_specificity_1: 0.6831 - val_specificity_at_sensitivity_1: 0.6556 - val_recall_1: 0.9723 - val_precision_1: 0.5678\n",
            "Epoch 408/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4290 - accuracy: 0.7848 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8574 - recall_1: 0.9583 - precision_1: 0.7096\n",
            "Epoch 408: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.4290 - accuracy: 0.7848 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8574 - recall_1: 0.9583 - precision_1: 0.7096 - val_loss: 0.6530 - val_accuracy: 0.6148 - val_sensitivity_at_specificity_1: 0.7288 - val_specificity_at_sensitivity_1: 0.6688 - val_recall_1: 0.9569 - val_precision_1: 0.5718\n",
            "Epoch 409/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4284 - accuracy: 0.7867 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8547 - recall_1: 0.9500 - precision_1: 0.7123\n",
            "Epoch 409: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 175ms/step - loss: 0.4284 - accuracy: 0.7867 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8547 - recall_1: 0.9500 - precision_1: 0.7123 - val_loss: 0.6629 - val_accuracy: 0.6266 - val_sensitivity_at_specificity_1: 0.7072 - val_specificity_at_sensitivity_1: 0.6529 - val_recall_1: 0.9661 - val_precision_1: 0.5789\n",
            "Epoch 410/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4150 - accuracy: 0.7980 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8654 - recall_1: 0.9444 - precision_1: 0.7362\n",
            "Epoch 410: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.4150 - accuracy: 0.7980 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8654 - recall_1: 0.9444 - precision_1: 0.7362 - val_loss: 0.7046 - val_accuracy: 0.6102 - val_sensitivity_at_specificity_1: 0.6481 - val_specificity_at_sensitivity_1: 0.5951 - val_recall_1: 0.9697 - val_precision_1: 0.5592\n",
            "Epoch 411/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4335 - accuracy: 0.7902 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8468 - recall_1: 0.9385 - precision_1: 0.7275\n",
            "Epoch 411: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.4335 - accuracy: 0.7902 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8468 - recall_1: 0.9385 - precision_1: 0.7275 - val_loss: 0.7015 - val_accuracy: 0.6141 - val_sensitivity_at_specificity_1: 0.7005 - val_specificity_at_sensitivity_1: 0.6137 - val_recall_1: 0.9708 - val_precision_1: 0.5709\n",
            "Epoch 412/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4346 - accuracy: 0.7863 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8292 - recall_1: 0.9602 - precision_1: 0.7171\n",
            "Epoch 412: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.4346 - accuracy: 0.7863 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8292 - recall_1: 0.9602 - precision_1: 0.7171 - val_loss: 0.6864 - val_accuracy: 0.6156 - val_sensitivity_at_specificity_1: 0.6998 - val_specificity_at_sensitivity_1: 0.5933 - val_recall_1: 0.9770 - val_precision_1: 0.5722\n",
            "Epoch 413/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4342 - accuracy: 0.7781 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8420 - recall_1: 0.9702 - precision_1: 0.7001\n",
            "Epoch 413: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.4342 - accuracy: 0.7781 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8420 - recall_1: 0.9702 - precision_1: 0.7001 - val_loss: 0.6788 - val_accuracy: 0.6141 - val_sensitivity_at_specificity_1: 0.6761 - val_specificity_at_sensitivity_1: 0.5978 - val_recall_1: 0.9701 - val_precision_1: 0.5650\n",
            "Epoch 414/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4321 - accuracy: 0.7871 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8504 - recall_1: 0.9252 - precision_1: 0.7306\n",
            "Epoch 414: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.4321 - accuracy: 0.7871 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8504 - recall_1: 0.9252 - precision_1: 0.7306 - val_loss: 0.6909 - val_accuracy: 0.6141 - val_sensitivity_at_specificity_1: 0.6646 - val_specificity_at_sensitivity_1: 0.5990 - val_recall_1: 0.9803 - val_precision_1: 0.5732\n",
            "Epoch 415/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4192 - accuracy: 0.7922 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8481 - recall_1: 0.9577 - precision_1: 0.7188\n",
            "Epoch 415: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.4192 - accuracy: 0.7922 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8481 - recall_1: 0.9577 - precision_1: 0.7188 - val_loss: 0.6678 - val_accuracy: 0.6148 - val_sensitivity_at_specificity_1: 0.7227 - val_specificity_at_sensitivity_1: 0.6498 - val_recall_1: 0.9445 - val_precision_1: 0.5729\n",
            "Epoch 416/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4344 - accuracy: 0.7852 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8442 - recall_1: 0.9341 - precision_1: 0.7214\n",
            "Epoch 416: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.4344 - accuracy: 0.7852 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8442 - recall_1: 0.9341 - precision_1: 0.7214 - val_loss: 0.6512 - val_accuracy: 0.6320 - val_sensitivity_at_specificity_1: 0.7359 - val_specificity_at_sensitivity_1: 0.6608 - val_recall_1: 0.9756 - val_precision_1: 0.5841\n",
            "Epoch 417/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4237 - accuracy: 0.7902 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8602 - recall_1: 0.9500 - precision_1: 0.7237\n",
            "Epoch 417: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.4237 - accuracy: 0.7902 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8602 - recall_1: 0.9500 - precision_1: 0.7237 - val_loss: 0.6860 - val_accuracy: 0.6031 - val_sensitivity_at_specificity_1: 0.6682 - val_specificity_at_sensitivity_1: 0.6304 - val_recall_1: 0.9623 - val_precision_1: 0.5584\n",
            "Epoch 418/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4157 - accuracy: 0.7980 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8591 - recall_1: 0.9491 - precision_1: 0.7319\n",
            "Epoch 418: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.4157 - accuracy: 0.7980 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8591 - recall_1: 0.9491 - precision_1: 0.7319 - val_loss: 0.6902 - val_accuracy: 0.6172 - val_sensitivity_at_specificity_1: 0.6835 - val_specificity_at_sensitivity_1: 0.6182 - val_recall_1: 0.9847 - val_precision_1: 0.5730\n",
            "Epoch 419/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4198 - accuracy: 0.7937 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8670 - recall_1: 0.9455 - precision_1: 0.7230\n",
            "Epoch 419: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.4198 - accuracy: 0.7937 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8670 - recall_1: 0.9455 - precision_1: 0.7230 - val_loss: 0.6816 - val_accuracy: 0.5969 - val_sensitivity_at_specificity_1: 0.7110 - val_specificity_at_sensitivity_1: 0.6393 - val_recall_1: 0.9672 - val_precision_1: 0.5429\n",
            "Epoch 420/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4024 - accuracy: 0.8121 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8566 - recall_1: 0.9579 - precision_1: 0.7423\n",
            "Epoch 420: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.4024 - accuracy: 0.8121 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8566 - recall_1: 0.9579 - precision_1: 0.7423 - val_loss: 0.6647 - val_accuracy: 0.6406 - val_sensitivity_at_specificity_1: 0.6820 - val_specificity_at_sensitivity_1: 0.6376 - val_recall_1: 0.9584 - val_precision_1: 0.5989\n",
            "Epoch 421/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4242 - accuracy: 0.7914 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8492 - recall_1: 0.9570 - precision_1: 0.7189\n",
            "Epoch 421: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.4242 - accuracy: 0.7914 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8492 - recall_1: 0.9570 - precision_1: 0.7189 - val_loss: 0.6885 - val_accuracy: 0.6000 - val_sensitivity_at_specificity_1: 0.7108 - val_specificity_at_sensitivity_1: 0.6657 - val_recall_1: 0.9677 - val_precision_1: 0.5490\n",
            "Epoch 422/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4278 - accuracy: 0.7941 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8575 - recall_1: 0.9507 - precision_1: 0.7306\n",
            "Epoch 422: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 188ms/step - loss: 0.4278 - accuracy: 0.7941 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8575 - recall_1: 0.9507 - precision_1: 0.7306 - val_loss: 0.7073 - val_accuracy: 0.5883 - val_sensitivity_at_specificity_1: 0.6415 - val_specificity_at_sensitivity_1: 0.5957 - val_recall_1: 0.9646 - val_precision_1: 0.5430\n",
            "Epoch 423/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4330 - accuracy: 0.7828 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8433 - recall_1: 0.9426 - precision_1: 0.7161\n",
            "Epoch 423: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.4330 - accuracy: 0.7828 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8433 - recall_1: 0.9426 - precision_1: 0.7161 - val_loss: 0.6894 - val_accuracy: 0.6187 - val_sensitivity_at_specificity_1: 0.7261 - val_specificity_at_sensitivity_1: 0.6459 - val_recall_1: 0.9750 - val_precision_1: 0.5689\n",
            "Epoch 424/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4243 - accuracy: 0.7949 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8460 - recall_1: 0.9543 - precision_1: 0.7293\n",
            "Epoch 424: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.4243 - accuracy: 0.7949 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8460 - recall_1: 0.9543 - precision_1: 0.7293 - val_loss: 0.6861 - val_accuracy: 0.6180 - val_sensitivity_at_specificity_1: 0.6438 - val_specificity_at_sensitivity_1: 0.6051 - val_recall_1: 0.9726 - val_precision_1: 0.5757\n",
            "Epoch 425/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4184 - accuracy: 0.8035 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8457 - recall_1: 0.9496 - precision_1: 0.7366\n",
            "Epoch 425: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.4184 - accuracy: 0.8035 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8457 - recall_1: 0.9496 - precision_1: 0.7366 - val_loss: 0.7137 - val_accuracy: 0.5828 - val_sensitivity_at_specificity_1: 0.6869 - val_specificity_at_sensitivity_1: 0.6687 - val_recall_1: 0.9590 - val_precision_1: 0.5347\n",
            "Epoch 426/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4272 - accuracy: 0.7832 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8605 - recall_1: 0.9355 - precision_1: 0.7097\n",
            "Epoch 426: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.4272 - accuracy: 0.7832 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8605 - recall_1: 0.9355 - precision_1: 0.7097 - val_loss: 0.6538 - val_accuracy: 0.6227 - val_sensitivity_at_specificity_1: 0.6907 - val_specificity_at_sensitivity_1: 0.5993 - val_recall_1: 0.9429 - val_precision_1: 0.5853\n",
            "Epoch 427/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4232 - accuracy: 0.7871 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8667 - recall_1: 0.9354 - precision_1: 0.7278\n",
            "Epoch 427: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.4232 - accuracy: 0.7871 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8667 - recall_1: 0.9354 - precision_1: 0.7278 - val_loss: 0.6855 - val_accuracy: 0.6180 - val_sensitivity_at_specificity_1: 0.6672 - val_specificity_at_sensitivity_1: 0.6485 - val_recall_1: 0.9717 - val_precision_1: 0.5679\n",
            "Epoch 428/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4200 - accuracy: 0.7930 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8620 - recall_1: 0.9637 - precision_1: 0.7115\n",
            "Epoch 428: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.4200 - accuracy: 0.7930 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8620 - recall_1: 0.9637 - precision_1: 0.7115 - val_loss: 0.6781 - val_accuracy: 0.6078 - val_sensitivity_at_specificity_1: 0.6771 - val_specificity_at_sensitivity_1: 0.6433 - val_recall_1: 0.9734 - val_precision_1: 0.5615\n",
            "Epoch 429/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4191 - accuracy: 0.7879 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8568 - recall_1: 0.9412 - precision_1: 0.7194\n",
            "Epoch 429: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.4191 - accuracy: 0.7879 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8568 - recall_1: 0.9412 - precision_1: 0.7194 - val_loss: 0.6853 - val_accuracy: 0.6125 - val_sensitivity_at_specificity_1: 0.6351 - val_specificity_at_sensitivity_1: 0.5936 - val_recall_1: 0.9710 - val_precision_1: 0.5714\n",
            "Epoch 430/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4039 - accuracy: 0.8059 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8790 - recall_1: 0.9594 - precision_1: 0.7381\n",
            "Epoch 430: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.4039 - accuracy: 0.8059 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8790 - recall_1: 0.9594 - precision_1: 0.7381 - val_loss: 0.7053 - val_accuracy: 0.5930 - val_sensitivity_at_specificity_1: 0.6596 - val_specificity_at_sensitivity_1: 0.6078 - val_recall_1: 0.9433 - val_precision_1: 0.5449\n",
            "Epoch 431/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4237 - accuracy: 0.7883 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8509 - recall_1: 0.9273 - precision_1: 0.7254\n",
            "Epoch 431: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.4237 - accuracy: 0.7883 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8509 - recall_1: 0.9273 - precision_1: 0.7254 - val_loss: 0.7039 - val_accuracy: 0.6102 - val_sensitivity_at_specificity_1: 0.6635 - val_specificity_at_sensitivity_1: 0.6537 - val_recall_1: 0.9624 - val_precision_1: 0.5642\n",
            "Epoch 432/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4172 - accuracy: 0.7914 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8672 - recall_1: 0.9368 - precision_1: 0.7173\n",
            "Epoch 432: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.4172 - accuracy: 0.7914 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8672 - recall_1: 0.9368 - precision_1: 0.7173 - val_loss: 0.6762 - val_accuracy: 0.6023 - val_sensitivity_at_specificity_1: 0.6925 - val_specificity_at_sensitivity_1: 0.6085 - val_recall_1: 0.9068 - val_precision_1: 0.5653\n",
            "Epoch 433/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4405 - accuracy: 0.7738 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8454 - recall_1: 0.9154 - precision_1: 0.7080\n",
            "Epoch 433: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.4405 - accuracy: 0.7738 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8454 - recall_1: 0.9154 - precision_1: 0.7080 - val_loss: 0.6425 - val_accuracy: 0.6305 - val_sensitivity_at_specificity_1: 0.7199 - val_specificity_at_sensitivity_1: 0.6517 - val_recall_1: 0.9422 - val_precision_1: 0.5873\n",
            "Epoch 434/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4214 - accuracy: 0.7941 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8481 - recall_1: 0.9429 - precision_1: 0.7296\n",
            "Epoch 434: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 174ms/step - loss: 0.4214 - accuracy: 0.7941 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8481 - recall_1: 0.9429 - precision_1: 0.7296 - val_loss: 0.6922 - val_accuracy: 0.6211 - val_sensitivity_at_specificity_1: 0.6713 - val_specificity_at_sensitivity_1: 0.6094 - val_recall_1: 0.9891 - val_precision_1: 0.5717\n",
            "Epoch 435/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4118 - accuracy: 0.7957 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8649 - recall_1: 0.9827 - precision_1: 0.7139\n",
            "Epoch 435: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.4118 - accuracy: 0.7957 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8649 - recall_1: 0.9827 - precision_1: 0.7139 - val_loss: 0.6560 - val_accuracy: 0.6125 - val_sensitivity_at_specificity_1: 0.6656 - val_specificity_at_sensitivity_1: 0.6348 - val_recall_1: 0.9651 - val_precision_1: 0.5623\n",
            "Epoch 436/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4093 - accuracy: 0.8086 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8715 - recall_1: 0.9610 - precision_1: 0.7410\n",
            "Epoch 436: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.4093 - accuracy: 0.8086 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8715 - recall_1: 0.9610 - precision_1: 0.7410 - val_loss: 0.6805 - val_accuracy: 0.6078 - val_sensitivity_at_specificity_1: 0.7183 - val_specificity_at_sensitivity_1: 0.6318 - val_recall_1: 0.9703 - val_precision_1: 0.5621\n",
            "Epoch 437/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4183 - accuracy: 0.8000 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8421 - recall_1: 0.9525 - precision_1: 0.7376\n",
            "Epoch 437: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.4183 - accuracy: 0.8000 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8421 - recall_1: 0.9525 - precision_1: 0.7376 - val_loss: 0.6975 - val_accuracy: 0.5953 - val_sensitivity_at_specificity_1: 0.6915 - val_specificity_at_sensitivity_1: 0.6373 - val_recall_1: 0.9636 - val_precision_1: 0.5516\n",
            "Epoch 438/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4253 - accuracy: 0.7899 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8534 - recall_1: 0.9415 - precision_1: 0.7243\n",
            "Epoch 438: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.4253 - accuracy: 0.7899 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8534 - recall_1: 0.9415 - precision_1: 0.7243 - val_loss: 0.6832 - val_accuracy: 0.6148 - val_sensitivity_at_specificity_1: 0.7359 - val_specificity_at_sensitivity_1: 0.6562 - val_recall_1: 0.9641 - val_precision_1: 0.5676\n",
            "Epoch 439/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4078 - accuracy: 0.8008 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8826 - recall_1: 0.9482 - precision_1: 0.7312\n",
            "Epoch 439: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.4078 - accuracy: 0.8008 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8826 - recall_1: 0.9482 - precision_1: 0.7312 - val_loss: 0.6702 - val_accuracy: 0.6219 - val_sensitivity_at_specificity_1: 0.7241 - val_specificity_at_sensitivity_1: 0.6791 - val_recall_1: 0.9687 - val_precision_1: 0.5712\n",
            "Epoch 440/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4362 - accuracy: 0.7789 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8450 - recall_1: 0.9240 - precision_1: 0.7103\n",
            "Epoch 440: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.4362 - accuracy: 0.7789 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8450 - recall_1: 0.9240 - precision_1: 0.7103 - val_loss: 0.6985 - val_accuracy: 0.5930 - val_sensitivity_at_specificity_1: 0.6817 - val_specificity_at_sensitivity_1: 0.6494 - val_recall_1: 0.9627 - val_precision_1: 0.5551\n",
            "Epoch 441/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4107 - accuracy: 0.7949 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8687 - recall_1: 0.9605 - precision_1: 0.7189\n",
            "Epoch 441: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.4107 - accuracy: 0.7949 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8687 - recall_1: 0.9605 - precision_1: 0.7189 - val_loss: 0.6760 - val_accuracy: 0.6172 - val_sensitivity_at_specificity_1: 0.6579 - val_specificity_at_sensitivity_1: 0.6295 - val_recall_1: 0.9658 - val_precision_1: 0.5702\n",
            "Epoch 442/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4165 - accuracy: 0.7992 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8541 - recall_1: 0.9549 - precision_1: 0.7255\n",
            "Epoch 442: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 174ms/step - loss: 0.4165 - accuracy: 0.7992 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8541 - recall_1: 0.9549 - precision_1: 0.7255 - val_loss: 0.6907 - val_accuracy: 0.6078 - val_sensitivity_at_specificity_1: 0.6952 - val_specificity_at_sensitivity_1: 0.6688 - val_recall_1: 0.9658 - val_precision_1: 0.5640\n",
            "Epoch 443/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4196 - accuracy: 0.7937 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8647 - recall_1: 0.9563 - precision_1: 0.7219\n",
            "Epoch 443: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.4196 - accuracy: 0.7937 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8647 - recall_1: 0.9563 - precision_1: 0.7219 - val_loss: 0.7095 - val_accuracy: 0.5953 - val_sensitivity_at_specificity_1: 0.6651 - val_specificity_at_sensitivity_1: 0.6296 - val_recall_1: 0.9712 - val_precision_1: 0.5479\n",
            "Epoch 444/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4328 - accuracy: 0.7746 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8616 - recall_1: 0.9006 - precision_1: 0.7167\n",
            "Epoch 444: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.4328 - accuracy: 0.7746 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8616 - recall_1: 0.9006 - precision_1: 0.7167 - val_loss: 0.6806 - val_accuracy: 0.6180 - val_sensitivity_at_specificity_1: 0.7129 - val_specificity_at_sensitivity_1: 0.6870 - val_recall_1: 0.9688 - val_precision_1: 0.5697\n",
            "Epoch 445/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4143 - accuracy: 0.7980 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8653 - recall_1: 0.9657 - precision_1: 0.7237\n",
            "Epoch 445: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 175ms/step - loss: 0.4143 - accuracy: 0.7980 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8653 - recall_1: 0.9657 - precision_1: 0.7237 - val_loss: 0.6977 - val_accuracy: 0.6047 - val_sensitivity_at_specificity_1: 0.6693 - val_specificity_at_sensitivity_1: 0.6237 - val_recall_1: 0.9857 - val_precision_1: 0.5551\n",
            "Epoch 446/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4303 - accuracy: 0.7832 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8550 - recall_1: 0.9455 - precision_1: 0.7145\n",
            "Epoch 446: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.4303 - accuracy: 0.7832 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8550 - recall_1: 0.9455 - precision_1: 0.7145 - val_loss: 0.6675 - val_accuracy: 0.6023 - val_sensitivity_at_specificity_1: 0.7352 - val_specificity_at_sensitivity_1: 0.6697 - val_recall_1: 0.9502 - val_precision_1: 0.5533\n",
            "Epoch 447/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4056 - accuracy: 0.8094 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8682 - recall_1: 0.9695 - precision_1: 0.7340\n",
            "Epoch 447: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.4056 - accuracy: 0.8094 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8682 - recall_1: 0.9695 - precision_1: 0.7340 - val_loss: 0.7140 - val_accuracy: 0.6031 - val_sensitivity_at_specificity_1: 0.7449 - val_specificity_at_sensitivity_1: 0.6484 - val_recall_1: 0.9829 - val_precision_1: 0.5598\n",
            "Epoch 448/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4055 - accuracy: 0.7973 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8891 - recall_1: 0.9445 - precision_1: 0.7296\n",
            "Epoch 448: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.4055 - accuracy: 0.7973 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8891 - recall_1: 0.9445 - precision_1: 0.7296 - val_loss: 0.7063 - val_accuracy: 0.6039 - val_sensitivity_at_specificity_1: 0.6918 - val_specificity_at_sensitivity_1: 0.6418 - val_recall_1: 0.9646 - val_precision_1: 0.5640\n",
            "Epoch 449/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4162 - accuracy: 0.8000 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8520 - recall_1: 0.9587 - precision_1: 0.7282\n",
            "Epoch 449: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.4162 - accuracy: 0.8000 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8520 - recall_1: 0.9587 - precision_1: 0.7282 - val_loss: 0.7094 - val_accuracy: 0.5984 - val_sensitivity_at_specificity_1: 0.7051 - val_specificity_at_sensitivity_1: 0.6540 - val_recall_1: 0.9808 - val_precision_1: 0.5494\n",
            "Epoch 450/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4133 - accuracy: 0.7988 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8575 - recall_1: 0.9469 - precision_1: 0.7273\n",
            "Epoch 450: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.4133 - accuracy: 0.7988 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8575 - recall_1: 0.9469 - precision_1: 0.7273 - val_loss: 0.6853 - val_accuracy: 0.6172 - val_sensitivity_at_specificity_1: 0.6833 - val_specificity_at_sensitivity_1: 0.6110 - val_recall_1: 0.9819 - val_precision_1: 0.5766\n",
            "Epoch 451/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4086 - accuracy: 0.8062 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8445 - recall_1: 0.9715 - precision_1: 0.7386\n",
            "Epoch 451: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.4086 - accuracy: 0.8062 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8445 - recall_1: 0.9715 - precision_1: 0.7386 - val_loss: 0.7473 - val_accuracy: 0.5938 - val_sensitivity_at_specificity_1: 0.6827 - val_specificity_at_sensitivity_1: 0.6174 - val_recall_1: 0.9888 - val_precision_1: 0.5460\n",
            "Epoch 452/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4152 - accuracy: 0.7965 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8656 - recall_1: 0.9513 - precision_1: 0.7251\n",
            "Epoch 452: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.4152 - accuracy: 0.7965 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8656 - recall_1: 0.9513 - precision_1: 0.7251 - val_loss: 0.6804 - val_accuracy: 0.6172 - val_sensitivity_at_specificity_1: 0.6509 - val_specificity_at_sensitivity_1: 0.6362 - val_recall_1: 0.9558 - val_precision_1: 0.5763\n",
            "Epoch 453/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4114 - accuracy: 0.7937 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8736 - recall_1: 0.9351 - precision_1: 0.7259\n",
            "Epoch 453: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.4114 - accuracy: 0.7937 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8736 - recall_1: 0.9351 - precision_1: 0.7259 - val_loss: 0.6962 - val_accuracy: 0.6203 - val_sensitivity_at_specificity_1: 0.6918 - val_specificity_at_sensitivity_1: 0.6242 - val_recall_1: 0.9701 - val_precision_1: 0.5692\n",
            "Epoch 454/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4145 - accuracy: 0.7953 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8761 - recall_1: 0.9477 - precision_1: 0.7300\n",
            "Epoch 454: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 0.4145 - accuracy: 0.7953 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8761 - recall_1: 0.9477 - precision_1: 0.7300 - val_loss: 0.7099 - val_accuracy: 0.5906 - val_sensitivity_at_specificity_1: 0.6274 - val_specificity_at_sensitivity_1: 0.6056 - val_recall_1: 0.9686 - val_precision_1: 0.5500\n",
            "Epoch 455/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4267 - accuracy: 0.7941 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8542 - recall_1: 0.9468 - precision_1: 0.7248\n",
            "Epoch 455: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.4267 - accuracy: 0.7941 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8542 - recall_1: 0.9468 - precision_1: 0.7248 - val_loss: 0.7008 - val_accuracy: 0.6125 - val_sensitivity_at_specificity_1: 0.6745 - val_specificity_at_sensitivity_1: 0.6223 - val_recall_1: 0.9626 - val_precision_1: 0.5670\n",
            "Epoch 456/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4173 - accuracy: 0.7965 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8690 - recall_1: 0.9526 - precision_1: 0.7308\n",
            "Epoch 456: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.4173 - accuracy: 0.7965 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8690 - recall_1: 0.9526 - precision_1: 0.7308 - val_loss: 0.6765 - val_accuracy: 0.6289 - val_sensitivity_at_specificity_1: 0.7051 - val_specificity_at_sensitivity_1: 0.6359 - val_recall_1: 0.9816 - val_precision_1: 0.5799\n",
            "Epoch 457/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4335 - accuracy: 0.7844 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8507 - recall_1: 0.9513 - precision_1: 0.7121\n",
            "Epoch 457: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.4335 - accuracy: 0.7844 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8507 - recall_1: 0.9513 - precision_1: 0.7121 - val_loss: 0.6617 - val_accuracy: 0.6180 - val_sensitivity_at_specificity_1: 0.6914 - val_specificity_at_sensitivity_1: 0.6582 - val_recall_1: 0.9475 - val_precision_1: 0.5744\n",
            "Epoch 458/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4209 - accuracy: 0.7914 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8594 - recall_1: 0.9526 - precision_1: 0.7179\n",
            "Epoch 458: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.4209 - accuracy: 0.7914 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8594 - recall_1: 0.9526 - precision_1: 0.7179 - val_loss: 0.7047 - val_accuracy: 0.5883 - val_sensitivity_at_specificity_1: 0.6924 - val_specificity_at_sensitivity_1: 0.6419 - val_recall_1: 0.9646 - val_precision_1: 0.5426\n",
            "Epoch 459/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4271 - accuracy: 0.7879 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8699 - recall_1: 0.9540 - precision_1: 0.7168\n",
            "Epoch 459: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.4271 - accuracy: 0.7879 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8699 - recall_1: 0.9540 - precision_1: 0.7168 - val_loss: 0.6689 - val_accuracy: 0.6234 - val_sensitivity_at_specificity_1: 0.6441 - val_specificity_at_sensitivity_1: 0.6000 - val_recall_1: 0.9544 - val_precision_1: 0.5900\n",
            "Epoch 460/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4131 - accuracy: 0.7965 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8640 - recall_1: 0.9272 - precision_1: 0.7267\n",
            "Epoch 460: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.4131 - accuracy: 0.7965 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8640 - recall_1: 0.9272 - precision_1: 0.7267 - val_loss: 0.7437 - val_accuracy: 0.5836 - val_sensitivity_at_specificity_1: 0.6995 - val_specificity_at_sensitivity_1: 0.6270 - val_recall_1: 0.9783 - val_precision_1: 0.5298\n",
            "Epoch 461/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3980 - accuracy: 0.8176 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8761 - recall_1: 0.9590 - precision_1: 0.7536\n",
            "Epoch 461: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 174ms/step - loss: 0.3980 - accuracy: 0.8176 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8761 - recall_1: 0.9590 - precision_1: 0.7536 - val_loss: 0.6998 - val_accuracy: 0.6203 - val_sensitivity_at_specificity_1: 0.6421 - val_specificity_at_sensitivity_1: 0.6003 - val_recall_1: 0.9545 - val_precision_1: 0.5709\n",
            "Epoch 462/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4155 - accuracy: 0.7973 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8640 - recall_1: 0.9413 - precision_1: 0.7335\n",
            "Epoch 462: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.4155 - accuracy: 0.7973 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8640 - recall_1: 0.9413 - precision_1: 0.7335 - val_loss: 0.6970 - val_accuracy: 0.5977 - val_sensitivity_at_specificity_1: 0.6584 - val_specificity_at_sensitivity_1: 0.6082 - val_recall_1: 0.9567 - val_precision_1: 0.5597\n",
            "Epoch 463/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4092 - accuracy: 0.7945 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8752 - recall_1: 0.9274 - precision_1: 0.7278\n",
            "Epoch 463: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.4092 - accuracy: 0.7945 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8752 - recall_1: 0.9274 - precision_1: 0.7278 - val_loss: 0.7096 - val_accuracy: 0.6094 - val_sensitivity_at_specificity_1: 0.6940 - val_specificity_at_sensitivity_1: 0.6347 - val_recall_1: 0.9748 - val_precision_1: 0.5608\n",
            "Epoch 464/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4176 - accuracy: 0.8000 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8595 - recall_1: 0.9492 - precision_1: 0.7345\n",
            "Epoch 464: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.4176 - accuracy: 0.8000 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8595 - recall_1: 0.9492 - precision_1: 0.7345 - val_loss: 0.7121 - val_accuracy: 0.5914 - val_sensitivity_at_specificity_1: 0.6391 - val_specificity_at_sensitivity_1: 0.5945 - val_recall_1: 0.9539 - val_precision_1: 0.5484\n",
            "Epoch 465/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4090 - accuracy: 0.8004 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8674 - recall_1: 0.9283 - precision_1: 0.7346\n",
            "Epoch 465: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.4090 - accuracy: 0.8004 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8674 - recall_1: 0.9283 - precision_1: 0.7346 - val_loss: 0.7142 - val_accuracy: 0.5938 - val_sensitivity_at_specificity_1: 0.6359 - val_specificity_at_sensitivity_1: 0.6254 - val_recall_1: 0.9628 - val_precision_1: 0.5449\n",
            "Epoch 466/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4054 - accuracy: 0.8016 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8669 - recall_1: 0.9475 - precision_1: 0.7326\n",
            "Epoch 466: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.4054 - accuracy: 0.8016 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8669 - recall_1: 0.9475 - precision_1: 0.7326 - val_loss: 0.6819 - val_accuracy: 0.6219 - val_sensitivity_at_specificity_1: 0.6836 - val_specificity_at_sensitivity_1: 0.6566 - val_recall_1: 0.9677 - val_precision_1: 0.5764\n",
            "Epoch 467/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3981 - accuracy: 0.8074 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8897 - recall_1: 0.9457 - precision_1: 0.7488\n",
            "Epoch 467: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 175ms/step - loss: 0.3981 - accuracy: 0.8074 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8897 - recall_1: 0.9457 - precision_1: 0.7488 - val_loss: 0.7070 - val_accuracy: 0.6117 - val_sensitivity_at_specificity_1: 0.6562 - val_specificity_at_sensitivity_1: 0.6267 - val_recall_1: 0.9717 - val_precision_1: 0.5638\n",
            "Epoch 468/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4264 - accuracy: 0.7891 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8491 - recall_1: 0.9457 - precision_1: 0.7216\n",
            "Epoch 468: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.4264 - accuracy: 0.7891 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8491 - recall_1: 0.9457 - precision_1: 0.7216 - val_loss: 0.6558 - val_accuracy: 0.6242 - val_sensitivity_at_specificity_1: 0.7177 - val_specificity_at_sensitivity_1: 0.6840 - val_recall_1: 0.9655 - val_precision_1: 0.5840\n",
            "Epoch 469/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4210 - accuracy: 0.7992 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8579 - recall_1: 0.9606 - precision_1: 0.7284\n",
            "Epoch 469: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.4210 - accuracy: 0.7992 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8579 - recall_1: 0.9606 - precision_1: 0.7284 - val_loss: 0.6768 - val_accuracy: 0.6187 - val_sensitivity_at_specificity_1: 0.6667 - val_specificity_at_sensitivity_1: 0.6615 - val_recall_1: 0.9812 - val_precision_1: 0.5684\n",
            "Epoch 470/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4242 - accuracy: 0.7852 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8731 - recall_1: 0.9467 - precision_1: 0.7148\n",
            "Epoch 470: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.4242 - accuracy: 0.7852 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8731 - recall_1: 0.9467 - precision_1: 0.7148 - val_loss: 0.6950 - val_accuracy: 0.6109 - val_sensitivity_at_specificity_1: 0.6677 - val_specificity_at_sensitivity_1: 0.6204 - val_recall_1: 0.9632 - val_precision_1: 0.5703\n",
            "Epoch 471/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4219 - accuracy: 0.7937 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8778 - recall_1: 0.9444 - precision_1: 0.7219\n",
            "Epoch 471: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.4219 - accuracy: 0.7937 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8778 - recall_1: 0.9444 - precision_1: 0.7219 - val_loss: 0.6876 - val_accuracy: 0.5906 - val_sensitivity_at_specificity_1: 0.6902 - val_specificity_at_sensitivity_1: 0.6358 - val_recall_1: 0.9377 - val_precision_1: 0.5406\n",
            "Epoch 472/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4131 - accuracy: 0.7977 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8758 - recall_1: 0.9295 - precision_1: 0.7296\n",
            "Epoch 472: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.4131 - accuracy: 0.7977 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8758 - recall_1: 0.9295 - precision_1: 0.7296 - val_loss: 0.7059 - val_accuracy: 0.6031 - val_sensitivity_at_specificity_1: 0.6852 - val_specificity_at_sensitivity_1: 0.6462 - val_recall_1: 0.9837 - val_precision_1: 0.5477\n",
            "Epoch 473/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4226 - accuracy: 0.7795 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8600 - recall_1: 0.9462 - precision_1: 0.7104\n",
            "Epoch 473: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 162ms/step - loss: 0.4226 - accuracy: 0.7795 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8600 - recall_1: 0.9462 - precision_1: 0.7104 - val_loss: 0.7036 - val_accuracy: 0.5898 - val_sensitivity_at_specificity_1: 0.6703 - val_specificity_at_sensitivity_1: 0.6138 - val_recall_1: 0.9440 - val_precision_1: 0.5538\n",
            "Epoch 474/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4187 - accuracy: 0.7930 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8683 - recall_1: 0.9311 - precision_1: 0.7318\n",
            "Epoch 474: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.4187 - accuracy: 0.7930 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8683 - recall_1: 0.9311 - precision_1: 0.7318 - val_loss: 0.7191 - val_accuracy: 0.5953 - val_sensitivity_at_specificity_1: 0.6345 - val_specificity_at_sensitivity_1: 0.5864 - val_recall_1: 0.9668 - val_precision_1: 0.5514\n",
            "Epoch 475/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4166 - accuracy: 0.7926 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8755 - recall_1: 0.9260 - precision_1: 0.7315\n",
            "Epoch 475: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.4166 - accuracy: 0.7926 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8755 - recall_1: 0.9260 - precision_1: 0.7315 - val_loss: 0.6962 - val_accuracy: 0.6320 - val_sensitivity_at_specificity_1: 0.6996 - val_specificity_at_sensitivity_1: 0.6268 - val_recall_1: 0.9686 - val_precision_1: 0.5902\n",
            "Epoch 476/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4021 - accuracy: 0.8039 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8653 - recall_1: 0.9564 - precision_1: 0.7334\n",
            "Epoch 476: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.4021 - accuracy: 0.8039 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8653 - recall_1: 0.9564 - precision_1: 0.7334 - val_loss: 0.7204 - val_accuracy: 0.6039 - val_sensitivity_at_specificity_1: 0.6878 - val_specificity_at_sensitivity_1: 0.6436 - val_recall_1: 0.9756 - val_precision_1: 0.5495\n",
            "Epoch 477/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4291 - accuracy: 0.7863 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8439 - recall_1: 0.9502 - precision_1: 0.7131\n",
            "Epoch 477: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.4291 - accuracy: 0.7863 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8439 - recall_1: 0.9502 - precision_1: 0.7131 - val_loss: 0.6899 - val_accuracy: 0.6172 - val_sensitivity_at_specificity_1: 0.6330 - val_specificity_at_sensitivity_1: 0.6185 - val_recall_1: 0.9907 - val_precision_1: 0.5682\n",
            "Epoch 478/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4299 - accuracy: 0.7906 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8487 - recall_1: 0.9367 - precision_1: 0.7305\n",
            "Epoch 478: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.4299 - accuracy: 0.7906 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8487 - recall_1: 0.9367 - precision_1: 0.7305 - val_loss: 0.6855 - val_accuracy: 0.5977 - val_sensitivity_at_specificity_1: 0.6814 - val_specificity_at_sensitivity_1: 0.5805 - val_recall_1: 0.9890 - val_precision_1: 0.5524\n",
            "Epoch 479/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4210 - accuracy: 0.7918 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8558 - recall_1: 0.9858 - precision_1: 0.7085\n",
            "Epoch 479: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.4210 - accuracy: 0.7918 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8558 - recall_1: 0.9858 - precision_1: 0.7085 - val_loss: 0.7298 - val_accuracy: 0.5883 - val_sensitivity_at_specificity_1: 0.6147 - val_specificity_at_sensitivity_1: 0.5556 - val_recall_1: 0.9782 - val_precision_1: 0.5500\n",
            "Epoch 480/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4214 - accuracy: 0.7961 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8547 - recall_1: 0.9560 - precision_1: 0.7268\n",
            "Epoch 480: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.4214 - accuracy: 0.7961 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8547 - recall_1: 0.9560 - precision_1: 0.7268 - val_loss: 0.7181 - val_accuracy: 0.5898 - val_sensitivity_at_specificity_1: 0.6813 - val_specificity_at_sensitivity_1: 0.6252 - val_recall_1: 0.9765 - val_precision_1: 0.5495\n",
            "Epoch 481/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4054 - accuracy: 0.8065 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8906 - recall_1: 0.9551 - precision_1: 0.7439\n",
            "Epoch 481: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.4054 - accuracy: 0.8065 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8906 - recall_1: 0.9551 - precision_1: 0.7439 - val_loss: 0.6716 - val_accuracy: 0.6281 - val_sensitivity_at_specificity_1: 0.6973 - val_specificity_at_sensitivity_1: 0.6228 - val_recall_1: 0.9704 - val_precision_1: 0.5765\n",
            "Epoch 482/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4171 - accuracy: 0.7930 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8674 - recall_1: 0.9363 - precision_1: 0.7231\n",
            "Epoch 482: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.4171 - accuracy: 0.7930 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8674 - recall_1: 0.9363 - precision_1: 0.7231 - val_loss: 0.7154 - val_accuracy: 0.5977 - val_sensitivity_at_specificity_1: 0.6287 - val_specificity_at_sensitivity_1: 0.5978 - val_recall_1: 0.9657 - val_precision_1: 0.5567\n",
            "Epoch 483/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4221 - accuracy: 0.7902 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8648 - recall_1: 0.9552 - precision_1: 0.7209\n",
            "Epoch 483: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.4221 - accuracy: 0.7902 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8648 - recall_1: 0.9552 - precision_1: 0.7209 - val_loss: 0.6844 - val_accuracy: 0.6148 - val_sensitivity_at_specificity_1: 0.6937 - val_specificity_at_sensitivity_1: 0.6523 - val_recall_1: 0.9801 - val_precision_1: 0.5714\n",
            "Epoch 484/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4186 - accuracy: 0.7898 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8692 - recall_1: 0.9566 - precision_1: 0.7152\n",
            "Epoch 484: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 171ms/step - loss: 0.4186 - accuracy: 0.7898 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8692 - recall_1: 0.9566 - precision_1: 0.7152 - val_loss: 0.6682 - val_accuracy: 0.6250 - val_sensitivity_at_specificity_1: 0.6951 - val_specificity_at_sensitivity_1: 0.6474 - val_recall_1: 0.9665 - val_precision_1: 0.5806\n",
            "Epoch 485/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4294 - accuracy: 0.7895 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8607 - recall_1: 0.9410 - precision_1: 0.7237\n",
            "Epoch 485: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 168ms/step - loss: 0.4294 - accuracy: 0.7895 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8607 - recall_1: 0.9410 - precision_1: 0.7237 - val_loss: 0.7214 - val_accuracy: 0.5852 - val_sensitivity_at_specificity_1: 0.7093 - val_specificity_at_sensitivity_1: 0.6575 - val_recall_1: 0.9760 - val_precision_1: 0.5421\n",
            "Epoch 486/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4107 - accuracy: 0.8027 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8502 - recall_1: 0.9515 - precision_1: 0.7330\n",
            "Epoch 486: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.4107 - accuracy: 0.8027 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8502 - recall_1: 0.9515 - precision_1: 0.7330 - val_loss: 0.7166 - val_accuracy: 0.6078 - val_sensitivity_at_specificity_1: 0.6734 - val_specificity_at_sensitivity_1: 0.6141 - val_recall_1: 0.9812 - val_precision_1: 0.5617\n",
            "Epoch 487/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4114 - accuracy: 0.7949 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8809 - recall_1: 0.9420 - precision_1: 0.7209\n",
            "Epoch 487: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.4114 - accuracy: 0.7949 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8809 - recall_1: 0.9420 - precision_1: 0.7209 - val_loss: 0.6846 - val_accuracy: 0.6109 - val_sensitivity_at_specificity_1: 0.6533 - val_specificity_at_sensitivity_1: 0.6307 - val_recall_1: 0.9307 - val_precision_1: 0.5714\n",
            "Epoch 488/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4222 - accuracy: 0.7902 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8695 - recall_1: 0.9458 - precision_1: 0.7268\n",
            "Epoch 488: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.4222 - accuracy: 0.7902 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8695 - recall_1: 0.9458 - precision_1: 0.7268 - val_loss: 0.7131 - val_accuracy: 0.5891 - val_sensitivity_at_specificity_1: 0.6719 - val_specificity_at_sensitivity_1: 0.6238 - val_recall_1: 0.9779 - val_precision_1: 0.5477\n",
            "Epoch 489/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4047 - accuracy: 0.8016 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8824 - recall_1: 0.9548 - precision_1: 0.7388\n",
            "Epoch 489: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.4047 - accuracy: 0.8016 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8824 - recall_1: 0.9548 - precision_1: 0.7388 - val_loss: 0.7186 - val_accuracy: 0.5945 - val_sensitivity_at_specificity_1: 0.6516 - val_specificity_at_sensitivity_1: 0.6203 - val_recall_1: 0.9625 - val_precision_1: 0.5545\n",
            "Epoch 490/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4158 - accuracy: 0.7937 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8712 - recall_1: 0.9554 - precision_1: 0.7218\n",
            "Epoch 490: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 169ms/step - loss: 0.4158 - accuracy: 0.7937 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8712 - recall_1: 0.9554 - precision_1: 0.7218 - val_loss: 0.6650 - val_accuracy: 0.6227 - val_sensitivity_at_specificity_1: 0.7520 - val_specificity_at_sensitivity_1: 0.6776 - val_recall_1: 0.9485 - val_precision_1: 0.5747\n",
            "Epoch 491/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4193 - accuracy: 0.7957 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8694 - recall_1: 0.9248 - precision_1: 0.7394\n",
            "Epoch 491: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.4193 - accuracy: 0.7957 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8694 - recall_1: 0.9248 - precision_1: 0.7394 - val_loss: 0.7089 - val_accuracy: 0.6031 - val_sensitivity_at_specificity_1: 0.6477 - val_specificity_at_sensitivity_1: 0.6136 - val_recall_1: 0.9479 - val_precision_1: 0.5581\n",
            "Epoch 492/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4171 - accuracy: 0.7934 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8673 - recall_1: 0.9457 - precision_1: 0.7232\n",
            "Epoch 492: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.4171 - accuracy: 0.7934 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8673 - recall_1: 0.9457 - precision_1: 0.7232 - val_loss: 0.7095 - val_accuracy: 0.6000 - val_sensitivity_at_specificity_1: 0.6651 - val_specificity_at_sensitivity_1: 0.6365 - val_recall_1: 0.9624 - val_precision_1: 0.5576\n",
            "Epoch 493/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4231 - accuracy: 0.7895 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8542 - recall_1: 0.9589 - precision_1: 0.7181\n",
            "Epoch 493: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.4231 - accuracy: 0.7895 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8542 - recall_1: 0.9589 - precision_1: 0.7181 - val_loss: 0.7273 - val_accuracy: 0.5766 - val_sensitivity_at_specificity_1: 0.6367 - val_specificity_at_sensitivity_1: 0.6132 - val_recall_1: 0.9817 - val_precision_1: 0.5259\n",
            "Epoch 494/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4232 - accuracy: 0.7875 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8740 - recall_1: 0.9621 - precision_1: 0.7106\n",
            "Epoch 494: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.4232 - accuracy: 0.7875 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8740 - recall_1: 0.9621 - precision_1: 0.7106 - val_loss: 0.6417 - val_accuracy: 0.6320 - val_sensitivity_at_specificity_1: 0.7195 - val_specificity_at_sensitivity_1: 0.6872 - val_recall_1: 0.9457 - val_precision_1: 0.5904\n",
            "Epoch 495/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4188 - accuracy: 0.7879 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8677 - recall_1: 0.9075 - precision_1: 0.7314\n",
            "Epoch 495: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.4188 - accuracy: 0.7879 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8677 - recall_1: 0.9075 - precision_1: 0.7314 - val_loss: 0.7187 - val_accuracy: 0.6141 - val_sensitivity_at_specificity_1: 0.6606 - val_specificity_at_sensitivity_1: 0.6166 - val_recall_1: 0.9740 - val_precision_1: 0.5718\n",
            "Epoch 496/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3995 - accuracy: 0.8055 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8840 - recall_1: 0.9431 - precision_1: 0.7402\n",
            "Epoch 496: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 178ms/step - loss: 0.3995 - accuracy: 0.8055 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8840 - recall_1: 0.9431 - precision_1: 0.7402 - val_loss: 0.7360 - val_accuracy: 0.5891 - val_sensitivity_at_specificity_1: 0.6443 - val_specificity_at_sensitivity_1: 0.5988 - val_recall_1: 0.9729 - val_precision_1: 0.5451\n",
            "Epoch 497/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4043 - accuracy: 0.8039 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8778 - recall_1: 0.9571 - precision_1: 0.7331\n",
            "Epoch 497: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 175ms/step - loss: 0.4043 - accuracy: 0.8039 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8778 - recall_1: 0.9571 - precision_1: 0.7331 - val_loss: 0.7362 - val_accuracy: 0.5914 - val_sensitivity_at_specificity_1: 0.7095 - val_specificity_at_sensitivity_1: 0.6210 - val_recall_1: 0.9839 - val_precision_1: 0.5444\n",
            "Epoch 498/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4227 - accuracy: 0.7944 - sensitivity_at_specificity_1: 0.9992 - specificity_at_sensitivity_1: 0.8488 - recall_1: 0.9438 - precision_1: 0.7280\n",
            "Epoch 498: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 165ms/step - loss: 0.4227 - accuracy: 0.7944 - sensitivity_at_specificity_1: 0.9992 - specificity_at_sensitivity_1: 0.8488 - recall_1: 0.9438 - precision_1: 0.7280 - val_loss: 0.6858 - val_accuracy: 0.6203 - val_sensitivity_at_specificity_1: 0.6537 - val_specificity_at_sensitivity_1: 0.6020 - val_recall_1: 0.9805 - val_precision_1: 0.5803\n",
            "Epoch 499/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4116 - accuracy: 0.8059 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8589 - recall_1: 0.9687 - precision_1: 0.7302\n",
            "Epoch 499: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 176ms/step - loss: 0.4116 - accuracy: 0.8059 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8589 - recall_1: 0.9687 - precision_1: 0.7302 - val_loss: 0.6772 - val_accuracy: 0.6109 - val_sensitivity_at_specificity_1: 0.6352 - val_specificity_at_sensitivity_1: 0.6071 - val_recall_1: 0.9654 - val_precision_1: 0.5633\n",
            "Epoch 500/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4154 - accuracy: 0.7941 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8775 - recall_1: 0.9439 - precision_1: 0.7169\n",
            "Epoch 500: val_accuracy did not improve from 0.64219\n",
            "10/10 [==============================] - 2s 173ms/step - loss: 0.4154 - accuracy: 0.7941 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.8775 - recall_1: 0.9439 - precision_1: 0.7169 - val_loss: 0.6882 - val_accuracy: 0.6133 - val_sensitivity_at_specificity_1: 0.6697 - val_specificity_at_sensitivity_1: 0.6100 - val_recall_1: 0.9422 - val_precision_1: 0.5753\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Performance Metrics**"
      ],
      "metadata": {
        "id": "9StDeFAYCnGH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Training_Accuracy=history.history['accuracy']\n",
        "Validation_Accuracy=history.history['val_accuracy']\n",
        "Validation_Specificity=history.history['val_specificity_at_sensitivity_1']\n",
        "Validation_Sensitivity=history.history['val_sensitivity_at_specificity_1']\n",
        "Validation_Recall=history.history['val_recall_1']\n",
        "Validation_Precision=history.history['val_precision_1']\n",
        "Validation_Loss=history.history['val_loss']\n",
        "\n",
        "print(\"Training Accuracy: \",max(Training_Accuracy))\n",
        "print(\"Validation Accuracy: \",max(Validation_Accuracy))\n",
        "print(\"Validation Specificity: \",max(Validation_Specificity))\n",
        "print(\"Validation Sensitivity: \",max(Validation_Sensitivity))\n",
        "print(\"Validation Recall: \",max(Validation_Recall))\n",
        "print(\"Validation Precision: \",max(Validation_Precision))\n",
        "print(\"Validation Loss: \",min(Validation_Loss))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCdS_0U65A0-",
        "outputId": "34bf2211-3337-4623-b634-588a527c44c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy:  0.817578136920929\n",
            "Validation Accuracy:  0.6421874761581421\n",
            "Validation Specificity:  0.6971080899238586\n",
            "Validation Sensitivity:  0.7842519879341125\n",
            "Validation Recall:  1.0\n",
            "Validation Precision:  0.8333333134651184\n",
            "Validation Loss:  0.6081289052963257\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Accuracy Graph**"
      ],
      "metadata": {
        "id": "ROKKNMMHCqPt"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLqjG2X-vdLj",
        "outputId": "38db483d-d9df-4928-d5aa-47b49ebc6fb5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        }
      },
      "source": [
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loss Graph**"
      ],
      "metadata": {
        "id": "MmUmcWXBCs99"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBSAyVfivvHX",
        "outputId": "0a596337-0a10-4048-b8ec-80480b9713e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        }
      },
      "source": [
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}