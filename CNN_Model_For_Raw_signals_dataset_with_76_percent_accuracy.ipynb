{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsTzc3oi726u"
      },
      "source": [
        "# **Building a Convolutional Neural Network with Keras**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Libraries Import**"
      ],
      "metadata": {
        "id": "DGQLsDz2-KS2"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCglDGFy8AhT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "c307b475-05e7-4b9b-cfc0-80cc2a9a8f2a"
      },
      "source": [
        "#IMPORT LIBRARIES\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "tf.__version__\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import matplotlib.image as mpimg\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "import imageio\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "\n",
        "import psutil\n",
        "import GPUtil\n",
        "\n",
        "import os,sys,humanize,psutil,GPUtil"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.8.2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Memory Utilization Checkup (Before/After Model Execution)**"
      ],
      "metadata": {
        "id": "iKIdf2EW90Dc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#CPU AND GPU LIBRARIES INSTALLATION (If you get error in import, please install the both psutil and GPUtil)\n",
        "\n",
        "!pip install psutil\n",
        "!pip install GPUtil"
      ],
      "metadata": {
        "id": "Q2bPbY1LEG_0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "001170fc-94ea-4c8e-ef7f-8e998d3b5ecd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting GPUtil\n",
            "  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\n",
            "Building wheels for collected packages: GPUtil\n",
            "  Building wheel for GPUtil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for GPUtil: filename=GPUtil-1.4.0-py3-none-any.whl size=7411 sha256=6878262b923d396ee454bde18190fc129bb8399d1d072519de509b84a5b910cd\n",
            "  Stored in directory: /root/.cache/pip/wheels/6e/f8/83/534c52482d6da64622ddbf72cd93c35d2ef2881b78fd08ff0c\n",
            "Successfully built GPUtil\n",
            "Installing collected packages: GPUtil\n",
            "Successfully installed GPUtil-1.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CHECKING THE CPU AND GPU MEMORY\n",
        "\n",
        "# Testing the psutil library for both CPU and RAM performance details\n",
        "print(psutil.cpu_percent())\n",
        "#print(psutil.sys.ram)\n",
        "print(psutil.virtual_memory().percent)\n",
        "# Testing the GPUtil library for both GPU performance details\n",
        "GPUtil.showUtilization()"
      ],
      "metadata": {
        "id": "rnT_bgIWERmI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#CPU Memory Utilization\n",
        "!cat /proc/meminfo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rwrm76EmJ2Fv",
        "outputId": "c607dd9a-e6fb-4c4b-e19e-7fb649331898"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MemTotal:       13298580 kB\n",
            "MemFree:         3316900 kB\n",
            "MemAvailable:   10266808 kB\n",
            "Buffers:          130028 kB\n",
            "Cached:          5937572 kB\n",
            "SwapCached:            0 kB\n",
            "Active:          3247484 kB\n",
            "Inactive:        6222332 kB\n",
            "Active(anon):    2410380 kB\n",
            "Inactive(anon):    14796 kB\n",
            "Active(file):     837104 kB\n",
            "Inactive(file):  6207536 kB\n",
            "Unevictable:           0 kB\n",
            "Mlocked:               0 kB\n",
            "SwapTotal:             0 kB\n",
            "SwapFree:              0 kB\n",
            "Dirty:               228 kB\n",
            "Writeback:             0 kB\n",
            "AnonPages:       3402276 kB\n",
            "Mapped:          1713880 kB\n",
            "Shmem:             15540 kB\n",
            "KReclaimable:     231192 kB\n",
            "Slab:             296624 kB\n",
            "SReclaimable:     231192 kB\n",
            "SUnreclaim:        65432 kB\n",
            "KernelStack:        5344 kB\n",
            "PageTables:        24580 kB\n",
            "NFS_Unstable:          0 kB\n",
            "Bounce:                0 kB\n",
            "WritebackTmp:          0 kB\n",
            "CommitLimit:     6649288 kB\n",
            "Committed_AS:    5888936 kB\n",
            "VmallocTotal:   34359738367 kB\n",
            "VmallocUsed:       51420 kB\n",
            "VmallocChunk:          0 kB\n",
            "Percpu:             1504 kB\n",
            "AnonHugePages:     12288 kB\n",
            "ShmemHugePages:        0 kB\n",
            "ShmemPmdMapped:        0 kB\n",
            "FileHugePages:         0 kB\n",
            "FilePmdMapped:         0 kB\n",
            "CmaTotal:              0 kB\n",
            "CmaFree:               0 kB\n",
            "HugePages_Total:       0\n",
            "HugePages_Free:        0\n",
            "HugePages_Rsvd:        0\n",
            "HugePages_Surp:        0\n",
            "Hugepagesize:       2048 kB\n",
            "Hugetlb:               0 kB\n",
            "DirectMap4k:      234304 kB\n",
            "DirectMap2M:     9199616 kB\n",
            "DirectMap1G:     6291456 kB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!grep MemTotal /proc/meminfo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0pgr9seSLdYf",
        "outputId": "20f1ccbf-e325-4728-b5e6-68431ddfbd41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MemTotal:       13298580 kB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#GPU Memory Utilization \n",
        "!nvidia-smi --query-gpu=memory.total --format=csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLQu663TLjBQ",
        "outputId": "84e5d717-3c8f-4e9a-beb4-8ff7d5653f03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "memory.total [MiB]\n",
            "15109 MiB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# function\n",
        "def mem_report():\n",
        "  print(\"CPU RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ))\n",
        "  \n",
        "  GPUs = GPUtil.getGPUs()\n",
        "  for i, gpu in enumerate(GPUs):\n",
        "    print('GPU {:d} ... Mem Free: {:.0f}MB / {:.0f}MB | Utilization {:3.0f}%'.format(i, gpu.memoryFree, gpu.memoryTotal, gpu.memoryUtil*100))\n",
        "\n",
        "mem_report()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fd_O6FIRJGtv",
        "outputId": "a146dddf-8ad5-4843-cc74-48d08318b535"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU RAM Free: 10.5 GB\n",
            "GPU 0 ... Mem Free: 10421MB / 15109MB | Utilization  31%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Let's Start with Model Implementation**"
      ],
      "metadata": {
        "id": "w9zQHgqb8zjd"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qf7eW3HC9XVL"
      },
      "source": [
        "**Data Acquisition and ImageDataGenerator**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0BfyGlJbx0l"
      },
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255) #Normalize the pixel values\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hsimgs7aqt6G"
      },
      "source": [
        "#File path to the folder containin images\n",
        "train_dir = os.path.join('/content/colab_dataset_rawSignals/Train')\n",
        "validation_dir = os.path.join('/content/colab_dataset_rawSignals/Test')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NyvlF41oqxEP",
        "outputId": "45b25331-7893-460b-9cf9-f1678a16bc33",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(64,64),\n",
        "    batch_size=256,\n",
        "    shuffle=True,\n",
        "    class_mode='binary')\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    validation_dir,\n",
        "    target_size=(64,64),\n",
        "    batch_size=256,\n",
        "    shuffle=True,\n",
        "    class_mode='binary')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 33128 images belonging to 2 classes.\n",
            "Found 6780 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3yhwpN_-BaS"
      },
      "source": [
        "**Building the Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSzxq4KDtKN6"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "                                    \n",
        "    # First convolution layer \n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(64, 64, 3),use_bias=True),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "\n",
        "    # Second convolution layer \n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu',use_bias=True),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    \n",
        "\n",
        "    # Third convolution layer \n",
        "    tf.keras.layers.Conv2D(256, (3,3), activation='relu',use_bias=True),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "\n",
        "  # Fourth convolution layer  \n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu',use_bias=True),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "\n",
        "\n",
        "    # Flatten the pooled feature maps\n",
        "    tf.keras.layers.Flatten(),\n",
        "\n",
        "    # Fully connected hidden layer\n",
        "    tf.keras.layers.Dense(8, activation='relu',use_bias=True),\n",
        "\n",
        "    # Output layer\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid',activity_regularizer=regularizers.L1(0.001))  \n",
        "\n",
        "])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Printing Model Summary**"
      ],
      "metadata": {
        "id": "6kqCwyax9Ec0"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HU0RFGLtNJb",
        "outputId": "08c30a3c-9036-4547-f6ec-6ffdd88b7e8f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 62, 62, 64)        1792      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 31, 31, 64)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 31, 31, 64)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 29, 29, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 14, 14, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 12, 12, 256)       295168    \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 6, 6, 256)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 6, 6, 256)         0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 4, 4, 64)          147520    \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 2, 2, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 2, 2, 64)          0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 8)                 2056      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 520,401\n",
            "Trainable params: 520,401\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THk8lK3G-cdk"
      },
      "source": [
        "**Optimizer Implementation and model training/validation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBN3GBMItPMH"
      },
      "source": [
        "#from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import SensitivityAtSpecificity,SpecificityAtSensitivity,Recall,Precision\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=Adam(learning_rate=0.001),\n",
        "              metrics=['accuracy',SensitivityAtSpecificity(0.5),SpecificityAtSensitivity(0.5),Recall(0.5),Precision(0.5)]) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Q0MPMwh3EgY"
      },
      "source": [
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('val_accuracy')>0.99): \n",
        "      print(\"\\nReached 99% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "callbacks = myCallback()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7f6gDG3dx9sJ",
        "outputId": "06d0fc97-ce2a-4b17-fb52-7a74b719365e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "checkpoint = ModelCheckpoint(\"ECG_Spectrogram_Model.h5\", monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
        "\n",
        "history = model.fit(\n",
        "      train_generator,\n",
        "      steps_per_epoch=10,  \n",
        "      epochs=500,\n",
        "      verbose=1,\n",
        "      validation_data = validation_generator,\n",
        "      validation_steps=5,\n",
        "      callbacks = [callbacks,checkpoint]\n",
        ") "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6949 - accuracy: 0.4996 - sensitivity_at_specificity: 0.1486 - specificity_at_sensitivity: 0.2473 - recall: 0.1749 - precision: 0.4752\n",
            "Epoch 1: val_accuracy improved from -inf to 0.48281, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 18s 273ms/step - loss: 0.6949 - accuracy: 0.4996 - sensitivity_at_specificity: 0.1486 - specificity_at_sensitivity: 0.2473 - recall: 0.1749 - precision: 0.4752 - val_loss: 0.6937 - val_accuracy: 0.4828 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
            "Epoch 2/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6932 - accuracy: 0.5059 - sensitivity_at_specificity: 0.1112 - specificity_at_sensitivity: 0.0949 - recall: 0.1390 - precision: 0.5455\n",
            "Epoch 2: val_accuracy improved from 0.48281 to 0.62969, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 212ms/step - loss: 0.6932 - accuracy: 0.5059 - sensitivity_at_specificity: 0.1112 - specificity_at_sensitivity: 0.0949 - recall: 0.1390 - precision: 0.5455 - val_loss: 0.6934 - val_accuracy: 0.6297 - val_sensitivity_at_specificity: 0.0016 - val_specificity_at_sensitivity: 0.0000e+00 - val_recall: 0.8425 - val_precision: 0.5792\n",
            "Epoch 3/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6939 - accuracy: 0.5066 - sensitivity_at_specificity: 0.3289 - specificity_at_sensitivity: 0.1047 - recall: 0.3711 - precision: 0.5091\n",
            "Epoch 3: val_accuracy did not improve from 0.62969\n",
            "10/10 [==============================] - 2s 202ms/step - loss: 0.6939 - accuracy: 0.5066 - sensitivity_at_specificity: 0.3289 - specificity_at_sensitivity: 0.1047 - recall: 0.3711 - precision: 0.5091 - val_loss: 0.6937 - val_accuracy: 0.4867 - val_sensitivity_at_specificity: 0.0000e+00 - val_specificity_at_sensitivity: 0.0000e+00 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
            "Epoch 4/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6902 - accuracy: 0.5301 - sensitivity_at_specificity: 0.4097 - specificity_at_sensitivity: 0.3817 - recall: 0.4556 - precision: 0.5372\n",
            "Epoch 4: val_accuracy improved from 0.62969 to 0.63359, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 206ms/step - loss: 0.6902 - accuracy: 0.5301 - sensitivity_at_specificity: 0.4097 - specificity_at_sensitivity: 0.3817 - recall: 0.4556 - precision: 0.5372 - val_loss: 0.6788 - val_accuracy: 0.6336 - val_sensitivity_at_specificity: 0.2403 - val_specificity_at_sensitivity: 0.3732 - val_recall: 1.0000 - val_precision: 0.5790\n",
            "Epoch 5/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6477 - accuracy: 0.6324 - sensitivity_at_specificity: 0.7193 - specificity_at_sensitivity: 0.6562 - recall: 0.8235 - precision: 0.5973\n",
            "Epoch 5: val_accuracy improved from 0.63359 to 0.64688, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 209ms/step - loss: 0.6477 - accuracy: 0.6324 - sensitivity_at_specificity: 0.7193 - specificity_at_sensitivity: 0.6562 - recall: 0.8235 - precision: 0.5973 - val_loss: 0.6099 - val_accuracy: 0.6469 - val_sensitivity_at_specificity: 0.5435 - val_specificity_at_sensitivity: 0.6053 - val_recall: 1.0000 - val_precision: 0.5876\n",
            "Epoch 6/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5903 - accuracy: 0.6488 - sensitivity_at_specificity: 0.7254 - specificity_at_sensitivity: 0.6611 - recall: 0.9454 - precision: 0.5975\n",
            "Epoch 6: val_accuracy improved from 0.64688 to 0.66328, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 209ms/step - loss: 0.5903 - accuracy: 0.6488 - sensitivity_at_specificity: 0.7254 - specificity_at_sensitivity: 0.6611 - recall: 0.9454 - precision: 0.5975 - val_loss: 0.5787 - val_accuracy: 0.6633 - val_sensitivity_at_specificity: 0.7609 - val_specificity_at_sensitivity: 0.5818 - val_recall: 1.0000 - val_precision: 0.5991\n",
            "Epoch 7/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5904 - accuracy: 0.6461 - sensitivity_at_specificity: 0.6991 - specificity_at_sensitivity: 0.6146 - recall: 0.9898 - precision: 0.5852\n",
            "Epoch 7: val_accuracy improved from 0.66328 to 0.67500, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 208ms/step - loss: 0.5904 - accuracy: 0.6461 - sensitivity_at_specificity: 0.6991 - specificity_at_sensitivity: 0.6146 - recall: 0.9898 - precision: 0.5852 - val_loss: 0.5654 - val_accuracy: 0.6750 - val_sensitivity_at_specificity: 0.5269 - val_specificity_at_sensitivity: 0.7377 - val_recall: 1.0000 - val_precision: 0.6031\n",
            "Epoch 8/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5649 - accuracy: 0.6594 - sensitivity_at_specificity: 0.7729 - specificity_at_sensitivity: 0.6590 - recall: 0.9984 - precision: 0.5902\n",
            "Epoch 8: val_accuracy improved from 0.67500 to 0.67734, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 203ms/step - loss: 0.5649 - accuracy: 0.6594 - sensitivity_at_specificity: 0.7729 - specificity_at_sensitivity: 0.6590 - recall: 0.9984 - precision: 0.5902 - val_loss: 0.5653 - val_accuracy: 0.6773 - val_sensitivity_at_specificity: 0.7508 - val_specificity_at_sensitivity: 0.5749 - val_recall: 1.0000 - val_precision: 0.6172\n",
            "Epoch 9/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5719 - accuracy: 0.6570 - sensitivity_at_specificity: 0.7107 - specificity_at_sensitivity: 0.6584 - recall: 0.9882 - precision: 0.5929\n",
            "Epoch 9: val_accuracy did not improve from 0.67734\n",
            "10/10 [==============================] - 2s 190ms/step - loss: 0.5719 - accuracy: 0.6570 - sensitivity_at_specificity: 0.7107 - specificity_at_sensitivity: 0.6584 - recall: 0.9882 - precision: 0.5929 - val_loss: 0.5679 - val_accuracy: 0.6617 - val_sensitivity_at_specificity: 0.8328 - val_specificity_at_sensitivity: 0.7031 - val_recall: 1.0000 - val_precision: 0.5965\n",
            "Epoch 10/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5606 - accuracy: 0.6727 - sensitivity_at_specificity: 0.7454 - specificity_at_sensitivity: 0.6593 - recall: 1.0000 - precision: 0.6066\n",
            "Epoch 10: val_accuracy did not improve from 0.67734\n",
            "10/10 [==============================] - 2s 200ms/step - loss: 0.5606 - accuracy: 0.6727 - sensitivity_at_specificity: 0.7454 - specificity_at_sensitivity: 0.6593 - recall: 1.0000 - precision: 0.6066 - val_loss: 0.5767 - val_accuracy: 0.6352 - val_sensitivity_at_specificity: 0.7918 - val_specificity_at_sensitivity: 0.6881 - val_recall: 1.0000 - val_precision: 0.5664\n",
            "Epoch 11/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5611 - accuracy: 0.6645 - sensitivity_at_specificity: 0.7535 - specificity_at_sensitivity: 0.6408 - recall: 0.9688 - precision: 0.6026\n",
            "Epoch 11: val_accuracy did not improve from 0.67734\n",
            "10/10 [==============================] - 2s 200ms/step - loss: 0.5611 - accuracy: 0.6645 - sensitivity_at_specificity: 0.7535 - specificity_at_sensitivity: 0.6408 - recall: 0.9688 - precision: 0.6026 - val_loss: 0.5726 - val_accuracy: 0.6562 - val_sensitivity_at_specificity: 0.7736 - val_specificity_at_sensitivity: 0.7112 - val_recall: 1.0000 - val_precision: 0.5911\n",
            "Epoch 12/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5765 - accuracy: 0.6602 - sensitivity_at_specificity: 0.7049 - specificity_at_sensitivity: 0.6478 - recall: 1.0000 - precision: 0.5974\n",
            "Epoch 12: val_accuracy did not improve from 0.67734\n",
            "10/10 [==============================] - 2s 200ms/step - loss: 0.5765 - accuracy: 0.6602 - sensitivity_at_specificity: 0.7049 - specificity_at_sensitivity: 0.6478 - recall: 1.0000 - precision: 0.5974 - val_loss: 0.5774 - val_accuracy: 0.6594 - val_sensitivity_at_specificity: 0.3631 - val_specificity_at_sensitivity: 0.4399 - val_recall: 1.0000 - val_precision: 0.5944\n",
            "Epoch 13/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5680 - accuracy: 0.6590 - sensitivity_at_specificity: 0.7220 - specificity_at_sensitivity: 0.6434 - recall: 0.9643 - precision: 0.5945\n",
            "Epoch 13: val_accuracy did not improve from 0.67734\n",
            "10/10 [==============================] - 2s 202ms/step - loss: 0.5680 - accuracy: 0.6590 - sensitivity_at_specificity: 0.7220 - specificity_at_sensitivity: 0.6434 - recall: 0.9643 - precision: 0.5945 - val_loss: 0.5944 - val_accuracy: 0.6422 - val_sensitivity_at_specificity: 0.7580 - val_specificity_at_sensitivity: 0.5827 - val_recall: 1.0000 - val_precision: 0.5892\n",
            "Epoch 14/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5878 - accuracy: 0.6406 - sensitivity_at_specificity: 0.6614 - specificity_at_sensitivity: 0.6419 - recall: 0.9906 - precision: 0.5808\n",
            "Epoch 14: val_accuracy improved from 0.67734 to 0.67891, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 204ms/step - loss: 0.5878 - accuracy: 0.6406 - sensitivity_at_specificity: 0.6614 - specificity_at_sensitivity: 0.6419 - recall: 0.9906 - precision: 0.5808 - val_loss: 0.5697 - val_accuracy: 0.6789 - val_sensitivity_at_specificity: 0.4303 - val_specificity_at_sensitivity: 0.4968 - val_recall: 1.0000 - val_precision: 0.6162\n",
            "Epoch 15/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5641 - accuracy: 0.6648 - sensitivity_at_specificity: 0.7665 - specificity_at_sensitivity: 0.6830 - recall: 0.9835 - precision: 0.5999\n",
            "Epoch 15: val_accuracy did not improve from 0.67891\n",
            "10/10 [==============================] - 2s 198ms/step - loss: 0.5641 - accuracy: 0.6648 - sensitivity_at_specificity: 0.7665 - specificity_at_sensitivity: 0.6830 - recall: 0.9835 - precision: 0.5999 - val_loss: 0.5649 - val_accuracy: 0.6641 - val_sensitivity_at_specificity: 0.8565 - val_specificity_at_sensitivity: 0.6291 - val_recall: 1.0000 - val_precision: 0.5985\n",
            "Epoch 16/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5677 - accuracy: 0.6607 - sensitivity_at_specificity: 0.7331 - specificity_at_sensitivity: 0.6653 - recall: 1.0000 - precision: 0.5939\n",
            "Epoch 16: val_accuracy did not improve from 0.67891\n",
            "10/10 [==============================] - 2s 230ms/step - loss: 0.5677 - accuracy: 0.6607 - sensitivity_at_specificity: 0.7331 - specificity_at_sensitivity: 0.6653 - recall: 1.0000 - precision: 0.5939 - val_loss: 0.5649 - val_accuracy: 0.6742 - val_sensitivity_at_specificity: 0.7223 - val_specificity_at_sensitivity: 0.6312 - val_recall: 1.0000 - val_precision: 0.6125\n",
            "Epoch 17/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5636 - accuracy: 0.6641 - sensitivity_at_specificity: 0.7494 - specificity_at_sensitivity: 0.6675 - recall: 0.9938 - precision: 0.5998\n",
            "Epoch 17: val_accuracy did not improve from 0.67891\n",
            "10/10 [==============================] - 2s 200ms/step - loss: 0.5636 - accuracy: 0.6641 - sensitivity_at_specificity: 0.7494 - specificity_at_sensitivity: 0.6675 - recall: 0.9938 - precision: 0.5998 - val_loss: 0.5670 - val_accuracy: 0.6734 - val_sensitivity_at_specificity: 0.7209 - val_specificity_at_sensitivity: 0.5885 - val_recall: 1.0000 - val_precision: 0.6158\n",
            "Epoch 18/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5582 - accuracy: 0.6777 - sensitivity_at_specificity: 0.7249 - specificity_at_sensitivity: 0.6447 - recall: 1.0000 - precision: 0.6147\n",
            "Epoch 18: val_accuracy did not improve from 0.67891\n",
            "10/10 [==============================] - 2s 199ms/step - loss: 0.5582 - accuracy: 0.6777 - sensitivity_at_specificity: 0.7249 - specificity_at_sensitivity: 0.6447 - recall: 1.0000 - precision: 0.6147 - val_loss: 0.5575 - val_accuracy: 0.6758 - val_sensitivity_at_specificity: 0.8398 - val_specificity_at_sensitivity: 0.6704 - val_recall: 1.0000 - val_precision: 0.6100\n",
            "Epoch 19/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5585 - accuracy: 0.6727 - sensitivity_at_specificity: 0.7645 - specificity_at_sensitivity: 0.6735 - recall: 0.9985 - precision: 0.6073\n",
            "Epoch 19: val_accuracy did not improve from 0.67891\n",
            "10/10 [==============================] - 2s 198ms/step - loss: 0.5585 - accuracy: 0.6727 - sensitivity_at_specificity: 0.7645 - specificity_at_sensitivity: 0.6735 - recall: 0.9985 - precision: 0.6073 - val_loss: 0.5613 - val_accuracy: 0.6625 - val_sensitivity_at_specificity: 0.8544 - val_specificity_at_sensitivity: 0.6389 - val_recall: 1.0000 - val_precision: 0.5940\n",
            "Epoch 20/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5592 - accuracy: 0.6664 - sensitivity_at_specificity: 0.7547 - specificity_at_sensitivity: 0.6861 - recall: 1.0000 - precision: 0.5991\n",
            "Epoch 20: val_accuracy improved from 0.67891 to 0.68672, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 204ms/step - loss: 0.5592 - accuracy: 0.6664 - sensitivity_at_specificity: 0.7547 - specificity_at_sensitivity: 0.6861 - recall: 1.0000 - precision: 0.5991 - val_loss: 0.5578 - val_accuracy: 0.6867 - val_sensitivity_at_specificity: 0.7199 - val_specificity_at_sensitivity: 0.5886 - val_recall: 1.0000 - val_precision: 0.6297\n",
            "Epoch 21/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5670 - accuracy: 0.6539 - sensitivity_at_specificity: 0.7502 - specificity_at_sensitivity: 0.6331 - recall: 0.9879 - precision: 0.5846\n",
            "Epoch 21: val_accuracy did not improve from 0.68672\n",
            "10/10 [==============================] - 2s 199ms/step - loss: 0.5670 - accuracy: 0.6539 - sensitivity_at_specificity: 0.7502 - specificity_at_sensitivity: 0.6331 - recall: 0.9879 - precision: 0.5846 - val_loss: 0.5649 - val_accuracy: 0.6539 - val_sensitivity_at_specificity: 0.8328 - val_specificity_at_sensitivity: 0.6337 - val_recall: 1.0000 - val_precision: 0.5840\n",
            "Epoch 22/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5724 - accuracy: 0.6520 - sensitivity_at_specificity: 0.6875 - specificity_at_sensitivity: 0.6602 - recall: 0.9992 - precision: 0.5891\n",
            "Epoch 22: val_accuracy did not improve from 0.68672\n",
            "10/10 [==============================] - 2s 198ms/step - loss: 0.5724 - accuracy: 0.6520 - sensitivity_at_specificity: 0.6875 - specificity_at_sensitivity: 0.6602 - recall: 0.9992 - precision: 0.5891 - val_loss: 0.5650 - val_accuracy: 0.6508 - val_sensitivity_at_specificity: 0.8613 - val_specificity_at_sensitivity: 0.5879 - val_recall: 1.0000 - val_precision: 0.5811\n",
            "Epoch 23/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5475 - accuracy: 0.6770 - sensitivity_at_specificity: 0.7937 - specificity_at_sensitivity: 0.7027 - recall: 1.0000 - precision: 0.6047\n",
            "Epoch 23: val_accuracy did not improve from 0.68672\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 0.5475 - accuracy: 0.6770 - sensitivity_at_specificity: 0.7937 - specificity_at_sensitivity: 0.7027 - recall: 1.0000 - precision: 0.6047 - val_loss: 0.5625 - val_accuracy: 0.6602 - val_sensitivity_at_specificity: 0.8009 - val_specificity_at_sensitivity: 0.6584 - val_recall: 1.0000 - val_precision: 0.5927\n",
            "Epoch 24/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5609 - accuracy: 0.6750 - sensitivity_at_specificity: 0.7602 - specificity_at_sensitivity: 0.6522 - recall: 1.0000 - precision: 0.6130\n",
            "Epoch 24: val_accuracy did not improve from 0.68672\n",
            "10/10 [==============================] - 2s 200ms/step - loss: 0.5609 - accuracy: 0.6750 - sensitivity_at_specificity: 0.7602 - specificity_at_sensitivity: 0.6522 - recall: 1.0000 - precision: 0.6130 - val_loss: 0.5802 - val_accuracy: 0.6398 - val_sensitivity_at_specificity: 0.7846 - val_specificity_at_sensitivity: 0.6289 - val_recall: 1.0000 - val_precision: 0.5798\n",
            "Epoch 25/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5588 - accuracy: 0.6707 - sensitivity_at_specificity: 0.8136 - specificity_at_sensitivity: 0.6823 - recall: 1.0000 - precision: 0.6063\n",
            "Epoch 25: val_accuracy did not improve from 0.68672\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 0.5588 - accuracy: 0.6707 - sensitivity_at_specificity: 0.8136 - specificity_at_sensitivity: 0.6823 - recall: 1.0000 - precision: 0.6063 - val_loss: 0.5757 - val_accuracy: 0.6523 - val_sensitivity_at_specificity: 0.8233 - val_specificity_at_sensitivity: 0.6852 - val_recall: 1.0000 - val_precision: 0.5940\n",
            "Epoch 26/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5499 - accuracy: 0.6730 - sensitivity_at_specificity: 0.8063 - specificity_at_sensitivity: 0.6700 - recall: 1.0000 - precision: 0.6009\n",
            "Epoch 26: val_accuracy did not improve from 0.68672\n",
            "10/10 [==============================] - 2s 198ms/step - loss: 0.5499 - accuracy: 0.6730 - sensitivity_at_specificity: 0.8063 - specificity_at_sensitivity: 0.6700 - recall: 1.0000 - precision: 0.6009 - val_loss: 0.5564 - val_accuracy: 0.6672 - val_sensitivity_at_specificity: 0.8057 - val_specificity_at_sensitivity: 0.7311 - val_recall: 1.0000 - val_precision: 0.5977\n",
            "Epoch 27/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5646 - accuracy: 0.6688 - sensitivity_at_specificity: 0.7364 - specificity_at_sensitivity: 0.6504 - recall: 1.0000 - precision: 0.6073\n",
            "Epoch 27: val_accuracy did not improve from 0.68672\n",
            "10/10 [==============================] - 2s 192ms/step - loss: 0.5597 - accuracy: 0.6748 - sensitivity_at_specificity: 0.7419 - specificity_at_sensitivity: 0.6544 - recall: 1.0000 - precision: 0.6122 - val_loss: 0.5568 - val_accuracy: 0.6617 - val_sensitivity_at_specificity: 0.8246 - val_specificity_at_sensitivity: 0.7259 - val_recall: 1.0000 - val_precision: 0.5915\n",
            "Epoch 28/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5611 - accuracy: 0.6652 - sensitivity_at_specificity: 0.7933 - specificity_at_sensitivity: 0.7287 - recall: 1.0000 - precision: 0.6012\n",
            "Epoch 28: val_accuracy did not improve from 0.68672\n",
            "10/10 [==============================] - 2s 193ms/step - loss: 0.5611 - accuracy: 0.6652 - sensitivity_at_specificity: 0.7933 - specificity_at_sensitivity: 0.7287 - recall: 1.0000 - precision: 0.6012 - val_loss: 0.5524 - val_accuracy: 0.6766 - val_sensitivity_at_specificity: 0.8794 - val_specificity_at_sensitivity: 0.7125 - val_recall: 1.0000 - val_precision: 0.6098\n",
            "Epoch 29/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5768 - accuracy: 0.6523 - sensitivity_at_specificity: 0.7425 - specificity_at_sensitivity: 0.6651 - recall: 0.9811 - precision: 0.5900\n",
            "Epoch 29: val_accuracy did not improve from 0.68672\n",
            "10/10 [==============================] - 2s 197ms/step - loss: 0.5768 - accuracy: 0.6523 - sensitivity_at_specificity: 0.7425 - specificity_at_sensitivity: 0.6651 - recall: 0.9811 - precision: 0.5900 - val_loss: 0.5832 - val_accuracy: 0.6547 - val_sensitivity_at_specificity: 0.8152 - val_specificity_at_sensitivity: 0.6323 - val_recall: 1.0000 - val_precision: 0.5989\n",
            "Epoch 30/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5855 - accuracy: 0.6309 - sensitivity_at_specificity: 0.6784 - specificity_at_sensitivity: 0.5897 - recall: 0.9664 - precision: 0.5664\n",
            "Epoch 30: val_accuracy did not improve from 0.68672\n",
            "10/10 [==============================] - 2s 198ms/step - loss: 0.5855 - accuracy: 0.6309 - sensitivity_at_specificity: 0.6784 - specificity_at_sensitivity: 0.5897 - recall: 0.9664 - precision: 0.5664 - val_loss: 0.5997 - val_accuracy: 0.6172 - val_sensitivity_at_specificity: 0.2552 - val_specificity_at_sensitivity: 0.4962 - val_recall: 1.0000 - val_precision: 0.5597\n",
            "Epoch 31/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5818 - accuracy: 0.6395 - sensitivity_at_specificity: 0.7295 - specificity_at_sensitivity: 0.6941 - recall: 0.9984 - precision: 0.5746\n",
            "Epoch 31: val_accuracy did not improve from 0.68672\n",
            "10/10 [==============================] - 2s 200ms/step - loss: 0.5818 - accuracy: 0.6395 - sensitivity_at_specificity: 0.7295 - specificity_at_sensitivity: 0.6941 - recall: 0.9984 - precision: 0.5746 - val_loss: 0.5676 - val_accuracy: 0.6711 - val_sensitivity_at_specificity: 0.8589 - val_specificity_at_sensitivity: 0.6425 - val_recall: 1.0000 - val_precision: 0.6051\n",
            "Epoch 32/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5622 - accuracy: 0.6633 - sensitivity_at_specificity: 0.7586 - specificity_at_sensitivity: 0.6552 - recall: 0.9960 - precision: 0.5933\n",
            "Epoch 32: val_accuracy did not improve from 0.68672\n",
            "10/10 [==============================] - 2s 199ms/step - loss: 0.5622 - accuracy: 0.6633 - sensitivity_at_specificity: 0.7586 - specificity_at_sensitivity: 0.6552 - recall: 0.9960 - precision: 0.5933 - val_loss: 0.5596 - val_accuracy: 0.6555 - val_sensitivity_at_specificity: 0.7626 - val_specificity_at_sensitivity: 0.6226 - val_recall: 1.0000 - val_precision: 0.5824\n",
            "Epoch 33/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5599 - accuracy: 0.6633 - sensitivity_at_specificity: 0.7181 - specificity_at_sensitivity: 0.6510 - recall: 0.9968 - precision: 0.5912\n",
            "Epoch 33: val_accuracy did not improve from 0.68672\n",
            "10/10 [==============================] - 2s 200ms/step - loss: 0.5599 - accuracy: 0.6633 - sensitivity_at_specificity: 0.7181 - specificity_at_sensitivity: 0.6510 - recall: 0.9968 - precision: 0.5912 - val_loss: 0.5810 - val_accuracy: 0.6422 - val_sensitivity_at_specificity: 0.7895 - val_specificity_at_sensitivity: 0.6922 - val_recall: 1.0000 - val_precision: 0.5779\n",
            "Epoch 34/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5618 - accuracy: 0.6687 - sensitivity_at_specificity: 0.8034 - specificity_at_sensitivity: 0.6960 - recall: 1.0000 - precision: 0.6028\n",
            "Epoch 34: val_accuracy did not improve from 0.68672\n",
            "10/10 [==============================] - 2s 198ms/step - loss: 0.5618 - accuracy: 0.6687 - sensitivity_at_specificity: 0.8034 - specificity_at_sensitivity: 0.6960 - recall: 1.0000 - precision: 0.6028 - val_loss: 0.5800 - val_accuracy: 0.6508 - val_sensitivity_at_specificity: 0.8096 - val_specificity_at_sensitivity: 0.7256 - val_recall: 1.0000 - val_precision: 0.5910\n",
            "Epoch 35/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5607 - accuracy: 0.6750 - sensitivity_at_specificity: 0.7380 - specificity_at_sensitivity: 0.6568 - recall: 1.0000 - precision: 0.6121\n",
            "Epoch 35: val_accuracy did not improve from 0.68672\n",
            "10/10 [==============================] - 2s 193ms/step - loss: 0.5607 - accuracy: 0.6750 - sensitivity_at_specificity: 0.7380 - specificity_at_sensitivity: 0.6568 - recall: 1.0000 - precision: 0.6121 - val_loss: 0.5610 - val_accuracy: 0.6664 - val_sensitivity_at_specificity: 0.8439 - val_specificity_at_sensitivity: 0.6714 - val_recall: 1.0000 - val_precision: 0.6024\n",
            "Epoch 36/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5709 - accuracy: 0.6578 - sensitivity_at_specificity: 0.6972 - specificity_at_sensitivity: 0.6459 - recall: 0.9969 - precision: 0.5937\n",
            "Epoch 36: val_accuracy did not improve from 0.68672\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 0.5709 - accuracy: 0.6578 - sensitivity_at_specificity: 0.6972 - specificity_at_sensitivity: 0.6459 - recall: 0.9969 - precision: 0.5937 - val_loss: 0.5561 - val_accuracy: 0.6711 - val_sensitivity_at_specificity: 0.8152 - val_specificity_at_sensitivity: 0.5487 - val_recall: 1.0000 - val_precision: 0.6006\n",
            "Epoch 37/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5619 - accuracy: 0.6711 - sensitivity_at_specificity: 0.7381 - specificity_at_sensitivity: 0.6521 - recall: 1.0000 - precision: 0.6060\n",
            "Epoch 37: val_accuracy did not improve from 0.68672\n",
            "10/10 [==============================] - 2s 192ms/step - loss: 0.5619 - accuracy: 0.6711 - sensitivity_at_specificity: 0.7381 - specificity_at_sensitivity: 0.6521 - recall: 1.0000 - precision: 0.6060 - val_loss: 0.5598 - val_accuracy: 0.6664 - val_sensitivity_at_specificity: 0.8538 - val_specificity_at_sensitivity: 0.5978 - val_recall: 1.0000 - val_precision: 0.5983\n",
            "Epoch 38/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5628 - accuracy: 0.6680 - sensitivity_at_specificity: 0.7560 - specificity_at_sensitivity: 0.6648 - recall: 1.0000 - precision: 0.6037\n",
            "Epoch 38: val_accuracy did not improve from 0.68672\n",
            "10/10 [==============================] - 2s 197ms/step - loss: 0.5628 - accuracy: 0.6680 - sensitivity_at_specificity: 0.7560 - specificity_at_sensitivity: 0.6648 - recall: 1.0000 - precision: 0.6037 - val_loss: 0.5536 - val_accuracy: 0.6789 - val_sensitivity_at_specificity: 0.8364 - val_specificity_at_sensitivity: 0.6709 - val_recall: 1.0000 - val_precision: 0.6141\n",
            "Epoch 39/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5647 - accuracy: 0.6609 - sensitivity_at_specificity: 0.7482 - specificity_at_sensitivity: 0.6307 - recall: 1.0000 - precision: 0.5942\n",
            "Epoch 39: val_accuracy did not improve from 0.68672\n",
            "10/10 [==============================] - 2s 193ms/step - loss: 0.5647 - accuracy: 0.6609 - sensitivity_at_specificity: 0.7482 - specificity_at_sensitivity: 0.6307 - recall: 1.0000 - precision: 0.5942 - val_loss: 0.5594 - val_accuracy: 0.6727 - val_sensitivity_at_specificity: 0.8194 - val_specificity_at_sensitivity: 0.7104 - val_recall: 1.0000 - val_precision: 0.6073\n",
            "Epoch 40/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5667 - accuracy: 0.6574 - sensitivity_at_specificity: 0.6518 - specificity_at_sensitivity: 0.6579 - recall: 1.0000 - precision: 0.5910\n",
            "Epoch 40: val_accuracy did not improve from 0.68672\n",
            "10/10 [==============================] - 2s 193ms/step - loss: 0.5667 - accuracy: 0.6574 - sensitivity_at_specificity: 0.6518 - specificity_at_sensitivity: 0.6579 - recall: 1.0000 - precision: 0.5910 - val_loss: 0.5649 - val_accuracy: 0.6586 - val_sensitivity_at_specificity: 0.8341 - val_specificity_at_sensitivity: 0.6631 - val_recall: 1.0000 - val_precision: 0.5916\n",
            "Epoch 41/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5685 - accuracy: 0.6598 - sensitivity_at_specificity: 0.6744 - specificity_at_sensitivity: 0.6159 - recall: 1.0000 - precision: 0.5964\n",
            "Epoch 41: val_accuracy did not improve from 0.68672\n",
            "10/10 [==============================] - 2s 196ms/step - loss: 0.5685 - accuracy: 0.6598 - sensitivity_at_specificity: 0.6744 - specificity_at_sensitivity: 0.6159 - recall: 1.0000 - precision: 0.5964 - val_loss: 0.5581 - val_accuracy: 0.6648 - val_sensitivity_at_specificity: 0.8101 - val_specificity_at_sensitivity: 0.6590 - val_recall: 1.0000 - val_precision: 0.5957\n",
            "Epoch 42/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5620 - accuracy: 0.6625 - sensitivity_at_specificity: 0.7484 - specificity_at_sensitivity: 0.6475 - recall: 1.0000 - precision: 0.5955\n",
            "Epoch 42: val_accuracy did not improve from 0.68672\n",
            "10/10 [==============================] - 2s 195ms/step - loss: 0.5620 - accuracy: 0.6625 - sensitivity_at_specificity: 0.7484 - specificity_at_sensitivity: 0.6475 - recall: 1.0000 - precision: 0.5955 - val_loss: 0.5670 - val_accuracy: 0.6695 - val_sensitivity_at_specificity: 0.7641 - val_specificity_at_sensitivity: 0.5618 - val_recall: 1.0000 - val_precision: 0.6083\n",
            "Epoch 43/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5618 - accuracy: 0.6629 - sensitivity_at_specificity: 0.7690 - specificity_at_sensitivity: 0.6705 - recall: 1.0000 - precision: 0.5943\n",
            "Epoch 43: val_accuracy did not improve from 0.68672\n",
            "10/10 [==============================] - 2s 197ms/step - loss: 0.5618 - accuracy: 0.6629 - sensitivity_at_specificity: 0.7690 - specificity_at_sensitivity: 0.6705 - recall: 1.0000 - precision: 0.5943 - val_loss: 0.5593 - val_accuracy: 0.6617 - val_sensitivity_at_specificity: 0.8760 - val_specificity_at_sensitivity: 0.5899 - val_recall: 1.0000 - val_precision: 0.5923\n",
            "Epoch 44/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5554 - accuracy: 0.6742 - sensitivity_at_specificity: 0.7556 - specificity_at_sensitivity: 0.6404 - recall: 1.0000 - precision: 0.6072\n",
            "Epoch 44: val_accuracy did not improve from 0.68672\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 0.5554 - accuracy: 0.6742 - sensitivity_at_specificity: 0.7556 - specificity_at_sensitivity: 0.6404 - recall: 1.0000 - precision: 0.6072 - val_loss: 0.5590 - val_accuracy: 0.6602 - val_sensitivity_at_specificity: 0.8437 - val_specificity_at_sensitivity: 0.7305 - val_recall: 1.0000 - val_precision: 0.5904\n",
            "Epoch 45/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5544 - accuracy: 0.6734 - sensitivity_at_specificity: 0.7992 - specificity_at_sensitivity: 0.6808 - recall: 1.0000 - precision: 0.6058\n",
            "Epoch 45: val_accuracy did not improve from 0.68672\n",
            "10/10 [==============================] - 3s 276ms/step - loss: 0.5544 - accuracy: 0.6734 - sensitivity_at_specificity: 0.7992 - specificity_at_sensitivity: 0.6808 - recall: 1.0000 - precision: 0.6058 - val_loss: 0.5546 - val_accuracy: 0.6781 - val_sensitivity_at_specificity: 0.8615 - val_specificity_at_sensitivity: 0.6356 - val_recall: 1.0000 - val_precision: 0.6146\n",
            "Epoch 46/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5680 - accuracy: 0.6555 - sensitivity_at_specificity: 0.7720 - specificity_at_sensitivity: 0.6724 - recall: 1.0000 - precision: 0.5905\n",
            "Epoch 46: val_accuracy did not improve from 0.68672\n",
            "10/10 [==============================] - 2s 195ms/step - loss: 0.5680 - accuracy: 0.6555 - sensitivity_at_specificity: 0.7720 - specificity_at_sensitivity: 0.6724 - recall: 1.0000 - precision: 0.5905 - val_loss: 0.5436 - val_accuracy: 0.6797 - val_sensitivity_at_specificity: 0.9033 - val_specificity_at_sensitivity: 0.6703 - val_recall: 1.0000 - val_precision: 0.6061\n",
            "Epoch 47/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5578 - accuracy: 0.6746 - sensitivity_at_specificity: 0.7707 - specificity_at_sensitivity: 0.6967 - recall: 1.0000 - precision: 0.6102\n",
            "Epoch 47: val_accuracy did not improve from 0.68672\n",
            "10/10 [==============================] - 2s 196ms/step - loss: 0.5578 - accuracy: 0.6746 - sensitivity_at_specificity: 0.7707 - specificity_at_sensitivity: 0.6967 - recall: 1.0000 - precision: 0.6102 - val_loss: 0.5588 - val_accuracy: 0.6711 - val_sensitivity_at_specificity: 0.8046 - val_specificity_at_sensitivity: 0.7032 - val_recall: 1.0000 - val_precision: 0.6069\n",
            "Epoch 48/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5609 - accuracy: 0.6637 - sensitivity_at_specificity: 0.7419 - specificity_at_sensitivity: 0.6427 - recall: 0.9992 - precision: 0.5955\n",
            "Epoch 48: val_accuracy did not improve from 0.68672\n",
            "10/10 [==============================] - 2s 198ms/step - loss: 0.5609 - accuracy: 0.6637 - sensitivity_at_specificity: 0.7419 - specificity_at_sensitivity: 0.6427 - recall: 0.9992 - precision: 0.5955 - val_loss: 0.5471 - val_accuracy: 0.6820 - val_sensitivity_at_specificity: 0.8693 - val_specificity_at_sensitivity: 0.7690 - val_recall: 1.0000 - val_precision: 0.6094\n",
            "Epoch 49/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5532 - accuracy: 0.6711 - sensitivity_at_specificity: 0.8232 - specificity_at_sensitivity: 0.6667 - recall: 1.0000 - precision: 0.5996\n",
            "Epoch 49: val_accuracy did not improve from 0.68672\n",
            "10/10 [==============================] - 2s 196ms/step - loss: 0.5532 - accuracy: 0.6711 - sensitivity_at_specificity: 0.8232 - specificity_at_sensitivity: 0.6667 - recall: 1.0000 - precision: 0.5996 - val_loss: 0.5561 - val_accuracy: 0.6695 - val_sensitivity_at_specificity: 0.8660 - val_specificity_at_sensitivity: 0.7241 - val_recall: 1.0000 - val_precision: 0.6028\n",
            "Epoch 50/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5501 - accuracy: 0.6738 - sensitivity_at_specificity: 0.8039 - specificity_at_sensitivity: 0.7217 - recall: 0.9984 - precision: 0.6035\n",
            "Epoch 50: val_accuracy did not improve from 0.68672\n",
            "10/10 [==============================] - 2s 197ms/step - loss: 0.5501 - accuracy: 0.6738 - sensitivity_at_specificity: 0.8039 - specificity_at_sensitivity: 0.7217 - recall: 0.9984 - precision: 0.6035 - val_loss: 0.5701 - val_accuracy: 0.6578 - val_sensitivity_at_specificity: 0.7948 - val_specificity_at_sensitivity: 0.7480 - val_recall: 0.9969 - val_precision: 0.5989\n",
            "Epoch 51/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5522 - accuracy: 0.6715 - sensitivity_at_specificity: 0.8002 - specificity_at_sensitivity: 0.6873 - recall: 0.9914 - precision: 0.6048\n",
            "Epoch 51: val_accuracy did not improve from 0.68672\n",
            "10/10 [==============================] - 2s 196ms/step - loss: 0.5522 - accuracy: 0.6715 - sensitivity_at_specificity: 0.8002 - specificity_at_sensitivity: 0.6873 - recall: 0.9914 - precision: 0.6048 - val_loss: 0.5584 - val_accuracy: 0.6586 - val_sensitivity_at_specificity: 0.8583 - val_specificity_at_sensitivity: 0.7270 - val_recall: 1.0000 - val_precision: 0.5897\n",
            "Epoch 52/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5473 - accuracy: 0.6750 - sensitivity_at_specificity: 0.8057 - specificity_at_sensitivity: 0.7048 - recall: 0.9976 - precision: 0.6037\n",
            "Epoch 52: val_accuracy did not improve from 0.68672\n",
            "10/10 [==============================] - 2s 195ms/step - loss: 0.5473 - accuracy: 0.6750 - sensitivity_at_specificity: 0.8057 - specificity_at_sensitivity: 0.7048 - recall: 0.9976 - precision: 0.6037 - val_loss: 0.5567 - val_accuracy: 0.6539 - val_sensitivity_at_specificity: 0.8401 - val_specificity_at_sensitivity: 0.6837 - val_recall: 1.0000 - val_precision: 0.5805\n",
            "Epoch 53/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5685 - accuracy: 0.6418 - sensitivity_at_specificity: 0.7725 - specificity_at_sensitivity: 0.7042 - recall: 0.9765 - precision: 0.5759\n",
            "Epoch 53: val_accuracy did not improve from 0.68672\n",
            "10/10 [==============================] - 2s 196ms/step - loss: 0.5685 - accuracy: 0.6418 - sensitivity_at_specificity: 0.7725 - specificity_at_sensitivity: 0.7042 - recall: 0.9765 - precision: 0.5759 - val_loss: 0.5562 - val_accuracy: 0.6516 - val_sensitivity_at_specificity: 0.8020 - val_specificity_at_sensitivity: 0.7818 - val_recall: 0.9885 - val_precision: 0.5791\n",
            "Epoch 54/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5579 - accuracy: 0.6625 - sensitivity_at_specificity: 0.8027 - specificity_at_sensitivity: 0.7583 - recall: 0.9912 - precision: 0.5936\n",
            "Epoch 54: val_accuracy did not improve from 0.68672\n",
            "10/10 [==============================] - 2s 198ms/step - loss: 0.5579 - accuracy: 0.6625 - sensitivity_at_specificity: 0.8027 - specificity_at_sensitivity: 0.7583 - recall: 0.9912 - precision: 0.5936 - val_loss: 0.5568 - val_accuracy: 0.6656 - val_sensitivity_at_specificity: 0.8432 - val_specificity_at_sensitivity: 0.8050 - val_recall: 0.9410 - val_precision: 0.6084\n",
            "Epoch 55/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5649 - accuracy: 0.6524 - sensitivity_at_specificity: 0.8198 - specificity_at_sensitivity: 0.7251 - recall: 0.9635 - precision: 0.5940\n",
            "Epoch 55: val_accuracy did not improve from 0.68672\n",
            "10/10 [==============================] - 2s 190ms/step - loss: 0.5649 - accuracy: 0.6524 - sensitivity_at_specificity: 0.8198 - specificity_at_sensitivity: 0.7251 - recall: 0.9635 - precision: 0.5940 - val_loss: 0.5577 - val_accuracy: 0.6438 - val_sensitivity_at_specificity: 0.8664 - val_specificity_at_sensitivity: 0.8153 - val_recall: 0.9984 - val_precision: 0.5740\n",
            "Epoch 56/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5477 - accuracy: 0.6711 - sensitivity_at_specificity: 0.8277 - specificity_at_sensitivity: 0.7825 - recall: 0.9854 - precision: 0.6088\n",
            "Epoch 56: val_accuracy improved from 0.68672 to 0.69922, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 209ms/step - loss: 0.5477 - accuracy: 0.6711 - sensitivity_at_specificity: 0.8277 - specificity_at_sensitivity: 0.7825 - recall: 0.9854 - precision: 0.6088 - val_loss: 0.5265 - val_accuracy: 0.6992 - val_sensitivity_at_specificity: 0.8780 - val_specificity_at_sensitivity: 0.8214 - val_recall: 0.9759 - val_precision: 0.6372\n",
            "Epoch 57/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5351 - accuracy: 0.6801 - sensitivity_at_specificity: 0.8814 - specificity_at_sensitivity: 0.7829 - recall: 0.9656 - precision: 0.6198\n",
            "Epoch 57: val_accuracy did not improve from 0.69922\n",
            "10/10 [==============================] - 2s 202ms/step - loss: 0.5351 - accuracy: 0.6801 - sensitivity_at_specificity: 0.8814 - specificity_at_sensitivity: 0.7829 - recall: 0.9656 - precision: 0.6198 - val_loss: 0.5553 - val_accuracy: 0.6461 - val_sensitivity_at_specificity: 0.8707 - val_specificity_at_sensitivity: 0.8142 - val_recall: 0.9984 - val_precision: 0.5834\n",
            "Epoch 58/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5361 - accuracy: 0.6816 - sensitivity_at_specificity: 0.8628 - specificity_at_sensitivity: 0.8104 - recall: 0.9701 - precision: 0.6200\n",
            "Epoch 58: val_accuracy did not improve from 0.69922\n",
            "10/10 [==============================] - 2s 197ms/step - loss: 0.5361 - accuracy: 0.6816 - sensitivity_at_specificity: 0.8628 - specificity_at_sensitivity: 0.8104 - recall: 0.9701 - precision: 0.6200 - val_loss: 0.5301 - val_accuracy: 0.6883 - val_sensitivity_at_specificity: 0.8778 - val_specificity_at_sensitivity: 0.8276 - val_recall: 1.0000 - val_precision: 0.6271\n",
            "Epoch 59/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5455 - accuracy: 0.6605 - sensitivity_at_specificity: 0.8453 - specificity_at_sensitivity: 0.7914 - recall: 0.9953 - precision: 0.5962\n",
            "Epoch 59: val_accuracy did not improve from 0.69922\n",
            "10/10 [==============================] - 2s 193ms/step - loss: 0.5455 - accuracy: 0.6605 - sensitivity_at_specificity: 0.8453 - specificity_at_sensitivity: 0.7914 - recall: 0.9953 - precision: 0.5962 - val_loss: 0.5416 - val_accuracy: 0.6547 - val_sensitivity_at_specificity: 0.8499 - val_specificity_at_sensitivity: 0.8066 - val_recall: 0.9902 - val_precision: 0.5820\n",
            "Epoch 60/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5561 - accuracy: 0.6523 - sensitivity_at_specificity: 0.8076 - specificity_at_sensitivity: 0.7727 - recall: 0.9509 - precision: 0.5962\n",
            "Epoch 60: val_accuracy did not improve from 0.69922\n",
            "10/10 [==============================] - 2s 196ms/step - loss: 0.5561 - accuracy: 0.6523 - sensitivity_at_specificity: 0.8076 - specificity_at_sensitivity: 0.7727 - recall: 0.9509 - precision: 0.5962 - val_loss: 0.5336 - val_accuracy: 0.6953 - val_sensitivity_at_specificity: 0.8628 - val_specificity_at_sensitivity: 0.8237 - val_recall: 0.8720 - val_precision: 0.6515\n",
            "Epoch 61/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5354 - accuracy: 0.6898 - sensitivity_at_specificity: 0.8174 - specificity_at_sensitivity: 0.7913 - recall: 0.8227 - precision: 0.6583\n",
            "Epoch 61: val_accuracy did not improve from 0.69922\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 0.5354 - accuracy: 0.6898 - sensitivity_at_specificity: 0.8174 - specificity_at_sensitivity: 0.7913 - recall: 0.8227 - precision: 0.6583 - val_loss: 0.5473 - val_accuracy: 0.6914 - val_sensitivity_at_specificity: 0.8702 - val_specificity_at_sensitivity: 0.7888 - val_recall: 0.8885 - val_precision: 0.6438\n",
            "Epoch 62/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5295 - accuracy: 0.6883 - sensitivity_at_specificity: 0.8590 - specificity_at_sensitivity: 0.8263 - recall: 0.8874 - precision: 0.6401\n",
            "Epoch 62: val_accuracy improved from 0.69922 to 0.71016, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 207ms/step - loss: 0.5295 - accuracy: 0.6883 - sensitivity_at_specificity: 0.8590 - specificity_at_sensitivity: 0.8263 - recall: 0.8874 - precision: 0.6401 - val_loss: 0.5200 - val_accuracy: 0.7102 - val_sensitivity_at_specificity: 0.8592 - val_specificity_at_sensitivity: 0.8440 - val_recall: 0.8670 - val_precision: 0.6595\n",
            "Epoch 63/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5478 - accuracy: 0.6734 - sensitivity_at_specificity: 0.7187 - specificity_at_sensitivity: 0.7969 - recall: 0.7246 - precision: 0.6295\n",
            "Epoch 63: val_accuracy improved from 0.71016 to 0.71094, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 207ms/step - loss: 0.5478 - accuracy: 0.6734 - sensitivity_at_specificity: 0.7187 - specificity_at_sensitivity: 0.7969 - recall: 0.7246 - precision: 0.6295 - val_loss: 0.5323 - val_accuracy: 0.7109 - val_sensitivity_at_specificity: 0.7808 - val_specificity_at_sensitivity: 0.8305 - val_recall: 0.7872 - val_precision: 0.6749\n",
            "Epoch 64/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5350 - accuracy: 0.6832 - sensitivity_at_specificity: 0.8245 - specificity_at_sensitivity: 0.7997 - recall: 0.8315 - precision: 0.6418\n",
            "Epoch 64: val_accuracy did not improve from 0.71094\n",
            "10/10 [==============================] - 2s 202ms/step - loss: 0.5350 - accuracy: 0.6832 - sensitivity_at_specificity: 0.8245 - specificity_at_sensitivity: 0.7997 - recall: 0.8315 - precision: 0.6418 - val_loss: 0.5160 - val_accuracy: 0.7047 - val_sensitivity_at_specificity: 0.8912 - val_specificity_at_sensitivity: 0.8483 - val_recall: 0.9471 - val_precision: 0.6531\n",
            "Epoch 65/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5339 - accuracy: 0.6961 - sensitivity_at_specificity: 0.8544 - specificity_at_sensitivity: 0.8071 - recall: 0.8600 - precision: 0.6440\n",
            "Epoch 65: val_accuracy did not improve from 0.71094\n",
            "10/10 [==============================] - 2s 206ms/step - loss: 0.5339 - accuracy: 0.6961 - sensitivity_at_specificity: 0.8544 - specificity_at_sensitivity: 0.8071 - recall: 0.8600 - precision: 0.6440 - val_loss: 0.5281 - val_accuracy: 0.6898 - val_sensitivity_at_specificity: 0.8018 - val_specificity_at_sensitivity: 0.8288 - val_recall: 0.8048 - val_precision: 0.6650\n",
            "Epoch 66/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5390 - accuracy: 0.6775 - sensitivity_at_specificity: 0.8472 - specificity_at_sensitivity: 0.8052 - recall: 0.8534 - precision: 0.6279\n",
            "Epoch 66: val_accuracy did not improve from 0.71094\n",
            "10/10 [==============================] - 2s 194ms/step - loss: 0.5393 - accuracy: 0.6786 - sensitivity_at_specificity: 0.8453 - specificity_at_sensitivity: 0.8051 - recall: 0.8527 - precision: 0.6319 - val_loss: 0.5289 - val_accuracy: 0.7086 - val_sensitivity_at_specificity: 0.8167 - val_specificity_at_sensitivity: 0.7952 - val_recall: 0.8091 - val_precision: 0.6837\n",
            "Epoch 67/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5368 - accuracy: 0.7060 - sensitivity_at_specificity: 0.8148 - specificity_at_sensitivity: 0.8241 - recall: 0.8107 - precision: 0.6775\n",
            "Epoch 67: val_accuracy did not improve from 0.71094\n",
            "10/10 [==============================] - 2s 193ms/step - loss: 0.5368 - accuracy: 0.7060 - sensitivity_at_specificity: 0.8148 - specificity_at_sensitivity: 0.8241 - recall: 0.8107 - precision: 0.6775 - val_loss: 0.5350 - val_accuracy: 0.6930 - val_sensitivity_at_specificity: 0.8617 - val_specificity_at_sensitivity: 0.8040 - val_recall: 0.8199 - val_precision: 0.6448\n",
            "Epoch 68/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5310 - accuracy: 0.6883 - sensitivity_at_specificity: 0.8548 - specificity_at_sensitivity: 0.8302 - recall: 0.8789 - precision: 0.6471\n",
            "Epoch 68: val_accuracy did not improve from 0.71094\n",
            "10/10 [==============================] - 2s 205ms/step - loss: 0.5310 - accuracy: 0.6883 - sensitivity_at_specificity: 0.8548 - specificity_at_sensitivity: 0.8302 - recall: 0.8789 - precision: 0.6471 - val_loss: 0.5285 - val_accuracy: 0.7008 - val_sensitivity_at_specificity: 0.8567 - val_specificity_at_sensitivity: 0.8252 - val_recall: 0.8487 - val_precision: 0.6492\n",
            "Epoch 69/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5443 - accuracy: 0.6758 - sensitivity_at_specificity: 0.8218 - specificity_at_sensitivity: 0.8141 - recall: 0.8179 - precision: 0.6381\n",
            "Epoch 69: val_accuracy improved from 0.71094 to 0.71953, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 206ms/step - loss: 0.5443 - accuracy: 0.6758 - sensitivity_at_specificity: 0.8218 - specificity_at_sensitivity: 0.8141 - recall: 0.8179 - precision: 0.6381 - val_loss: 0.5053 - val_accuracy: 0.7195 - val_sensitivity_at_specificity: 0.8741 - val_specificity_at_sensitivity: 0.8467 - val_recall: 0.8726 - val_precision: 0.6799\n",
            "Epoch 70/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5352 - accuracy: 0.6859 - sensitivity_at_specificity: 0.8493 - specificity_at_sensitivity: 0.8212 - recall: 0.8562 - precision: 0.6450\n",
            "Epoch 70: val_accuracy did not improve from 0.71953\n",
            "10/10 [==============================] - 2s 202ms/step - loss: 0.5352 - accuracy: 0.6859 - sensitivity_at_specificity: 0.8493 - specificity_at_sensitivity: 0.8212 - recall: 0.8562 - precision: 0.6450 - val_loss: 0.5219 - val_accuracy: 0.6891 - val_sensitivity_at_specificity: 0.8228 - val_specificity_at_sensitivity: 0.8550 - val_recall: 0.8162 - val_precision: 0.6321\n",
            "Epoch 71/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5490 - accuracy: 0.6762 - sensitivity_at_specificity: 0.7472 - specificity_at_sensitivity: 0.7853 - recall: 0.7399 - precision: 0.6449\n",
            "Epoch 71: val_accuracy did not improve from 0.71953\n",
            "10/10 [==============================] - 2s 204ms/step - loss: 0.5490 - accuracy: 0.6762 - sensitivity_at_specificity: 0.7472 - specificity_at_sensitivity: 0.7853 - recall: 0.7399 - precision: 0.6449 - val_loss: 0.5266 - val_accuracy: 0.7055 - val_sensitivity_at_specificity: 0.8039 - val_specificity_at_sensitivity: 0.8220 - val_recall: 0.7942 - val_precision: 0.6622\n",
            "Epoch 72/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5215 - accuracy: 0.7072 - sensitivity_at_specificity: 0.8458 - specificity_at_sensitivity: 0.8319 - recall: 0.8391 - precision: 0.6645\n",
            "Epoch 72: val_accuracy did not improve from 0.71953\n",
            "10/10 [==============================] - 2s 195ms/step - loss: 0.5215 - accuracy: 0.7072 - sensitivity_at_specificity: 0.8458 - specificity_at_sensitivity: 0.8319 - recall: 0.8391 - precision: 0.6645 - val_loss: 0.5116 - val_accuracy: 0.7055 - val_sensitivity_at_specificity: 0.8693 - val_specificity_at_sensitivity: 0.8620 - val_recall: 0.8630 - val_precision: 0.6539\n",
            "Epoch 73/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5408 - accuracy: 0.6744 - sensitivity_at_specificity: 0.7447 - specificity_at_sensitivity: 0.8165 - recall: 0.7439 - precision: 0.6478\n",
            "Epoch 73: val_accuracy improved from 0.71953 to 0.72500, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 204ms/step - loss: 0.5408 - accuracy: 0.6744 - sensitivity_at_specificity: 0.7447 - specificity_at_sensitivity: 0.8165 - recall: 0.7439 - precision: 0.6478 - val_loss: 0.5258 - val_accuracy: 0.7250 - val_sensitivity_at_specificity: 0.9135 - val_specificity_at_sensitivity: 0.8308 - val_recall: 0.7099 - val_precision: 0.7215\n",
            "Epoch 74/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5384 - accuracy: 0.6703 - sensitivity_at_specificity: 0.7324 - specificity_at_sensitivity: 0.8002 - recall: 0.7263 - precision: 0.6648\n",
            "Epoch 74: val_accuracy did not improve from 0.72500\n",
            "10/10 [==============================] - 2s 204ms/step - loss: 0.5384 - accuracy: 0.6703 - sensitivity_at_specificity: 0.7324 - specificity_at_sensitivity: 0.8002 - recall: 0.7263 - precision: 0.6648 - val_loss: 0.5349 - val_accuracy: 0.6859 - val_sensitivity_at_specificity: 0.8578 - val_specificity_at_sensitivity: 0.8303 - val_recall: 0.8498 - val_precision: 0.6333\n",
            "Epoch 75/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5301 - accuracy: 0.6812 - sensitivity_at_specificity: 0.8481 - specificity_at_sensitivity: 0.8274 - recall: 0.8389 - precision: 0.6419\n",
            "Epoch 75: val_accuracy did not improve from 0.72500\n",
            "10/10 [==============================] - 2s 203ms/step - loss: 0.5301 - accuracy: 0.6812 - sensitivity_at_specificity: 0.8481 - specificity_at_sensitivity: 0.8274 - recall: 0.8389 - precision: 0.6419 - val_loss: 0.5276 - val_accuracy: 0.6930 - val_sensitivity_at_specificity: 0.8460 - val_specificity_at_sensitivity: 0.8536 - val_recall: 0.8361 - val_precision: 0.6320\n",
            "Epoch 76/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5096 - accuracy: 0.7105 - sensitivity_at_specificity: 0.8273 - specificity_at_sensitivity: 0.8545 - recall: 0.8202 - precision: 0.6697\n",
            "Epoch 76: val_accuracy did not improve from 0.72500\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 0.5096 - accuracy: 0.7105 - sensitivity_at_specificity: 0.8273 - specificity_at_sensitivity: 0.8545 - recall: 0.8202 - precision: 0.6697 - val_loss: 0.5143 - val_accuracy: 0.6977 - val_sensitivity_at_specificity: 0.8824 - val_specificity_at_sensitivity: 0.8489 - val_recall: 0.8871 - val_precision: 0.6425\n",
            "Epoch 77/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5258 - accuracy: 0.6992 - sensitivity_at_specificity: 0.8674 - specificity_at_sensitivity: 0.8401 - recall: 0.8602 - precision: 0.6458\n",
            "Epoch 77: val_accuracy did not improve from 0.72500\n",
            "10/10 [==============================] - 2s 199ms/step - loss: 0.5258 - accuracy: 0.6992 - sensitivity_at_specificity: 0.8674 - specificity_at_sensitivity: 0.8401 - recall: 0.8602 - precision: 0.6458 - val_loss: 0.5140 - val_accuracy: 0.7180 - val_sensitivity_at_specificity: 0.8138 - val_specificity_at_sensitivity: 0.8540 - val_recall: 0.8062 - val_precision: 0.6904\n",
            "Epoch 78/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5119 - accuracy: 0.7047 - sensitivity_at_specificity: 0.8022 - specificity_at_sensitivity: 0.8517 - recall: 0.7929 - precision: 0.6790\n",
            "Epoch 78: val_accuracy did not improve from 0.72500\n",
            "10/10 [==============================] - 2s 205ms/step - loss: 0.5119 - accuracy: 0.7047 - sensitivity_at_specificity: 0.8022 - specificity_at_sensitivity: 0.8517 - recall: 0.7929 - precision: 0.6790 - val_loss: 0.5203 - val_accuracy: 0.6867 - val_sensitivity_at_specificity: 0.8522 - val_specificity_at_sensitivity: 0.8717 - val_recall: 0.8455 - val_precision: 0.6230\n",
            "Epoch 79/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5547 - accuracy: 0.6727 - sensitivity_at_specificity: 0.8270 - specificity_at_sensitivity: 0.8109 - recall: 0.8206 - precision: 0.6267\n",
            "Epoch 79: val_accuracy did not improve from 0.72500\n",
            "10/10 [==============================] - 2s 196ms/step - loss: 0.5547 - accuracy: 0.6727 - sensitivity_at_specificity: 0.8270 - specificity_at_sensitivity: 0.8109 - recall: 0.8206 - precision: 0.6267 - val_loss: 0.5541 - val_accuracy: 0.6844 - val_sensitivity_at_specificity: 0.7447 - val_specificity_at_sensitivity: 0.8188 - val_recall: 0.7024 - val_precision: 0.6920\n",
            "Epoch 80/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5859 - accuracy: 0.5977 - sensitivity_at_specificity: 0.7500 - specificity_at_sensitivity: 0.6180 - recall: 0.4414 - precision: 0.6420\n",
            "Epoch 80: val_accuracy did not improve from 0.72500\n",
            "10/10 [==============================] - 2s 206ms/step - loss: 0.5859 - accuracy: 0.5977 - sensitivity_at_specificity: 0.7500 - specificity_at_sensitivity: 0.6180 - recall: 0.4414 - precision: 0.6420 - val_loss: 0.5523 - val_accuracy: 0.7039 - val_sensitivity_at_specificity: 0.8668 - val_specificity_at_sensitivity: 0.8038 - val_recall: 0.8560 - val_precision: 0.6623\n",
            "Epoch 81/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5468 - accuracy: 0.6711 - sensitivity_at_specificity: 0.8385 - specificity_at_sensitivity: 0.7537 - recall: 0.9086 - precision: 0.6136\n",
            "Epoch 81: val_accuracy did not improve from 0.72500\n",
            "10/10 [==============================] - 2s 199ms/step - loss: 0.5468 - accuracy: 0.6711 - sensitivity_at_specificity: 0.8385 - specificity_at_sensitivity: 0.7537 - recall: 0.9086 - precision: 0.6136 - val_loss: 0.5622 - val_accuracy: 0.6633 - val_sensitivity_at_specificity: 0.8391 - val_specificity_at_sensitivity: 0.7690 - val_recall: 0.8916 - val_precision: 0.5980\n",
            "Epoch 82/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5590 - accuracy: 0.6598 - sensitivity_at_specificity: 0.8133 - specificity_at_sensitivity: 0.7809 - recall: 0.8046 - precision: 0.6184\n",
            "Epoch 82: val_accuracy did not improve from 0.72500\n",
            "10/10 [==============================] - 2s 197ms/step - loss: 0.5590 - accuracy: 0.6598 - sensitivity_at_specificity: 0.8133 - specificity_at_sensitivity: 0.7809 - recall: 0.8046 - precision: 0.6184 - val_loss: 0.5343 - val_accuracy: 0.6805 - val_sensitivity_at_specificity: 0.8114 - val_specificity_at_sensitivity: 0.7935 - val_recall: 0.8003 - val_precision: 0.6409\n",
            "Epoch 83/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5236 - accuracy: 0.6859 - sensitivity_at_specificity: 0.7865 - specificity_at_sensitivity: 0.8100 - recall: 0.7825 - precision: 0.6490\n",
            "Epoch 83: val_accuracy did not improve from 0.72500\n",
            "10/10 [==============================] - 2s 197ms/step - loss: 0.5236 - accuracy: 0.6859 - sensitivity_at_specificity: 0.7865 - specificity_at_sensitivity: 0.8100 - recall: 0.7825 - precision: 0.6490 - val_loss: 0.5260 - val_accuracy: 0.6938 - val_sensitivity_at_specificity: 0.7617 - val_specificity_at_sensitivity: 0.8041 - val_recall: 0.7539 - val_precision: 0.6741\n",
            "Epoch 84/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5415 - accuracy: 0.6801 - sensitivity_at_specificity: 0.8163 - specificity_at_sensitivity: 0.8064 - recall: 0.8077 - precision: 0.6432\n",
            "Epoch 84: val_accuracy did not improve from 0.72500\n",
            "10/10 [==============================] - 2s 199ms/step - loss: 0.5415 - accuracy: 0.6801 - sensitivity_at_specificity: 0.8163 - specificity_at_sensitivity: 0.8064 - recall: 0.8077 - precision: 0.6432 - val_loss: 0.5196 - val_accuracy: 0.7109 - val_sensitivity_at_specificity: 0.8493 - val_specificity_at_sensitivity: 0.8258 - val_recall: 0.8430 - val_precision: 0.6654\n",
            "Epoch 85/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5369 - accuracy: 0.6785 - sensitivity_at_specificity: 0.7992 - specificity_at_sensitivity: 0.8122 - recall: 0.7888 - precision: 0.6382\n",
            "Epoch 85: val_accuracy did not improve from 0.72500\n",
            "10/10 [==============================] - 2s 200ms/step - loss: 0.5369 - accuracy: 0.6785 - sensitivity_at_specificity: 0.7992 - specificity_at_sensitivity: 0.8122 - recall: 0.7888 - precision: 0.6382 - val_loss: 0.5135 - val_accuracy: 0.7156 - val_sensitivity_at_specificity: 0.7833 - val_specificity_at_sensitivity: 0.8675 - val_recall: 0.7771 - val_precision: 0.6953\n",
            "Epoch 86/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5341 - accuracy: 0.6836 - sensitivity_at_specificity: 0.7981 - specificity_at_sensitivity: 0.8097 - recall: 0.7904 - precision: 0.6534\n",
            "Epoch 86: val_accuracy did not improve from 0.72500\n",
            "10/10 [==============================] - 2s 203ms/step - loss: 0.5341 - accuracy: 0.6836 - sensitivity_at_specificity: 0.7981 - specificity_at_sensitivity: 0.8097 - recall: 0.7904 - precision: 0.6534 - val_loss: 0.5302 - val_accuracy: 0.7063 - val_sensitivity_at_specificity: 0.8447 - val_specificity_at_sensitivity: 0.8278 - val_recall: 0.8350 - val_precision: 0.6532\n",
            "Epoch 87/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5396 - accuracy: 0.6801 - sensitivity_at_specificity: 0.8269 - specificity_at_sensitivity: 0.8316 - recall: 0.8220 - precision: 0.6291\n",
            "Epoch 87: val_accuracy did not improve from 0.72500\n",
            "10/10 [==============================] - 2s 205ms/step - loss: 0.5396 - accuracy: 0.6801 - sensitivity_at_specificity: 0.8269 - specificity_at_sensitivity: 0.8316 - recall: 0.8220 - precision: 0.6291 - val_loss: 0.5394 - val_accuracy: 0.6703 - val_sensitivity_at_specificity: 0.7722 - val_specificity_at_sensitivity: 0.8290 - val_recall: 0.7641 - val_precision: 0.6315\n",
            "Epoch 88/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5275 - accuracy: 0.6906 - sensitivity_at_specificity: 0.7853 - specificity_at_sensitivity: 0.8090 - recall: 0.7739 - precision: 0.6713\n",
            "Epoch 88: val_accuracy did not improve from 0.72500\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 0.5275 - accuracy: 0.6906 - sensitivity_at_specificity: 0.7853 - specificity_at_sensitivity: 0.8090 - recall: 0.7739 - precision: 0.6713 - val_loss: 0.5148 - val_accuracy: 0.7180 - val_sensitivity_at_specificity: 0.8153 - val_specificity_at_sensitivity: 0.8681 - val_recall: 0.8078 - val_precision: 0.6978\n",
            "Epoch 89/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5292 - accuracy: 0.6910 - sensitivity_at_specificity: 0.8357 - specificity_at_sensitivity: 0.8220 - recall: 0.8279 - precision: 0.6524\n",
            "Epoch 89: val_accuracy did not improve from 0.72500\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 0.5292 - accuracy: 0.6910 - sensitivity_at_specificity: 0.8357 - specificity_at_sensitivity: 0.8220 - recall: 0.8279 - precision: 0.6524 - val_loss: 0.5269 - val_accuracy: 0.6836 - val_sensitivity_at_specificity: 0.8129 - val_specificity_at_sensitivity: 0.8212 - val_recall: 0.8048 - val_precision: 0.6373\n",
            "Epoch 90/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5386 - accuracy: 0.6691 - sensitivity_at_specificity: 0.7885 - specificity_at_sensitivity: 0.8159 - recall: 0.7790 - precision: 0.6351\n",
            "Epoch 90: val_accuracy did not improve from 0.72500\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 0.5386 - accuracy: 0.6691 - sensitivity_at_specificity: 0.7885 - specificity_at_sensitivity: 0.8159 - recall: 0.7790 - precision: 0.6351 - val_loss: 0.5092 - val_accuracy: 0.7234 - val_sensitivity_at_specificity: 0.9097 - val_specificity_at_sensitivity: 0.8574 - val_recall: 0.8349 - val_precision: 0.6837\n",
            "Epoch 91/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5430 - accuracy: 0.6668 - sensitivity_at_specificity: 0.7860 - specificity_at_sensitivity: 0.8058 - recall: 0.7772 - precision: 0.6303\n",
            "Epoch 91: val_accuracy did not improve from 0.72500\n",
            "10/10 [==============================] - 2s 195ms/step - loss: 0.5430 - accuracy: 0.6668 - sensitivity_at_specificity: 0.7860 - specificity_at_sensitivity: 0.8058 - recall: 0.7772 - precision: 0.6303 - val_loss: 0.5291 - val_accuracy: 0.6758 - val_sensitivity_at_specificity: 0.8059 - val_specificity_at_sensitivity: 0.8159 - val_recall: 0.7887 - val_precision: 0.6429\n",
            "Epoch 92/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5270 - accuracy: 0.6879 - sensitivity_at_specificity: 0.7925 - specificity_at_sensitivity: 0.8135 - recall: 0.7811 - precision: 0.6667\n",
            "Epoch 92: val_accuracy did not improve from 0.72500\n",
            "10/10 [==============================] - 2s 199ms/step - loss: 0.5270 - accuracy: 0.6879 - sensitivity_at_specificity: 0.7925 - specificity_at_sensitivity: 0.8135 - recall: 0.7811 - precision: 0.6667 - val_loss: 0.5351 - val_accuracy: 0.6930 - val_sensitivity_at_specificity: 0.8019 - val_specificity_at_sensitivity: 0.8276 - val_recall: 0.7940 - val_precision: 0.6584\n",
            "Epoch 93/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5367 - accuracy: 0.6914 - sensitivity_at_specificity: 0.8240 - specificity_at_sensitivity: 0.8205 - recall: 0.8178 - precision: 0.6538\n",
            "Epoch 93: val_accuracy did not improve from 0.72500\n",
            "10/10 [==============================] - 2s 197ms/step - loss: 0.5367 - accuracy: 0.6914 - sensitivity_at_specificity: 0.8240 - specificity_at_sensitivity: 0.8205 - recall: 0.8178 - precision: 0.6538 - val_loss: 0.5307 - val_accuracy: 0.6859 - val_sensitivity_at_specificity: 0.8391 - val_specificity_at_sensitivity: 0.8359 - val_recall: 0.8328 - val_precision: 0.6408\n",
            "Epoch 94/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5268 - accuracy: 0.6855 - sensitivity_at_specificity: 0.7834 - specificity_at_sensitivity: 0.8205 - recall: 0.7717 - precision: 0.6580\n",
            "Epoch 94: val_accuracy did not improve from 0.72500\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 0.5268 - accuracy: 0.6855 - sensitivity_at_specificity: 0.7834 - specificity_at_sensitivity: 0.8205 - recall: 0.7717 - precision: 0.6580 - val_loss: 0.5199 - val_accuracy: 0.7039 - val_sensitivity_at_specificity: 0.8475 - val_specificity_at_sensitivity: 0.8634 - val_recall: 0.8381 - val_precision: 0.6588\n",
            "Epoch 95/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5391 - accuracy: 0.6848 - sensitivity_at_specificity: 0.7909 - specificity_at_sensitivity: 0.8098 - recall: 0.7823 - precision: 0.6538\n",
            "Epoch 95: val_accuracy did not improve from 0.72500\n",
            "10/10 [==============================] - 2s 199ms/step - loss: 0.5391 - accuracy: 0.6848 - sensitivity_at_specificity: 0.7909 - specificity_at_sensitivity: 0.8098 - recall: 0.7823 - precision: 0.6538 - val_loss: 0.5239 - val_accuracy: 0.7055 - val_sensitivity_at_specificity: 0.8451 - val_specificity_at_sensitivity: 0.8424 - val_recall: 0.8388 - val_precision: 0.6617\n",
            "Epoch 96/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5430 - accuracy: 0.6794 - sensitivity_at_specificity: 0.8274 - specificity_at_sensitivity: 0.8232 - recall: 0.8195 - precision: 0.6246\n",
            "Epoch 96: val_accuracy did not improve from 0.72500\n",
            "10/10 [==============================] - 2s 194ms/step - loss: 0.5430 - accuracy: 0.6794 - sensitivity_at_specificity: 0.8274 - specificity_at_sensitivity: 0.8232 - recall: 0.8195 - precision: 0.6246 - val_loss: 0.5271 - val_accuracy: 0.6906 - val_sensitivity_at_specificity: 0.8282 - val_specificity_at_sensitivity: 0.8386 - val_recall: 0.7942 - val_precision: 0.6456\n",
            "Epoch 97/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5298 - accuracy: 0.6859 - sensitivity_at_specificity: 0.7428 - specificity_at_sensitivity: 0.8290 - recall: 0.7197 - precision: 0.6667\n",
            "Epoch 97: val_accuracy did not improve from 0.72500\n",
            "10/10 [==============================] - 2s 200ms/step - loss: 0.5298 - accuracy: 0.6859 - sensitivity_at_specificity: 0.7428 - specificity_at_sensitivity: 0.8290 - recall: 0.7197 - precision: 0.6667 - val_loss: 0.5213 - val_accuracy: 0.6945 - val_sensitivity_at_specificity: 0.7863 - val_specificity_at_sensitivity: 0.8246 - val_recall: 0.7700 - val_precision: 0.6537\n",
            "Epoch 98/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5204 - accuracy: 0.7066 - sensitivity_at_specificity: 0.8204 - specificity_at_sensitivity: 0.8480 - recall: 0.8046 - precision: 0.6686\n",
            "Epoch 98: val_accuracy did not improve from 0.72500\n",
            "10/10 [==============================] - 2s 199ms/step - loss: 0.5204 - accuracy: 0.7066 - sensitivity_at_specificity: 0.8204 - specificity_at_sensitivity: 0.8480 - recall: 0.8046 - precision: 0.6686 - val_loss: 0.5413 - val_accuracy: 0.6945 - val_sensitivity_at_specificity: 0.8114 - val_specificity_at_sensitivity: 0.8012 - val_recall: 0.7987 - val_precision: 0.6562\n",
            "Epoch 99/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5217 - accuracy: 0.6914 - sensitivity_at_specificity: 0.7477 - specificity_at_sensitivity: 0.8222 - recall: 0.7354 - precision: 0.6819\n",
            "Epoch 99: val_accuracy did not improve from 0.72500\n",
            "10/10 [==============================] - 2s 198ms/step - loss: 0.5217 - accuracy: 0.6914 - sensitivity_at_specificity: 0.7477 - specificity_at_sensitivity: 0.8222 - recall: 0.7354 - precision: 0.6819 - val_loss: 0.5318 - val_accuracy: 0.6836 - val_sensitivity_at_specificity: 0.7405 - val_specificity_at_sensitivity: 0.8102 - val_recall: 0.7199 - val_precision: 0.6662\n",
            "Epoch 100/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5424 - accuracy: 0.6828 - sensitivity_at_specificity: 0.8028 - specificity_at_sensitivity: 0.8375 - recall: 0.7839 - precision: 0.6488\n",
            "Epoch 100: val_accuracy did not improve from 0.72500\n",
            "10/10 [==============================] - 2s 202ms/step - loss: 0.5424 - accuracy: 0.6828 - sensitivity_at_specificity: 0.8028 - specificity_at_sensitivity: 0.8375 - recall: 0.7839 - precision: 0.6488 - val_loss: 0.5115 - val_accuracy: 0.6961 - val_sensitivity_at_specificity: 0.7937 - val_specificity_at_sensitivity: 0.8462 - val_recall: 0.7746 - val_precision: 0.6639\n",
            "Epoch 101/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5253 - accuracy: 0.6918 - sensitivity_at_specificity: 0.8382 - specificity_at_sensitivity: 0.8383 - recall: 0.7145 - precision: 0.6774\n",
            "Epoch 101: val_accuracy did not improve from 0.72500\n",
            "10/10 [==============================] - 3s 259ms/step - loss: 0.5253 - accuracy: 0.6918 - sensitivity_at_specificity: 0.8382 - specificity_at_sensitivity: 0.8383 - recall: 0.7145 - precision: 0.6774 - val_loss: 0.5373 - val_accuracy: 0.6961 - val_sensitivity_at_specificity: 0.7951 - val_specificity_at_sensitivity: 0.8060 - val_recall: 0.7740 - val_precision: 0.6556\n",
            "Epoch 102/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5167 - accuracy: 0.6984 - sensitivity_at_specificity: 0.8027 - specificity_at_sensitivity: 0.8407 - recall: 0.7861 - precision: 0.6802\n",
            "Epoch 102: val_accuracy did not improve from 0.72500\n",
            "10/10 [==============================] - 2s 217ms/step - loss: 0.5167 - accuracy: 0.6984 - sensitivity_at_specificity: 0.8027 - specificity_at_sensitivity: 0.8407 - recall: 0.7861 - precision: 0.6802 - val_loss: 0.5127 - val_accuracy: 0.7039 - val_sensitivity_at_specificity: 0.8316 - val_specificity_at_sensitivity: 0.8519 - val_recall: 0.8194 - val_precision: 0.6750\n",
            "Epoch 103/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5314 - accuracy: 0.6781 - sensitivity_at_specificity: 0.7782 - specificity_at_sensitivity: 0.8039 - recall: 0.7525 - precision: 0.6667\n",
            "Epoch 103: val_accuracy did not improve from 0.72500\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 0.5314 - accuracy: 0.6781 - sensitivity_at_specificity: 0.7782 - specificity_at_sensitivity: 0.8039 - recall: 0.7525 - precision: 0.6667 - val_loss: 0.5259 - val_accuracy: 0.7141 - val_sensitivity_at_specificity: 0.7763 - val_specificity_at_sensitivity: 0.8347 - val_recall: 0.7565 - val_precision: 0.7070\n",
            "Epoch 104/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5122 - accuracy: 0.7004 - sensitivity_at_specificity: 0.7807 - specificity_at_sensitivity: 0.8621 - recall: 0.7619 - precision: 0.6915\n",
            "Epoch 104: val_accuracy did not improve from 0.72500\n",
            "10/10 [==============================] - 2s 205ms/step - loss: 0.5122 - accuracy: 0.7004 - sensitivity_at_specificity: 0.7807 - specificity_at_sensitivity: 0.8621 - recall: 0.7619 - precision: 0.6915 - val_loss: 0.5126 - val_accuracy: 0.7078 - val_sensitivity_at_specificity: 0.8898 - val_specificity_at_sensitivity: 0.8791 - val_recall: 0.8819 - val_precision: 0.6519\n",
            "Epoch 105/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5178 - accuracy: 0.6852 - sensitivity_at_specificity: 0.8688 - specificity_at_sensitivity: 0.8361 - recall: 0.8075 - precision: 0.6469\n",
            "Epoch 105: val_accuracy did not improve from 0.72500\n",
            "10/10 [==============================] - 2s 212ms/step - loss: 0.5178 - accuracy: 0.6852 - sensitivity_at_specificity: 0.8688 - specificity_at_sensitivity: 0.8361 - recall: 0.8075 - precision: 0.6469 - val_loss: 0.5188 - val_accuracy: 0.7039 - val_sensitivity_at_specificity: 0.8390 - val_specificity_at_sensitivity: 0.8646 - val_recall: 0.8221 - val_precision: 0.6708\n",
            "Epoch 106/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5140 - accuracy: 0.6871 - sensitivity_at_specificity: 0.7752 - specificity_at_sensitivity: 0.8559 - recall: 0.7512 - precision: 0.6687\n",
            "Epoch 106: val_accuracy did not improve from 0.72500\n",
            "10/10 [==============================] - 2s 205ms/step - loss: 0.5140 - accuracy: 0.6871 - sensitivity_at_specificity: 0.7752 - specificity_at_sensitivity: 0.8559 - recall: 0.7512 - precision: 0.6687 - val_loss: 0.5245 - val_accuracy: 0.6844 - val_sensitivity_at_specificity: 0.8035 - val_specificity_at_sensitivity: 0.8413 - val_recall: 0.7845 - val_precision: 0.6488\n",
            "Epoch 107/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5239 - accuracy: 0.6906 - sensitivity_at_specificity: 0.8524 - specificity_at_sensitivity: 0.8523 - recall: 0.7284 - precision: 0.6754\n",
            "Epoch 107: val_accuracy did not improve from 0.72500\n",
            "10/10 [==============================] - 2s 200ms/step - loss: 0.5239 - accuracy: 0.6906 - sensitivity_at_specificity: 0.8524 - specificity_at_sensitivity: 0.8523 - recall: 0.7284 - precision: 0.6754 - val_loss: 0.5117 - val_accuracy: 0.7195 - val_sensitivity_at_specificity: 0.8877 - val_specificity_at_sensitivity: 0.8660 - val_recall: 0.7784 - val_precision: 0.7114\n",
            "Epoch 108/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5256 - accuracy: 0.6863 - sensitivity_at_specificity: 0.7542 - specificity_at_sensitivity: 0.8345 - recall: 0.7286 - precision: 0.6623\n",
            "Epoch 108: val_accuracy did not improve from 0.72500\n",
            "10/10 [==============================] - 2s 203ms/step - loss: 0.5256 - accuracy: 0.6863 - sensitivity_at_specificity: 0.7542 - specificity_at_sensitivity: 0.8345 - recall: 0.7286 - precision: 0.6623 - val_loss: 0.5119 - val_accuracy: 0.6938 - val_sensitivity_at_specificity: 0.7656 - val_specificity_at_sensitivity: 0.8422 - val_recall: 0.7281 - val_precision: 0.6813\n",
            "Epoch 109/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5126 - accuracy: 0.7043 - sensitivity_at_specificity: 0.8306 - specificity_at_sensitivity: 0.8626 - recall: 0.8070 - precision: 0.6559\n",
            "Epoch 109: val_accuracy did not improve from 0.72500\n",
            "10/10 [==============================] - 2s 207ms/step - loss: 0.5126 - accuracy: 0.7043 - sensitivity_at_specificity: 0.8306 - specificity_at_sensitivity: 0.8626 - recall: 0.8070 - precision: 0.6559 - val_loss: 0.5024 - val_accuracy: 0.7148 - val_sensitivity_at_specificity: 0.8351 - val_specificity_at_sensitivity: 0.8752 - val_recall: 0.8214 - val_precision: 0.6845\n",
            "Epoch 110/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5061 - accuracy: 0.7000 - sensitivity_at_specificity: 0.8904 - specificity_at_sensitivity: 0.8607 - recall: 0.7405 - precision: 0.6814\n",
            "Epoch 110: val_accuracy did not improve from 0.72500\n",
            "10/10 [==============================] - 2s 206ms/step - loss: 0.5061 - accuracy: 0.7000 - sensitivity_at_specificity: 0.8904 - specificity_at_sensitivity: 0.8607 - recall: 0.7405 - precision: 0.6814 - val_loss: 0.5157 - val_accuracy: 0.7063 - val_sensitivity_at_specificity: 0.8736 - val_specificity_at_sensitivity: 0.8563 - val_recall: 0.6761 - val_precision: 0.7145\n",
            "Epoch 111/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5093 - accuracy: 0.7086 - sensitivity_at_specificity: 0.8624 - specificity_at_sensitivity: 0.8767 - recall: 0.7326 - precision: 0.6987\n",
            "Epoch 111: val_accuracy did not improve from 0.72500\n",
            "10/10 [==============================] - 2s 202ms/step - loss: 0.5093 - accuracy: 0.7086 - sensitivity_at_specificity: 0.8624 - specificity_at_sensitivity: 0.8767 - recall: 0.7326 - precision: 0.6987 - val_loss: 0.4969 - val_accuracy: 0.7250 - val_sensitivity_at_specificity: 0.9103 - val_specificity_at_sensitivity: 0.8730 - val_recall: 0.7964 - val_precision: 0.7062\n",
            "Epoch 112/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5058 - accuracy: 0.7102 - sensitivity_at_specificity: 0.8844 - specificity_at_sensitivity: 0.8665 - recall: 0.7193 - precision: 0.7038\n",
            "Epoch 112: val_accuracy improved from 0.72500 to 0.73359, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 206ms/step - loss: 0.5058 - accuracy: 0.7102 - sensitivity_at_specificity: 0.8844 - specificity_at_sensitivity: 0.8665 - recall: 0.7193 - precision: 0.7038 - val_loss: 0.4955 - val_accuracy: 0.7336 - val_sensitivity_at_specificity: 0.8458 - val_specificity_at_sensitivity: 0.8992 - val_recall: 0.7313 - val_precision: 0.7438\n",
            "Epoch 113/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5169 - accuracy: 0.6898 - sensitivity_at_specificity: 0.8540 - specificity_at_sensitivity: 0.8643 - recall: 0.7322 - precision: 0.6875\n",
            "Epoch 113: val_accuracy did not improve from 0.73359\n",
            "10/10 [==============================] - 2s 204ms/step - loss: 0.5169 - accuracy: 0.6898 - sensitivity_at_specificity: 0.8540 - specificity_at_sensitivity: 0.8643 - recall: 0.7322 - precision: 0.6875 - val_loss: 0.5062 - val_accuracy: 0.7078 - val_sensitivity_at_specificity: 0.9091 - val_specificity_at_sensitivity: 0.8729 - val_recall: 0.7815 - val_precision: 0.6740\n",
            "Epoch 114/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5040 - accuracy: 0.7078 - sensitivity_at_specificity: 0.8871 - specificity_at_sensitivity: 0.8668 - recall: 0.7641 - precision: 0.6857\n",
            "Epoch 114: val_accuracy did not improve from 0.73359\n",
            "10/10 [==============================] - 2s 200ms/step - loss: 0.5040 - accuracy: 0.7078 - sensitivity_at_specificity: 0.8871 - specificity_at_sensitivity: 0.8668 - recall: 0.7641 - precision: 0.6857 - val_loss: 0.4976 - val_accuracy: 0.7273 - val_sensitivity_at_specificity: 0.8933 - val_specificity_at_sensitivity: 0.8850 - val_recall: 0.7818 - val_precision: 0.6984\n",
            "Epoch 115/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5083 - accuracy: 0.6973 - sensitivity_at_specificity: 0.8884 - specificity_at_sensitivity: 0.8802 - recall: 0.7339 - precision: 0.6921\n",
            "Epoch 115: val_accuracy did not improve from 0.73359\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 0.5083 - accuracy: 0.6973 - sensitivity_at_specificity: 0.8884 - specificity_at_sensitivity: 0.8802 - recall: 0.7339 - precision: 0.6921 - val_loss: 0.5016 - val_accuracy: 0.7133 - val_sensitivity_at_specificity: 0.8861 - val_specificity_at_sensitivity: 0.8548 - val_recall: 0.7556 - val_precision: 0.7119\n",
            "Epoch 116/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5153 - accuracy: 0.6969 - sensitivity_at_specificity: 0.8378 - specificity_at_sensitivity: 0.8545 - recall: 0.7367 - precision: 0.6868\n",
            "Epoch 116: val_accuracy did not improve from 0.73359\n",
            "10/10 [==============================] - 2s 205ms/step - loss: 0.5153 - accuracy: 0.6969 - sensitivity_at_specificity: 0.8378 - specificity_at_sensitivity: 0.8545 - recall: 0.7367 - precision: 0.6868 - val_loss: 0.5102 - val_accuracy: 0.7156 - val_sensitivity_at_specificity: 0.8963 - val_specificity_at_sensitivity: 0.8683 - val_recall: 0.7065 - val_precision: 0.7111\n",
            "Epoch 117/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5130 - accuracy: 0.7068 - sensitivity_at_specificity: 0.8671 - specificity_at_sensitivity: 0.8728 - recall: 0.7065 - precision: 0.7018\n",
            "Epoch 117: val_accuracy did not improve from 0.73359\n",
            "10/10 [==============================] - 2s 196ms/step - loss: 0.5130 - accuracy: 0.7068 - sensitivity_at_specificity: 0.8671 - specificity_at_sensitivity: 0.8728 - recall: 0.7065 - precision: 0.7018 - val_loss: 0.5112 - val_accuracy: 0.7023 - val_sensitivity_at_specificity: 0.8309 - val_specificity_at_sensitivity: 0.8943 - val_recall: 0.7241 - val_precision: 0.6858\n",
            "Epoch 118/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5013 - accuracy: 0.7094 - sensitivity_at_specificity: 0.8698 - specificity_at_sensitivity: 0.8748 - recall: 0.7603 - precision: 0.6973\n",
            "Epoch 118: val_accuracy did not improve from 0.73359\n",
            "10/10 [==============================] - 2s 205ms/step - loss: 0.5013 - accuracy: 0.7094 - sensitivity_at_specificity: 0.8698 - specificity_at_sensitivity: 0.8748 - recall: 0.7603 - precision: 0.6973 - val_loss: 0.5071 - val_accuracy: 0.6992 - val_sensitivity_at_specificity: 0.8765 - val_specificity_at_sensitivity: 0.8847 - val_recall: 0.7184 - val_precision: 0.7067\n",
            "Epoch 119/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5023 - accuracy: 0.7059 - sensitivity_at_specificity: 0.8818 - specificity_at_sensitivity: 0.8621 - recall: 0.7288 - precision: 0.7089\n",
            "Epoch 119: val_accuracy did not improve from 0.73359\n",
            "10/10 [==============================] - 2s 202ms/step - loss: 0.5023 - accuracy: 0.7059 - sensitivity_at_specificity: 0.8818 - specificity_at_sensitivity: 0.8621 - recall: 0.7288 - precision: 0.7089 - val_loss: 0.4879 - val_accuracy: 0.7234 - val_sensitivity_at_specificity: 0.8771 - val_specificity_at_sensitivity: 0.8887 - val_recall: 0.8372 - val_precision: 0.6873\n",
            "Epoch 120/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5026 - accuracy: 0.7125 - sensitivity_at_specificity: 0.8860 - specificity_at_sensitivity: 0.8913 - recall: 0.7289 - precision: 0.6977\n",
            "Epoch 120: val_accuracy did not improve from 0.73359\n",
            "10/10 [==============================] - 2s 204ms/step - loss: 0.5026 - accuracy: 0.7125 - sensitivity_at_specificity: 0.8860 - specificity_at_sensitivity: 0.8913 - recall: 0.7289 - precision: 0.6977 - val_loss: 0.5034 - val_accuracy: 0.7195 - val_sensitivity_at_specificity: 0.9046 - val_specificity_at_sensitivity: 0.9063 - val_recall: 0.8347 - val_precision: 0.6731\n",
            "Epoch 121/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4924 - accuracy: 0.7113 - sensitivity_at_specificity: 0.8911 - specificity_at_sensitivity: 0.8871 - recall: 0.7030 - precision: 0.7136\n",
            "Epoch 121: val_accuracy did not improve from 0.73359\n",
            "10/10 [==============================] - 2s 203ms/step - loss: 0.4924 - accuracy: 0.7113 - sensitivity_at_specificity: 0.8911 - specificity_at_sensitivity: 0.8871 - recall: 0.7030 - precision: 0.7136 - val_loss: 0.4987 - val_accuracy: 0.7172 - val_sensitivity_at_specificity: 0.9082 - val_specificity_at_sensitivity: 0.8719 - val_recall: 0.8291 - val_precision: 0.6735\n",
            "Epoch 122/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4934 - accuracy: 0.7176 - sensitivity_at_specificity: 0.8863 - specificity_at_sensitivity: 0.8903 - recall: 0.7336 - precision: 0.7112\n",
            "Epoch 122: val_accuracy did not improve from 0.73359\n",
            "10/10 [==============================] - 2s 191ms/step - loss: 0.4934 - accuracy: 0.7176 - sensitivity_at_specificity: 0.8863 - specificity_at_sensitivity: 0.8903 - recall: 0.7336 - precision: 0.7112 - val_loss: 0.4897 - val_accuracy: 0.7156 - val_sensitivity_at_specificity: 0.8948 - val_specificity_at_sensitivity: 0.8830 - val_recall: 0.7271 - val_precision: 0.7205\n",
            "Epoch 123/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4907 - accuracy: 0.7250 - sensitivity_at_specificity: 0.9100 - specificity_at_sensitivity: 0.8748 - recall: 0.7504 - precision: 0.7100\n",
            "Epoch 123: val_accuracy did not improve from 0.73359\n",
            "10/10 [==============================] - 2s 202ms/step - loss: 0.4907 - accuracy: 0.7250 - sensitivity_at_specificity: 0.9100 - specificity_at_sensitivity: 0.8748 - recall: 0.7504 - precision: 0.7100 - val_loss: 0.4958 - val_accuracy: 0.7211 - val_sensitivity_at_specificity: 0.8729 - val_specificity_at_sensitivity: 0.8868 - val_recall: 0.6891 - val_precision: 0.7450\n",
            "Epoch 124/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5068 - accuracy: 0.7191 - sensitivity_at_specificity: 0.8972 - specificity_at_sensitivity: 0.8764 - recall: 0.6601 - precision: 0.7429\n",
            "Epoch 124: val_accuracy improved from 0.73359 to 0.74141, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 204ms/step - loss: 0.5068 - accuracy: 0.7191 - sensitivity_at_specificity: 0.8972 - specificity_at_sensitivity: 0.8764 - recall: 0.6601 - precision: 0.7429 - val_loss: 0.4974 - val_accuracy: 0.7414 - val_sensitivity_at_specificity: 0.9242 - val_specificity_at_sensitivity: 0.8818 - val_recall: 0.8145 - val_precision: 0.7004\n",
            "Epoch 125/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4852 - accuracy: 0.7223 - sensitivity_at_specificity: 0.9090 - specificity_at_sensitivity: 0.8846 - recall: 0.7846 - precision: 0.6992\n",
            "Epoch 125: val_accuracy did not improve from 0.74141\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 0.4852 - accuracy: 0.7223 - sensitivity_at_specificity: 0.9090 - specificity_at_sensitivity: 0.8846 - recall: 0.7846 - precision: 0.6992 - val_loss: 0.5052 - val_accuracy: 0.6805 - val_sensitivity_at_specificity: 0.8650 - val_specificity_at_sensitivity: 0.8942 - val_recall: 0.8838 - val_precision: 0.6269\n",
            "Epoch 126/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5034 - accuracy: 0.7133 - sensitivity_at_specificity: 0.8956 - specificity_at_sensitivity: 0.8764 - recall: 0.8195 - precision: 0.6744\n",
            "Epoch 126: val_accuracy did not improve from 0.74141\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 0.5034 - accuracy: 0.7133 - sensitivity_at_specificity: 0.8956 - specificity_at_sensitivity: 0.8764 - recall: 0.8195 - precision: 0.6744 - val_loss: 0.4997 - val_accuracy: 0.7211 - val_sensitivity_at_specificity: 0.9082 - val_specificity_at_sensitivity: 0.8744 - val_recall: 0.8305 - val_precision: 0.6829\n",
            "Epoch 127/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4955 - accuracy: 0.7195 - sensitivity_at_specificity: 0.8774 - specificity_at_sensitivity: 0.8789 - recall: 0.7406 - precision: 0.7083\n",
            "Epoch 127: val_accuracy did not improve from 0.74141\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 0.4955 - accuracy: 0.7195 - sensitivity_at_specificity: 0.8774 - specificity_at_sensitivity: 0.8789 - recall: 0.7406 - precision: 0.7083 - val_loss: 0.4963 - val_accuracy: 0.7273 - val_sensitivity_at_specificity: 0.9041 - val_specificity_at_sensitivity: 0.8748 - val_recall: 0.7154 - val_precision: 0.7437\n",
            "Epoch 128/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4845 - accuracy: 0.7328 - sensitivity_at_specificity: 0.9099 - specificity_at_sensitivity: 0.8841 - recall: 0.7341 - precision: 0.7409\n",
            "Epoch 128: val_accuracy did not improve from 0.74141\n",
            "10/10 [==============================] - 2s 204ms/step - loss: 0.4845 - accuracy: 0.7328 - sensitivity_at_specificity: 0.9099 - specificity_at_sensitivity: 0.8841 - recall: 0.7341 - precision: 0.7409 - val_loss: 0.4865 - val_accuracy: 0.7336 - val_sensitivity_at_specificity: 0.8990 - val_specificity_at_sensitivity: 0.9131 - val_recall: 0.7804 - val_precision: 0.7048\n",
            "Epoch 129/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4879 - accuracy: 0.7129 - sensitivity_at_specificity: 0.8851 - specificity_at_sensitivity: 0.8908 - recall: 0.7142 - precision: 0.7202\n",
            "Epoch 129: val_accuracy improved from 0.74141 to 0.75000, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 207ms/step - loss: 0.4879 - accuracy: 0.7129 - sensitivity_at_specificity: 0.8851 - specificity_at_sensitivity: 0.8908 - recall: 0.7142 - precision: 0.7202 - val_loss: 0.4776 - val_accuracy: 0.7500 - val_sensitivity_at_specificity: 0.9054 - val_specificity_at_sensitivity: 0.9009 - val_recall: 0.7603 - val_precision: 0.7415\n",
            "Epoch 130/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4895 - accuracy: 0.7176 - sensitivity_at_specificity: 0.8870 - specificity_at_sensitivity: 0.9000 - recall: 0.7282 - precision: 0.7222\n",
            "Epoch 130: val_accuracy did not improve from 0.75000\n",
            "10/10 [==============================] - 2s 203ms/step - loss: 0.4895 - accuracy: 0.7176 - sensitivity_at_specificity: 0.8870 - specificity_at_sensitivity: 0.9000 - recall: 0.7282 - precision: 0.7222 - val_loss: 0.4904 - val_accuracy: 0.7258 - val_sensitivity_at_specificity: 0.9062 - val_specificity_at_sensitivity: 0.9107 - val_recall: 0.7944 - val_precision: 0.6812\n",
            "Epoch 131/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4976 - accuracy: 0.7141 - sensitivity_at_specificity: 0.8805 - specificity_at_sensitivity: 0.8961 - recall: 0.7703 - precision: 0.6924\n",
            "Epoch 131: val_accuracy did not improve from 0.75000\n",
            "10/10 [==============================] - 2s 208ms/step - loss: 0.4976 - accuracy: 0.7141 - sensitivity_at_specificity: 0.8805 - specificity_at_sensitivity: 0.8961 - recall: 0.7703 - precision: 0.6924 - val_loss: 0.4853 - val_accuracy: 0.7430 - val_sensitivity_at_specificity: 0.8909 - val_specificity_at_sensitivity: 0.9110 - val_recall: 0.6805 - val_precision: 0.7855\n",
            "Epoch 132/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4799 - accuracy: 0.7352 - sensitivity_at_specificity: 0.8961 - specificity_at_sensitivity: 0.9097 - recall: 0.7196 - precision: 0.7518\n",
            "Epoch 132: val_accuracy did not improve from 0.75000\n",
            "10/10 [==============================] - 2s 209ms/step - loss: 0.4799 - accuracy: 0.7352 - sensitivity_at_specificity: 0.8961 - specificity_at_sensitivity: 0.9097 - recall: 0.7196 - precision: 0.7518 - val_loss: 0.4995 - val_accuracy: 0.7383 - val_sensitivity_at_specificity: 0.9025 - val_specificity_at_sensitivity: 0.8804 - val_recall: 0.8270 - val_precision: 0.7004\n",
            "Epoch 133/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4853 - accuracy: 0.7234 - sensitivity_at_specificity: 0.8909 - specificity_at_sensitivity: 0.8911 - recall: 0.7300 - precision: 0.7187\n",
            "Epoch 133: val_accuracy did not improve from 0.75000\n",
            "10/10 [==============================] - 2s 204ms/step - loss: 0.4853 - accuracy: 0.7234 - sensitivity_at_specificity: 0.8909 - specificity_at_sensitivity: 0.8911 - recall: 0.7300 - precision: 0.7187 - val_loss: 0.4993 - val_accuracy: 0.7297 - val_sensitivity_at_specificity: 0.9112 - val_specificity_at_sensitivity: 0.8934 - val_recall: 0.8364 - val_precision: 0.6902\n",
            "Epoch 134/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4733 - accuracy: 0.7406 - sensitivity_at_specificity: 0.8939 - specificity_at_sensitivity: 0.9204 - recall: 0.7273 - precision: 0.7391\n",
            "Epoch 134: val_accuracy did not improve from 0.75000\n",
            "10/10 [==============================] - 2s 206ms/step - loss: 0.4733 - accuracy: 0.7406 - sensitivity_at_specificity: 0.8939 - specificity_at_sensitivity: 0.9204 - recall: 0.7273 - precision: 0.7391 - val_loss: 0.4964 - val_accuracy: 0.7195 - val_sensitivity_at_specificity: 0.8871 - val_specificity_at_sensitivity: 0.8986 - val_recall: 0.8045 - val_precision: 0.6819\n",
            "Epoch 135/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4812 - accuracy: 0.7238 - sensitivity_at_specificity: 0.9171 - specificity_at_sensitivity: 0.9033 - recall: 0.7074 - precision: 0.7308\n",
            "Epoch 135: val_accuracy did not improve from 0.75000\n",
            "10/10 [==============================] - 2s 206ms/step - loss: 0.4812 - accuracy: 0.7238 - sensitivity_at_specificity: 0.9171 - specificity_at_sensitivity: 0.9033 - recall: 0.7074 - precision: 0.7308 - val_loss: 0.4825 - val_accuracy: 0.7500 - val_sensitivity_at_specificity: 0.8815 - val_specificity_at_sensitivity: 0.9175 - val_recall: 0.7062 - val_precision: 0.7806\n",
            "Epoch 136/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4670 - accuracy: 0.7410 - sensitivity_at_specificity: 0.9096 - specificity_at_sensitivity: 0.9199 - recall: 0.7502 - precision: 0.7311\n",
            "Epoch 136: val_accuracy did not improve from 0.75000\n",
            "10/10 [==============================] - 2s 204ms/step - loss: 0.4670 - accuracy: 0.7410 - sensitivity_at_specificity: 0.9096 - specificity_at_sensitivity: 0.9199 - recall: 0.7502 - precision: 0.7311 - val_loss: 0.4689 - val_accuracy: 0.7461 - val_sensitivity_at_specificity: 0.9259 - val_specificity_at_sensitivity: 0.9241 - val_recall: 0.8707 - val_precision: 0.6943\n",
            "Epoch 137/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4924 - accuracy: 0.7101 - sensitivity_at_specificity: 0.8842 - specificity_at_sensitivity: 0.8916 - recall: 0.6502 - precision: 0.7444\n",
            "Epoch 137: val_accuracy did not improve from 0.75000\n",
            "10/10 [==============================] - 2s 195ms/step - loss: 0.4924 - accuracy: 0.7101 - sensitivity_at_specificity: 0.8842 - specificity_at_sensitivity: 0.8916 - recall: 0.6502 - precision: 0.7444 - val_loss: 0.4778 - val_accuracy: 0.7477 - val_sensitivity_at_specificity: 0.9200 - val_specificity_at_sensitivity: 0.9160 - val_recall: 0.8256 - val_precision: 0.7068\n",
            "Epoch 138/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4767 - accuracy: 0.7227 - sensitivity_at_specificity: 0.8751 - specificity_at_sensitivity: 0.9088 - recall: 0.7419 - precision: 0.7265\n",
            "Epoch 138: val_accuracy did not improve from 0.75000\n",
            "10/10 [==============================] - 2s 204ms/step - loss: 0.4767 - accuracy: 0.7227 - sensitivity_at_specificity: 0.8751 - specificity_at_sensitivity: 0.9088 - recall: 0.7419 - precision: 0.7265 - val_loss: 0.4804 - val_accuracy: 0.7359 - val_sensitivity_at_specificity: 0.9344 - val_specificity_at_sensitivity: 0.8962 - val_recall: 0.8112 - val_precision: 0.6974\n",
            "Epoch 139/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4888 - accuracy: 0.7133 - sensitivity_at_specificity: 0.8834 - specificity_at_sensitivity: 0.9089 - recall: 0.7014 - precision: 0.7204\n",
            "Epoch 139: val_accuracy did not improve from 0.75000\n",
            "10/10 [==============================] - 2s 205ms/step - loss: 0.4888 - accuracy: 0.7133 - sensitivity_at_specificity: 0.8834 - specificity_at_sensitivity: 0.9089 - recall: 0.7014 - precision: 0.7204 - val_loss: 0.4879 - val_accuracy: 0.7453 - val_sensitivity_at_specificity: 0.9289 - val_specificity_at_sensitivity: 0.8894 - val_recall: 0.8114 - val_precision: 0.7202\n",
            "Epoch 140/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4749 - accuracy: 0.7172 - sensitivity_at_specificity: 0.9010 - specificity_at_sensitivity: 0.9006 - recall: 0.7375 - precision: 0.7156\n",
            "Epoch 140: val_accuracy did not improve from 0.75000\n",
            "10/10 [==============================] - 2s 204ms/step - loss: 0.4749 - accuracy: 0.7172 - sensitivity_at_specificity: 0.9010 - specificity_at_sensitivity: 0.9006 - recall: 0.7375 - precision: 0.7156 - val_loss: 0.4825 - val_accuracy: 0.7266 - val_sensitivity_at_specificity: 0.9150 - val_specificity_at_sensitivity: 0.9101 - val_recall: 0.8583 - val_precision: 0.6770\n",
            "Epoch 141/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4717 - accuracy: 0.7324 - sensitivity_at_specificity: 0.8983 - specificity_at_sensitivity: 0.9184 - recall: 0.7773 - precision: 0.7181\n",
            "Epoch 141: val_accuracy did not improve from 0.75000\n",
            "10/10 [==============================] - 2s 205ms/step - loss: 0.4717 - accuracy: 0.7324 - sensitivity_at_specificity: 0.8983 - specificity_at_sensitivity: 0.9184 - recall: 0.7773 - precision: 0.7181 - val_loss: 0.4815 - val_accuracy: 0.7328 - val_sensitivity_at_specificity: 0.9027 - val_specificity_at_sensitivity: 0.9219 - val_recall: 0.8565 - val_precision: 0.6806\n",
            "Epoch 142/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4708 - accuracy: 0.7387 - sensitivity_at_specificity: 0.9098 - specificity_at_sensitivity: 0.9188 - recall: 0.6924 - precision: 0.7498\n",
            "Epoch 142: val_accuracy did not improve from 0.75000\n",
            "10/10 [==============================] - 2s 204ms/step - loss: 0.4708 - accuracy: 0.7387 - sensitivity_at_specificity: 0.9098 - specificity_at_sensitivity: 0.9188 - recall: 0.6924 - precision: 0.7498 - val_loss: 0.4696 - val_accuracy: 0.7469 - val_sensitivity_at_specificity: 0.9200 - val_specificity_at_sensitivity: 0.9317 - val_recall: 0.8615 - val_precision: 0.7053\n",
            "Epoch 143/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4658 - accuracy: 0.7406 - sensitivity_at_specificity: 0.9006 - specificity_at_sensitivity: 0.9179 - recall: 0.7428 - precision: 0.7508\n",
            "Epoch 143: val_accuracy did not improve from 0.75000\n",
            "10/10 [==============================] - 2s 205ms/step - loss: 0.4658 - accuracy: 0.7406 - sensitivity_at_specificity: 0.9006 - specificity_at_sensitivity: 0.9179 - recall: 0.7428 - precision: 0.7508 - val_loss: 0.4707 - val_accuracy: 0.7398 - val_sensitivity_at_specificity: 0.9119 - val_specificity_at_sensitivity: 0.9325 - val_recall: 0.8571 - val_precision: 0.7024\n",
            "Epoch 144/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4656 - accuracy: 0.7262 - sensitivity_at_specificity: 0.9118 - specificity_at_sensitivity: 0.9225 - recall: 0.7417 - precision: 0.7163\n",
            "Epoch 144: val_accuracy improved from 0.75000 to 0.76484, saving model to ECG_Spectrogram_Model.h5\n",
            "10/10 [==============================] - 2s 210ms/step - loss: 0.4656 - accuracy: 0.7262 - sensitivity_at_specificity: 0.9118 - specificity_at_sensitivity: 0.9225 - recall: 0.7417 - precision: 0.7163 - val_loss: 0.4698 - val_accuracy: 0.7648 - val_sensitivity_at_specificity: 0.9290 - val_specificity_at_sensitivity: 0.9180 - val_recall: 0.7681 - val_precision: 0.7598\n",
            "Epoch 145/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4626 - accuracy: 0.7317 - sensitivity_at_specificity: 0.8943 - specificity_at_sensitivity: 0.9362 - recall: 0.6786 - precision: 0.7581\n",
            "Epoch 145: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 196ms/step - loss: 0.4626 - accuracy: 0.7317 - sensitivity_at_specificity: 0.8943 - specificity_at_sensitivity: 0.9362 - recall: 0.6786 - precision: 0.7581 - val_loss: 0.4555 - val_accuracy: 0.7547 - val_sensitivity_at_specificity: 0.9199 - val_specificity_at_sensitivity: 0.9353 - val_recall: 0.8036 - val_precision: 0.7430\n",
            "Epoch 146/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4665 - accuracy: 0.7387 - sensitivity_at_specificity: 0.9051 - specificity_at_sensitivity: 0.9266 - recall: 0.7162 - precision: 0.7451\n",
            "Epoch 146: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 208ms/step - loss: 0.4665 - accuracy: 0.7387 - sensitivity_at_specificity: 0.9051 - specificity_at_sensitivity: 0.9266 - recall: 0.7162 - precision: 0.7451 - val_loss: 0.4533 - val_accuracy: 0.7508 - val_sensitivity_at_specificity: 0.9252 - val_specificity_at_sensitivity: 0.9344 - val_recall: 0.7282 - val_precision: 0.7718\n",
            "Epoch 147/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4588 - accuracy: 0.7582 - sensitivity_at_specificity: 0.9313 - specificity_at_sensitivity: 0.9304 - recall: 0.7172 - precision: 0.7767\n",
            "Epoch 147: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 206ms/step - loss: 0.4588 - accuracy: 0.7582 - sensitivity_at_specificity: 0.9313 - specificity_at_sensitivity: 0.9304 - recall: 0.7172 - precision: 0.7767 - val_loss: 0.4657 - val_accuracy: 0.7508 - val_sensitivity_at_specificity: 0.9138 - val_specificity_at_sensitivity: 0.9208 - val_recall: 0.7458 - val_precision: 0.7655\n",
            "Epoch 148/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4481 - accuracy: 0.7625 - sensitivity_at_specificity: 0.9219 - specificity_at_sensitivity: 0.9412 - recall: 0.7165 - precision: 0.7683\n",
            "Epoch 148: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 208ms/step - loss: 0.4481 - accuracy: 0.7625 - sensitivity_at_specificity: 0.9219 - specificity_at_sensitivity: 0.9412 - recall: 0.7165 - precision: 0.7683 - val_loss: 0.4765 - val_accuracy: 0.7500 - val_sensitivity_at_specificity: 0.9043 - val_specificity_at_sensitivity: 0.9180 - val_recall: 0.8207 - val_precision: 0.7278\n",
            "Epoch 149/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4548 - accuracy: 0.7594 - sensitivity_at_specificity: 0.9185 - specificity_at_sensitivity: 0.9286 - recall: 0.7585 - precision: 0.7655\n",
            "Epoch 149: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 206ms/step - loss: 0.4548 - accuracy: 0.7594 - sensitivity_at_specificity: 0.9185 - specificity_at_sensitivity: 0.9286 - recall: 0.7585 - precision: 0.7655 - val_loss: 0.4724 - val_accuracy: 0.7453 - val_sensitivity_at_specificity: 0.9287 - val_specificity_at_sensitivity: 0.9214 - val_recall: 0.8067 - val_precision: 0.7139\n",
            "Epoch 150/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4667 - accuracy: 0.7418 - sensitivity_at_specificity: 0.9047 - specificity_at_sensitivity: 0.9273 - recall: 0.7436 - precision: 0.7533\n",
            "Epoch 150: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 202ms/step - loss: 0.4667 - accuracy: 0.7418 - sensitivity_at_specificity: 0.9047 - specificity_at_sensitivity: 0.9273 - recall: 0.7436 - precision: 0.7533 - val_loss: 0.5038 - val_accuracy: 0.7219 - val_sensitivity_at_specificity: 0.8976 - val_specificity_at_sensitivity: 0.9085 - val_recall: 0.8236 - val_precision: 0.6819\n",
            "Epoch 151/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4530 - accuracy: 0.7517 - sensitivity_at_specificity: 0.9280 - specificity_at_sensitivity: 0.9275 - recall: 0.7699 - precision: 0.7401\n",
            "Epoch 151: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 197ms/step - loss: 0.4530 - accuracy: 0.7517 - sensitivity_at_specificity: 0.9280 - specificity_at_sensitivity: 0.9275 - recall: 0.7699 - precision: 0.7401 - val_loss: 0.4784 - val_accuracy: 0.7484 - val_sensitivity_at_specificity: 0.9458 - val_specificity_at_sensitivity: 0.9342 - val_recall: 0.8868 - val_precision: 0.6890\n",
            "Epoch 152/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4497 - accuracy: 0.7543 - sensitivity_at_specificity: 0.9335 - specificity_at_sensitivity: 0.9415 - recall: 0.7496 - precision: 0.7608\n",
            "Epoch 152: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 202ms/step - loss: 0.4497 - accuracy: 0.7543 - sensitivity_at_specificity: 0.9335 - specificity_at_sensitivity: 0.9415 - recall: 0.7496 - precision: 0.7608 - val_loss: 0.4535 - val_accuracy: 0.7617 - val_sensitivity_at_specificity: 0.9260 - val_specificity_at_sensitivity: 0.9287 - val_recall: 0.7559 - val_precision: 0.7619\n",
            "Epoch 153/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4529 - accuracy: 0.7484 - sensitivity_at_specificity: 0.9236 - specificity_at_sensitivity: 0.9383 - recall: 0.7199 - precision: 0.7685\n",
            "Epoch 153: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 202ms/step - loss: 0.4529 - accuracy: 0.7484 - sensitivity_at_specificity: 0.9236 - specificity_at_sensitivity: 0.9383 - recall: 0.7199 - precision: 0.7685 - val_loss: 0.4906 - val_accuracy: 0.7469 - val_sensitivity_at_specificity: 0.8902 - val_specificity_at_sensitivity: 0.8910 - val_recall: 0.7530 - val_precision: 0.7530\n",
            "Epoch 154/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4503 - accuracy: 0.7543 - sensitivity_at_specificity: 0.9303 - specificity_at_sensitivity: 0.9362 - recall: 0.7428 - precision: 0.7635\n",
            "Epoch 154: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 200ms/step - loss: 0.4503 - accuracy: 0.7543 - sensitivity_at_specificity: 0.9303 - specificity_at_sensitivity: 0.9362 - recall: 0.7428 - precision: 0.7635 - val_loss: 0.4681 - val_accuracy: 0.7414 - val_sensitivity_at_specificity: 0.9321 - val_specificity_at_sensitivity: 0.9380 - val_recall: 0.8546 - val_precision: 0.6870\n",
            "Epoch 155/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4740 - accuracy: 0.7273 - sensitivity_at_specificity: 0.8956 - specificity_at_sensitivity: 0.9264 - recall: 0.7576 - precision: 0.7152\n",
            "Epoch 155: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 202ms/step - loss: 0.4740 - accuracy: 0.7273 - sensitivity_at_specificity: 0.8956 - specificity_at_sensitivity: 0.9264 - recall: 0.7576 - precision: 0.7152 - val_loss: 0.4806 - val_accuracy: 0.7414 - val_sensitivity_at_specificity: 0.9072 - val_specificity_at_sensitivity: 0.9133 - val_recall: 0.7382 - val_precision: 0.7531\n",
            "Epoch 156/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4516 - accuracy: 0.7594 - sensitivity_at_specificity: 0.9185 - specificity_at_sensitivity: 0.9439 - recall: 0.7380 - precision: 0.7808\n",
            "Epoch 156: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 211ms/step - loss: 0.4516 - accuracy: 0.7594 - sensitivity_at_specificity: 0.9185 - specificity_at_sensitivity: 0.9439 - recall: 0.7380 - precision: 0.7808 - val_loss: 0.5022 - val_accuracy: 0.7273 - val_sensitivity_at_specificity: 0.9300 - val_specificity_at_sensitivity: 0.9324 - val_recall: 0.8909 - val_precision: 0.6598\n",
            "Epoch 157/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4489 - accuracy: 0.7570 - sensitivity_at_specificity: 0.9171 - specificity_at_sensitivity: 0.9459 - recall: 0.7680 - precision: 0.7576\n",
            "Epoch 157: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 3s 268ms/step - loss: 0.4489 - accuracy: 0.7570 - sensitivity_at_specificity: 0.9171 - specificity_at_sensitivity: 0.9459 - recall: 0.7680 - precision: 0.7576 - val_loss: 0.5025 - val_accuracy: 0.7305 - val_sensitivity_at_specificity: 0.9305 - val_specificity_at_sensitivity: 0.9304 - val_recall: 0.8831 - val_precision: 0.6735\n",
            "Epoch 158/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4602 - accuracy: 0.7523 - sensitivity_at_specificity: 0.9168 - specificity_at_sensitivity: 0.9262 - recall: 0.7092 - precision: 0.7782\n",
            "Epoch 158: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 204ms/step - loss: 0.4602 - accuracy: 0.7523 - sensitivity_at_specificity: 0.9168 - specificity_at_sensitivity: 0.9262 - recall: 0.7092 - precision: 0.7782 - val_loss: 0.4949 - val_accuracy: 0.7281 - val_sensitivity_at_specificity: 0.9317 - val_specificity_at_sensitivity: 0.9261 - val_recall: 0.8758 - val_precision: 0.6779\n",
            "Epoch 159/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4591 - accuracy: 0.7516 - sensitivity_at_specificity: 0.9115 - specificity_at_sensitivity: 0.9342 - recall: 0.7504 - precision: 0.7445\n",
            "Epoch 159: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 207ms/step - loss: 0.4591 - accuracy: 0.7516 - sensitivity_at_specificity: 0.9115 - specificity_at_sensitivity: 0.9342 - recall: 0.7504 - precision: 0.7445 - val_loss: 0.4883 - val_accuracy: 0.7352 - val_sensitivity_at_specificity: 0.9246 - val_specificity_at_sensitivity: 0.9239 - val_recall: 0.8427 - val_precision: 0.6854\n",
            "Epoch 160/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4513 - accuracy: 0.7563 - sensitivity_at_specificity: 0.9416 - specificity_at_sensitivity: 0.9245 - recall: 0.7648 - precision: 0.7578\n",
            "Epoch 160: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 208ms/step - loss: 0.4513 - accuracy: 0.7563 - sensitivity_at_specificity: 0.9416 - specificity_at_sensitivity: 0.9245 - recall: 0.7648 - precision: 0.7578 - val_loss: 0.4780 - val_accuracy: 0.7469 - val_sensitivity_at_specificity: 0.9169 - val_specificity_at_sensitivity: 0.9143 - val_recall: 0.8431 - val_precision: 0.7117\n",
            "Epoch 161/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4452 - accuracy: 0.7570 - sensitivity_at_specificity: 0.9181 - specificity_at_sensitivity: 0.9424 - recall: 0.7136 - precision: 0.7739\n",
            "Epoch 161: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 209ms/step - loss: 0.4452 - accuracy: 0.7570 - sensitivity_at_specificity: 0.9181 - specificity_at_sensitivity: 0.9424 - recall: 0.7136 - precision: 0.7739 - val_loss: 0.4642 - val_accuracy: 0.7578 - val_sensitivity_at_specificity: 0.9120 - val_specificity_at_sensitivity: 0.9304 - val_recall: 0.7639 - val_precision: 0.7592\n",
            "Epoch 162/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4462 - accuracy: 0.7715 - sensitivity_at_specificity: 0.9396 - specificity_at_sensitivity: 0.9331 - recall: 0.7818 - precision: 0.7644\n",
            "Epoch 162: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 202ms/step - loss: 0.4462 - accuracy: 0.7715 - sensitivity_at_specificity: 0.9396 - specificity_at_sensitivity: 0.9331 - recall: 0.7818 - precision: 0.7644 - val_loss: 0.4914 - val_accuracy: 0.7312 - val_sensitivity_at_specificity: 0.8919 - val_specificity_at_sensitivity: 0.9149 - val_recall: 0.8478 - val_precision: 0.6954\n",
            "Epoch 163/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4496 - accuracy: 0.7543 - sensitivity_at_specificity: 0.9305 - specificity_at_sensitivity: 0.9281 - recall: 0.7547 - precision: 0.7541\n",
            "Epoch 163: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 204ms/step - loss: 0.4496 - accuracy: 0.7543 - sensitivity_at_specificity: 0.9305 - specificity_at_sensitivity: 0.9281 - recall: 0.7547 - precision: 0.7541 - val_loss: 0.4969 - val_accuracy: 0.7383 - val_sensitivity_at_specificity: 0.9253 - val_specificity_at_sensitivity: 0.9094 - val_recall: 0.8283 - val_precision: 0.6965\n",
            "Epoch 164/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4385 - accuracy: 0.7688 - sensitivity_at_specificity: 0.9343 - specificity_at_sensitivity: 0.9481 - recall: 0.7438 - precision: 0.7735\n",
            "Epoch 164: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 208ms/step - loss: 0.4385 - accuracy: 0.7688 - sensitivity_at_specificity: 0.9343 - specificity_at_sensitivity: 0.9481 - recall: 0.7438 - precision: 0.7735 - val_loss: 0.4842 - val_accuracy: 0.7461 - val_sensitivity_at_specificity: 0.9150 - val_specificity_at_sensitivity: 0.9114 - val_recall: 0.8270 - val_precision: 0.7209\n",
            "Epoch 165/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4212 - accuracy: 0.7750 - sensitivity_at_specificity: 0.9351 - specificity_at_sensitivity: 0.9618 - recall: 0.7629 - precision: 0.7812\n",
            "Epoch 165: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 206ms/step - loss: 0.4212 - accuracy: 0.7750 - sensitivity_at_specificity: 0.9351 - specificity_at_sensitivity: 0.9618 - recall: 0.7629 - precision: 0.7812 - val_loss: 0.4814 - val_accuracy: 0.7422 - val_sensitivity_at_specificity: 0.9374 - val_specificity_at_sensitivity: 0.9198 - val_recall: 0.8451 - val_precision: 0.6849\n",
            "Epoch 166/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4228 - accuracy: 0.7824 - sensitivity_at_specificity: 0.9449 - specificity_at_sensitivity: 0.9497 - recall: 0.7814 - precision: 0.7916\n",
            "Epoch 166: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 199ms/step - loss: 0.4228 - accuracy: 0.7824 - sensitivity_at_specificity: 0.9449 - specificity_at_sensitivity: 0.9497 - recall: 0.7814 - precision: 0.7916 - val_loss: 0.4560 - val_accuracy: 0.7625 - val_sensitivity_at_specificity: 0.9369 - val_specificity_at_sensitivity: 0.9283 - val_recall: 0.8754 - val_precision: 0.7251\n",
            "Epoch 167/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4253 - accuracy: 0.7762 - sensitivity_at_specificity: 0.9442 - specificity_at_sensitivity: 0.9536 - recall: 0.7945 - precision: 0.7738\n",
            "Epoch 167: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 206ms/step - loss: 0.4253 - accuracy: 0.7762 - sensitivity_at_specificity: 0.9442 - specificity_at_sensitivity: 0.9536 - recall: 0.7945 - precision: 0.7738 - val_loss: 0.4993 - val_accuracy: 0.7477 - val_sensitivity_at_specificity: 0.9455 - val_specificity_at_sensitivity: 0.9091 - val_recall: 0.8458 - val_precision: 0.7080\n",
            "Epoch 168/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4259 - accuracy: 0.7785 - sensitivity_at_specificity: 0.9505 - specificity_at_sensitivity: 0.9527 - recall: 0.7697 - precision: 0.7978\n",
            "Epoch 168: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 204ms/step - loss: 0.4259 - accuracy: 0.7785 - sensitivity_at_specificity: 0.9505 - specificity_at_sensitivity: 0.9527 - recall: 0.7697 - precision: 0.7978 - val_loss: 0.4722 - val_accuracy: 0.7594 - val_sensitivity_at_specificity: 0.9144 - val_specificity_at_sensitivity: 0.9399 - val_recall: 0.8399 - val_precision: 0.7191\n",
            "Epoch 169/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4166 - accuracy: 0.7895 - sensitivity_at_specificity: 0.9357 - specificity_at_sensitivity: 0.9634 - recall: 0.7812 - precision: 0.7930\n",
            "Epoch 169: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 205ms/step - loss: 0.4166 - accuracy: 0.7895 - sensitivity_at_specificity: 0.9357 - specificity_at_sensitivity: 0.9634 - recall: 0.7812 - precision: 0.7930 - val_loss: 0.5072 - val_accuracy: 0.7445 - val_sensitivity_at_specificity: 0.9308 - val_specificity_at_sensitivity: 0.9183 - val_recall: 0.8386 - val_precision: 0.6897\n",
            "Epoch 170/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4173 - accuracy: 0.7867 - sensitivity_at_specificity: 0.9459 - specificity_at_sensitivity: 0.9593 - recall: 0.7518 - precision: 0.8015\n",
            "Epoch 170: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 206ms/step - loss: 0.4173 - accuracy: 0.7867 - sensitivity_at_specificity: 0.9459 - specificity_at_sensitivity: 0.9593 - recall: 0.7518 - precision: 0.8015 - val_loss: 0.5111 - val_accuracy: 0.7203 - val_sensitivity_at_specificity: 0.8930 - val_specificity_at_sensitivity: 0.9213 - val_recall: 0.8264 - val_precision: 0.6842\n",
            "Epoch 171/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4286 - accuracy: 0.7793 - sensitivity_at_specificity: 0.9485 - specificity_at_sensitivity: 0.9547 - recall: 0.7780 - precision: 0.7859\n",
            "Epoch 171: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 213ms/step - loss: 0.4286 - accuracy: 0.7793 - sensitivity_at_specificity: 0.9485 - specificity_at_sensitivity: 0.9547 - recall: 0.7780 - precision: 0.7859 - val_loss: 0.4630 - val_accuracy: 0.7383 - val_sensitivity_at_specificity: 0.9353 - val_specificity_at_sensitivity: 0.9118 - val_recall: 0.7366 - val_precision: 0.7354\n",
            "Epoch 172/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4176 - accuracy: 0.7805 - sensitivity_at_specificity: 0.9501 - specificity_at_sensitivity: 0.9537 - recall: 0.7633 - precision: 0.7857\n",
            "Epoch 172: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 209ms/step - loss: 0.4176 - accuracy: 0.7805 - sensitivity_at_specificity: 0.9501 - specificity_at_sensitivity: 0.9537 - recall: 0.7633 - precision: 0.7857 - val_loss: 0.4797 - val_accuracy: 0.7477 - val_sensitivity_at_specificity: 0.9311 - val_specificity_at_sensitivity: 0.9358 - val_recall: 0.8311 - val_precision: 0.6974\n",
            "Epoch 173/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4052 - accuracy: 0.7910 - sensitivity_at_specificity: 0.9455 - specificity_at_sensitivity: 0.9650 - recall: 0.7905 - precision: 0.7972\n",
            "Epoch 173: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 212ms/step - loss: 0.4052 - accuracy: 0.7910 - sensitivity_at_specificity: 0.9455 - specificity_at_sensitivity: 0.9650 - recall: 0.7905 - precision: 0.7972 - val_loss: 0.5084 - val_accuracy: 0.7437 - val_sensitivity_at_specificity: 0.9278 - val_specificity_at_sensitivity: 0.9132 - val_recall: 0.8202 - val_precision: 0.7029\n",
            "Epoch 174/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4070 - accuracy: 0.7824 - sensitivity_at_specificity: 0.9459 - specificity_at_sensitivity: 0.9720 - recall: 0.7719 - precision: 0.7874\n",
            "Epoch 174: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 210ms/step - loss: 0.4070 - accuracy: 0.7824 - sensitivity_at_specificity: 0.9459 - specificity_at_sensitivity: 0.9720 - recall: 0.7719 - precision: 0.7874 - val_loss: 0.5127 - val_accuracy: 0.7352 - val_sensitivity_at_specificity: 0.9195 - val_specificity_at_sensitivity: 0.9240 - val_recall: 0.8289 - val_precision: 0.6758\n",
            "Epoch 175/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4213 - accuracy: 0.7801 - sensitivity_at_specificity: 0.9518 - specificity_at_sensitivity: 0.9537 - recall: 0.7619 - precision: 0.7921\n",
            "Epoch 175: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 208ms/step - loss: 0.4213 - accuracy: 0.7801 - sensitivity_at_specificity: 0.9518 - specificity_at_sensitivity: 0.9537 - recall: 0.7619 - precision: 0.7921 - val_loss: 0.4799 - val_accuracy: 0.7461 - val_sensitivity_at_specificity: 0.9194 - val_specificity_at_sensitivity: 0.9213 - val_recall: 0.8403 - val_precision: 0.7094\n",
            "Epoch 176/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4040 - accuracy: 0.7910 - sensitivity_at_specificity: 0.9569 - specificity_at_sensitivity: 0.9730 - recall: 0.7829 - precision: 0.8008\n",
            "Epoch 176: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 205ms/step - loss: 0.4040 - accuracy: 0.7910 - sensitivity_at_specificity: 0.9569 - specificity_at_sensitivity: 0.9730 - recall: 0.7829 - precision: 0.8008 - val_loss: 0.5309 - val_accuracy: 0.7305 - val_sensitivity_at_specificity: 0.9253 - val_specificity_at_sensitivity: 0.9066 - val_recall: 0.8864 - val_precision: 0.6650\n",
            "Epoch 177/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4115 - accuracy: 0.7922 - sensitivity_at_specificity: 0.9526 - specificity_at_sensitivity: 0.9598 - recall: 0.7852 - precision: 0.7927\n",
            "Epoch 177: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 205ms/step - loss: 0.4115 - accuracy: 0.7922 - sensitivity_at_specificity: 0.9526 - specificity_at_sensitivity: 0.9598 - recall: 0.7852 - precision: 0.7927 - val_loss: 0.4786 - val_accuracy: 0.7414 - val_sensitivity_at_specificity: 0.9230 - val_specificity_at_sensitivity: 0.9176 - val_recall: 0.7843 - val_precision: 0.7271\n",
            "Epoch 178/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4056 - accuracy: 0.7922 - sensitivity_at_specificity: 0.9527 - specificity_at_sensitivity: 0.9776 - recall: 0.7768 - precision: 0.7982\n",
            "Epoch 178: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 208ms/step - loss: 0.4056 - accuracy: 0.7922 - sensitivity_at_specificity: 0.9527 - specificity_at_sensitivity: 0.9776 - recall: 0.7768 - precision: 0.7982 - val_loss: 0.5312 - val_accuracy: 0.7188 - val_sensitivity_at_specificity: 0.9133 - val_specificity_at_sensitivity: 0.9102 - val_recall: 0.8523 - val_precision: 0.6646\n",
            "Epoch 179/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3892 - accuracy: 0.7969 - sensitivity_at_specificity: 0.9569 - specificity_at_sensitivity: 0.9738 - recall: 0.7783 - precision: 0.8134\n",
            "Epoch 179: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 208ms/step - loss: 0.3892 - accuracy: 0.7969 - sensitivity_at_specificity: 0.9569 - specificity_at_sensitivity: 0.9738 - recall: 0.7783 - precision: 0.8134 - val_loss: 0.4936 - val_accuracy: 0.7563 - val_sensitivity_at_specificity: 0.9351 - val_specificity_at_sensitivity: 0.9213 - val_recall: 0.8133 - val_precision: 0.7260\n",
            "Epoch 180/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3810 - accuracy: 0.8164 - sensitivity_at_specificity: 0.9634 - specificity_at_sensitivity: 0.9773 - recall: 0.7944 - precision: 0.8320\n",
            "Epoch 180: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 208ms/step - loss: 0.3810 - accuracy: 0.8164 - sensitivity_at_specificity: 0.9634 - specificity_at_sensitivity: 0.9773 - recall: 0.7944 - precision: 0.8320 - val_loss: 0.5326 - val_accuracy: 0.7367 - val_sensitivity_at_specificity: 0.9188 - val_specificity_at_sensitivity: 0.8834 - val_recall: 0.7309 - val_precision: 0.7321\n",
            "Epoch 181/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3888 - accuracy: 0.8086 - sensitivity_at_specificity: 0.9616 - specificity_at_sensitivity: 0.9666 - recall: 0.7974 - precision: 0.8213\n",
            "Epoch 181: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 206ms/step - loss: 0.3888 - accuracy: 0.8086 - sensitivity_at_specificity: 0.9616 - specificity_at_sensitivity: 0.9666 - recall: 0.7974 - precision: 0.8213 - val_loss: 0.5056 - val_accuracy: 0.7469 - val_sensitivity_at_specificity: 0.9329 - val_specificity_at_sensitivity: 0.9311 - val_recall: 0.8534 - val_precision: 0.7040\n",
            "Epoch 182/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3921 - accuracy: 0.8125 - sensitivity_at_specificity: 0.9599 - specificity_at_sensitivity: 0.9715 - recall: 0.7941 - precision: 0.8286\n",
            "Epoch 182: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 207ms/step - loss: 0.3921 - accuracy: 0.8125 - sensitivity_at_specificity: 0.9599 - specificity_at_sensitivity: 0.9715 - recall: 0.7941 - precision: 0.8286 - val_loss: 0.5021 - val_accuracy: 0.7297 - val_sensitivity_at_specificity: 0.9038 - val_specificity_at_sensitivity: 0.9073 - val_recall: 0.8256 - val_precision: 0.7047\n",
            "Epoch 183/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3741 - accuracy: 0.8238 - sensitivity_at_specificity: 0.9687 - specificity_at_sensitivity: 0.9758 - recall: 0.8147 - precision: 0.8296\n",
            "Epoch 183: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 202ms/step - loss: 0.3741 - accuracy: 0.8238 - sensitivity_at_specificity: 0.9687 - specificity_at_sensitivity: 0.9758 - recall: 0.8147 - precision: 0.8296 - val_loss: 0.5202 - val_accuracy: 0.7398 - val_sensitivity_at_specificity: 0.9135 - val_specificity_at_sensitivity: 0.9286 - val_recall: 0.8381 - val_precision: 0.6986\n",
            "Epoch 184/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3656 - accuracy: 0.8129 - sensitivity_at_specificity: 0.9728 - specificity_at_sensitivity: 0.9859 - recall: 0.8089 - precision: 0.8171\n",
            "Epoch 184: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 208ms/step - loss: 0.3656 - accuracy: 0.8129 - sensitivity_at_specificity: 0.9728 - specificity_at_sensitivity: 0.9859 - recall: 0.8089 - precision: 0.8171 - val_loss: 0.4936 - val_accuracy: 0.7570 - val_sensitivity_at_specificity: 0.9375 - val_specificity_at_sensitivity: 0.9038 - val_recall: 0.8399 - val_precision: 0.7279\n",
            "Epoch 185/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3728 - accuracy: 0.8188 - sensitivity_at_specificity: 0.9516 - specificity_at_sensitivity: 0.9875 - recall: 0.7852 - precision: 0.8417\n",
            "Epoch 185: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 203ms/step - loss: 0.3728 - accuracy: 0.8188 - sensitivity_at_specificity: 0.9516 - specificity_at_sensitivity: 0.9875 - recall: 0.7852 - precision: 0.8417 - val_loss: 0.5690 - val_accuracy: 0.7383 - val_sensitivity_at_specificity: 0.9081 - val_specificity_at_sensitivity: 0.9171 - val_recall: 0.8637 - val_precision: 0.6963\n",
            "Epoch 186/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3636 - accuracy: 0.8152 - sensitivity_at_specificity: 0.9732 - specificity_at_sensitivity: 0.9860 - recall: 0.8086 - precision: 0.8341\n",
            "Epoch 186: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 209ms/step - loss: 0.3636 - accuracy: 0.8152 - sensitivity_at_specificity: 0.9732 - specificity_at_sensitivity: 0.9860 - recall: 0.8086 - precision: 0.8341 - val_loss: 0.5465 - val_accuracy: 0.7359 - val_sensitivity_at_specificity: 0.9241 - val_specificity_at_sensitivity: 0.9120 - val_recall: 0.8766 - val_precision: 0.6806\n",
            "Epoch 187/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3735 - accuracy: 0.8152 - sensitivity_at_specificity: 0.9680 - specificity_at_sensitivity: 0.9828 - recall: 0.7947 - precision: 0.8290\n",
            "Epoch 187: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 206ms/step - loss: 0.3735 - accuracy: 0.8152 - sensitivity_at_specificity: 0.9680 - specificity_at_sensitivity: 0.9828 - recall: 0.7947 - precision: 0.8290 - val_loss: 0.4781 - val_accuracy: 0.7281 - val_sensitivity_at_specificity: 0.8984 - val_specificity_at_sensitivity: 0.9203 - val_recall: 0.7188 - val_precision: 0.7325\n",
            "Epoch 188/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3963 - accuracy: 0.7949 - sensitivity_at_specificity: 0.9634 - specificity_at_sensitivity: 0.9734 - recall: 0.7830 - precision: 0.8017\n",
            "Epoch 188: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 198ms/step - loss: 0.3963 - accuracy: 0.7949 - sensitivity_at_specificity: 0.9634 - specificity_at_sensitivity: 0.9734 - recall: 0.7830 - precision: 0.8017 - val_loss: 0.5824 - val_accuracy: 0.6766 - val_sensitivity_at_specificity: 0.8491 - val_specificity_at_sensitivity: 0.8666 - val_recall: 0.8243 - val_precision: 0.6378\n",
            "Epoch 189/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3982 - accuracy: 0.8121 - sensitivity_at_specificity: 0.9560 - specificity_at_sensitivity: 0.9720 - recall: 0.7862 - precision: 0.8271\n",
            "Epoch 189: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 207ms/step - loss: 0.3982 - accuracy: 0.8121 - sensitivity_at_specificity: 0.9560 - specificity_at_sensitivity: 0.9720 - recall: 0.7862 - precision: 0.8271 - val_loss: 0.5539 - val_accuracy: 0.7289 - val_sensitivity_at_specificity: 0.9167 - val_specificity_at_sensitivity: 0.9145 - val_recall: 0.8576 - val_precision: 0.6911\n",
            "Epoch 190/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3570 - accuracy: 0.8184 - sensitivity_at_specificity: 0.9796 - specificity_at_sensitivity: 0.9862 - recall: 0.8180 - precision: 0.8286\n",
            "Epoch 190: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 204ms/step - loss: 0.3570 - accuracy: 0.8184 - sensitivity_at_specificity: 0.9796 - specificity_at_sensitivity: 0.9862 - recall: 0.8180 - precision: 0.8286 - val_loss: 0.5181 - val_accuracy: 0.7484 - val_sensitivity_at_specificity: 0.9409 - val_specificity_at_sensitivity: 0.9294 - val_recall: 0.8491 - val_precision: 0.7082\n",
            "Epoch 191/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3574 - accuracy: 0.8156 - sensitivity_at_specificity: 0.9768 - specificity_at_sensitivity: 0.9874 - recall: 0.8127 - precision: 0.8203\n",
            "Epoch 191: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 208ms/step - loss: 0.3574 - accuracy: 0.8156 - sensitivity_at_specificity: 0.9768 - specificity_at_sensitivity: 0.9874 - recall: 0.8127 - precision: 0.8203 - val_loss: 0.5169 - val_accuracy: 0.7406 - val_sensitivity_at_specificity: 0.9142 - val_specificity_at_sensitivity: 0.9043 - val_recall: 0.7917 - val_precision: 0.7251\n",
            "Epoch 192/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3609 - accuracy: 0.8199 - sensitivity_at_specificity: 0.9628 - specificity_at_sensitivity: 0.9877 - recall: 0.7656 - precision: 0.8542\n",
            "Epoch 192: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 206ms/step - loss: 0.3609 - accuracy: 0.8199 - sensitivity_at_specificity: 0.9628 - specificity_at_sensitivity: 0.9877 - recall: 0.7656 - precision: 0.8542 - val_loss: 0.5525 - val_accuracy: 0.7305 - val_sensitivity_at_specificity: 0.9183 - val_specificity_at_sensitivity: 0.9223 - val_recall: 0.8598 - val_precision: 0.6872\n",
            "Epoch 193/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3370 - accuracy: 0.8375 - sensitivity_at_specificity: 0.9733 - specificity_at_sensitivity: 0.9880 - recall: 0.8273 - precision: 0.8507\n",
            "Epoch 193: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 211ms/step - loss: 0.3370 - accuracy: 0.8375 - sensitivity_at_specificity: 0.9733 - specificity_at_sensitivity: 0.9880 - recall: 0.8273 - precision: 0.8507 - val_loss: 0.5863 - val_accuracy: 0.7203 - val_sensitivity_at_specificity: 0.9331 - val_specificity_at_sensitivity: 0.9121 - val_recall: 0.8663 - val_precision: 0.6719\n",
            "Epoch 194/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3521 - accuracy: 0.8180 - sensitivity_at_specificity: 0.9729 - specificity_at_sensitivity: 0.9916 - recall: 0.7949 - precision: 0.8266\n",
            "Epoch 194: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 204ms/step - loss: 0.3521 - accuracy: 0.8180 - sensitivity_at_specificity: 0.9729 - specificity_at_sensitivity: 0.9916 - recall: 0.7949 - precision: 0.8266 - val_loss: 0.5698 - val_accuracy: 0.7234 - val_sensitivity_at_specificity: 0.9216 - val_specificity_at_sensitivity: 0.9034 - val_recall: 0.8182 - val_precision: 0.6868\n",
            "Epoch 195/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3326 - accuracy: 0.8441 - sensitivity_at_specificity: 0.9745 - specificity_at_sensitivity: 0.9937 - recall: 0.8065 - precision: 0.8749\n",
            "Epoch 195: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 206ms/step - loss: 0.3326 - accuracy: 0.8441 - sensitivity_at_specificity: 0.9745 - specificity_at_sensitivity: 0.9937 - recall: 0.8065 - precision: 0.8749 - val_loss: 0.5983 - val_accuracy: 0.7000 - val_sensitivity_at_specificity: 0.8876 - val_specificity_at_sensitivity: 0.9224 - val_recall: 0.8523 - val_precision: 0.6452\n",
            "Epoch 196/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3309 - accuracy: 0.8434 - sensitivity_at_specificity: 0.9734 - specificity_at_sensitivity: 0.9938 - recall: 0.8202 - precision: 0.8598\n",
            "Epoch 196: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 204ms/step - loss: 0.3309 - accuracy: 0.8434 - sensitivity_at_specificity: 0.9734 - specificity_at_sensitivity: 0.9938 - recall: 0.8202 - precision: 0.8598 - val_loss: 0.6126 - val_accuracy: 0.7359 - val_sensitivity_at_specificity: 0.9230 - val_specificity_at_sensitivity: 0.9223 - val_recall: 0.8474 - val_precision: 0.7088\n",
            "Epoch 197/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3382 - accuracy: 0.8426 - sensitivity_at_specificity: 0.9753 - specificity_at_sensitivity: 0.9911 - recall: 0.8027 - precision: 0.8653\n",
            "Epoch 197: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 196ms/step - loss: 0.3382 - accuracy: 0.8426 - sensitivity_at_specificity: 0.9753 - specificity_at_sensitivity: 0.9911 - recall: 0.8027 - precision: 0.8653 - val_loss: 0.5746 - val_accuracy: 0.7211 - val_sensitivity_at_specificity: 0.9167 - val_specificity_at_sensitivity: 0.9256 - val_recall: 0.8395 - val_precision: 0.6826\n",
            "Epoch 198/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3175 - accuracy: 0.8449 - sensitivity_at_specificity: 0.9800 - specificity_at_sensitivity: 0.9954 - recall: 0.8175 - precision: 0.8580\n",
            "Epoch 198: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 207ms/step - loss: 0.3175 - accuracy: 0.8449 - sensitivity_at_specificity: 0.9800 - specificity_at_sensitivity: 0.9954 - recall: 0.8175 - precision: 0.8580 - val_loss: 0.6566 - val_accuracy: 0.7203 - val_sensitivity_at_specificity: 0.8995 - val_specificity_at_sensitivity: 0.8847 - val_recall: 0.8423 - val_precision: 0.6804\n",
            "Epoch 199/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3258 - accuracy: 0.8480 - sensitivity_at_specificity: 0.9790 - specificity_at_sensitivity: 0.9898 - recall: 0.8248 - precision: 0.8659\n",
            "Epoch 199: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 207ms/step - loss: 0.3258 - accuracy: 0.8480 - sensitivity_at_specificity: 0.9790 - specificity_at_sensitivity: 0.9898 - recall: 0.8248 - precision: 0.8659 - val_loss: 0.7043 - val_accuracy: 0.7133 - val_sensitivity_at_specificity: 0.9299 - val_specificity_at_sensitivity: 0.8896 - val_recall: 0.9299 - val_precision: 0.6439\n",
            "Epoch 200/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3392 - accuracy: 0.8355 - sensitivity_at_specificity: 0.9689 - specificity_at_sensitivity: 0.9953 - recall: 0.8226 - precision: 0.8456\n",
            "Epoch 200: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 208ms/step - loss: 0.3392 - accuracy: 0.8355 - sensitivity_at_specificity: 0.9689 - specificity_at_sensitivity: 0.9953 - recall: 0.8226 - precision: 0.8456 - val_loss: 0.5996 - val_accuracy: 0.7094 - val_sensitivity_at_specificity: 0.9253 - val_specificity_at_sensitivity: 0.8879 - val_recall: 0.8458 - val_precision: 0.6592\n",
            "Epoch 201/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3152 - accuracy: 0.8509 - sensitivity_at_specificity: 0.9756 - specificity_at_sensitivity: 0.9967 - recall: 0.8049 - precision: 0.8828\n",
            "Epoch 201: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 198ms/step - loss: 0.3152 - accuracy: 0.8509 - sensitivity_at_specificity: 0.9756 - specificity_at_sensitivity: 0.9967 - recall: 0.8049 - precision: 0.8828 - val_loss: 0.6150 - val_accuracy: 0.7203 - val_sensitivity_at_specificity: 0.9058 - val_specificity_at_sensitivity: 0.9067 - val_recall: 0.8248 - val_precision: 0.6644\n",
            "Epoch 202/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3168 - accuracy: 0.8469 - sensitivity_at_specificity: 0.9795 - specificity_at_sensitivity: 0.9960 - recall: 0.8126 - precision: 0.8808\n",
            "Epoch 202: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 208ms/step - loss: 0.3168 - accuracy: 0.8469 - sensitivity_at_specificity: 0.9795 - specificity_at_sensitivity: 0.9960 - recall: 0.8126 - precision: 0.8808 - val_loss: 0.5905 - val_accuracy: 0.7375 - val_sensitivity_at_specificity: 0.9396 - val_specificity_at_sensitivity: 0.9155 - val_recall: 0.8744 - val_precision: 0.6815\n",
            "Epoch 203/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3249 - accuracy: 0.8426 - sensitivity_at_specificity: 0.9835 - specificity_at_sensitivity: 0.9923 - recall: 0.8140 - precision: 0.8608\n",
            "Epoch 203: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 206ms/step - loss: 0.3249 - accuracy: 0.8426 - sensitivity_at_specificity: 0.9835 - specificity_at_sensitivity: 0.9923 - recall: 0.8140 - precision: 0.8608 - val_loss: 0.5988 - val_accuracy: 0.7336 - val_sensitivity_at_specificity: 0.9375 - val_specificity_at_sensitivity: 0.9187 - val_recall: 0.8813 - val_precision: 0.6803\n",
            "Epoch 204/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3230 - accuracy: 0.8449 - sensitivity_at_specificity: 0.9773 - specificity_at_sensitivity: 0.9938 - recall: 0.8285 - precision: 0.8560\n",
            "Epoch 204: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 208ms/step - loss: 0.3230 - accuracy: 0.8449 - sensitivity_at_specificity: 0.9773 - specificity_at_sensitivity: 0.9938 - recall: 0.8285 - precision: 0.8560 - val_loss: 0.5779 - val_accuracy: 0.7320 - val_sensitivity_at_specificity: 0.9080 - val_specificity_at_sensitivity: 0.9061 - val_recall: 0.8466 - val_precision: 0.6943\n",
            "Epoch 205/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2997 - accuracy: 0.8594 - sensitivity_at_specificity: 0.9847 - specificity_at_sensitivity: 0.9992 - recall: 0.8305 - precision: 0.8863\n",
            "Epoch 205: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 210ms/step - loss: 0.2997 - accuracy: 0.8594 - sensitivity_at_specificity: 0.9847 - specificity_at_sensitivity: 0.9992 - recall: 0.8305 - precision: 0.8863 - val_loss: 0.6529 - val_accuracy: 0.7148 - val_sensitivity_at_specificity: 0.9038 - val_specificity_at_sensitivity: 0.8824 - val_recall: 0.8344 - val_precision: 0.6705\n",
            "Epoch 206/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3039 - accuracy: 0.8555 - sensitivity_at_specificity: 0.9823 - specificity_at_sensitivity: 0.9937 - recall: 0.8419 - precision: 0.8687\n",
            "Epoch 206: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 208ms/step - loss: 0.3039 - accuracy: 0.8555 - sensitivity_at_specificity: 0.9823 - specificity_at_sensitivity: 0.9937 - recall: 0.8419 - precision: 0.8687 - val_loss: 0.5629 - val_accuracy: 0.7570 - val_sensitivity_at_specificity: 0.9313 - val_specificity_at_sensitivity: 0.9200 - val_recall: 0.8626 - val_precision: 0.7188\n",
            "Epoch 207/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2890 - accuracy: 0.8711 - sensitivity_at_specificity: 0.9865 - specificity_at_sensitivity: 0.9977 - recall: 0.8425 - precision: 0.8892\n",
            "Epoch 207: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 206ms/step - loss: 0.2890 - accuracy: 0.8711 - sensitivity_at_specificity: 0.9865 - specificity_at_sensitivity: 0.9977 - recall: 0.8425 - precision: 0.8892 - val_loss: 0.6304 - val_accuracy: 0.7312 - val_sensitivity_at_specificity: 0.9167 - val_specificity_at_sensitivity: 0.8799 - val_recall: 0.8155 - val_precision: 0.7135\n",
            "Epoch 208/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2928 - accuracy: 0.8621 - sensitivity_at_specificity: 0.9890 - specificity_at_sensitivity: 0.9938 - recall: 0.8263 - precision: 0.8896\n",
            "Epoch 208: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 205ms/step - loss: 0.2928 - accuracy: 0.8621 - sensitivity_at_specificity: 0.9890 - specificity_at_sensitivity: 0.9938 - recall: 0.8263 - precision: 0.8896 - val_loss: 0.7193 - val_accuracy: 0.7156 - val_sensitivity_at_specificity: 0.9105 - val_specificity_at_sensitivity: 0.8895 - val_recall: 0.8885 - val_precision: 0.6383\n",
            "Epoch 209/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2969 - accuracy: 0.8594 - sensitivity_at_specificity: 0.9838 - specificity_at_sensitivity: 0.9968 - recall: 0.8314 - precision: 0.8833\n",
            "Epoch 209: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 206ms/step - loss: 0.2969 - accuracy: 0.8594 - sensitivity_at_specificity: 0.9838 - specificity_at_sensitivity: 0.9968 - recall: 0.8314 - precision: 0.8833 - val_loss: 0.6767 - val_accuracy: 0.7172 - val_sensitivity_at_specificity: 0.9198 - val_specificity_at_sensitivity: 0.9128 - val_recall: 0.8775 - val_precision: 0.6736\n",
            "Epoch 210/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2883 - accuracy: 0.8672 - sensitivity_at_specificity: 0.9913 - specificity_at_sensitivity: 0.9977 - recall: 0.8456 - precision: 0.8805\n",
            "Epoch 210: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 207ms/step - loss: 0.2883 - accuracy: 0.8672 - sensitivity_at_specificity: 0.9913 - specificity_at_sensitivity: 0.9977 - recall: 0.8456 - precision: 0.8805 - val_loss: 0.7269 - val_accuracy: 0.7234 - val_sensitivity_at_specificity: 0.9533 - val_specificity_at_sensitivity: 0.8793 - val_recall: 0.8816 - val_precision: 0.6706\n",
            "Epoch 211/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2855 - accuracy: 0.8596 - sensitivity_at_specificity: 0.9876 - specificity_at_sensitivity: 0.9967 - recall: 0.8456 - precision: 0.8715\n",
            "Epoch 211: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 3s 279ms/step - loss: 0.2855 - accuracy: 0.8596 - sensitivity_at_specificity: 0.9876 - specificity_at_sensitivity: 0.9967 - recall: 0.8456 - precision: 0.8715 - val_loss: 0.6535 - val_accuracy: 0.7344 - val_sensitivity_at_specificity: 0.9265 - val_specificity_at_sensitivity: 0.8947 - val_recall: 0.8622 - val_precision: 0.6925\n",
            "Epoch 212/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2963 - accuracy: 0.8660 - sensitivity_at_specificity: 0.9891 - specificity_at_sensitivity: 0.9945 - recall: 0.8379 - precision: 0.8896\n",
            "Epoch 212: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 214ms/step - loss: 0.2963 - accuracy: 0.8660 - sensitivity_at_specificity: 0.9891 - specificity_at_sensitivity: 0.9945 - recall: 0.8379 - precision: 0.8896 - val_loss: 0.6385 - val_accuracy: 0.7281 - val_sensitivity_at_specificity: 0.8998 - val_specificity_at_sensitivity: 0.8908 - val_recall: 0.8310 - val_precision: 0.6887\n",
            "Epoch 213/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2767 - accuracy: 0.8777 - sensitivity_at_specificity: 0.9861 - specificity_at_sensitivity: 0.9985 - recall: 0.8474 - precision: 0.8905\n",
            "Epoch 213: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 209ms/step - loss: 0.2767 - accuracy: 0.8777 - sensitivity_at_specificity: 0.9861 - specificity_at_sensitivity: 0.9985 - recall: 0.8474 - precision: 0.8905 - val_loss: 0.6711 - val_accuracy: 0.7352 - val_sensitivity_at_specificity: 0.9172 - val_specificity_at_sensitivity: 0.8891 - val_recall: 0.8813 - val_precision: 0.6820\n",
            "Epoch 214/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2675 - accuracy: 0.8844 - sensitivity_at_specificity: 0.9861 - specificity_at_sensitivity: 0.9968 - recall: 0.8623 - precision: 0.9043\n",
            "Epoch 214: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 212ms/step - loss: 0.2675 - accuracy: 0.8844 - sensitivity_at_specificity: 0.9861 - specificity_at_sensitivity: 0.9968 - recall: 0.8623 - precision: 0.9043 - val_loss: 0.6493 - val_accuracy: 0.7312 - val_sensitivity_at_specificity: 0.9006 - val_specificity_at_sensitivity: 0.8947 - val_recall: 0.8168 - val_precision: 0.6995\n",
            "Epoch 215/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2984 - accuracy: 0.8641 - sensitivity_at_specificity: 0.9826 - specificity_at_sensitivity: 0.9960 - recall: 0.8378 - precision: 0.8918\n",
            "Epoch 215: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 211ms/step - loss: 0.2984 - accuracy: 0.8641 - sensitivity_at_specificity: 0.9826 - specificity_at_sensitivity: 0.9960 - recall: 0.8378 - precision: 0.8918 - val_loss: 0.6107 - val_accuracy: 0.7141 - val_sensitivity_at_specificity: 0.9092 - val_specificity_at_sensitivity: 0.8924 - val_recall: 0.8435 - val_precision: 0.6696\n",
            "Epoch 216/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2763 - accuracy: 0.8809 - sensitivity_at_specificity: 0.9854 - specificity_at_sensitivity: 0.9984 - recall: 0.8688 - precision: 0.8942\n",
            "Epoch 216: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 211ms/step - loss: 0.2763 - accuracy: 0.8809 - sensitivity_at_specificity: 0.9854 - specificity_at_sensitivity: 0.9984 - recall: 0.8688 - precision: 0.8942 - val_loss: 0.7168 - val_accuracy: 0.7086 - val_sensitivity_at_specificity: 0.9064 - val_specificity_at_sensitivity: 0.8967 - val_recall: 0.8409 - val_precision: 0.6654\n",
            "Epoch 217/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2870 - accuracy: 0.8668 - sensitivity_at_specificity: 0.9913 - specificity_at_sensitivity: 0.9946 - recall: 0.8446 - precision: 0.8815\n",
            "Epoch 217: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 209ms/step - loss: 0.2870 - accuracy: 0.8668 - sensitivity_at_specificity: 0.9913 - specificity_at_sensitivity: 0.9946 - recall: 0.8446 - precision: 0.8815 - val_loss: 0.7672 - val_accuracy: 0.7352 - val_sensitivity_at_specificity: 0.9357 - val_specificity_at_sensitivity: 0.8972 - val_recall: 0.8997 - val_precision: 0.6761\n",
            "Epoch 218/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2638 - accuracy: 0.8813 - sensitivity_at_specificity: 0.9877 - specificity_at_sensitivity: 0.9992 - recall: 0.8750 - precision: 0.8900\n",
            "Epoch 218: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 207ms/step - loss: 0.2638 - accuracy: 0.8813 - sensitivity_at_specificity: 0.9877 - specificity_at_sensitivity: 0.9992 - recall: 0.8750 - precision: 0.8900 - val_loss: 0.7721 - val_accuracy: 0.7102 - val_sensitivity_at_specificity: 0.9136 - val_specificity_at_sensitivity: 0.9084 - val_recall: 0.9104 - val_precision: 0.6437\n",
            "Epoch 219/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2721 - accuracy: 0.8797 - sensitivity_at_specificity: 0.9900 - specificity_at_sensitivity: 0.9968 - recall: 0.8501 - precision: 0.9061\n",
            "Epoch 219: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 206ms/step - loss: 0.2721 - accuracy: 0.8797 - sensitivity_at_specificity: 0.9900 - specificity_at_sensitivity: 0.9968 - recall: 0.8501 - precision: 0.9061 - val_loss: 0.7452 - val_accuracy: 0.7180 - val_sensitivity_at_specificity: 0.9286 - val_specificity_at_sensitivity: 0.9072 - val_recall: 0.9239 - val_precision: 0.6560\n",
            "Epoch 220/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2558 - accuracy: 0.8829 - sensitivity_at_specificity: 0.9931 - specificity_at_sensitivity: 0.9968 - recall: 0.8616 - precision: 0.8923\n",
            "Epoch 220: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 0.2558 - accuracy: 0.8829 - sensitivity_at_specificity: 0.9931 - specificity_at_sensitivity: 0.9968 - recall: 0.8616 - precision: 0.8923 - val_loss: 0.7454 - val_accuracy: 0.7148 - val_sensitivity_at_specificity: 0.9242 - val_specificity_at_sensitivity: 0.8924 - val_recall: 0.8903 - val_precision: 0.6502\n",
            "Epoch 221/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2529 - accuracy: 0.8840 - sensitivity_at_specificity: 0.9896 - specificity_at_sensitivity: 0.9992 - recall: 0.8524 - precision: 0.9051\n",
            "Epoch 221: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 210ms/step - loss: 0.2529 - accuracy: 0.8840 - sensitivity_at_specificity: 0.9896 - specificity_at_sensitivity: 0.9992 - recall: 0.8524 - precision: 0.9051 - val_loss: 0.8233 - val_accuracy: 0.7133 - val_sensitivity_at_specificity: 0.9153 - val_specificity_at_sensitivity: 0.8807 - val_recall: 0.8578 - val_precision: 0.6589\n",
            "Epoch 222/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2441 - accuracy: 0.8953 - sensitivity_at_specificity: 0.9939 - specificity_at_sensitivity: 1.0000 - recall: 0.8711 - precision: 0.9202\n",
            "Epoch 222: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 208ms/step - loss: 0.2441 - accuracy: 0.8953 - sensitivity_at_specificity: 0.9939 - specificity_at_sensitivity: 1.0000 - recall: 0.8711 - precision: 0.9202 - val_loss: 0.7069 - val_accuracy: 0.7234 - val_sensitivity_at_specificity: 0.9401 - val_specificity_at_sensitivity: 0.8903 - val_recall: 0.9017 - val_precision: 0.6693\n",
            "Epoch 223/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2602 - accuracy: 0.8871 - sensitivity_at_specificity: 0.9857 - specificity_at_sensitivity: 0.9992 - recall: 0.8563 - precision: 0.9090\n",
            "Epoch 223: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 211ms/step - loss: 0.2602 - accuracy: 0.8871 - sensitivity_at_specificity: 0.9857 - specificity_at_sensitivity: 0.9992 - recall: 0.8563 - precision: 0.9090 - val_loss: 0.8308 - val_accuracy: 0.7258 - val_sensitivity_at_specificity: 0.9432 - val_specificity_at_sensitivity: 0.8824 - val_recall: 0.9309 - val_precision: 0.6645\n",
            "Epoch 224/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2474 - accuracy: 0.8887 - sensitivity_at_specificity: 0.9923 - specificity_at_sensitivity: 0.9984 - recall: 0.8770 - precision: 0.9013\n",
            "Epoch 224: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 212ms/step - loss: 0.2474 - accuracy: 0.8887 - sensitivity_at_specificity: 0.9923 - specificity_at_sensitivity: 0.9984 - recall: 0.8770 - precision: 0.9013 - val_loss: 0.8445 - val_accuracy: 0.7352 - val_sensitivity_at_specificity: 0.9246 - val_specificity_at_sensitivity: 0.8606 - val_recall: 0.8854 - val_precision: 0.6906\n",
            "Epoch 225/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2567 - accuracy: 0.8859 - sensitivity_at_specificity: 0.9929 - specificity_at_sensitivity: 0.9977 - recall: 0.8578 - precision: 0.9053\n",
            "Epoch 225: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 214ms/step - loss: 0.2567 - accuracy: 0.8859 - sensitivity_at_specificity: 0.9929 - specificity_at_sensitivity: 0.9977 - recall: 0.8578 - precision: 0.9053 - val_loss: 0.7637 - val_accuracy: 0.7141 - val_sensitivity_at_specificity: 0.9091 - val_specificity_at_sensitivity: 0.8690 - val_recall: 0.8669 - val_precision: 0.6528\n",
            "Epoch 226/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2384 - accuracy: 0.8938 - sensitivity_at_specificity: 0.9946 - specificity_at_sensitivity: 1.0000 - recall: 0.8694 - precision: 0.9149\n",
            "Epoch 226: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 208ms/step - loss: 0.2384 - accuracy: 0.8938 - sensitivity_at_specificity: 0.9946 - specificity_at_sensitivity: 1.0000 - recall: 0.8694 - precision: 0.9149 - val_loss: 0.9072 - val_accuracy: 0.7164 - val_sensitivity_at_specificity: 0.9135 - val_specificity_at_sensitivity: 0.8674 - val_recall: 0.9006 - val_precision: 0.6512\n",
            "Epoch 227/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2291 - accuracy: 0.8984 - sensitivity_at_specificity: 0.9960 - specificity_at_sensitivity: 0.9992 - recall: 0.8810 - precision: 0.9099\n",
            "Epoch 227: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 207ms/step - loss: 0.2291 - accuracy: 0.8984 - sensitivity_at_specificity: 0.9960 - specificity_at_sensitivity: 0.9992 - recall: 0.8810 - precision: 0.9099 - val_loss: 0.8573 - val_accuracy: 0.7195 - val_sensitivity_at_specificity: 0.9212 - val_specificity_at_sensitivity: 0.8500 - val_recall: 0.9000 - val_precision: 0.6697\n",
            "Epoch 228/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2391 - accuracy: 0.8898 - sensitivity_at_specificity: 0.9977 - specificity_at_sensitivity: 1.0000 - recall: 0.8672 - precision: 0.9083\n",
            "Epoch 228: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 207ms/step - loss: 0.2391 - accuracy: 0.8898 - sensitivity_at_specificity: 0.9977 - specificity_at_sensitivity: 1.0000 - recall: 0.8672 - precision: 0.9083 - val_loss: 0.7491 - val_accuracy: 0.7227 - val_sensitivity_at_specificity: 0.9304 - val_specificity_at_sensitivity: 0.8805 - val_recall: 0.8759 - val_precision: 0.6796\n",
            "Epoch 229/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2423 - accuracy: 0.8929 - sensitivity_at_specificity: 0.9918 - specificity_at_sensitivity: 1.0000 - recall: 0.8705 - precision: 0.9139\n",
            "Epoch 229: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 200ms/step - loss: 0.2423 - accuracy: 0.8929 - sensitivity_at_specificity: 0.9918 - specificity_at_sensitivity: 1.0000 - recall: 0.8705 - precision: 0.9139 - val_loss: 0.8169 - val_accuracy: 0.7258 - val_sensitivity_at_specificity: 0.9228 - val_specificity_at_sensitivity: 0.8643 - val_recall: 0.9017 - val_precision: 0.6757\n",
            "Epoch 230/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2368 - accuracy: 0.8980 - sensitivity_at_specificity: 0.9947 - specificity_at_sensitivity: 0.9992 - recall: 0.8881 - precision: 0.9110\n",
            "Epoch 230: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 206ms/step - loss: 0.2368 - accuracy: 0.8980 - sensitivity_at_specificity: 0.9947 - specificity_at_sensitivity: 0.9992 - recall: 0.8881 - precision: 0.9110 - val_loss: 0.7914 - val_accuracy: 0.7086 - val_sensitivity_at_specificity: 0.9266 - val_specificity_at_sensitivity: 0.8734 - val_recall: 0.8750 - val_precision: 0.6565\n",
            "Epoch 231/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2315 - accuracy: 0.8914 - sensitivity_at_specificity: 0.9952 - specificity_at_sensitivity: 1.0000 - recall: 0.8640 - precision: 0.9091\n",
            "Epoch 231: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 208ms/step - loss: 0.2315 - accuracy: 0.8914 - sensitivity_at_specificity: 0.9952 - specificity_at_sensitivity: 1.0000 - recall: 0.8640 - precision: 0.9091 - val_loss: 0.6692 - val_accuracy: 0.7406 - val_sensitivity_at_specificity: 0.9312 - val_specificity_at_sensitivity: 0.8844 - val_recall: 0.8697 - val_precision: 0.7097\n",
            "Epoch 232/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2364 - accuracy: 0.9003 - sensitivity_at_specificity: 0.9900 - specificity_at_sensitivity: 1.0000 - recall: 0.8569 - precision: 0.9369\n",
            "Epoch 232: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 196ms/step - loss: 0.2364 - accuracy: 0.9003 - sensitivity_at_specificity: 0.9900 - specificity_at_sensitivity: 1.0000 - recall: 0.8569 - precision: 0.9369 - val_loss: 0.8207 - val_accuracy: 0.7141 - val_sensitivity_at_specificity: 0.9087 - val_specificity_at_sensitivity: 0.8925 - val_recall: 0.8828 - val_precision: 0.6674\n",
            "Epoch 233/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2358 - accuracy: 0.8949 - sensitivity_at_specificity: 0.9932 - specificity_at_sensitivity: 0.9992 - recall: 0.8815 - precision: 0.9125\n",
            "Epoch 233: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 208ms/step - loss: 0.2358 - accuracy: 0.8949 - sensitivity_at_specificity: 0.9932 - specificity_at_sensitivity: 0.9992 - recall: 0.8815 - precision: 0.9125 - val_loss: 0.8223 - val_accuracy: 0.7281 - val_sensitivity_at_specificity: 0.9174 - val_specificity_at_sensitivity: 0.8844 - val_recall: 0.9144 - val_precision: 0.6767\n",
            "Epoch 234/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2199 - accuracy: 0.9047 - sensitivity_at_specificity: 0.9959 - specificity_at_sensitivity: 0.9992 - recall: 0.8904 - precision: 0.9096\n",
            "Epoch 234: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 206ms/step - loss: 0.2199 - accuracy: 0.9047 - sensitivity_at_specificity: 0.9959 - specificity_at_sensitivity: 0.9992 - recall: 0.8904 - precision: 0.9096 - val_loss: 0.9399 - val_accuracy: 0.7195 - val_sensitivity_at_specificity: 0.9206 - val_specificity_at_sensitivity: 0.8699 - val_recall: 0.9143 - val_precision: 0.6588\n",
            "Epoch 235/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2269 - accuracy: 0.8984 - sensitivity_at_specificity: 0.9953 - specificity_at_sensitivity: 0.9992 - recall: 0.8718 - precision: 0.9183\n",
            "Epoch 235: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 207ms/step - loss: 0.2269 - accuracy: 0.8984 - sensitivity_at_specificity: 0.9953 - specificity_at_sensitivity: 0.9992 - recall: 0.8718 - precision: 0.9183 - val_loss: 0.8290 - val_accuracy: 0.7109 - val_sensitivity_at_specificity: 0.8990 - val_specificity_at_sensitivity: 0.8765 - val_recall: 0.8654 - val_precision: 0.6538\n",
            "Epoch 236/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2151 - accuracy: 0.9102 - sensitivity_at_specificity: 0.9952 - specificity_at_sensitivity: 1.0000 - recall: 0.8961 - precision: 0.9194\n",
            "Epoch 236: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 207ms/step - loss: 0.2151 - accuracy: 0.9102 - sensitivity_at_specificity: 0.9952 - specificity_at_sensitivity: 1.0000 - recall: 0.8961 - precision: 0.9194 - val_loss: 0.8742 - val_accuracy: 0.7070 - val_sensitivity_at_specificity: 0.9210 - val_specificity_at_sensitivity: 0.8894 - val_recall: 0.9000 - val_precision: 0.6406\n",
            "Epoch 237/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2229 - accuracy: 0.9070 - sensitivity_at_specificity: 0.9930 - specificity_at_sensitivity: 0.9992 - recall: 0.8874 - precision: 0.9235\n",
            "Epoch 237: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 207ms/step - loss: 0.2229 - accuracy: 0.9070 - sensitivity_at_specificity: 0.9930 - specificity_at_sensitivity: 0.9992 - recall: 0.8874 - precision: 0.9235 - val_loss: 0.9000 - val_accuracy: 0.7133 - val_sensitivity_at_specificity: 0.9263 - val_specificity_at_sensitivity: 0.8948 - val_recall: 0.8926 - val_precision: 0.6499\n",
            "Epoch 238/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2165 - accuracy: 0.9051 - sensitivity_at_specificity: 0.9953 - specificity_at_sensitivity: 0.9992 - recall: 0.8853 - precision: 0.9195\n",
            "Epoch 238: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 205ms/step - loss: 0.2165 - accuracy: 0.9051 - sensitivity_at_specificity: 0.9953 - specificity_at_sensitivity: 0.9992 - recall: 0.8853 - precision: 0.9195 - val_loss: 0.8835 - val_accuracy: 0.7281 - val_sensitivity_at_specificity: 0.9328 - val_specificity_at_sensitivity: 0.8859 - val_recall: 0.9078 - val_precision: 0.6678\n",
            "Epoch 239/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2152 - accuracy: 0.9055 - sensitivity_at_specificity: 0.9977 - specificity_at_sensitivity: 1.0000 - recall: 0.8876 - precision: 0.9244\n",
            "Epoch 239: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 207ms/step - loss: 0.2152 - accuracy: 0.9055 - sensitivity_at_specificity: 0.9977 - specificity_at_sensitivity: 1.0000 - recall: 0.8876 - precision: 0.9244 - val_loss: 0.8739 - val_accuracy: 0.7328 - val_sensitivity_at_specificity: 0.9353 - val_specificity_at_sensitivity: 0.8780 - val_recall: 0.9053 - val_precision: 0.6833\n",
            "Epoch 240/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2178 - accuracy: 0.9049 - sensitivity_at_specificity: 0.9967 - specificity_at_sensitivity: 0.9983 - recall: 0.8936 - precision: 0.9169\n",
            "Epoch 240: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 202ms/step - loss: 0.2178 - accuracy: 0.9049 - sensitivity_at_specificity: 0.9967 - specificity_at_sensitivity: 0.9983 - recall: 0.8936 - precision: 0.9169 - val_loss: 0.9004 - val_accuracy: 0.7227 - val_sensitivity_at_specificity: 0.9262 - val_specificity_at_sensitivity: 0.8810 - val_recall: 0.9077 - val_precision: 0.6667\n",
            "Epoch 241/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2117 - accuracy: 0.9047 - sensitivity_at_specificity: 0.9946 - specificity_at_sensitivity: 1.0000 - recall: 0.8960 - precision: 0.9156\n",
            "Epoch 241: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 213ms/step - loss: 0.2117 - accuracy: 0.9047 - sensitivity_at_specificity: 0.9946 - specificity_at_sensitivity: 1.0000 - recall: 0.8960 - precision: 0.9156 - val_loss: 0.7806 - val_accuracy: 0.7445 - val_sensitivity_at_specificity: 0.9493 - val_specificity_at_sensitivity: 0.8783 - val_recall: 0.9097 - val_precision: 0.6801\n",
            "Epoch 242/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2307 - accuracy: 0.9045 - sensitivity_at_specificity: 0.9923 - specificity_at_sensitivity: 1.0000 - recall: 0.8768 - precision: 0.9226\n",
            "Epoch 242: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 202ms/step - loss: 0.2307 - accuracy: 0.9045 - sensitivity_at_specificity: 0.9923 - specificity_at_sensitivity: 1.0000 - recall: 0.8768 - precision: 0.9226 - val_loss: 0.9502 - val_accuracy: 0.6977 - val_sensitivity_at_specificity: 0.9078 - val_specificity_at_sensitivity: 0.8701 - val_recall: 0.9061 - val_precision: 0.6299\n",
            "Epoch 243/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2070 - accuracy: 0.9094 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.8917 - precision: 0.9236\n",
            "Epoch 243: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 208ms/step - loss: 0.2070 - accuracy: 0.9094 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.8917 - precision: 0.9236 - val_loss: 0.9921 - val_accuracy: 0.7195 - val_sensitivity_at_specificity: 0.9148 - val_specificity_at_sensitivity: 0.8716 - val_recall: 0.9041 - val_precision: 0.6674\n",
            "Epoch 244/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2108 - accuracy: 0.9086 - sensitivity_at_specificity: 0.9945 - specificity_at_sensitivity: 0.9992 - recall: 0.8796 - precision: 0.9336\n",
            "Epoch 244: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 209ms/step - loss: 0.2108 - accuracy: 0.9086 - sensitivity_at_specificity: 0.9945 - specificity_at_sensitivity: 0.9992 - recall: 0.8796 - precision: 0.9336 - val_loss: 1.0367 - val_accuracy: 0.7141 - val_sensitivity_at_specificity: 0.9199 - val_specificity_at_sensitivity: 0.8336 - val_recall: 0.9183 - val_precision: 0.6557\n",
            "Epoch 245/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2141 - accuracy: 0.9074 - sensitivity_at_specificity: 0.9937 - specificity_at_sensitivity: 0.9984 - recall: 0.8868 - precision: 0.9238\n",
            "Epoch 245: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 205ms/step - loss: 0.2141 - accuracy: 0.9074 - sensitivity_at_specificity: 0.9937 - specificity_at_sensitivity: 0.9984 - recall: 0.8868 - precision: 0.9238 - val_loss: 0.8407 - val_accuracy: 0.7289 - val_sensitivity_at_specificity: 0.9277 - val_specificity_at_sensitivity: 0.8665 - val_recall: 0.9009 - val_precision: 0.6686\n",
            "Epoch 246/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2084 - accuracy: 0.9053 - sensitivity_at_specificity: 0.9944 - specificity_at_sensitivity: 1.0000 - recall: 0.8857 - precision: 0.9275\n",
            "Epoch 246: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 204ms/step - loss: 0.2084 - accuracy: 0.9053 - sensitivity_at_specificity: 0.9944 - specificity_at_sensitivity: 1.0000 - recall: 0.8857 - precision: 0.9275 - val_loss: 0.9198 - val_accuracy: 0.7195 - val_sensitivity_at_specificity: 0.9204 - val_specificity_at_sensitivity: 0.8779 - val_recall: 0.9142 - val_precision: 0.6584\n",
            "Epoch 247/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1894 - accuracy: 0.9223 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9086 - precision: 0.9367\n",
            "Epoch 247: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 214ms/step - loss: 0.1894 - accuracy: 0.9223 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9086 - precision: 0.9367 - val_loss: 0.9219 - val_accuracy: 0.7453 - val_sensitivity_at_specificity: 0.9476 - val_specificity_at_sensitivity: 0.8574 - val_recall: 0.9122 - val_precision: 0.6876\n",
            "Epoch 248/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1998 - accuracy: 0.9113 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9992 - recall: 0.8936 - precision: 0.9275\n",
            "Epoch 248: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 211ms/step - loss: 0.1998 - accuracy: 0.9113 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9992 - recall: 0.8936 - precision: 0.9275 - val_loss: 0.8352 - val_accuracy: 0.7102 - val_sensitivity_at_specificity: 0.9111 - val_specificity_at_sensitivity: 0.8775 - val_recall: 0.8498 - val_precision: 0.6542\n",
            "Epoch 249/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1882 - accuracy: 0.9195 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.8978 - precision: 0.9339\n",
            "Epoch 249: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 208ms/step - loss: 0.1882 - accuracy: 0.9195 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.8978 - precision: 0.9339 - val_loss: 0.9257 - val_accuracy: 0.7320 - val_sensitivity_at_specificity: 0.9352 - val_specificity_at_sensitivity: 0.8639 - val_recall: 0.9259 - val_precision: 0.6704\n",
            "Epoch 250/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1912 - accuracy: 0.9199 - sensitivity_at_specificity: 0.9977 - specificity_at_sensitivity: 1.0000 - recall: 0.9008 - precision: 0.9391\n",
            "Epoch 250: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 212ms/step - loss: 0.1912 - accuracy: 0.9199 - sensitivity_at_specificity: 0.9977 - specificity_at_sensitivity: 1.0000 - recall: 0.9008 - precision: 0.9391 - val_loss: 1.0195 - val_accuracy: 0.7039 - val_sensitivity_at_specificity: 0.9192 - val_specificity_at_sensitivity: 0.8998 - val_recall: 0.9255 - val_precision: 0.6376\n",
            "Epoch 251/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2065 - accuracy: 0.9125 - sensitivity_at_specificity: 0.9953 - specificity_at_sensitivity: 1.0000 - recall: 0.8961 - precision: 0.9252\n",
            "Epoch 251: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 213ms/step - loss: 0.2065 - accuracy: 0.9125 - sensitivity_at_specificity: 0.9953 - specificity_at_sensitivity: 1.0000 - recall: 0.8961 - precision: 0.9252 - val_loss: 0.8036 - val_accuracy: 0.7328 - val_sensitivity_at_specificity: 0.9463 - val_specificity_at_sensitivity: 0.8779 - val_recall: 0.8957 - val_precision: 0.6726\n",
            "Epoch 252/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1993 - accuracy: 0.9141 - sensitivity_at_specificity: 0.9954 - specificity_at_sensitivity: 0.9992 - recall: 0.9025 - precision: 0.9254\n",
            "Epoch 252: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 209ms/step - loss: 0.1993 - accuracy: 0.9141 - sensitivity_at_specificity: 0.9954 - specificity_at_sensitivity: 0.9992 - recall: 0.9025 - precision: 0.9254 - val_loss: 0.9776 - val_accuracy: 0.6992 - val_sensitivity_at_specificity: 0.9148 - val_specificity_at_sensitivity: 0.8526 - val_recall: 0.8971 - val_precision: 0.6348\n",
            "Epoch 253/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1908 - accuracy: 0.9215 - sensitivity_at_specificity: 0.9969 - specificity_at_sensitivity: 1.0000 - recall: 0.9024 - precision: 0.9370\n",
            "Epoch 253: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 211ms/step - loss: 0.1908 - accuracy: 0.9215 - sensitivity_at_specificity: 0.9969 - specificity_at_sensitivity: 1.0000 - recall: 0.9024 - precision: 0.9370 - val_loss: 0.9814 - val_accuracy: 0.7086 - val_sensitivity_at_specificity: 0.9014 - val_specificity_at_sensitivity: 0.8583 - val_recall: 0.8847 - val_precision: 0.6625\n",
            "Epoch 254/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1966 - accuracy: 0.9141 - sensitivity_at_specificity: 0.9977 - specificity_at_sensitivity: 1.0000 - recall: 0.8912 - precision: 0.9360\n",
            "Epoch 254: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 212ms/step - loss: 0.1966 - accuracy: 0.9141 - sensitivity_at_specificity: 0.9977 - specificity_at_sensitivity: 1.0000 - recall: 0.8912 - precision: 0.9360 - val_loss: 0.9873 - val_accuracy: 0.7086 - val_sensitivity_at_specificity: 0.9184 - val_specificity_at_sensitivity: 0.8672 - val_recall: 0.9168 - val_precision: 0.6409\n",
            "Epoch 255/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1829 - accuracy: 0.9207 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9992 - recall: 0.8940 - precision: 0.9413\n",
            "Epoch 255: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 207ms/step - loss: 0.1829 - accuracy: 0.9207 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9992 - recall: 0.8940 - precision: 0.9413 - val_loss: 0.8501 - val_accuracy: 0.7180 - val_sensitivity_at_specificity: 0.9104 - val_specificity_at_sensitivity: 0.8656 - val_recall: 0.8776 - val_precision: 0.6782\n",
            "Epoch 256/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1922 - accuracy: 0.9191 - sensitivity_at_specificity: 0.9976 - specificity_at_sensitivity: 1.0000 - recall: 0.8997 - precision: 0.9331\n",
            "Epoch 256: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 207ms/step - loss: 0.1922 - accuracy: 0.9191 - sensitivity_at_specificity: 0.9976 - specificity_at_sensitivity: 1.0000 - recall: 0.8997 - precision: 0.9331 - val_loss: 0.8855 - val_accuracy: 0.7258 - val_sensitivity_at_specificity: 0.9187 - val_specificity_at_sensitivity: 0.8912 - val_recall: 0.9081 - val_precision: 0.6753\n",
            "Epoch 257/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1842 - accuracy: 0.9187 - sensitivity_at_specificity: 0.9961 - specificity_at_sensitivity: 1.0000 - recall: 0.9034 - precision: 0.9312\n",
            "Epoch 257: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 208ms/step - loss: 0.1842 - accuracy: 0.9187 - sensitivity_at_specificity: 0.9961 - specificity_at_sensitivity: 1.0000 - recall: 0.9034 - precision: 0.9312 - val_loss: 0.9714 - val_accuracy: 0.7141 - val_sensitivity_at_specificity: 0.9309 - val_specificity_at_sensitivity: 0.8974 - val_recall: 0.9137 - val_precision: 0.6517\n",
            "Epoch 258/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1801 - accuracy: 0.9195 - sensitivity_at_specificity: 0.9976 - specificity_at_sensitivity: 1.0000 - recall: 0.8965 - precision: 0.9368\n",
            "Epoch 258: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 206ms/step - loss: 0.1801 - accuracy: 0.9195 - sensitivity_at_specificity: 0.9976 - specificity_at_sensitivity: 1.0000 - recall: 0.8965 - precision: 0.9368 - val_loss: 0.9363 - val_accuracy: 0.7328 - val_sensitivity_at_specificity: 0.9486 - val_specificity_at_sensitivity: 0.9060 - val_recall: 0.8988 - val_precision: 0.6756\n",
            "Epoch 259/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1813 - accuracy: 0.9219 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9109 - precision: 0.9313\n",
            "Epoch 259: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 208ms/step - loss: 0.1813 - accuracy: 0.9219 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9109 - precision: 0.9313 - val_loss: 1.1534 - val_accuracy: 0.6969 - val_sensitivity_at_specificity: 0.9102 - val_specificity_at_sensitivity: 0.8682 - val_recall: 0.9213 - val_precision: 0.6338\n",
            "Epoch 260/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1707 - accuracy: 0.9273 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9086 - precision: 0.9363\n",
            "Epoch 260: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 209ms/step - loss: 0.1707 - accuracy: 0.9273 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9086 - precision: 0.9363 - val_loss: 1.0905 - val_accuracy: 0.7063 - val_sensitivity_at_specificity: 0.9009 - val_specificity_at_sensitivity: 0.8898 - val_recall: 0.8947 - val_precision: 0.6481\n",
            "Epoch 261/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1779 - accuracy: 0.9219 - sensitivity_at_specificity: 0.9977 - specificity_at_sensitivity: 1.0000 - recall: 0.9000 - precision: 0.9447\n",
            "Epoch 261: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 210ms/step - loss: 0.1779 - accuracy: 0.9219 - sensitivity_at_specificity: 0.9977 - specificity_at_sensitivity: 1.0000 - recall: 0.9000 - precision: 0.9447 - val_loss: 1.0063 - val_accuracy: 0.7344 - val_sensitivity_at_specificity: 0.9356 - val_specificity_at_sensitivity: 0.8758 - val_recall: 0.9162 - val_precision: 0.6830\n",
            "Epoch 262/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1743 - accuracy: 0.9277 - sensitivity_at_specificity: 0.9977 - specificity_at_sensitivity: 1.0000 - recall: 0.9124 - precision: 0.9436\n",
            "Epoch 262: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 211ms/step - loss: 0.1743 - accuracy: 0.9277 - sensitivity_at_specificity: 0.9977 - specificity_at_sensitivity: 1.0000 - recall: 0.9124 - precision: 0.9436 - val_loss: 1.0811 - val_accuracy: 0.7063 - val_sensitivity_at_specificity: 0.9076 - val_specificity_at_sensitivity: 0.8507 - val_recall: 0.9044 - val_precision: 0.6377\n",
            "Epoch 263/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1697 - accuracy: 0.9266 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9045 - precision: 0.9435\n",
            "Epoch 263: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 214ms/step - loss: 0.1697 - accuracy: 0.9266 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9045 - precision: 0.9435 - val_loss: 1.1917 - val_accuracy: 0.7219 - val_sensitivity_at_specificity: 0.9419 - val_specificity_at_sensitivity: 0.8429 - val_recall: 0.9419 - val_precision: 0.6529\n",
            "Epoch 264/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1596 - accuracy: 0.9352 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9224 - precision: 0.9474\n",
            "Epoch 264: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 239ms/step - loss: 0.1596 - accuracy: 0.9352 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9224 - precision: 0.9474 - val_loss: 1.0988 - val_accuracy: 0.7047 - val_sensitivity_at_specificity: 0.9278 - val_specificity_at_sensitivity: 0.8756 - val_recall: 0.9388 - val_precision: 0.6382\n",
            "Epoch 265/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1766 - accuracy: 0.9244 - sensitivity_at_specificity: 0.9983 - specificity_at_sensitivity: 1.0000 - recall: 0.9123 - precision: 0.9328\n",
            "Epoch 265: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 240ms/step - loss: 0.1766 - accuracy: 0.9244 - sensitivity_at_specificity: 0.9983 - specificity_at_sensitivity: 1.0000 - recall: 0.9123 - precision: 0.9328 - val_loss: 1.1101 - val_accuracy: 0.6992 - val_sensitivity_at_specificity: 0.9217 - val_specificity_at_sensitivity: 0.8756 - val_recall: 0.9217 - val_precision: 0.6264\n",
            "Epoch 266/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1726 - accuracy: 0.9312 - sensitivity_at_specificity: 0.9962 - specificity_at_sensitivity: 1.0000 - recall: 0.9199 - precision: 0.9457\n",
            "Epoch 266: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 209ms/step - loss: 0.1726 - accuracy: 0.9312 - sensitivity_at_specificity: 0.9962 - specificity_at_sensitivity: 1.0000 - recall: 0.9199 - precision: 0.9457 - val_loss: 1.0840 - val_accuracy: 0.7039 - val_sensitivity_at_specificity: 0.8968 - val_specificity_at_sensitivity: 0.8374 - val_recall: 0.9105 - val_precision: 0.6522\n",
            "Epoch 267/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1610 - accuracy: 0.9332 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9245 - precision: 0.9414\n",
            "Epoch 267: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 212ms/step - loss: 0.1610 - accuracy: 0.9332 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9245 - precision: 0.9414 - val_loss: 1.0282 - val_accuracy: 0.7039 - val_sensitivity_at_specificity: 0.9067 - val_specificity_at_sensitivity: 0.8776 - val_recall: 0.9082 - val_precision: 0.6460\n",
            "Epoch 268/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1670 - accuracy: 0.9273 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9141 - precision: 0.9378\n",
            "Epoch 268: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 208ms/step - loss: 0.1670 - accuracy: 0.9273 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9141 - precision: 0.9378 - val_loss: 1.0732 - val_accuracy: 0.7164 - val_sensitivity_at_specificity: 0.9237 - val_specificity_at_sensitivity: 0.8694 - val_recall: 0.9094 - val_precision: 0.6515\n",
            "Epoch 269/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1616 - accuracy: 0.9359 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9166 - precision: 0.9538\n",
            "Epoch 269: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 211ms/step - loss: 0.1616 - accuracy: 0.9359 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9166 - precision: 0.9538 - val_loss: 1.1219 - val_accuracy: 0.7039 - val_sensitivity_at_specificity: 0.9220 - val_specificity_at_sensitivity: 0.8574 - val_recall: 0.9220 - val_precision: 0.6370\n",
            "Epoch 270/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1685 - accuracy: 0.9302 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9133 - precision: 0.9448\n",
            "Epoch 270: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 204ms/step - loss: 0.1685 - accuracy: 0.9302 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9133 - precision: 0.9448 - val_loss: 1.0251 - val_accuracy: 0.7289 - val_sensitivity_at_specificity: 0.9426 - val_specificity_at_sensitivity: 0.8803 - val_recall: 0.9302 - val_precision: 0.6652\n",
            "Epoch 271/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1704 - accuracy: 0.9324 - sensitivity_at_specificity: 0.9961 - specificity_at_sensitivity: 1.0000 - recall: 0.9253 - precision: 0.9392\n",
            "Epoch 271: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 208ms/step - loss: 0.1704 - accuracy: 0.9324 - sensitivity_at_specificity: 0.9961 - specificity_at_sensitivity: 1.0000 - recall: 0.9253 - precision: 0.9392 - val_loss: 1.0259 - val_accuracy: 0.7148 - val_sensitivity_at_specificity: 0.9260 - val_specificity_at_sensitivity: 0.8632 - val_recall: 0.9196 - val_precision: 0.6449\n",
            "Epoch 272/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1678 - accuracy: 0.9285 - sensitivity_at_specificity: 0.9977 - specificity_at_sensitivity: 1.0000 - recall: 0.9142 - precision: 0.9438\n",
            "Epoch 272: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 213ms/step - loss: 0.1678 - accuracy: 0.9285 - sensitivity_at_specificity: 0.9977 - specificity_at_sensitivity: 1.0000 - recall: 0.9142 - precision: 0.9438 - val_loss: 1.0114 - val_accuracy: 0.7250 - val_sensitivity_at_specificity: 0.9416 - val_specificity_at_sensitivity: 0.8870 - val_recall: 0.9322 - val_precision: 0.6567\n",
            "Epoch 273/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1411 - accuracy: 0.9418 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9292 - precision: 0.9524\n",
            "Epoch 273: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 212ms/step - loss: 0.1411 - accuracy: 0.9418 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9292 - precision: 0.9524 - val_loss: 1.3925 - val_accuracy: 0.6758 - val_sensitivity_at_specificity: 0.9070 - val_specificity_at_sensitivity: 0.8246 - val_recall: 0.9250 - val_precision: 0.6058\n",
            "Epoch 274/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1699 - accuracy: 0.9301 - sensitivity_at_specificity: 0.9976 - specificity_at_sensitivity: 1.0000 - recall: 0.9169 - precision: 0.9413\n",
            "Epoch 274: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 207ms/step - loss: 0.1699 - accuracy: 0.9301 - sensitivity_at_specificity: 0.9976 - specificity_at_sensitivity: 1.0000 - recall: 0.9169 - precision: 0.9413 - val_loss: 1.0618 - val_accuracy: 0.7125 - val_sensitivity_at_specificity: 0.9201 - val_specificity_at_sensitivity: 0.8792 - val_recall: 0.9278 - val_precision: 0.6530\n",
            "Epoch 275/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1590 - accuracy: 0.9379 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9265 - precision: 0.9517\n",
            "Epoch 275: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 208ms/step - loss: 0.1590 - accuracy: 0.9379 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9265 - precision: 0.9517 - val_loss: 1.2739 - val_accuracy: 0.6992 - val_sensitivity_at_specificity: 0.9116 - val_specificity_at_sensitivity: 0.8268 - val_recall: 0.9473 - val_precision: 0.6351\n",
            "Epoch 276/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1454 - accuracy: 0.9398 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 1.0000 - recall: 0.9284 - precision: 0.9531\n",
            "Epoch 276: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 214ms/step - loss: 0.1454 - accuracy: 0.9398 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 1.0000 - recall: 0.9284 - precision: 0.9531 - val_loss: 1.1984 - val_accuracy: 0.7039 - val_sensitivity_at_specificity: 0.9123 - val_specificity_at_sensitivity: 0.8397 - val_recall: 0.9308 - val_precision: 0.6443\n",
            "Epoch 277/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1437 - accuracy: 0.9438 - sensitivity_at_specificity: 0.9976 - specificity_at_sensitivity: 1.0000 - recall: 0.9370 - precision: 0.9476\n",
            "Epoch 277: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 207ms/step - loss: 0.1437 - accuracy: 0.9438 - sensitivity_at_specificity: 0.9976 - specificity_at_sensitivity: 1.0000 - recall: 0.9370 - precision: 0.9476 - val_loss: 1.2343 - val_accuracy: 0.7102 - val_sensitivity_at_specificity: 0.9168 - val_specificity_at_sensitivity: 0.8336 - val_recall: 0.9337 - val_precision: 0.6488\n",
            "Epoch 278/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1478 - accuracy: 0.9391 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9306 - precision: 0.9455\n",
            "Epoch 278: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 206ms/step - loss: 0.1478 - accuracy: 0.9391 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9306 - precision: 0.9455 - val_loss: 1.1146 - val_accuracy: 0.6977 - val_sensitivity_at_specificity: 0.9081 - val_specificity_at_sensitivity: 0.8697 - val_recall: 0.9000 - val_precision: 0.6319\n",
            "Epoch 279/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1689 - accuracy: 0.9281 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9992 - recall: 0.9126 - precision: 0.9394\n",
            "Epoch 279: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 207ms/step - loss: 0.1689 - accuracy: 0.9281 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9992 - recall: 0.9126 - precision: 0.9394 - val_loss: 0.9866 - val_accuracy: 0.7141 - val_sensitivity_at_specificity: 0.9274 - val_specificity_at_sensitivity: 0.8715 - val_recall: 0.8975 - val_precision: 0.6540\n",
            "Epoch 280/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1557 - accuracy: 0.9383 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9252 - precision: 0.9504\n",
            "Epoch 280: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 207ms/step - loss: 0.1557 - accuracy: 0.9383 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9252 - precision: 0.9504 - val_loss: 1.1398 - val_accuracy: 0.7039 - val_sensitivity_at_specificity: 0.9046 - val_specificity_at_sensitivity: 0.8539 - val_recall: 0.9329 - val_precision: 0.6521\n",
            "Epoch 281/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1577 - accuracy: 0.9344 - sensitivity_at_specificity: 0.9969 - specificity_at_sensitivity: 1.0000 - recall: 0.9213 - precision: 0.9451\n",
            "Epoch 281: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 207ms/step - loss: 0.1577 - accuracy: 0.9344 - sensitivity_at_specificity: 0.9969 - specificity_at_sensitivity: 1.0000 - recall: 0.9213 - precision: 0.9451 - val_loss: 1.2701 - val_accuracy: 0.6945 - val_sensitivity_at_specificity: 0.9187 - val_specificity_at_sensitivity: 0.8203 - val_recall: 0.9406 - val_precision: 0.6304\n",
            "Epoch 282/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1453 - accuracy: 0.9469 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9292 - precision: 0.9637\n",
            "Epoch 282: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 209ms/step - loss: 0.1453 - accuracy: 0.9469 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9292 - precision: 0.9637 - val_loss: 1.4538 - val_accuracy: 0.6758 - val_sensitivity_at_specificity: 0.8967 - val_specificity_at_sensitivity: 0.8049 - val_recall: 0.9459 - val_precision: 0.6096\n",
            "Epoch 283/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1692 - accuracy: 0.9297 - sensitivity_at_specificity: 0.9969 - specificity_at_sensitivity: 1.0000 - recall: 0.9079 - precision: 0.9482\n",
            "Epoch 283: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 210ms/step - loss: 0.1692 - accuracy: 0.9297 - sensitivity_at_specificity: 0.9969 - specificity_at_sensitivity: 1.0000 - recall: 0.9079 - precision: 0.9482 - val_loss: 1.1914 - val_accuracy: 0.6891 - val_sensitivity_at_specificity: 0.8824 - val_specificity_at_sensitivity: 0.8495 - val_recall: 0.9459 - val_precision: 0.6204\n",
            "Epoch 284/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1487 - accuracy: 0.9383 - sensitivity_at_specificity: 0.9977 - specificity_at_sensitivity: 0.9992 - recall: 0.9334 - precision: 0.9450\n",
            "Epoch 284: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 207ms/step - loss: 0.1487 - accuracy: 0.9383 - sensitivity_at_specificity: 0.9977 - specificity_at_sensitivity: 0.9992 - recall: 0.9334 - precision: 0.9450 - val_loss: 1.2628 - val_accuracy: 0.6891 - val_sensitivity_at_specificity: 0.8872 - val_specificity_at_sensitivity: 0.8215 - val_recall: 0.9088 - val_precision: 0.6343\n",
            "Epoch 285/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1465 - accuracy: 0.9375 - sensitivity_at_specificity: 0.9978 - specificity_at_sensitivity: 1.0000 - recall: 0.9247 - precision: 0.9546\n",
            "Epoch 285: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 210ms/step - loss: 0.1465 - accuracy: 0.9375 - sensitivity_at_specificity: 0.9978 - specificity_at_sensitivity: 1.0000 - recall: 0.9247 - precision: 0.9546 - val_loss: 1.3225 - val_accuracy: 0.6828 - val_sensitivity_at_specificity: 0.9115 - val_specificity_at_sensitivity: 0.8209 - val_recall: 0.9410 - val_precision: 0.6081\n",
            "Epoch 286/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1284 - accuracy: 0.9473 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 1.0000 - recall: 0.9393 - precision: 0.9587\n",
            "Epoch 286: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 207ms/step - loss: 0.1284 - accuracy: 0.9473 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 1.0000 - recall: 0.9393 - precision: 0.9587 - val_loss: 1.2748 - val_accuracy: 0.7078 - val_sensitivity_at_specificity: 0.9270 - val_specificity_at_sensitivity: 0.8169 - val_recall: 0.9381 - val_precision: 0.6382\n",
            "Epoch 287/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1481 - accuracy: 0.9395 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 1.0000 - recall: 0.9301 - precision: 0.9498\n",
            "Epoch 287: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 209ms/step - loss: 0.1481 - accuracy: 0.9395 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 1.0000 - recall: 0.9301 - precision: 0.9498 - val_loss: 1.2756 - val_accuracy: 0.6891 - val_sensitivity_at_specificity: 0.9067 - val_specificity_at_sensitivity: 0.8257 - val_recall: 0.9176 - val_precision: 0.6310\n",
            "Epoch 288/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1499 - accuracy: 0.9422 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9278 - precision: 0.9572\n",
            "Epoch 288: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 207ms/step - loss: 0.1499 - accuracy: 0.9422 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9278 - precision: 0.9572 - val_loss: 1.2985 - val_accuracy: 0.6969 - val_sensitivity_at_specificity: 0.9064 - val_specificity_at_sensitivity: 0.8341 - val_recall: 0.9454 - val_precision: 0.6319\n",
            "Epoch 289/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1342 - accuracy: 0.9488 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9361 - precision: 0.9608\n",
            "Epoch 289: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 206ms/step - loss: 0.1342 - accuracy: 0.9488 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9361 - precision: 0.9608 - val_loss: 1.3165 - val_accuracy: 0.6867 - val_sensitivity_at_specificity: 0.8694 - val_specificity_at_sensitivity: 0.8226 - val_recall: 0.9191 - val_precision: 0.6287\n",
            "Epoch 290/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1429 - accuracy: 0.9418 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 1.0000 - recall: 0.9311 - precision: 0.9537\n",
            "Epoch 290: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 208ms/step - loss: 0.1429 - accuracy: 0.9418 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 1.0000 - recall: 0.9311 - precision: 0.9537 - val_loss: 1.3089 - val_accuracy: 0.6977 - val_sensitivity_at_specificity: 0.9153 - val_specificity_at_sensitivity: 0.8150 - val_recall: 0.9441 - val_precision: 0.6267\n",
            "Epoch 291/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1346 - accuracy: 0.9414 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9201 - precision: 0.9584\n",
            "Epoch 291: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 198ms/step - loss: 0.1346 - accuracy: 0.9414 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9201 - precision: 0.9584 - val_loss: 1.3022 - val_accuracy: 0.6984 - val_sensitivity_at_specificity: 0.9082 - val_specificity_at_sensitivity: 0.8226 - val_recall: 0.9222 - val_precision: 0.6383\n",
            "Epoch 292/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1382 - accuracy: 0.9473 - sensitivity_at_specificity: 0.9977 - specificity_at_sensitivity: 0.9984 - recall: 0.9396 - precision: 0.9564\n",
            "Epoch 292: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 207ms/step - loss: 0.1382 - accuracy: 0.9473 - sensitivity_at_specificity: 0.9977 - specificity_at_sensitivity: 0.9984 - recall: 0.9396 - precision: 0.9564 - val_loss: 1.1568 - val_accuracy: 0.7305 - val_sensitivity_at_specificity: 0.9395 - val_specificity_at_sensitivity: 0.8239 - val_recall: 0.9277 - val_precision: 0.6800\n",
            "Epoch 293/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1266 - accuracy: 0.9496 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 1.0000 - recall: 0.9397 - precision: 0.9622\n",
            "Epoch 293: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 211ms/step - loss: 0.1266 - accuracy: 0.9496 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 1.0000 - recall: 0.9397 - precision: 0.9622 - val_loss: 1.3381 - val_accuracy: 0.6984 - val_sensitivity_at_specificity: 0.9028 - val_specificity_at_sensitivity: 0.8036 - val_recall: 0.9477 - val_precision: 0.6437\n",
            "Epoch 294/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1211 - accuracy: 0.9523 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9464 - precision: 0.9596\n",
            "Epoch 294: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 206ms/step - loss: 0.1211 - accuracy: 0.9523 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9464 - precision: 0.9596 - val_loss: 1.3628 - val_accuracy: 0.6891 - val_sensitivity_at_specificity: 0.9039 - val_specificity_at_sensitivity: 0.8153 - val_recall: 0.9218 - val_precision: 0.6179\n",
            "Epoch 295/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1559 - accuracy: 0.9373 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9333 - precision: 0.9433\n",
            "Epoch 295: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 196ms/step - loss: 0.1559 - accuracy: 0.9373 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9333 - precision: 0.9433 - val_loss: 1.2467 - val_accuracy: 0.6789 - val_sensitivity_at_specificity: 0.8915 - val_specificity_at_sensitivity: 0.8423 - val_recall: 0.9203 - val_precision: 0.6151\n",
            "Epoch 296/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1476 - accuracy: 0.9375 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9992 - recall: 0.9141 - precision: 0.9555\n",
            "Epoch 296: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 212ms/step - loss: 0.1476 - accuracy: 0.9375 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9992 - recall: 0.9141 - precision: 0.9555 - val_loss: 1.7498 - val_accuracy: 0.6695 - val_sensitivity_at_specificity: 0.8856 - val_specificity_at_sensitivity: 0.7336 - val_recall: 0.9530 - val_precision: 0.6074\n",
            "Epoch 297/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1470 - accuracy: 0.9402 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9240 - precision: 0.9547\n",
            "Epoch 297: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 210ms/step - loss: 0.1470 - accuracy: 0.9402 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9240 - precision: 0.9547 - val_loss: 1.2902 - val_accuracy: 0.6930 - val_sensitivity_at_specificity: 0.8974 - val_specificity_at_sensitivity: 0.8198 - val_recall: 0.9387 - val_precision: 0.6346\n",
            "Epoch 298/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1389 - accuracy: 0.9453 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9992 - recall: 0.9352 - precision: 0.9533\n",
            "Epoch 298: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 217ms/step - loss: 0.1389 - accuracy: 0.9453 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9992 - recall: 0.9352 - precision: 0.9533 - val_loss: 1.2327 - val_accuracy: 0.6969 - val_sensitivity_at_specificity: 0.9146 - val_specificity_at_sensitivity: 0.8349 - val_recall: 0.9304 - val_precision: 0.6309\n",
            "Epoch 299/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1182 - accuracy: 0.9516 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9423 - precision: 0.9577\n",
            "Epoch 299: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 212ms/step - loss: 0.1182 - accuracy: 0.9516 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9423 - precision: 0.9577 - val_loss: 1.5778 - val_accuracy: 0.6859 - val_sensitivity_at_specificity: 0.9035 - val_specificity_at_sensitivity: 0.7531 - val_recall: 0.9636 - val_precision: 0.6164\n",
            "Epoch 300/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1243 - accuracy: 0.9531 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9416 - precision: 0.9629\n",
            "Epoch 300: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 211ms/step - loss: 0.1243 - accuracy: 0.9531 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9416 - precision: 0.9629 - val_loss: 1.2758 - val_accuracy: 0.7055 - val_sensitivity_at_specificity: 0.8960 - val_specificity_at_sensitivity: 0.8163 - val_recall: 0.9220 - val_precision: 0.6491\n",
            "Epoch 301/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1186 - accuracy: 0.9570 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9431 - precision: 0.9691\n",
            "Epoch 301: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 211ms/step - loss: 0.1186 - accuracy: 0.9570 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9431 - precision: 0.9691 - val_loss: 1.4906 - val_accuracy: 0.6891 - val_sensitivity_at_specificity: 0.9073 - val_specificity_at_sensitivity: 0.7835 - val_recall: 0.9415 - val_precision: 0.6153\n",
            "Epoch 302/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1161 - accuracy: 0.9531 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9367 - precision: 0.9669\n",
            "Epoch 302: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 204ms/step - loss: 0.1161 - accuracy: 0.9531 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9367 - precision: 0.9669 - val_loss: 1.3382 - val_accuracy: 0.6711 - val_sensitivity_at_specificity: 0.8925 - val_specificity_at_sensitivity: 0.8273 - val_recall: 0.9349 - val_precision: 0.6010\n",
            "Epoch 303/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1193 - accuracy: 0.9570 - sensitivity_at_specificity: 0.9976 - specificity_at_sensitivity: 1.0000 - recall: 0.9552 - precision: 0.9552\n",
            "Epoch 303: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 210ms/step - loss: 0.1193 - accuracy: 0.9570 - sensitivity_at_specificity: 0.9976 - specificity_at_sensitivity: 1.0000 - recall: 0.9552 - precision: 0.9552 - val_loss: 1.1821 - val_accuracy: 0.7008 - val_sensitivity_at_specificity: 0.9084 - val_specificity_at_sensitivity: 0.8563 - val_recall: 0.9179 - val_precision: 0.6371\n",
            "Epoch 304/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.1178 - accuracy: 0.9523 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9419 - precision: 0.9647\n",
            "Epoch 304: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 201ms/step - loss: 0.1174 - accuracy: 0.9518 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9438 - precision: 0.9623 - val_loss: 1.6030 - val_accuracy: 0.6789 - val_sensitivity_at_specificity: 0.9156 - val_specificity_at_sensitivity: 0.7638 - val_recall: 0.9634 - val_precision: 0.6093\n",
            "Epoch 305/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1207 - accuracy: 0.9523 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9363 - precision: 0.9655\n",
            "Epoch 305: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 215ms/step - loss: 0.1207 - accuracy: 0.9523 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9363 - precision: 0.9655 - val_loss: 1.5308 - val_accuracy: 0.7008 - val_sensitivity_at_specificity: 0.9190 - val_specificity_at_sensitivity: 0.7649 - val_recall: 0.9611 - val_precision: 0.6328\n",
            "Epoch 306/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1086 - accuracy: 0.9574 - sensitivity_at_specificity: 0.9977 - specificity_at_sensitivity: 1.0000 - recall: 0.9505 - precision: 0.9647\n",
            "Epoch 306: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 211ms/step - loss: 0.1086 - accuracy: 0.9574 - sensitivity_at_specificity: 0.9977 - specificity_at_sensitivity: 1.0000 - recall: 0.9505 - precision: 0.9647 - val_loss: 1.4823 - val_accuracy: 0.6977 - val_sensitivity_at_specificity: 0.9319 - val_specificity_at_sensitivity: 0.7797 - val_recall: 0.9635 - val_precision: 0.6255\n",
            "Epoch 307/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1344 - accuracy: 0.9449 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9412 - precision: 0.9507\n",
            "Epoch 307: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 203ms/step - loss: 0.1344 - accuracy: 0.9449 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9412 - precision: 0.9507 - val_loss: 1.4215 - val_accuracy: 0.6859 - val_sensitivity_at_specificity: 0.8913 - val_specificity_at_sensitivity: 0.8082 - val_recall: 0.9363 - val_precision: 0.6255\n",
            "Epoch 308/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1331 - accuracy: 0.9438 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9248 - precision: 0.9585\n",
            "Epoch 308: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 207ms/step - loss: 0.1331 - accuracy: 0.9438 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9248 - precision: 0.9585 - val_loss: 1.3864 - val_accuracy: 0.7047 - val_sensitivity_at_specificity: 0.9091 - val_specificity_at_sensitivity: 0.8067 - val_recall: 0.9399 - val_precision: 0.6428\n",
            "Epoch 309/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1180 - accuracy: 0.9559 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9440 - precision: 0.9661\n",
            "Epoch 309: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 211ms/step - loss: 0.1180 - accuracy: 0.9559 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9440 - precision: 0.9661 - val_loss: 1.3440 - val_accuracy: 0.6977 - val_sensitivity_at_specificity: 0.9036 - val_specificity_at_sensitivity: 0.7987 - val_recall: 0.9488 - val_precision: 0.6409\n",
            "Epoch 310/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1052 - accuracy: 0.9605 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9498 - precision: 0.9691\n",
            "Epoch 310: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 207ms/step - loss: 0.1052 - accuracy: 0.9605 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9498 - precision: 0.9691 - val_loss: 1.5564 - val_accuracy: 0.6953 - val_sensitivity_at_specificity: 0.9143 - val_specificity_at_sensitivity: 0.7696 - val_recall: 0.9564 - val_precision: 0.6291\n",
            "Epoch 311/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1190 - accuracy: 0.9543 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9436 - precision: 0.9627\n",
            "Epoch 311: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 206ms/step - loss: 0.1190 - accuracy: 0.9543 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9436 - precision: 0.9627 - val_loss: 1.6773 - val_accuracy: 0.6875 - val_sensitivity_at_specificity: 0.9101 - val_specificity_at_sensitivity: 0.7458 - val_recall: 0.9615 - val_precision: 0.6144\n",
            "Epoch 312/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1306 - accuracy: 0.9484 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9992 - recall: 0.9347 - precision: 0.9604\n",
            "Epoch 312: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 211ms/step - loss: 0.1306 - accuracy: 0.9484 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9992 - recall: 0.9347 - precision: 0.9604 - val_loss: 1.6790 - val_accuracy: 0.6836 - val_sensitivity_at_specificity: 0.9148 - val_specificity_at_sensitivity: 0.7538 - val_recall: 0.9534 - val_precision: 0.6120\n",
            "Epoch 313/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1196 - accuracy: 0.9516 - sensitivity_at_specificity: 0.9976 - specificity_at_sensitivity: 1.0000 - recall: 0.9438 - precision: 0.9561\n",
            "Epoch 313: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 209ms/step - loss: 0.1196 - accuracy: 0.9516 - sensitivity_at_specificity: 0.9976 - specificity_at_sensitivity: 1.0000 - recall: 0.9438 - precision: 0.9561 - val_loss: 1.4098 - val_accuracy: 0.7039 - val_sensitivity_at_specificity: 0.9123 - val_specificity_at_sensitivity: 0.7921 - val_recall: 0.9415 - val_precision: 0.6422\n",
            "Epoch 314/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1232 - accuracy: 0.9465 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9334 - precision: 0.9582\n",
            "Epoch 314: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 211ms/step - loss: 0.1232 - accuracy: 0.9465 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9334 - precision: 0.9582 - val_loss: 1.5072 - val_accuracy: 0.6898 - val_sensitivity_at_specificity: 0.8975 - val_specificity_at_sensitivity: 0.7833 - val_recall: 0.9338 - val_precision: 0.6251\n",
            "Epoch 315/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1095 - accuracy: 0.9582 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9512 - precision: 0.9667\n",
            "Epoch 315: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 205ms/step - loss: 0.1095 - accuracy: 0.9582 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9512 - precision: 0.9667 - val_loss: 1.4004 - val_accuracy: 0.7000 - val_sensitivity_at_specificity: 0.9151 - val_specificity_at_sensitivity: 0.8110 - val_recall: 0.9551 - val_precision: 0.6261\n",
            "Epoch 316/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1129 - accuracy: 0.9563 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 0.9992 - recall: 0.9525 - precision: 0.9613\n",
            "Epoch 316: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 214ms/step - loss: 0.1129 - accuracy: 0.9563 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 0.9992 - recall: 0.9525 - precision: 0.9613 - val_loss: 1.5637 - val_accuracy: 0.6938 - val_sensitivity_at_specificity: 0.9098 - val_specificity_at_sensitivity: 0.7840 - val_recall: 0.9525 - val_precision: 0.6245\n",
            "Epoch 317/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0948 - accuracy: 0.9617 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9504 - precision: 0.9718\n",
            "Epoch 317: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 253ms/step - loss: 0.0948 - accuracy: 0.9617 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9504 - precision: 0.9718 - val_loss: 1.4061 - val_accuracy: 0.6930 - val_sensitivity_at_specificity: 0.9020 - val_specificity_at_sensitivity: 0.7879 - val_recall: 0.9265 - val_precision: 0.6368\n",
            "Epoch 318/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1047 - accuracy: 0.9582 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9435 - precision: 0.9705\n",
            "Epoch 318: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 246ms/step - loss: 0.1047 - accuracy: 0.9582 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9435 - precision: 0.9705 - val_loss: 1.7110 - val_accuracy: 0.6797 - val_sensitivity_at_specificity: 0.8989 - val_specificity_at_sensitivity: 0.7450 - val_recall: 0.9494 - val_precision: 0.6139\n",
            "Epoch 319/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1140 - accuracy: 0.9582 - sensitivity_at_specificity: 0.9977 - specificity_at_sensitivity: 1.0000 - recall: 0.9452 - precision: 0.9703\n",
            "Epoch 319: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 210ms/step - loss: 0.1140 - accuracy: 0.9582 - sensitivity_at_specificity: 0.9977 - specificity_at_sensitivity: 1.0000 - recall: 0.9452 - precision: 0.9703 - val_loss: 1.3984 - val_accuracy: 0.7023 - val_sensitivity_at_specificity: 0.9211 - val_specificity_at_sensitivity: 0.7855 - val_recall: 0.9536 - val_precision: 0.6370\n",
            "Epoch 320/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1172 - accuracy: 0.9539 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9541 - precision: 0.9541\n",
            "Epoch 320: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 210ms/step - loss: 0.1172 - accuracy: 0.9539 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9541 - precision: 0.9541 - val_loss: 1.4181 - val_accuracy: 0.6938 - val_sensitivity_at_specificity: 0.9209 - val_specificity_at_sensitivity: 0.7886 - val_recall: 0.9573 - val_precision: 0.6237\n",
            "Epoch 321/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.0984 - accuracy: 0.9622 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9488 - precision: 0.9737\n",
            "Epoch 321: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 203ms/step - loss: 0.1003 - accuracy: 0.9601 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9453 - precision: 0.9731 - val_loss: 1.7349 - val_accuracy: 0.6758 - val_sensitivity_at_specificity: 0.8911 - val_specificity_at_sensitivity: 0.7323 - val_recall: 0.9593 - val_precision: 0.6020\n",
            "Epoch 322/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1056 - accuracy: 0.9582 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9583 - precision: 0.9591\n",
            "Epoch 322: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 207ms/step - loss: 0.1056 - accuracy: 0.9582 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9583 - precision: 0.9591 - val_loss: 1.4741 - val_accuracy: 0.6969 - val_sensitivity_at_specificity: 0.9115 - val_specificity_at_sensitivity: 0.7840 - val_recall: 0.9542 - val_precision: 0.6358\n",
            "Epoch 323/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1134 - accuracy: 0.9551 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9430 - precision: 0.9639\n",
            "Epoch 323: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 212ms/step - loss: 0.1134 - accuracy: 0.9551 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9430 - precision: 0.9639 - val_loss: 1.4435 - val_accuracy: 0.6844 - val_sensitivity_at_specificity: 0.9339 - val_specificity_at_sensitivity: 0.8207 - val_recall: 0.9554 - val_precision: 0.6052\n",
            "Epoch 324/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0969 - accuracy: 0.9629 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9523 - precision: 0.9740\n",
            "Epoch 324: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 212ms/step - loss: 0.0969 - accuracy: 0.9629 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9523 - precision: 0.9740 - val_loss: 1.5058 - val_accuracy: 0.6977 - val_sensitivity_at_specificity: 0.9074 - val_specificity_at_sensitivity: 0.7697 - val_recall: 0.9560 - val_precision: 0.6377\n",
            "Epoch 325/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1040 - accuracy: 0.9535 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9479 - precision: 0.9591\n",
            "Epoch 325: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 208ms/step - loss: 0.1040 - accuracy: 0.9535 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9479 - precision: 0.9591 - val_loss: 1.7605 - val_accuracy: 0.6727 - val_sensitivity_at_specificity: 0.8951 - val_specificity_at_sensitivity: 0.7192 - val_recall: 0.9671 - val_precision: 0.6083\n",
            "Epoch 326/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1063 - accuracy: 0.9531 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9415 - precision: 0.9641\n",
            "Epoch 326: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 212ms/step - loss: 0.1063 - accuracy: 0.9531 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9415 - precision: 0.9641 - val_loss: 1.4240 - val_accuracy: 0.6852 - val_sensitivity_at_specificity: 0.9092 - val_specificity_at_sensitivity: 0.8175 - val_recall: 0.9433 - val_precision: 0.6126\n",
            "Epoch 327/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1146 - accuracy: 0.9539 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9420 - precision: 0.9659\n",
            "Epoch 327: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 212ms/step - loss: 0.1146 - accuracy: 0.9539 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9420 - precision: 0.9659 - val_loss: 1.5539 - val_accuracy: 0.6984 - val_sensitivity_at_specificity: 0.9359 - val_specificity_at_sensitivity: 0.7536 - val_recall: 0.9603 - val_precision: 0.6360\n",
            "Epoch 328/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1038 - accuracy: 0.9629 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9536 - precision: 0.9699\n",
            "Epoch 328: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 209ms/step - loss: 0.1038 - accuracy: 0.9629 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9536 - precision: 0.9699 - val_loss: 1.7917 - val_accuracy: 0.6977 - val_sensitivity_at_specificity: 0.9130 - val_specificity_at_sensitivity: 0.7194 - val_recall: 0.9670 - val_precision: 0.6386\n",
            "Epoch 329/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1013 - accuracy: 0.9633 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 1.0000 - recall: 0.9508 - precision: 0.9763\n",
            "Epoch 329: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 211ms/step - loss: 0.1013 - accuracy: 0.9633 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 1.0000 - recall: 0.9508 - precision: 0.9763 - val_loss: 1.5222 - val_accuracy: 0.6969 - val_sensitivity_at_specificity: 0.9212 - val_specificity_at_sensitivity: 0.7918 - val_recall: 0.9469 - val_precision: 0.6239\n",
            "Epoch 330/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1087 - accuracy: 0.9555 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9512 - precision: 0.9573\n",
            "Epoch 330: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 213ms/step - loss: 0.1087 - accuracy: 0.9555 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9512 - precision: 0.9573 - val_loss: 1.4874 - val_accuracy: 0.6984 - val_sensitivity_at_specificity: 0.9138 - val_specificity_at_sensitivity: 0.7778 - val_recall: 0.9477 - val_precision: 0.6364\n",
            "Epoch 331/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1098 - accuracy: 0.9578 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9444 - precision: 0.9714\n",
            "Epoch 331: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 213ms/step - loss: 0.1098 - accuracy: 0.9578 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9444 - precision: 0.9714 - val_loss: 1.7323 - val_accuracy: 0.6742 - val_sensitivity_at_specificity: 0.8988 - val_specificity_at_sensitivity: 0.7273 - val_recall: 0.9595 - val_precision: 0.6117\n",
            "Epoch 332/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1021 - accuracy: 0.9633 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9506 - precision: 0.9727\n",
            "Epoch 332: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 212ms/step - loss: 0.1021 - accuracy: 0.9633 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9506 - precision: 0.9727 - val_loss: 1.8379 - val_accuracy: 0.6914 - val_sensitivity_at_specificity: 0.9160 - val_specificity_at_sensitivity: 0.7159 - val_recall: 0.9596 - val_precision: 0.6258\n",
            "Epoch 333/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0837 - accuracy: 0.9672 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9628 - precision: 0.9718\n",
            "Epoch 333: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 210ms/step - loss: 0.0837 - accuracy: 0.9672 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9628 - precision: 0.9718 - val_loss: 1.7622 - val_accuracy: 0.6906 - val_sensitivity_at_specificity: 0.9122 - val_specificity_at_sensitivity: 0.7243 - val_recall: 0.9592 - val_precision: 0.6232\n",
            "Epoch 334/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0985 - accuracy: 0.9609 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9526 - precision: 0.9704\n",
            "Epoch 334: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 210ms/step - loss: 0.0985 - accuracy: 0.9609 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9526 - precision: 0.9704 - val_loss: 1.5604 - val_accuracy: 0.6938 - val_sensitivity_at_specificity: 0.9165 - val_specificity_at_sensitivity: 0.7567 - val_recall: 0.9583 - val_precision: 0.6294\n",
            "Epoch 335/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1101 - accuracy: 0.9617 - sensitivity_at_specificity: 0.9977 - specificity_at_sensitivity: 0.9992 - recall: 0.9584 - precision: 0.9672\n",
            "Epoch 335: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 214ms/step - loss: 0.1101 - accuracy: 0.9617 - sensitivity_at_specificity: 0.9977 - specificity_at_sensitivity: 0.9992 - recall: 0.9584 - precision: 0.9672 - val_loss: 1.6413 - val_accuracy: 0.6680 - val_sensitivity_at_specificity: 0.8955 - val_specificity_at_sensitivity: 0.7584 - val_recall: 0.9518 - val_precision: 0.5998\n",
            "Epoch 336/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0893 - accuracy: 0.9625 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9543 - precision: 0.9708\n",
            "Epoch 336: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 219ms/step - loss: 0.0893 - accuracy: 0.9625 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9543 - precision: 0.9708 - val_loss: 1.4536 - val_accuracy: 0.6797 - val_sensitivity_at_specificity: 0.8844 - val_specificity_at_sensitivity: 0.7984 - val_recall: 0.9328 - val_precision: 0.6193\n",
            "Epoch 337/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0910 - accuracy: 0.9637 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9574 - precision: 0.9688\n",
            "Epoch 337: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 220ms/step - loss: 0.0910 - accuracy: 0.9637 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9574 - precision: 0.9688 - val_loss: 1.8743 - val_accuracy: 0.6609 - val_sensitivity_at_specificity: 0.8812 - val_specificity_at_sensitivity: 0.7489 - val_recall: 0.9518 - val_precision: 0.5948\n",
            "Epoch 338/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0901 - accuracy: 0.9680 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9579 - precision: 0.9765\n",
            "Epoch 338: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 215ms/step - loss: 0.0901 - accuracy: 0.9680 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9579 - precision: 0.9765 - val_loss: 1.6247 - val_accuracy: 0.6953 - val_sensitivity_at_specificity: 0.9193 - val_specificity_at_sensitivity: 0.7639 - val_recall: 0.9604 - val_precision: 0.6245\n",
            "Epoch 339/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0909 - accuracy: 0.9645 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9599 - precision: 0.9669\n",
            "Epoch 339: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 215ms/step - loss: 0.0909 - accuracy: 0.9645 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9599 - precision: 0.9669 - val_loss: 1.6356 - val_accuracy: 0.6922 - val_sensitivity_at_specificity: 0.9190 - val_specificity_at_sensitivity: 0.7647 - val_recall: 0.9530 - val_precision: 0.6170\n",
            "Epoch 340/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0850 - accuracy: 0.9680 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9617 - precision: 0.9751\n",
            "Epoch 340: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 209ms/step - loss: 0.0850 - accuracy: 0.9680 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9617 - precision: 0.9751 - val_loss: 1.8186 - val_accuracy: 0.6797 - val_sensitivity_at_specificity: 0.8962 - val_specificity_at_sensitivity: 0.7220 - val_recall: 0.9654 - val_precision: 0.6128\n",
            "Epoch 341/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0979 - accuracy: 0.9645 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9546 - precision: 0.9737\n",
            "Epoch 341: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 212ms/step - loss: 0.0979 - accuracy: 0.9645 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9546 - precision: 0.9737 - val_loss: 1.6440 - val_accuracy: 0.6719 - val_sensitivity_at_specificity: 0.9159 - val_specificity_at_sensitivity: 0.7523 - val_recall: 0.9429 - val_precision: 0.6074\n",
            "Epoch 342/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0996 - accuracy: 0.9602 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9579 - precision: 0.9624\n",
            "Epoch 342: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 209ms/step - loss: 0.0996 - accuracy: 0.9602 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9579 - precision: 0.9624 - val_loss: 1.4968 - val_accuracy: 0.6867 - val_sensitivity_at_specificity: 0.9213 - val_specificity_at_sensitivity: 0.7927 - val_recall: 0.9568 - val_precision: 0.6244\n",
            "Epoch 343/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0887 - accuracy: 0.9664 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9517 - precision: 0.9785\n",
            "Epoch 343: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 214ms/step - loss: 0.0887 - accuracy: 0.9664 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9517 - precision: 0.9785 - val_loss: 1.9065 - val_accuracy: 0.6820 - val_sensitivity_at_specificity: 0.9324 - val_specificity_at_sensitivity: 0.7071 - val_recall: 0.9807 - val_precision: 0.6066\n",
            "Epoch 344/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1033 - accuracy: 0.9594 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9514 - precision: 0.9666\n",
            "Epoch 344: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 212ms/step - loss: 0.1033 - accuracy: 0.9594 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9514 - precision: 0.9666 - val_loss: 1.5401 - val_accuracy: 0.6945 - val_sensitivity_at_specificity: 0.9311 - val_specificity_at_sensitivity: 0.7566 - val_recall: 0.9562 - val_precision: 0.6273\n",
            "Epoch 345/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0972 - accuracy: 0.9633 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9625 - precision: 0.9625\n",
            "Epoch 345: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 211ms/step - loss: 0.0972 - accuracy: 0.9633 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9625 - precision: 0.9625 - val_loss: 1.5023 - val_accuracy: 0.6922 - val_sensitivity_at_specificity: 0.8947 - val_specificity_at_sensitivity: 0.7871 - val_recall: 0.9443 - val_precision: 0.6302\n",
            "Epoch 346/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0920 - accuracy: 0.9672 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9580 - precision: 0.9762\n",
            "Epoch 346: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 214ms/step - loss: 0.0920 - accuracy: 0.9672 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9580 - precision: 0.9762 - val_loss: 1.5343 - val_accuracy: 0.7086 - val_sensitivity_at_specificity: 0.9390 - val_specificity_at_sensitivity: 0.7582 - val_recall: 0.9688 - val_precision: 0.6491\n",
            "Epoch 347/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0793 - accuracy: 0.9719 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9611 - precision: 0.9825\n",
            "Epoch 347: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 217ms/step - loss: 0.0793 - accuracy: 0.9719 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9611 - precision: 0.9825 - val_loss: 2.0074 - val_accuracy: 0.6773 - val_sensitivity_at_specificity: 0.9072 - val_specificity_at_sensitivity: 0.7023 - val_recall: 0.9632 - val_precision: 0.6069\n",
            "Epoch 348/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0956 - accuracy: 0.9656 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9570 - precision: 0.9737\n",
            "Epoch 348: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 216ms/step - loss: 0.0956 - accuracy: 0.9656 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9570 - precision: 0.9737 - val_loss: 1.6106 - val_accuracy: 0.6977 - val_sensitivity_at_specificity: 0.9177 - val_specificity_at_sensitivity: 0.7598 - val_recall: 0.9686 - val_precision: 0.6387\n",
            "Epoch 349/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0817 - accuracy: 0.9707 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9690 - precision: 0.9728\n",
            "Epoch 349: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 216ms/step - loss: 0.0817 - accuracy: 0.9707 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9690 - precision: 0.9728 - val_loss: 1.5942 - val_accuracy: 0.6859 - val_sensitivity_at_specificity: 0.9266 - val_specificity_at_sensitivity: 0.7625 - val_recall: 0.9563 - val_precision: 0.6207\n",
            "Epoch 350/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0798 - accuracy: 0.9680 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9622 - precision: 0.9742\n",
            "Epoch 350: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 216ms/step - loss: 0.0798 - accuracy: 0.9680 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9622 - precision: 0.9742 - val_loss: 1.7608 - val_accuracy: 0.7039 - val_sensitivity_at_specificity: 0.9268 - val_specificity_at_sensitivity: 0.7398 - val_recall: 0.9579 - val_precision: 0.6360\n",
            "Epoch 351/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0795 - accuracy: 0.9699 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9626 - precision: 0.9771\n",
            "Epoch 351: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 218ms/step - loss: 0.0795 - accuracy: 0.9699 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9626 - precision: 0.9771 - val_loss: 1.6191 - val_accuracy: 0.6891 - val_sensitivity_at_specificity: 0.9141 - val_specificity_at_sensitivity: 0.7496 - val_recall: 0.9571 - val_precision: 0.6187\n",
            "Epoch 352/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0915 - accuracy: 0.9645 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9598 - precision: 0.9708\n",
            "Epoch 352: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 217ms/step - loss: 0.0915 - accuracy: 0.9645 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9598 - precision: 0.9708 - val_loss: 1.8286 - val_accuracy: 0.6828 - val_sensitivity_at_specificity: 0.9115 - val_specificity_at_sensitivity: 0.7311 - val_recall: 0.9716 - val_precision: 0.6132\n",
            "Epoch 353/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0793 - accuracy: 0.9719 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9688 - precision: 0.9735\n",
            "Epoch 353: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 223ms/step - loss: 0.0793 - accuracy: 0.9719 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9688 - precision: 0.9735 - val_loss: 1.7098 - val_accuracy: 0.6789 - val_sensitivity_at_specificity: 0.9102 - val_specificity_at_sensitivity: 0.7442 - val_recall: 0.9465 - val_precision: 0.6145\n",
            "Epoch 354/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0926 - accuracy: 0.9652 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9558 - precision: 0.9747\n",
            "Epoch 354: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 216ms/step - loss: 0.0926 - accuracy: 0.9652 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9558 - precision: 0.9747 - val_loss: 2.0626 - val_accuracy: 0.6891 - val_sensitivity_at_specificity: 0.9283 - val_specificity_at_sensitivity: 0.6825 - val_recall: 0.9809 - val_precision: 0.6148\n",
            "Epoch 355/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0725 - accuracy: 0.9689 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9659 - precision: 0.9730\n",
            "Epoch 355: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 218ms/step - loss: 0.0725 - accuracy: 0.9689 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9659 - precision: 0.9730 - val_loss: 1.8442 - val_accuracy: 0.6984 - val_sensitivity_at_specificity: 0.9289 - val_specificity_at_sensitivity: 0.7187 - val_recall: 0.9573 - val_precision: 0.6280\n",
            "Epoch 356/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0875 - accuracy: 0.9668 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9577 - precision: 0.9753\n",
            "Epoch 356: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 213ms/step - loss: 0.0875 - accuracy: 0.9668 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9577 - precision: 0.9753 - val_loss: 1.7381 - val_accuracy: 0.6914 - val_sensitivity_at_specificity: 0.9291 - val_specificity_at_sensitivity: 0.7302 - val_recall: 0.9701 - val_precision: 0.6210\n",
            "Epoch 357/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0977 - accuracy: 0.9625 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9541 - precision: 0.9719\n",
            "Epoch 357: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 212ms/step - loss: 0.0977 - accuracy: 0.9625 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9541 - precision: 0.9719 - val_loss: 1.7887 - val_accuracy: 0.6750 - val_sensitivity_at_specificity: 0.9009 - val_specificity_at_sensitivity: 0.7158 - val_recall: 0.9701 - val_precision: 0.6085\n",
            "Epoch 358/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0931 - accuracy: 0.9645 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9633 - precision: 0.9655\n",
            "Epoch 358: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 216ms/step - loss: 0.0931 - accuracy: 0.9645 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9633 - precision: 0.9655 - val_loss: 2.0064 - val_accuracy: 0.6797 - val_sensitivity_at_specificity: 0.8786 - val_specificity_at_sensitivity: 0.6741 - val_recall: 0.9539 - val_precision: 0.6204\n",
            "Epoch 359/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0817 - accuracy: 0.9691 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9691 - precision: 0.9683\n",
            "Epoch 359: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 216ms/step - loss: 0.0817 - accuracy: 0.9691 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9691 - precision: 0.9683 - val_loss: 1.6106 - val_accuracy: 0.6859 - val_sensitivity_at_specificity: 0.9197 - val_specificity_at_sensitivity: 0.7717 - val_recall: 0.9470 - val_precision: 0.6152\n",
            "Epoch 360/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0883 - accuracy: 0.9668 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9583 - precision: 0.9756\n",
            "Epoch 360: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 215ms/step - loss: 0.0883 - accuracy: 0.9668 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9583 - precision: 0.9756 - val_loss: 1.7944 - val_accuracy: 0.6852 - val_sensitivity_at_specificity: 0.9104 - val_specificity_at_sensitivity: 0.7125 - val_recall: 0.9645 - val_precision: 0.6215\n",
            "Epoch 361/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0936 - accuracy: 0.9672 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9650 - precision: 0.9696\n",
            "Epoch 361: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 213ms/step - loss: 0.0936 - accuracy: 0.9672 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9650 - precision: 0.9696 - val_loss: 1.5090 - val_accuracy: 0.7125 - val_sensitivity_at_specificity: 0.9347 - val_specificity_at_sensitivity: 0.7572 - val_recall: 0.9483 - val_precision: 0.6514\n",
            "Epoch 362/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0733 - accuracy: 0.9738 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 1.0000 - recall: 0.9708 - precision: 0.9776\n",
            "Epoch 362: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 216ms/step - loss: 0.0733 - accuracy: 0.9738 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 1.0000 - recall: 0.9708 - precision: 0.9776 - val_loss: 1.8465 - val_accuracy: 0.6930 - val_sensitivity_at_specificity: 0.9076 - val_specificity_at_sensitivity: 0.6968 - val_recall: 0.9682 - val_precision: 0.6320\n",
            "Epoch 363/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0700 - accuracy: 0.9742 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9678 - precision: 0.9801\n",
            "Epoch 363: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 215ms/step - loss: 0.0700 - accuracy: 0.9742 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9678 - precision: 0.9801 - val_loss: 1.8071 - val_accuracy: 0.6758 - val_sensitivity_at_specificity: 0.9056 - val_specificity_at_sensitivity: 0.7420 - val_recall: 0.9504 - val_precision: 0.6074\n",
            "Epoch 364/500\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.0705 - accuracy: 0.9727 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9703 - precision: 0.9761\n",
            "Epoch 364: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 210ms/step - loss: 0.0736 - accuracy: 0.9718 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9675 - precision: 0.9770 - val_loss: 1.6412 - val_accuracy: 0.7117 - val_sensitivity_at_specificity: 0.9368 - val_specificity_at_sensitivity: 0.7258 - val_recall: 0.9507 - val_precision: 0.6468\n",
            "Epoch 365/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0915 - accuracy: 0.9664 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9658 - precision: 0.9673\n",
            "Epoch 365: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 213ms/step - loss: 0.0915 - accuracy: 0.9664 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9658 - precision: 0.9673 - val_loss: 1.8124 - val_accuracy: 0.6844 - val_sensitivity_at_specificity: 0.9071 - val_specificity_at_sensitivity: 0.7163 - val_recall: 0.9606 - val_precision: 0.6168\n",
            "Epoch 366/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0833 - accuracy: 0.9701 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9622 - precision: 0.9783\n",
            "Epoch 366: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 204ms/step - loss: 0.0833 - accuracy: 0.9701 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9622 - precision: 0.9783 - val_loss: 1.9593 - val_accuracy: 0.6867 - val_sensitivity_at_specificity: 0.8905 - val_specificity_at_sensitivity: 0.6973 - val_recall: 0.9640 - val_precision: 0.6197\n",
            "Epoch 367/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0839 - accuracy: 0.9703 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9659 - precision: 0.9750\n",
            "Epoch 367: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 215ms/step - loss: 0.0839 - accuracy: 0.9703 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9659 - precision: 0.9750 - val_loss: 1.7027 - val_accuracy: 0.6891 - val_sensitivity_at_specificity: 0.9227 - val_specificity_at_sensitivity: 0.7322 - val_recall: 0.9716 - val_precision: 0.6185\n",
            "Epoch 368/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0740 - accuracy: 0.9738 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9708 - precision: 0.9789\n",
            "Epoch 368: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 214ms/step - loss: 0.0740 - accuracy: 0.9738 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9708 - precision: 0.9789 - val_loss: 1.7511 - val_accuracy: 0.6945 - val_sensitivity_at_specificity: 0.9021 - val_specificity_at_sensitivity: 0.7419 - val_recall: 0.9621 - val_precision: 0.6240\n",
            "Epoch 369/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0804 - accuracy: 0.9715 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9686 - precision: 0.9725\n",
            "Epoch 369: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 233ms/step - loss: 0.0804 - accuracy: 0.9715 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9686 - precision: 0.9725 - val_loss: 2.0556 - val_accuracy: 0.6773 - val_sensitivity_at_specificity: 0.8905 - val_specificity_at_sensitivity: 0.6771 - val_recall: 0.9703 - val_precision: 0.6114\n",
            "Epoch 370/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0729 - accuracy: 0.9711 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9664 - precision: 0.9755\n",
            "Epoch 370: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 3s 256ms/step - loss: 0.0729 - accuracy: 0.9711 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9664 - precision: 0.9755 - val_loss: 1.7859 - val_accuracy: 0.6742 - val_sensitivity_at_specificity: 0.8887 - val_specificity_at_sensitivity: 0.7455 - val_recall: 0.9435 - val_precision: 0.6050\n",
            "Epoch 371/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0800 - accuracy: 0.9695 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9637 - precision: 0.9745\n",
            "Epoch 371: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 211ms/step - loss: 0.0800 - accuracy: 0.9695 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9637 - precision: 0.9745 - val_loss: 1.7219 - val_accuracy: 0.6797 - val_sensitivity_at_specificity: 0.8838 - val_specificity_at_sensitivity: 0.7469 - val_recall: 0.9506 - val_precision: 0.6117\n",
            "Epoch 372/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0780 - accuracy: 0.9699 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9626 - precision: 0.9758\n",
            "Epoch 372: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 212ms/step - loss: 0.0780 - accuracy: 0.9699 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9626 - precision: 0.9758 - val_loss: 1.8849 - val_accuracy: 0.6938 - val_sensitivity_at_specificity: 0.9246 - val_specificity_at_sensitivity: 0.7139 - val_recall: 0.9679 - val_precision: 0.6185\n",
            "Epoch 373/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0658 - accuracy: 0.9770 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9718 - precision: 0.9805\n",
            "Epoch 373: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 213ms/step - loss: 0.0658 - accuracy: 0.9770 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9718 - precision: 0.9805 - val_loss: 1.7301 - val_accuracy: 0.7063 - val_sensitivity_at_specificity: 0.9252 - val_specificity_at_sensitivity: 0.7216 - val_recall: 0.9527 - val_precision: 0.6440\n",
            "Epoch 374/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0778 - accuracy: 0.9734 - sensitivity_at_specificity: 0.9977 - specificity_at_sensitivity: 1.0000 - recall: 0.9673 - precision: 0.9795\n",
            "Epoch 374: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 211ms/step - loss: 0.0778 - accuracy: 0.9734 - sensitivity_at_specificity: 0.9977 - specificity_at_sensitivity: 1.0000 - recall: 0.9673 - precision: 0.9795 - val_loss: 1.8299 - val_accuracy: 0.6969 - val_sensitivity_at_specificity: 0.9336 - val_specificity_at_sensitivity: 0.7311 - val_recall: 0.9510 - val_precision: 0.6277\n",
            "Epoch 375/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0800 - accuracy: 0.9652 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9547 - precision: 0.9764\n",
            "Epoch 375: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 213ms/step - loss: 0.0800 - accuracy: 0.9652 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9547 - precision: 0.9764 - val_loss: 1.9279 - val_accuracy: 0.6812 - val_sensitivity_at_specificity: 0.9094 - val_specificity_at_sensitivity: 0.7130 - val_recall: 0.9595 - val_precision: 0.6076\n",
            "Epoch 376/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0661 - accuracy: 0.9773 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9705 - precision: 0.9830\n",
            "Epoch 376: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 212ms/step - loss: 0.0661 - accuracy: 0.9773 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9705 - precision: 0.9830 - val_loss: 1.8501 - val_accuracy: 0.6969 - val_sensitivity_at_specificity: 0.8958 - val_specificity_at_sensitivity: 0.7087 - val_recall: 0.9637 - val_precision: 0.6367\n",
            "Epoch 377/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0742 - accuracy: 0.9762 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9728 - precision: 0.9782\n",
            "Epoch 377: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 216ms/step - loss: 0.0742 - accuracy: 0.9762 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9728 - precision: 0.9782 - val_loss: 1.6881 - val_accuracy: 0.6852 - val_sensitivity_at_specificity: 0.9181 - val_specificity_at_sensitivity: 0.7378 - val_recall: 0.9413 - val_precision: 0.6253\n",
            "Epoch 378/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0822 - accuracy: 0.9668 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9611 - precision: 0.9725\n",
            "Epoch 378: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 213ms/step - loss: 0.0822 - accuracy: 0.9668 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9611 - precision: 0.9725 - val_loss: 1.7379 - val_accuracy: 0.6859 - val_sensitivity_at_specificity: 0.9143 - val_specificity_at_sensitivity: 0.7462 - val_recall: 0.9571 - val_precision: 0.6166\n",
            "Epoch 379/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0729 - accuracy: 0.9770 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9985 - recall: 0.9690 - precision: 0.9838\n",
            "Epoch 379: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 211ms/step - loss: 0.0729 - accuracy: 0.9770 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9985 - recall: 0.9690 - precision: 0.9838 - val_loss: 1.7624 - val_accuracy: 0.6930 - val_sensitivity_at_specificity: 0.9024 - val_specificity_at_sensitivity: 0.7147 - val_recall: 0.9604 - val_precision: 0.6319\n",
            "Epoch 380/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0753 - accuracy: 0.9699 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9598 - precision: 0.9791\n",
            "Epoch 380: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 214ms/step - loss: 0.0753 - accuracy: 0.9699 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9598 - precision: 0.9791 - val_loss: 2.1534 - val_accuracy: 0.6750 - val_sensitivity_at_specificity: 0.9082 - val_specificity_at_sensitivity: 0.6737 - val_recall: 0.9791 - val_precision: 0.6014\n",
            "Epoch 381/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0623 - accuracy: 0.9766 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9711 - precision: 0.9831\n",
            "Epoch 381: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 214ms/step - loss: 0.0623 - accuracy: 0.9766 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9711 - precision: 0.9831 - val_loss: 1.5779 - val_accuracy: 0.6898 - val_sensitivity_at_specificity: 0.9099 - val_specificity_at_sensitivity: 0.7673 - val_recall: 0.9363 - val_precision: 0.6288\n",
            "Epoch 382/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0822 - accuracy: 0.9703 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9698 - precision: 0.9698\n",
            "Epoch 382: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 213ms/step - loss: 0.0822 - accuracy: 0.9703 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9698 - precision: 0.9698 - val_loss: 1.7119 - val_accuracy: 0.6867 - val_sensitivity_at_specificity: 0.9072 - val_specificity_at_sensitivity: 0.7450 - val_recall: 0.9456 - val_precision: 0.6169\n",
            "Epoch 383/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0713 - accuracy: 0.9747 - sensitivity_at_specificity: 0.9983 - specificity_at_sensitivity: 1.0000 - recall: 0.9648 - precision: 0.9825\n",
            "Epoch 383: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 205ms/step - loss: 0.0713 - accuracy: 0.9747 - sensitivity_at_specificity: 0.9983 - specificity_at_sensitivity: 1.0000 - recall: 0.9648 - precision: 0.9825 - val_loss: 2.1143 - val_accuracy: 0.6883 - val_sensitivity_at_specificity: 0.8816 - val_specificity_at_sensitivity: 0.6490 - val_recall: 0.9666 - val_precision: 0.6282\n",
            "Epoch 384/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0793 - accuracy: 0.9723 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9625 - precision: 0.9817\n",
            "Epoch 384: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 215ms/step - loss: 0.0793 - accuracy: 0.9723 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9625 - precision: 0.9817 - val_loss: 1.9891 - val_accuracy: 0.6891 - val_sensitivity_at_specificity: 0.9273 - val_specificity_at_sensitivity: 0.6847 - val_recall: 0.9700 - val_precision: 0.6183\n",
            "Epoch 385/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0687 - accuracy: 0.9754 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9722 - precision: 0.9790\n",
            "Epoch 385: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 215ms/step - loss: 0.0687 - accuracy: 0.9754 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9722 - precision: 0.9790 - val_loss: 1.6854 - val_accuracy: 0.6953 - val_sensitivity_at_specificity: 0.9276 - val_specificity_at_sensitivity: 0.7426 - val_recall: 0.9559 - val_precision: 0.6264\n",
            "Epoch 386/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0693 - accuracy: 0.9711 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9719 - precision: 0.9704\n",
            "Epoch 386: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 220ms/step - loss: 0.0693 - accuracy: 0.9711 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9719 - precision: 0.9704 - val_loss: 1.8213 - val_accuracy: 0.6953 - val_sensitivity_at_specificity: 0.9205 - val_specificity_at_sensitivity: 0.7013 - val_recall: 0.9755 - val_precision: 0.6304\n",
            "Epoch 387/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0738 - accuracy: 0.9734 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9664 - precision: 0.9814\n",
            "Epoch 387: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 214ms/step - loss: 0.0738 - accuracy: 0.9734 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9664 - precision: 0.9814 - val_loss: 1.7942 - val_accuracy: 0.6992 - val_sensitivity_at_specificity: 0.9169 - val_specificity_at_sensitivity: 0.7206 - val_recall: 0.9769 - val_precision: 0.6318\n",
            "Epoch 388/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0666 - accuracy: 0.9734 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9670 - precision: 0.9806\n",
            "Epoch 388: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 213ms/step - loss: 0.0666 - accuracy: 0.9734 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9670 - precision: 0.9806 - val_loss: 1.8038 - val_accuracy: 0.6930 - val_sensitivity_at_specificity: 0.9379 - val_specificity_at_sensitivity: 0.7147 - val_recall: 0.9825 - val_precision: 0.6176\n",
            "Epoch 389/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0757 - accuracy: 0.9703 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9660 - precision: 0.9750\n",
            "Epoch 389: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 216ms/step - loss: 0.0757 - accuracy: 0.9703 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9660 - precision: 0.9750 - val_loss: 1.6101 - val_accuracy: 0.6945 - val_sensitivity_at_specificity: 0.9098 - val_specificity_at_sensitivity: 0.7444 - val_recall: 0.9572 - val_precision: 0.6330\n",
            "Epoch 390/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0556 - accuracy: 0.9828 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9793 - precision: 0.9856\n",
            "Epoch 390: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 219ms/step - loss: 0.0556 - accuracy: 0.9828 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9793 - precision: 0.9856 - val_loss: 1.7561 - val_accuracy: 0.7000 - val_sensitivity_at_specificity: 0.9099 - val_specificity_at_sensitivity: 0.7264 - val_recall: 0.9705 - val_precision: 0.6313\n",
            "Epoch 391/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0593 - accuracy: 0.9809 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9772 - precision: 0.9842\n",
            "Epoch 391: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 211ms/step - loss: 0.0593 - accuracy: 0.9809 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9772 - precision: 0.9842 - val_loss: 1.9211 - val_accuracy: 0.6891 - val_sensitivity_at_specificity: 0.9273 - val_specificity_at_sensitivity: 0.6924 - val_recall: 0.9684 - val_precision: 0.6186\n",
            "Epoch 392/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0745 - accuracy: 0.9715 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9634 - precision: 0.9806\n",
            "Epoch 392: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 217ms/step - loss: 0.0745 - accuracy: 0.9715 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9634 - precision: 0.9806 - val_loss: 2.2868 - val_accuracy: 0.6578 - val_sensitivity_at_specificity: 0.8594 - val_specificity_at_sensitivity: 0.6483 - val_recall: 0.9633 - val_precision: 0.5923\n",
            "Epoch 393/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0616 - accuracy: 0.9805 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9762 - precision: 0.9853\n",
            "Epoch 393: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 213ms/step - loss: 0.0616 - accuracy: 0.9805 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9762 - precision: 0.9853 - val_loss: 1.9269 - val_accuracy: 0.6828 - val_sensitivity_at_specificity: 0.8950 - val_specificity_at_sensitivity: 0.6978 - val_recall: 0.9545 - val_precision: 0.6176\n",
            "Epoch 394/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0755 - accuracy: 0.9713 - sensitivity_at_specificity: 0.9991 - specificity_at_sensitivity: 1.0000 - recall: 0.9668 - precision: 0.9742\n",
            "Epoch 394: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 209ms/step - loss: 0.0755 - accuracy: 0.9713 - sensitivity_at_specificity: 0.9991 - specificity_at_sensitivity: 1.0000 - recall: 0.9668 - precision: 0.9742 - val_loss: 1.6824 - val_accuracy: 0.6930 - val_sensitivity_at_specificity: 0.9260 - val_specificity_at_sensitivity: 0.7306 - val_recall: 0.9538 - val_precision: 0.6303\n",
            "Epoch 395/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0749 - accuracy: 0.9703 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9651 - precision: 0.9757\n",
            "Epoch 395: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 214ms/step - loss: 0.0749 - accuracy: 0.9703 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9651 - precision: 0.9757 - val_loss: 1.9229 - val_accuracy: 0.6766 - val_sensitivity_at_specificity: 0.8780 - val_specificity_at_sensitivity: 0.7203 - val_recall: 0.9659 - val_precision: 0.6018\n",
            "Epoch 396/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0627 - accuracy: 0.9754 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9746 - precision: 0.9768\n",
            "Epoch 396: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 215ms/step - loss: 0.0627 - accuracy: 0.9754 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9746 - precision: 0.9768 - val_loss: 1.7091 - val_accuracy: 0.7031 - val_sensitivity_at_specificity: 0.9277 - val_specificity_at_sensitivity: 0.7302 - val_recall: 0.9662 - val_precision: 0.6369\n",
            "Epoch 397/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0641 - accuracy: 0.9742 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9672 - precision: 0.9822\n",
            "Epoch 397: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 211ms/step - loss: 0.0641 - accuracy: 0.9742 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9672 - precision: 0.9822 - val_loss: 1.9497 - val_accuracy: 0.6984 - val_sensitivity_at_specificity: 0.9208 - val_specificity_at_sensitivity: 0.6710 - val_recall: 0.9701 - val_precision: 0.6394\n",
            "Epoch 398/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0659 - accuracy: 0.9727 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9695 - precision: 0.9769\n",
            "Epoch 398: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 210ms/step - loss: 0.0659 - accuracy: 0.9727 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9695 - precision: 0.9769 - val_loss: 1.9563 - val_accuracy: 0.6875 - val_sensitivity_at_specificity: 0.9138 - val_specificity_at_sensitivity: 0.6857 - val_recall: 0.9708 - val_precision: 0.6235\n",
            "Epoch 399/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0675 - accuracy: 0.9754 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9751 - precision: 0.9759\n",
            "Epoch 399: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 209ms/step - loss: 0.0675 - accuracy: 0.9754 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9751 - precision: 0.9759 - val_loss: 1.9982 - val_accuracy: 0.6734 - val_sensitivity_at_specificity: 0.8936 - val_specificity_at_sensitivity: 0.7085 - val_recall: 0.9558 - val_precision: 0.5990\n",
            "Epoch 400/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0764 - accuracy: 0.9711 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9640 - precision: 0.9778\n",
            "Epoch 400: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 215ms/step - loss: 0.0764 - accuracy: 0.9711 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9640 - precision: 0.9778 - val_loss: 1.9339 - val_accuracy: 0.6891 - val_sensitivity_at_specificity: 0.9021 - val_specificity_at_sensitivity: 0.6753 - val_recall: 0.9714 - val_precision: 0.6299\n",
            "Epoch 401/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0763 - accuracy: 0.9715 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9663 - precision: 0.9763\n",
            "Epoch 401: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 211ms/step - loss: 0.0763 - accuracy: 0.9715 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9663 - precision: 0.9763 - val_loss: 1.9106 - val_accuracy: 0.6672 - val_sensitivity_at_specificity: 0.8892 - val_specificity_at_sensitivity: 0.7089 - val_recall: 0.9548 - val_precision: 0.6065\n",
            "Epoch 402/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0722 - accuracy: 0.9707 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9654 - precision: 0.9767\n",
            "Epoch 402: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 220ms/step - loss: 0.0722 - accuracy: 0.9707 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9654 - precision: 0.9767 - val_loss: 2.0589 - val_accuracy: 0.6828 - val_sensitivity_at_specificity: 0.8937 - val_specificity_at_sensitivity: 0.6692 - val_recall: 0.9730 - val_precision: 0.6118\n",
            "Epoch 403/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0619 - accuracy: 0.9781 - sensitivity_at_specificity: 0.9993 - specificity_at_sensitivity: 1.0000 - recall: 0.9742 - precision: 0.9844\n",
            "Epoch 403: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 216ms/step - loss: 0.0619 - accuracy: 0.9781 - sensitivity_at_specificity: 0.9993 - specificity_at_sensitivity: 1.0000 - recall: 0.9742 - precision: 0.9844 - val_loss: 1.9413 - val_accuracy: 0.6992 - val_sensitivity_at_specificity: 0.9256 - val_specificity_at_sensitivity: 0.6860 - val_recall: 0.9803 - val_precision: 0.6346\n",
            "Epoch 404/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0517 - accuracy: 0.9812 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9814 - precision: 0.9814\n",
            "Epoch 404: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 216ms/step - loss: 0.0517 - accuracy: 0.9812 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9814 - precision: 0.9814 - val_loss: 1.9439 - val_accuracy: 0.6828 - val_sensitivity_at_specificity: 0.9036 - val_specificity_at_sensitivity: 0.6954 - val_recall: 0.9549 - val_precision: 0.6196\n",
            "Epoch 405/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0619 - accuracy: 0.9742 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9713 - precision: 0.9774\n",
            "Epoch 405: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 216ms/step - loss: 0.0619 - accuracy: 0.9742 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9713 - precision: 0.9774 - val_loss: 1.8820 - val_accuracy: 0.6969 - val_sensitivity_at_specificity: 0.9176 - val_specificity_at_sensitivity: 0.7149 - val_recall: 0.9540 - val_precision: 0.6264\n",
            "Epoch 406/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0537 - accuracy: 0.9788 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9799 - precision: 0.9774\n",
            "Epoch 406: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 206ms/step - loss: 0.0537 - accuracy: 0.9788 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9799 - precision: 0.9774 - val_loss: 1.9356 - val_accuracy: 0.6922 - val_sensitivity_at_specificity: 0.9278 - val_specificity_at_sensitivity: 0.6998 - val_recall: 0.9655 - val_precision: 0.6231\n",
            "Epoch 407/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0646 - accuracy: 0.9750 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9650 - precision: 0.9849\n",
            "Epoch 407: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 215ms/step - loss: 0.0646 - accuracy: 0.9750 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9650 - precision: 0.9849 - val_loss: 2.0780 - val_accuracy: 0.6844 - val_sensitivity_at_specificity: 0.9371 - val_specificity_at_sensitivity: 0.6848 - val_recall: 0.9654 - val_precision: 0.6165\n",
            "Epoch 408/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0575 - accuracy: 0.9742 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9692 - precision: 0.9798\n",
            "Epoch 408: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 215ms/step - loss: 0.0575 - accuracy: 0.9742 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9692 - precision: 0.9798 - val_loss: 1.7686 - val_accuracy: 0.7102 - val_sensitivity_at_specificity: 0.9302 - val_specificity_at_sensitivity: 0.7182 - val_recall: 0.9651 - val_precision: 0.6463\n",
            "Epoch 409/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0609 - accuracy: 0.9766 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9745 - precision: 0.9790\n",
            "Epoch 409: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 215ms/step - loss: 0.0609 - accuracy: 0.9766 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9745 - precision: 0.9790 - val_loss: 2.0753 - val_accuracy: 0.6961 - val_sensitivity_at_specificity: 0.9048 - val_specificity_at_sensitivity: 0.6480 - val_recall: 0.9628 - val_precision: 0.6400\n",
            "Epoch 410/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0538 - accuracy: 0.9816 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9762 - precision: 0.9876\n",
            "Epoch 410: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 215ms/step - loss: 0.0538 - accuracy: 0.9816 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9762 - precision: 0.9876 - val_loss: 1.9288 - val_accuracy: 0.6945 - val_sensitivity_at_specificity: 0.9269 - val_specificity_at_sensitivity: 0.7035 - val_recall: 0.9714 - val_precision: 0.6209\n",
            "Epoch 411/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0615 - accuracy: 0.9776 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9704 - precision: 0.9862\n",
            "Epoch 411: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 209ms/step - loss: 0.0615 - accuracy: 0.9776 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9704 - precision: 0.9862 - val_loss: 2.0910 - val_accuracy: 0.6922 - val_sensitivity_at_specificity: 0.9118 - val_specificity_at_sensitivity: 0.6751 - val_recall: 0.9706 - val_precision: 0.6257\n",
            "Epoch 412/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0717 - accuracy: 0.9723 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9692 - precision: 0.9759\n",
            "Epoch 412: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 218ms/step - loss: 0.0717 - accuracy: 0.9723 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9692 - precision: 0.9759 - val_loss: 1.7088 - val_accuracy: 0.7086 - val_sensitivity_at_specificity: 0.9259 - val_specificity_at_sensitivity: 0.7189 - val_recall: 0.9713 - val_precision: 0.6446\n",
            "Epoch 413/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0639 - accuracy: 0.9770 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9713 - precision: 0.9839\n",
            "Epoch 413: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 215ms/step - loss: 0.0639 - accuracy: 0.9770 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9713 - precision: 0.9839 - val_loss: 2.2282 - val_accuracy: 0.6859 - val_sensitivity_at_specificity: 0.9059 - val_specificity_at_sensitivity: 0.6371 - val_recall: 0.9793 - val_precision: 0.6122\n",
            "Epoch 414/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0590 - accuracy: 0.9789 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9691 - precision: 0.9867\n",
            "Epoch 414: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 216ms/step - loss: 0.0590 - accuracy: 0.9789 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9691 - precision: 0.9867 - val_loss: 2.4838 - val_accuracy: 0.6602 - val_sensitivity_at_specificity: 0.8605 - val_specificity_at_sensitivity: 0.6059 - val_recall: 0.9812 - val_precision: 0.5968\n",
            "Epoch 415/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0700 - accuracy: 0.9773 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9771 - precision: 0.9771\n",
            "Epoch 415: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 221ms/step - loss: 0.0700 - accuracy: 0.9773 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9771 - precision: 0.9771 - val_loss: 1.8293 - val_accuracy: 0.7070 - val_sensitivity_at_specificity: 0.9287 - val_specificity_at_sensitivity: 0.7196 - val_recall: 0.9540 - val_precision: 0.6350\n",
            "Epoch 416/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0720 - accuracy: 0.9719 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9655 - precision: 0.9778\n",
            "Epoch 416: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 219ms/step - loss: 0.0720 - accuracy: 0.9719 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9655 - precision: 0.9778 - val_loss: 1.6872 - val_accuracy: 0.6930 - val_sensitivity_at_specificity: 0.9081 - val_specificity_at_sensitivity: 0.7350 - val_recall: 0.9414 - val_precision: 0.6253\n",
            "Epoch 417/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0746 - accuracy: 0.9719 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9700 - precision: 0.9745\n",
            "Epoch 417: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 215ms/step - loss: 0.0746 - accuracy: 0.9719 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9700 - precision: 0.9745 - val_loss: 2.2547 - val_accuracy: 0.6664 - val_sensitivity_at_specificity: 0.8866 - val_specificity_at_sensitivity: 0.6226 - val_recall: 0.9720 - val_precision: 0.6048\n",
            "Epoch 418/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0718 - accuracy: 0.9730 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9650 - precision: 0.9798\n",
            "Epoch 418: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 214ms/step - loss: 0.0718 - accuracy: 0.9730 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9650 - precision: 0.9798 - val_loss: 2.0182 - val_accuracy: 0.6836 - val_sensitivity_at_specificity: 0.9062 - val_specificity_at_sensitivity: 0.6844 - val_recall: 0.9734 - val_precision: 0.6162\n",
            "Epoch 419/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0569 - accuracy: 0.9805 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9781 - precision: 0.9827\n",
            "Epoch 419: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 217ms/step - loss: 0.0569 - accuracy: 0.9805 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9781 - precision: 0.9827 - val_loss: 1.8923 - val_accuracy: 0.6781 - val_sensitivity_at_specificity: 0.9042 - val_specificity_at_sensitivity: 0.6983 - val_recall: 0.9567 - val_precision: 0.6171\n",
            "Epoch 420/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0540 - accuracy: 0.9797 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9772 - precision: 0.9818\n",
            "Epoch 420: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 218ms/step - loss: 0.0540 - accuracy: 0.9797 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9772 - precision: 0.9818 - val_loss: 2.2359 - val_accuracy: 0.6797 - val_sensitivity_at_specificity: 0.9289 - val_specificity_at_sensitivity: 0.6476 - val_recall: 0.9731 - val_precision: 0.6105\n",
            "Epoch 421/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0700 - accuracy: 0.9734 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9984 - recall: 0.9709 - precision: 0.9755\n",
            "Epoch 421: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 218ms/step - loss: 0.0700 - accuracy: 0.9734 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9984 - recall: 0.9709 - precision: 0.9755 - val_loss: 2.0554 - val_accuracy: 0.6859 - val_sensitivity_at_specificity: 0.9190 - val_specificity_at_sensitivity: 0.6740 - val_recall: 0.9657 - val_precision: 0.6200\n",
            "Epoch 422/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0666 - accuracy: 0.9762 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9744 - precision: 0.9782\n",
            "Epoch 422: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 3s 289ms/step - loss: 0.0666 - accuracy: 0.9762 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9744 - precision: 0.9782 - val_loss: 2.1414 - val_accuracy: 0.6812 - val_sensitivity_at_specificity: 0.9113 - val_specificity_at_sensitivity: 0.6833 - val_recall: 0.9758 - val_precision: 0.6062\n",
            "Epoch 423/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0677 - accuracy: 0.9746 - sensitivity_at_specificity: 0.9993 - specificity_at_sensitivity: 1.0000 - recall: 0.9682 - precision: 0.9835\n",
            "Epoch 423: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 220ms/step - loss: 0.0677 - accuracy: 0.9746 - sensitivity_at_specificity: 0.9993 - specificity_at_sensitivity: 1.0000 - recall: 0.9682 - precision: 0.9835 - val_loss: 1.9511 - val_accuracy: 0.6992 - val_sensitivity_at_specificity: 0.9288 - val_specificity_at_sensitivity: 0.7032 - val_recall: 0.9561 - val_precision: 0.6393\n",
            "Epoch 424/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0598 - accuracy: 0.9746 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9698 - precision: 0.9784\n",
            "Epoch 424: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 214ms/step - loss: 0.0598 - accuracy: 0.9746 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9698 - precision: 0.9784 - val_loss: 1.8985 - val_accuracy: 0.6859 - val_sensitivity_at_specificity: 0.9208 - val_specificity_at_sensitivity: 0.6949 - val_recall: 0.9651 - val_precision: 0.6158\n",
            "Epoch 425/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0652 - accuracy: 0.9777 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9992 - recall: 0.9712 - precision: 0.9830\n",
            "Epoch 425: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 210ms/step - loss: 0.0652 - accuracy: 0.9777 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9992 - recall: 0.9712 - precision: 0.9830 - val_loss: 1.9764 - val_accuracy: 0.6562 - val_sensitivity_at_specificity: 0.8780 - val_specificity_at_sensitivity: 0.7173 - val_recall: 0.9561 - val_precision: 0.5874\n",
            "Epoch 426/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0619 - accuracy: 0.9766 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9775 - precision: 0.9744\n",
            "Epoch 426: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 217ms/step - loss: 0.0619 - accuracy: 0.9766 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9775 - precision: 0.9744 - val_loss: 1.7834 - val_accuracy: 0.7016 - val_sensitivity_at_specificity: 0.9118 - val_specificity_at_sensitivity: 0.7395 - val_recall: 0.9449 - val_precision: 0.6336\n",
            "Epoch 427/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0739 - accuracy: 0.9715 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9661 - precision: 0.9774\n",
            "Epoch 427: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 214ms/step - loss: 0.0739 - accuracy: 0.9715 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9661 - precision: 0.9774 - val_loss: 2.2895 - val_accuracy: 0.6891 - val_sensitivity_at_specificity: 0.9194 - val_specificity_at_sensitivity: 0.6275 - val_recall: 0.9795 - val_precision: 0.6169\n",
            "Epoch 428/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0645 - accuracy: 0.9754 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9658 - precision: 0.9871\n",
            "Epoch 428: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 219ms/step - loss: 0.0645 - accuracy: 0.9754 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9658 - precision: 0.9871 - val_loss: 2.2646 - val_accuracy: 0.6922 - val_sensitivity_at_specificity: 0.9258 - val_specificity_at_sensitivity: 0.6538 - val_recall: 0.9810 - val_precision: 0.6191\n",
            "Epoch 429/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0637 - accuracy: 0.9785 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9789 - precision: 0.9781\n",
            "Epoch 429: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 212ms/step - loss: 0.0637 - accuracy: 0.9785 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9789 - precision: 0.9781 - val_loss: 1.9513 - val_accuracy: 0.6789 - val_sensitivity_at_specificity: 0.9017 - val_specificity_at_sensitivity: 0.6933 - val_recall: 0.9548 - val_precision: 0.6157\n",
            "Epoch 430/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0486 - accuracy: 0.9821 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9814 - precision: 0.9822\n",
            "Epoch 430: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 209ms/step - loss: 0.0486 - accuracy: 0.9821 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9814 - precision: 0.9822 - val_loss: 1.9639 - val_accuracy: 0.6891 - val_sensitivity_at_specificity: 0.9182 - val_specificity_at_sensitivity: 0.7089 - val_recall: 0.9660 - val_precision: 0.6248\n",
            "Epoch 431/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0632 - accuracy: 0.9758 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9666 - precision: 0.9838\n",
            "Epoch 431: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 211ms/step - loss: 0.0632 - accuracy: 0.9758 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9666 - precision: 0.9838 - val_loss: 2.2581 - val_accuracy: 0.6953 - val_sensitivity_at_specificity: 0.9248 - val_specificity_at_sensitivity: 0.6322 - val_recall: 0.9755 - val_precision: 0.6297\n",
            "Epoch 432/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0489 - accuracy: 0.9832 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9847 - precision: 0.9825\n",
            "Epoch 432: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 214ms/step - loss: 0.0489 - accuracy: 0.9832 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9847 - precision: 0.9825 - val_loss: 2.0063 - val_accuracy: 0.6867 - val_sensitivity_at_specificity: 0.9062 - val_specificity_at_sensitivity: 0.6774 - val_recall: 0.9682 - val_precision: 0.6152\n",
            "Epoch 433/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0472 - accuracy: 0.9812 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9755 - precision: 0.9876\n",
            "Epoch 433: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 213ms/step - loss: 0.0472 - accuracy: 0.9812 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9755 - precision: 0.9876 - val_loss: 2.4421 - val_accuracy: 0.6844 - val_sensitivity_at_specificity: 0.9108 - val_specificity_at_sensitivity: 0.6089 - val_recall: 0.9729 - val_precision: 0.6122\n",
            "Epoch 434/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0443 - accuracy: 0.9809 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9800 - precision: 0.9823\n",
            "Epoch 434: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 211ms/step - loss: 0.0443 - accuracy: 0.9809 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9800 - precision: 0.9823 - val_loss: 2.4648 - val_accuracy: 0.6680 - val_sensitivity_at_specificity: 0.8952 - val_specificity_at_sensitivity: 0.6181 - val_recall: 0.9630 - val_precision: 0.6092\n",
            "Epoch 435/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0467 - accuracy: 0.9852 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9805 - precision: 0.9897\n",
            "Epoch 435: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 212ms/step - loss: 0.0467 - accuracy: 0.9852 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9805 - precision: 0.9897 - val_loss: 2.5708 - val_accuracy: 0.6781 - val_sensitivity_at_specificity: 0.8877 - val_specificity_at_sensitivity: 0.6127 - val_recall: 0.9668 - val_precision: 0.6098\n",
            "Epoch 436/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0601 - accuracy: 0.9770 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9702 - precision: 0.9821\n",
            "Epoch 436: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 210ms/step - loss: 0.0601 - accuracy: 0.9770 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9702 - precision: 0.9821 - val_loss: 2.4351 - val_accuracy: 0.6766 - val_sensitivity_at_specificity: 0.9072 - val_specificity_at_sensitivity: 0.6397 - val_recall: 0.9584 - val_precision: 0.6069\n",
            "Epoch 437/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0490 - accuracy: 0.9824 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9777 - precision: 0.9864\n",
            "Epoch 437: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 215ms/step - loss: 0.0490 - accuracy: 0.9824 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9777 - precision: 0.9864 - val_loss: 2.5882 - val_accuracy: 0.6828 - val_sensitivity_at_specificity: 0.9108 - val_specificity_at_sensitivity: 0.6127 - val_recall: 0.9631 - val_precision: 0.6210\n",
            "Epoch 438/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0585 - accuracy: 0.9809 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9747 - precision: 0.9864\n",
            "Epoch 438: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 211ms/step - loss: 0.0585 - accuracy: 0.9809 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9747 - precision: 0.9864 - val_loss: 2.4638 - val_accuracy: 0.6828 - val_sensitivity_at_specificity: 0.9033 - val_specificity_at_sensitivity: 0.6088 - val_recall: 0.9610 - val_precision: 0.6179\n",
            "Epoch 439/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0631 - accuracy: 0.9789 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 0.9984 - recall: 0.9766 - precision: 0.9825\n",
            "Epoch 439: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 213ms/step - loss: 0.0631 - accuracy: 0.9789 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 0.9984 - recall: 0.9766 - precision: 0.9825 - val_loss: 1.9150 - val_accuracy: 0.6883 - val_sensitivity_at_specificity: 0.8981 - val_specificity_at_sensitivity: 0.7057 - val_recall: 0.9522 - val_precision: 0.6264\n",
            "Epoch 440/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0596 - accuracy: 0.9801 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9992 - recall: 0.9735 - precision: 0.9866\n",
            "Epoch 440: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 210ms/step - loss: 0.0596 - accuracy: 0.9801 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9992 - recall: 0.9735 - precision: 0.9866 - val_loss: 2.2417 - val_accuracy: 0.7031 - val_sensitivity_at_specificity: 0.9134 - val_specificity_at_sensitivity: 0.6334 - val_recall: 0.9757 - val_precision: 0.6382\n",
            "Epoch 441/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0676 - accuracy: 0.9734 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9682 - precision: 0.9788\n",
            "Epoch 441: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 218ms/step - loss: 0.0676 - accuracy: 0.9734 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9682 - precision: 0.9788 - val_loss: 2.2621 - val_accuracy: 0.7164 - val_sensitivity_at_specificity: 0.9161 - val_specificity_at_sensitivity: 0.6007 - val_recall: 0.9794 - val_precision: 0.6558\n",
            "Epoch 442/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0598 - accuracy: 0.9812 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9791 - precision: 0.9836\n",
            "Epoch 442: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 212ms/step - loss: 0.0598 - accuracy: 0.9812 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9791 - precision: 0.9836 - val_loss: 2.1849 - val_accuracy: 0.6781 - val_sensitivity_at_specificity: 0.8927 - val_specificity_at_sensitivity: 0.6327 - val_recall: 0.9658 - val_precision: 0.6142\n",
            "Epoch 443/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0742 - accuracy: 0.9762 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 0.9984 - recall: 0.9747 - precision: 0.9784\n",
            "Epoch 443: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 216ms/step - loss: 0.0742 - accuracy: 0.9762 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 0.9984 - recall: 0.9747 - precision: 0.9784 - val_loss: 1.9322 - val_accuracy: 0.6898 - val_sensitivity_at_specificity: 0.8860 - val_specificity_at_sensitivity: 0.7005 - val_recall: 0.9630 - val_precision: 0.6263\n",
            "Epoch 444/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0646 - accuracy: 0.9754 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9725 - precision: 0.9779\n",
            "Epoch 444: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 217ms/step - loss: 0.0646 - accuracy: 0.9754 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9725 - precision: 0.9779 - val_loss: 2.1329 - val_accuracy: 0.6859 - val_sensitivity_at_specificity: 0.9067 - val_specificity_at_sensitivity: 0.6430 - val_recall: 0.9793 - val_precision: 0.6301\n",
            "Epoch 445/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0609 - accuracy: 0.9777 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9785 - precision: 0.9778\n",
            "Epoch 445: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 220ms/step - loss: 0.0609 - accuracy: 0.9777 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9785 - precision: 0.9778 - val_loss: 2.2155 - val_accuracy: 0.6758 - val_sensitivity_at_specificity: 0.9078 - val_specificity_at_sensitivity: 0.6297 - val_recall: 0.9750 - val_precision: 0.6100\n",
            "Epoch 446/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0539 - accuracy: 0.9809 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9739 - precision: 0.9872\n",
            "Epoch 446: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 215ms/step - loss: 0.0539 - accuracy: 0.9809 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9739 - precision: 0.9872 - val_loss: 2.2405 - val_accuracy: 0.6945 - val_sensitivity_at_specificity: 0.9268 - val_specificity_at_sensitivity: 0.6552 - val_recall: 0.9860 - val_precision: 0.6236\n",
            "Epoch 447/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0409 - accuracy: 0.9855 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9840 - precision: 0.9863\n",
            "Epoch 447: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 215ms/step - loss: 0.0409 - accuracy: 0.9855 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9840 - precision: 0.9863 - val_loss: 2.0696 - val_accuracy: 0.6758 - val_sensitivity_at_specificity: 0.8815 - val_specificity_at_sensitivity: 0.6704 - val_recall: 0.9559 - val_precision: 0.6197\n",
            "Epoch 448/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0564 - accuracy: 0.9812 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9773 - precision: 0.9850\n",
            "Epoch 448: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 213ms/step - loss: 0.0564 - accuracy: 0.9812 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9773 - precision: 0.9850 - val_loss: 2.1290 - val_accuracy: 0.6898 - val_sensitivity_at_specificity: 0.9105 - val_specificity_at_sensitivity: 0.6656 - val_recall: 0.9529 - val_precision: 0.6232\n",
            "Epoch 449/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0629 - accuracy: 0.9746 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9715 - precision: 0.9796\n",
            "Epoch 449: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 214ms/step - loss: 0.0629 - accuracy: 0.9746 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9715 - precision: 0.9796 - val_loss: 2.4134 - val_accuracy: 0.6750 - val_sensitivity_at_specificity: 0.8983 - val_specificity_at_sensitivity: 0.6131 - val_recall: 0.9734 - val_precision: 0.6092\n",
            "Epoch 450/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0585 - accuracy: 0.9812 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9762 - precision: 0.9843\n",
            "Epoch 450: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 216ms/step - loss: 0.0585 - accuracy: 0.9812 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9762 - precision: 0.9843 - val_loss: 1.9947 - val_accuracy: 0.6961 - val_sensitivity_at_specificity: 0.9296 - val_specificity_at_sensitivity: 0.6989 - val_recall: 0.9828 - val_precision: 0.6243\n",
            "Epoch 451/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0710 - accuracy: 0.9727 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9668 - precision: 0.9789\n",
            "Epoch 451: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 214ms/step - loss: 0.0710 - accuracy: 0.9727 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9668 - precision: 0.9789 - val_loss: 2.1027 - val_accuracy: 0.6711 - val_sensitivity_at_specificity: 0.9358 - val_specificity_at_sensitivity: 0.6802 - val_recall: 0.9747 - val_precision: 0.5870\n",
            "Epoch 452/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0655 - accuracy: 0.9789 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9765 - precision: 0.9811\n",
            "Epoch 452: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 216ms/step - loss: 0.0655 - accuracy: 0.9789 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9765 - precision: 0.9811 - val_loss: 2.1529 - val_accuracy: 0.6562 - val_sensitivity_at_specificity: 0.8621 - val_specificity_at_sensitivity: 0.6604 - val_recall: 0.9577 - val_precision: 0.5967\n",
            "Epoch 453/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0585 - accuracy: 0.9785 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9780 - precision: 0.9802\n",
            "Epoch 453: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 214ms/step - loss: 0.0585 - accuracy: 0.9785 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9780 - precision: 0.9802 - val_loss: 2.3719 - val_accuracy: 0.6695 - val_sensitivity_at_specificity: 0.9205 - val_specificity_at_sensitivity: 0.6461 - val_recall: 0.9854 - val_precision: 0.5945\n",
            "Epoch 454/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0513 - accuracy: 0.9793 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9742 - precision: 0.9854\n",
            "Epoch 454: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 220ms/step - loss: 0.0513 - accuracy: 0.9793 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9742 - precision: 0.9854 - val_loss: 2.3109 - val_accuracy: 0.6781 - val_sensitivity_at_specificity: 0.9092 - val_specificity_at_sensitivity: 0.6365 - val_recall: 0.9640 - val_precision: 0.6129\n",
            "Epoch 455/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0584 - accuracy: 0.9776 - sensitivity_at_specificity: 0.9975 - specificity_at_sensitivity: 1.0000 - recall: 0.9678 - precision: 0.9862\n",
            "Epoch 455: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 206ms/step - loss: 0.0584 - accuracy: 0.9776 - sensitivity_at_specificity: 0.9975 - specificity_at_sensitivity: 1.0000 - recall: 0.9678 - precision: 0.9862 - val_loss: 2.3270 - val_accuracy: 0.6922 - val_sensitivity_at_specificity: 0.9165 - val_specificity_at_sensitivity: 0.6351 - val_recall: 0.9722 - val_precision: 0.6259\n",
            "Epoch 456/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0517 - accuracy: 0.9812 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9771 - precision: 0.9849\n",
            "Epoch 456: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 215ms/step - loss: 0.0517 - accuracy: 0.9812 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9771 - precision: 0.9849 - val_loss: 2.1184 - val_accuracy: 0.6891 - val_sensitivity_at_specificity: 0.8709 - val_specificity_at_sensitivity: 0.6466 - val_recall: 0.9760 - val_precision: 0.6298\n",
            "Epoch 457/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0546 - accuracy: 0.9797 - sensitivity_at_specificity: 0.9993 - specificity_at_sensitivity: 1.0000 - recall: 0.9769 - precision: 0.9843\n",
            "Epoch 457: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 215ms/step - loss: 0.0546 - accuracy: 0.9797 - sensitivity_at_specificity: 0.9993 - specificity_at_sensitivity: 1.0000 - recall: 0.9769 - precision: 0.9843 - val_loss: 2.1918 - val_accuracy: 0.6922 - val_sensitivity_at_specificity: 0.9209 - val_specificity_at_sensitivity: 0.6340 - val_recall: 0.9756 - val_precision: 0.6290\n",
            "Epoch 458/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0587 - accuracy: 0.9773 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9771 - precision: 0.9786\n",
            "Epoch 458: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 214ms/step - loss: 0.0587 - accuracy: 0.9773 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9771 - precision: 0.9786 - val_loss: 2.3408 - val_accuracy: 0.6828 - val_sensitivity_at_specificity: 0.9008 - val_specificity_at_sensitivity: 0.6295 - val_recall: 0.9717 - val_precision: 0.6139\n",
            "Epoch 459/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0588 - accuracy: 0.9816 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9984 - recall: 0.9774 - precision: 0.9859\n",
            "Epoch 459: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 212ms/step - loss: 0.0588 - accuracy: 0.9816 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9984 - recall: 0.9774 - precision: 0.9859 - val_loss: 1.8933 - val_accuracy: 0.6898 - val_sensitivity_at_specificity: 0.9164 - val_specificity_at_sensitivity: 0.7260 - val_recall: 0.9590 - val_precision: 0.6210\n",
            "Epoch 460/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0491 - accuracy: 0.9812 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9779 - precision: 0.9841\n",
            "Epoch 460: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 213ms/step - loss: 0.0491 - accuracy: 0.9812 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9779 - precision: 0.9841 - val_loss: 2.0634 - val_accuracy: 0.6961 - val_sensitivity_at_specificity: 0.9218 - val_specificity_at_sensitivity: 0.7005 - val_recall: 0.9671 - val_precision: 0.6268\n",
            "Epoch 461/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0451 - accuracy: 0.9828 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9801 - precision: 0.9862\n",
            "Epoch 461: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 216ms/step - loss: 0.0451 - accuracy: 0.9828 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9801 - precision: 0.9862 - val_loss: 2.4093 - val_accuracy: 0.6680 - val_sensitivity_at_specificity: 0.8947 - val_specificity_at_sensitivity: 0.6263 - val_recall: 0.9681 - val_precision: 0.5998\n",
            "Epoch 462/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0465 - accuracy: 0.9812 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9809 - precision: 0.9824\n",
            "Epoch 462: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 214ms/step - loss: 0.0465 - accuracy: 0.9812 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9809 - precision: 0.9824 - val_loss: 2.5255 - val_accuracy: 0.6648 - val_sensitivity_at_specificity: 0.9045 - val_specificity_at_sensitivity: 0.6042 - val_recall: 0.9790 - val_precision: 0.5926\n",
            "Epoch 463/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0518 - accuracy: 0.9792 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9719 - precision: 0.9866\n",
            "Epoch 463: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 216ms/step - loss: 0.0518 - accuracy: 0.9792 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9719 - precision: 0.9866 - val_loss: 2.1548 - val_accuracy: 0.6922 - val_sensitivity_at_specificity: 0.9213 - val_specificity_at_sensitivity: 0.6512 - val_recall: 0.9685 - val_precision: 0.6218\n",
            "Epoch 464/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0544 - accuracy: 0.9801 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9788 - precision: 0.9811\n",
            "Epoch 464: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 219ms/step - loss: 0.0544 - accuracy: 0.9801 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9788 - precision: 0.9811 - val_loss: 2.2194 - val_accuracy: 0.6906 - val_sensitivity_at_specificity: 0.9203 - val_specificity_at_sensitivity: 0.6738 - val_recall: 0.9681 - val_precision: 0.6175\n",
            "Epoch 465/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0549 - accuracy: 0.9805 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9992 - recall: 0.9772 - precision: 0.9834\n",
            "Epoch 465: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 219ms/step - loss: 0.0549 - accuracy: 0.9805 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9992 - recall: 0.9772 - precision: 0.9834 - val_loss: 2.3235 - val_accuracy: 0.6805 - val_sensitivity_at_specificity: 0.9060 - val_specificity_at_sensitivity: 0.6228 - val_recall: 0.9599 - val_precision: 0.6193\n",
            "Epoch 466/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0535 - accuracy: 0.9812 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9825 - precision: 0.9810\n",
            "Epoch 466: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 216ms/step - loss: 0.0535 - accuracy: 0.9812 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9825 - precision: 0.9810 - val_loss: 2.3285 - val_accuracy: 0.6914 - val_sensitivity_at_specificity: 0.9030 - val_specificity_at_sensitivity: 0.6209 - val_recall: 0.9718 - val_precision: 0.6222\n",
            "Epoch 467/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0453 - accuracy: 0.9840 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9847 - precision: 0.9840\n",
            "Epoch 467: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 220ms/step - loss: 0.0453 - accuracy: 0.9840 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9847 - precision: 0.9840 - val_loss: 2.2424 - val_accuracy: 0.6961 - val_sensitivity_at_specificity: 0.8841 - val_specificity_at_sensitivity: 0.6068 - val_recall: 0.9623 - val_precision: 0.6465\n",
            "Epoch 468/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0430 - accuracy: 0.9836 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9827 - precision: 0.9842\n",
            "Epoch 468: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 215ms/step - loss: 0.0430 - accuracy: 0.9836 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9827 - precision: 0.9842 - val_loss: 2.5697 - val_accuracy: 0.6797 - val_sensitivity_at_specificity: 0.8807 - val_specificity_at_sensitivity: 0.6065 - val_recall: 0.9686 - val_precision: 0.6127\n",
            "Epoch 469/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0597 - accuracy: 0.9766 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9699 - precision: 0.9836\n",
            "Epoch 469: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 217ms/step - loss: 0.0597 - accuracy: 0.9766 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9699 - precision: 0.9836 - val_loss: 2.2452 - val_accuracy: 0.6844 - val_sensitivity_at_specificity: 0.9124 - val_specificity_at_sensitivity: 0.6518 - val_recall: 0.9647 - val_precision: 0.6224\n",
            "Epoch 470/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0492 - accuracy: 0.9805 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9801 - precision: 0.9816\n",
            "Epoch 470: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 217ms/step - loss: 0.0492 - accuracy: 0.9805 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9801 - precision: 0.9816 - val_loss: 1.9368 - val_accuracy: 0.7164 - val_sensitivity_at_specificity: 0.9378 - val_specificity_at_sensitivity: 0.6661 - val_recall: 0.9763 - val_precision: 0.6551\n",
            "Epoch 471/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0481 - accuracy: 0.9816 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9797 - precision: 0.9835\n",
            "Epoch 471: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 215ms/step - loss: 0.0481 - accuracy: 0.9816 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9797 - precision: 0.9835 - val_loss: 2.3562 - val_accuracy: 0.6805 - val_sensitivity_at_specificity: 0.9111 - val_specificity_at_sensitivity: 0.6218 - val_recall: 0.9729 - val_precision: 0.6230\n",
            "Epoch 472/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0473 - accuracy: 0.9836 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9801 - precision: 0.9877\n",
            "Epoch 472: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 213ms/step - loss: 0.0473 - accuracy: 0.9836 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9801 - precision: 0.9877 - val_loss: 2.2288 - val_accuracy: 0.6938 - val_sensitivity_at_specificity: 0.9345 - val_specificity_at_sensitivity: 0.6483 - val_recall: 0.9681 - val_precision: 0.6196\n",
            "Epoch 473/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0536 - accuracy: 0.9773 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9760 - precision: 0.9791\n",
            "Epoch 473: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 216ms/step - loss: 0.0536 - accuracy: 0.9773 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9760 - precision: 0.9791 - val_loss: 2.3133 - val_accuracy: 0.6719 - val_sensitivity_at_specificity: 0.9150 - val_specificity_at_sensitivity: 0.6512 - val_recall: 0.9673 - val_precision: 0.5968\n",
            "Epoch 474/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0563 - accuracy: 0.9785 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9776 - precision: 0.9799\n",
            "Epoch 474: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 3s 286ms/step - loss: 0.0563 - accuracy: 0.9785 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9776 - precision: 0.9799 - val_loss: 2.3232 - val_accuracy: 0.6750 - val_sensitivity_at_specificity: 0.9008 - val_specificity_at_sensitivity: 0.6419 - val_recall: 0.9764 - val_precision: 0.6072\n",
            "Epoch 475/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0722 - accuracy: 0.9734 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9737 - precision: 0.9752\n",
            "Epoch 475: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 209ms/step - loss: 0.0722 - accuracy: 0.9734 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9737 - precision: 0.9752 - val_loss: 2.2845 - val_accuracy: 0.6727 - val_sensitivity_at_specificity: 0.8815 - val_specificity_at_sensitivity: 0.6291 - val_recall: 0.9731 - val_precision: 0.6051\n",
            "Epoch 476/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0488 - accuracy: 0.9809 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9771 - precision: 0.9841\n",
            "Epoch 476: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 216ms/step - loss: 0.0488 - accuracy: 0.9809 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9771 - precision: 0.9841 - val_loss: 2.4084 - val_accuracy: 0.6766 - val_sensitivity_at_specificity: 0.8796 - val_specificity_at_sensitivity: 0.6028 - val_recall: 0.9815 - val_precision: 0.6127\n",
            "Epoch 477/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0488 - accuracy: 0.9797 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9790 - precision: 0.9805\n",
            "Epoch 477: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 213ms/step - loss: 0.0488 - accuracy: 0.9797 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9790 - precision: 0.9805 - val_loss: 2.2037 - val_accuracy: 0.6867 - val_sensitivity_at_specificity: 0.8706 - val_specificity_at_sensitivity: 0.6324 - val_recall: 0.9635 - val_precision: 0.6267\n",
            "Epoch 478/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0548 - accuracy: 0.9773 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9746 - precision: 0.9793\n",
            "Epoch 478: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 215ms/step - loss: 0.0548 - accuracy: 0.9773 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9746 - precision: 0.9793 - val_loss: 2.1328 - val_accuracy: 0.6984 - val_sensitivity_at_specificity: 0.8953 - val_specificity_at_sensitivity: 0.6329 - val_recall: 0.9779 - val_precision: 0.6412\n",
            "Epoch 479/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0391 - accuracy: 0.9840 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9811 - precision: 0.9866\n",
            "Epoch 479: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 220ms/step - loss: 0.0391 - accuracy: 0.9840 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9811 - precision: 0.9866 - val_loss: 2.2583 - val_accuracy: 0.6703 - val_sensitivity_at_specificity: 0.8976 - val_specificity_at_sensitivity: 0.6527 - val_recall: 0.9669 - val_precision: 0.6049\n",
            "Epoch 480/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0525 - accuracy: 0.9852 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9802 - precision: 0.9883\n",
            "Epoch 480: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 218ms/step - loss: 0.0525 - accuracy: 0.9852 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9802 - precision: 0.9883 - val_loss: 2.3538 - val_accuracy: 0.6695 - val_sensitivity_at_specificity: 0.8744 - val_specificity_at_sensitivity: 0.6221 - val_recall: 0.9592 - val_precision: 0.6062\n",
            "Epoch 481/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0466 - accuracy: 0.9852 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9842 - precision: 0.9857\n",
            "Epoch 481: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 216ms/step - loss: 0.0466 - accuracy: 0.9852 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 1.0000 - recall: 0.9842 - precision: 0.9857 - val_loss: 2.0989 - val_accuracy: 0.6961 - val_sensitivity_at_specificity: 0.9369 - val_specificity_at_sensitivity: 0.6710 - val_recall: 0.9625 - val_precision: 0.6378\n",
            "Epoch 482/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0342 - accuracy: 0.9875 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9826 - precision: 0.9920\n",
            "Epoch 482: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 217ms/step - loss: 0.0342 - accuracy: 0.9875 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9826 - precision: 0.9920 - val_loss: 2.7739 - val_accuracy: 0.6719 - val_sensitivity_at_specificity: 0.9164 - val_specificity_at_sensitivity: 0.5776 - val_recall: 0.9869 - val_precision: 0.5937\n",
            "Epoch 483/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0537 - accuracy: 0.9809 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9992 - recall: 0.9788 - precision: 0.9827\n",
            "Epoch 483: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 219ms/step - loss: 0.0537 - accuracy: 0.9809 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9992 - recall: 0.9788 - precision: 0.9827 - val_loss: 2.1769 - val_accuracy: 0.6867 - val_sensitivity_at_specificity: 0.9216 - val_specificity_at_sensitivity: 0.6353 - val_recall: 0.9774 - val_precision: 0.6267\n",
            "Epoch 484/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0505 - accuracy: 0.9805 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9798 - precision: 0.9822\n",
            "Epoch 484: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 210ms/step - loss: 0.0505 - accuracy: 0.9805 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9798 - precision: 0.9822 - val_loss: 2.3656 - val_accuracy: 0.6750 - val_sensitivity_at_specificity: 0.9024 - val_specificity_at_sensitivity: 0.6295 - val_recall: 0.9764 - val_precision: 0.6072\n",
            "Epoch 485/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0495 - accuracy: 0.9805 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9798 - precision: 0.9814\n",
            "Epoch 485: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 214ms/step - loss: 0.0495 - accuracy: 0.9805 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9798 - precision: 0.9814 - val_loss: 2.3362 - val_accuracy: 0.6766 - val_sensitivity_at_specificity: 0.8914 - val_specificity_at_sensitivity: 0.6214 - val_recall: 0.9692 - val_precision: 0.6022\n",
            "Epoch 486/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0557 - accuracy: 0.9805 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9754 - precision: 0.9860\n",
            "Epoch 486: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 218ms/step - loss: 0.0557 - accuracy: 0.9805 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9754 - precision: 0.9860 - val_loss: 2.3545 - val_accuracy: 0.6680 - val_sensitivity_at_specificity: 0.9024 - val_specificity_at_sensitivity: 0.6279 - val_recall: 0.9701 - val_precision: 0.6027\n",
            "Epoch 487/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0477 - accuracy: 0.9859 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9805 - precision: 0.9913\n",
            "Epoch 487: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 219ms/step - loss: 0.0477 - accuracy: 0.9859 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9805 - precision: 0.9913 - val_loss: 2.5168 - val_accuracy: 0.6766 - val_sensitivity_at_specificity: 0.9022 - val_specificity_at_sensitivity: 0.5991 - val_recall: 0.9842 - val_precision: 0.6070\n",
            "Epoch 488/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0525 - accuracy: 0.9828 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 0.9992 - recall: 0.9834 - precision: 0.9834\n",
            "Epoch 488: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 216ms/step - loss: 0.0525 - accuracy: 0.9828 - sensitivity_at_specificity: 0.9985 - specificity_at_sensitivity: 0.9992 - recall: 0.9834 - precision: 0.9834 - val_loss: 2.0312 - val_accuracy: 0.6812 - val_sensitivity_at_specificity: 0.9055 - val_specificity_at_sensitivity: 0.6713 - val_recall: 0.9685 - val_precision: 0.6132\n",
            "Epoch 489/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0483 - accuracy: 0.9848 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9869 - precision: 0.9831\n",
            "Epoch 489: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 217ms/step - loss: 0.0483 - accuracy: 0.9848 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9869 - precision: 0.9831 - val_loss: 2.0010 - val_accuracy: 0.6812 - val_sensitivity_at_specificity: 0.8896 - val_specificity_at_sensitivity: 0.6842 - val_recall: 0.9527 - val_precision: 0.6151\n",
            "Epoch 490/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0508 - accuracy: 0.9820 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9985 - recall: 0.9746 - precision: 0.9887\n",
            "Epoch 490: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 216ms/step - loss: 0.0508 - accuracy: 0.9820 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9985 - recall: 0.9746 - precision: 0.9887 - val_loss: 2.3838 - val_accuracy: 0.6687 - val_sensitivity_at_specificity: 0.9087 - val_specificity_at_sensitivity: 0.6341 - val_recall: 0.9776 - val_precision: 0.5980\n",
            "Epoch 491/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0477 - accuracy: 0.9816 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9800 - precision: 0.9838\n",
            "Epoch 491: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 214ms/step - loss: 0.0477 - accuracy: 0.9816 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9800 - precision: 0.9838 - val_loss: 2.3598 - val_accuracy: 0.6836 - val_sensitivity_at_specificity: 0.9107 - val_specificity_at_sensitivity: 0.6277 - val_recall: 0.9702 - val_precision: 0.6159\n",
            "Epoch 492/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0564 - accuracy: 0.9785 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9752 - precision: 0.9807\n",
            "Epoch 492: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 220ms/step - loss: 0.0564 - accuracy: 0.9785 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9752 - precision: 0.9807 - val_loss: 2.1782 - val_accuracy: 0.6625 - val_sensitivity_at_specificity: 0.8995 - val_specificity_at_sensitivity: 0.6667 - val_recall: 0.9708 - val_precision: 0.5913\n",
            "Epoch 493/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0496 - accuracy: 0.9812 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9799 - precision: 0.9829\n",
            "Epoch 493: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 215ms/step - loss: 0.0496 - accuracy: 0.9812 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 0.9992 - recall: 0.9799 - precision: 0.9829 - val_loss: 2.1434 - val_accuracy: 0.6703 - val_sensitivity_at_specificity: 0.8922 - val_specificity_at_sensitivity: 0.6359 - val_recall: 0.9609 - val_precision: 0.6077\n",
            "Epoch 494/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0450 - accuracy: 0.9832 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9798 - precision: 0.9867\n",
            "Epoch 494: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 216ms/step - loss: 0.0450 - accuracy: 0.9832 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9798 - precision: 0.9867 - val_loss: 2.3208 - val_accuracy: 0.6820 - val_sensitivity_at_specificity: 0.8938 - val_specificity_at_sensitivity: 0.5862 - val_recall: 0.9803 - val_precision: 0.6212\n",
            "Epoch 495/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0482 - accuracy: 0.9859 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9992 - recall: 0.9791 - precision: 0.9919\n",
            "Epoch 495: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 217ms/step - loss: 0.0482 - accuracy: 0.9859 - sensitivity_at_specificity: 0.9984 - specificity_at_sensitivity: 0.9992 - recall: 0.9791 - precision: 0.9919 - val_loss: 2.2608 - val_accuracy: 0.6750 - val_sensitivity_at_specificity: 0.9076 - val_specificity_at_sensitivity: 0.6580 - val_recall: 0.9809 - val_precision: 0.6039\n",
            "Epoch 496/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0449 - accuracy: 0.9859 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9842 - precision: 0.9873\n",
            "Epoch 496: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 216ms/step - loss: 0.0449 - accuracy: 0.9859 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9842 - precision: 0.9873 - val_loss: 2.0184 - val_accuracy: 0.6773 - val_sensitivity_at_specificity: 0.8703 - val_specificity_at_sensitivity: 0.6698 - val_recall: 0.9668 - val_precision: 0.6092\n",
            "Epoch 497/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0513 - accuracy: 0.9797 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9761 - precision: 0.9824\n",
            "Epoch 497: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 217ms/step - loss: 0.0513 - accuracy: 0.9797 - sensitivity_at_specificity: 0.9992 - specificity_at_sensitivity: 1.0000 - recall: 0.9761 - precision: 0.9824 - val_loss: 2.4639 - val_accuracy: 0.6844 - val_sensitivity_at_specificity: 0.8820 - val_specificity_at_sensitivity: 0.5928 - val_recall: 0.9829 - val_precision: 0.6170\n",
            "Epoch 498/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0453 - accuracy: 0.9828 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9757 - precision: 0.9897\n",
            "Epoch 498: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 214ms/step - loss: 0.0453 - accuracy: 0.9828 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 1.0000 - recall: 0.9757 - precision: 0.9897 - val_loss: 2.4447 - val_accuracy: 0.6875 - val_sensitivity_at_specificity: 0.9203 - val_specificity_at_sensitivity: 0.6141 - val_recall: 0.9904 - val_precision: 0.6118\n",
            "Epoch 499/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0387 - accuracy: 0.9859 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9855 - precision: 0.9870\n",
            "Epoch 499: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 216ms/step - loss: 0.0387 - accuracy: 0.9859 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9855 - precision: 0.9870 - val_loss: 2.2167 - val_accuracy: 0.6867 - val_sensitivity_at_specificity: 0.8979 - val_specificity_at_sensitivity: 0.6250 - val_recall: 0.9710 - val_precision: 0.6251\n",
            "Epoch 500/500\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0456 - accuracy: 0.9836 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9861 - precision: 0.9815\n",
            "Epoch 500: val_accuracy did not improve from 0.76484\n",
            "10/10 [==============================] - 2s 215ms/step - loss: 0.0456 - accuracy: 0.9836 - sensitivity_at_specificity: 1.0000 - specificity_at_sensitivity: 0.9992 - recall: 0.9861 - precision: 0.9815 - val_loss: 2.2190 - val_accuracy: 0.6789 - val_sensitivity_at_specificity: 0.9128 - val_specificity_at_sensitivity: 0.6425 - val_recall: 0.9715 - val_precision: 0.6093\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Performance Metrics**"
      ],
      "metadata": {
        "id": "8CDWnAN79ifV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Training_Accuracy=history.history['accuracy']\n",
        "Validation_Accuracy=history.history['val_accuracy']\n",
        "Validation_Specificity=history.history['val_specificity_at_sensitivity']\n",
        "Validation_Sensitivity=history.history['val_sensitivity_at_specificity']\n",
        "Validation_Recall=history.history['val_recall']\n",
        "Validation_Precision=history.history['val_precision']\n",
        "Validation_Loss=history.history['val_loss']\n",
        "\n",
        "print(\"Training Accuracy: \",max(Training_Accuracy))\n",
        "print(\"Validation Accuracy: \",max(Validation_Accuracy))\n",
        "print(\"Validation Specificity: \",max(Validation_Specificity))\n",
        "print(\"Validation Sensitivity: \",max(Validation_Sensitivity))\n",
        "print(\"Validation Recall: \",max(Validation_Recall))\n",
        "print(\"Validation Precision: \",max(Validation_Precision))\n",
        "print(\"Validation Loss: \",min(Validation_Loss))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCdS_0U65A0-",
        "outputId": "7903921c-ce43-494b-f2c8-d39f6f02be39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy:  0.987500011920929\n",
            "Validation Accuracy:  0.764843761920929\n",
            "Validation Specificity:  0.9399075508117676\n",
            "Validation Sensitivity:  0.9532710313796997\n",
            "Validation Recall:  1.0\n",
            "Validation Precision:  0.7854610085487366\n",
            "Validation Loss:  0.4533052444458008\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Accuracy Graph**"
      ],
      "metadata": {
        "id": "qykByzz39oIE"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLqjG2X-vdLj",
        "outputId": "d1bf44bc-a15c-45b0-a979-836bb27f471a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        }
      },
      "source": [
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loss Graph**"
      ],
      "metadata": {
        "id": "Q-QYoIq79qNs"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBSAyVfivvHX",
        "outputId": "c83ccdc3-b5b3-4c75-f3b2-ba4b206621f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        }
      },
      "source": [
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}